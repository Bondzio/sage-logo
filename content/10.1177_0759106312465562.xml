<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BMS</journal-id>
<journal-id journal-id-type="hwp">spbms</journal-id>
<journal-title>Bulletin de Méthodologie Sociologique</journal-title>
<issn pub-type="ppub">0759-1063</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0759106312465562</article-id>
<article-id pub-id-type="publisher-id">10.1177_0759106312465562</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Ongoing Research/Recherche en cours</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Articles</article-title>
</title-group>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>117</volume>
<issue>1</issue>
<fpage>114</fpage>
<lpage>117</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE/ Association Internationale de Méthodologie Sociologique</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<p>
<italic>Full presentations of many of the entries below have already been distributed to </italic>BMS<italic> subscribers and RC33 members over the </italic>BMS<italic>-RC33 distribution list<sup>
<xref ref-type="fn" rid="fn1-0759106312465562">1</xref>
</sup>
</italic>
</p>
<p>
<bold>Robert Clark</bold>, “How should Samples be Designed for Difficult to Reach Populations?”, <italic>Survey Statistician</italic>, July 2011, 64, 8-11. Populations may be hard to reach for several reasons: 1. They may tend to live in remote locations. For example, 24 percent of the Australian indigenous population live in areas classified as “very remote”, compared to only 3 percent of the general population (Rogers and Brent, 2008). 2. They may be only a small proportion of the general population. For example, the indigenous populations of Australia, Canada and New Zealand make up 2.4 percent 3.3 percent and 12.1 percent, respectively, of the general population (Clark, 2009). 3. There may be no frame or list available of the population of interest, or the list may be incomplete, out of date or inaccurate. 4. The population may be geographically dispersed, as opposed to being concentrated in particular areas. 5. The population of interest may be mobile, reluctant to participate in surveys, or have a first language differing from the population majority. It is not unusual for all five of these challenges to coincide. The hard to reach population will be referred to as a subpopulation, to distinguish from the general population of which it is part. Subpopulations of interest can include indigenous populations, particular ethnicities, migrants, homeless people, people with a disability, or sufferers of particular medical conditions. Good field procedures, instrument design, interviewer training and effective communication with respondents and communities are the most important elements of a successful survey of a hard to reach population. An effective sample design is also essential. This review describes some of the sample design approaches available.</p>
<p>
<bold>Rebecca R. Andridge</bold> and <bold>Roderick J. A. Little</bold>, “Proxy Pattern-Mixture Analysis for Survey Nonresponse”, <italic>Survey Statistician</italic>, July 2011, 21-26. Missing data are often a problem in sample surveys, arising when a sampled unit does not respond to the entire survey (unit nonresponse) or to a particular question (item nonresponse). We propose a new method for measurement of, and adjustment for, nonresponse in a single continuous variable Y subject to missing values, when a set of variables are available for both respondents and nonrespondents. With unit nonresponse, this set of variables is generally restricted to survey design variables, except in longitudinal surveys where variables are measured prior to dropout. With item nonresponse, the set of observed variables can include survey items not subject to nonresponse, and hence is potentially more extensive. With a set of variables Y subject to nonresponse, our methods could be applied separately for each variable, but we do not consider here methods for multivariate missing data where variables are missing for different sets of cases. The three major components to consider in evaluating nonresponse are (a) the amount of missing data; (b) differences between respondents and nonrespondents on characteristics observed for the entire sample; and (c) the relationship between these fully observed covariates and the survey outcome of interest. Each facet provides some information about the impact of nonresponse, but no single component completely tells the story.</p>
<p>
<bold>Barry Schouten, Jelke Bethlehem, Koen Beullens, Øyvin Kleven, Geert Loosveldt, Annemieke Luiten, Katja Rutar, Natalie Shlomo <bold>and</bold> Chris Skinner</bold>, “Evaluating, Comparing, Monitoring and Improving Representativeness of Survey Response through R-indicators and Partial R-indicators, <italic>Survey Statistician</italic>, January 2012, 65, 24-30. Recently, a strong focus on methods for survey data collection monitoring and tailoring has emerged as a new paradigm to efficiently reduce nonresponse error. Paradata and adaptive survey designs are key words in these new developments. Prerequisites to evaluating, comparing, monitoring and improving quality of survey response are a conceptual framework for representative survey response, indicators to measure deviations thereof, and indicators to identify subpopulations that need increased effort. We describe a set of indicators, called R-indicators, that we believe are fit for these purposes.</p>
<p>
<bold>Manfred Max Bergman</bold>, “The Politics, Fashions, and Conventions of Research Methods”, <italic>Journal of Mixed Methods Research</italic>, 2011, 5, 2, 99-102. The results of an empirical study of any set of phenomena, whether investigating structures, processes, or combinations thereof, are influenced by the theoretical framework and the research methods employed. This article examines the influence of research methods on how phenomena under investigation are conceptualized, defined, measured, and interpreted. It argues that qualitative, quantitative, and, by extension, mixed methods research influence how phenomena are studies, and how these methods are concurrently subject to politics, fashions, and conventions. Inconsistent and impoverished research may be the consequence, particularly for mixed methods research.</p>
<p>
<bold>Nancy L. Leech, Amy B. Dellinger, Kim B. Brannagan <bold>and</bold> Hideyuki Tanaka</bold>, “Evaluating Mixed Research Studies: A Mixed Methods Approach”, <italic>Journal of Mixed Methods Research</italic>, 2010, 4, 1, 17-31. This article demonstrates application of a new framework, the validation framework (VF), to assist researchers in evaluating mixed research studies. Based on an earlier work by Dellinger and Leech, a description of the VF is provided and applied to three studies from education, health care, and counseling fields.</p>
<p>
<bold>Benoît Rihoux</bold>, “Qualitative Comparative Analysis (QCA) and Related Systematic Comparative Methods - Recent Advances and Remaining Challenges for Social Science Research”, <italic>International Sociology</italic>, 2006, 21, 5, 679-706. Recently, qualitative comparative analysis (QCA) has been complemented by other related methods and techniques which this article assesses. The author argues that QCA has decisive advantages in small and intermediate N research designs. QCA and three other related techniques – multi-value QCA (MVQCA), fuzzy sets and MSDO/MDSO – are presented and some current debates on them are summarized. The article also surveys recent contributions and ongoing efforts that have provided some advances in the application of these techniques.</p>
<p>
<bold>Jean-Louis Genard</bold>, « Sept programmes normatifs pour une sociologie critique des inégalités », <italic>SociologieS</italic>, mai 2012, disponibles à http://sociologies.revues.org/3927. Toute sociologie critique présuppose la référence à un horizon normatif fondant la défense des positions critiques. Cet horizon normatif demeure parfois, voire souvent, implicite, vraisemblablement parce que son explicitation paraîtrait transgresser l’impératif de neutralisation axiologique qui marque fortement l’épistémologie des sciences sociales, ou, à tout le moins, parce qu’il fait glisser le travail du sociologue sur les terrains de la théorie politique ou du militantisme. Cette contribution cherche au contraire à rendre explicites ces horizons normatifs dans le cas, central pour la sociologie critique, des inégalités sociales. Sept paradigmes normatifs sont ainsi dégagés, articulés et mis en relation avec les enjeux actuels relatifs aux théories de la justice.</p>
<p>
<bold>Dorothée Behr</bold> and <bold>Evi Scholz</bold>, “Questionnaire Translation in Cross-National Survey Research - On the Types and Value of Annotations”, <italic>Methoden – Daten – Analysen. Zeitschrift für Empirische Sozialforschung</italic>, 2011, 5, 2, 157-80, available at http://www.gesis.org/fileadmin/upload/forschung/publikationen/zeitschriften/mda/Vol.5_Heft_2/MDA_2011_2_Gesamt.pdf. Good questionnaire design and high quality questionnaire translations are vital for data comparability in cross-national survey research. The International Social Survey Programme (ISSP) and the European Social Survey (ESS) annotate the source questionnaire specifically for translation, thus providing guidance on what needs to be considered in translation. This paper studies these translation annotations, a topic having received scant attention in research so far. The goal of this paper is to raise awareness of this special support structure and of potential pitfalls in questionnaire translation.</p>
<p>
<bold>Robert Schoen</bold> and <bold>Claudia Nau</bold>, “A Behaviorally-based Approach to Measuring Inequality”, <italic>Demographic Research</italic>, 2008, 19, 49, 1727-48. The measurement of inequality is often made using observed population-based distributions, such as the distribution of income or the distribution of members of different groups across neighborhoods. Unfortunately, such distributions confound the behavior of a given year with earlier events that influence the composition of the population. Here, we advocate measuring inequality using current behavioral measures and their compositional implications, and show how such measures may be obtained from frequently available data. The results are insensitive to whether inequality is measured by entropy, the Gini Index, or the Index of Dissimilarity. However, the type of distribution analyzed – whether observed or behaviorally derived – can make a significant difference in the results obtained. Because behaviorally derived distributions reflect the inequality implications of actual behavior, they are recommended for greater use in analyses of inequality.</p>
<p>
<bold>Sage Publications Press Release</bold> (2 July 2012). Is social media censorship a means to quell a modern uprising? Some politicians and law enforcers during the political turbulence of 2011 thought so, but recent research suggests that uncensored citizens experience less violence and longer periods of peace between outbursts than communities subject to censorship. These new findings appear in the <italic>Bulletin of Sociological Methodology</italic>, published by Sage. A consensus is forming around Internet censorship in the wake of the 2011 uprisings, extending from the Arab Spring to the UK, according to Antonio Casilli, associate professor in digital humanities at Telecom ParisTech, France, and Paola Tubaro, senior lecturer in economic sociology at the University of Greenwich, UK. The authors used sophisticated computer modeling to find out if the assumptions that actors’ use of media – such as Twitter – fueled mob action through greater awareness were true. Ambiguously, current narratives among the European political establishment suggest social media can be either the tools of liberation (in developing countries) or threats to values of peace and freedom (in Western countries). The researchers used state-of-the-art agent-based modelling as a starting point. Political conflict is often described as cumulative, involving “escalating” conflict and sometimes ending with regime change. However, in reality, periods of relative stability punctuated with violent outbursts are more typical. Existing models include a variable called “vision”, an individual agent’s ability to scan his/her neighbourhood for signs of police officers and/or active protesters. Higher vision means greater awareness of one’s surroundings and a larger range of possible actions. In Casilli and Tubaro’s computer simulation, censorship narrows down vision. It interrupts the flow of communication and decreases the ability of individuals to appreciate their environment. In this sense, censorship blinds social actors to their own context. The researchers found that all possible scenarios led to initial outbursts of violence, but how the situation evolved was significantly influenced by government social media censorship. In a total censorship scenario, similar to the Egyptian riots, violence levels remained at a maximum. Stronger censorship led to an increase in the average level of endemic violence over time. According to the model, the “no censorship” situation at first appears bleak, with incessant, high-level violent outbursts that seem larger than in other scenarios. However, looking at average violence levels over time, the uncensored scenario still has the least aggression.</p>
<p>
<bold>Bart Buelens</bold> and <bold>Jan van den Brakel</bold>, “On the Necessity to Include Personal Interviewing in Mixed-Mode Surveys”, <italic>Survey Practice</italic>, 2010, 10, available at http://surveypractice.wordpress.com/2010/10/27/include-personal-interviewing-in-mixed-mode/.</p>
<p>
<bold>Martina Yvonne Feilzer</bold>, “Doing Mixed Methods Research Pragmatically: Implications for the Rediscovery of Pragmatism as a Research Paradigm”, <italic>Journal of Mixed Methods Research</italic>, 2010, 4, 1, 6-16.</p>
</body>
<back>
<fn-group>
<fn fn-type="other" id="fn1-0759106312465562">
<p><sup>1</sup><email>bms-rc33@services.cnrs.fr</email></p>
</fn>
</fn-group>
</back>
</article>