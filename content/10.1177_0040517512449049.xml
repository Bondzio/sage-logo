<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TRJ</journal-id>
<journal-id journal-id-type="hwp">sptrj</journal-id>
<journal-title>Textile Research Journal</journal-title>
<issn pub-type="ppub">0040-5175</issn>
<issn pub-type="epub">1746-7748</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0040517512449049</article-id>
<article-id pub-id-type="publisher-id">10.1177_0040517512449049</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Objective evaluation of fabric pilling based on wavelet transform and the local binary pattern</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Jing</surname><given-names>Junfeng</given-names></name>
<xref ref-type="aff" rid="aff1-0040517512449049">1</xref>
<xref ref-type="aff" rid="aff2-0040517512449049">2</xref>
<xref ref-type="corresp" rid="corresp1-0040517512449049"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Zhang</surname><given-names>Zanzan</given-names></name>
<xref ref-type="aff" rid="aff2-0040517512449049">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kang</surname><given-names>Xuejuan</given-names></name>
<xref ref-type="aff" rid="aff3-0040517512449049">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Jia</surname><given-names>Jianyuan</given-names></name>
<xref ref-type="aff" rid="aff1-0040517512449049">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0040517512449049"><label>1</label>School of Electronical and Mechanical Engineering, Xidian University, China</aff>
<aff id="aff2-0040517512449049"><label>2</label>School of Electronic and Information, Xi’an Polytechnic University, China</aff>
<aff id="aff3-0040517512449049"><label>3</label>Electric Department, Xi’an Aerotechnical College, China</aff>
<author-notes>
<corresp id="corresp1-0040517512449049">Junfeng Jing, School of Electronic and Information, Xi’an Polytechnic University, 19 South Road, Jinhua, Xi’an, China. Email: <email>jingjunfeng0718@sina.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>11</month>
<year>2012</year>
</pub-date>
<volume>82</volume>
<issue>18</issue>
<fpage>1880</fpage>
<lpage>1887</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>A new objective fabric pilling evaluation method based on wavelet transform and the local binary pattern (LBP) is developed. The surface pills are identified from the high-frequency noise, fabric texture, and illuminative variation of a pilled fabric image by the two-dimensional discrete wavelet transform. The energies of each detailed sub-image at scales 4–6 in three orientations (horizontal, vertical, and diagonal) and the LBP features of the reconstructed detail image from scales 3 to 6 are calculated as elements of the pilling feature vector to characterize the pilling intensity. These feature values are normalized and the vector dimensions are reduced by principal component analysis. Then the support vector machine, a kind of data mining tool, is used as a classifier to classify the pilling grades. The result suggests that the proposed method can successfully evaluate the pilling intensity of knitted fabrics and could be applicable to practical objective pilling evaluation.</p>
</abstract>
<kwd-group>
<kwd>Fabric pilling</kwd>
<kwd>wavelet transform</kwd>
<kwd>local binary pattern</kwd>
<kwd>principal component analysis</kwd>
<kwd>support vector machine</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Fabric surface pilling that affects the quality of products is perceived as a serious problem for the apparel industry.<sup><xref ref-type="bibr" rid="bibr1-0040517512449049">1</xref></sup> Pilling is a process in which the entangled fuzzes, protruding from fibers, form pills on the fabric surface.<sup><xref ref-type="bibr" rid="bibr2-0040517512449049">2</xref></sup> Pilling is an important indicator for evaluating fabric performance and quality. Generally, for the assessment of fabric pilling grades, pilled fabric specimens are compared with a set of standard pilling images by an expert to determine the grade of pilling on a level ranging from 1 to 5 (from severe pilling to no pilling).<sup><xref ref-type="bibr" rid="bibr3-0040517512449049">3</xref></sup> However, this subjective evaluation might be inconsistent and inaccurate in different evaluation personnel.</p>
<p>For an objective pilling evaluating process, a number of automated image analysis systems have been developed and reported.<sup><xref ref-type="bibr" rid="bibr4-0040517512449049">4</xref></sup><sup>–</sup><sup><xref ref-type="bibr" rid="bibr8-0040517512449049">8</xref></sup> All of these methods employ either expensive and complicated equipment or complex image processing algorithms involving multiple stages.<sup><xref ref-type="bibr" rid="bibr9-0040517512449049">9</xref></sup> The wavelet analysis has appeared in the literature to evaluate the pilling intensity objectively. The discrete wavelet transform (DWT) has been used to identify the pilling information in the spatial domain or frequency domain.<sup><xref ref-type="bibr" rid="bibr10-0040517512449049">10</xref></sup><sup>–</sup><sup><xref ref-type="bibr" rid="bibr12-0040517512449049">12</xref></sup> However, all of the above those methods can only provide the gross summary information about the entire image, not accurate local information.</p>
<p>In this study, an integrated feature extraction technique combining two-dimensional discrete wavelet transform (2DDWT) with the local binary pattern (LBP) for pilled fabric image recognition is proposed. The wavelet describes the texture characteristics from the global pixels, while the LBP from the local or pixel neighborhood area describes the texture changes. These two characteristics can well complement each other, because the LBP does not consider the pixels relatively far from the central pixel, but the wavelet just does. In this paper, the pilled images are transformed with the wavelet function Coif1. Pills are identified by the reconstructed detailed sub-images at scales 4–6 (see <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(e)</xref>), and then the wavelet features are extracted. The LBP features of the reconstructed detail image from scales 3–6 (see <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(f)</xref>) are also used as pilling features. These features, in 19 dimensions, yield excellent pilling grade classification. By using principal component analysis (PCA) to reduce the dimension of the pilling feature vector, the support vector machine (SVM) is used to evaluate pilling grades.
<fig id="fig1-0040517512449049" position="float"><label>Figure 1.</label><caption><p>The reconstructed detail images at scales (a) 1–2, (b) 2–3, (c) 3–4, (d) 5–6, (e) 4–6, (f) 3–6, (g) the scale 7 approximation image using wavelet Coif1, and (h) the original pilling knitted sample image.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig1.tif"/></fig></p>
<sec id="sec1-0040517512449049"><title>Two-dimensional discrete wavelet transform</title>
<p>The wavelet transform has a good localization property simultaneously in the time domain and frequency domain. Because it uses a gradually refining sampling step length in the time domain or frequency domain for the high-frequency components, it can focus on any detail of the object, which is called “mathematical microscope”.</p>
<p>A fabric image can be viewed as a two-dimensional signal, and the specific process of using two-dimensional wavelet transform in the image is that the one-dimensional wavelet transform is used sequentially for the rows and columns of a matrix consisting of the pixel gray value.</p>
<p>The result of wavelet decomposition on the image <inline-formula id="ilm1-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math1-0040517512449049"><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> can be expressed as a low-resolution approximate sub-image and all the detailed sub-images.<sup><xref ref-type="bibr" rid="bibr13-0040517512449049">13</xref>,<xref ref-type="bibr" rid="bibr14-0040517512449049">14</xref></sup> These detailed sub-images obtained at each decomposition stage belong to the high frequencies. For example, the <italic>j</italic>th stage will get a low-frequency sub-image <inline-formula id="ilm2-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math2-0040517512449049"><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and three high-frequency sub-images <inline-formula id="ilm3-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math3-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula id="ilm4-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math4-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="ilm5-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math5-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. Then the low-frequency sub-image will be decomposed further at the <italic>j</italic> + 1 stage, and so forth, until the value of <italic>j</italic> is up to the expected scale.</p>
<p>The algorithm is illustrated in <xref ref-type="fig" rid="fig2-0040517512449049">Figure 2</xref>, where Lo_D is the low-pass filter, Hi_D is the high-pass filter; “2 ↓ 1” represents downsampling columns retaining the even column, “1 ↓ 2” represents downsampling rows retaining the even row, and <inline-formula id="ilm6-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math6-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula id="ilm7-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math7-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="ilm8-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math8-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are called the horizontal, vertical, and diagonal detail sub-images, respectively.
<fig id="fig2-0040517512449049" position="float"><label>Figure 2.</label><caption><p>Two-dimensional discrete wavelet decomposition algorithm.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig2.tif"/></fig></p>
<p>A pilled fabric image includes information such as the high-frequency noise, fabric texture, fuzz, pills, surface unevenness, and illuminative variation, while pills are the main features in the pilling evaluating procedure.<sup><xref ref-type="bibr" rid="bibr15-0040517512449049">15</xref></sup> In order to acquire pilling information, we can reconstruct the fabric image with wavelet components. The reconstruction process is converse to the decomposition process. There is a simple and effective method to attain the reconstructed pilling images by simply setting the irrelevant detail coefficients to zero.<sup><xref ref-type="bibr" rid="bibr3-0040517512449049">3</xref></sup></p>
</sec>
<sec id="sec2-0040517512449049"><title>Local binary pattern</title>
<p>The LBP, which was first proposed by Ojala (Ojala et al.;<sup><xref ref-type="bibr" rid="bibr16-0040517512449049">16</xref></sup> Ahonen et al.<sup><xref ref-type="bibr" rid="bibr17-0040517512449049">17</xref></sup>), is a kind of operator that describes the texture characteristics effectively. The LBP features have a highly discriminative ability, high computational efficiency, the rotational invariance, gray invariance, and other significant advantages.</p>
<sec id="sec3-0040517512449049"><title>The basic LBP operator</title>
<p>The application process of the LBP operator is similar to the template operation in the filtering process, the progressive-scanning image (see <xref ref-type="fig" rid="fig3-0040517512449049">Figure 3</xref>). For each pixel (<italic>x<sub>c</sub></italic>, <italic>y<sub>c</sub></italic>), the gray value <italic>i<sub>c</sub></italic> is used as threshold of a local 3 × 3 window pixel gray value <italic>i<sub>n</sub></italic>(<italic>n</italic> = 0, 1, 2, … , 7) for binarization. If the neighbor has a higher or equal gray value than the central pixel, it is assigned a code bit 1, otherwise 0. These bits are read out according to a certain order, such as clockwise, and placed in a dyadic code word in accordance with <xref ref-type="disp-formula" rid="disp-formula1-0040517512449049">Equation (1)</xref>:
<disp-formula id="disp-formula1-0040517512449049"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math1-0040517512449049"><mml:mrow><mml:mi>LBP</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:munderover><mml:mi>s</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>among</mml:mtext><mml:mi>s</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo/><mml:mo>{</mml:mo></mml:mrow><mml:msub><mml:mi/><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo/></mml:mrow></mml:math><graphic alternate-form-of="disp-formula1-0040517512449049" xlink:href="10.1177_0040517512449049-eq1.tif"/></disp-formula>
<fig id="fig3-0040517512449049" position="float"><label>Figure 3.</label><caption><p>Basic local binary pattern operator.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig3.tif"/></fig></p>
</sec>
<sec id="sec4-0040517512449049"><title>Circular neighborhood <italic>LBP<sub>P</sub></italic><sub>, R</sub> operator</title>
<p>The basic LBP operator has been further extended to achieve rotational invariance. Using a circular neighborhood with bilinear interpolation operation allows us to get any radius and any number of neighbors. This kind of LBP operator is usually written as <italic>LBP<sub>P</sub></italic><sub>, </sub><italic><sub>R</sub></italic>, where <italic>P</italic> indicates the number of pixels contained in the neighbors and <italic>R</italic> is the neighbor radius. Three common LBP operators written, as <italic>LBP</italic><sub>8,2</sub>, <italic>LBP</italic><sub>16,2</sub>, and <italic>LBP</italic><sub>24,3</sub>, are shown in <xref ref-type="fig" rid="fig4-0040517512449049">Figure 4</xref>. With circular LBP patterns, the image is evaluated around a pixel on a circle around the pixel. For detecting small changes effectively in textures, we used eight circular neighbor points on images. This LBP description is more compact and more robust against noise.
<fig id="fig4-0040517512449049" position="float"><label>Figure 4.</label><caption><p>Circularly symmetric neighbor sets for different (<italic>P</italic>, <italic>R</italic>).</p></caption><graphic xlink:href="10.1177_0040517512449049-fig4.tif"/></fig></p>
<p>Through further improvement, Ojala et al.<sup><xref ref-type="bibr" rid="bibr16-0040517512449049">16</xref></sup> put forward the uniform patterns concept, which is another major improvement of the LBP operator. For a LBP, if the number of 0/1 changes is no more than two in the same circular structure, it is called a uniform pattern, written as <inline-formula id="ilm9-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math9-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>LBP</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The superscript <italic>u</italic><sub>2</sub> indicates the uniform pattern of rotational invariance. Uniform <italic>LBP<sub>P</sub></italic><sub>, </sub><italic><sub>R</sub></italic> is defined as follows:
<disp-formula id="disp-formula2-0040517512449049"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math2-0040517512449049"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>LBP</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo/><mml:mo>{</mml:mo></mml:mrow><mml:msub><mml:mi/><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>   </mml:mi><mml:mi>else</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mtext>S</mml:mtext><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>   </mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>LBP</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo/><mml:mo/></mml:mrow><mml:mo>,</mml:mo><mml:mi>   </mml:mi><mml:mtext>among</mml:mtext></mml:mrow><mml:mtr><mml:mtd columnalign="right" columnspan="1"><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>LBP</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" columnspan="1"><mml:mrow><mml:mi>   </mml:mi><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:math><graphic alternate-form-of="disp-formula2-0040517512449049" xlink:href="10.1177_0040517512449049-eq2.tif"/></disp-formula>
</p>
<p><xref ref-type="fig" rid="fig5-0040517512449049">Figure 5</xref> shows the radius <italic>R</italic> = 1, neighbors <italic>P</italic> = 8 corresponding to the <italic>P</italic> + 1 = 9 kinds of uniform patterns (white points are 1, black points are 0).
<fig id="fig5-0040517512449049" position="float"><label>Figure 5.</label><caption><p><italic>R</italic> = 1, <italic>P</italic> = 8 corresponding to the uniform pattern.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig5.tif"/></fig></p>
<p>After the LBP transform, the feature vectors could be calculated from their histograms. In this paper, we calculate the 10-dimensional frequency histogram with a uniform LBP of eight circular neighbor points. The uniform histogram realizes the histogram dimensional reduction and contains important texture information, with good statistical significance.</p>
</sec>
</sec>
<sec id="sec5-0040517512449049"><title>Experimental details</title>
<sec id="sec6-0040517512449049" sec-type="methods"><title>Method</title>
<p>The method proposed in this paper is shown in <xref ref-type="fig" rid="fig6-0040517512449049">Figure 6</xref>. After normalization and PCA, these features are used as the input values of the SVM for training and testing.
<fig id="fig6-0040517512449049" position="float"><label>Figure 6.</label><caption><p>Diagram of the proposed method.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig6.tif"/></fig></p>
</sec>
<sec id="sec7-0040517512449049"><title>Sample preparation</title>
<p>The standard knitted pilling test image set has five pilling grades (1–5). For each pilling grade, there are 10 sample images of 512 × 512 pixels (see <xref ref-type="fig" rid="fig7-0040517512449049">Figure 7</xref>), each of which includes all of the pilling information.
<fig id="fig7-0040517512449049" position="float"><label>Figure 7.</label><caption><p>Standard knitted pilling test image set.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig7.tif"/></fig></p>
</sec>
<sec id="sec8-0040517512449049"><title>Image transformation</title>
<p>The pilling image is transformed by the wavelet decomposition and reconstruction, and the results are showed in <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1</xref>. It is obvious that scale 1 and scale 2 detailed sub-images have no pilling information; they contain the highest frequency noise (see <xref ref-type="fig" rid="fig1-0040517512449049">Figures 1(a) and 1(b)</xref>) in the original image. Scale 3 comprises mainly fabric texture and scale 4 has some small pills (see <xref ref-type="fig" rid="fig1-0040517512449049">Figures 1(b) and 1(c)</xref>). Scales 5 and 6 include lots of different size fuzz and pills (see <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(d)</xref>); scale 7 is the approximation image with largely background illuminative variation (see <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(g)</xref>). Combining scale 4 with scale 6 detailed sub-images, <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(e)</xref> is the reconstructed image, which captures almost all of the pilling information. <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(f)</xref>, which is reconstructed by combining scale 3 with scale 6 detailed sub-images, is almost identical to the original image (see <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(h)</xref>), except background gray values.</p>
<p>From the above analysis, the fuzz and pills could be identified by the wavelet decomposition and reconstruction detailed images at several scales; the minimum size of pills will be measured further by the LBP technique.</p>
</sec>
<sec id="sec9-0040517512449049"><title>Wavelet feature extraction</title>
<p>The wavelet feature contains the energies of three directional (<italic>h</italic>, <italic>v</italic>, <italic>d</italic>) detailed sub-images at scales 4–6. The energy is defined as
<disp-formula id="disp-formula3-0040517512449049"><label>(3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math3-0040517512449049"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>jk</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo>≤</mml:mo><mml:mtext>j</mml:mtext><mml:mo>≤</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula3-0040517512449049" xlink:href="10.1177_0040517512449049-eq3.tif"/></disp-formula>
where <italic>M</italic> × <italic>N</italic> is the size of the image and <inline-formula id="ilm10-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math10-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the pixel gray value at the <italic>j</italic>th scale and the <italic>k</italic> direction. Because the mean value of each detail coefficient is zero, the energy is equal to the standard deviation of the wavelet detail coefficient.<sup><xref ref-type="bibr" rid="bibr15-0040517512449049">15</xref></sup></p>
</sec>
<sec id="sec10-0040517512449049"><title>LBP feature extraction</title>
<p>Wavelet transform has multi-scale characteristics and the uniform LBP operator has the shift and rotation invariance for describing the texture changes. These two characteristics can well complement each other.</p>
<p>The LBP feature is presented by the frequency histogram. We extracted the LBP feature from the reconstructed fabric texture image that is shown in <xref ref-type="fig" rid="fig1-0040517512449049">Figure 1(f)</xref>.</p>
<p>The combined detection approach is used for the experiment process evaluating the standard knitted pilling images. We extract the energies of each detail sub-image at scales 4–6 in three directions and the LBP features of the reconstructed detail image from scales 3–6 as the elements of the pilling feature vector to characterize the pilling intensity.</p>
</sec>
<sec id="sec11-0040517512449049"><title>Pilling evaluation using the SVM</title>
<p>The SVM is a new machine learning method based on the structural risk minimization principle. It is a supervised learning system that has been developed from statistical learning theory.<sup><xref ref-type="bibr" rid="bibr18-0040517512449049">18</xref>,<xref ref-type="bibr" rid="bibr19-0040517512449049">19</xref></sup> The goal of the SVM is to find an optimal separating hyperplane, which can give the input samples correctly classified as consistent and distinct categories, and make the classification interval between the divided input samples the largest possible.</p>
<p>Given a training sample set (<italic>x<sub>i</sub></italic>, <italic>y<sub>i</sub></italic>), <italic>i</italic> = 1, 2, 3, … , <italic>n</italic>, <italic>x</italic> ∈ <italic>R<sup>d</sup></italic>, <italic>y</italic> ∈ (+1, −1) is the class label. The linear discriminant function in the <italic>d</italic>-dimensional space is <inline-formula id="ilm11-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math11-0040517512449049"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mo>·</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></inline-formula>; the classification surface equation is <inline-formula id="ilm12-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math12-0040517512449049"><mml:mrow><mml:mi>w</mml:mi><mml:mo>·</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Normalize the discriminant function to make all samples meet <inline-formula id="ilm13-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math13-0040517512449049"><mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. That is to say the samples near the hyperplane meet <inline-formula id="ilm14-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math14-0040517512449049"><mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Therefore, the classification interval is <inline-formula id="ilm15-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math15-0040517512449049"><mml:mrow><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo/></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo/></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> and, in order to make the interval largest, <inline-formula id="ilm16-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math16-0040517512449049"><mml:mrow><mml:mrow><mml:mo/></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo/></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> (or <inline-formula id="ilm17-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math17-0040517512449049"><mml:mrow><mml:mrow><mml:mo/></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:mo/></mml:mrow><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) must be the lowest value. The SVM requires the following optimization classification equation to solve the optimization problem:
<disp-formula id="disp-formula4-0040517512449049"><label>(4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math4-0040517512449049"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>sgn</mml:mtext><mml:mrow><mml:mo/><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo/><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>sgn</mml:mtext><mml:mrow><mml:mo/><mml:mo>{</mml:mo></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo/><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula4-0040517512449049" xlink:href="10.1177_0040517512449049-eq4.tif"/></disp-formula>
where <inline-formula id="ilm18-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math18-0040517512449049"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the optimal solution and its value is 0 for the non-support vector; <inline-formula id="ilm19-0040517512449049"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math19-0040517512449049"><mml:mrow><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the classification threshold. For the non-linear problem, the input space is firstly transformed to a higher (maybe infinite) dimensional space through the inner product kernel function, and then SVM finds a linear optimal hyperplane in the new space. The optimization classification equation becomes
<disp-formula id="disp-formula5-0040517512449049"><label>(5)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math5-0040517512449049"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>sgn</mml:mtext><mml:mrow><mml:mo/><mml:mo>{</mml:mo></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo/><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula5-0040517512449049" xlink:href="10.1177_0040517512449049-eq5.tif"/></disp-formula>
</p>
<p>In this paper, the radial basis kernel function (RBF) is the first choice:
<disp-formula id="disp-formula6-0040517512449049"><label>(6)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math6-0040517512449049"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mi>γ</mml:mi><mml:mrow><mml:mo/></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>-</mml:mo><mml:mtext>x</mml:mtext></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/></mml:mrow><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula6-0040517512449049" xlink:href="10.1177_0040517512449049-eq6.tif"/></disp-formula>
</p>
<p>All of the sample images are extracted features according to the above experimental procedure, and the original data set (see <xref ref-type="fig" rid="fig8-0040517512449049">Figure 8(a)</xref>) contains the class labels and several attributes. Firstly, this data set should be separated into training and testing sets. Secondly, both the training and testing data are scaled to the range [0, 1]; the training data scaling are showed in <xref ref-type="fig" rid="fig8-0040517512449049">Figures 8(b) and (c)</xref>. This is very important for the SVM to avoid the data in the greater numeric range dominating those in the smaller numeric range. Thirdly, the feature vector is 19 dimensions, making it too large to use the SVM. With PCA, several representative pilling features can be extracted from the original data. In <xref ref-type="fig" rid="fig8-0040517512449049">Figure 8(f)</xref>, we can see that the first four principal components account for more than 90% of the variance in the data set, thus they are selected as the input data of the SVM. After PCA, the first three principal components plots of training and testing sets are as shown in <xref ref-type="fig" rid="fig8-0040517512449049">Figures 8(d) and (e)</xref>. This can more convenient for the SVM to classify the pilling samples accurately. Finally, these features are operated by the SVM and, in the process, the SVM can produce a model based on the training data, which predicts the target values of the testing data. <xref ref-type="fig" rid="fig8-0040517512449049">Figure 8(g)</xref> is the classification result of the testing data using the SVM, and the classification accuracy is 95%.
<fig id="fig8-0040517512449049" position="float"><label>Figure 8.</label><caption><p>The classification process of the pilling samples using the support vector machine.</p></caption><graphic xlink:href="10.1177_0040517512449049-fig8a.tif"/><graphic xlink:href="10.1177_0040517512449049-fig8b.tif"/></fig>
</p>
</sec>
</sec>
<sec id="sec12-0040517512449049" sec-type="conclusions"><title>Conclusion</title>
<p>We have provided an effective way to objectively evaluate the pilling grades of standard pilling test images based on wavelet transform and the LBP. It has been found that the fabric texture information comes from the high-frequency detailed sub-images and the pilling information is from the low-frequency ones. Therefore, the fuzz and pills can be identified by using wavelet decomposition and reconstruction: the reconstructed detail image at scales 4–6 captures almost all of the pilling information and the fabric texture image from the reconstructed scales 3–6 detailed images is almost identical to the original image. The combined pilling feature vector contains the wavelet features and the LBP features. These feature values are classified by the SVM to evaluate the pilling grades. The classification results further verify the ability of the pilling identification and characterization method.</p>
</sec>
</body>
<back>
<sec id="sec13-0040517512449049"><title>Funding</title>
<p>This work was supported by the Scientific Research Program funded by Shaanxi Provincial Education Department (grant numbers 11JK0910, 11JK0919), Shaanxi, PRC.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="bibr1-0040517512449049"><label>1</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yap</surname><given-names>PH</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><etal/></person-group>. <article-title>Prediction of wool knitwear pilling propensity using support vector machines</article-title>. <source>Text Res J</source> <year>2010</year>; <volume>80</volume>: <fpage>77</fpage>–<lpage>83</lpage>.</citation></ref>
<ref id="bibr2-0040517512449049"><label>2</label><citation citation-type="other"><comment>Tortora PG and Collier BJ. <italic>Understanding Textiles</italic>. 5th ed. New Jersey, United States: Prentice-Hall, 1997</comment>.</citation></ref>
<ref id="bibr3-0040517512449049"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group>. <article-title>An integrated method of feature extraction and objective evaluation of fabric pilling</article-title>. <source>J Text Inst</source> <year>2011</year>; <volume>102</volume>: <fpage>1</fpage>–<lpage>13</lpage>.</citation></ref>
<ref id="bibr4-0040517512449049"><label>4</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Amirbayat</surname><given-names>J</given-names></name><name><surname>Alagha</surname><given-names>MJ</given-names></name></person-group>. <article-title>The objective assessment of fabric pilling - Part II: experimental work</article-title>. <source>J Text Inst</source> <year>1994</year>; <volume>85</volume>: <fpage>397</fpage>–<lpage>401</lpage>.</citation></ref>
<ref id="bibr5-0040517512449049"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>B</given-names></name></person-group>. <article-title>Instrumental evaluation of fabric pilling</article-title>. <source>J Text Inst</source> <year>1997</year>; <volume>88</volume>: <fpage>488</fpage>–<lpage>500</lpage>.</citation></ref>
<ref id="bibr6-0040517512449049"><label>6</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Abril</surname><given-names>HC</given-names></name><name><surname>Millan</surname><given-names>MS</given-names></name><name><surname>Torres</surname><given-names>Y</given-names></name><etal/></person-group>. <article-title>An automatic method based on image analysis for pilling evaluation in fabrics</article-title>. <source>Opt Eng</source> <year>1998</year>; <volume>37</volume>: <fpage>2937</fpage>–<lpage>2947</lpage>.</citation></ref>
<ref id="bibr7-0040517512449049"><label>7</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sirikasemleert</surname><given-names>A</given-names></name><name><surname>Tao</surname><given-names>X</given-names></name></person-group>. <article-title>Objective evaluation of textural changes in knitted fabrics by laser triangulation</article-title>. <source>Text Res J</source> <year>2000</year>; <volume>70</volume>: <fpage>1076</fpage>–<lpage>1087</lpage>.</citation></ref>
<ref id="bibr8-0040517512449049"><label>8</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>XB</given-names></name></person-group>. <article-title>Evaluating fabric pilling with light-projected image analysis</article-title>. <source>Text Res J</source> <year>2004</year>; <volume>74</volume>: <fpage>977</fpage>–<lpage>981</lpage>.</citation></ref>
<ref id="bibr9-0040517512449049"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group>. <article-title>Objective classification of fabric pilling based on the two-dimensional discrete wavelet transform</article-title>. <source>Text Res J</source> <year>2003</year>; <volume>73</volume>: <fpage>713</fpage>–<lpage>720</lpage>.</citation></ref>
<ref id="bibr10-0040517512449049"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mallat</surname><given-names>SG</given-names></name></person-group>. <article-title>A theory for multiresolution signal decomposition: the wavelet representation</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <year>1989</year>; <volume>11</volume>: <fpage>674</fpage>–<lpage>693</lpage>.</citation></ref>
<ref id="bibr11-0040517512449049"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>CY</given-names></name><name><surname>Chiu</surname><given-names>SH</given-names></name><name><surname>Hsu</surname><given-names>WS</given-names></name><etal/></person-group>. <article-title>Defect segmentation of texture images with wavelet transform and a co-occurrence matrix</article-title>. <source>Text Res J</source> <year>2001</year>; <volume>71</volume>: <fpage>743</fpage>–<lpage>749</lpage>.</citation></ref>
<ref id="bibr12-0040517512449049"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tsai</surname><given-names>DM</given-names></name><name><surname>Chiang</surname><given-names>CH</given-names></name></person-group>. <article-title>Automatic band selection for wavelet reconstruction in the application of defect detection</article-title>. <source>Image Vision Comput</source> <year>2003</year>; <volume>21</volume>: <fpage>413</fpage>–<lpage>431</lpage>.</citation></ref>
<ref id="bibr13-0040517512449049"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>CS</given-names></name><name><surname>Chung</surname><given-names>PC</given-names></name><name><surname>Chen</surname><given-names>CF</given-names></name></person-group>. <article-title>Unsupervised texture segmentation via wavelet transform</article-title>. <source>Pattern Recognit</source> <year>1997</year>; <volume>30</volume>: <fpage>729</fpage>–<lpage>742</lpage>.</citation></ref>
<ref id="bibr14-0040517512449049"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bashar</surname><given-names>MK</given-names></name><name><surname>Matsumoto</surname><given-names>T</given-names></name><name><surname>Ohnishi</surname><given-names>N</given-names></name></person-group>. <article-title>Wavelet transform-based locally orderless images for texture segmentation</article-title>. <source>Pattern Recognit Lett</source> <year>2003</year>; <volume>24</volume>: <fpage>2633</fpage>–<lpage>2650</lpage>.</citation></ref>
<ref id="bibr15-0040517512449049"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Palmer</surname><given-names>S</given-names></name></person-group>. <article-title>Objective pilling evaluation of wool fabrics</article-title>. <source>Text Res J</source> <year>2007</year>; <volume>77</volume>: <fpage>929</fpage>–<lpage>936</lpage>.</citation></ref>
<ref id="bibr16-0040517512449049"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ojala</surname><given-names>T</given-names></name><name><surname>Pietikainen</surname><given-names>M</given-names></name><name><surname>Maenpaa</surname><given-names>T</given-names></name></person-group>. <article-title>Multi-resolution gray-scale and rotation invariant texture classification with local binary patterns</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <year>2002</year>; <volume>24</volume>: <fpage>971</fpage>–<lpage>978</lpage>.</citation></ref>
<ref id="bibr17-0040517512449049"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ahonen</surname><given-names>T</given-names></name><name><surname>Hadid</surname><given-names>A</given-names></name><name><surname>Pietikainen</surname><given-names>M</given-names></name></person-group>. <article-title>Face description with local binary patterns: application to face recognition</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <year>2006</year>; <volume>28</volume>: <fpage>2037</fpage>–<lpage>2041</lpage>.</citation></ref>
<ref id="bibr18-0040517512449049"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>KQ</given-names></name><name><surname>Ong</surname><given-names>CJ</given-names></name><name><surname>Li</surname><given-names>XP</given-names></name><etal/></person-group>. <article-title>Feature selection using SVM probabilistic outputs</article-title>. <source>Lect Notes Comput Sci</source> <year>2006</year>; <volume>4232</volume>: <fpage>782</fpage>–<lpage>791</lpage>.</citation></ref>
<ref id="bibr19-0040517512449049"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mavroforakis</surname><given-names>ME</given-names></name><name><surname>Theodoridis</surname><given-names>S</given-names></name></person-group>. <article-title>A geometric approach to support vector machine (SVM) classification</article-title>. <source>IEEE Trans Neural Networks</source> <year>2006</year>; <volume>17</volume>: <fpage>671</fpage>–<lpage>682</lpage>.</citation></ref>
</ref-list>
</back>
</article>