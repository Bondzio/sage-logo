<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">APM</journal-id>
<journal-id journal-id-type="hwp">spapm</journal-id>
<journal-title>Applied Psychological Measurement</journal-title>
<issn pub-type="ppub">0146-6216</issn>
<issn pub-type="epub">1552-3497</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0146621612449069</article-id>
<article-id pub-id-type="publisher-id">10.1177_0146621612449069</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Recognizing Uncertainty in the Q-Matrix via a Bayesian Extension of the DINA Model</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>DeCarlo</surname><given-names>Lawrence T.</given-names></name>
<xref ref-type="aff" rid="aff1-0146621612449069">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0146621612449069"><label>1</label>Columbia University, NY, USA</aff>
<author-notes>
<corresp id="corresp1-0146621612449069">Lawrence T. DeCarlo, Department of Human Development, Box 118, Teachers College, Columbia University, 525 West 120th Street, New York, NY 10027-6696, USA Email: <email>decarlo@tc.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2012</year>
</pub-date>
<volume>36</volume>
<issue>6</issue>
<fpage>447</fpage>
<lpage>468</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>In the typical application of a cognitive diagnosis model, the Q-matrix, which reflects the theory with respect to the skills indicated by the items, is assumed to be known. However, the Q-matrix is usually determined by expert judgment, and so there can be uncertainty about some of its elements. Here it is shown that this uncertainty can be recognized and explored via a Bayesian extension of the DINA (deterministic input noisy and) model. The approach used is to specify some elements of the Q-matrix as being random rather than as fixed; posterior distributions can then be used to obtain information about elements whose inclusion in the Q-matrix is questionable. Simulations show that this approach helps to recover the true Q-matrix when there is uncertainty about some elements. An application to the fraction-subtraction data of K. K. Tatsuoka suggests a modified Q-matrix that gives improved relative fit.</p>
</abstract>
<kwd-group>
<kwd>cognitive diagnosis</kwd>
<kwd>DINA</kwd>
<kwd>Q-matrix</kwd>
<kwd>Bayesian analysis</kwd>
<kwd>fraction-subtraction data</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>The goal in cognitive diagnosis, as the name suggests, is to “diagnose” which skills examinees have or do not have. This approach potentially offers more useful feedback to examinees than a simple overall score derived from classical test theory or item response theory, and so cognitive diagnosis models (CDMs) have become popular in recent years (for reviews, see <xref ref-type="bibr" rid="bibr9-0146621612449069">DiBello, Roussos, &amp; Stout, 2007</xref>; <xref ref-type="bibr" rid="bibr10-0146621612449069">Fu &amp; Li, 2007</xref>; <xref ref-type="bibr" rid="bibr24-0146621612449069">Rupp &amp; Templin, 2008b</xref>). A useful CDM that has been widely studied is the DINA (deterministic input noisy and) model (<xref ref-type="bibr" rid="bibr12-0146621612449069">Haertel, 1989</xref>; <xref ref-type="bibr" rid="bibr15-0146621612449069">Junker &amp; Sijtsma, 2001</xref>; <xref ref-type="bibr" rid="bibr18-0146621612449069">Macready &amp; Dayton, 1977</xref>).</p>
<p>The use of a CDM requires the specification of a Q-matrix (<xref ref-type="bibr" rid="bibr27-0146621612449069">K. K. Tatsuoka, 1990</xref>); the Q-matrix indicates the set of skills that are required to answer a particular item correctly. The Q-matrix is usually determined by expert judgment, and so there can be uncertainty about some of its elements. Here, it is noted that this uncertainty can be recognized by using a Bayesian approach, with some elements of the Q-matrix specified as being random rather than as fixed. Posterior distributions can then be used to obtain information about the inclusion or exclusion of these elements, as shown in the following. The Bayesian approach allows one to explore possible modifications of the Q-matrix, ideally as suggested by expert judgment or by substantive considerations. It is shown that the approach is simple to implement, particularly with a reparameterized version of the DINA model. Simulations that explore benefits and limitations of the approach are presented, and the widely analyzed fraction-subtraction data of <xref ref-type="bibr" rid="bibr27-0146621612449069">K. K. Tatsuoka (1990)</xref> are examined.</p>
<sec id="section1-0146621612449069">
<title>Uncertainty in the Q-Matrix</title>
<p>Most researchers who have worked with CDMs have recognized that there is often uncertainty with respect to at least some elements of the Q-matrix. For example, virtually every researcher who has analyzed the fraction-subtraction data has suggested possible modifications of the Q-matrix (e.g., <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>; <xref ref-type="bibr" rid="bibr6-0146621612449069">de la Torre, 2009</xref>; <xref ref-type="bibr" rid="bibr8-0146621612449069">de la Torre &amp; Douglas, 2008</xref>; <xref ref-type="bibr" rid="bibr14-0146621612449069">Henson, Templin, &amp; Willse, 2009</xref>; <xref ref-type="bibr" rid="bibr26-0146621612449069">C. Tatsuoka, 2002</xref>; <xref ref-type="bibr" rid="bibr27-0146621612449069">K. K. Tatsuoka, 1990</xref>), and so there is clearly uncertainty as to the correct specification of some elements. There are several approaches to this problem. One is to consider a set of alternative Q-matrices and to fit the models associated with these matrices; indices of relative fit, such as the Bayesian information criterion (BIC) or Akaike information criterion (AIC), can then be used to help determine the appropriate Q-matrix. This approach has been used by a number of researchers (e.g., <xref ref-type="bibr" rid="bibr1-0146621612449069">Barnes, Bitzer, &amp; Vouk, 2005</xref>; <xref ref-type="bibr" rid="bibr2-0146621612449069">Cen, Koedinger, &amp; Junker, 2005</xref>; <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>; <xref ref-type="bibr" rid="bibr8-0146621612449069">de la Torre &amp; Douglas, 2008</xref>; <xref ref-type="bibr" rid="bibr23-0146621612449069">Rupp &amp; Templin, 2008a</xref>). A limitation of this approach, however, is that the number of possible Q-matrices grows quickly as the number of uncertain elements increases. For example, the following simulation examines a situation where there is uncertainty about 12 elements of the Q-matrix (out of 60 elements), which gives 2<sup>12</sup> = 4,096 possible Q-matrices, and so a large number of models would need to be fitted and compared.</p>
<p>An approach to this problem was offered by <xref ref-type="bibr" rid="bibr5-0146621612449069">de la Torre (2008)</xref>, in which he suggested using a sequential search algorithm, which helps to avoid the large number of possibilities associated with an exhaustive search. In particular, a sequential search algorithm was used with a fit statistic that minimizes the sum of the average slip and guess parameters. There are, however, some limitations to that approach. For example, de la Torre noted that the approach is based on a particular fit statistic, δ, and that other statistics might be more useful or appropriate. Another problem is that the sequential search algorithm might not lead to the best solution; this is suggested below in a reanalysis of the fraction-subtraction data of <xref ref-type="bibr" rid="bibr27-0146621612449069">K. K. Tatsuoka (1990)</xref>.</p>
<p>Another way to recognize uncertainty is via a Bayesian approach, as has been noted by several researchers. For example, <xref ref-type="bibr" rid="bibr28-0146621612449069">J. Templin and Henson (2006)</xref> used a Bayesian approach to allow for uncertain elements in the Q-matrix, in the same manner as done here. Similarly, <xref ref-type="bibr" rid="bibr21-0146621612449069">Muthén and Asparouhov (2010)</xref> discussed using a Bayesian approach to recognize uncertainty in factor analysis models (e.g., to recognize uncertainty about factor loadings) and other (structural equation and regression) models. It is shown here that a Bayesian approach is useful and is simple to implement, particularly with a reparameterized version of the DINA model.</p>
</sec>
<sec id="section2-0146621612449069">
<title>The DINA Model and a Reparameterization</title>
<p>The basic idea underlying the DINA model is that, for each item, certain skills are needed for an examinee to answer the item correctly. The skills are assumed to be either present or absent, and so the skills are latent dichotomous variables that take on values of zero or one, typically denoted as α<sub><italic>ik</italic></sub> for examinee <italic>i</italic> and skill <italic>k</italic>. The DINA model is a <italic>conjunctive</italic> model (<xref ref-type="bibr" rid="bibr19-0146621612449069">Maris, 1999</xref>), in that it is assumed that an examinee must have <italic>all</italic> the required skills to answer an item correctly.</p>
<p>Let <italic>Y</italic><sub><italic>ij</italic></sub> be a binary variable that indicates whether the response of the <italic>i</italic>th examinee to the <italic>j</italic>th item is correct or incorrect (1 or 0), and let <inline-formula id="inline-formula1-0146621612449069">
<mml:math display="inline" id="math1-0146621612449069">
<mml:mrow>
<mml:mi mathvariant="bold">α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> denote the vector of <italic>K</italic> skills that are needed to solve the items. The Q-matrix consists of elements <italic>q</italic><sub><italic>jk</italic></sub> that specify which of the <italic>K</italic> skills are needed to solve the <italic>j</italic>th item. Thus, the Q-matrix elements consist of zeroes and ones, with a value of zero indicating that the <italic>k</italic>th skill is <italic>not</italic> needed, and a value of one indicating that the skill is needed. These ideas lead to the DINA model, where the probability that an examinee gets an item correct is</p>
<p><disp-formula id="disp-formula1-0146621612449069">
<mml:math display="block" id="math2-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi mathvariant="bold">α</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>η</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msup>
<mml:msubsup>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>η</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0146621612449069" xlink:href="10.1177_0146621612449069-eq1.tif"/>
</disp-formula></p>
<p>with <inline-formula id="inline-formula2-0146621612449069">
<mml:math display="inline" id="math3-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>η</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ik</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> (e.g., <xref ref-type="bibr" rid="bibr6-0146621612449069">de la Torre, 2009</xref>; <xref ref-type="bibr" rid="bibr14-0146621612449069">Henson et al., 2009</xref>; <xref ref-type="bibr" rid="bibr15-0146621612449069">Junker &amp; Sijtsma, 2001</xref>). The parameter <italic>s</italic><sub><italic>j</italic></sub> is the <italic>slip</italic> rate for examinee <italic>j</italic>, which is the probability that an examinee who has the requisite skills gets the item incorrect. The parameter <italic>g</italic><sub><italic>j</italic></sub> is the <italic>guess</italic> rate. It has previously been noted (e.g., <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>; <xref ref-type="bibr" rid="bibr15-0146621612449069">Junker &amp; Sijtsma, 2001</xref>) that the DINA model is a type of signal detection model. In signal detection theory (SDT; <xref ref-type="bibr" rid="bibr17-0146621612449069">Macmillan &amp; Creelman, 2005</xref>), a “slip” is a <italic>miss</italic>: The examinee has the requisite skills, but he or she misses getting the item correct. A “guess” in SDT is related to the <italic>false alarm</italic> rate: The examinee does not have the requisite skills, but nevertheless gets the item correct (guessing is simply an interpretation of false alarms).</p>
<p>Substituting the second equation above into the first gives the DINA model,</p>
<p><disp-formula id="disp-formula2-0146621612449069">
<mml:math display="block" id="math4-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi mathvariant="bold">α</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:munderover>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ik</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:msup>
<mml:msubsup>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:munderover>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ik</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0146621612449069" xlink:href="10.1177_0146621612449069-eq2.tif"/>
</disp-formula></p>
<p>For the Bayesian generalization, uncertainty is recognized by allowing some of the elements of the Q-matrix (i.e., the <italic>q</italic><sub><italic>jk</italic></sub>) to be random rather than fixed, as done by <xref ref-type="bibr" rid="bibr28-0146621612449069">J. Templin and Henson (2006)</xref> and discussed the following. The preceding form of the model, however, is somewhat complex (e.g., the <italic>q</italic><sub><italic>jk</italic></sub> are exponents of exponents). A simpler (but equivalent) form of the model can be obtained by reparameterizing it as follows:</p>
<p><disp-formula id="disp-formula3-0146621612449069">
<mml:math display="block" id="math5-0146621612449069">
<mml:mrow>
<mml:mtext>logit</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi mathvariant="bold">α</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:munderover>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ik</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0146621612449069" xlink:href="10.1177_0146621612449069-eq3.tif"/>
</disp-formula>
</p>
<p><xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref> is a reparameterization of the DINA model and has been referred to as the RDINA (reparameterized deterministic input noisy and) model (<xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>). The parameter <italic>f</italic><sub><italic>j</italic></sub> is the false alarm rate, as described earlier, whereas <italic>d</italic><sub><italic>j</italic></sub> is a <italic>discrimination</italic> (detection) parameter that indicates how well the item discriminates between the presence versus absence of the required skill set. The parameter <italic>d</italic><sub><italic>j</italic></sub> has an interpretation in SDT as a distance measure (e.g., <xref ref-type="bibr" rid="bibr3-0146621612449069">DeCarlo, 2010</xref>; <xref ref-type="bibr" rid="bibr17-0146621612449069">Macmillan &amp; Creelman, 2005</xref>); a related discrimination parameter, although not a distance measure, has been discussed by <xref ref-type="bibr" rid="bibr13-0146621612449069">Henson, Roussos, Douglas, and He (2008)</xref>. Note that the DINA parameters are easily recovered from the RDINA parameters,</p>
<p><disp-formula id="disp-formula4-0146621612449069">
<mml:math display="block" id="math6-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0146621612449069" xlink:href="10.1177_0146621612449069-eq4.tif"/>
</disp-formula></p>
<p>where exp is the exponential function, and</p>
<p><disp-formula id="disp-formula5-0146621612449069">
<mml:math display="block" id="math7-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0146621612449069" xlink:href="10.1177_0146621612449069-eq5.tif"/>
</disp-formula></p>
<p>An attractive aspect of <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref> is that it is a simple logistic regression model with latent (multiplicative) predictors (i.e., the latent dichotomous α), and so it can easily be fit with software for latent class analysis, as previously shown (<xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>). In a similar vein, although the Bayesian generalization can be accomplished with either form of the model, the RDINA version is simple to implement, as shown in the <xref ref-type="app" rid="app1-0146621612449069">Appendix</xref>.</p>
<p>Note that, when fitting the DINA or RDINA model, the fixed elements <italic>q</italic><sub><italic>jk</italic></sub> in <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref> are simply set to zero or one, according to the Q-matrix specification. For example, suppose that out of a set of four skills, Skills 1 and 3 are considered as necessary to solve the first item, but not Skills 2 or 4. The first row of the Q-matrix is then 1, 0, 1, 0, which means that the model for the first item is</p>
<p><disp-formula id="disp-formula6-0146621612449069">
<mml:math display="block" id="math8-0146621612449069">
<mml:mrow>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mtext>logit</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>×</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>×</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>×</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0146621612449069" xlink:href="10.1177_0146621612449069-eq6.tif"/>
</disp-formula></p>
<p>which shows that the <italic>q</italic><sub><italic>jk</italic></sub> elements simply select which terms (α<sub><italic>ik</italic></sub>) appear in the model. Note that the product term following <italic>d</italic><sub>1</sub> is equal to one only if skills α<sub><italic>i</italic>1</sub> and α<sub><italic>i</italic>3</sub> are present; otherwise, it is equal to zero, which is the conjunctive aspect of the model. The Bayesian extension of <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref> differs in that some <italic>q</italic><sub><italic>jk</italic></sub> explicitly appear in the model as random parameters, rather than being set to zero or one.</p>
<p><xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref> is the “examinee-level” part of the model, which is concerned with how the examinees’ response patterns are related to the skill patterns. The full model includes a (higher order) model for the skill patterns:</p>
<p><disp-formula id="disp-formula7-0146621612449069">
<mml:math display="block" id="math9-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mi mathvariant="bold">α</mml:mi>
</mml:munder>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:munder>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∏</mml:mo>
</mml:mstyle>
<mml:mi>j</mml:mi>
</mml:munder>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0146621612449069" xlink:href="10.1177_0146621612449069-eq7.tif"/>
</disp-formula></p>
<p>where the first term on the right of the equal sign is the “skill-level” model and the second term is the examinee-level model. The skill-level model is concerned with relations among the skills, and the term <inline-formula id="inline-formula3-0146621612449069">
<mml:math display="inline" id="math10-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> is the probability of a particular skill pattern. A simple assumption is independence, in which case</p>
<p><disp-formula id="disp-formula8-0146621612449069">
<mml:math display="block" id="math11-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0146621612449069" xlink:href="10.1177_0146621612449069-eq8.tif"/>
</disp-formula></p>
<p>where <italic>p</italic>(α<sub><italic>k</italic></sub>) are the probabilities of the <italic>K</italic> skills (latent class sizes in latent class analysis). <xref ref-type="disp-formula" rid="disp-formula7-0146621612449069">Equation 2</xref> also has a product term, which follows from an assumption of local independence of the indicators given the skills. Note that <inline-formula id="inline-formula4-0146621612449069">
<mml:math display="inline" id="math12-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>α</mml:mtext>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> in <xref ref-type="disp-formula" rid="disp-formula7-0146621612449069">Equation 2</xref> can be obtained by applying the inverse of the logit function to <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref>, where the inverse of the logit function, known as the <italic>expit</italic> function, is exp(<italic>a</italic>)/[1 + exp(<italic>a</italic>)]. This form of the model is used in the program given in the <xref ref-type="app" rid="app1-0146621612449069">appendix</xref>.</p>
<p>In addition to the simple DINA and RDINA models with independence, various higher order models have also been considered in the literature on CDMs (e.g., <xref ref-type="bibr" rid="bibr7-0146621612449069">de la Torre &amp; Douglas, 2004</xref>; <xref ref-type="bibr" rid="bibr29-0146621612449069">J. L. Templin, Henson, Templin, &amp; Roussos, 2008</xref>); these models allow for structure in the skill-level part of the model, such as allowing for correlations among the skills. For example, the independence assumption can be replaced with a conditional independence assumption by including a latent continuous variable θ (e.g., examinee ability) in the skill-level part of the model as follows:</p>
<p><disp-formula id="disp-formula9-0146621612449069">
<mml:math display="block" id="math13-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mo>∫</mml:mo>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>θ</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0146621612449069" xlink:href="10.1177_0146621612449069-eq9.tif"/>
</disp-formula></p>
<p>The latent variable θ accounts for associations among the <italic>K</italic> skills, as in a factor analysis model. Replacing <inline-formula id="inline-formula5-0146621612449069">
<mml:math display="inline" id="math14-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> in <xref ref-type="disp-formula" rid="disp-formula7-0146621612449069">Equation 2</xref> with the preceding gives a higher order model for the skills, which has been referred to as the HO-DINA (higher order deterministic input noisy and) model (e.g., <xref ref-type="bibr" rid="bibr7-0146621612449069">de la Torre &amp; Douglas, 2004</xref>). In this case, it is assumed that the conditional probabilities of the skills, <italic>p</italic>(<bold>α</bold>|θ), are independent conditional on θ:</p>
<p><disp-formula id="disp-formula10-0146621612449069">
<mml:math display="block" id="math15-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0146621612449069" xlink:href="10.1177_0146621612449069-eq10.tif"/>
</disp-formula></p>
<p>A simple logistic model has been used for the higher order model (e.g., <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>; <xref ref-type="bibr" rid="bibr7-0146621612449069">de la Torre &amp; Douglas, 2004</xref>):</p>
<p><disp-formula id="disp-formula11-0146621612449069">
<mml:math display="block" id="math16-0146621612449069">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0146621612449069" xlink:href="10.1177_0146621612449069-eq11.tif"/>
</disp-formula></p>
<p>where <italic>b</italic><sub><italic>k</italic></sub> is an item difficulty parameter and <italic>a</italic><sub><italic>k</italic></sub> is an item discrimination parameter. Using the higher order model with <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equations 1</xref> and <xref ref-type="disp-formula" rid="disp-formula7-0146621612449069">2</xref> gives a higher order version of the reparameterized version of the model (higher order reparameterized deterministic input noisy and [HO-RDINA]).</p>
<p>As previously shown, the RDINA and HO-RDINA models are simple to implement in software that can fit logistic models, or more generally, <italic>generalized linear models</italic> with latent predictors, such as LEM (<xref ref-type="bibr" rid="bibr31-0146621612449069">Vermunt, 1997</xref>), Latent Gold (<xref ref-type="bibr" rid="bibr32-0146621612449069">Vermunt &amp; Magidson, 2005</xref>), and other software (e.g., GLLAMM; <xref ref-type="bibr" rid="bibr22-0146621612449069">Rabe-Hesketh, Skrondal, &amp; Pickles, 2004</xref>); for sample LEM and Latent Gold programs, see <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo (2011)</xref>. The software can also be used to consider various extensions of the models, such as allowing for more than two response categories (with nominal or ordinal responses) or allowing for skills with more than two categories (either nominal or ordinal). With respect to the (more complex) Bayesian extensions of the RDINA and HO-RDINA models considered here, the freely available software OpenBUGS (<xref ref-type="bibr" rid="bibr30-0146621612449069">Thomas, O’Hara, Ligges, &amp; Sturtz, 2006</xref>) can be used; the <xref ref-type="app" rid="app1-0146621612449069">Appendix</xref> provides a sample program.</p>
</sec>
<sec id="section3-0146621612449069">
<title>The Bayesian RDINA/HO-RDINA Models</title>
<p>Bayesian extensions of the above models allow some of the elements of the Q-matrix to be random rather than fixed. In particular, instead of fixing all the <italic>q</italic><sub><italic>jk</italic></sub> to zero or one, which is the usual approach to specifying the Q-matrix, some of the <italic>q</italic><sub><italic>jk</italic></sub> are treated as random variables, and in particular as Bernoulli variables with parameters <italic>p</italic><sub><italic>jk</italic></sub>. The choice of Bernoulli variables reflects the fact that the <italic>q</italic><sub><italic>jk</italic></sub> only take on values of zero or one. The current approach relaxes the assumption, for some elements of Q, that the <italic>q</italic><sub><italic>jk</italic></sub> are known. Posterior distributions can then be used to guide decisions about the <italic>q</italic><sub><italic>jk</italic></sub> in question.</p>
<p>The Bayesian version of the RDINA model can be specified in the same manner as earlier. To start, the <italic>Y</italic><sub><italic>ij</italic></sub> are conditionally independent and Bernoulli distributed:</p>
<p><disp-formula id="disp-formula12-0146621612449069">
<mml:math display="block" id="math17-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mtext>Bernoulli</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0146621612449069" xlink:href="10.1177_0146621612449069-eq12.tif"/>
</disp-formula></p>
<p>where <italic>p</italic><sub><italic>j</italic></sub> is given by the inverse of <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref>; that is,</p>
<p><disp-formula id="disp-formula13-0146621612449069">
<mml:math display="block" id="math18-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi mathvariant="bold">α</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mtext>expit</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:munderover>
<mml:mo>Π</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ik</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula13-0146621612449069" xlink:href="10.1177_0146621612449069-eq13.tif"/>
</disp-formula></p>
<p>where the expit function is as defined above. In the Bayesian approach, the parameters <italic>f</italic><sub><italic>j</italic></sub> and <italic>d</italic><sub><italic>j</italic></sub> are specified as random. In addition, instead of being fixed, some of the elements of the Q-matrix are now treated as Bernoulli variables:</p>
<p><disp-formula id="disp-formula14-0146621612449069">
<mml:math display="block" id="math19-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mtext>Bernoulli</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula14-0146621612449069" xlink:href="10.1177_0146621612449069-eq14.tif"/>
</disp-formula></p>
<p>where the tilde (~) on <italic>q</italic> is used to indicate that the element is random (compare <xref ref-type="bibr" rid="bibr16-0146621612449069">Lee, 2004</xref> ); note that the use of tilde is avoided in the following when it is clear from the context that <italic>q</italic> is random. As before, elements of the Q-matrix that are assumed to be known are set to zero or one, according to the Q-matrix specification. For uncertain elements, however, <inline-formula id="inline-formula6-0146621612449069">
<mml:math display="inline" id="math20-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is a Bernoulli variable with probability <italic>p</italic><sub><italic>jk</italic></sub> (note that <italic>p</italic><sub><italic>j</italic></sub> is the conditional response probability, whereas <italic>p</italic><sub><italic>jk</italic></sub> is the Q-element probability). A Beta prior, with hyperparameters α and β, is used for <italic>p</italic><sub><italic>jk</italic></sub>:</p>
<p><disp-formula id="disp-formula15-0146621612449069">
<mml:math display="block" id="math21-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mtext>Beta</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula15-0146621612449069" xlink:href="10.1177_0146621612449069-eq15.tif"/>
</disp-formula></p>
<p>For example, Beta(1,1) is the uniform distribution and is used as a prior below. As is well known in Bayesian analysis, the Beta distribution is a conjugate prior for the Bernoulli distribution, and so the posteriors of <italic>p</italic><sub><italic>jk</italic></sub> given <inline-formula id="inline-formula7-0146621612449069">
<mml:math display="inline" id="math22-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> are also Beta:</p>
<p><disp-formula id="disp-formula16-0146621612449069">
<mml:math display="block" id="math23-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mtext>Beta</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula16-0146621612449069" xlink:href="10.1177_0146621612449069-eq16.tif"/>
</disp-formula></p>
<p>The posterior reflects the information that the data provide about whether <inline-formula id="inline-formula8-0146621612449069">
<mml:math display="inline" id="math24-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is one or zero; it has a mean of</p>
<p><disp-formula id="disp-formula17-0146621612449069">
<mml:math display="block" id="math25-0146621612449069">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>α</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mi>α</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula17-0146621612449069" xlink:href="10.1177_0146621612449069-eq17.tif"/>
</disp-formula></p>
<p><xref ref-type="disp-formula" rid="disp-formula17-0146621612449069">Equation 4</xref> shows that, for a Beta(1,1) prior, the posterior mean for <italic>p</italic><sub><italic>jk</italic></sub> will be 1/3 if <inline-formula id="inline-formula9-0146621612449069">
<mml:math display="inline" id="math26-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> and 2/3 if <inline-formula id="inline-formula10-0146621612449069">
<mml:math display="inline" id="math27-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> (see the following results). The posterior density of <inline-formula id="inline-formula11-0146621612449069">
<mml:math display="inline" id="math28-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> or <italic>p</italic><sub><italic>jk</italic></sub> for the random elements of Q can be used to help determine whether a skill should be included in a particular item, that is, whether the “true”<italic>q</italic><sub><italic>jk</italic></sub> is zero or one. A decision can be implemented by simply rounding the posterior mean of <inline-formula id="inline-formula12-0146621612449069">
<mml:math display="inline" id="math29-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, as done by <xref ref-type="bibr" rid="bibr28-0146621612449069">J. Templin and Henson (2006)</xref> and below or, similarly, by using a cut point of 0.50 for the posterior mean of <italic>p</italic><sub><italic>jk</italic></sub> (i.e., <italic>q</italic><sub><italic>jk</italic></sub> is zero if <italic>p</italic><sub><italic>jk</italic></sub>&lt; .5 and one otherwise).</p>
</sec>
<sec id="section4-0146621612449069">
<title>Implementation in OpenBUGS</title>
<p>The <xref ref-type="app" rid="app1-0146621612449069">Appendix</xref> provides a program that shows how to implement the Bayesian RDINA model using the freely available software OpenBUGS. The program includes uncertainty about the skills for Items 1, 8, and 13, as in the simulations below. The program shows that to include uncertain elements, the latent dichotomous variable α<sub><italic>k</italic></sub> (denoted as <italic>xk</italic> in the program) is raised to the power <italic>q</italic><sub><italic>jk</italic></sub>, where <italic>q</italic><sub><italic>jk</italic></sub> is a Bernoulli variable with parameter <italic>p</italic><sub><italic>jk</italic></sub>. Each uncertain element has its own probability, with a Beta(1,1) prior used for <italic>p</italic><sub><italic>jk</italic></sub>. In addition, “mildly” informative normal priors (mean of 0 and variance of 10; note that OpenBUGS uses the precision, which is the inverse of the variance) are used for <italic>f</italic><sub><italic>j</italic></sub> and <italic>d</italic><sub><italic>j</italic></sub>, and the bounds function, I(0,), is used to restrict <italic>d</italic> to positive values (more informative priors could also be used, given that there is often information available about values of SDT parameters found in practice).</p>
<p>Note that, although the model could be fit as in <xref ref-type="disp-formula" rid="disp-formula3-0146621612449069">Equation 1</xref> by using a logit transform of the response probabilities, problems can arise with this approach when there are extreme probabilities, because the logits then go toward plus or minus infinity. This problem does not appear to arise if the probability version of the model (i.e., with the expit function) is used, as is done in the program in the <xref ref-type="app" rid="app1-0146621612449069">Appendix</xref>.</p>
</sec>
<sec id="section5-0146621612449069">
<title>Simulations: Uncertainty About Q-Matrix Elements</title>
<p>The utility of the Bayesian approach is examined in a number of small simulations. The basic RDINA model with independence is first examined in several conditions to determine if the Bayesian approach is of use in at least the simplest case. In the first simulation, there is uncertainty about 4 elements of the Q-matrix (for three items), with the remaining elements correctly specified. In the second simulation, there is complete uncertainty about the skills for three items, giving a total of 12 uncertain elements (20% of the 60 Q-matrix elements), as shown by the Bayesian Q-matrix in <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>. The third simulation introduces a new aspect, in that there is again uncertainty about 12 elements, as in the second simulation; however, 6 other elements of the Q-matrix are now incorrectly specified in the fitted model, as shown in <xref ref-type="table" rid="table2-0146621612449069">Table 2</xref>. Thus, the third simulation examines the effect of misspecification of other parts of the Q-matrix (i.e., parts that are not under question) on recovery of elements that are considered uncertain. One could argue that this is a realistic situation, in that it seems likely that in practice, some elements of the Q-matrix might be misspecified without the researcher’s knowledge (i.e., the elements are not recognized as being uncertain).</p>
<table-wrap id="table1-0146621612449069" position="float">
<label>Table 1.</label>
<caption><p>True Q-Matrix and Bayesian Q-Matrix (Conditions 2 and 7) for Four Skills and Fifteen Items</p>
</caption>
<graphic alternate-form-of="table1-0146621612449069" xlink:href="10.1177_0146621612449069-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Q-matrix<hr/></th>
<th align="center" colspan="4">Bayesian Q-matrix<hr/></th>
</tr>
<tr>
<th align="left">Item No.</th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><italic>q</italic><sub>11</sub></td>
<td><italic>q</italic><sub>12</sub></td>
<td><italic>q</italic><sub>13</sub></td>
<td><italic>q</italic><sub>14</sub></td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>7</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>8</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td><italic>q</italic><sub>81</sub></td>
<td><italic>q</italic><sub>82</sub></td>
<td><italic>q</italic><sub>83</sub></td>
<td><italic>q</italic><sub>84</sub></td>
</tr>
<tr>
<td>9</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>10</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>11</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>12</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>13</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td><italic>q</italic><sub>131</sub></td>
<td><italic>q</italic><sub>132</sub></td>
<td><italic>q</italic><sub>133</sub></td>
<td><italic>q</italic><sub>134</sub></td>
</tr>
<tr>
<td>14</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>15</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0146621612449069">
<p>Note: The Bayesian Q-matrix has complete uncertainty about the four skills for Items 1, 8, and 13.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table2-0146621612449069" position="float">
<label>Table 2.</label>
<caption><p>Q-matrix With Complete Uncertainty for Three Items and Six Misspecified Elements (Conditions 3 and 8)</p>
</caption>
<graphic alternate-form-of="table2-0146621612449069" xlink:href="10.1177_0146621612449069-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Bayesian Q-matrix with misspecification<hr/></th>
</tr>
<tr>
<th align="left">Item No.</th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><italic>q</italic><sub>11</sub></td>
<td><italic>q</italic><sub>12</sub></td>
<td><italic>q</italic><sub>13</sub></td>
<td><italic>q</italic><sub>14</sub></td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0→1</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>0→1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>7</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1→0</td>
</tr>
<tr>
<td>8</td>
<td><italic>q</italic><sub>81</sub></td>
<td><italic>q</italic><sub>82</sub></td>
<td><italic>q</italic><sub>83</sub></td>
<td><italic>q</italic><sub>84</sub></td>
</tr>
<tr>
<td>9</td>
<td>0→1</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>10</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>11</td>
<td>1</td>
<td>1</td>
<td>1→0</td>
<td>0</td>
</tr>
<tr>
<td>12</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>13</td>
<td><italic>q</italic><sub>131</sub></td>
<td><italic>q</italic><sub>132</sub></td>
<td><italic>q</italic><sub>133</sub></td>
<td><italic>q</italic><sub>134</sub></td>
</tr>
<tr>
<td>14</td>
<td>0</td>
<td>1→0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>15</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0146621612449069">
<p>Note: Misspecified elements are shown with arrows, with original value followed by the misspecified value. For example, Skill 3 (α<sub>3</sub>) for Item 2 is misspecified as 1, whereas it is 0 in the true Q-matrix shown in <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The preceding conditions examine the utility of the Bayesian approach for determining uncertain elements in the Q-matrix, with the number of skills correctly specified. The next three conditions provide some information about a different question, which is whether the correct number of skills has been specified. In the fourth condition, the same data used in the first three simulations were used, and the fitted model used the correct Q-matrix for the first three skills; however, the fourth skill (which was necessary) was specified as being completely uncertain for all 15 items. In this situation, one is not sure if the fourth skill should be included, but in fact it is necessary. The fifth condition is the same as the fourth condition, except that five other elements of the Q-matrix were misspecified, as shown in <xref ref-type="table" rid="table2-0146621612449069">Table 2</xref> (although <italic>q</italic><sub>74</sub> was now uncertain instead of misspecified). In the sixth condition, the Q-matrix was correctly specified for the first four skills, but a fifth (nonrequired) skill, with complete uncertainty about its elements, was introduced. In this situation, one is again not sure whether an additional skill is needed, but in this case it should not be included. The fourth through sixth conditions provide information about the use of the Bayesian approach in situations where there is uncertainty as to the number of skills.</p>
<p>Finally, the seventh and eighth conditions examined the utility of the approach in situations where the skills have a higher order structure. In particular, data were generated according to the HO-RDINA model given earlier. In the seventh condition, the fitted model had 12 uncertain elements, as in the second condition stated earlier, with the difference that the generated data had a higher order structure. In the eighth condition, the fitted model again had 12 uncertain elements and, in addition, 6 misspecified elements, as in the third condition stated earlier. The simulations provide information about a range of basic situations of interest.</p>
<sec id="section6-0146621612449069">
<title>Method</title>
<p>The simulations used a Q-matrix for 15 items that was previously used by <xref ref-type="bibr" rid="bibr23-0146621612449069">Rupp and Templin (2008a)</xref> and <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo (2011)</xref>; the matrix is shown in <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>. For the generated data, the population values chosen for the detection parameters <italic>d</italic><sub><italic>j</italic></sub> and the false alarm rates <italic>f</italic><sub><italic>j</italic></sub> were similar to estimates obtained for real data in previous research. For example, an analysis of Tatsuoka’s fraction-subtraction data with RDINA (<xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>) gave estimates of <italic>d</italic><sub><italic>j</italic></sub> for 21 items that ranged from 1.7 to 6.9 with a mean of 4.3, and estimates of <italic>f</italic><sub><italic>j</italic></sub> that ranged from −4.8 to −0.1 with a mean of −2.3. For the current simulation, values of <italic>d</italic><sub><italic>j</italic></sub> from 1.5 to 5.5 and <italic>f</italic><sub><italic>j</italic></sub> from −4 to 0 were used; the skill class sizes were 0.38, 0.50, 0.62, and 0.73, and the sample size was 1,000. The purpose here was not to examine parameter recovery (which appeared to be good), but rather to explore whether the Bayesian approach helps to recover the true Q-matrix elements when there is uncertainty about them.</p>
<p>The Bayesian RDINA and HO-RDINA models were fitted using OpenBUGS. For each condition, the complete analysis was repeated for the 20 generated data sets. For each run, the data were loaded into OpenBUGS, and the syntax program (see the <xref ref-type="app" rid="app1-0146621612449069">appendix</xref>) was then run with 5,000 burn-ins followed by 20,000 iterations for posterior sampling. With this number of iterations, the Monte Carlo errors (see <xref ref-type="bibr" rid="bibr11-0146621612449069">Geyer, 1992</xref>), which are given in the OpenBUGS output, were generally less than 5% of the sample standard deviations (also given in the output), which has previously been suggested as a rule of thumb to assess convergence (<xref ref-type="bibr" rid="bibr25-0146621612449069">Spiegelhalter, Thomas, Best, &amp; Lunn, 2003</xref>). Multiple chains also appeared to converge.</p>
<p>In the first condition, four elements in the fitted RDINA model were specified as being uncertain; specifically, elements <italic>q</italic><sub>13</sub>, <italic>q</italic><sub>14</sub>, <italic>q</italic><sub>82</sub>, and <italic>q</italic><sub>131</sub> for Items 1, 8, and 13 were treated as Bernoulli variables. In the second condition, there was complete uncertainty about all the skills for 3 items (a kind of worst-case scenario), as shown by the Q-matrix on the right side of <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref> with 12 uncertain elements; note that this would require an examination of 4,096 Q-matrices in an exhaustive search approach. In the third condition, there were again 12 uncertain elements in the Q-matrix, but 6 other elements were incorrectly specified in the fitted model, and in particular, three skills were incorrectly included and three skills were incorrectly excluded, as shown by the Q-matrix in <xref ref-type="table" rid="table2-0146621612449069">Table 2</xref>.</p>
<p>The next three conditions examined situations where there was complete uncertainty about a skill. In the fourth condition, the fitted model used the correct Q-matrix (shown on the left side of <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>); however, all elements for the fourth skill were treated as being uncertain, that is, the <italic>q</italic><sub><italic>j</italic>4</sub> were random for all 15 items. This examines a situation where there is uncertainty about whether the skill is needed, when in fact it is needed. The fifth condition was the same except that five other elements of the Q-matrix were misspecified, as shown in <xref ref-type="table" rid="table2-0146621612449069">Table 2</xref> (with the difference that <italic>q</italic><sub>74</sub> was specified as uncertain rather than misspecified). For the sixth condition, the fitted model used the Q-matrix for the four skills, as shown in <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>, but a fifth skill was also included, with all elements treated as uncertain, and so the <italic>q</italic><sub><italic>j</italic>5</sub> were uncertain for all 15 items. This examines a situation where there is uncertainty about whether an additional skill should be included, when in fact it should not be included.</p>
<p>Finally, in the seventh and eighth conditions, data with a simple higher order structure for the skills were generated. These conditions provide information about Q-element recovery in the presence of a higher order skill structure. In particular, data for the HO-RDINA model were generated, with <xref ref-type="disp-formula" rid="disp-formula11-0146621612449069">Equation 3</xref> used to specify the higher order structure; the Q-matrix was the same as that shown in <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>. The population values for the higher order parameters were suggested by results for an application of the HO-RDINA model (and restricted versions) to the fraction-subtraction data (<xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>), which found estimates of <italic>a</italic><sub><italic>k</italic></sub> that ranged from 0.7 to 4.0 (and 3.5 for a version with equal <italic>a</italic><sub><italic>k</italic></sub>) and estimates of <italic>b</italic><sub><italic>k</italic></sub> that ranged from −1 to 4. For the simulation, a common value of <italic>a</italic><sub><italic>k</italic></sub> = 3 was used with values of <italic>b</italic><sub>1</sub> to <italic>b</italic><sub>4</sub> of −1, 0, 1, and 2, respectively (which give skill class sizes similar to those used for the RDINA simulation above). In Condition 7, the fitted HO-RDINA model (with equal <italic>a</italic><sub><italic>k</italic></sub>) had 12 elements of the Q-matrix specified as being uncertain, as in Condition 2. In Condition 8, the fitted model had 12 uncertain Q-elements, and 6 misspecified elements, as in Condition 3.</p>
</sec>
<sec id="section7-0146621612449069">
<title>Results</title>
<sec id="section8-0146621612449069">
<title>Condition 1: Four uncertain Q-elements</title>
<p>The main tools used here are means and plots of the posterior distributions of <italic>q</italic><sub><italic>jk</italic></sub> and <italic>p</italic><sub><italic>jk</italic></sub> for the uncertain elements. For example, for the first generated data set, <xref ref-type="fig" rid="fig1-0146621612449069">Figure 1</xref> shows plots from OpenBUGS of the posterior distributions of <italic>q</italic><sub><italic>jk</italic></sub> and <italic>p</italic><sub><italic>jk</italic></sub>. The true Q-matrix elements in this case are 0, 0, 1, 1, and it is apparent that a similar pattern appears in the plots. For example, the first row of <xref ref-type="fig" rid="fig1-0146621612449069">Figure 1</xref> shows that the posteriors for <inline-formula id="inline-formula13-0146621612449069">
<mml:math display="inline" id="math30-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> are fractional and suggest values of zero. The second row shows that the posteriors of <inline-formula id="inline-formula14-0146621612449069">
<mml:math display="inline" id="math31-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> are both simply one. Thus, the posteriors clearly suggest the pattern 0, 0, 1, 1, which is correct. The same holds for the posterior distributions of <italic>p</italic><sub><italic>jk</italic></sub>, shown in the third and fourth rows of <xref ref-type="fig" rid="fig1-0146621612449069">Figure 1</xref>, which tend toward “left-edge” triangles when the true <italic>q</italic><sub><italic>jk</italic></sub> is zero (third row) and “right-edge” triangles when the true <italic>q</italic><sub><italic>jk</italic></sub> is one (fourth row). Note that a left- or right-edge triangle shape occurs when the posteriors are Beta(1,2) or Beta(2,1), respectively, which gives posterior means of 0.33 and 0.67, as shown in <xref ref-type="disp-formula" rid="disp-formula17-0146621612449069">Equation 4</xref>. The data in this case provide a single observation as to whether <inline-formula id="inline-formula15-0146621612449069">
<mml:math display="inline" id="math32-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is 0 or 1. Note that, although the fourth row shows sharp triangles, which reflect the posterior means of 0.67 found for <italic>p</italic><sub><italic>jk</italic></sub>, the third row does not, but rather shows “left-leaning” plots with posterior means of <italic>p</italic><sub><italic>jk</italic></sub> of 0.41 and 0.42 (see <xref ref-type="table" rid="table3-0146621612449069">Table 3</xref>), and so there is fractional evidence that the <inline-formula id="inline-formula16-0146621612449069">
<mml:math display="inline" id="math33-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> are zero, exactly as shown by the posterior means of <inline-formula id="inline-formula17-0146621612449069">
<mml:math display="inline" id="math34-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> in the first row.</p>
<fig id="fig1-0146621612449069" position="float">
<label>Figure 1.</label>
<caption><p>The top four plots are the posterior distributions for <inline-formula id="inline-formula18-0146621612449069">
<mml:math display="inline" id="math35-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> for the first generated data set in the first condition, with a plot for each of the four uncertain elements. The second four plots are the posterior distributions for <italic>p</italic><sub><italic>jk</italic></sub>.</p>
</caption>
<graphic xlink:href="10.1177_0146621612449069-fig1.tif"/>
</fig>
<table-wrap id="table3-0146621612449069" position="float">
<label>Table 3.</label>
<caption><p>Posterior Means of Q-Matrix Elements and Probabilities for 20 Replications (Condition 1)</p>
</caption>
<graphic alternate-form-of="table3-0146621612449069" xlink:href="10.1177_0146621612449069-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Data set</th>
<th align="center"><italic>q</italic><sub>13</sub></th>
<th align="center"><italic>q</italic><sub>14</sub></th>
<th align="center"><italic>q</italic><sub>82</sub></th>
<th align="center"><italic>q</italic><sub>131</sub></th>
<th align="center"><italic>p</italic><sub>13</sub></th>
<th align="center"><italic>p</italic><sub>14</sub></th>
<th align="center"><italic>p</italic><sub>82</sub></th>
<th align="center"><italic>p</italic><sub>131</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.227</td>
<td>0.269</td>
<td>1.000</td>
<td>1.000</td>
<td>0.407</td>
<td>0.423</td>
<td>0.666</td>
<td>0.664</td>
</tr>
<tr>
<td>2</td>
<td>0.321</td>
<td>0.323</td>
<td>1.000</td>
<td>1.000</td>
<td>0.442</td>
<td>0.442</td>
<td>0.666</td>
<td>0.666</td>
</tr>
<tr>
<td>3</td>
<td>0.001</td>
<td>0.013</td>
<td>1.000</td>
<td>1.000</td>
<td>0.336</td>
<td>0.338</td>
<td>0.667</td>
<td>0.667</td>
</tr>
<tr>
<td>4</td>
<td>0.218</td>
<td><bold>0.708</bold></td>
<td>1.000</td>
<td>1.000</td>
<td>0.405</td>
<td><bold>0.570</bold></td>
<td>0.666</td>
<td>0.666</td>
</tr>
<tr>
<td>5</td>
<td>0.006</td>
<td><bold>0.508</bold></td>
<td>1.000</td>
<td>1.000</td>
<td>0.335</td>
<td><bold>0.506</bold></td>
<td>0.665</td>
<td>0.665</td>
</tr>
<tr>
<td>6</td>
<td>0.032</td>
<td>0.322</td>
<td>1.000</td>
<td>1.000</td>
<td>0.343</td>
<td>0.441</td>
<td>0.667</td>
<td>0.666</td>
</tr>
<tr>
<td>7</td>
<td>0.001</td>
<td>0.028</td>
<td>1.000</td>
<td>1.000</td>
<td>0.337</td>
<td>0.343</td>
<td>0.668</td>
<td>0.668</td>
</tr>
<tr>
<td>8</td>
<td><bold>0.638</bold></td>
<td>0.174</td>
<td>1.000</td>
<td>1.000</td>
<td><bold>0.544</bold></td>
<td>0.390</td>
<td>0.666</td>
<td>0.666</td>
</tr>
<tr>
<td>9</td>
<td>0.183</td>
<td><bold>0.751</bold></td>
<td>1.000</td>
<td>1.000</td>
<td>0.392</td>
<td><bold>0.585</bold></td>
<td>0.666</td>
<td>0.668</td>
</tr>
<tr>
<td>10</td>
<td>0.035</td>
<td>0.101</td>
<td>1.000</td>
<td>1.000</td>
<td>0.345</td>
<td>0.366</td>
<td>0.668</td>
<td>0.668</td>
</tr>
<tr>
<td>11</td>
<td>0.058</td>
<td>0.209</td>
<td>1.000</td>
<td>1.000</td>
<td>0.353</td>
<td>0.404</td>
<td>0.667</td>
<td>0.669</td>
</tr>
<tr>
<td>12</td>
<td>0.082</td>
<td>0.223</td>
<td>1.000</td>
<td>1.000</td>
<td>0.363</td>
<td>0.407</td>
<td>0.668</td>
<td>0.668</td>
</tr>
<tr>
<td>13</td>
<td>0.334</td>
<td>0.329</td>
<td>1.000</td>
<td>1.000</td>
<td>0.443</td>
<td>0.444</td>
<td>0.666</td>
<td>0.668</td>
</tr>
<tr>
<td>14</td>
<td>0.039</td>
<td><bold>0.571</bold></td>
<td>1.000</td>
<td>1.000</td>
<td>0.346</td>
<td><bold>0.525</bold></td>
<td>0.672</td>
<td>0.665</td>
</tr>
<tr>
<td>15</td>
<td>0.137</td>
<td>0.060</td>
<td>1.000</td>
<td>1.000</td>
<td>0.378</td>
<td>0.354</td>
<td>0.666</td>
<td>0.664</td>
</tr>
<tr>
<td>16</td>
<td><bold>0.505</bold></td>
<td>0.492</td>
<td>1.000</td>
<td>1.000</td>
<td><bold>0.503</bold></td>
<td>0.495</td>
<td>0.664</td>
<td>0.668</td>
</tr>
<tr>
<td>17</td>
<td>0.154</td>
<td>0.007</td>
<td>1.000</td>
<td>1.000</td>
<td>0.386</td>
<td>0.334</td>
<td>0.668</td>
<td>0.664</td>
</tr>
<tr>
<td>18</td>
<td>0.160</td>
<td>0.430</td>
<td>1.000</td>
<td>1.000</td>
<td>0.387</td>
<td>0.477</td>
<td>0.667</td>
<td>0.668</td>
</tr>
<tr>
<td>19</td>
<td>0.090</td>
<td>0.250</td>
<td>1.000</td>
<td>1.000</td>
<td>0.364</td>
<td>0.416</td>
<td>0.667</td>
<td>0.666</td>
</tr>
<tr>
<td>20</td>
<td><bold>0.652</bold></td>
<td><bold>0.727</bold></td>
<td>1.000</td>
<td>1.000</td>
<td><bold>0.552</bold></td>
<td><bold>0.575</bold></td>
<td>0.666</td>
<td>0.667</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0146621612449069">
<p>Note: The true Q-values are 0, 0, 1, and 1. Posteriors that give incorrect <italic>q</italic>s are shown in bold.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p><xref ref-type="table" rid="table3-0146621612449069">Table 3</xref> shows, for the first condition, the posterior means for the uncertain Q-matrix elements for all 20 data sets. The true <italic>q</italic><sub><italic>jk</italic></sub> elements are 0, 0, 1, and 1. The third and fourth columns of <xref ref-type="table" rid="table3-0146621612449069">Table 3</xref> show that the posterior means of <inline-formula id="inline-formula19-0146621612449069">
<mml:math display="inline" id="math36-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>82</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula20-0146621612449069">
<mml:math display="inline" id="math37-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>131</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> are 1.0 for all 20 data sets, and so the recovery rate is 100% for these elements. The first and second columns show that the posterior means of <inline-formula id="inline-formula21-0146621612449069">
<mml:math display="inline" id="math38-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>13</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula22-0146621612449069">
<mml:math display="inline" id="math39-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>14</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> generally indicate values of zero, with the exception of three cases for <inline-formula id="inline-formula23-0146621612449069">
<mml:math display="inline" id="math40-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>13</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, shown in bold, and five cases for <inline-formula id="inline-formula24-0146621612449069">
<mml:math display="inline" id="math41-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>14</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. It is also apparent from <xref ref-type="table" rid="table3-0146621612449069">Table 3</xref> that the same decisions are made regardless of whether the posterior means of <inline-formula id="inline-formula25-0146621612449069">
<mml:math display="inline" id="math42-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> or <italic>p</italic><sub><italic>jk</italic></sub> are used.</p>
<p>As noted above, a simple procedure is to round the Q-matrix element posterior mean (of <inline-formula id="inline-formula26-0146621612449069">
<mml:math display="inline" id="math43-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>) to zero or one. <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> shows, for the first three conditions, the results of this procedure. The first matrix in <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> (top left) shows the true Q-matrix elements for the 3 items. The next matrix (top right) shows, for the first condition, the percentage of cases (out of 20) where the Q-element was correctly recovered. Recovery is 100% (that the skill should be included) for Items 8 and 13 (Skills 2 and 1, respectively), 85% (that the skill should not be included) for the third skill of Item 1, and 75% (that the item should not be included) for the fourth skill of Item 1. Thus, using the mean of the posterior density to set <italic>q</italic><sub><italic>jk</italic></sub> to zero or one generally led to a correct decision. The table also shows that the detection of 1s in the Q-matrix (skill needed) appears to be better than the detection of 0s (skill not needed), as also shown in <xref ref-type="table" rid="table3-0146621612449069">Table 3</xref>.</p>
<table-wrap id="table4-0146621612449069" position="float">
<label>Table 4.</label>
<caption><p>Percent-Correct Recovery of Q-Matrix Elements for Conditions 1, 2, and 3</p>
</caption>
<graphic alternate-form-of="table4-0146621612449069" xlink:href="10.1177_0146621612449069-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">True Q-matrix<hr/></th>
<th align="center" colspan="4">Q-matrix (4 uncertain)<hr/></th>
</tr>
<tr>
<th align="left">RDINA Item No.</th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td align="center">—</td>
<td align="center">—</td>
<td>85</td>
<td>75</td>
</tr>
<tr>
<td>8</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td align="center">—</td>
<td>100</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>13</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>100</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="9"><hr/></td>
</tr>
<tr>
<th/>
<th align="center" colspan="4">Q-matrix (12 uncertain)<hr/></th>
<th align="center" colspan="4">Misspecified Q-matrix<hr/></th>
</tr>
<tr>
<th align="left">RDINA Item No.</th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
</tr>
<tr>
<td colspan="9"><hr/></td>
</tr>
<tr>
<td>1</td>
<td>100</td>
<td>85</td>
<td>85</td>
<td>75</td>
<td>100</td>
<td>85</td>
<td>90</td>
<td>60</td>
</tr>
<tr>
<td>8</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>65</td>
<td>100</td>
<td>100</td>
<td>80</td>
</tr>
<tr>
<td>13</td>
<td>95</td>
<td>100</td>
<td>90</td>
<td>95</td>
<td>95</td>
<td>100</td>
<td>85</td>
<td>85</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0146621612449069">
<p>Note: RDINA = reparameterized deterministic input noisy and. Except for the true Q-matrix, entries indicate the percent-correct recovery of the element for 20 data sets. The misspecified Q-matrix had 12 uncertain elements and 6 misspecified elements.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section9-0146621612449069">
<title>Condition 2: Twelve uncertain Q-matrix elements</title>
<p>In the second condition, there was complete uncertainty for all four skills for Items 1, 8, and 13, giving a total of 12 uncertain elements. Using the approach noted above (i.e., rounding the posterior mean of <italic>q</italic><sub><italic>jk</italic></sub>), the matrix at the bottom left of <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> shows that the four skills for Item 8 are correctly detected as being zero or one in 100% of the cases, whereas for Item 13, detection is correct for 90% to 100% of the cases. For Item 1, the need to include the first skill is detected correctly in 75% to 100% of the cases. Thus, although it was expected that the inclusion of a greater number of uncertain skills would lead to less accurate detection, the results in <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> suggest generally good detection for a situation with 12 uncertain skills.</p>
</sec>
<sec id="section10-0146621612449069">
<title>Condition 3: Twelve uncertain Q-matrix elements and six misspecifications</title>
<p>In the above conditions, the specification of the Q-matrix was uncertain for some of the elements, but the other Q-elements were correctly specified. In Condition 3, there was again uncertainty about 12 Q-matrix elements, as in Condition 2; however, six other elements of the Q-matrix were incorrectly specified. As shown in <xref ref-type="table" rid="table2-0146621612449069">Table 2</xref>, three elements were incorrectly excluded and three elements were incorrectly included. It is of interest to see how this affects recovery of the uncertain Q-matrix elements in the Bayesian approach.</p>
<p>The posterior means were again used to determine the Q-matrix elements. The lower right of <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> shows recovery of the uncertain elements. Recovery is somewhat better than expected, still being around 80% or higher for 10 of the 12 elements (and 100% for 4 elements); however, recovery is poor for two elements. Notably, it is 60% and 65% for elements <italic>q</italic><sub>14</sub> and <italic>q</italic><sub>81</sub> (both with true values of zero). This shows that misspecification of other elements of the Q-matrix can affect recovery rates for some of the uncertain elements.</p>
</sec>
<sec id="section11-0146621612449069">
<title>Conditions 4, 5, and 6: Complete uncertainty about a skill</title>
<p><xref ref-type="table" rid="table5-0146621612449069">Table 5</xref> shows recovery of the Q-elements for the fourth, fifth, and sixth conditions. The third column shows the percent-correct recovery for the fourth condition, where the fourth skill was necessary but had all 15 elements specified as being uncertain. The table shows that recovery is generally excellent, with 90% to 100% correct recovery for 14 of the 15 elements, whereas one element had only 75% recovery. The second column of <xref ref-type="table" rid="table5-0146621612449069">Table 5</xref> shows results for the fifth condition, which again had complete uncertainty about the fourth skill, but five other elements of the Q-matrix were also misspecified. In this case, recovery is quite poor for many elements. This shows that, when there is complete uncertainty about a skill, misspecification of other elements of the Q-matrix can have a profound effect on the recovery rates. In the sixth condition, a fifth skill with complete uncertainty was included. Given that the skill is not necessary, one might expect to find posteriors for <italic>q</italic><sub><italic>jk</italic></sub> that are all close to zero, suggesting that the skill should not be included; however, the posteriors instead tended to be around 0.5, and the resulting recovery rates were uniformly poor (i.e., around 50%), as shown in <xref ref-type="table" rid="table5-0146621612449069">Table 5</xref>. An interesting result is that the posterior means (not shown) of the class size for the nonnecessary Skill 5 tended to be large (i.e., &gt;.90), which is consistent with an earlier conjecture that including a nonnecessary skill can lead to a class size close to one (<xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>).</p>
<table-wrap id="table5-0146621612449069" position="float">
<label>Table 5.</label>
<caption><p>Recovery of Q-Matrix Elements for Conditions 4, 5, and 6</p>
</caption>
<graphic alternate-form-of="table5-0146621612449069" xlink:href="10.1177_0146621612449069-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Item No.</th>
<th align="center" colspan="2">Condition 4<hr/></th>
<th align="center" colspan="2">Condition 5<hr/></th>
<th align="center" colspan="2">Condition 6<hr/></th>
</tr>
<tr>
<th/>
<th align="center">True <italic>q</italic><sub><italic>j</italic>4</sub></th>
<th align="center">% correct</th>
<th align="center">True <italic>q</italic><sub><italic>j</italic>4</sub></th>
<th align="center">% correct</th>
<th align="center">True <italic>q</italic><sub><italic>j</italic>5</sub></th>
<th align="center">% correct</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>75</td>
<td>0</td>
<td>80</td>
<td>0</td>
<td>40</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>100</td>
<td>0</td>
<td>100</td>
<td>0</td>
<td>65</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>95</td>
<td>0</td>
<td>25</td>
<td>0</td>
<td>70</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>100</td>
<td>1</td>
<td>45</td>
<td>0</td>
<td>60</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>100</td>
<td>0</td>
<td>90</td>
<td>0</td>
<td>55</td>
</tr>
<tr>
<td>6</td>
<td>0</td>
<td>100</td>
<td>0</td>
<td>15</td>
<td>0</td>
<td>35</td>
</tr>
<tr>
<td>7</td>
<td>1</td>
<td>90</td>
<td>1</td>
<td>25</td>
<td>0</td>
<td>40</td>
</tr>
<tr>
<td>8</td>
<td>0</td>
<td>100</td>
<td>0</td>
<td>25</td>
<td>0</td>
<td>65</td>
</tr>
<tr>
<td>9</td>
<td>0</td>
<td>90</td>
<td>0</td>
<td>20</td>
<td>0</td>
<td>60</td>
</tr>
<tr>
<td>10</td>
<td>1</td>
<td>100</td>
<td>1</td>
<td>75</td>
<td>0</td>
<td>45</td>
</tr>
<tr>
<td>11</td>
<td>0</td>
<td>100</td>
<td>0</td>
<td>15</td>
<td>0</td>
<td>45</td>
</tr>
<tr>
<td>12</td>
<td>1</td>
<td>100</td>
<td>1</td>
<td>30</td>
<td>0</td>
<td>50</td>
</tr>
<tr>
<td>13</td>
<td>1</td>
<td>95</td>
<td>1</td>
<td>100</td>
<td>0</td>
<td>40</td>
</tr>
<tr>
<td>14</td>
<td>1</td>
<td>95</td>
<td>1</td>
<td>90</td>
<td>0</td>
<td>40</td>
</tr>
<tr>
<td>15</td>
<td>1</td>
<td>100</td>
<td>1</td>
<td>95</td>
<td>0</td>
<td>40</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0146621612449069">
<p>Note: Entries indicate the proportion of times the element was correctly recovered for 20 data sets. For Condition 4, the fourth skill was specified as uncertain for all 15 items. Condition 5 was the same as Condition 4, except that five other elements were also misspecified. For Condition 6, the first four skills were correctly specified; however, a fifth skill was (incorrectly) included, with each element specified as uncertain.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section12-0146621612449069">
<title>Conditions 7 and 8: HO-RDINA</title>
<p>Data in these conditions (20 data sets) were generated according to the HO-RDINA model as described above. In Condition 7, the Bayesian HO-RDINA model (with a common value of <italic>a</italic><sub><italic>k</italic></sub> in <xref ref-type="disp-formula" rid="disp-formula11-0146621612449069">Equation 3</xref>) was fit with 12 uncertain elements, as shown by the Bayesian Q-matrix in <xref ref-type="table" rid="table1-0146621612449069">Table 1</xref>. The left side of <xref ref-type="table" rid="table6-0146621612449069">Table 6</xref> shows that recovery of many elements is quite good, with the same pattern as shown in the lower left part of <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> (Condition 2 for the RDINA model). A difference, however, is that some elements are poorly recovered, most notably elements <italic>q</italic><sub>13</sub> and <italic>q</italic><sub>14</sub> for Item 1, which are correctly detected as being zero only 55% of the time (and so the false alarm rate is quite high at 45%). The recovery rates for elements <italic>q</italic><sub>133</sub> and <italic>q</italic><sub>134</sub> are also lower compared with the results shown in the lower left part of <xref ref-type="table" rid="table4-0146621612449069">Table 4</xref> (Condition 2). In Condition 8, there were again 12 uncertain elements for the higher order model, but six other elements were misspecified (as in Condition 3). The right side of <xref ref-type="table" rid="table6-0146621612449069">Table 6</xref> shows that recovery was excellent for many elements, but was again poor for Skills 3 and 4 for Item 1 (where the skills are not necessary), and was also poor for Skills 3 and 4 for Item 13 (where the skills are necessary). Thus, as for the model without a higher order structure (Condition 3), the results for Condition 8 suggest that misspecification of other parts of the Q-matrix affects recovery rates for some of the uncertain elements. In addition, recovery rates for data with a higher order structure appear to be lower for some elements than those for data with an independence structure.</p>
<table-wrap id="table6-0146621612449069" position="float">
<label>Table 6.</label>
<caption><p>Recovery of Q-Matrix Elements for a HO-RDINA Model, Conditions 7 and 8</p>
</caption>
<graphic alternate-form-of="table6-0146621612449069" xlink:href="10.1177_0146621612449069-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Q-matrix (12 uncertain)<hr/></th>
<th align="center" colspan="4">Misspecified Q-matrix<hr/></th>
</tr>
<tr>
<th align="left">HO-RDINA Item No.</th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>90</td>
<td>80</td>
<td>55</td>
<td>55</td>
<td>90</td>
<td>90</td>
<td>60</td>
<td>55</td>
</tr>
<tr>
<td>8</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>90</td>
</tr>
<tr>
<td>13</td>
<td>95</td>
<td>100</td>
<td>80</td>
<td>70</td>
<td>100</td>
<td>100</td>
<td>60</td>
<td>60</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-0146621612449069">
<p>Note: HO-RDINA = higher order reparameterized deterministic input noisy and.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section13-0146621612449069">
<title>Discussion</title>
<p>The simulations show that the posterior distributions for the random Q-matrix elements provide useful information about which elements should or should not be included (i.e., whether <inline-formula id="inline-formula27-0146621612449069">
<mml:math display="inline" id="math44-0146621612449069">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>jk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> should be zero or one). The approach generally led to correct recovery of elements in situations where there was uncertainty about 4 (7%) or 12 (20%) elements of the Q-matrix (Conditions 1 and 2), with the rest of the matrix correctly specified. When in addition, six elements of the Q-matrix were incorrectly specified (Condition 3), recovery of 12 uncertain elements was still generally quite good; however, recovery for some elements was apparently degraded. These results also appeared for data with a higher order structure (Conditions 7 and 8); recovery rates for some elements also appeared to be lower. These results differ somewhat from those reported by <xref ref-type="bibr" rid="bibr28-0146621612449069">J. Templin and Henson (2006)</xref>, who examined the DINA model with a higher order structure (using tetrachoric correlations for the skill patterns), in that they reported 100% recovery in three conditions where the percentage of uncertain elements was varied. The present results show excellent recovery in many cases, but not always 100%, and in fact recovery was quite poor for some elements in some conditions, as discussed earlier. A new finding, shown here, is that recovery rates can be adversely affected for some uncertain elements when other elements of the Q-matrix are not correctly specified.</p>
<p>With respect to situations that involve uncertainty about the number of skills, the Bayesian approach appears to be of some, but limited, utility. The results for Condition 4, for example, showed that when a skill was necessary, the Bayesian approach worked very well with respect to indicating which items the skill should load on. However, when (five) other elements of the Q-matrix were misspecified (Condition 5), the approach started to break down and recovery rates were poor for many elements. Furthermore, when a nonnecessary skill was introduced (Condition 6), the posteriors for the Q-elements were not zero, but tended to vary around 0.5, and so the recovery rates were poor. The results suggest that the Bayesian approach might be of limited utility with respect to determining when to stop adding skills: It correctly reveals the skill loadings when the rest of the Q-matrix is correctly specified, but less so when other elements are misspecified; it also does not clearly indicate when a skill is <italic>not</italic> needed.</p>
<p>Overall, the results are encouraging and suggest that it is worthwhile to examine the Bayesian approach in more extensive simulations, and to apply it to real-world data.</p>
</sec>
</sec>
<sec id="section14-0146621612449069">
<title>An Application: The Fraction-Subtraction Data</title>
<p>The Bayesian approach to Q-matrix determination is applied to the widely analyzed fraction-subtraction data of <xref ref-type="bibr" rid="bibr27-0146621612449069">K. K. Tatsuoka (1990)</xref>, which consists of 536 examinees. The Q-matrix, which in this case is for 15 of the items, is the same as that used by <xref ref-type="bibr" rid="bibr5-0146621612449069">de la Torre (2008)</xref> in a prior study that was concerned with validity of the Q-matrix; the Q-matrix was adapted from <xref ref-type="bibr" rid="bibr20-0146621612449069">Mislevy (1996)</xref> and is shown in <xref ref-type="table" rid="table7-0146621612449069">Table 7</xref>. The labels given to the five skills are (a) performing basic fraction-subtraction operation, (b) simplifying/reducing, (c) separating whole numbers from fractions, (d) borrowing one from whole number to fraction, and (e) converting whole numbers to fractions.</p>
<table-wrap id="table7-0146621612449069" position="float">
<label>Table 7.</label>
<caption><p>Fraction-Subtraction Data, 15 Items, Five Hypothesized Skills</p>
</caption>
<graphic alternate-form-of="table7-0146621612449069" xlink:href="10.1177_0146621612449069-table7.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="5">Original Q-matrix<hr/></th>
<th align="center" colspan="5">Bayesian Q-matrix<hr/></th>
</tr>
<tr>
<th align="left">No.</th>
<th align="center">Item</th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
<th align="center">α<sub>5</sub></th>
<th align="center">α<sub>1</sub></th>
<th align="center">α<sub>2</sub></th>
<th align="center">α<sub>3</sub></th>
<th align="center">α<sub>4</sub></th>
<th align="center">α<sub>5</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><inline-formula id="inline-formula28-0146621612449069">
<mml:math display="inline" id="math45-0146621612449069">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td><inline-formula id="inline-formula29-0146621612449069">
<mml:math display="inline" id="math46-0146621612449069">
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td><inline-formula id="inline-formula30-0146621612449069">
<mml:math display="inline" id="math47-0146621612449069">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>6</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td><inline-formula id="inline-formula31-0146621612449069">
<mml:math display="inline" id="math48-0146621612449069">
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><italic>q</italic><sub>42</sub></td>
<td>1</td>
<td><italic>q</italic><sub>44</sub></td>
<td><italic>q</italic><sub>45</sub></td>
</tr>
<tr>
<td>5</td>
<td><inline-formula id="inline-formula32-0146621612449069">
<mml:math display="inline" id="math49-0146621612449069">
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td><italic>q</italic><sub>52</sub></td>
<td>1</td>
<td><italic>q</italic><sub>54</sub></td>
<td><italic>q</italic><sub>55</sub></td>
</tr>
<tr>
<td>6</td>
<td><inline-formula id="inline-formula33-0146621612449069">
<mml:math display="inline" id="math50-0146621612449069">
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>7</td>
<td><inline-formula id="inline-formula34-0146621612449069">
<mml:math display="inline" id="math51-0146621612449069">
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>8</td>
<td><inline-formula id="inline-formula35-0146621612449069">
<mml:math display="inline" id="math52-0146621612449069">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>11</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>9</td>
<td><inline-formula id="inline-formula36-0146621612449069">
<mml:math display="inline" id="math53-0146621612449069">
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>3</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>10</td>
<td><inline-formula id="inline-formula37-0146621612449069">
<mml:math display="inline" id="math54-0146621612449069">
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><italic>q</italic><sub>102</sub></td>
<td>1</td>
<td><italic>q</italic><sub>104</sub></td>
<td><italic>q</italic><sub>105</sub></td>
</tr>
<tr>
<td>11</td>
<td><inline-formula id="inline-formula38-0146621612449069">
<mml:math display="inline" id="math55-0146621612449069">
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>12</td>
<td><inline-formula id="inline-formula39-0146621612449069">
<mml:math display="inline" id="math56-0146621612449069">
<mml:mrow>
<mml:mn>7</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>13</td>
<td><inline-formula id="inline-formula40-0146621612449069">
<mml:math display="inline" id="math57-0146621612449069">
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>14</td>
<td><inline-formula id="inline-formula41-0146621612449069">
<mml:math display="inline" id="math58-0146621612449069">
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><italic>q</italic><sub>142</sub></td>
<td>1</td>
<td><italic>q</italic><sub>144</sub></td>
<td><italic>q</italic><sub>145</sub></td>
</tr>
<tr>
<td>15</td>
<td><inline-formula id="inline-formula42-0146621612449069">
<mml:math display="inline" id="math59-0146621612449069">
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn7-0146621612449069">
<p>Note: Skill labels are (a) performing basic fraction-subtraction operation, (b) simplifying/reducing, (c) separating whole numbers from fractions, (d) borrowing one from whole number to fraction, and (e) converting whole numbers to fractions.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Prior analyses of these data (e.g., <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>; <xref ref-type="bibr" rid="bibr5-0146621612449069">de la Torre, 2008</xref>) suggested that there is some uncertainty associated with items that involve whole numbers (without fractions), which consists of 4 items in <xref ref-type="table" rid="table7-0146621612449069">Table 7</xref> (Items 4, 5, 10, and 14) and so these 4 items are examined more closely here. All 4 items include Skills 1 and 3; however, they differ with respect to which of the other three skills (Skills 2, 4, and 5) are included, if any. Thus, the Q-matrix considered here has uncertainty with respect to whether Skills 2, 4, and 5 should be included in Items 4, 5, 10, and 14, which gives 12 uncertain elements. The Bayesian Q-matrix is shown on the right side of <xref ref-type="table" rid="table7-0146621612449069">Table 7</xref>.</p>
<p>Note that one can make substantive arguments for the possible inclusion or exclusion of different skills in these (and other) items because of ambiguities with respect to solving items that involve whole numbers. For example, the first item with a whole number, Item 4, is 3 − 2 1/5, and the original Q-matrix considers all five skills as being involved in this item. There are, however, several different ways to solve this item. For example, one could simply convert both terms to fractions with common denominators and then subtract: 15/5 − 11/5 = 4/5. Or one could borrow from the first whole number, convert to a fraction, and then subtract parts: 3 − 2 1/5 = 2 5/5 − 2 1/5, and so 2 − 2 = 0 and 5/5 − 1/5 = 4/5. Or one could first subtract the whole numbers, 3 − 2 = 1, and then subtract the remaining fraction, 1/5, from the converted remainder, 1− 1/5 = 5/5 − 1/5 = 4/5, and so on. The point is that the set of skills required for this simple item are questionable, and in general there are several approaches to solving the items that involve different combinations of skills. Of course, this is undesirable—ideally, a test for cognitive diagnosis should use items that clearly require certain skills and not others, without ambiguities, but that is easier said than done. In any case, the Bayesian approach recognizes that there is uncertainty about some elements of the Q-matrix and allows one in essence to simultaneously consider a large number of possible respecifications.</p>
<sec id="section15-0146621612449069">
<title>Results</title>
<p>OpenBUGS was again used with 5,000 burn-ins and 20,000 iterations. <xref ref-type="table" rid="table8-0146621612449069">Table 8</xref> shows the posterior means of <italic>q</italic><sub><italic>jk</italic></sub> for fits of the model with 12 uncertain elements. In this case, all the posterior means are close to zero or one. Note, for example, that the third and fourth rows of <xref ref-type="table" rid="table8-0146621612449069">Table 8</xref> suggest patterns of 0, 1, 1 and 1, 1, 1, respectively, which matches the original Q-matrix, and so the results suggest that Items 10 and 14 are correctly specified. However, the first and second rows suggest three changes to the Q-matrix. In particular, the table suggests that Skills α<sub>2</sub> and α<sub>5</sub> should be included in Item 5, and Skill α<sub>2</sub> should be dropped from Item 4.<sup>
<xref ref-type="fn" rid="fn1-0146621612449069">1</xref>
</sup> Note that results of this sort could possibly be useful to substantive experts. For example, of the (at least) three strategies for solving Item 4 noted earlier, the Bayesian results (Skill 2 is not necessary) suggest that the third strategy might be the one used (3 − 2 = 1, 1 = 5/5, 5/5 − 1/5 = 4/5) because it involves the other skills but not Skill 2 (simplify/reduce).</p>
<table-wrap id="table8-0146621612449069" position="float">
<label>Table 8.</label>
<caption><p>Posterior Means of Q-Matrix Elements for the Fraction-Subtraction Data</p>
</caption>
<graphic alternate-form-of="table8-0146621612449069" xlink:href="10.1177_0146621612449069-table8.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Item</th>
<th align="center"><italic>q</italic><sub><italic>j</italic>2</sub></th>
<th align="center"><italic>q</italic><sub><italic>j</italic>4</sub></th>
<th align="center"><italic>q</italic><sub><italic>j</italic>5</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>0.005</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td>5</td>
<td>0.980</td>
<td>0.000</td>
<td>1.000</td>
</tr>
<tr>
<td>10</td>
<td>0.013</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td>14</td>
<td>0.999</td>
<td>1.000</td>
<td>1.000</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>To explore modifications of the Q-matrix suggested by the Bayesian analysis, <xref ref-type="table" rid="table9-0146621612449069">Table 9</xref> shows results for a fit of the original model and the model with a modified Q-matrix; in both cases, Latent Gold was used (using posterior mode estimation with Bayes’s constants of 1; see <xref ref-type="bibr" rid="bibr4-0146621612449069">DeCarlo, 2011</xref>). The table shows that BIC and AIC are smaller for the modified model (by more than 40), which indicates better relative fit compared with the original model. <xref ref-type="table" rid="table10-0146621612449069">Table 10</xref> shows parameter estimates for the original and modified model. For the modified Items 4 and 5, the discrimination parameters are slightly larger in magnitude than for the original model (whereas the false alarm rates are slightly lower in one case and higher in the other). <xref ref-type="table" rid="table10-0146621612449069">Table 10</xref> also shows that estimates of the skill probabilities (the latent class sizes) for the respecified Q-matrix are similar to those obtained for the original Q-matrix. The table also shows that the standard errors are large for the first item.</p>
<table-wrap id="table9-0146621612449069" position="float">
<label>Table 9.</label>
<caption><p>Information Criteria for Various Models: Fraction-Subtraction Data, <italic>N</italic> = 536</p>
</caption>
<graphic alternate-form-of="table9-0146621612449069" xlink:href="10.1177_0146621612449069-table9.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">No. of parameters</th>
<th align="center">BIC</th>
<th align="center">AIC</th>
<th/>
</tr>
</thead>
<tbody>
<tr>
<td>RDINA</td>
<td>35</td>
<td>7,163.0</td>
<td colspan="2">7,013.1</td>
</tr>
<tr>
<td>RDINA from Bayesian analysis</td>
<td>35</td>
<td>7,120.5</td>
<td colspan="2">6,970.5</td>
</tr>
<tr>
<td colspan="5"><hr/></td>
</tr>
<tr>
<th align="center" colspan="5">Effect of including an irrelevant attribute</th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center">No. of parameters</th>
<th align="center">BIC</th>
<th align="center">AIC</th>
<th align="center"><inline-formula id="inline-formula43-0146621612449069">
<mml:math display="inline" id="math60-0146621612449069">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>+</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
<tr>
<td colspan="5"><hr/></td>
</tr>
<tr>
<td>RDINA</td>
<td>35</td>
<td>7,163.0</td>
<td>7,013.1</td>
<td>.2461</td>
</tr>
<tr>
<td>RDINA (α<sub>5</sub> in Item 1)</td>
<td>35</td>
<td>7,188.0</td>
<td>7,038.1</td>
<td>.2379</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn8-0146621612449069">
<p>Note: BIC = Bayesian information criterion; AIC = Akaike information criterion; RDINA = reparameterized deterministic input noisy and.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table10-0146621612449069" position="float">
<label>Table 10.</label>
<caption><p>Parameter Estimates (<italic>SE</italic>s in Parenthesis) for the RDINA Model, Fraction-Subtraction Data</p>
</caption>
<graphic alternate-form-of="table10-0146621612449069" xlink:href="10.1177_0146621612449069-table10.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Item</th>
<th align="center" colspan="4">Original Q-matrix<hr/></th>
<th align="center" colspan="5">Modified Q-matrix<hr/></th>
</tr>
<tr>
<th/>
<th align="center"><italic>f</italic><sub><italic>j</italic></sub></th>
<th/>
<th align="center"><italic>d</italic><sub><italic>j</italic></sub></th>
<th/>
<th align="center"><italic>f</italic><sub><italic>j</italic></sub></th>
<th/>
<th/>
<th align="center"><italic>d</italic><sub><italic>j</italic></sub></th>
<th/>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td colspan="2">−4.97 (1.91)</td>
<td colspan="2">5.96 (1.91)</td>
<td colspan="3">−4.90 (1.92)</td>
<td colspan="2">5.92 (1.92)</td>
</tr>
<tr>
<td>2</td>
<td colspan="2">−1.31 (0.15)</td>
<td colspan="2">3.33 (0.25)</td>
<td colspan="3">−1.31 (0.15)</td>
<td colspan="2">3.31 (0.25)</td>
</tr>
<tr>
<td>3</td>
<td colspan="2">−1.58 (0.34)</td>
<td colspan="2">4.84 (0.43)</td>
<td colspan="3">−1.47 (0.33)</td>
<td colspan="2">4.76 (0.43)</td>
</tr>
<tr>
<td><bold>4</bold></td>
<td colspan="2"><bold>−1.93 (0.17)</bold></td>
<td colspan="2"><bold>3.83 (0.31)</bold></td>
<td colspan="3"><bold>−2.18 (0.21)</bold></td>
<td colspan="2"><bold>3.99 (0.32)</bold></td>
</tr>
<tr>
<td><bold>5</bold></td>
<td colspan="2"><bold>−0.62 (0.19)</bold></td>
<td colspan="2"><bold>1.75 (0.23)</bold></td>
<td colspan="3"><bold>−0.49 (0.16)</bold></td>
<td colspan="2"><bold>2.33 (0.26)</bold></td>
</tr>
<tr>
<td>6</td>
<td colspan="2">−3.35 (0.35)</td>
<td colspan="2">4.59 (0.38)</td>
<td colspan="3">−3.37 (0.35)</td>
<td colspan="2">4.60 (0.38)</td>
</tr>
<tr>
<td>7</td>
<td colspan="2">−2.53 (0.24)</td>
<td colspan="2">5.03 (0.35)</td>
<td colspan="3">−2.53 (0.24)</td>
<td colspan="2">5.01 (0.35)</td>
</tr>
<tr>
<td>8</td>
<td colspan="2">−1.70 (0.32)</td>
<td colspan="2">4.07 (0.40)</td>
<td colspan="3">−1.49 (0.32)</td>
<td colspan="2">3.98 (0.38)</td>
</tr>
<tr>
<td>9</td>
<td colspan="2">−2.08 (0.38)</td>
<td colspan="2">4.91 (0.45)</td>
<td colspan="3">−1.96 (0.35)</td>
<td colspan="2">4.80 (0.43)</td>
</tr>
<tr>
<td>10</td>
<td colspan="2">−1.62 (0.17)</td>
<td colspan="2">4.17 (0.35)</td>
<td colspan="3">−1.80 (0.19)</td>
<td colspan="2">4.39 (0.36)</td>
</tr>
<tr>
<td>11</td>
<td colspan="2">−1.92 (0.32)</td>
<td colspan="2">4.14 (0.37)</td>
<td colspan="3">−1.87 (0.31)</td>
<td colspan="2">4.13 (0.36)</td>
</tr>
<tr>
<td>12</td>
<td colspan="2">−3.45 (0.41)</td>
<td colspan="2">5.30 (0.45)</td>
<td colspan="3">−3.50 (0.43)</td>
<td colspan="2">5.20 (0.46)</td>
</tr>
<tr>
<td>13</td>
<td colspan="2">−1.85 (0.18)</td>
<td colspan="2">3.53 (0.25)</td>
<td colspan="3">−1.86 (0.18)</td>
<td colspan="2">3.53 (0.25)</td>
</tr>
<tr>
<td>14</td>
<td colspan="2">−3.75 (0.44)</td>
<td colspan="2">5.16 (0.48)</td>
<td colspan="3">−3.65 (0.41)</td>
<td colspan="2">4.92 (0.45)</td>
</tr>
<tr>
<td>15</td>
<td colspan="2">−4.34 (0.57)</td>
<td colspan="2">5.85 (0.60)</td>
<td colspan="3">−4.44 (0.60)</td>
<td colspan="2">5.95 (0.62)</td>
</tr>
<tr>
<td align="center"><italic>p</italic><sub>1</sub></td>
<td align="center"><italic>p</italic><sub>2</sub></td>
<td align="center"><italic>p</italic><sub>3</sub></td>
<td align="center"><italic>p</italic><sub>4</sub></td>
<td align="center"><italic>p</italic><sub>5</sub></td>
<td align="center"><italic>p</italic><sub>1</sub></td>
<td align="center"><italic>p</italic><sub>2</sub></td>
<td align="center"><italic>p</italic><sub>3</sub></td>
<td align="center"><italic>p</italic><sub>4</sub></td>
<td align="center"><italic>p</italic><sub>5</sub></td>
</tr>
<tr>
<td align="center">.79 (0.02)</td>
<td align="center">.96 (0.02)</td>
<td align="center">.93 (0.02)</td>
<td align="center">.66 (0.03)</td>
<td align="center">.78 (0.03)</td>
<td align="center">.78 (0.02)</td>
<td align="center">.94 (0.02)</td>
<td align="center">.93 (0.02)</td>
<td align="center">.68 (0.03)</td>
<td align="center">.80 (0.03)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn9-0146621612449069">
<p>Note: RDINA = reparameterized deterministic input noisy and. <italic>p</italic><sub>1</sub> to <italic>p</italic><sub>5</sub> are the skill probabilities (latent class sizes) for the five skills.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Another study of the validity of the Q-matrix that used the fraction-subtraction data and the same Q-matrix as used here was presented by <xref ref-type="bibr" rid="bibr5-0146621612449069">de la Torre (2008)</xref>. A sequential search algorithm was used along with a fit statistic, δ, that is basically the sum of the average slip and guess rates (the approach was referred to as the “δ-method”). Based on this analysis, de la Torre concluded that the original Q-matrix was supported. In contrast, the Bayesian approach used here suggested a modified Q-matrix that led to better relative fit, which suggests that the sequential search approach missed an improvement in the Q-matrix that was detected by the Bayesian approach.</p>
<p>A limitation of the δ-method was illustrated by <xref ref-type="bibr" rid="bibr5-0146621612449069">de la Torre (2008)</xref>, who included an irrelevant skill for one item (Skill 5 was included in Item 1). It was shown that this led to a smaller value of the proposed fit statistic (indicating better fit), although the inclusion was not theoretically plausible. However, using the Bayesian approach leads to the correct decision—the Bayesian RDINA model was fitted with uncertainty about Skill 5 in Item 1 and the posterior mean for <italic>q</italic><sub>15</sub> was close to zero, which (correctly) indicates that the attribute should not be included. The lower part of <xref ref-type="table" rid="table9-0146621612449069">Table 9</xref> shows, for the model with an irrelevant skill, the δ fit statistics reported by de la Torre as well as information criteria. The table shows that BIC and AIC are larger for the incorrect modification, and so they correctly detect that the modification leads to relatively worse fit. Thus, the example illustrates a limitation of the δ-method, but supports the Bayesian approach, as well as the use of conventional information criteria, both of which pick up the error.</p>
</sec>
</sec>
<sec id="section16-0146621612449069" sec-type="conclusions">
<title>Summary and Conclusion</title>
<p>An approach to recognizing uncertainty in the Q-matrix is presented. Instead of specifying all the elements of the Q-matrix as being known (i.e., as zero or one), some elements are specified as being random (Bernoulli) variables. The probability parameters for the random elements are given a prior, such as the Beta distribution. The posterior of the element <italic>q</italic>, or its probability <italic>p</italic>, can then be used to help determine whether a Q-matrix element should be set to zero or one.</p>
<p>The utility of the approach was examined in several simulations. In the first two conditions, there was uncertainty about some elements of the Q-matrix (either 4 or 12 elements out of 60), with the rest of the elements correctly specified. In the third condition, a novel aspect was introduced in that there was again uncertainty about 12 elements of the Q-matrix, but 6 other elements were incorrectly specified. Conditions with complete uncertainty about a skill (i.e., for all items) were also examined, as well as data with a higher order structure. The results show that the Bayesian approach generally appears to be useful for helping to determine which skills should be included or excluded for each item. The best situation is when the skills are correctly specified for most or all of the Q-matrix, and there are questions about only some skills for some items. This situation appears to be somewhat robust to misspecifications of other parts of the Q-matrix, although misspecification leads to lower recovery rates for some elements. Similar results were found for data with a higher order structure, except that recovery rates for some elements were lower, particularly when other elements of the Q-matrix were misspecified. The approach appears to break down to some degree, however, when there is complete uncertainty about a skill, with other elements of the Q-matrix misspecified (Condition 5), or when an unnecessary skill is included (Condition 6). In short, the Bayesian approach appears to be useful for detecting which skills the items should load on when the Q-matrix and number of skills are at least generally correctly specified. Of course, the importance of theory in the development and respecification of the Q-matrix cannot be overemphasized.</p>
<p>There are also some limitations as well as directions for future research. For example, the present studies provide some basic groundwork, but the results are, of course, limited to the particular Q-matrices and parameter values examined. Simulations with other types of Q-matrices, a greater number of attributes, and other higher order structures need to be conducted. The use of more informative priors and a greater number of iterations should also be examined, particularly in the problematical situations found above. It might also be possible to use the approach in a more exploratory manner, for example, by considering most or all of the Q-matrix elements as being uncertain. However, the results found for Conditions 5 and 6, where there was complete uncertainty about a skill, raise some doubts about using the approach in this manner, although this remains to be explored.</p>
<p>Effects of using cut points in different ways for the random elements can also be examined. For example, a reviewer suggested a sequential version of the Bayesian approach, where after a first run, only elements with posterior means above or below certain cut points (e.g., below 0.2 or above 0.8) are set to zero or one. A second run can then be used with these elements fixed to see if this helps to set the remaining uncertain elements.</p>
<p>The results also have important practical implications. Given that CDMs are being more widely used in practice, the Bayesian approach offers a way for researchers to consider theory-guided modifications of their particular Q-matrix, without having to consider the dozens or hundreds of alternatives that arise when more than four elements are in question. The approach is simple to implement, and computational time is fairly short, which should encourage researchers to apply the approach in practical applications of CDMs.</p>
<p>Finally, it should be noted that although sophisticated models are helpful, there is also a need to collect data to <italic>experimentally test</italic> the Q-matrix under consideration. For example, for the fraction-subtraction task, one could instruct examinees as to which strategy to use (e.g., “solve all problems by converting to a common denominator”). Convincing evidence of the validity of a Q-matrix would be obtained if it could be shown that variations in the instructions (within or across examinees) lead to detectable differences in the Q-matrix. Although the fraction-subtraction data have been analyzed for decades, there has yet to be a basic demonstration of this sort, at least to the author’s knowledge.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0146621612449069">
<title>Appendix</title>
<sec id="section17-0146621612449069">
<title>An OpenBUGS Program for the Bayesian RDINA (Reparameterized Deterministic Input Noisy And) Model</title>
<graphic id="img1-0146621612449069" position="anchor" xlink:href="10.1177_0146621612449069-img1.tif"/>
</sec>
</app>
</app-group>
<ack><p>The author thanks Matthew S. Johnson for some helpful discussions.</p></ack>
<fn-group>
<fn fn-type="other">
<label>Author’s Note</label>
<p>Links to software and sample programs are available at the author’s website: <ext-link ext-link-type="uri" xlink:href="http://www.columbia.edu/~ld208">http://www.columbia.edu/~ld208</ext-link>.</p>
</fn>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0146621612449069">
<label>1.</label>
<p>It is interesting to note that the same results were found for a fit of the Bayesian version of the HO-RDINA (higher order reparameterized deterministic input noisy and) model (with free <italic>a</italic><sub><italic>k</italic></sub>).</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0146621612449069">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Barnes</surname><given-names>T.</given-names></name>
<name><surname>Bitzer</surname><given-names>D.</given-names></name>
<name><surname>Vouk</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Experimental analysis of the q-matrix method in knowledge discovery</article-title>. <conf-name>Proceedings of the 15th International Symposium on Methodologies for Intelligent Systems 2005</conf-name>. <conf-loc>Saratoga Springs, NY</conf-loc>.</citation>
</ref>
<ref id="bibr2-0146621612449069">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Cen</surname><given-names>H.</given-names></name>
<name><surname>Koedinger</surname><given-names>K.</given-names></name>
<name><surname>Junker</surname><given-names>B.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Learning factors analysis—A general method for cognitive model evaluation and improvement</article-title>. In <person-group person-group-type="editor">
<name><surname>Ikeda</surname><given-names>M.</given-names></name>
<name><surname>Ashley</surname><given-names>K.</given-names></name>
<name><surname>Chan</surname><given-names>T.</given-names></name>
</person-group> (Eds.), <conf-name>Intelligent tutoring systems: 8th International Conference</conf-name> (pp. <fpage>164</fpage>-<lpage>175</lpage>). <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr3-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeCarlo</surname><given-names>L. T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>On the statistical and theoretical basis of signal detection theory and extensions: Unequal variance, random coefficient, and mixture models</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>54</volume>, <fpage>304</fpage>-<lpage>313</lpage>.</citation>
</ref>
<ref id="bibr4-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeCarlo</surname><given-names>L. T.</given-names></name>
</person-group> (<year>2011</year>). <article-title>On the analysis of fraction subtraction data: The DINA model, classification, latent class sizes, and the Q-matrix</article-title>. <source>Applied Psychological Measurement</source>, <volume>35</volume>, <fpage>8</fpage>-<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr5-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>de la Torre</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>An empirically based method of Q-matrix validation for the DINA model: Development and applications</article-title>. <source>Journal of Educational Measurement</source>, <volume>45</volume>, <fpage>343</fpage>-<lpage>362</lpage>.</citation>
</ref>
<ref id="bibr6-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>de la Torre</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>DINA model and parameter estimation: A didactic</article-title>. <source>Journal of Educational and Behavioral Statistics</source>, <volume>34</volume>, <fpage>115</fpage>-<lpage>130</lpage>.</citation>
</ref>
<ref id="bibr7-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>de la Torre</surname><given-names>J.</given-names></name>
<name><surname>Douglas</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Higher-order latent trait models for cognitive diagnosis</article-title>. <source>Psychometrika</source>, <volume>69</volume>, <fpage>333</fpage>-<lpage>353</lpage>.</citation>
</ref>
<ref id="bibr8-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>de la Torre</surname><given-names>J.</given-names></name>
<name><surname>Douglas</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Model evaluation and multiple strategies in cognitive diagnosis: An analysis of fraction subtraction data</article-title>. <source>Psychometrika</source>, <volume>73</volume>, <fpage>595</fpage>-<lpage>624</lpage>.</citation>
</ref>
<ref id="bibr9-0146621612449069">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>DiBello</surname><given-names>L. V.</given-names></name>
<name><surname>Roussos</surname><given-names>L. A.</given-names></name>
<name><surname>Stout</surname><given-names>W. F.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Review of cognitively diagnostic assessment and a summary of psychometric models</article-title>. In <person-group person-group-type="editor">
<name><surname>Rao</surname><given-names>C. R.</given-names></name>
<name><surname>Sinharay</surname><given-names>S.</given-names></name>
</person-group> (Eds.), <source>Handbook of statistics, Volume 26: Psychometrics</source> (pp. <fpage>979</fpage>-<lpage>1030</lpage>). <publisher-loc>Amsterdam, Netherlands</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</citation>
</ref>
<ref id="bibr10-0146621612449069">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Fu</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
</person-group> (<conf-date>2007, April</conf-date>). <source>An integrative review of cognitively diagnostic psychometric models</source>. <conf-name>Paper presented at the annual meeting of the National Council on Measurement in Education</conf-name>, <conf-loc>Chicago, IL</conf-loc>.</citation>
</ref>
<ref id="bibr11-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Geyer</surname><given-names>C. J.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Practical Markov chain Monte Carlo</article-title>. <source>Statistical Science</source>, <volume>7</volume>, <fpage>473</fpage>-<lpage>483</lpage>.</citation>
</ref>
<ref id="bibr12-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haertel</surname><given-names>E. H.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Using restricted latent class models to map the skill structure of achievement items</article-title>. <source>Journal of Educational Measurement</source>, <volume>26</volume>, <fpage>301</fpage>-<lpage>321</lpage>.</citation>
</ref>
<ref id="bibr13-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henson</surname><given-names>R. A.</given-names></name>
<name><surname>Roussos</surname><given-names>L.</given-names></name>
<name><surname>Douglas</surname><given-names>J.</given-names></name>
<name><surname>He</surname><given-names>X.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Cognitive diagnostic attribute-level discrimination indices</article-title>. <source>Applied Psychological Measurement</source>, <volume>32</volume>, <fpage>275</fpage>-<lpage>288</lpage>.</citation>
</ref>
<ref id="bibr14-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henson</surname><given-names>R. A.</given-names></name>
<name><surname>Templin</surname><given-names>J. L.</given-names></name>
<name><surname>Willse</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Defining a family of cognitive diagnosis models using log-linear models with latent variables</article-title>. <source>Psychometrika</source>, <volume>74</volume>, <fpage>191</fpage>-<lpage>210</lpage>.</citation>
</ref>
<ref id="bibr15-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Junker</surname><given-names>B. W.</given-names></name>
<name><surname>Sijtsma</surname><given-names>K.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Cognitive assessment models with few assumptions, and connections with nonparametric item response theory</article-title>. <source>Applied Psychological Measurement</source>, <volume>25</volume>, <fpage>258</fpage>-<lpage>272</lpage>.</citation>
</ref>
<ref id="bibr16-0146621612449069">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>P. M.</given-names></name>
</person-group> (<year>2004</year>). <source>Bayesian statistics: An introduction</source> (<edition>3rd ed.</edition>). <publisher-loc>London, England</publisher-loc>: <publisher-name>Hodder Education</publisher-name>.</citation>
</ref>
<ref id="bibr17-0146621612449069">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Macmillan</surname><given-names>N. A.</given-names></name>
<name><surname>Creelman</surname><given-names>C. D.</given-names></name>
</person-group> (<year>2005</year>). <source>Detection theory: A user’s guide</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Macready</surname><given-names>G. B.</given-names></name>
<name><surname>Dayton</surname><given-names>C. M.</given-names></name>
</person-group> (<year>1977</year>). <article-title>The use of probabilistic models in the assessment of mastery</article-title>. <source>Journal of Educational Statistics</source>, <volume>2</volume>, <fpage>99</fpage>-<lpage>120</lpage>.</citation>
</ref>
<ref id="bibr19-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Maris</surname><given-names>E.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Estimating multiple classification latent class models</article-title>. <source>Psychometrika</source>, <volume>64</volume>, <fpage>187</fpage>-<lpage>212</lpage>.</citation>
</ref>
<ref id="bibr20-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mislevy</surname><given-names>R. J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Test theory reconceived</article-title>. <source>Journal of Educational Measurement</source>, <volume>33</volume>, <fpage>379</fpage>-<lpage>416</lpage>.</citation>
</ref>
<ref id="bibr21-0146621612449069">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Muthén</surname><given-names>B.</given-names></name>
<name><surname>Asparouhov</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <source>Bayesian SEM: A more flexible representation of substantive theory</source>. <comment>Available from <ext-link ext-link-type="uri" xlink:href="http://www.statmodel.com">http://www.statmodel.com</ext-link></comment></citation>
</ref>
<ref id="bibr22-0146621612449069">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Rabe-Hesketh</surname><given-names>S.</given-names></name>
<name><surname>Skrondal</surname><given-names>A.</given-names></name>
<name><surname>Pickles</surname><given-names>A.</given-names></name>
</person-group> (<year>2004</year>). <source>GLLAMM manual</source> (<comment>Technical Report No. 160, U.C. Berkeley Division of Biostatistics Working Paper Series</comment>). <publisher-loc>Berkeley</publisher-loc>: <publisher-name>University of California</publisher-name>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.bepress.com/ucbbiostat/paper160/">http://www.bepress.com/ucbbiostat/paper160/</ext-link></comment></citation>
</ref>
<ref id="bibr23-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rupp</surname><given-names>A. A.</given-names></name>
<name><surname>Templin</surname><given-names>J. L.</given-names></name>
</person-group> (<year>2008a</year>). <article-title>The effects of Q-matrix misspecification on parameter estimates and classification accuracy in the DINA model</article-title>. <source>Educational and Psychological Measurement</source>, <volume>68</volume>, <fpage>78</fpage>-<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr24-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rupp</surname><given-names>A. A.</given-names></name>
<name><surname>Templin</surname><given-names>J. L.</given-names></name>
</person-group> (<year>2008b</year>). <article-title>Unique characteristics of diagnostic classification models: A comprehensive review of the current state-of-the-art</article-title>. <source>Measurement</source>, <volume>6</volume>, <fpage>219</fpage>-<lpage>262</lpage>.</citation>
</ref>
<ref id="bibr25-0146621612449069">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Spiegelhalter</surname><given-names>D.</given-names></name>
<name><surname>Thomas</surname><given-names>A.</given-names></name>
<name><surname>Best</surname><given-names>N. G.</given-names></name>
<name><surname>Lunn</surname><given-names>D.</given-names></name>
</person-group> (<year>2003</year>). <source>WinBUGS user manual</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.mrc-bsu.cam.ac.uk/bugs/">http://www.mrc-bsu.cam.ac.uk/bugs/</ext-link></comment></citation>
</ref>
<ref id="bibr26-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tatsuoka</surname><given-names>C.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Data analytic methods for latent partially ordered classification models</article-title>. <source>Journal of the Royal Statistical Society, Series C (Applied Statistics)</source>, <volume>51</volume>, <fpage>337</fpage>-<lpage>350</lpage>.</citation>
</ref>
<ref id="bibr27-0146621612449069">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tatsuoka</surname><given-names>K. K.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Toward an integration of item-response theory and cognitive error diagnosis</article-title>. In <person-group person-group-type="editor">
<name><surname>Frederiksen</surname><given-names>N.</given-names></name>
<name><surname>Glaser</surname><given-names>R.</given-names></name>
<name><surname>Lesgold</surname><given-names>A.</given-names></name>
<name><surname>Shafto</surname><given-names>M.</given-names></name>
</person-group> (Eds.), <source>Diagnostic monitoring of skill and knowledge acquisition</source> (pp. <fpage>453</fpage>-<lpage>488</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr28-0146621612449069">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Templin</surname><given-names>J.</given-names></name>
<name><surname>Henson</surname><given-names>R.</given-names></name>
</person-group> (<conf-date>2006, April</conf-date>). <source>A Bayesian method for incorporating uncertainty into Q-matrix estimation in skills assessment</source>. <conf-name>Paper presented at the annual meeting of the National Council on Measurement in Education</conf-name>, <conf-loc>San Francisco, CA</conf-loc>.</citation>
</ref>
<ref id="bibr29-0146621612449069">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Templin</surname><given-names>J. L.</given-names></name>
<name><surname>Henson</surname><given-names>R. A.</given-names></name>
<name><surname>Templin</surname><given-names>S. E.</given-names></name>
<name><surname>Roussos</surname><given-names>L.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Robustness of hierarchical modeling of skill association in cognitive diagnosis models</article-title>. <source>Applied Psychological Measurement</source>, <volume>32</volume>, <fpage>559</fpage>-<lpage>574</lpage>.</citation>
</ref>
<ref id="bibr30-0146621612449069">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Thomas</surname><given-names>A.</given-names></name>
<name><surname>O’Hara</surname><given-names>B.</given-names></name>
<name><surname>Ligges</surname><given-names>U.</given-names></name>
<name><surname>Sturtz</surname><given-names>S.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Making BUGS open</article-title>. <source>R News</source>, <volume>6</volume>, <fpage>12</fpage>-<lpage>17</lpage>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://mathstat.helsinki.fi/openbugs/FAQFrames.html">http://mathstat.helsinki.fi/openbugs/FAQFrames.html</ext-link></comment></citation>
</ref>
<ref id="bibr31-0146621612449069">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vermunt</surname><given-names>J. K.</given-names></name>
</person-group> (<year>1997</year>). <source>LEM: A general program for the analysis of categorical data</source>. <publisher-loc>Tilburg, Netherlands</publisher-loc>: <publisher-name>Tilburg University</publisher-name>.</citation>
</ref>
<ref id="bibr32-0146621612449069">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vermunt</surname><given-names>J. K.</given-names></name>
<name><surname>Magidson</surname><given-names>J.</given-names></name>
</person-group> (<year>2005</year>). <source>Technical guide for Latent Gold 4.0: Basic and advanced</source>. <publisher-loc>Belmont, MA</publisher-loc>: <publisher-name>Statistical Innovations</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>