<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">DIS</journal-id>
<journal-id journal-id-type="hwp">spdis</journal-id>
<journal-title>Discourse Studies</journal-title>
<issn pub-type="ppub">1461-4456</issn>
<issn pub-type="epub">1461-7080</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1461445612466468</article-id>
<article-id pub-id-type="publisher-id">10.1177_1461445612466468</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Rhetorical relations in multimodal documents</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Taboada</surname><given-names>Maite</given-names></name>
<aff id="aff1-1461445612466468">Simon Fraser University, Canada</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Habel</surname><given-names>Christopher</given-names></name>
<aff id="aff2-1461445612466468">University of Hamburg, Germany</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-1461445612466468">Maite Taboada, Department of Linguistics, Simon Fraser University, 8888 University Dr., Burnaby, BC, Canada V5A 1S6. Email: <email>mtaboada@sfu.ca</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2013</year>
</pub-date>
<volume>15</volume>
<issue>1</issue>
<fpage>65</fpage>
<lpage>89</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>We present a corpus-based study of coherence in multimodal documents. We concern ourselves with the types of relationships between graphs and tables and the text of the document in which they appear. In order to understand and categorize the types of relations across modalities, we are making use of Rhetorical Structure Theory (Mann and Thompson, 1988), and propose that this can adequately describe these types of relations. We analyzed a corpus comprising three different genres, and consisting of about 1500 pages of material and almost 600 figures, tables and graphs. We show that figures stand in both presentational and subject matter relations to the text, and that the relationship between figures and text is one of a small set out of the larger possible rhetorical relations. We also discuss several issues that arise in the treatment of multimodal material, such as the potential for multiple connections between figure and text.</p>
</abstract>
<kwd-group>
<kwd>Coherence</kwd>
<kwd>genre</kwd>
<kwd>multimodality</kwd>
<kwd>Rhetorical Structure Theory</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1461445612466468" sec-type="intro">
<title>Introduction</title>
<p>A great deal of work in the last few years has focused on the relationships between pure text and material presented through other modalities, be it visual, audio, or a combination of the two. Research on document design and learning has been trying to elucidate what kind of impact multimodal material has on the reader. <xref ref-type="bibr" rid="bibr45-1461445612466468">Mayer (2009)</xref>, for instance, reports on years of studies showing that students learn better when they learn from words and pictures than when they learn from words alone. The learning, however, is improved only when certain principles in the presentation of the multimedia material are followed. The principles refer to the order of presentation, the coherence of the text and pictures, and the type of cross-reference used.</p>
<p>Much research has studied whether to use multimodal material or not, where to place it, and what effect captions or other verbal information surrounding such material have on the reader (for an extensive literature review, see <xref ref-type="bibr" rid="bibr1-1461445612466468">Acartürk, 2010</xref>). Less frequently discussed is the nature of the relationship between depictive material and the text itself, that is, whether pictures, charts, tables, diagrams, etc., serve as illustration, merely decoration, evidence, example, or something else.</p>
<p>In this article, we concern ourselves with the types of relationships between pictures, figures and tables, and the text in which they appear. The rhetorical relations between figures and text can be understood as coherence links, contributing to the perceived coherence of a document (<xref ref-type="bibr" rid="bibr57-1461445612466468">Taboada, 2004</xref>). One fundamental assumption in the study of discourse and communication is that most discourse is coherent. In Rhetorical Structure Theory (RST), one theory that tries to account for text coherence, coherence is understood as the absence of non-sequiturs, that is, as a property of texts whereby all parts of a text have a reason to be in the text and, furthermore, there is no sense that there are parts that are somehow missing (<xref ref-type="bibr" rid="bibr40-1461445612466468">Mann and Taboada, 2010</xref>; <xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>). Our hypothesis is that multimodal documents exhibit a form of coherence that links not only the verbal material, but also the depictive material – the links being rhetorical relations.</p>
<p>This view of coherence is also framed within the notion of genre, the view that texts and discourses are a result of the context in which they are produced and processed, and that the specific goals of a genre have an effect on that genre’s structure and lexicogrammatical realizations. For our approach to genre, we follow Systemic Functional Linguistics. Within that school, the widely quoted definition by Martin is that genre is ‘a staged, goal-oriented, purposeful activity in which speakers engage as members of our culture’ (<xref ref-type="bibr" rid="bibr44-1461445612466468">Martin, 1984</xref>: 25). The study of genre within Systemic Functional Linguistics has concentrated on structural characterizations through genre staging. Stages are the constitutive elements of a genre, which follow each other in a predetermined fashion, specific to each genre. <xref ref-type="bibr" rid="bibr18-1461445612466468">Eggins (1994)</xref> characterizes the staging, or schematic structure of a genre, as a description of the parts that form the whole, and how the parts relate to each other. This is achieved following both formal and functional criteria.</p>
<p>Because we believe genre constrains the types of figures present, their placement and their relationship to the text, we study three different genres: newspaper articles, magazine articles in a scientific magazine, and scientific articles. Newspaper articles have the main goal of informing and entertaining, and develop in stages determined by the ‘inverted pyramid’ structure of newspaper writing (see <xref ref-type="bibr" rid="bibr50-1461445612466468">Scanlan, 2000</xref>, for a description and a history). Magazine articles tend to be more entertaining in both content and presentation, but in our case the articles originate in a scientific magazine, whose purpose is to disseminate research to a wider audience – professional, but also potentially lay. Finally, scientific articles have a much more restricted audience of researchers in a specific area. Their generic structure varies, but it tends to follow the introduction–method– result–discussion structure described by <xref ref-type="bibr" rid="bibr56-1461445612466468">Swales (1990)</xref>.</p>
<p>We are concerned mostly with figures (flow diagrams, bar or other charts, system overviews, maps, etc.) and tables. We will discuss briefly the role of photographs, but the study of photographs themselves and their relationship to the text will be left for future work (as we believe it is more complex than that between figures and text). We will often use the generic word ‘figure’ or ‘graph’ to refer to the types of illustrations discussed, as a whole, but prefer the term ‘depiction’ for modalities other than text (<xref ref-type="bibr" rid="bibr32-1461445612466468">Kosslyn et al., 2006</xref>), and will use it as a cover term for pictures, graphs, figures, and tables.</p>
<p>There is extensive research on different aspects of multimodality, from its reception and its effect on learning and recall (<xref ref-type="bibr" rid="bibr27-1461445612466468">Holsanova et al., 2009</xref>; <xref ref-type="bibr" rid="bibr45-1461445612466468">Mayer, 2009</xref>; <xref ref-type="bibr" rid="bibr46-1461445612466468">Moreno and Mayer, 1999</xref>), to the particular aspects of layout, design, and links between different modes (<xref ref-type="bibr" rid="bibr29-1461445612466468">Jeung et al., 1997</xref>). We focus on two particular modes: text and the depictive material that accompanies the text, and in particular on the links between the two. Issues of presentation and layout are beyond the scope of this work, but they are undoubtedly important, and have been studied elsewhere, for instance, in the work of Bateman and colleagues (<xref ref-type="bibr" rid="bibr8-1461445612466468">Bateman, 2008b</xref>; <xref ref-type="bibr" rid="bibr10-1461445612466468">Bateman et al., 2000</xref>, <xref ref-type="bibr" rid="bibr12-1461445612466468">2001</xref>). One interesting avenue to pursue in this direction is the effect of layout in understanding, and research using eye tracking technology seems most promising in that regard (<xref ref-type="bibr" rid="bibr2-1461445612466468">Acartürk et al., 2008</xref>; <xref ref-type="bibr" rid="bibr15-1461445612466468">Chu et al., 2009</xref>).</p>
<p>Captions for figures are also an element to bear in mind. Extensive research has shown that they are used to bridge text and images, and to process the individual parts of images (<xref ref-type="bibr" rid="bibr19-1461445612466468">Elzer et al., 2005</xref>). However, and in order to focus the current research, captions have been ignored, and considered a whole together with the figure. We consider that the rhetorical relation is between the text and the figure as a whole, including the caption.</p>
<p>In order to understand and categorize the types of relations between figures and text, we are making use of Rhetorical Structure Theory (<xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>), which we discuss in the following section.</p>
</sec>
<sec id="section2-1461445612466468">
<title>Coherence: Rhetorical relations between text and depictive material</title>
<p>In this section, we refer to the relations between depictive material and the portion of the document that introduces such figure, and propose that they stand in a coherence/rhetorical/argumentative relation. Previous research on the relations between parts of a document (<xref ref-type="bibr" rid="bibr12-1461445612466468">Bateman et al., 2001</xref>; <xref ref-type="bibr" rid="bibr31-1461445612466468">Kong, 2006</xref>) has established that the relations can be captured making use of the taxonomy of logico-semantic relations provided by Systemic Functional Linguistics (<xref ref-type="bibr" rid="bibr23-1461445612466468">Halliday and Matthiessen, 2004</xref>), a school of linguistics that has long been associated with the study of multimodality (<xref ref-type="bibr" rid="bibr5-1461445612466468">Baldry and Thibault, 2006</xref>; <xref ref-type="bibr" rid="bibr7-1461445612466468">Bateman, 2008a</xref>; <xref ref-type="bibr" rid="bibr34-1461445612466468">Kress and Van Leeuwen, 2006</xref>; <xref ref-type="bibr" rid="bibr35-1461445612466468">Kress et al., 2001</xref>; <xref ref-type="bibr" rid="bibr37-1461445612466468">Lemke, 1998</xref>; <xref ref-type="bibr" rid="bibr47-1461445612466468">O’Halloran, 2008</xref>; <xref ref-type="bibr" rid="bibr49-1461445612466468">Royce, 2007</xref>; <xref ref-type="bibr" rid="bibr53-1461445612466468">Stenglin, 2009</xref>; <xref ref-type="bibr" rid="bibr61-1461445612466468">Ventola et al., 2004</xref>). Other proposals for this relationship exist, most of them nicely summarized by <xref ref-type="bibr" rid="bibr7-1461445612466468">Bateman (2008a)</xref> and <xref ref-type="bibr" rid="bibr55-1461445612466468">Stöckl (2009)</xref>, who also proposes rhetorical-logical relations for the connection between text and depiction.</p>
<p>In our work, we make use of the related relations in Rhetorical Structure Theory (RST) (<xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>). We postulate that figures, graphs, pictures, and tables are in a rhetorical relation with the text that they accompany. By rhetorical relation we mean a relation that establishes a coherent relation between the text and the depiction. The advantage of using RST relations is that they are well-defined and have been extensively tested.</p>
<p>In RST, texts are understood as coherent wholes, made up of parts that stand in rhetorical relations to each other. The parts are typically clauses or sentences, and the relations are those that capture the perceived coherence of most texts. Relations are, at the lower level of the text, closely related to the coordinate and subordinate relations of traditional grammar (Concession, Condition, Cause, Result), but they can become more abstract (Elaboration, Antithesis, Summary, Background), typically when the relation is between larger chunks of the text. Relations are recursively applied, that is, two clauses may stand in a Condition relation and, as a unit, they may become part of an Elaboration relation with another unit in the text, a unit that can in turn be as small as a clause or as large as a paragraph. Units are called spans, and they may be atomic (one clause or one sentence), or composed of other spans.</p>
<p>Another fundamental aspect of RST is the relative status of spans. In most relations, one part of the relation (one span) is considered to be the main part, and the other one is secondary. They are called nucleus and satellite, respectively, and are analogous to the main and subordinate clauses of traditional grammar. Relations between a nucleus and one or more satellites are hypotactic. Some relations are paratactic, consisting of two or more nuclei, in a relation similar to that between coordinated clauses.</p>
<p>To illustrate these concepts, we will use the text in Example (1), represented graphically in <xref ref-type="fig" rid="fig1-1461445612466468">Figure 1</xref>, and taken from our corpus.<sup><xref ref-type="fn" rid="fn1-1461445612466468">1</xref></sup></p>
<list id="list1-1461445612466468" list-type="simple">
<list-item><p>(1) MNCs’ trade-offs between scale, innovation, and responsiveness need to be made taking into account a complex mix of factors including: industry, size, desired levels of synergies, access to skilled people, and the roles of scale, innovation and responsiveness in the business model. <xref ref-type="table" rid="table3-1461445612466468">Table 3</xref> lists some of the questions we suggest CIOs consider in deciding the extent of scale, innovation, and responsiveness desired.</p>
</list-item></list>
<fig id="fig1-1461445612466468" position="float">
<label>Figure 1.</label>
<caption>
<p>Sample RST analysis.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig1.tif"/>
</fig>
<p>In the figure, we see the representation of main and secondary parts (nuclei and satellites) as vertical lines and arrows. Leaving aside the question of how the text was segmented (there could have been further segmentation in unit 1), we see that the three units are related to each other. First of all, unit 3 is secondary to unit 2, with the two in a conditional relation <italic>(if you need to decide the extent of scale, innovation, and responsiveness, then look at the questions in <xref ref-type="table" rid="table3-1461445612466468">Table 3</xref>)</italic>. Those two spans become one unit, which is an elaboration of the first unit. Further multimodal analysis would include the relation of this piece of text to <xref ref-type="table" rid="table3-1461445612466468">Table 3</xref> itself.</p>
<p>In RST, relations are defined in terms of intentions that lead authors to use a particular relation. Thus, an RST diagram such as the one provided in <xref ref-type="fig" rid="fig1-1461445612466468">Figure 1</xref> provides a view of some of the author’s purposes or intentions for including each part.</p>
<p>Spans of texts can be related recursively by using relations, which are defined by constraints on the nucleus, on the satellite, and mainly by the effect that the writer wants to achieve on the reader. When labeling a particular relation, the analyst must make a plausibility judgment, based on the contextual situation and the (presumed or declared) intentions of the writer. That is, the analyst judges whether it is plausible that the writer had such-and-such intentions or desired to obtain such-and-such effects when creating the text.</p>
<p>Space precludes a more extensive discussion of the theory itself. More detail can be found in the original paper on RST (<xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>), a more recent overview (<xref ref-type="bibr" rid="bibr58-1461445612466468">Taboada and Mann, 2006a</xref>, <xref ref-type="bibr" rid="bibr59-1461445612466468">2006b</xref>), or the RST web site (<xref ref-type="bibr" rid="bibr40-1461445612466468">Mann and Taboada, 2010</xref>). The types of general relations that we shall be using will be hopefully self-explanatory from their labels (Evidence, Condition, Elaboration, etc.), but full definitions are available on the RST web site.</p>
<p>Most research in RST has examined texts and the relations contained therein. There have been applications in spoken discourse as well (for a review of applications, see <xref ref-type="bibr" rid="bibr58-1461445612466468">Taboada and Mann, 2006a</xref>), but not much research has addressed the connection between different types of components, for instance, different modes in a multimodal document. One exception is the work of Bateman and colleagues (<xref ref-type="bibr" rid="bibr8-1461445612466468">Bateman, 2008b</xref>; <xref ref-type="bibr" rid="bibr10-1461445612466468">Bateman et al., 2000</xref>, <xref ref-type="bibr" rid="bibr12-1461445612466468">2001</xref>; <xref ref-type="bibr" rid="bibr17-1461445612466468">Delin and Bateman, 2002</xref>), where rhetorical relations are annotated for entire documents, and figures and other graphic material are found to be in rhetorical relations with other text elements. Bateman and colleagues have also brought in the idea of genre, the type of text under consideration, and how that affects both the layout and the relationship of text and illustrations. Other work examining multimodal documents as coherent wholes that may be built out of rhetorical structures includes the work of André (<xref ref-type="bibr" rid="bibr3-1461445612466468">André, 1995</xref>; <xref ref-type="bibr" rid="bibr4-1461445612466468">André and Rist, 1996</xref>), <xref ref-type="bibr" rid="bibr20-1461445612466468">Feiner and McKeown (1993)</xref>, or Stock and others (<xref ref-type="bibr" rid="bibr13-1461445612466468">Carenini et al., 1993</xref>; <xref ref-type="bibr" rid="bibr54-1461445612466468">Stock, 1993</xref>). In most of this work there was a computational component, with the intention of generating multimodal documents.</p>
</sec>
<sec id="section3-1461445612466468">
<title>Corpus</title>
<p>This is a preliminary and mostly qualitative study, and thus our corpus size is moderate. We have studied three different types of texts: newspapers (print and/or online); scientific magazine articles; and scientific articles. The three types of texts were chosen because they were easily accessible and provide a range of comparison from the expertise point of view, since we can assume that newspaper layout is generally produced by experts, whereas scientific articles are created out of intuition and exposure to the genre, but usually not by people who have expertise in layout. Magazine articles combine experts of both types: writers who have some scientific knowledge, but who devote themselves to dissemination of scientific knowledge.<sup><xref ref-type="fn" rid="fn2-1461445612466468">2</xref></sup></p>
<p>Composition of the corpus:</p>
<list id="list2-1461445612466468" list-type="bullet">
<list-item><p><italic>Communications of the ACM</italic> (<ext-link ext-link-type="uri" xlink:href="http://cacm.acm.org/">http://cacm.acm.org/</ext-link>), henceforth CACM:</p>
<list id="list3-1461445612466468" list-type="bullet">
<list-item><p>all issues for January–June 2010 (six issues).</p></list-item>
</list></list-item>
<list-item><p><italic>Journal of Computational Linguistics</italic> (<ext-link ext-link-type="uri" xlink:href="http://www.mitpressjournals.org/loi/coli">http://www.mitpressjournals.org/loi/coli</ext-link>), henceforth CL:</p>
<list id="list4-1461445612466468" list-type="bullet">
<list-item><p>all issues for 2009 (four issues);</p></list-item>
<list-item><p>of those, only main articles (about four per issue).</p></list-item>
</list></list-item>
<list-item><p><italic>New York Times</italic>, henceforth NYT:</p>
<list id="list5-1461445612466468" list-type="bullet">
<list-item><p>articles from the ProQuest edition of the <italic>New York Times</italic> (available from the Simon Fraser University Library system via the ProQuest service):</p>
<list id="list6-1461445612466468" list-type="bullet">
<list-item><p>articles between 1 January and 31 December 2006 (most recent year available within ProQuest);</p></list-item>
<list-item><p>articles extracted with the search terms ‘oil spill’, a total of 54 documents (more were extracted, but discarded if they did not contain the words in the general sense of spilling of oil in the processes of drilling).<sup><xref ref-type="fn" rid="fn3-1461445612466468">3</xref></sup></p></list-item></list></list-item></list></list-item>
</list>
<p>The corpus as a whole contains about 1500 pages of material, with 579 instances of depictive material (pictures, figures, tables, and maps). The annotation process involved identifying, for each issue and article, what types of depictive material the articles contain. We then determined the type of relation between depictive material and text. In this section, we provide a summary of the numbers of articles annotated, and the types of depictive material by genre. <xref ref-type="table" rid="table1-1461445612466468">Table 1</xref> summarizes the counts for each component in the corpus.</p>
<table-wrap id="table1-1461445612466468" position="float">
<label>Table 1.</label>
<caption>
<p>Composition of the corpus.</p>
</caption>
<graphic alternate-form-of="table1-1461445612466468" xlink:href="10.1177_1461445612466468-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Page count</th>
<th align="left">Pictures</th>
<th align="left">Figures, graphs</th>
<th align="left">Tables</th>
<th align="left">Maps</th>
</tr>
</thead>
<tbody>
<tr>
<td><italic>Communications of the ACM</italic></td>
<td>736</td>
<td>35</td>
<td>189</td>
<td>21</td>
<td>–</td>
</tr>
<tr>
<td><italic>Computational Linguistics</italic></td>
<td>645</td>
<td>–</td>
<td>137</td>
<td>139</td>
<td>–</td>
</tr>
<tr>
<td><italic>New York Times</italic></td>
<td>62</td>
<td>51</td>
<td>–</td>
<td>–</td>
<td>7</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section4-1461445612466468">
<title>Analysis of rhetorical relations</title>
<p>In this section, we provide a summary of the type of relations and the signaling between depiction and text, again divided into the three corpora studied.</p>
<p>A few notes on methodology are in order here. First of all, we see the relation between depiction and text as happening at different levels, and affecting different types of spans. In some cases, the depictive material stands in a relationship to the entire text; such is the case with some of the Background and Preparation pictures in the <italic>New York Times</italic> articles. The relationship is akin to that of a title to the body of the article. In other cases, however, the relationship is between one paragraph that introduces and describes the depiction and the depiction itself. In some other cases, the relation is much more local, linking a single span of text (clause or sentence) and the depictive material, which together form a multimodal cluster (<xref ref-type="bibr" rid="bibr5-1461445612466468">Baldry and Thibault, 2006</xref>).</p>
<p>Second, most of the relations found were hypotactic, that is, they have two unequal members, one the nucleus and one the satellite. The vast majority of the examples have the depictive material as satellite. In the analysis, we found that the depictive material was almost always secondary to the information presented in the text. To ensure the accuracy of the annotation, we used the deletion test (<xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>; <xref ref-type="bibr" rid="bibr43-1461445612466468">Marcu et al., 1999</xref>): whichever one of the text or the depictive material can be deleted, that one is the satellite. As we mention in the Discussion section, we found that most depictive material acts as illustration, in <xref ref-type="bibr" rid="bibr6-1461445612466468">Barthes’ (1977)</xref> terms, certainly a characteristic of the genres studied.</p>
<p>In general, the annotation process involved reading the entire text, paying attention to depictive material when the author(s) included a deictic reference to it, or when it appeared in the layout, in the cases where there was no reference. A note was made of the most likely span of text that had a relation to the depictive material. Upon a second reading, nuclearity and type of relation were decided.</p>
<sec id="section5-1461445612466468">
<title>Communications of the ACM</title>
<p><xref ref-type="table" rid="table2-1461445612466468">Table 2</xref> provides a summary of the relations found within the CACM corpus, broken down by type of depictive material. As is clear from the table, Elaboration relations are the most frequent. This is because the depictive material, especially the figures, takes the material presented on the text further and provides additional information. This can take many different forms, as suggested in the RST definition of Elaboration, where the nucleus and the satellite (in this case, the graphical material) can be in one of the following relations: set-member, abstraction-instance, whole-part, process-step, object-attribute, generalization-specific.</p>
<table-wrap id="table2-1461445612466468" position="float">
<label>Table 2.</label>
<caption>
<p>Rhetorical relations in the CACM corpus.</p>
</caption>
<graphic alternate-form-of="table2-1461445612466468" xlink:href="10.1177_1461445612466468-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Pictures</th>
<th align="left">Figures</th>
<th align="left">Tables</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>Elaboration</td>
<td>7</td>
<td>134</td>
<td>10</td>
<td>151</td>
</tr>
<tr>
<td>Enablement</td>
<td>–</td>
<td>1</td>
<td>–</td>
<td>1</td>
</tr>
<tr>
<td>Evidence</td>
<td>2</td>
<td>48</td>
<td>9</td>
<td>59</td>
</tr>
<tr>
<td>Motivation</td>
<td>25</td>
<td>–</td>
<td>–</td>
<td>25</td>
</tr>
<tr>
<td>Preparation</td>
<td>1</td>
<td>–</td>
<td>–</td>
<td>1</td>
</tr>
<tr>
<td>Restatement</td>
<td>–</td>
<td>3</td>
<td>–</td>
<td>3</td>
</tr>
<tr>
<td>Summary</td>
<td>–</td>
<td>3</td>
<td>2</td>
<td>5</td>
</tr>
<tr>
<td>Total</td>
<td>35</td>
<td>189</td>
<td>21</td>
<td>245</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>By type of material, pictures are most often used for motivation, figures for elaboration, and tables for evidence. We discuss next some examples of these relations.</p>
<p>We saw, in the statistics presented earlier, that the CACM corpus had a relatively high number of pictures, mostly presented without captions. These tend to serve as illustrations to the text, and are often abstract representations relating to the content of the article. It was difficult to decide what rhetorical relation to assign to this picture–text relationship, as there was no signaling to make that connection more transparent. In the cases where the picture appeared towards the beginning of the article, it was straightforward to label them as Preparation. The Preparation relation states that the satellite precedes the nucleus and tends to make the reader more ready, interested, or oriented for reading the nucleus (in our case, the text itself). We will see later on that in the NYT corpus we have relaxed the precedence constraint, and have included cases where the picture appears towards the beginning of the article, not necessarily preceding the text, but in a salient position (see <xref ref-type="fig" rid="fig4-1461445612466468">Figure 4</xref>). In the CACM corpus, we find some instances of pictures as Preparation. We also find, however, instances of similar pictures that appear later on in the article, sometimes on pages 2 or 3 in a multi-page article. We can hardly label those as Preparation to the entire article, as we have done with pictures at the beginning of the article. We decided, in those cases, to label them as Motivation. The Effect of Motivation, in the RST definition, is that the reader’s desire to perform the action in the nucleus is increased. We considered that the picture serves as motivation for the reader to continue reading the text.</p>
<p>An example is <xref ref-type="fig" rid="fig2-1461445612466468">Figure 2</xref>, a small-scale rendition of a page from the CACM corpus (‘Other people’s data’, January 2010, p. 55). The article deals with the issues surrounding storage of large amounts of data. The picture represents the second page of the article, and depicts three file cabinet drawers overflowing with documents, and a ruler with a seemingly arbitrary scale at the bottom. The picture does not prepare us to read the text, or elaborate on it. It simply motivates the reader to continue reading and maybe helps to break the flow of the page, so as to avoid a full page of text. The placement of the picture is consistent with research (<xref ref-type="bibr" rid="bibr21-1461445612466468">Garcia and Stark, 1991</xref>; <xref ref-type="bibr" rid="bibr28-1461445612466468">Holsanova et al., 2006</xref>) that shows that readers scan text and start reading at certain entry points. Entry points can be headlines, boxes, or any other elements that break the flow, and pictures and graphics have been found to be entry points.</p>
<fig id="fig2-1461445612466468" position="float">
<label>Figure 2.</label>
<caption>
<p>Picture as Motivation.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig2.tif"/>
</fig>
<p>The original RST definition of Restatement (<xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>) proposed it as a hypotactic relation, with a satellite as a restatement of a nucleus of comparable bulk, but of more central importance. The issue of central importance is much more difficult to decide when one of the spans is in a different mode. For that reason, the GeM project (<xref ref-type="bibr" rid="bibr11-1461445612466468">Bateman et al., 2007</xref>; <xref ref-type="bibr" rid="bibr24-1461445612466468">Henschel, 2003</xref>) proposed a new type of multinuclear Restatement relation, already present in the RST Discourse Treebank corpus annotations (<xref ref-type="bibr" rid="bibr14-1461445612466468">Carlson et al., 2002</xref>; <xref ref-type="bibr" rid="bibr42-1461445612466468">Marcu, 1999</xref>). In our corpus, figures restate, in a different mode, the information already presented in the text (or, vice versa, the text restates the information provided by the figure). Restatements are one of the few cases where the depictive material is not a satellite to the text.</p>
</sec>
<sec id="section6-1461445612466468">
<title>Computational Linguistics</title>
<p>The articles in <italic>Computational Linguistics</italic> (a total of 18 studied, of which two had no tables or figures) contain a less varied distribution of rhetorical relations. As <xref ref-type="table" rid="table3-1461445612466468">Table 3</xref> shows, the majority of the figures and tables stand in an Elaboration and Evidence relation to the text.</p>
<table-wrap id="table3-1461445612466468" position="float">
<label>Table 3.</label>
<caption>
<p>Rhetorical relations in the CL corpus.</p></caption>
<graphic alternate-form-of="table3-1461445612466468" xlink:href="10.1177_1461445612466468-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Figures</th>
<th align="left">Tables</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>Elaboration</td>
<td>120</td>
<td>67</td>
<td>187</td>
</tr>
<tr>
<td>Evidence</td>
<td>16</td>
<td>72</td>
<td>88</td>
</tr>
<tr>
<td>Preparation</td>
<td>1</td>
<td>–</td>
<td>1</td>
</tr>
<tr>
<td>Total</td>
<td>137</td>
<td>139</td>
<td>276</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>As in the other corpora, tables most often have an Evidence function, showing data that the authors believe will bolster the claims made in the text. Some of the tables also have a simple Elaboration relation, providing additional quantitative material that would be much more difficult to read in prose form.</p>
<p>In terms of distribution across the stages of the research article genre, Elaboration relations tend to occur at the beginning of the article, whereas Evidence appears towards the middle and end, in the results section or sections.</p>
</sec>
<sec id="section7-1461445612466468">
<title>The New York Times</title>
<p><xref ref-type="table" rid="table4-1461445612466468">Table 4</xref> summarizes our analysis of the pictures and maps in the NYT corpus. We find that maps have the unique function of setting up a framework, and then relate to the text in a Circumstance relation (see below for an example). With respect to pictures, they have two main functions: Elaboration and Preparation. We discuss some examples below.</p>
<table-wrap id="table4-1461445612466468" position="float">
<label>Table 4.</label>
<caption>
<p>Rhetorical relations in the NYT corpus.</p>
</caption>
<graphic alternate-form-of="table4-1461445612466468" xlink:href="10.1177_1461445612466468-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Pictures</th>
<th align="left">Maps</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>Circumstance</td>
<td>1</td>
<td>7</td>
<td>8</td>
</tr>
<tr>
<td>Contrast</td>
<td>1</td>
<td>–</td>
<td>1</td>
</tr>
<tr>
<td>Elaboration</td>
<td>19</td>
<td>–</td>
<td>19</td>
</tr>
<tr>
<td>Evidence</td>
<td>9</td>
<td>–</td>
<td>9</td>
</tr>
<tr>
<td>Motivation</td>
<td>1</td>
<td>–</td>
<td>1</td>
</tr>
<tr>
<td>Preparation</td>
<td>20</td>
<td>–</td>
<td>20</td>
</tr>
<tr>
<td>Total</td>
<td>51</td>
<td>7</td>
<td>58</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>One of the characteristics of the pictures in NYT is that they function as Preparation to the rest of the story. For example, a picture in ‘Remembrance of downtown past’ (1 September 2006, p. E21) portrays the landscape around the former location of the World Trade Center in New York in 1978. The article is a personal reminiscence of that space in the 1970s and 1980s, interspersed with factual information about the art scene in that location. The picture serves as preparation for the rest of the story, a prompt that the location of the World Trade Center is still barren after the terrorist attacks of 11 September 2001, and a pathway into the time before the World Trade Center was erected, when the land was also barren. <xref ref-type="fig" rid="fig3-1461445612466468">Figure 3</xref> is a low-quality<sup><xref ref-type="fn" rid="fn4-1461445612466468">4</xref></sup> rendition of the beginning of the article, with a picture that dominates the page (this part of the article occupies the first half of the newspaper page). The picture, according to the caption, is a 1978 art installation on Battery Park. Part of the World Trade Center towers can be seen in the background, to the right.</p>
<fig id="fig3-1461445612466468" position="float">
<label>Figure 3.</label>
<caption>
<p>Beginning of <italic>New York Times</italic> article, 1 September 2006.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig3.tif"/>
</fig>
<p>A large number of the figures and pictures in NYT, as in CACM, serve as Preparation for the rest of the text. Eye-tracking studies of newspaper reading show that pictures, especially large ones, are processed first, before the text is read.<sup><xref ref-type="fn" rid="fn5-1461445612466468">5</xref></sup></p>
<p>One issue, however, is that the preparatory pictures are not always <italic>before</italic> the text, as the standard definition for Preparation states. The constraints on the relation read: ‘S precedes N in the text; S tends to make R more ready, interested or oriented for reading N’ (<xref ref-type="bibr" rid="bibr40-1461445612466468">Mann and Taboada, 2010</xref>). We have decided to waive the precedence requirement, as the salience of pictures has, in a sense, certain precedence: the picture is seen before the text (or at least the body of the text) is read. In all cases where we labeled a picture as Preparation, the picture was towards the beginning of the article, that is, never on a continuation page. Such is the case in <xref ref-type="fig" rid="fig4-1461445612466468">Figure 4</xref> (‘BP knew of safety problems at refinery, U.S. panel says’, 31 October 2006, p. C3). The picture, although to the right of the beginning of the text, is quite prominent, and larger than either the body text to its left or the heading.</p>
<fig id="fig4-1461445612466468" position="float">
<label>Figure 4.</label>
<caption>
<p>Picture as Preparation.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig4.tif"/>
</fig>
<p>We also find many pictures of the people involved in the story, which were also labeled as Preparation, since they seem to prepare and motivate the reader, by reading the article, to find out more about the people portrayed in the picture.</p>
<p>There is probably much more to the placement of the pictures than we have space to discuss here. In general, we have avoided discussing layout, as it would make the analysis and discussion more complex. We would simply like to point out, in the discussion of the Preparation relation and the placement of pictures in a Preparation relation, that one could analyze the two spans of the relation (text and picture) with respect to placement on the page, and using <xref ref-type="bibr" rid="bibr34-1461445612466468">Kress and Van Leeuwen’s (2006)</xref> Given–New/Ideal–Real distinctions, where Given is presented to the left of New, and Ideal on top of Real. The pictures at the beginning of the text act as Given material, with the text to be read as New.</p>
<p>Another interesting characteristic of NYT articles is the presence of maps. Maps allow the reader to locate a city, area or country that the reader may not be familiar with. Quite often, they provide additional information, a framework or grid to locate information presented in the article. In the same article that we discussed earlier (‘Remembrance of downtown past’, 1 September 2006, p. E21), a map identifies the locations discussed in the article, such as the location of the World Trade Center, Battery Park, and other, perhaps less familiar locations such as Herman Melville’s birthplace and other sites of artistic interest. This type of relation we labeled as Circumstance, with the map as satellite. In RST terms, the satellite of a Circumstance relation sets the framework within which the reader is to understand the nucleus. The framework may be temporal, spatial, or of a similar type. Most maps clearly provide a spatial framework.</p>
</sec>
<sec id="section8-1461445612466468">
<title>Reliabilty study</title>
<p>We have, so far, presented results of our analysis, and would like in this section to show that the analyses are reliable. RST analyses have been argued to be subjective, and the judgment of the analyst has always been part of how the theory is applied (<xref ref-type="bibr" rid="bibr41-1461445612466468">Mann and Thompson, 1988</xref>). Critics may argue that transferring RST to multimodal documents could make it even more subjective. In order to demonstrate that our analyses are reproducible, we conducted a reliability study.</p>
<p>For the study, we selected several documents: one from the CACM, one from CL, and three NYT articles. In total, they contain 56 different relations, about 10% of the relations in the corpus. We asked an independent analyst, trained in RST analyses, to label the relationship between text and depiction following some basic guidelines, mostly the RST definitions, with the additional information that we have presented here, namely that depictive material tends to enter into only a handful of relations with text, and that nuclearity can be tested with the deletion test.</p>
<p>Out of the 56 relations, the analyst agreed with our analyses in 41 of the cases, that is, 73.21% of the time. Percentage agreement can be misleading, since it is not sensitive to the range of options (in our case, an analyst can choose one of the 30 RST relations). To account for the fact that multiple categories are possible, we calculated agreement using Cohen’s kappa, for nominal data and unweighed (<xref ref-type="bibr" rid="bibr16-1461445612466468">Cohen, 1960</xref>). The kappa value for the 56 examples, labeled with one of nine relations (the actual relations used by either us or the analyst) is 0.616. This is considered ‘substantial’ agreement according to <xref ref-type="bibr" rid="bibr36-1461445612466468">Landis and Koch (1977)</xref>, and much higher than expected by chance. We can conclude that the methodology that we followed is reproducible, given a trained RST analyst.</p>
<p>Disagreements between our original analyses and those of the third analyst had mostly to do with the function of tables, and whether they were considered to be in Elaboration or Evidence relations with the text. Similarly, Preparation and Background were also annotated differently by the analyst. These are natural grey areas in the analysis, and showed intra-annotator consistency (i.e. the analyst tended to use more Evidence for tables, whereas the original analyses tended to use Elaboration).</p>
</sec>
</sec>
<sec id="section9-1461445612466468" sec-type="discussion">
<title>Discussion</title>
<p>We can summarize the findings of our analysis as follows:</p>
<list id="list7-1461445612466468" list-type="bullet">
<list-item><p>figures tend to elaborate on the text;</p></list-item>
<list-item><p>tables tend to provide evidence for claims and proposals in the text;</p></list-item>
<list-item><p>pictures provide background and motivation for the information in the text.</p></list-item>
</list>
<p>Pictures, graphs, and diagrams are most often subsidiary to the text, whereas tables provide either additional information or data demonstrating the validity of the methods and experiments in the text.</p>
<p>This secondary nature of illustrations is a result of the types of texts studied. In all three cases, the genre is one where words are most important and communication of verbal information is primary. The genres studied are examples of a text-flow semiotic mode (<xref ref-type="bibr" rid="bibr9-1461445612466468">Bateman, 2009</xref>), where the most important information is conveyed in the text, and the depictive material is used to support the text.</p>
<p>We found that, from the range of RST relations typically used (25–30 in most applications of RST), we used only a handful, and that those tended to be presentational, that is, relations that facilitate the presentation process and are internal to the text, as opposed to subject matter relations, which express parts of the subject matter of the text and reflect the state of affairs outside the text. We believe this is because of the wordy, text-flow characteristic of the documents. <xref ref-type="bibr" rid="bibr39-1461445612466468">Liu and O’Halloran (2009)</xref>, in analyzing news articles, also used only four of the possible conjunctive relations: Comparison, Addition, Consequence, and Time. Other research in document design (e.g. <xref ref-type="bibr" rid="bibr51-1461445612466468">Schriver, 1997</xref>) seems to point to a limited number of functions that depictive material has with respect to the text.</p>
<p>In the rest of this section, we would like to discuss more extensively three particular aspects of the analysis, and their implications for further studies of multimodal documents: the consequences of the creation process, the nature of the Elaboration relation, and the possibility that there are multiple relations connecting the same depiction to different parts of the text.</p>
<sec id="section10-1461445612466468">
<title>The creation process</title>
<p>The creation process in some of the documents studied is such that there may not be a single author, or even the same author involved in all parts of the document. In particular, in newspaper articles (and possibly some articles in CACM), one author may write the text, and a graphic artist may insert the picture, map, or graph, while an editor oversees the process and final product. It is also the case that many of the CL articles have multiple authors. RST assumes a single writer for the whole text, with particular intentions and effects that he or she wants to achieve. The presence of possible multiple authors complicates a straightforward set of constraints and desired effects that every RST relation is supposed to have.</p>
<p>In our analyses, we have assumed the usual situation of a single creator for the document, or rather, a single ‘mind’. One could consider that the authors/contributors have certain purposes and effects they, as a group, want to achieve with the multimodal document. This is the view that we have taken, but we also understand that more fine-grained analyses would have to study the creation process in order to understand the contribution of different authors and contributors to the final product.</p>
</sec>
<sec id="section11-1461445612466468">
<title>The Elaboration relation</title>
<p>The second aspect of the analysis that we would like to discuss is the predominance of the Elaboration relation. Taken together, all the corpora contain 579 relations. Of those, 61.66% are Elaboration relations (see <xref ref-type="table" rid="table5-1461445612466468">Table 5</xref>).</p>
<table-wrap id="table5-1461445612466468" position="float">
<label>Table 5.</label>
<caption>
<p>Summary, RST relations in entire corpus.</p></caption>
<graphic alternate-form-of="table5-1461445612466468" xlink:href="10.1177_1461445612466468-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Pictures</th>
<th align="left">Figures</th>
<th align="left">Tables</th>
<th align="left">Maps</th>
<th align="left">Total</th>
<th align="left">%</th>
</tr>
</thead>
<tbody>
<tr>
<td>Elaboration</td>
<td>26</td>
<td>254</td>
<td>77</td>
<td>0</td>
<td>357</td>
<td>61.66</td>
</tr>
<tr>
<td>Evidence</td>
<td>11</td>
<td>64</td>
<td>81</td>
<td>0</td>
<td>156</td>
<td>26.94</td>
</tr>
<tr>
<td>Motivation</td>
<td>26</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>26</td>
<td>4.49</td>
</tr>
<tr>
<td>Preparation</td>
<td>21</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>22</td>
<td>3.80</td>
</tr>
<tr>
<td>Circumstance</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>7</td>
<td>8</td>
<td>1.38</td>
</tr>
<tr>
<td>Summary</td>
<td>0</td>
<td>3</td>
<td>2</td>
<td>0</td>
<td>5</td>
<td>0.86</td>
</tr>
<tr>
<td>Restatement</td>
<td>0</td>
<td>3</td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>0.52</td>
</tr>
<tr>
<td>Enablement</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0.17</td>
</tr>
<tr>
<td>Contrast</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0.17</td>
</tr>
<tr>
<td>Total</td>
<td>86</td>
<td>326</td>
<td>160</td>
<td>7</td>
<td>579</td>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<p>The main reason that such a high proportion of the relations are Elaboration is that the documents analyzed convey most of their information through the text. Figures, pictures, tables, and maps are brought in to support information provided in the text. That type of relation is, in essence, an Elaboration relation.</p>
<p>Example (2) and <xref ref-type="fig" rid="fig5-1461445612466468">Figure 5</xref> show an instance of an Elaboration relation from the CL corpus.<sup><xref ref-type="fn" rid="fn6-1461445612466468">6</xref></sup> The text introduces the figure as presenting the overall architecture, and refers only to one part of the figure (MCUBE). The figure is the whole of the system, whereas the text contains a reference to only a part of it.</p>
<fig id="fig5-1461445612466468" position="float">
<label>Figure 5.</label>
<caption>
<p>A diagram in an Elaboration relation.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig5.tif"/>
</fig>
<list id="list8-1461445612466468" list-type="simple">
<list-item><p>(2) The underlying architecture that supports MATCH consists of a series of re-usable components which communicate over IP through a facilitator (MCUBE) (<xref ref-type="fig" rid="fig5-1461445612466468">Figure 5</xref>).</p></list-item>
</list>
<p>Similarly, in Example (3) and <xref ref-type="fig" rid="fig6-1461445612466468">Figure 6</xref>, from the CACM corpus,<sup><xref ref-type="fn" rid="fn7-1461445612466468">7</xref></sup> we see an Elaboration where the table provides additional information to the material presented in the text. Although the text uses the keyword ‘summarizes’, the summary is of ideas external to the text (i.e. held by the authors), whereas the table simply provides specific details to the generalization that there are critical obstacles.</p>
<list id="list9-1461445612466468" list-type="simple">
<list-item><p>(3) <xref ref-type="table" rid="table2-1461445612466468">Table 2</xref> summarizes our ranked list of critical obstacles to growth of cloud computing. The first three affect adoption, the next five affect growth, and the last two are policy and business obstacles. Each obstacle is paired with an opportunity to overcome that obstacle, ranging from product development to research projects.</p></list-item>
</list>
<fig id="fig6-1461445612466468" position="float">
<label>Figure 6.</label>
<caption>
<p>Table in an Elaboration relation.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig6.tif"/>
</fig>
<p>In many cases, the depiction is a specific member, instance or part of a general case discussed in the text. In other cases, the relationship works in the other direction (thus reversing the status of the depiction from satellite to nucleus): the depiction presents an entire process, of which only one or two steps are discussed in the text. In a sense, most Elaboration relations are specific cases of the general <italic>illustration</italic> function that <xref ref-type="bibr" rid="bibr6-1461445612466468">Barthes (1977)</xref> defined.</p>
<p>The Elaboration relation has been criticized as not being a true rhetorical relation (a relation of coherence), rather a relation of cohesion, that is, a relation among entities in the discourse. <xref ref-type="bibr" rid="bibr30-1461445612466468">Knott et al. (2001)</xref> discuss one of the cases of Elaboration, object–attribute Elaboration, and conclude that it is different in nature from other types of Elaboration and from other relations, since it is a relation between entities: one of the spans contains an attribute on an entity present in the other span. All other RST relations are relations between propositions, thus making (object–attribute) Elaboration a global relation, linking entities that are within focus spaces in the discourse, of the type proposed by <xref ref-type="bibr" rid="bibr22-1461445612466468">Grosz and Sidner (1986)</xref>. Knott et al.’s proposal involves removing object–attribute Elaboration from the set of RST relations. It is not clear, however, whether this applies to all types of Elaboration.</p>
<p>In our corpus, there are few entity-based Elaboration relations between text and figures. Most of the Elaboration cases are abstraction-instance, whole-part, process-step, or generalization-specific. It does seem, however, that labeling a text–graphic relation as Elaboration in over 60% of the cases provides little information about the type of relation holding. A proposal for multimodal documents would be to incorporate the additional labels to the Elaboration label, thus specifying what type of Elaboration relation holds.</p>
<p>Discussions by Baldry and Thibault (<xref ref-type="bibr" rid="bibr5-1461445612466468">Baldry and Thibault, 2006</xref>; <xref ref-type="bibr" rid="bibr60-1461445612466468">Thibault, 1997</xref>) and <xref ref-type="bibr" rid="bibr8-1461445612466468">Bateman (2008b)</xref> also deal with other problems with elaboration relations. Bateman points out ( <xref ref-type="bibr" rid="bibr8-1461445612466468">2008b</xref>) that, for instance, the relationship between a depiction and labels identifying different parts of it could be classified as Elaboration, but one that holds between elements that would not be naturally considered units in RST, since they are fragments. Another aspect worth mentioning in the context of the Elaboration relation is its relationship to cohesive links, that is, connections between elements that are related through relations such as reference, synonymy, or hypernymy. The connections may take place within modality, such as the words <italic>bird</italic> and <italic>gannet</italic>, but also across, such as the phrase <italic>off the NW coast of Europe</italic> and a map depicting that area (<xref ref-type="bibr" rid="bibr7-1461445612466468">Bateman, 2008a</xref>).</p>
</sec>
<sec id="section12-1461445612466468">
<title>Multiple relations</title>
<p>We have, in our analyses, always assumed that there is some relation between text and graphical material. We have, furthermore, assumed that such relation is unique, between a particular portion of a text (the scope of which may be under-defined) and the corresponding illustration. We would like now to explore the possibility that graphical material stands in multiple relationships to the text in the document.</p>
<p>RST assumes a linear order of processing. That is often the case in reading, and certainly so in speech, although one can look back in text, and also exploit some of the benefits of echoic memory for discontinuous processing of speech. In general, however, we follow the flow of reading or speaking. In multimodal documents, on the other hand, linear processing cannot be assumed. In a multimodal document, the text is processed in linear order, but with ‘excursions’ to the graphical material (<xref ref-type="bibr" rid="bibr25-1461445612466468">Holmqvist et al., 2003</xref>; <xref ref-type="bibr" rid="bibr38-1461445612466468">Lewenstein et al., 2000</xref>; <xref ref-type="bibr" rid="bibr52-1461445612466468">Stark Adam et al., 2007</xref>), and we know that, upon first contact with a multimodal document, we may scan back and forth, rather than read (<xref ref-type="bibr" rid="bibr33-1461445612466468">Kress and van Leeuwen, 1998</xref>). It may well be the case that a depiction is examined multiple times as the document is read. If so, then the relation between depiction and text may be a different one in each of those situations.</p>
<p>Let us consider one example, from a paper in CL.<sup><xref ref-type="fn" rid="fn8-1461445612466468">8</xref></sup> A table, reproduced in <xref ref-type="fig" rid="fig7-1461445612466468">Figure 7</xref>, is presented towards the beginning of the article, as Preparation to make the reader more able to understand the rest of the text. In (4), we reproduce the text used to justify the presence of the table. The text is in the same section as the table.</p>
<fig id="fig7-1461445612466468" position="float">
<label>Figure 7.</label>
<caption>
<p>Table with multiple relations to the text.</p>
</caption>
<graphic xlink:href="10.1177_1461445612466468-fig7.tif"/>
</fig>
<list id="list10-1461445612466468" list-type="simple">
<list-item><p>(4) Because this section combines notation from different theoretical frameworks (in particular, from formal semantics and statistical time-series modeling), a notation summary is provided in <xref ref-type="table" rid="table1-1461445612466468">Table 1</xref>.</p></list-item>
</list>
<p>At this point in the article, some of the terminology and notations in the table have already been introduced. The table could then serve as a Summary of definitions presented earlier (in Section 3 in the article), Preparation for the terminology presented in Section 4, and a Summary throughout the rest of the paper. It is quite likely that the reader will flip back to this table as he or she reads the paper, then establishing new links between text and table.</p>
<p>Another example of potential multiple relations is the already discussed article ‘Remembrance of downtown past’, from the <italic>New York Times</italic> corpus. As we mentioned earlier, the picture at the beginning of the article stands in a Preparation relation to the rest of the article: the reader, by looking at the photo, is more prepared to understand that the article is about a time in the past in New York City. However, as the article progresses, we also find that it is not only about a past time, but also, more specifically, about the art scene at that time. The fourth paragraph in the article is as follows:</p>
<list id="list11-1461445612466468" list-type="simple">
<list-item><p>(5) By the time I got to the neighborhood, the Twin Towers had been open for two years, but were hunting for tenants. The 92 acres of nearby Hudson River landfill were ready for Battery Park City, but there was no cash to build it. So for years, the long-planned revitalization of Lower Manhattan consisted, basically, of two squared-off, pinstripe-patterned 110-story structures set beside a riverside lot of scrub grass and dunes.</p></list-item>
</list>
<p>It is plausible that, at the point that ‘a riverside lot of scrub grass and dunes’ is mentioned, the reader looks back at the photo (right on top of this paragraph) and establishes a new relationship between text and photo, this time one of Elaboration. The photo elaborates, pictorially, what the text is describing.</p>
<p>On the next page, we read the following paragraph:</p>
<list id="list12-1461445612466468" list-type="simple">
<list-item><p>(6) Creative Time, led by Anita Contini, struck gold when she persuaded the Battery Park City Authority to let her use its empty landfill for art events. The location, which we were already using for sunbathing and kite flying, was stark, stunning and slightly eerie. [. . .]</p>
</list-item>
</list>
<p>The justification for the photo at the beginning seems now complete, with a new Elaboration relation. At first, we just see the photo as Preparation that, together with the title, leads us to think that the article is about a previous time. Then we realize that it is about how Lower Manhattan had empty spaces next to the World Trade Center. Finally, we understand that this space was the location of an art installation.</p>
<p>Thus, the reader has presumably established three different relations between photo and text. There are potential additional relations created with the help of the photo caption, which reads:</p>
<list id="list13-1461445612466468" list-type="simple">
<list-item><p>(7) “New York Ripple,” a 1978 installation by Patsy Norvell for “Art on the Beach,” a project on the Battery Park City landfill. See Page 26 for today’s view.</p></list-item>
</list>
<p>The caption helps us establish the later two Elaboration relations, keying the concepts of art installation and landfill to what the text describes.</p>
<p>The possibility of multiple relations between text and depiction is also entertained by Liu and O’Halloran, although in their paper they explore only single conjunctive relations between ‘two contiguous visual-linguistic messages’ (<xref ref-type="bibr" rid="bibr39-1461445612466468">Liu and O’Halloran, 2009</xref>: 379).</p>
<p>The presence of multiple relations to the same illustration may re-open a debate on RST on the cognitive status of rhetorical relations. If the reader can establish multiple relations between one span and another (in this case, between a table or figure and portions of the text), then it is also possible that different readers will establish different relations. For instance, it is entirely plausible that some readers will flip back to the table presented in <xref ref-type="fig" rid="fig7-1461445612466468">Figure 7</xref>, but that other readers will consult the table fewer times, or not at all. The relations established are then in the mind of the reader, and are not necessarily what the writer intended. It is also possible that the relation is established without the need to look back at the picture, making use of mental imagery (e.g. <xref ref-type="bibr" rid="bibr32-1461445612466468">Kosslyn et al., 2006</xref>; <xref ref-type="bibr" rid="bibr48-1461445612466468">Paivio, 1986</xref>).</p>
<p>RST has often been pegged as presenting a view of text as product, as opposed to text and discourse as a process. We believe RST does not need to be necessarily reduced to analyzing texts as finished products, and that it is therefore consistent with a treatment where different readers have different interpretations of the document, and where interpretation of the role of depictive material changes as the document is processed. We have shown, in previous work, that RST can be used in the analysis of process-based language, such as conversation (<xref ref-type="bibr" rid="bibr57-1461445612466468">Taboada, 2004</xref>).</p>
</sec>
</sec>
<sec id="section13-1461445612466468" sec-type="conclusions">
<title>6. Conclusions</title>
<p>We have presented a corpus-based analysis of the coherence and cohesion relations established between text and depictive material in multimodal documents. We argue that text and depictions stand in coherence relations, which we have chosen to define as rhetorical relations.</p>
<p>We have tried to show that the types of coherence relations that we find in verbal discourse also exist in multimodal discourse. This is at the risk of what Bateman calls ‘linguistic imperialism’ (<xref ref-type="bibr" rid="bibr9-1461445612466468">Bateman, 2009</xref>), whereby researchers tend to assume that other semiotic modes will behave like language, the semiotic mode that we know best. Bateman suggests that such an assumption needs to be empirically investigated, and that is precisely what we have attempted to do in this article. We have found the hypothesis wanting in some aspects (very few of the RST relations are used), but applicable in many others (relations are identifiable, and they capture the functions of depiction).</p>
<p>Our work contributes to ongoing research in the structure of multimodal documents. We follow Bateman’s framework (e.g. <xref ref-type="bibr" rid="bibr7-1461445612466468">Bateman, 2008b</xref>) in using Rhetorical Structure Theory, and extend it by applying RST to a large collection of assorted documents. We also see a relationship to the work of Holsanova and others (<xref ref-type="bibr" rid="bibr26-1461445612466468">Holsanova, 2008</xref>; <xref ref-type="bibr" rid="bibr27-1461445612466468">Holsanova et al., 2009</xref>), adding a corpus dimension.</p>
<p>The most significant implication of the research that we would like to conclude with is the potential presence of multiple relations between a particular instance of depictive material and different parts of the text. This could lead to a re-thinking of the structure of RST relations. The most common representation of the structure of a text in RST terms is in the form of a tree. It has been argued that trees are insufficient in some cases, such as parallelism, and that reported speech and other phenomena lead to crossed dependencies that trees cannot capture (<xref ref-type="bibr" rid="bibr62-1461445612466468">Wolf and Gibson, 2005</xref>). There is, a priori, no theoretical commitment to trees (<xref ref-type="bibr" rid="bibr59-1461445612466468">Taboada and Mann, 2006b</xref>), and thus other structures are possible.</p>
</sec>
</body>
<back>
<ack>
<p>We would like to thank audiences at the CINACS Summer School (Hamburg, September 2010), the workshop ‘Language and Depiction’ (Hamburg, November 2010), the Discourse Research Group (Utrecht, November 2010), and the Cognitive Science Speaker Series (Vancouver, February 2011) for useful feedback and suggestions, in particular Sabine Bartsch, John Bateman, and Manfred Stede. Thanks also to Debopam Das for carrying out the reliability study.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This work was supported by the Natural Sciences and Engineering Research Council of Canada (Discovery Grant 261104-2008). The research was conducted while Maite Taboada was a guest at the University of Hamburg, sponsored by a Fellowship for Experienced Researchers from the Alexander von Humboldt Foundation. We gratefully acknowledge their support.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1461445612466468">
<label>1.</label>
<p>From the <italic>Communications of the Association for Computing Machinery</italic> 53(3): 63, ‘Global IT Management: Structuring for scale, responsiveness and innovation’. The segmentation of this example is done at a coarse level, showing only higher-level relations.</p>
</fn>
<fn fn-type="other" id="fn2-1461445612466468">
<label>2.</label>
<p>The articles in <italic>Communications of the Association for Computing Machinery</italic> have a range of authors, from those more frequently involved in science dissemination, to regular academics who wish to publish in a more accessible venue.</p>
</fn>
<fn fn-type="other" id="fn3-1461445612466468">
<label>3.</label>
<p>The choice of a term was opportunistic (collection was done at around the time of the oil spill in the Gulf of Mexico in 2010) and differed from the approach for the other two genres, where entire collections (a year, or a few months) were used. We could not study a chronological set for the entire newspaper (week, month, or more), and that would have also resulted in many different genres. This was also a practical issue. It was not easy to find an electronic version of a complete issue of <italic>The New York Times</italic>, with pictures as they appeared in print. Their historical archive, which does contain pdf files of the original layout, is searchable, but not browsable by issue.</p>
</fn>
<fn fn-type="other" id="fn4-1461445612466468">
<label>4.</label>
<p>The article, with higher-quality pictures, is available at: <ext-link ext-link-type="uri" xlink:href="http://www.nytimes.com/2006/09/01/arts/design/01city.html">http://www.nytimes.com/2006/09/01/arts/design/01city.html</ext-link> (accessed 22 June 2012).</p>
</fn>
<fn fn-type="other" id="fn5-1461445612466468">
<label>5.</label>
<p>An initial study by the Poynter Institute showed that readers attend to images first, then to headlines and the rest of the text. A subsequent study by the same organization attested first attention to headlines, then to pictures. The experimenters attribute the difference to experimental design: in the second study, participants had been asked to refrain from reading the day’s newspapers. The subjects were then presumably genuinely interested in the news, and thus read the headlines first. Full details of the studies are available in the book <italic>Eyetracking the News</italic> (<xref ref-type="bibr" rid="bibr52-1461445612466468">Stark Adam et al., 2007</xref>), or from the Institute’s web site: <ext-link ext-link-type="uri" xlink:href="http://www.poynter.org/">http://www.poynter.org/</ext-link>, with the search term ‘eye-tracking’ (accessed 22 June 2012). There is also a difference in behavior between print and online news reading, with online readers attending first to text. See <xref ref-type="bibr" rid="bibr38-1461445612466468">Lewenstein et al. (2000)</xref> for a description of these studies.</p>
</fn>
<fn fn-type="other" id="fn6-1461445612466468">
<label>6.</label>
<p>Bangalore S and Johnston M (2009) Robust understanding in multimodal interfaces. <italic>Computational Linguistics</italic> 35(3): 345–397.</p>
</fn>
<fn fn-type="other" id="fn7-1461445612466468">
<label>7.</label>
<p>Armbrust M, Fox A, Griffith R et al. (2010) A view of cloud computing. <italic>Communications of the Association for Computing Machinery</italic> 53(4): 50–58.</p>
</fn>
<fn fn-type="other" id="fn8-1461445612466468">
<label>8.</label>
<p>Schuler W, Wu S and Schwartz L (2010) A framework for fast incremental interpretation during speech decoding. <italic>Computational Linguistics</italic> 35(3): 314–343.</p>
</fn>
</fn-group>
</notes>
<bio>
<title>Author biographies</title>
<p><bold>Maite Taboada</bold> is Associate Professor of Linguistics at Simon Fraser University, Canada. She works in the areas of discourse analysis, systemic functional linguistics and computational linguistics. She has carried out research on coherence and cohesion, information structure and turn- taking. She has also participated in research projects in natural language generation, machine translation and software agents. Ongoing research addresses the study of opinion and sentiment in text, including a system that extracts sentiment automatically. Other current areas of research are coherence in multimodal documents, and the study of cataphoric relations.</p>
<p><bold>Christopher Habel</bold> is Full Professor in Computer Science (Artificial Intelligence) and Adjunct Professor of Linguistics at the University of Hamburg, Germany. He holds a doctoral degree from the University of Osnabrück, Germany. He is the director of the Knowledge and Language Processing Group and the director of the study program Human–Computer-Interaction at the Department of Informatics. His areas of research are discourse and event structure; representation of knowledge, in particular, about space, time and events; language comprehension and language production. Some of his current research projects are: multimodal representations and communication; verbal assistance for tactile map explorations.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1461445612466468">
<citation citation-type="thesis">
<person-group person-group-type="author">
<name><surname>Acartürk</surname><given-names>C</given-names></name>
</person-group> (<year>2010</year>) <article-title>Multimodal comprehension of graph–text constellations: An information processing perspective</article-title>. PhD dissertation, <publisher-name>University of Hamburg</publisher-name>, <publisher-loc>Hamburg</publisher-loc>.</citation>
</ref>
<ref id="bibr2-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Acartürk</surname><given-names>C</given-names></name>
<name><surname>Habel</surname><given-names>C</given-names></name>
<name><surname>Cagiltay</surname><given-names>K</given-names></name>
<name><surname>Alacam</surname><given-names>O</given-names></name>
</person-group> (<year>2008</year>) <article-title>Multimodal comprehension of language and graphics: Graphs with and without annotations</article-title>. <source>Journal of Eye Movement Research</source> <volume>1</volume>(<issue>3</issue>): <fpage>1</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr3-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>André</surname><given-names>E</given-names></name>
</person-group> (<year>1995</year>) <source>Ein planbasierter Ansatz zur Generierung multimedialer Präsentationen</source> [<trans-source>A plan-based approach to the generation of multimedia presentations</trans-source>]. <publisher-loc>St Augustin</publisher-loc>: <publisher-name>Infix</publisher-name>.</citation>
</ref>
<ref id="bibr4-1461445612466468">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>André</surname><given-names>E</given-names></name>
<name><surname>Rist</surname><given-names>T</given-names></name>
</person-group> (<year>1996</year>) <article-title>Coping with temporal constraints in multimedia presentation planning</article-title>. <conf-name>Proceedings of Thirteenth National Conference on Artificial Intelligence</conf-name>, <conf-loc>Portland, OR</conf-loc>, pp. <fpage>142</fpage>–<lpage>147</lpage>.</citation>
</ref>
<ref id="bibr5-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Baldry</surname><given-names>A</given-names></name>
<name><surname>Thibault</surname><given-names>PJ</given-names></name>
</person-group> (<year>2006</year>) <source>Multimodal Transcription and Text Analysis: A Multimedia Toolkit and Coursebook</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Equinox</publisher-name>.</citation>
</ref>
<ref id="bibr6-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Barthes</surname><given-names>R</given-names></name>
</person-group> (<year>1977</year>) <source>Image, Music, Text</source>, trans. <person-group person-group-type="translator">
<name><surname>Heath</surname><given-names>S.</given-names></name>
</person-group> <publisher-loc>London</publisher-loc>: <publisher-name>Fontana</publisher-name>.</citation>
</ref>
<ref id="bibr7-1461445612466468">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Bateman</surname><given-names>J</given-names></name>
</person-group> (<year>2008a</year>) <source>Basic techniques and problems in multimodal analysis</source>. Available at: <ext-link ext-link-type="uri" xlink:href="http://www.fb10.uni-bremen.de/anglistik/langpro/webspace/jb/repository/talks/session-statics.pdf">http://www.fb10.uni-bremen.de/anglistik/langpro/webspace/jb/repository/talks/session-statics.pdf</ext-link> (<access-date>accessed 22 June 2012</access-date>).</citation>
</ref>
<ref id="bibr8-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bateman</surname><given-names>J</given-names></name>
</person-group> (<year>2008b</year>) <source>Multimodality and Genre: A Foundation for the Systematic Analysis of Multimodal Documents</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Palgrave Macmillan</publisher-name>.</citation>
</ref>
<ref id="bibr9-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bateman</surname><given-names>J</given-names></name>
</person-group> (<year>2009</year>) <article-title>Discourse across semiotic modes</article-title>. In: <person-group person-group-type="editor">
<name><surname>Renkema</surname><given-names>J</given-names></name>
</person-group> (ed.) <source>Discourse, Of Course</source>. <publisher-loc>Amsterdam and Philadelphia, PA</publisher-loc>: <publisher-name>John Benjamins</publisher-name>, pp. <fpage>55</fpage>–<lpage>66</lpage>.</citation>
</ref>
<ref id="bibr10-1461445612466468">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bateman</surname><given-names>J</given-names></name>
<name><surname>Delin</surname><given-names>J</given-names></name>
<name><surname>Allen</surname><given-names>P</given-names></name>
</person-group> (<year>2000</year>) <article-title>Constraints on layout in multimodal document generation</article-title>. <conf-name>Proceedings of First International Natural Language Generation Conference, Workshop on Coherence in Generated Multimedia</conf-name>, <conf-loc>Mitzpe Ramon, Israel</conf-loc>.</citation>
</ref>
<ref id="bibr11-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bateman</surname><given-names>J</given-names></name>
<name><surname>Delin</surname><given-names>J</given-names></name>
<name><surname>Henschel</surname><given-names>R</given-names></name>
</person-group> (<year>2007</year>) <article-title>Mapping the multimodal genres of traditional and electronic newspapers</article-title>. In: <person-group person-group-type="editor">
<name><surname>Royce</surname><given-names>TD</given-names></name>
<name><surname>Bowcher</surname><given-names>WL</given-names></name>
</person-group> (eds) <source>New Directions in the Analysis of Multimodal Discourse</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>, pp. <fpage>147</fpage>–<lpage>172</lpage>.</citation>
</ref>
<ref id="bibr12-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bateman</surname><given-names>J</given-names></name>
<name><surname>Kamps</surname><given-names>T</given-names></name>
<name><surname>Kleinz</surname><given-names>J</given-names></name>
<name><surname>Reichenberger</surname><given-names>K</given-names></name>
</person-group> (<year>2001</year>) <article-title>Towards constructive text, diagram, and layout generation for information presentation</article-title>. <source>Computational Linguistics</source> <volume>27</volume>(<issue>3</issue>): <fpage>409</fpage>–<lpage>449</lpage>.</citation>
</ref>
<ref id="bibr13-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carenini</surname><given-names>G</given-names></name>
<name><surname>Pianesi</surname><given-names>F</given-names></name>
<name><surname>Ponzi</surname><given-names>M</given-names></name>
<name><surname>Stock</surname><given-names>O</given-names></name>
</person-group> (<year>1993</year>) <article-title>Natural language generation and hypertext access</article-title>. <source>Applied Artificial Intelligence</source> <volume>7</volume>(<issue>2</issue>): <fpage>135</fpage>–<lpage>164</lpage>.</citation>
</ref>
<ref id="bibr14-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Carlson</surname><given-names>L</given-names></name>
<name><surname>Marcu</surname><given-names>D</given-names></name>
<name><surname>Okurowski</surname><given-names>ME</given-names></name>
</person-group> (<year>2002</year>) <source>RST Discourse Treebank</source>, LDC2002T07 [Corpus]. <publisher-loc>Philadelphia, PA</publisher-loc>: <publisher-name>Linguistic Data Consortium</publisher-name>.</citation>
</ref>
<ref id="bibr15-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chu</surname><given-names>S</given-names></name>
<name><surname>Paul</surname><given-names>N</given-names></name>
<name><surname>Ruel</surname><given-names>L</given-names></name>
</person-group> (<year>2009</year>) <article-title>Using eye tracking technology to examine the effectiveness of design elements on news websites</article-title>. <source>Information Design Journal</source> <volume>17</volume>(<issue>1</issue>): <fpage>31</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr16-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cohen</surname><given-names>J</given-names></name>
</person-group> (<year>1960</year>) <article-title>A coefficient of agreement for nominal scales</article-title>. <source>Educational and Psychological Measurement</source> <volume>20</volume>(<issue>1</issue>): <fpage>37</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr17-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Delin</surname><given-names>J</given-names></name>
<name><surname>Bateman</surname><given-names>J</given-names></name>
</person-group> (<year>2002</year>) <article-title>Describing and critiquing multimodal documents</article-title>. <source>Document Design</source> <volume>3</volume>(<issue>2</issue>): <fpage>140</fpage>–<lpage>155</lpage>.</citation>
</ref>
<ref id="bibr18-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Eggins</surname><given-names>S</given-names></name>
</person-group> (<year>1994</year>) <source>An Introduction to Systemic Functional Linguistics</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Pinter</publisher-name>.</citation>
</ref>
<ref id="bibr19-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Elzer</surname><given-names>S</given-names></name>
<name><surname>Carberry</surname><given-names>S</given-names></name>
<name><surname>Chester</surname><given-names>D</given-names></name>
<name><surname>Demir</surname><given-names>S</given-names></name>
<name><surname>Green</surname><given-names>N</given-names></name>
<name><surname>Zukerman</surname><given-names>I</given-names></name>
<name><surname>Trnka</surname><given-names>K</given-names></name>
</person-group> (<year>2005</year>) <article-title>Exploring and exploiting the limited utility of captions in recognizing intention in information graphics</article-title>. <conf-name>Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</conf-name>, <conf-loc>Ann Arbor, MI</conf-loc>, pp. <fpage>223</fpage>–<lpage>230</lpage>.</citation>
</ref>
<ref id="bibr20-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Feiner</surname><given-names>SK</given-names></name>
<name><surname>McKeown</surname><given-names>K</given-names></name>
</person-group> (<year>1993</year>) <article-title>Automating the generation of coordinated multimedia explanations</article-title>. In: <person-group person-group-type="editor">
<name><surname>Maybury</surname><given-names>M</given-names></name>
</person-group> (ed.) <source>Intelligent Multimedia Interfaces</source>. <publisher-loc>Menlo Park, CA</publisher-loc>: <publisher-name>AAAI Press</publisher-name>, pp. <fpage>117</fpage>–<lpage>138</lpage>.</citation>
</ref>
<ref id="bibr21-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Garcia</surname><given-names>M</given-names></name>
<name><surname>Stark</surname><given-names>P</given-names></name>
</person-group> (<year>1991</year>) <source>Eyes on the News</source>. <publisher-loc>St Petersburg, FL</publisher-loc>: <publisher-name>The Poynter Institute</publisher-name>.</citation>
</ref>
<ref id="bibr22-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Grosz</surname><given-names>BJ</given-names></name>
<name><surname>Sidner</surname><given-names>CL</given-names></name>
</person-group> (<year>1986</year>) <article-title>Attention, intentions, and the structure of discourse</article-title>. <source>Computational Linguistics</source> <volume>12</volume>(<issue>3</issue>): <fpage>175</fpage>–<lpage>204</lpage>.</citation>
</ref>
<ref id="bibr23-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Halliday</surname><given-names>MAK</given-names></name>
<name><surname>Matthiessen</surname><given-names>CMIM</given-names></name>
</person-group> (<year>2004</year>) <source>An Introduction to Functional Grammar</source>, <edition>3rd edn.</edition> <publisher-loc>London</publisher-loc>: <publisher-name>Arnold</publisher-name>.</citation>
</ref>
<ref id="bibr24-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Henschel</surname><given-names>R</given-names></name>
</person-group> (<year>2003</year>) <source>GeM Annotation Manual</source>. <publisher-loc>Bremen</publisher-loc>: <publisher-name>University of Bremen</publisher-name>.</citation>
</ref>
<ref id="bibr25-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Holmqvist</surname><given-names>K</given-names></name>
<name><surname>Holsanova</surname><given-names>J</given-names></name>
<name><surname>Barthelson</surname><given-names>M</given-names></name>
<name><surname>Lundqvist</surname><given-names>D</given-names></name>
</person-group> (<year>2003</year>) <article-title>Reading or scanning? A study of newspaper and net paper reading</article-title>. In: <person-group person-group-type="editor">
<name><surname>Hyönä</surname><given-names>J</given-names></name>
<name><surname>Radach</surname><given-names>R</given-names></name>
<name><surname>Deubel</surname><given-names>H</given-names></name>
</person-group> (eds) <source>The Mind’s Eye: Cognitive and Applied Aspects of Eye Movement Research</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>, pp. <fpage>657</fpage>–<lpage>670</lpage>.</citation>
</ref>
<ref id="bibr26-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Holsanova</surname><given-names>J</given-names></name>
</person-group> (<year>2008</year>) <source>Discourse, Vision, and Cognition</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>John Benjamins</publisher-name>.</citation>
</ref>
<ref id="bibr27-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Holsanova</surname><given-names>J</given-names></name>
<name><surname>Holmberg</surname><given-names>N</given-names></name>
<name><surname>Holmqvist</surname><given-names>K</given-names></name>
</person-group> (<year>2009</year>) <article-title>Reading information graphics: The role of spatial contiguity and dual attentional guidance</article-title>. <source>Applied Cognitive Psychology</source> <volume>23</volume>: <fpage>1215</fpage>–<lpage>1226</lpage>.</citation>
</ref>
<ref id="bibr28-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Holsanova</surname><given-names>J</given-names></name>
<name><surname>Rahm</surname><given-names>H</given-names></name>
<name><surname>Holmqvist</surname><given-names>K</given-names></name>
</person-group> (<year>2006</year>) <article-title>Entry points and reading paths on newspaper spreads: Comparing a semiotic analysis with eye-tracking measurements</article-title>. <source>Visual Communication</source> <volume>5</volume>(<issue>1</issue>): pp. <fpage>65</fpage>–<lpage>93</lpage>.</citation>
</ref>
<ref id="bibr29-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jeung</surname><given-names>H-J</given-names></name>
<name><surname>Chandler</surname><given-names>P</given-names></name>
<name><surname>Sweller</surname><given-names>P</given-names></name>
</person-group> (<year>1997</year>) <article-title>The role of visual indicators in dual sensory mode instruction</article-title>. <source>Educational Psychology</source> <volume>17</volume>(<issue>3</issue>): <fpage>329</fpage>–<lpage>345</lpage>.</citation>
</ref>
<ref id="bibr30-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Knott</surname><given-names>A</given-names></name>
<name><surname>Oberlander</surname><given-names>J</given-names></name>
<name><surname>O’Donnell</surname><given-names>M</given-names></name>
<name><surname>Mellish</surname><given-names>C</given-names></name>
</person-group> (<year>2001</year>) <article-title>Beyond elaboration: The interaction of relations and focus in coherent text</article-title>. In: <person-group person-group-type="editor">
<name><surname>Sanders</surname><given-names>T</given-names></name>
<name><surname>Schilperoord</surname><given-names>J</given-names></name>
<name><surname>Spooren</surname><given-names>W</given-names></name>
</person-group> (eds) <source>Text Representation: Linguistic and Psycholinguistic Aspects</source>. <publisher-loc>Amsterdam and Philadelphia, PA</publisher-loc>: <publisher-name>John Benjamins</publisher-name>, pp. <fpage>181</fpage>–<lpage>196</lpage>.</citation>
</ref>
<ref id="bibr31-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kong</surname><given-names>KCC</given-names></name>
</person-group> (<year>2006</year>) <article-title>A taxonomy of the discourse relations between words and visual</article-title>. <source>Information Design Journal</source> <volume>14</volume>(<issue>3</issue>): <fpage>207</fpage>–<lpage>230</lpage>.</citation>
</ref>
<ref id="bibr32-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kosslyn</surname><given-names>SM</given-names></name>
<name><surname>Thompson</surname><given-names>WL</given-names></name>
<name><surname>Ganis</surname><given-names>G</given-names></name>
</person-group> (<year>2006</year>) <source>The Case for Mental Imagery</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr33-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kress</surname><given-names>G</given-names></name>
<name><surname>van Leeuwen</surname><given-names>T</given-names></name>
</person-group> (<year>1998</year>) <article-title>Front page: (The critical) analysis of newspaper layout</article-title>. In: <person-group person-group-type="editor">
<name><surname>Bell</surname><given-names>A</given-names></name>
<name><surname>Garrett</surname><given-names>P</given-names></name>
</person-group> (eds) <source>Approaches to Media Discourse</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Blackwell</publisher-name>, pp. <fpage>186</fpage>–<lpage>219</lpage>.</citation>
</ref>
<ref id="bibr34-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kress</surname><given-names>G</given-names></name>
<name><surname>van Leeuwen</surname><given-names>T</given-names></name>
</person-group> (<year>2006</year>) <source>Reading Images: The Grammar of Visual Design</source>, <edition>2nd edn.</edition> <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr35-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kress</surname><given-names>G</given-names></name>
<name><surname>Jewitt</surname><given-names>C</given-names></name>
<name><surname>Ogborn</surname><given-names>J</given-names></name>
<name><surname>Tsatsarelis</surname><given-names>C</given-names></name>
</person-group> (<year>2001</year>) <source>Multimodal Teaching and Learning: The Rhetorics of the Science Classroom</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Continuum</publisher-name>.</citation>
</ref>
<ref id="bibr36-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Landis</surname><given-names>JR</given-names></name>
<name><surname>Koch</surname><given-names>GG</given-names></name>
</person-group> (<year>1977</year>) <article-title>The measurement of observer agreement for categorical data</article-title>. <source>Biometrics</source> <volume>33</volume>(<issue>1</issue>): <fpage>159</fpage>–<lpage>174</lpage>.</citation>
</ref>
<ref id="bibr37-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lemke</surname><given-names>J</given-names></name>
</person-group> (<year>1998</year>) <article-title>Multiplying meaning: Visual and verbal semiotics in scientific text</article-title>. In: <person-group person-group-type="editor">
<name><surname>Martin</surname><given-names>JR</given-names></name>
<name><surname>Veel</surname><given-names>R</given-names></name>
</person-group> (eds) <source>Reading Science: Critical and Funcitonal Perspectives on Discourses of Science</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>, pp. <fpage>87</fpage>–<lpage>113</lpage>.</citation>
</ref>
<ref id="bibr38-1461445612466468">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Lewenstein</surname><given-names>M</given-names></name>
<name><surname>Edwards</surname><given-names>G</given-names></name>
<name><surname>Tatar</surname><given-names>D</given-names></name>
<name><surname>DeVigal</surname><given-names>A</given-names></name>
</person-group> (<year>2000</year>) <source>Poynter Eyetrack Study</source>. <publisher-loc>St Petersburg, FL</publisher-loc>: <publisher-name>The Poynter Institute</publisher-name>. Available at: <ext-link ext-link-type="uri" xlink:href="http://www.poynter.org/eyetrack2000">http://www.poynter.org/eyetrack2000</ext-link>.</citation>
</ref>
<ref id="bibr39-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liu</surname><given-names>Y</given-names></name>
<name><surname>O’Halloran</surname><given-names>K</given-names></name>
</person-group> (<year>2009</year>) <article-title>Intersemiotic texture: Analyzing cohesive devices between language and images</article-title>. <source>Social Semiotics</source> <volume>19</volume>(<issue>4</issue>): <fpage>367</fpage>–<lpage>388</lpage>.</citation>
</ref>
<ref id="bibr40-1461445612466468">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Mann</surname><given-names>WC</given-names></name>
<name><surname>Taboada</surname><given-names>M</given-names></name>
</person-group> (<year>2010</year>) <source>RST Web Site</source>. Available at: <ext-link ext-link-type="uri" xlink:href="http://www.sfu.ca/rst">http://www.sfu.ca/rst</ext-link>.</citation>
</ref>
<ref id="bibr41-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mann</surname><given-names>WC</given-names></name>
<name><surname>Thompson</surname><given-names>SA</given-names></name>
</person-group> (<year>1988</year>) <article-title>Rhetorical Structure Theory: Toward a functional theory of text organization</article-title>. <source>Text</source> <volume>8</volume>(<issue>3</issue>): <fpage>243</fpage>–<lpage>281</lpage>.</citation>
</ref>
<ref id="bibr42-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Marcu</surname><given-names>D</given-names></name>
</person-group> (<year>1999</year>) <source>Instructions for Manually Annotating the Discourse Structures of Texts</source> (Manual). <publisher-name>Marina del Rey</publisher-name>, <publisher-loc>California</publisher-loc>.</citation>
</ref>
<ref id="bibr43-1461445612466468">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Marcu</surname><given-names>D</given-names></name>
<name><surname>Romera</surname><given-names>M</given-names></name>
<name><surname>Amorrortu</surname><given-names>E</given-names></name>
</person-group> (<year>1999</year>) <article-title>Experiments in constructing a corpus of discourse trees: Problems, annotation choices, issues</article-title>. <conf-name>Workshop on Levels of Representation in Discourse</conf-name>, <conf-loc>Edinburgh, UK</conf-loc>, pp. <fpage>71</fpage>–<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr44-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Martin</surname><given-names>JR</given-names></name>
</person-group> (<year>1984</year>) <article-title>Language, register and genre</article-title>. In: <person-group person-group-type="editor">
<name><surname>Christie</surname><given-names>F</given-names></name>
</person-group> (ed.) <source>Children Writing: Reader</source>. <publisher-loc>Geelong, Victoria</publisher-loc>: <publisher-name>Deakin University Press</publisher-name>, pp. <fpage>21</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr45-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mayer</surname><given-names>RE</given-names></name>
</person-group> (<year>2009</year>) <source>Multimedia Learning</source>, <edition>2nd edn.</edition> <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr46-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moreno</surname><given-names>R</given-names></name>
<name><surname>Mayer</surname><given-names>RE</given-names></name>
</person-group> (<year>1999</year>) <article-title>Cognitive principles of multimedia learning: The role of modality and contiguity</article-title>. <source>Journal of Educational Psychology</source> <volume>91</volume>(<issue>2</issue>): <fpage>358</fpage>–<lpage>368</lpage>.</citation>
</ref>
<ref id="bibr47-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>O’Halloran</surname><given-names>K</given-names></name>
</person-group> (<year>2008</year>) <article-title>Systemic Functional-Multimodal Discourse Analysis (SF-MDA): Constructing ideational meaning using language and visual imagery</article-title>. <source>Visual Communication</source> <volume>7</volume>(<issue>4</issue>): <fpage>443</fpage>–<lpage>475</lpage>.</citation>
</ref>
<ref id="bibr48-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Paivio</surname><given-names>A</given-names></name>
</person-group> (<year>1986</year>) <source>Mental Representations: A Dual Coding Approach</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr49-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Royce</surname><given-names>TD</given-names></name>
</person-group> (<year>2007</year>) <article-title>Inter-semiotic complementarity: A framework for multimodal discourse analysis</article-title>. In: <person-group person-group-type="editor">
<name><surname>Royce</surname><given-names>TD</given-names></name>
<name><surname>Bowcher</surname><given-names>WL</given-names></name>
</person-group> (eds) <source>New Directions in the Analysis of Multimodal Discourse</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>, pp. <fpage>63</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr50-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scanlan</surname><given-names>C</given-names></name>
</person-group> (<year>2000</year>) <source>Reporting and Writing: Basics for the 21st Century</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr51-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Schriver</surname><given-names>KA</given-names></name>
</person-group> (<year>1997</year>) <source>Dynamics in Document Design</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr52-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stark Adam</surname><given-names>P</given-names></name>
<name><surname>Quinn</surname><given-names>S</given-names></name>
<name><surname>Edmonds</surname><given-names>R</given-names></name>
</person-group> (<year>2007</year>) <source>Eyetracking the News</source>. <publisher-loc>St Petersburg, FL</publisher-loc>: <publisher-name>The Poynter Institute</publisher-name>.</citation>
</ref>
<ref id="bibr53-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stenglin</surname><given-names>M</given-names></name>
</person-group> (<year>2009</year>) <article-title>Space odyssey: Towards a social semiotic model of three-dimensional space</article-title>. <source>Visual Communication</source> <volume>8</volume>(<issue>1</issue>): <fpage>35</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr54-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stock</surname><given-names>O</given-names></name>
</person-group> (<year>1993</year>) <article-title>ALFRESCO: Enjoing the combination of natural language processing and hypermedia for information exploration</article-title>. In: <person-group person-group-type="editor">
<name><surname>Maybury</surname><given-names>M</given-names></name>
</person-group> (ed.) <source>Intelligent Multimedia Interfaces</source>. <publisher-loc>Menlo Park; CA</publisher-loc>: <publisher-name>AAAI Press</publisher-name>, pp. <fpage>197</fpage>–<lpage>224</lpage>.</citation>
</ref>
<ref id="bibr55-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stöckl</surname><given-names>H</given-names></name>
</person-group> (<year>2009</year>) <article-title>Beyond depicting: Language-image-links in the service of advertising</article-title>. <source>AAA – Arbeiten aus Anglistik und Amerikanistik</source> <volume>34</volume>(<issue>1</issue>): <fpage>3</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr56-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Swales</surname><given-names>JM</given-names></name>
</person-group> (<year>1990</year>) <source>Genre Analysis: English in Academic and Research Settings</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr57-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Taboada</surname><given-names>M</given-names></name>
</person-group> (<year>2004</year>) <source>Building Coherence and Cohesion: Task-oriented Dialogue in English and Spanish</source>. <publisher-loc>Amsterdam and Philadelphia, PA</publisher-loc>: <publisher-name>John Benjamins</publisher-name>.</citation>
</ref>
<ref id="bibr58-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Taboada</surname><given-names>M</given-names></name>
<name><surname>Mann</surname><given-names>WC</given-names></name>
</person-group> (<year>2006a</year>) <article-title>Applications of Rhetorical Structure Theory</article-title>. <source>Discourse Studies</source> <volume>8</volume>(<issue>4</issue>): <fpage>567</fpage>–<lpage>588</lpage>.</citation>
</ref>
<ref id="bibr59-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Taboada</surname><given-names>M</given-names></name>
<name><surname>Mann</surname><given-names>WC</given-names></name>
</person-group> (<year>2006b</year>) <article-title>Rhetorical Structure Theory: Looking back and moving ahead</article-title>. <source>Discourse Studies</source> <volume>8</volume>(<issue>3</issue>): <fpage>423</fpage>–<lpage>459</lpage>.</citation>
</ref>
<ref id="bibr60-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thibault</surname><given-names>PJ</given-names></name>
</person-group> (<year>1997</year>) <source>Re-reading Saussure: The Dynamics of Signs in Social Life</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr61-1461445612466468">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Ventola</surname><given-names>E</given-names></name>
<name><surname>Charles</surname><given-names>C</given-names></name>
<name><surname>Kaltenbacher</surname><given-names>M</given-names></name>
</person-group> (eds) (<year>2004</year>) <source>Perspectives on Multimodality</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>John Benjamins</publisher-name>.</citation>
</ref>
<ref id="bibr62-1461445612466468">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolf</surname><given-names>F</given-names></name>
<name><surname>Gibson</surname><given-names>E</given-names></name>
</person-group> (<year>2005</year>) <article-title>Representing discourse coherence: A corpus-based analysis</article-title>. <source>Computational Linguistics</source> <volume>31</volume>(<issue>2</issue>): <fpage>249</fpage>–<lpage>287</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>