<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPM</journal-id>
<journal-id journal-id-type="hwp">spepm</journal-id>
<journal-title>Educational and Psychological Measurement</journal-title>
<issn pub-type="ppub">0013-1644</issn>
<issn pub-type="epub">1552-3888</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0013164411406533</article-id>
<article-id pub-id-type="publisher-id">10.1177_0013164411406533</article-id>
<title-group>
<article-title>A Comparison of Methods for Estimating Confidence Intervals for Omega-Squared Effect Size</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Finch</surname><given-names>W. Holmes</given-names></name>
<xref ref-type="aff" rid="aff1-0013164411406533">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>French</surname><given-names>Brian F.</given-names></name>
<xref ref-type="aff" rid="aff2-0013164411406533">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0013164411406533"><label>1</label>Ball State University, Muncie, IN, USA</aff>
<aff id="aff2-0013164411406533"><label>2</label>Washington State University, Pullman, WA, USA</aff>
<author-notes>
<corresp id="corresp1-0013164411406533">W. Holmes Finch, Department of Educational Psychology, TC 521, Ball State University, Muncie, IN 47306, USA. Email: <email>whfinch@bsu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2012</year>
</pub-date>
<volume>72</volume>
<issue>1</issue>
<fpage>68</fpage>
<lpage>77</lpage>
<permissions>
<copyright-statement>© 2012 SAGE Publications</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Effect size use has been increasing in the past decade in many research areas. Confidence intervals associated with effect sizes are encouraged to be reported. Prior work has investigated the performance of confidence interval estimation with Cohen’s <italic>d</italic>. This study extends this line of work to the analysis of variance case with more than two groups. Confidence interval estimation for the omega-squared (ω<sup>2</sup>) effect size measure was evaluated under a variety of simulated conditions with three methods where the primary interest was in the comparative performance of the three confidence interval calculation methods (i.e., parametric, percentile bootstrap, and bootstrap bias-corrected and accelerated confidence interval [BCA]) across a variety of real-life data situations. Results suggest that sample size and magnitude of the effect influence coverage rates and interval width. The percentile bootstrap method produced the widest intervals and had higher coverage rates in the smaller effect size conditions compared with the parametric and BCA approaches.</p>
</abstract>
<kwd-group>
<kwd>effect size</kwd>
<kwd>ANOVA</kwd>
<kwd>confidence intervals</kwd>
<kwd>parametric</kwd>
<kwd>bootstrap</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Effect size use is widespread in the social sciences as researchers recognize their effectiveness in communicating information regarding the magnitude of an effect beyond statistical significance. Moreover, effect sizes are one method to overcome some of the limitations of statistical tests (<xref ref-type="bibr" rid="bibr5-0013164411406533">Kline, 2004</xref>). <xref ref-type="bibr" rid="bibr10-0013164411406533">Thompson (2006)</xref> defined an effect size as a measure of “the extent to which sample statistics diverge from the null hypothesis” (p. 172). With regard to comparison of means using analytic tools such as the <italic>t</italic> test or analysis of variance (ANOVA), effect sizes can be expressed either as a measure of standardized mean differences, such as Cohen’s <italic>d</italic> and <italic>f</italic><sup>2</sup>, or as a proportion of variance explained, such as eta-squared (η<sup>2</sup>) and omega-squared (ω<sup>2</sup>). Indeed, many educational and psychological journals require authors to report an effect size measure associated with the statistical test (<xref ref-type="bibr" rid="bibr6-0013164411406533">Olejnik &amp; Algina, 2003</xref>). Beyond being reported in journals, effect sizes also appear in the legal realm, for example, in court cases concerning hiring practices (<xref ref-type="bibr" rid="bibr2-0013164411406533">Grissom &amp; Kim, 2005</xref>), highlighting the importance of accurate effect estimates and interpretation. Although effect size measures do not themselves equal practical significance, they do provide assistance in judging practical significance, which in part is responsible for the increased frequency of their use.</p>
<p>The American Psychological Association (APA) Board of Scientific Affairs Task Force on Statistical Inference stated that effect size estimates should be reported in conjunction with the results of a significance test and encouraged reporting confidence intervals for parameters whenever possible, including specifically those for effect sizes, which has been echoed elsewhere in the literature (e.g., <xref ref-type="bibr" rid="bibr7-0013164411406533">Smithson, 2001</xref>; <xref ref-type="bibr" rid="bibr9-0013164411406533">Steiger &amp; Fouladi, 1997</xref>).</p>
<p>The purpose of the current simulation study was to compare the performance of three methods (i.e., parametric, percentile bootstrap, and bootstrap bias-corrected and accelerated confidence interval [BCA]) for calculating confidence intervals for ω<sup>2</sup>, which is the preferred effect size estimate for ANOVA (<xref ref-type="bibr" rid="bibr4-0013164411406533">Kirk, 1995</xref>; <xref ref-type="bibr" rid="bibr10-0013164411406533">Thompson, 2006</xref>). Prior work (<xref ref-type="bibr" rid="bibr1-0013164411406533">Algina, Keselman, &amp; Penfield, 2006</xref>; <xref ref-type="bibr" rid="bibr3-0013164411406533">Kelley, 2005</xref>) on these three methods has focused on the two groups case (Cohen’s <italic>d</italic>), but not on more complex ANOVA models, including factorial designs. For technical details on these methods, see <xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al. (2006)</xref> and <xref ref-type="bibr" rid="bibr3-0013164411406533">Kelley (2005)</xref>. Prior results showed superior coverage for Cohen’s <italic>d</italic> by the bootstrap methods in some instances. There has been little comparative simulation work conducted to assess the performance of confidence intervals for ω<sup>2</sup>, either with the parametric or bootstrap approaches. Given the importance of ω<sup>2</sup> in the reporting of ANOVA results, our study compared these methods for more than two groups, and with a factorial ANOVA.</p>
<sec id="section1-0013164411406533" sec-type="methods">
<title>Methods</title>
<p>The Monte Carlo simulation methodology (1,000 replications) was conducted across the following manipulated conditions, which are similar to those employed in <xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al. (2006)</xref> and <xref ref-type="bibr" rid="bibr3-0013164411406533">Kelley (2005)</xref>, with appropriate extensions for ANOVA. The manipulated factors were the aforementioned methods for calculating confidence intervals, population effect size (0 = no effect, 0.01 = small, 0.059 = medium, and 0.138 = large), distribution of dependent variable (standard and seven nonnormal conditions; see <xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al., 2006</xref>), group variance homogeneity (differing by a factor of 0, 0.5, 1.0, and 1.5), number of groups (three, four, and five), number of independent variables (one variable only, two variables with the same effect size but no interaction, or two variables with the same effect size and a significant interaction), and sample size (5, 10, 20, 50, and 100 per group). The outcome variables included coverage rates for ω<sup>2</sup>, effect size estimation, and width of the intervals.</p>
</sec>
<sec id="section2-0013164411406533" sec-type="results">
<title>Results</title>
<p>Repeated measures ANOVA was used to identify significant manipulated factors in the simulation, which are discussed below.</p>
<sec id="section3-0013164411406533">
<title>Coverage Rates</title>
<p>Coverage rates for all methods were frequently below the 0.95 nominal value (see <xref ref-type="fig" rid="fig1-0013164411406533">Figure 1</xref>). When the data were simulated from a normal distribution (Distribution 1 in <xref ref-type="fig" rid="fig1-0013164411406533">Figure 1</xref>), the coverage rates for the parametric approach were somewhat higher than those of both the percentile and BCA bootstrapping methods. Although a similar pattern to that for the normal distribution was apparent for most of the nonnormal conditions, the actual coverage rates varied greatly across distributions and within distribution across effect size values.</p>
<fig id="fig1-0013164411406533" position="float">
<label>Figure 1.</label>
<caption>
<p>Coverage rates by distribution of dependent variable, effect size magnitude, and sample size</p>
<p>PARM = parametric; PERC = percentile bootstrap; BCA = bootstrap bias-corrected and accelerated.</p>
</caption>
<graphic xlink:href="10.1177_0013164411406533-fig1.tif"/>
</fig>
<p>When the data were normally distributed, the coverage rates for the parametric method were largely unchanged across sample sizes (see <xref ref-type="fig" rid="fig1-0013164411406533">Figure 1</xref>). In contrast, for most of the nonnormal conditions, coverage rates were generally higher for larger samples. The influence of distribution and sample size on both bootstrap methods was complex and somewhat different compared with the parametric method. One consistent pattern across the nonnormal distributions was lower bootstrap coverage rates for smaller sample size conditions. In addition, for most of the distributions, the coverage rates were higher for the percentile method compared with the BCA method, and both generally had lower coverage rates than the parametric method for the nonnormal distributions regardless of sample size. This latter result was particularly notable for the most extreme kurtosis conditions, except when the population effect size was 0, in which case coverage rates were at or very near the nominal level. Coverage rates for all three confidence intervals were lowest when there was a second variable present in the analysis and that variable interacted with the target (<xref ref-type="table" rid="table1-0013164411406533">Table 1</xref>). Otherwise, coverage rates were comparable across conditions. In addition, the impact of the interaction on the coverage rates was greater for the two bootstrap approaches than for the parametric method.</p>
<table-wrap id="table1-0013164411406533" position="float">
<label>Table 1.</label>
<caption>
<p>Coverage and Confidence Interval Width Values by Number of Independent Variables</p>
</caption>
<graphic alternate-form-of="table1-0013164411406533" xlink:href="10.1177_0013164411406533-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="3">Coverage Rates</th>
<th align="center" colspan="3">Mean CI Width</th>
</tr>
<tr>
<th align="left">Variables</th>
<th align="center">ω<sup>2</sup> Parm</th>
<th align="center">ω<sup>2</sup> Perc</th>
<th align="center">ω<sup>2</sup> BCA</th>
<th align="center">Parm</th>
<th align="center">Perc</th>
<th align="center">BCA</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.86</td>
<td>0.91</td>
<td>0.89</td>
<td>0.21</td>
<td>0.31</td>
<td>0.26</td>
</tr>
<tr>
<td>2, main effects only</td>
<td>0.86</td>
<td>0.92</td>
<td>0.86</td>
<td>0.22</td>
<td>0.34</td>
<td>0.26</td>
</tr>
<tr>
<td>2, with interaction</td>
<td>0.81</td>
<td>0.72</td>
<td>0.71</td>
<td>0.16</td>
<td>0.19</td>
<td>0.17</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0013164411406533">
<p>CI = confidence interval; Parm = parametric; Perc = percentile bootstrap; BCA = bootstrap bias-corrected and accelerated.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section4-0013164411406533">
<title>Effect Size Estimation</title>
<p>There are two primary candidate causes for the variation in coverage rates reported above: (a) accuracy of effect size estimation and (b) width of the intervals. In general, when the data were normally distributed (1 in <xref ref-type="fig" rid="fig2-0013164411406533">Figure 2</xref>), bias was low across effect sizes, though slightly higher for small and medium effect sizes (2 and 3 in <xref ref-type="fig" rid="fig2-0013164411406533">Figure 2</xref>) than for no or a large effect. This low bias was evident in nonnormal conditions except for Distributions 6 and 7 where there was somewhat greater positive bias for the small (3), medium (2), and large (1) effect sizes, with increasing bias associated with a greater effect. Conversely, for Distribution 8 (greatest kurtosis), there was a marked negative bias for the large effect size.</p>
<fig id="fig2-0013164411406533" position="float">
<label>Figure 2.</label>
<caption>
<p>Bias in estimate of ω<sup>2</sup> by effect, distribution, and sample size</p>
</caption>
<graphic xlink:href="10.1177_0013164411406533-fig2.tif"/>
</fig>
<p>Across distributions, smaller sample sizes resulted in greater bias in estimates of ω<sup>2</sup> (<xref ref-type="fig" rid="fig2-0013164411406533">Figure 2</xref>), though there was not a consistent pattern in its direction, with overestimation in some instances and underestimation in others. For distributions with greater kurtosis (4, 5, 6, 7, and 8), this relationship between sample size and bias was most notable, with positive bias in evidence for most of the distributions except for Distribution 8, where the degree of negative bias increased with increasing sample size. Interpreting these results in light of those presented earlier for the coverage rates, it appears that part of the reason for poor coverage in some of the nonnormal conditions was poor estimation of ω<sup>2</sup> itself.</p>
<p>The bias in ω<sup>2</sup> estimates by the number of significant independent variables and interactions by effect size appear in <xref ref-type="table" rid="table2-0013164411406533">Table 2</xref>. For the medium effect size, the estimate of ω<sup>2</sup> was biased upward when a significant interaction was present and biased downward in the presence of another main effect but no interaction. No other conditions displayed estimation bias greater than 0.01. Because the variance inequality and number of groups conditions were not significantly related to confidence interval coverage rates, the estimates of ω<sup>2</sup> under these conditions are not discussed here.</p>
<table-wrap id="table2-0013164411406533" position="float">
<label>Table 2.</label>
<caption>
<p>ω<sup>2</sup> Estimation Bias by Number of Independent Variables and Effect Size</p>
</caption>
<graphic alternate-form-of="table2-0013164411406533" xlink:href="10.1177_0013164411406533-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Variables</th>
<th align="center">ω<sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="2">Large effect</td>
</tr>
<tr>
<td> 1</td>
<td>−0.006</td>
</tr>
<tr>
<td> 2, main effects only</td>
<td>−0.008</td>
</tr>
<tr>
<td> 2, with interaction</td>
<td>−0.005</td>
</tr>
<tr>
<td colspan="2">Medium effect</td>
</tr>
<tr>
<td> 1</td>
<td>−0.003</td>
</tr>
<tr>
<td> 2, main effects only</td>
<td>−0.010</td>
</tr>
<tr>
<td> 2, with interaction</td>
<td>0.029</td>
</tr>
<tr>
<td colspan="2">Small effect</td>
</tr>
<tr>
<td> 1</td>
<td>0.008</td>
</tr>
<tr>
<td> 2, main effects only</td>
<td>−0.003</td>
</tr>
<tr>
<td> 2, with interaction</td>
<td>0.009</td>
</tr>
<tr>
<td colspan="2">No effect</td>
</tr>
<tr>
<td> 1</td>
<td>0.001</td>
</tr>
<tr>
<td> 2, main effects only</td>
<td>0.000</td>
</tr>
<tr>
<td> 2, with interaction</td>
<td>0.000</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section5-0013164411406533">
<title>Confidence Interval Width</title>
<p>As well as bias in the estimate of ω<sup>2</sup>, coverage rates also can be influenced by the width of the intervals themselves. Because width results were highly similar across simulated effect sizes, only the no effect condition was examined here, with results appearing in <xref ref-type="table" rid="table3-0013164411406533">Table 3</xref>. The widths for each method generally decreased as sample size increased across distributions. The percentile bootstrap confidence interval was consistently the widest across nearly all the conditions for <italic>N</italic> of 50 or fewer, whereas the BCA displayed the next widest interval. In contrast, when the sample size was 100, there was essentially no difference in interval width for the three methods. In terms of distributions, those with higher kurtosis demonstrated slightly narrower confidence intervals for <italic>N</italic> of 20 or fewer but had comparable width for larger sample sizes. The confidence interval width by the number of terms in the model appears in <xref ref-type="table" rid="table1-0013164411406533">Table 1</xref>. These results show that the narrowest confidence intervals occurred when there were two independent variables and a significant interaction between them. It is interesting to note that it was under this condition that the coverage rates for the three methods were at their lowest.</p>
<table-wrap id="table3-0013164411406533" position="float">
<label>Table 3.</label>
<caption>
<p>CI Width by Distribution and Sample Size for the No Effect Size Condition</p>
</caption>
<graphic alternate-form-of="table3-0013164411406533" xlink:href="10.1177_0013164411406533-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Parm</th>
<th align="center">Perc</th>
<th align="center">BCA</th>
<th align="center">Parm</th>
<th align="center">Perc</th>
<th align="center">BCA</th>
</tr>
<tr>
<th align="left"><italic>N</italic></th>
<th align="center" colspan="3">CI Width: Normal</th>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 1.75, <italic>K</italic> = 3.75</th>
</tr>
</thead>
<tbody>
<tr>
<td>5</td>
<td>0.34</td>
<td>0.65</td>
<td>0.49</td>
<td>0.32</td>
<td>0.63</td>
<td>0.44</td>
</tr>
<tr>
<td>10</td>
<td>0.20</td>
<td>0.34</td>
<td>0.25</td>
<td>0.19</td>
<td>0.32</td>
<td>0.23</td>
</tr>
<tr>
<td>20</td>
<td>0.10</td>
<td>0.17</td>
<td>0.12</td>
<td>0.09</td>
<td>0.15</td>
<td>0.10</td>
</tr>
<tr>
<td>50</td>
<td>0.04</td>
<td>0.07</td>
<td>0.05</td>
<td>0.04</td>
<td>0.06</td>
<td>0.05</td>
</tr>
<tr>
<td>100</td>
<td>0.02</td>
<td>0.04</td>
<td>0.03</td>
<td>0.02</td>
<td>0.03</td>
<td>0.02</td>
</tr>
<tr>
<th/>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 1.00, <italic>K</italic> = 1.50</th>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 0.25, <italic>K</italic> = −0.75</th>
</tr>
<tr>
<td>5</td>
<td>0.36</td>
<td>0.66</td>
<td>0.49</td>
<td>0.34</td>
<td>0.69</td>
<td>0.47</td>
</tr>
<tr>
<td>10</td>
<td>0.22</td>
<td>0.33</td>
<td>0.26</td>
<td>0.18</td>
<td>0.33</td>
<td>0.25</td>
</tr>
<tr>
<td>20</td>
<td>0.11</td>
<td>0.17</td>
<td>0.13</td>
<td>0.12</td>
<td>0.17</td>
<td>0.14</td>
</tr>
<tr>
<td>50</td>
<td>0.05</td>
<td>0.07</td>
<td>0.06</td>
<td>0.04</td>
<td>0.07</td>
<td>0.05</td>
</tr>
<tr>
<td>100</td>
<td>0.02</td>
<td>0.03</td>
<td>0.02</td>
<td>0.02</td>
<td>0.04</td>
<td>0.03</td>
</tr>
<tr>
<th/>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 0, <italic>K</italic> = 6</th>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 2, <italic>K</italic> = 6</th>
</tr>
<tr>
<td>5</td>
<td>0.38</td>
<td>0.64</td>
<td>0.51</td>
<td>0.33</td>
<td>0.62</td>
<td>0.47</td>
</tr>
<tr>
<td>10</td>
<td>0.18</td>
<td>0.33</td>
<td>0.23</td>
<td>0.20</td>
<td>0.32</td>
<td>0.25</td>
</tr>
<tr>
<td>20</td>
<td>0.10</td>
<td>0.16</td>
<td>0.11</td>
<td>0.11</td>
<td>0.16</td>
<td>0.12</td>
</tr>
<tr>
<td>50</td>
<td>0.04</td>
<td>0.06</td>
<td>0.04</td>
<td>0.04</td>
<td>0.06</td>
<td>0.05</td>
</tr>
<tr>
<td>100</td>
<td>0.02</td>
<td>0.03</td>
<td>0.03</td>
<td>0.02</td>
<td>0.04</td>
<td>0.03</td>
</tr>
<tr>
<th/>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 0, <italic>K</italic> = 154.84</th>
<th align="center" colspan="3">CI Width: <italic>S</italic> = 0, <italic>K</italic> = 4673.8</th>
</tr>
<tr>
<td>5</td>
<td>0.31</td>
<td>0.61</td>
<td>0.44</td>
<td>0.35</td>
<td>0.64</td>
<td>0.49</td>
</tr>
<tr>
<td>10</td>
<td>0.21</td>
<td>0.29</td>
<td>0.23</td>
<td>0.25</td>
<td>0.35</td>
<td>0.30</td>
</tr>
<tr>
<td>20</td>
<td>0.12</td>
<td>0.14</td>
<td>0.11</td>
<td>0.12</td>
<td>0.19</td>
<td>0.14</td>
</tr>
<tr>
<td>50</td>
<td>0.04</td>
<td>0.06</td>
<td>0.04</td>
<td>0.04</td>
<td>0.07</td>
<td>0.05</td>
</tr>
<tr>
<td>100</td>
<td>0.02</td>
<td>0.03</td>
<td>0.02</td>
<td>0.02</td>
<td>0.04</td>
<td>0.03</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0013164411406533">
<p>CI = confidence interval; Parm = parametric; Perc = percentile bootstrap; BCA = bootstrap bias-corrected and accelerated.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section6-0013164411406533" sec-type="discussion">
<title>Discussion</title>
<p>Inclusion of effect sizes is becoming standard practice when reporting statistical significant tests in the social sciences. The suggestion has been made that confidence intervals for effect size values may be more useful than the simple point estimates (<xref ref-type="bibr" rid="bibr8-0013164411406533">Steiger, 2004</xref>). Although comparisons of the performance of methods for calculating confidence intervals for Cohen’s <italic>d</italic> for the simple case of mean comparisons for two groups has been conducted (e.g., <xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al., 2006</xref>; <xref ref-type="bibr" rid="bibr3-0013164411406533">Kelley, 2005</xref>), empirical evaluation of the performance of methods for calculating intervals for ω<sup>2</sup> has not been examined. This study took this next step in assessing these methods for confidence interval calculation for ω<sup>2</sup>.
</p>
<p>A number of the results of this study are similar to those found in previous examinations of confidence intervals for Cohen’s <italic>d</italic>. For example, the coverage rate of the parametric confidence interval method was degraded in the presence of nonnormal data (<xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al., 2006</xref>; <xref ref-type="bibr" rid="bibr3-0013164411406533">Kelley, 2005</xref>). However, an unexpected outcome in the current study, given the results in <xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al. (2006)</xref>, is that the BCA approach for ω<sup>2</sup> was generally not the best performer for nonnormal data. Unlike in the earlier study, for several of these nonnormal conditions, the parametric approach produced comparable coverage to the bootstrap alternatives, whereas for others the percentile bootstrap had clearly higher coverage rates. In relatively few instances did the BCA technique provide the best coverage. On the other hand, the BCA intervals were generally narrower compared with the percentile method, while providing better coverage than the parametric method in several instances. Therefore, this combination of typically having the second best coverage rates and the second best interval width in certain nonnormal cases may make the BCA an attractive alternative for researchers interested in calculating confidence intervals for ω<sup>2</sup>, despite the fact that it was rarely the best performer. Another unexpected result was that the coverage rates for all three methods were influenced by the inclusion of a second significant variable in a factorial ANOVA model. Thus, researchers need to be aware that the calculation of confidence intervals for one variable is not independent of other variables included in such a design. Finally, it appears that when data are not normally distributed, none of the three confidence intervals will provide coverage rates at the nominal level unless the sample size is 50 or higher, and the level of kurtosis is fairly low. This result is somewhat different from that reported in <xref ref-type="bibr" rid="bibr1-0013164411406533">Algina et al. (2006)</xref> and <xref ref-type="bibr" rid="bibr3-0013164411406533">Kelley (2005)</xref>, in which the BCA approach was particularly effective in the presence of nonnormal data for the two groups problem. This outcome would speak to the need for researchers to be aware of how such distributions may differentially affect confidence interval calculation for more complex models.</p>
<sec id="section7-0013164411406533">
<title>Study Limitations and Directions for Future Study</title>
<p>We note that this study and the resultant recommendations are limited. For instance, we focused on balanced designs and fixed effects in the models we selected to simulate. Methods for examining standardized mean differences in more complex factorial designs are not as developed or well studied in comparison with the two groups and one-way design cases. However, this work should begin to move research forward for those more complex cases by providing some understanding of the accuracy of these three estimation methods under a variety of well-understood conditions for relatively simple models. Such information can provide the needed foundation to continue to study more complicated scenarios with an eye toward increasing the accuracy of effect size estimates. Such continued work, over time, should assist in improving tools we use to study group differences and accurately capture the magnitude of these differences.</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0013164411406533">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Algina</surname><given-names>J.</given-names></name>
<name><surname>Keselman</surname><given-names>H. J.</given-names></name>
<name><surname>Penfield</surname><given-names>R. D.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Confidence interval coverage for Cohen’s effect size statistic</article-title>. <source>Educational and Psychological Measurement</source>, <volume>66</volume>, <fpage>945</fpage>-<lpage>960</lpage>.</citation>
</ref>
<ref id="bibr2-0013164411406533">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Grissom</surname><given-names>R. J.</given-names></name>
<name><surname>Kim</surname><given-names>J. J.</given-names></name>
</person-group> (<year>2005</year>). <source>Effect sizes for research: A broad practical approach</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr3-0013164411406533">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kelley</surname><given-names>K.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The effects of nonnormal distributions on confidence intervals around the standardized mean difference: Bootstrap and parametric confidence intervals</article-title>. <source>Educational and Psychological Measurement</source>, <volume>65</volume>, <fpage>51</fpage>-<lpage>69</lpage>.</citation>
</ref>
<ref id="bibr4-0013164411406533">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kirk</surname><given-names>R. E.</given-names></name>
</person-group> (<year>1995</year>). <source>Experimental design</source>. <publisher-loc>Pacific Grove, CA</publisher-loc>: <publisher-name>Brooks/Cole</publisher-name>.</citation>
</ref>
<ref id="bibr5-0013164411406533">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kline</surname><given-names>R. B.</given-names></name>
</person-group> (<year>2004</year>). <source>Beyond significance testing: Reforming data analysis methods in behavioral Research</source>. <publisher-loc>American Psychological Association</publisher-loc>: <publisher-name>Washington, DC</publisher-name>.</citation>
</ref>
<ref id="bibr6-0013164411406533">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Olejnik</surname><given-names>S.</given-names></name>
<name><surname>Algina</surname><given-names>J.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Generalized eta and omega squared statistics: Measures of effect size for some common research designs</article-title>. <source>Psychological Methods</source>, <volume>8</volume>, <fpage>334</fpage>-<lpage>337</lpage>.</citation>
</ref>
<ref id="bibr7-0013164411406533">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Smithson</surname><given-names>M.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Correct confidence intervals for various regression effect sizes and parameters: The importance of noncentral distributions in computing intervals</article-title>. <source>Educational and Psychological Measurement</source>, <volume>61</volume>, <fpage>605</fpage>-<lpage>632</lpage>.</citation>
</ref>
<ref id="bibr8-0013164411406533">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Steiger</surname><given-names>J. H.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Beyond the</article-title> <source>F</source> <publisher-loc>test</publisher-loc>: <publisher-name>Effect size confidence intervals and tests of close fit in the analysis of variance and contrast analysis</publisher-name>. <source>Psychological Methods</source>, <volume>9</volume>, <fpage>164</fpage>-<lpage>182</lpage>.</citation>
</ref>
<ref id="bibr9-0013164411406533">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Steiger</surname><given-names>J. H.</given-names></name>
<name><surname>Fouladi</surname><given-names>R. T.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Noncentrality interval estimation and the evaluation of statistical models</article-title>. In <person-group person-group-type="editor">
<name><surname>Harlow</surname><given-names>L. L.</given-names></name>
<name><surname>Mulaik</surname><given-names>S. A.</given-names></name>
<name><surname>Steiger</surname><given-names>J. H.</given-names></name>
</person-group> (Eds.), <source>What if there were no significance tests?</source>(pp. <fpage>221</fpage>-<lpage>257</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr10-0013164411406533">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>B.</given-names></name>
</person-group> (<year>2006</year>). <source>Foundations of behavioral statistics: An insight-based approach</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>