<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">HPC</journal-id>
<journal-id journal-id-type="hwp">sphpc</journal-id>
<journal-title>The International Journal of High Performance Computing Applications</journal-title>
<issn pub-type="ppub">1094-3420</issn>
<issn pub-type="epub">1741-2846</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1094342013488238</article-id>
<article-id pub-id-type="publisher-id">10.1177_1094342013488238</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Special Issue Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Post-failure recovery of MPI communication capability</article-title>
<subtitle>Design and rationale</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bland</surname>
<given-names>Wesley</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488238"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bouteiller</surname>
<given-names>Aurelien</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488238"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Herault</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488238"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Bosilca</surname>
<given-names>George</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488238"/>
<xref ref-type="corresp" rid="corresp1-1094342013488238"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dongarra</surname>
<given-names>Jack</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488238"/>
</contrib>
<aff id="aff1-1094342013488238">Innovative Computing Laboratory, University of Tennessee, Knoxville, TN, USA</aff>
<bio>
<title>Author biographies</title>
<p>
<italic>Wesley Bland</italic> is a Graduate Research Assistant in the Innovative Computing Laboratory at the University of Tennessee, Knoxville. He will be defending his thesis on methods to add fault tolerance to high-performance computing middle-wares, specifically MPI. He received his B.S. degree at Tennessee Technological University in Cookeville, TN in 2007 and his M.S. degree from the University of Tennessee, Knoxville in 2009. Upon graduation, he will begin a Postdoctoral Appointment at Argonne National Laboratory in Chicago, IL.</p>
<p>
<italic>Aurelien Bouteiller</italic> is currently a researcher at the Innovative Computing Laboratory, University of Tennessee. He received is Ph.D. from University of Paris in 2006 on the subject of rollback recovery fault tolerance. His research is focused on improving performance and reliability of distributed memory systems. Toward that goal, he investigated automatic (message-logging-based) checkpointing approaches in MPI, algorithm-based fault tolerance approaches and their runtime support, mechanisms to improve communication speed and balance within nodes of many-core clusters, and employing emerging data flow programming models to negate the raise of jitter on large-scale systems. These works resulted in over thirty publications in international conferences and journals and three distinguished paper awards from IPDPS and EuroPar. He his also a contributor to Open MPI and one of the leading designer of MPI Forum efforts toward fault-tolerance interfaces.</p>
<p>
<italic>Thomas Herault</italic> is a Research Scientist in the Innovative Computing Laboratory at the University of Tennessee, Knoxville. His research focuses on fault-tolerance in high-performance computing, middleware for communication and data-flow environment in distributed memory systems. He received his B.S. and M.S. degrees in computer science from the Paris-Sud University at Orsay, France. He defended his PhD in computer science on failure detection and mending in self-stabilizing systems at the Paris-Sud University, Orsay, France, in 2003, then joined the Grand-Large INRIA team and the Parall team of the Informatics Research Laboratory of the University of Orsay, France, where he held the position of assistant professor for 5 years. In 2008, he then joined the Innovative Computing Laboratory of the University of Tennessee, Knoxville.</p>
<p>
<italic>George Bosilca</italic> holds an Assistant Research Professor at the University of Tennessee. He received his Ph.D. from University of Paris in 2003 in the domain of Parallel Architectures and programming models. He joined the University of Tennessee in 2003 as a Post-doctoral Researcher. He specialized in several aspects of high-performance computing, from low-level drivers up to high-level programming paradigms. He is actively involved in several projects preparing the software stack for the challenges of tomorrow’s hardware requirements, in terms of heterogeneity, degree of parallelism, scalability and resilience. He remains an active contributor and lead architect of several software packages, such as FT-MPI, Open MPI, and PaRSEC.</p>
<p>
<italic>Jack Dongarra</italic> holds an appointment at the University of Tennessee, Oak Ridge National Laboratory, and the University of Manchester. He specializes in numerical algorithms in linear algebra, parallel computing, use of advanced-computer architectures, programming methodology, and tools for parallel computers. He was awarded the IEEE Sid Fernbach Award in 2004 for his contributions in the application of high-performance computers using innovative approaches; in 2008 he was the recipient of the first IEEE Medal of Excellence in Scalable Computing; in 2010 he was the first recipient of the SIAM Special Interest Group on Supercomputing’s award for Career Achievement; and in 2011 he was the recipient of the IEEE IPDPS 2011 Charles Babbage Award. He is a Fellow of the AAAS, ACM, IEEE, and SIAM and a member of the National Academy of Engineering.</p>
</bio>
</contrib-group>
<author-notes>
<corresp id="corresp1-1094342013488238">George Bosilca, Innovative Computing Laboratory, University of Tennessee, 1122 Volunteer Boulevard, Knoxville, TN 37996-3450, USA. Email: <email>bosilca@icl.utk.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2013</year>
</pub-date>
<volume>27</volume>
<issue>3</issue>
<issue-title>Special Issue section on CCDSC 2012 Workshop</issue-title>
<fpage>244</fpage>
<lpage>254</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>As supercomputers are entering an era of massive parallelism where the frequency of faults is increasing, the MPI Standard remains distressingly vague on the consequence of failures on MPI communications. Advanced fault-tolerance techniques have the potential to prevent full-scale application restart and therefore lower the cost incurred for each failure, but they demand from MPI the capability to detect failures and resume communications afterward. In this paper, we present a set of extensions to MPI that allow communication capabilities to be restored, while maintaining the extreme level of performance to which MPI users have become accustomed. The motivation behind the design choices are weighted against alternatives, a task that requires simultaneously considering MPI from the viewpoint of both the user and the implementor. The usability of the interfaces for expressing advanced recovery techniques is then discussed, including the difficult issue of enabling separate software layers to coordinate their recovery.</p>
</abstract>
<kwd-group>
<kwd>Fault tolerance</kwd>
<kwd>message passing interface</kwd>
<kwd>user-level failure mitigation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1094342013488238">
<title>1. Introduction</title>
<p>Innovation in science and engineering strongly depends on the pervasive use of computer-assisted design and simulation, thereby demanding breakthrough computing capabilities. In the last decade, supercomputers have relied on increasing the number of processors to deliver unrivaled performance. The rationale behind this development is, essentially, driven by the lower operational cost of designs featuring a large number of low-power processors (<xref ref-type="bibr" rid="bibr6-1094342013488238">Bright et al., 2005</xref>). According to current projections in processor, memory and interconnect technologies, and ultimately the thermal limitations of semiconductors, this trend is expected to continue into the foreseeable future (<xref ref-type="bibr" rid="bibr13-1094342013488238">Dongarra et al., 2011</xref>). An unfortunate consequence of harnessing such a large amount of individual components is the resulting aggregate unreliability. As system size increases exponentially over the years, the improvements in component manufacture are outpaced, and long-running applications spanning the entire system experience increasing disruption from failures (<xref ref-type="bibr" rid="bibr25-1094342013488238">Schroeder and Gibson, 2007</xref>; <xref ref-type="bibr" rid="bibr8-1094342013488238">Cappello, 2009</xref>).</p>
<p>Message passing, and in particular the Message Passing Interface (MPI) (<xref ref-type="bibr" rid="bibr28-1094342013488238">The MPI Forum, 2012</xref>), is the prevailing approach for developing parallel applications on massive-scale high-performance computing (HPC) systems. Historically, many MPI applications have relied on rollback recovery to recover from failures, a strategy that can be achieved without support from the MPI library. However, recent studies outline that, in light of the expected mean time between failures (MTBF) of exascale HPC systems and beyond (<xref ref-type="bibr" rid="bibr13-1094342013488238">Dongarra et al., 2011</xref>), checkpoint–restart-based rollback recovery could underperform to the point where replication would become a compelling option (<xref ref-type="bibr" rid="bibr19-1094342013488238">Ferreira et al., 2011</xref>). The literature is rich in alternative recovery strategies permitting better performance in a volatile, high-failure-rate environment. The variety of techniques employed is very wide, and notably include checkpoint–restart variations based on uncoordinated rollback recovery (<xref ref-type="bibr" rid="bibr5-1094342013488238">Bouteiller et al., 2011</xref>), replication (<xref ref-type="bibr" rid="bibr19-1094342013488238">Ferreira et al., 2011</xref>), algorithm-based fault tolerance where mathematical properties are leveraged to avoid checkpoints (<xref ref-type="bibr" rid="bibr12-1094342013488238">Davies et al., 2011</xref>; <xref ref-type="bibr" rid="bibr14-1094342013488238">Du et al., 2012</xref>), etc. A common feature found in most of these advanced failure recovery strategies is that, unlike historical rollback recovery where the entire application is interrupted and later restarted from a checkpoint, the application is expected to continue operating despite processor failures, thereby reducing the incurred I/O, downtime and computation loss overheads. However, the MPI Standard does not define a precise behavior for MPI implementations when disrupted by failures. As a consequence, the deployment of advanced fault-tolerance techniques is challenging, taking a strain on software development productivity in many applied science communities, and fault tolerant applications suffer from the lack of portability of <italic>ad hoc</italic> solutions.</p>
<p>Several issues prevented the standardization of recovery behavior by the MPI Standard. Most prominently, the diversity of the available recovery strategies is, in itself, problematic: there does not appear to be a single best practice, but a complex ecosystem of techniques that apply best to their niche of applications. The second issue is that, without a careful, conservative design, fault-tolerance additions generally take an excruciating toll on bare communication performance. Many MPI implementors, system vendors and users are unwilling to suffer this overhead, an attitude further reinforced by the aforementioned diversity of fault tolerance techniques which results in costly additions being best suited for somebody else’s problem.</p>
<p>In this paper, we describe a set of extended MPI routines and definitions called user-level failure mitigation ( ULFM ), that permit MPI applications to continue communicating across failures, while avoiding the two issues described above. The main contributions of this paper are (1) to identify a minimal set of generic requirements from MPI that enable continued operations across failures; (2) to propose a set of semantics that limit the complexity for MPI implementors, a feature that, beyond comfort, is paramount for maintaining extreme communication performance; (3) expose the rationale for the design choices and discuss the consequences of alternative approaches; (4) illustrate how high-level fault-tolerance techniques can benefit from the proposed constructs; (5) discuss how these semantics and constructs can be effectively used in production codes that intermix multiple layers of libraries from distinct providers.</p>
<p>The rest of this paper is organized as follows: Section 2 provides a background survey of fault-tolerance techniques and identifies common requirements, Section 3 gives an overview of the goals of providing fault tolerance in the MPI Standard, Section 4 describes the new constructs introduced by ULFM, Section 5 explores some of the rationale behind the ULFM design, Section 6 gives an overview of some possible compositions of fault-tolerance techniques on top of ULFM , Section 7 describes some of the previous work with integrating fault tolerance within MPI, before we conclude and look beyond the scope of MPI in Section 8.</p>
</sec>
<sec id="section2-1094342013488238">
<title>2. Background</title>
<p>In this work, we consider the effect of fail-stop failures (that is, when a processor crashes and stops responding completely). Network failures are equally important to tolerate, but are generally handled at the link protocol level, thereby relieving MPI programs from experiencing their effect. Silent errors that damage the dataset of the application (memory corruption) without hindering the capacity to deliver messages (or resulting in a crash), are the sole responsibility of the application to correct. The survey by <xref ref-type="bibr" rid="bibr8-1094342013488238">Cappello (2009</xref>) provides an extensive summary of fail-stop recovery techniques available in the literature. Since the focus of this work is to design an extension to the MPI runtime to enable effective deployment of advanced fault tolerance techniques, it is critical to understand the specificities, issues, common features and opportunities offered by this wide range of recovery techniques.</p>
<sec id="section3-1094342013488238">
<title>2.1. Checkpoint–restart (with coordinated rollback)</title>
<p>Rollback recovery is based on the intuitive procedure of restarting the failed application each time it is impacted by a failure. In order to diminish the amount of lost computation, the progress of the application is periodically saved by taking checkpoints. Should a failure happen, instead of restarting the application from the beginning it will be restarted from the last saved state, a more advanced state toward the application completion. In a parallel application, the matter is complicated by the exchange of messages: if the message initiation at the sender and its delivery at the receiver cross the line formed by the state of processes when reloaded from a checkpoint, the state of the application may be inconsistent, and the recovery impossible. The traditional approach is to construct a set of <italic>coordinated checkpoints</italic> that eliminates such messages completely, so that the checkpoint set is consistent (<xref ref-type="bibr" rid="bibr11-1094342013488238">Chandy and Lamport, 1985</xref>). However, in such a case, the consistent recovery point is guaranteed only if the entire application is restarted from the checkpoint set.</p>
<p>Many MPI libraries provide coordinated checkpointing automatically, without application knowledge or involvement (<xref ref-type="bibr" rid="bibr7-1094342013488238">Buntinas et al., 2008</xref>; <xref ref-type="bibr" rid="bibr23-1094342013488238">Hursey et al., 2007</xref>). Because of the use of system-based checkpoint routines, these libraries have to be internally modified to remove the MPI state from the checkpoints. However, these modifications do not alter the interface presented to users and the performance hit on communication routines is usually insignificant. More generally, coordinated rollback recovery has been widely deployed by message-passing applications without any specific requirements from the MPI implementation. The program code flow is designed so that checkpoints are taken at points when no messages have been injected into MPI (hence, the network is empty and the checkpoint set consistent) (<xref ref-type="bibr" rid="bibr26-1094342013488238">Silva and Silva, 1998</xref>).</p>
</sec>
<sec id="section4-1094342013488238">
<title>2.2. Checkpoint–restart (with partial rollback)</title>
<p>In checkpoint–restart with partial rollback recovery, processes that have not been damaged by a failure are kept alive and can continue computing as long as they do not depend on a message from a failed process. To permit independent recovery of processes restarted from a checkpoint, a procedure called message logging (<xref ref-type="bibr" rid="bibr1-1094342013488238">Alvisi and Marzullo, 1995</xref>; <xref ref-type="bibr" rid="bibr16-1094342013488238">Elnozahy et al., 2002</xref>) stores supplementary information every time communications are involved. The message log is then used to direct the recovery of restarted processes toward a state that is consistent with the global state of processes that continued without restart. Recent advances in message logging (<xref ref-type="bibr" rid="bibr4-1094342013488238">Bouteiller et al., 2010</xref>; <xref ref-type="bibr" rid="bibr17-1094342013488238">Esteban Meneses and Kalé, 2010</xref>; <xref ref-type="bibr" rid="bibr21-1094342013488238">Guermouche et al., 2012</xref>; <xref ref-type="bibr" rid="bibr5-1094342013488238">Bouteiller et al., 2011</xref>) have demonstrated that this approach can deliver a compelling level of performance and may exceed the performance of coordinated rollback recovery.</p>
</sec>
<sec id="section5-1094342013488238">
<title>2.3. Replication</title>
<p>Replication (<xref ref-type="bibr" rid="bibr19-1094342013488238">Ferreira et al., 2011</xref>) is the idea that in order to provide fault tolerance for an application, rather than changing the application to incorporate fault-tolerance techniques or spend time writing checkpoints to disk and then performing full-system restarts, an application can execute multiple concurrent copies of itself simultaneously. In most variations, the replicates need to remain strongly synchronized, and messages’ delivery are effectively atomic commits to multiple targets. As long as one of the replicates is still alive, no data loss has happened and the application can continue. New clones of failed processes can be recreated on the fly to ensure continued protection from further failures. While replication has a large overhead from duplicating computation and requiring heavy synchronization on message deliveries, it has been shown to provide a higher level of efficiency than checkpoint/restart under the extreme pressure of numerous, frequent failures.</p>
</sec>
<sec id="section6-1094342013488238">
<title>2.4. Migration</title>
<p>Process migration (<xref ref-type="bibr" rid="bibr9-1094342013488238">Chakravorty et al., 2006</xref>; <xref ref-type="bibr" rid="bibr29-1094342013488238">Wang et al., 2008</xref>) is a form of fault tolerance which combines advanced, proactive failure detectors with some other form of fault tolerance, often checkpoint/restart. To reduce the increasing overhead of other forms of fault tolerance at scale, process migration detects that a failure is likely to occur at a particular process and moves it (or replicates it) to a node in the system less likely to fail. Migration requires accurate failure predictors to be useful, but when successful, it can reduce the overhead of other fault tolerance mechanisms significantly.</p>
</sec>
<sec id="section7-1094342013488238">
<title>2.5. Transactions</title>
<p>Transactional-based computation can be seen as a form of speculative progress with lightweight checkpoints. The basic idea is that the algorithm is divided into blocks of code. Each block is concluded with a construct that decides the status of all communication operations which occurred within the block, as opposed to checking the status of each communication operation as it occurs (<xref ref-type="bibr" rid="bibr27-1094342013488238">Skjellum, 2012</xref>). If the construct determines that a process failure had occurred in the preceding block, it allows the application to return to the status before the beginning of the block, giving it the opportunity to execute the block again (after replacing the failed process).</p>
</sec>
<sec id="section8-1094342013488238">
<title>2.6. Algorithm-based fault tolerance</title>
<p>Algorithm-based fault tolerance (<xref ref-type="bibr" rid="bibr12-1094342013488238">Davies et al., 2011</xref>; <xref ref-type="bibr" rid="bibr14-1094342013488238">Du et al., 2012</xref>) is a family of recovery techniques based on algorithmic properties of the application. In some naturally fault-tolerant applications, when a failure occurs, the application can simply continue while ignoring the lost processes (typical of master–slave applications). In other cases, the application uses intricate knowledge of the structure of the computation to maintain supplementary, redundant data, that is updated algorithmically and forms a recovery dataset that does not rely on checkpoints. Although generally exhibiting excellent performance and resiliency, algorithm-based fault tolerance requires that the algorithm is innately able to incorporate fault tolerance and therefore might be a less generalist approach.</p>
</sec>
</sec>
<sec id="section9-1094342013488238">
<title>3. Design goals</title>
<p>After evaluating the strengths and weaknesses of the previous efforts toward fault tolerance both within MPI and with other models, we converged on four overarching goals for ULFM. More specifics on the design, rationale and generally how ULFM meets these goals can be found in Sections 4 and 5.</p>
<p>Flexibility in fault response is paramount: not all applications have identical requirements. In the simple case of a Monte Carlo master–worker application that can continue computations despite failures, the application should not have to pay for the cost of any recovery actions; in contrast, consistency restoration interfaces must be available for applications that need to restore a global context (a typical case for applications with collective communications). As a consequence, and in sharp contrast with previous approaches (see Section 7), we believe that MPI should not attempt to define the failure recovery model or to repair applications. It should inform applications of specific conditions that prevent the successful delivery of messages, and provide constructs and definitions that permit applications to restore MPI objects and communication functionalities. Such constructs must be sufficient to express advanced high-level abstractions (without replacing them), such as transactional fault tolerance, uncoordinated checkpoint/restart, and programming language extensions. The failure recovery strategies can then be featured by independent portable packages that provide tailored, problem specific recovery techniques and drive the recovery of MPI on behalf of the applications.</p>
<p>Resiliency refers to the ability of the MPI application not only to survive failures, but also to recover into a consistent state from which the execution can be resumed. One of the most strenuous challenges is to ensure that no MPI operation stalls as a consequences of a failure, for fault tolerance is impossible if the application cannot regain full control of the execution. An error must be raised when a failure prevents a communication from completing. However, we propose that such a notice indicates only the local status of the operation, and does not permit inferring whether the associated failure has impacted MPI operations at other ranks. This design choice avoids expensive consensus synchronizations from obtruding into MPI routines, but leaves open the danger of some processes proceeding unaware of the failure. Therefore, supplementary constructs must be sparingly employed in the application code to let processes which have received an error resolve their divergences.</p>
<p>Productivity and the ability to handle the large number of legacy codes already deployed in production is another key feature. Backward compatibility ( i.e. supporting unchanged non fault tolerant applications) and incremental migration are necessary. A fault-tolerant API should be easy to understand and use in common scenarios, as complex tools have a steep learning curve and a slow adoption rate by the targeted communities. To this end, the number of newly proposed constructs must be small, and have clear and well-defined semantics that are familiar to users.</p>
<p>Performance impact outside of recovery periods should be minimal. Failure protection actions within the implementation must be outside the performance critical path, and recovery actions triggered by the application only when necessary. As most functions are left unmodified (as an example, the implementation of collective operations), they continue to deliver the extraordinary performance resulting from years of careful optimization. Overheads are tolerated only as a consequence of actual failures.</p>
</sec>
<sec id="section10-1094342013488238">
<title>4. ULFM constructs</title>
<p>ULFM was proposed as an extension to the MPI Forum<sup><xref ref-type="fn" rid="fn1-1094342013488238">1</xref></sup> to introduce fault-tolerance constructs in the MPI standard. It is designed according to the criterion identified in the previous section: to be the minimal interface necessary to restore the complete MPI capability to transport messages after failures. As requested by our flexibility goal, it does not attempt to define a specific application recovery strategy. Instead, it defines the set of functions that can be used by applications (or libraries and languages that provide high-level fault-tolerance abstractions) to repair the state of MPI. In this section, we summarize the new definitions and functions added by ULFM ; the rationale behind these design choices will be discussed in Section 5.</p>
<sec id="section11-1094342013488238">
<title>4.1. Failure reporting</title>
<p>Failures are reported on a per-operation basis, and indicate essentially that the operation could not be carried out successfully because a failure occurred on one of the processes involved in the operation. For performance reasons, not all failures need to be propagated, in particular, processes that do not communicate with the failed process are not expected to detect its demise. Similarly, during a collective communication, some processes may detect the failure, while some other may consider that the operation was successful; a particularity that we name non-uniform error reporting. Let's imagine a broadcast communication using a tree-based topology. The processes that are high in the tree topology, close to the root, complete the broadcast earlier than the leaves. Consequently, these processes may report the successful completion of the broadcast, before the failure disrupts the communication, or even before the failure happens, while processes below a failed process cannot deliver the message and have to report an error.</p>
<p>The first new construct, <monospace>MPI_COMM_REVOKE</monospace>, is the most crucial and complex, and is intended to resolve the issues resulting from non-uniform error reporting. As seen above, if non-uniform error reporting is possible, the view of processes, and accordingly the actions that they will undergo in the future, may diverge. Processes that have detected the failure may need to initiate a recovery procedure, but they have the conflicting need to match pending operations that have been initiated by processes that have proceeded unaware of the failure, as otherwise these may deadlock while waiting for their operation to complete. When such a situation is possible, according to the communication pattern of the application, processes that have detected that recovery action is needed and intend to interrupt following the normal flow of communication operations can release other processes by explicitly calling the <monospace>MPI_COMM_REVOKE</monospace> function on the communication object. Like many other MPI constructs <monospace>MPI_COMM_REVOKE</monospace> is a collective operation over the associated communicator. However, unlike any other collective MPI constructs it does not require a symmetric call on all processes, a single processes in the communicator calling the revoke operation ensure the communicator will be eventually revoked. In other words it has a behavior similar to <monospace>MPI_ABORT</monospace> with the exception that it does not abort processes, instead it terminate all ongoing operations on the communicator and mark the communicator as improper for future communications.</p>
<p>As an example, in <xref ref-type="fig" rid="fig1-1094342013488238">Figure 1</xref>, four processes are communicating in a point-to-point pattern. Process 2 is waiting to receive a message from process 3, which is waiting to receive a message from process 0, itself waiting to receive a message from process 1. In the meantime, process 1 has failed, but this condition is detected only by process 0, as other processes do not communicate with process 1 directly. At this point, without a new construct, the algorithm would reach a deadlock: the messages that processes 2 and 3 are waiting for will never arrive because process 0 has branched to enter recovery. To resolve this scenario, before switching to the recovery procedure, process 0 calls <monospace>MPI_COMM_REVOKE</monospace>, which notifies all other processes in the communicator that a condition requiring recovery actions has been reached. When receiving this notification, any communication on the communicator (ongoing or future) is interrupted and a special error code returned. From this point, any operation (point-to-point or collective) on the communicator returns that same error code, and the communicator becomes effectively unusable for any purpose. Then, all surviving processes can safely enter the recovery procedure of the application, knowing that no alive process belonging to that communicator can deadlock on a communication that will not happen.</p>
<fig id="fig1-1094342013488238" position="float">
<label>Figure 1.</label>
<caption>
<p>An example of a scenario where MPI_COMM_REVOKE is necessary to resolve a potential deadlock in the communication pattern.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488238-fig1.tif"/>
</fig>
</sec>
<sec id="section12-1094342013488238">
<title>4.2. Rebuilding communicators</title>
<p>The next construct provides a recovery mechanism: <monospace>MPI_COMM_SHRINK</monospace>. Although the state of a communicator is left unchanged by process failures, and point-to-point operations between non-failed processes are still functional, it is to be expected that most collective communication will always raise an error, as they involve all processes in the communicator. Therefore, to restore full communication capacity, MPI communicators objects must be repaired. The <monospace>MPI_COMM_SHRINK</monospace> function create a new functional communicator based on an existing, revoked communicator containing failed processes. It does this by creating a duplicate communicator (in the sense of <monospace>MPI_COMM_DUP</monospace>) but omitting any processes which are agreed to have failed by all remaining processes in the shrinking communicator. If there are new process failures which are discovered during the shrink operation, these failures are absorbed as part of the operation.</p>
</sec>
<sec id="section13-1094342013488238">
<title>4.3. Continue without revoke</title>
<p>Revoking a communicator is an effective but heavy-handed recovery strategy, as no further communication can happen on the revoked communicator, and a new working communicator can only be created by calling <monospace>MPI_COMM_SHRINK</monospace>. Depending on the application communication pattern, the occurrence of a failure may never result in a deadlock (an opportunity that is impossible to detect at the implementation level, but that may be known by the programmer, typically in a domain decomposition application). In accordance to the flexibility principle, such applications should not have to pay for the cost of complete recovery when they can simply continue to operate on the communicator without further involving the failed processes.</p>
</sec>
<sec id="section14-1094342013488238">
<title>4.4. Retrieving the local knowledge about failed processes</title>
<p>The next two functions, <monospace>MPI_COMM_FAILURE_ACK</monospace> and <monospace>MPI_COMM_FAILURE_GET_ACKED</monospace> are introduced as a lightweight mechanism to continue using point-to-point operations on a communicator that contains failed processes. Using these functions, the application can determine which processes are known to have failed, and inform the MPI library that it acknowledges that no future receive operation can match sends from any of the reported dead processes. <monospace>MPI_COMM_FAILURE_GET_ACKED</monospace> returns the group containing all processes which were locally known to have failed at the time the last <monospace>MPI_COMM_FAILURE_ACK</monospace> was called. These functions can be used on any type of communicator, be it revoked or not.</p>
<p>The operation of retrieving the group of failed processes is split into two functions for two reasons. First, it permits multiple threads to synchronize on the acknowledge, to prevent situations were multiple thread read a different group of failed processes. Second, the acknowledge acts as a mechanism for alerting the MPI library that the application has been notified of a process failure, permitting to relax error reporting rules for “wildcard” <monospace>MPI_ANY_SOURCE</monospace> receives. Without an acknowledgement function, the MPI library would not be able to determine whether the failed process is a potential matching sender, and would have to take the safe course of systematically returning an error, thereby preventing any use of wildcard receives after the first failure. Once the application has called <monospace>MPI_COMM_FAILURE_ACK</monospace>, it becomes its responsibility to check that no posted “wildcard” receive should be matched by a send at a reported dead process, as MPI stops reporting errors for such processes. However, it will continue to raise errors for named point-to-point operations with the failed process as well as collective communications.</p>
</sec>
<sec id="section15-1094342013488238">
<title>4.5. Ensuring consistent state</title>
<p>The last function permits deciding on the completion of an algorithmic section: <monospace>MPI_COMM_AGREE</monospace>. This function, which is intrinsically costly, is designed to be used sparingly, for example when a consistent view of the status of a communicator is necessary, such as during algorithm completion. This operation performs an agreement algorithm, computing the conjunction of boolean values provided by all alive processes in a communicator. Dead processes “participate” with the default value ’false’. It is important to note that this function will continue successfully even if a communicator has known failures (or if failures happen during the operation progress).</p>
</sec>
<sec id="section16-1094342013488238">
<title>4.6. Beyond communicators</title>
<p>While communicator operations are the historic core of MPI, the standard has been extended over the years to support other types of communication contexts, namely shared memory windows (with explicit put/get operations) and collective file I/O. The same principles described in this paper are extended to these MPI objects in the complete proposal; in particular, windows and files have a similar Revoke function. A notable difference, though, is that file and window object do not have repair functions. These objects are initially derived from a communicator object, and the expected recovery strategy is to create a repaired copy of this communicator, before using it to create a new instance of the window or file object. While windows also have the failure introspection function <monospace>MPI_WIN_GET_FAILED</monospace>, which is useful for continuing active target operations on the window when failed processors can be ignored (similarly to point-to-point operations on a communicator), all file operations are collective, hence this function is not provided, as the only meaningful continuation of a failure impacting a file object is to revoke the file object. It should be noted that in the case of file objects, only failures of MPI processes (that may disrupt collective operations on the file) are addressed. Failures of the file backend itself are already defined in MPI-2.</p>
</sec>
</sec>
<sec id="section17-1094342013488238">
<title>5. Design rationale</title>
<p>In this section we discuss the rationale behind the proposed design by taking the view of MPI implementors in analyzing the challenges and performance implications that result from possible implementations, and explain why sometime counterintuitive designs are superior. While presenting implementation details or practical results is outside the scope of this paper, our claims that the proposed design does indeed achieve excellent performance is supported by an implementation, presented in <xref ref-type="bibr" rid="bibr2-1094342013488238">Bland et al. (2012a)</xref>.</p>
<sec id="section18-1094342013488238">
<title>5.1. Failure detection</title>
<p>Failure detection has proven to be a complex but crucial area of fault-tolerance research. Although in the most adverse hypothesis of a completely asynchronous system, failures are intractable in theory, the existence of an appropriate failure detector permits resolving most of the theoretical impossibilities (<xref ref-type="bibr" rid="bibr10-1094342013488238">Chandra and Toueg, 1996</xref>). One of the crucial goals of ULFM is to prevent deadlocks from arising, which indeed requires the use of some failure detection mechanism (in order to discriminate between arbitrarily long message delays and failures). However, because the practicality of implementing a particular type of failure detector strongly depends on the hardware features, the specification is intentionally vague and refrains from forcing a particular failure detection strategy. Instead, it leaves open to the implementations choices that better match the target system. On some systems, hardware introspection may be available and provide total awareness of failures (typically, an IPMI capable batch scheduler). However, on many systems, a process may detect a failure only if it has an active open connection with the failed resource, or if it is actively monitoring its status with heartbeat messages. In the latter situation requiring complete awareness of failures of every process by every process would generate an immense amount of system noise (from heartbeat messages injected into the network and the according treatments on the computing resources to respond to them), and it is known that MPI communication performance is very sensitive to system noise (<xref ref-type="bibr" rid="bibr24-1094342013488238">Petrini et al., 2003</xref>). Furthermore, processes that are not trying to communicate with the dead process do not need to be aware of its failure, as their operations are with alive processors and therefore deadlock-free. As a consequence, to conserve generality and avoid extensive generation of system noise, failure detection in ULFM requires only to detect failures of processes that are active partners in a communication operation, so that this operation eventually returns an appropriate error. In the ideal case, the implementation should be able to turn on failure monitoring only for the processes it is expecting events from (such as the source or destination in a point-to-point operation). Some cases (such as wildcard receives from any source) may require a wider scoped failure detection scheme, as any processor is a potential sender. However, the triggering of active failure detection can be delayed according to implementation internal timers, so that latency critical operations do not have to suffer a performance penalty.</p>
</sec>
<sec id="section19-1094342013488238">
<title>5.2. Communication objects status</title>
<p>A natural conception is to consider that detection of failures results in MPI automatically altering the state of all communication objects (i.e. communicators, windows, etc.) in which the associated process appears. In such a model, it is understood that the failure “damages” the communication object and renders it inappropriate for further communications. However, a complication is hidden in such an approach: the state of MPI communication objects is the aggregate state of individual views by each process of distributed system. As failure awareness is not expected to be global, the implementation would then require internal and asynchronous propagation of failure detection, a process prone to introduce jitter. Furthermore, MPI messages would be able to cross the toggling of the communication object into an invalid state, resulting in a confuse semantic where operations issued on a valid communication object would still fail, diluting the meaning of a valid and invalid state of communication objects.</p>
<p>We decided to take the opposite stance on the issue, failures never automatically modify the state of communication objects. Even if it contains failed processes, a communicator remains a valid communication object. Instead, error reporting is not intended to indicate that a process failed, but to indicate that an operation cannot complete. As long as no failures happen, the normal semantic of MPI must be respected. When a failure has happened, but the MPI operation can proceed without disruption, it completes normally. Obviously, when the failed process is supposed to participate to the result of the operation, it is impossible for the operation to succeed, and an appropriate error is returned. Posting more operations that involve the dead processes is allowed, but is expected to result in similar errors.</p>
<p>There are multiple advantages to this approach. First, the consistency of MPI objects is always guaranteed, as their state remains unchanged as long as users don’t explicitly change it with one of the recovery constructs. Second, there is no need to introduce background propagation of failure detections to update the consistent state of MPI objects, because operations that need to report an error do actively require the dead process’ participation, thereby active failure detection is forced only at the appropriate time and place.</p>
</sec>
<sec id="section20-1094342013488238">
<title>5.3. Local or uniform error reporting</title>
<p>In the ULFM design, errors notify the application that an operation could not satisfy its MPI specification. However, most MPI operations are collective, or have a matching call at some other process. Should the same error be returned <italic>uniformly</italic> at all ranks that participated in the communication? Although such a feature is desirable for some users, as it permits easily tracking the global progress of the application (and then infer a consistent synchronized recovery point), the consequences on performance are dire. This would require that each communication conclude with a global agreement operation to determine the success or failure of the previous communication as viewed by each process. Such an operation has been shown to require at least O(<italic>n</italic><sup>2</sup>) messages (where <italic>n</italic> is the number of processes participating in the communication), and would thus impose an enormous overhead on communication. With regards to the goal of maintaining unchanged level of performance, it is clearly unacceptable to double, at best, the cost of all communication operations, even when no failure happened.</p>
<p>As a consequence, in ULFM, the reporting of errors has a local semantic: the local completion status (in error, or successfully) cannot be used to assume whether the operation has failed or succeeded at other ranks. In many applications, this uncertainty is manageable, because the communication pattern is simple enough. When the communication pattern does not allow such flexibility, the application is required to resolve this uncertainty itself by explicitly changing the state of the communication object to <italic>Revoked</italic>. Indeed, it is extremely difficult for MPI to assess whether a particular communication pattern is still consistent (it would require computing global snapshots after any communication), while the user can know through algorithm invariants when it is the case. Thanks to that flexibility, the cost associated with consistency in error reporting is paid only after an actual failure has happened, and applications that do not need consistency can enjoy unchanged performance.</p>
</sec>
<sec id="section21-1094342013488238">
<title>5.4. Restoring consistency and communication capabilities</title>
<p>Revoking a communication object result in a definitive alteration of the state of the object, that is consistent across all processes. This alteration is not to be seen as the (direct) consequence of a failure, but as the consequence of the user calling a specific operation on the communication object. In a sense, revoking a communication object explicitly achieves the propagation of failure knowledge that has intentionally not been required, but is provided when the user determines necessary. Another important feature of that change of state is that it is definitive. After a communication object has been revoked, it can never be repaired. The rationale is to avoid the matching to have to check for stale messages from past incarnations of a repaired communication object. Because the object is discarded definitively, any stale message matches the revoked object and is appropriately ignored without modifications in the matching logic. In order to restore communication capacity, the repair function derive new, fresh communication objects, that do not risk intermixing pre-failure operations.</p>
</sec>
<sec id="section22-1094342013488238">
<title>5.5. Library construction</title>
<p>At the heart of all of the design decisions in ULFM was a minimalistic approach which encouraged extensions via supplementary libraries. Because fault-tolerance research shows such a clear need in the future and no single practice has emerged as dominant, ULFM provides the foundations to construct new consistency models on top of MPI as a library. For instance, if an application is willing to pay the performance cost of globally consistent collective operations which uniformly return error codes among participating processes, it can create a library which amends the existing collective operations with an agreement operation to decide the status of the communication. Further discussion of composing fault-tolerant techniques on top of ULFM can be found in Section 6.</p>
<p>While not specifically mentioned in the ULFM specification, library composition is a complex topic that required some consideration in the design. To ensure that libraries could interoperate and maintain a consistent view of the system throughout the software stack, a sample library stack was envisioned to demonstrate the feasibility of ULFM with other libraries. <xref ref-type="fig" rid="fig1-1094342013488238">Figure 1</xref> demonstrates one possible method of propagating failure information up through the stack to the application, then performing a top-down recovery to repair communication and continue the algorithm. As the figure shows, the recovery operations should occur at the highest level first, rather than the lowest. This is especially true when the algorithm requires the replacement of failed processes with new processes. If this replacement occurs at the lowest level, transparent to libraries and applications which sit on top of it, the MPI communicators lose their consistency. For example, if an application provides a communicator to a library, rank 2 in the communicator fails and the library automatically spawns a new process and inserts it into the communicator, the original application has no knowledge of this new process and therefore cannot bring it back into the original application. However, if the original application is responsible for repairing the communicator by recreating failed processes and providing the repaired communicator to the library, both levels can now communicate with the replacement process and the application can continue.</p>
</sec>
</sec>
<sec id="section23-1094342013488238">
<title>6. Composition of fault-tolerant libraries and applications</title>
<p>ULFM was specifically created not to promote any particular form of fault tolerance over another. Instead, it was designed to enable the support of many types of fault-tolerance techniques provided either via extension libraries or independent packages, with a portable and efficient interface. The portability claim is paramount, as one of the major obstacles for progress in the fault-tolerance area is the lack of consistent interfaces to retrieve and handle process failures from multiple MPI implementations. With ULFM constructs, as fault tolerance evolves as a research field and new ideas come about, their implementations can be built using the consistent and portable set of constructs with minimal overhead. This section will expand on how existing fault-tolerance techniques from Section 2 could be constructed in conjunction with ULFM.</p>
<sec id="section24-1094342013488238">
<title>6.1. Automatic methods</title>
<p>As fault tolerance continues to evolve, checkpoint/restart will continue to be a popular design for legacy codes and therefore should be supported by any new fault-tolerant environments. ULFM supports the coordinated rollback form of checkpoint/restart without modification as there are many libraries which function with the existing MPI Standard (<xref ref-type="bibr" rid="bibr15-1094342013488238">Duell, 2002</xref>). However, partial rollback forms of checkpoint/restart can be developed which could take advantage of the additions in ULFM without requiring the application to restart entirely. Most of the event-logging mechanisms can be implemented in a portable way by using the already standardized PMPI interface. When a failure happens, the message logging library can revoke communicators internally in the PMPI hooks, silently swap them with replacements obtained by the usual shrink, spawn, merge combination, and continue.</p>
<p>In the case of replication and migration, the PMPI hooks are usually used to redirect messages to the appropriate target, or to integrate the consistent delivery protocol to multiple replicates. When operations are addressed to other processes, the library can intercept the MPI calls and recalculate their targets. For example, the library might redirect the communication to point to the currently active target depending on which replica is being used or if a process has migrated. When a failure happens, the similar internal hot swapping of the communication object can be realized in the PMPI interface.</p>
<p>By employing message-logging techniques and using ULFM constructs, the application might not need to roll back any processes, but could use an MPI_COMM_AGREE function to decide the status of the failed process and then consistently replay the messages that were sent to the recovered process.</p>
</sec>
<sec id="section25-1094342013488238">
<title>6.2. Algorithm-based fault tolerance</title>
<p>Algorithm-based fault-tolerant ( ABFT ) codes are another form of application that could easily be directly integrated with ULFM. For ABFT codes which tolerating the lost of processes, a simple <monospace>MPI_COMM_REVOKE</monospace> followed by <monospace>MPI_COMM_SHRINK</monospace> approach could restore functionality by dropping failed processes. Other applications which require a full set of processes to continue can replace the failed processes by adding a call to <monospace>MPI_COMM_SPAWN</monospace>, and reintegrating the new processes in the original set. To the best of the authors’ knowledge, neither of these types of applications require another level of complexity through an external library, but receive all of the fault-tolerance support they require through ULFM.</p>
</sec>
<sec id="section26-1094342013488238">
<title>6.3. Transactional fault tolerance</title>
<p>Transactional fault tolerance can also be implemented as a library on top of ULFM by adding a new function that remaps to <monospace>MPI_COMM_AGREE</monospace> to determine the completion status of previous operations and, on success, saves any necessary data to stable storage, or, on failure, loads the necessary data from storage and returns to a previous point in the code. It would also be necessary to perform operations to replace failed processes using existing MPI-2 dynamic processing functions. Timers and bailouts that are defined in some transactional frameworks can be introduced in PMPI hooks.</p>
</sec>
</sec>
<sec id="section27-1094342013488238">
<title>7. Related work</title>
<p>
<xref ref-type="bibr" rid="bibr20-1094342013488238">Gropp and Lusk (2004</xref>) describe methods using the then current version of the MPI Standard to perform fault tolerance. They described methods including checkpointing, <monospace>MPI_ERRHANDLER</monospace>s, and using inter-communicators to provide some form of fault tolerance. They outline the goals of providing fault tolerance without requiring changes to the MPI Standard. However, at the time of writing, fault tolerance was still an emerging topic of research with few solutions beyond checkpointing and simple ABFT in the form of master–worker applications. As fault tolerance has evolved to include those paradigms mentioned in Section 2, the requirements on the MPI implementation have also grown, and the limited functionality emphasized are insufficient for general communication purposes.</p>
<p>Another notable effort was FT-MPI (<xref ref-type="bibr" rid="bibr18-1094342013488238">Fagg and Dongarra, 2000</xref>). The overreaching goal was to support ABFT techniques, it thereby provide three failure modes adapted to this type of recovery techniques, but difficult to use in other contexts. In the <italic>Blank</italic> mode, failed processes were automatically replaced by <monospace>MPI_PROC_NULL</monospace>; messages to and from them were silently discarded and collective communications had to be significantly modified to cope with the presence of <monospace>MPI_PROC_NULL</monospace> processes in the communicator. In the <italic>Replace</italic> mode, faulty processes were replaced with new processes. In the <italic>Shrink</italic> mode, the communicator would be changed to remove failed processes (and ranks reordered accordingly). In all cases, only <monospace>MPI_COMM_WORLD</monospace> would be repaired and the application was in charge of rebuilding any other communicators. No standardization effort was pursued, and it was mostly used as a playground for understanding the fundamental concepts. A major distinction with the ULFM design is that when FT-MPI detects a failure, it repairs the state of MPI internally according to the selected recovery mode, and then only triggers the coordinated user recovery handle at all nodes. Library composition is rendered difficult by the fact that recovery preempts the normal flow of execution and returns to the highest level of the software stack without alerting intermediate layers that a failure happened.</p>
<p>A more recent effort to introduce failure handling mechanisms was the run-through stabilization proposal (<xref ref-type="bibr" rid="bibr22-1094342013488238">Hursey et al., 2011</xref>). This proposal introduced many new constructs for MPI including the ability to “validate” communicators as a way of marking failure as recognized and allowing the application to continue using the communicator. It included other new ideas such as failure handlers for uniform failure notification. Because of the implementation complexity imposed by resuming operations on failed communicators, this proposal was eventually unsuccessful in its introduction to the MPI Standard.</p>
<p>Simultaneously with the proposed changes to the MPI Standard, Checkpoint-on-Failure (CoF) (<xref ref-type="bibr" rid="bibr3-1094342013488238">Bland et al., 2012b</xref>) is a new protocol designed to permit supporting forward recovery strategies in the context of the existing MPI standard. In this strategy, when a failure happens, MPI operations return an error, but do not abort the application (a behavior defined as a “high-quality” implementation in MPI-2). However, it is not expected from MPI that communications can continue or resume at a later time. Instead of trying to recover immediately, the entire application undergoes checkpoint. Because the checkpoints are taken only after effective failures have happened, the traditional overhead of customary periodic checkpoint is eliminated and checkpoints are indeed taken at the optimal interval (one checkpoint per fault). After the checkpoints are taken, the application undergoes a complete restart, because, unlike in ULFM, MPI communications cannot be repaired without such a drastic measure. Once that full restart is completed, the application can proceed with its forward recovery strategy (typically including communicating) to restore the dataset of processes that have failed before completing their checkpoint.</p>
</sec>
<sec id="section28-1094342013488238">
<title>8. Conclusion</title>
<p>Simple communication interfaces, such as sockets or streams, have been featuring robust fault tolerance for decades. It may come as a surprise that specifying the behavior of MPI when fail-stop failures strike is so challenging. In this paper we have identified the contentious issues, rooted in the fact that the state of MPI objects is implicitly distributed and that specifying the behavior of collective operations and communication routines requires a careful, precise investigation of unexpected consequences on the concepts as well as on the performance. We first took a review of the field of fault tolerance and recovery methods; most require that MPI can restore the full set of communication functionalities after a failure happened. Then, we proposed the ULFM interface, which responds to that demand, and took the critical viewpoint of the implementor unwilling to compromise performance, on a number of hidden, but crucial issues regarding the state of MPI objects when failure happen. Lastly, we took the viewpoint of MPI users, and depicted how the ULFM specification can be used to support high-level recovery strategies.</p>
<p>We believe that, beyond MPI, the insight gained in the ULFM design is applicable to other communication middleware relying on generic concepts such as stateful communication objects representing the context of a communication or defining collective operations. In particular, the pitfalls associated with defining a particular type of recovery strategy that matches only a niche of applications, rather than defining the minimal set of functionalities that permit restoring communication capabilities, as well as the caveats of returning uniform errors and its implementation cost should highlight similar difficulties in any type of distributed memory framework, and we hope some of the insight presented in this paper can be reused in this context.</p>
<p>ULFM is currently considered for standardization by the MPI Forum. More libraries and applications are being adapted to take advantage of its new constructs. As these developments conclude, a more compelling argument for ULFM will take shape and hopefully drive its adoption as a critical part of the future versions of the MPI standard.<xref ref-type="fig" rid="fig2-1094342013488238"/>
</p>
<fig id="fig2-1094342013488238" position="float">
<label>Figure 2.</label>
<caption>
<p>An example of library construction, error propagation, and recovery through the software stack.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488238-fig2.tif"/>
</fig>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure" id="fn2-1094342013488238">
<label>Funding</label>
<p>This document describes combined research conducted under the following contracts: NSF-0904952 and NSF-1144042 between the U.S. National Science Foundation and the University of Tennessee, and DE-FC02-11ER26059 supported by the U.S. Department of Energy.</p>
</fn>
</fn-group>
<notes>
<title>Note</title>
<fn-group>
<fn fn-type="other" id="fn1-1094342013488238">
<label>1.</label>
<p>The interested reader may refer to chapter 17 of the complete draft, available from <ext-link ext-link-type="uri" xlink:href="http://fault-tolerance.org/ulfm/ulfm-specification">http://fault-tolerance.org/ulfm/ulfm-specification</ext-link></p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References </title>
<ref id="bibr1-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Alvisi</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Marzullo</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>1995</year>) <article-title>Message logging: pessimistic, optimistic, and causal</article-title>. In: <source>Proceedings of the 15th International Conference on Distributed Computing Systems (ICDCS 1995)</source>. <publisher-loc>Los Alamitos, CA</publisher-loc>: <publisher-name>IEEE CS Press</publisher-name>, pp. <fpage>229</fpage>–<lpage>236</lpage>.</citation>
</ref>
<ref id="bibr2-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bland</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Bouteiller</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Herault</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Hursey</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Bosilca</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Dongarra</surname>
<given-names>JJ</given-names>
</name>
</person-group> (<year>2012 a</year>) <article-title>An evaluation of User-Level Failure Mitigation support in MPI</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Träff</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Benkner</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Dongarra</surname>
<given-names>J</given-names>
</name>
</person-group> (eds.) <source>19th EuroMPI</source>, <publisher-loc>Vienna, Austria</publisher-loc>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr3-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bland</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Du</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Bouteiller</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Herault</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Bosilca</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Dongarra</surname>
<given-names>JJ</given-names>
</name>
</person-group> (<year>2012 b</year>) <article-title>A Checkpoint-on-Failure protocol for algorithm-based recovery in standard MPI</article-title>. In: <source>18th Euro-Par</source>, <publisher-loc>Rhodes Island, Greece. Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr4-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bouteiller</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Bosilca</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Dongarra</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Redesigning the message logging model for high performance</article-title>. <source>Concurrency and Computation: Practice and Experience</source> <volume>22</volume>(<issue>16</issue>): <fpage>2196</fpage>–<lpage>2211</lpage>.</citation>
</ref>
<ref id="bibr5-1094342013488238">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Bouteiller</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Herault</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Bosilca</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Dongarra</surname>
<given-names>JJ</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Correlated set coordination in fault tolerant message logging protocols</article-title>. In: <source>Proceedings of Euro-Par’11 (II) (Lecture Notes in Computer Society</source>, vol. <volume>6853</volume>). <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, pp. <fpage>51</fpage>–<lpage>64</lpage>. <comment>DOI:</comment> <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-3-642-23397-5_6">http://dx.doi.org/10.1007/978-3-642-23397-5_6</ext-link>.</citation>
</ref>
<ref id="bibr6-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bright</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Ellavsky</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Gara</surname>
<given-names>A</given-names>
</name>
<etal/>
</person-group>. (<year>2005</year>) <article-title>Creating the BlueGene/L supercomputer from low-power SoC ASICs</article-title>. In: <source>Solid-State Circuits Conference, Digest of Technical Papers (ISSCC)</source>, <volume>volume 1</volume>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, pp. <fpage>188</fpage>–<lpage>189</lpage>. <comment>DOI: 10.1109/ISSCC.2005.1493932</comment>.</citation>
</ref>
<ref id="bibr7-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Buntinas</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Coti</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Herault</surname>
<given-names>T</given-names>
</name>
<etal/>
</person-group>. (<year>2008</year>) <article-title>Blocking vs. non-blocking coordinated checkpointing for large-scale fault tolerant MPI protocols</article-title>. <source>Future Generation Computer Systems</source> <volume>24</volume>(<issue>1</issue>): <fpage>73</fpage>–<lpage>84</lpage>. <comment>DOI: 10.1016/j.future.2007.02.002</comment>.</citation>
</ref>
<ref id="bibr8-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cappello</surname>
<given-names>F</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Fault tolerance in petascale/exascale systems: Current knowledge, challenges and research opportunities</article-title>. <source>International Journal of High Performance Computing Applications</source> <volume>23</volume>(<issue>3</issue>): <fpage>212</fpage>.</citation>
</ref>
<ref id="bibr9-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Chakravorty</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Mendes</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Kalé</surname>
<given-names>LV</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Proactive fault tolerance in MPI applications via task migration</article-title>. In: <source>HiPC 2006, the IEEE High performance Computing Conference</source>. <publisher-loc>Los Alamitos, CA</publisher-loc>: <publisher-name>IEEE Computer Society Press</publisher-name>, pp. <fpage>485</fpage>–<lpage>496</lpage>.</citation>
</ref>
<ref id="bibr10-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chandra</surname>
<given-names>TD</given-names>
</name>
<name>
<surname>Toueg</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>Unreliable failure detectors for reliable distributed systems</article-title>. <source>Journal of the ACM</source> <volume>43</volume>(<issue>2</issue>): <fpage>225</fpage>–<lpage>267</lpage>.</citation>
</ref>
<ref id="bibr11-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chandy</surname>
<given-names>KM</given-names>
</name>
<name>
<surname>Lamport</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>1985</year>) <article-title>Distributed snapshots: determining global states of distributed systems</article-title>. <source>Transactions on Computer Systems</source> <volume>3</volume>(<issue>1</issue>): <fpage>63</fpage>–<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr12-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Davies</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Karlsson</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Ding</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>Z</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>High performance Linpack benchmark: a fault tolerant implementation without checkpointing</article-title>. In: <source>Proceedings of the 25th ACM International Conference on Supercomputing (ICS 2011)</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dongarra</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Beckman</surname>
<given-names>P</given-names>
</name>
<etal/>
</person-group>. (<year>2011</year>) <article-title>The international exascale software roadmap</article-title>. <source>International Journal of High Performance Computing Applications</source> <volume>25</volume>(<issue>11</issue>): <fpage>3</fpage>–<lpage>60</lpage>.</citation>
</ref>
<ref id="bibr14-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Du</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Bouteiller</surname>
<given-names>A</given-names>
</name>
<etal/>
</person-group>. (<year>2012</year>) <article-title>Algorithm-Based Fault Tolerance for dense matrix factorizations</article-title>. In: <source>17th SIGPLAN PPoPP</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>, pp. <fpage>225</fpage>–<lpage>234</lpage>.</citation>
</ref>
<ref id="bibr15-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Duell</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>The Design and Implementation of Berkeley Lab’s Linux Checkpoint/Restart</article-title>. <comment>Technical Report LBNL-54941</comment>.</citation>
</ref>
<ref id="bibr16-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Elnozahy</surname>
<given-names>ENM</given-names>
</name>
<name>
<surname>Alvisi</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>YM</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>DB</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>A survey of rollback-recovery protocols in message-passing systems</article-title>. <source>ACM Computing Survey</source> <volume>34</volume>: <fpage>375</fpage>–<lpage>408</lpage>.</citation>
</ref>
<ref id="bibr17-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Esteban Meneses</surname>
<given-names>CLM</given-names>
</name>
<name>
<surname>Kalé</surname>
<given-names>LV</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Team-based message logging: Preliminary results</article-title>. In: <source>3rd Workshop on Resiliency in High Performance Computing (Resilience) in Clusters, Clouds, and Grids (CCGRID 2010)</source>.</citation>
</ref>
<ref id="bibr18-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Fagg</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Dongarra</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2000</year>) <article-title>FT-MPI: Fault Tolerant MPI, supporting dynamic applications in a dynamic world</article-title>. In: <source>EuroPVM/MPI</source>.</citation>
</ref>
<ref id="bibr19-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Ferreira</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Stearley</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Laros</surname>
<given-names>J</given-names>
</name>
<etal/>
</person-group>. (<year>2011</year>) <article-title>Evaluating the viability of process replication reliability for exascale systems</article-title>. In: <source>2011 International Conference for High Performance Computing, Networking, Storage and Analysis (SC)</source>. <comment>ACM Request Permissions</comment>, pp. <fpage>1</fpage>–<lpage>12</lpage>.</citation>
</ref>
<ref id="bibr20-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gropp</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Lusk</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2004</year>) <article-title>Fault tolerance in message passing interface programs</article-title>. <source>International Journal of High Performance Computing Applications</source> <volume>18</volume>: <fpage>363</fpage>–<lpage>372</lpage>. <comment>DOI: 10.1177/1094342004046045</comment>.</citation>
</ref>
<ref id="bibr21-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Guermouche</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Ropars</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Snir</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Cappello</surname>
<given-names>F</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>HydEE: failure containment without event logging for large scale send-deterministic MPI applications</article-title>. In: <source>2012 IEEE 26th International Parallel Distributed Processing Symposium (IPDPS)</source>, pp. 1216 –1227. <comment>DOI: 10.1109/IPDPS.2012.111</comment>.</citation>
</ref>
<ref id="bibr22-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hursey</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Graham</surname>
<given-names>RL</given-names>
</name>
<name>
<surname>Bronevetsky</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Buntinas</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Pritchard</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Solt</surname>
<given-names>DG</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Run-through stabilization: An MPI proposal for process fault tolerance</article-title>. In: <source>EuroMPI 2011: Proceedings of the 18th EuroMPI Conference</source>, <publisher-loc>Santorini, Greece</publisher-loc>.</citation>
</ref>
<ref id="bibr23-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hursey</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Squyres</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Mattox</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Lumsdaine</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>The design and implementation of checkpoint/restart process fault tolerance for Open MPI</article-title>. In: <source>IEEE International Parallel and Distributed Processing Symposium, 2007 (IPDPS 2007)</source>, pp. <fpage>1</fpage>–<lpage>8</lpage>. <comment>DOI: 10.1109/IPDPS.2007.370605</comment>.</citation>
</ref>
<ref id="bibr24-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Petrini</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Frachtenberg</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Hoisie</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Coll</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2003</year>) <article-title>Performance evaluation of the Quadrics interconnection network</article-title>. <source>Cluster Computing</source> <volume>6</volume>(<issue>2</issue>): <fpage>125</fpage>–<lpage>142</lpage>. <comment>DOI: 10.1023/A:1022852505633</comment>.</citation>
</ref>
<ref id="bibr25-1094342013488238">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schroeder</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Gibson</surname>
<given-names>GA</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Understanding failures in petascale computers</article-title>. <source>Journal of Physics: Conference Series</source> <volume>78</volume>: <fpage>012022</fpage>.</citation>
</ref>
<ref id="bibr26-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Silva</surname>
<given-names>LM</given-names>
</name>
<name>
<surname>Silva</surname>
<given-names>JG</given-names>
</name>
</person-group> (<year>1998</year>) <article-title>System-level versus user-defined checkpointing</article-title>. In: <source>Proceedings of the The 17th IEEE Symposium on Reliable Distributed Systems (SRDS ‘98)</source>, <publisher-loc>Washington, DC. Los Alamitos, CA</publisher-loc>: <publisher-name>IEEE Computer Society Press</publisher-name>, p. <fpage>68</fpage>.</citation>
</ref>
<ref id="bibr27-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Skjellum</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>Middle-out Transactional Requirements on Exascale Parallel Middleware, Storage, and Services</article-title>. <comment>Technical Report UABCIS-TR-2012-020312, University of Alabama at Birmingham, Computer and Information Sciences</comment>.</citation>
</ref>
<ref id="bibr28-1094342013488238">
<citation citation-type="book">
<collab collab-type="author">The MPI Forum</collab> (<year>2012</year>) <comment>MPI: A Message-Passing Interface Standard, Version 3.0. Technical report</comment>.</citation>
</ref>
<ref id="bibr29-1094342013488238">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Mueller</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Engelmann</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Scott</surname>
<given-names>SL</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Proactive process-level live migration in HPC environments</article-title>. In: <source>SC ‘08: Proceedings of the 2008 ACM/IEEE conference on Supercomputing</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE Press</publisher-name>, pp. <fpage>1</fpage>–<lpage>12</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>