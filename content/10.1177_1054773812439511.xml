<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="editorial">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">CNR</journal-id>
<journal-id journal-id-type="hwp">spcnr</journal-id>
<journal-id journal-id-type="nlm-ta">Clin Nurs Res</journal-id>
<journal-title>Clinical Nursing Research</journal-title>
<issn pub-type="ppub">1054-7738</issn>
<issn pub-type="epub">1552-3799</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1054773812439511</article-id>
<article-id pub-id-type="publisher-id">10.1177_1054773812439511</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Editorial</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Strategies for Selecting Measures for Pediatric and Maternal Child Research</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Deatrick</surname><given-names>Janet A.</given-names></name>
<xref ref-type="aff" rid="aff1-1054773812439511">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hardie</surname><given-names>Thomas</given-names></name>
<xref ref-type="aff" rid="aff1-1054773812439511">1</xref>
<xref ref-type="aff" rid="aff2-1054773812439511">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-1054773812439511"><label>1</label>University of Pennsylvania School of Nursing, Philadelphia, PA, USA</aff>
<aff id="aff2-1054773812439511"><label>2</label>Drexel University, Philadelphia, PA, USA</aff>
<author-notes>
<corresp id="corresp1-1054773812439511">Janet A. Deatrick, University of Pennsylvania School of Nursing, Center for Health Equity Research, Claire M. Fagin Hall, 418 Curie Blvd., 223 (2L), Philadelphia, PA 19104-4217, USA Email: <email>deatrick@nursing.upenn.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>5</month>
<year>2012</year>
</pub-date>
<volume>21</volume>
<issue>2</issue>
<issue-title>Special Issue: Maternal Child</issue-title>
<fpage>135</fpage>
<lpage>141</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<p>Mandates from the clinical, academic, policy, and ethical arenas concerning evidence-based practice are both welcome and formidable. Although nursing science and the preparation of clinical scientists has improved over the past decades, answering complex clinical questions remains challenging. One common scenario is that we find a research question that is both compelling and pertinent to our practice, and we find a willing population of potential participants to study. Yet designing a research plan that includes valid and reliable measures can be a challenge.</p>
<p>We offer a case study from our own research to illustrate the process of selecting measures for clinical research with pediatric and maternal–child populations. We also discern the steps in the process and the criteria to use when selecting measures.</p>
<sec id="section1-1054773812439511">
<title>Prologue: Case Study-Proposing the Caregiver Study</title>
<p>The long-term goal of our interdisciplinary team is to improve the quality of life for adolescent and young adult brain tumor survivors (14-40 years old) and their families. As a large number of these survivors are not able to live independent of their families, the first logical step toward our research team’s long-term goal was to focus primarily on the caregivers and secondarily on the survivors to advance our understanding of the nature of caregiver competence.</p>
</sec>
<sec id="section2-1054773812439511">
<title>Steps in the Process</title>
<p>While considering what measures to use in a study, the measures themselves are not the first thing to be considered. After an initial draft of study aims, a conceptual “map” needs to be developed and/or adopted. In this case, the map was found in the lifespan literature because both adolescents and young adults were being studied (<xref ref-type="bibr" rid="bibr8-1054773812439511">Raina et al., 2004</xref>).</p>
<p>Constructs were identified in the literature relative to caregiving, family issues, oncology, and children with neurocognitive deficits. These constructs were caregiver health, survivor health, household functioning, caregiver demands, and caregiver competence.</p>
<p>As a next step, measures were then selected for each construct using quantitative and qualitative measurement strategies. See <xref ref-type="table" rid="table1-1054773812439511">Table 1</xref> noting the decisions that were made regarding selection of the measures. The Preparedness for Caregiving Scale (PCS; <xref ref-type="bibr" rid="bibr2-1054773812439511">Archbold, Stewart, Greenlick, &amp; Harvath, 1990</xref>) was not selected because it was not a good conceptual fit with the study.</p>
<table-wrap id="table1-1054773812439511" position="float">
<label>Table 1.</label>
<caption>
<p>Case Study: Selecting and Using Measures of Caregiver Competence</p>
</caption>
<graphic alternate-form-of="table1-1054773812439511" xlink:href="10.1177_1054773812439511-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Instrument</th>
<th align="center">Intended inference from scores</th>
<th align="center">Reliability (α)-literature</th>
<th align="center">Validity-literature</th>
<th align="center">Using measure in study</th>
</tr>
</thead>
<tbody>
<tr>
<td>Caregiver Competence (From Family Illness Beliefs Inventory [FIBI]; <xref ref-type="bibr" rid="bibr6-1054773812439511">Kazak et al., 2004</xref>)</td>
<td>Caregiver’s belief’s about their own abilities to care for their child who has cancer</td>
<td>α = .72 (<xref ref-type="bibr" rid="bibr6-1054773812439511">Kazak et al., 2004</xref>)</td>
<td>More adaptive family functioning (lower scores means more adaptive functioning) was associated (–0.09) with beliefs indicating better competence (higher scores mean better competence) in caregiving</td>
<td>Decided not to use data because of poor internal consistency reliability (.45) of the measure in our population, probably because it has not been validated with long-term survivors</td>
</tr>
<tr>
<td>Qualitative interview with caregiver</td>
<td>Contextualized understanding of caregiver competence</td>
<td>NA</td>
<td>NA</td>
<td>Rich data that are congruent with the quantitative results; helpful to guide the study as well as to interpret results</td>
</tr>
<tr>
<td>Condition Management Ability (subscale of Family Management Measure [FaMM]; <xref ref-type="bibr" rid="bibr7-1054773812439511">Knafl et al., 2011</xref>)</td>
<td>Caregiver’s perceptions about the overall manageability of their child’s condition</td>
<td>α = .72; test-retest = 0.79</td>
<td>Content and construct validity are documented; more adaptive family functioning (lower scores means more adaptive functioning) was associated (−0.35) with more positive perceptions about overall manageability of the condition (higher scores mean more competent)</td>
<td>Reliable (α = .735) and mixed method provided congruent results</td>
</tr>
<tr>
<td>Preparedness for Caregiving Scale (PCS; <xref ref-type="bibr" rid="bibr2-1054773812439511">Archbold et al., 1990</xref>)</td>
<td>Perceptions of caregivers about their preparedness (perceived readiness)</td>
<td>α = .88-.93</td>
<td>Construct and content validity are documented between caregiver preparedness and caregiver worry and preparedness and availability of resources.</td>
<td>Decided not to use measure in study because it is not best conceptual fit with competence</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Finally a design and analysis plan was drafted based on the literature as well as expert input. The quantitative, cross-sectional design using parallel mixed methods (QUAN+qual) was selected (<xref ref-type="bibr" rid="bibr9-1054773812439511">Teddlie &amp; Tashakkori, 2009</xref>). Quantitative analyses included structural equation modeling to simultaneously assess the hypothesized relationships among the predictors of caregiver competence. Content analysis was planned as the analytic technique for the qualitative data (<xref ref-type="bibr" rid="bibr5-1054773812439511">Hsieh &amp; Shannon, 2005</xref>), and a typological approach was proposed to mix the qualitative and quantitative data (<xref ref-type="bibr" rid="bibr9-1054773812439511">Teddlie &amp; Tashakkori, 2009</xref>).</p>
</sec>
<sec id="section3-1054773812439511">
<title>Criteria to Use When Selecting Measures</title>
<p>The best approach to instrument selection results from a well-informed researcher who has mastery of the extant knowledge of the domains or concepts in the research question(s). For example, Waters reviewed how to select quality-of-life instruments for children and adolescents with neurodisabilities (<xref ref-type="bibr" rid="bibr10-1054773812439511">Waters et al., 2009</xref>). They suggested some general considerations that can be applied generally to maternal–child research. They included the original purpose, focus, domains, and items of the instrument; the opportunity for patient report; clarity of items; use of appropriate and nonoffensive language; and reasonable burden of completing the measure (<xref ref-type="bibr" rid="bibr10-1054773812439511">Waters et al., 2009</xref>). Other general considerations offered in the federal guidelines include the population to be measured, the instrument’s ability or sensitivity to detect change and readability (which is function of the population of interest—often at the 6th- to 8th-grade level; <xref ref-type="bibr" rid="bibr3-1054773812439511">Center for Drug Evaluation and Research, Center for Biologics Evaluation and Research, &amp; Center for Devices and Radiological Health, 2009</xref>).</p>
<p>In terms of the psychometric properties of the measure, both the validity and reliability should be considered. Validity is how well the measure reflects the concept of interest and the evidence and theory that supports any interpretation of test scores (<xref ref-type="bibr" rid="bibr1-1054773812439511">American Educational Research Association &amp; American Psychological Association, 1999</xref>). As such, validity is not really a property of an instrument but a function of the intended use of the score (<xref ref-type="bibr" rid="bibr4-1054773812439511">Cook &amp; Beckman, 2006</xref>). For example depressed mood can be measured in several ways; if a measure and the outcome of interest are congruent, a valid inference can be made from the score. If an instrument which provides data on the presence or absence of major depression is used to look at the relationship between depressed mood and caregiver satisfaction, it is likely to have very poor validity. In addition, investigators are encouraged to seek specific evidence of validity and not accept broad claims that the measure had strong validity in other studies. Evidence on construct, content, and/or criterion validity is necessary. Alternatively, some authorities now combine these foci and examine evidence concerning only construct validity (<xref ref-type="bibr" rid="bibr4-1054773812439511">Cook &amp; Beckman, 2006</xref>).</p>
<p>Once a researcher identifies measures of the construct of interest, they are examined at the question level to assure they provide adequate coverage of the critical elements of the construct defined by the research question. For example, symptoms can be defined in a number of ways, the presence of absence of a symptom, the number of symptoms, the number and intensity of a symptom or changes in a symptom (in any of those defined) over time. When selecting measures, investigators should consider if existing instruments are flexible enough to cover several definitions of symptoms or are quite specific.</p>
<p>After potential measures are selected, expert statistical consultation should be obtained to interpret the measures’ psychometric strength and the impact of selecting a specific measure on sample size and other methodological issues. Many researchers have limited access to statistical experts but can make effective choices by following guidance offered in the literature (Center for Drug Evaluation and Research, Center for Biologics Evaluation and Research, &amp; Center for Devices and Radiological Health, 2009b).</p>
<p>A valid instrument must also be reliable, as unreliable scores from a valid measure are meaningless. Evidence of previous reliability is important, as well as evidence of the reliability of the measure as you conduct your study. At one of the most basic levels, the internal consistency reliability is usually measured. Other types of reliability which may be appropriate include administering a self-report measure at two different times to ascertain if a similar score is obtained (test-retest) or using two observers who both administer an observational measure and compare the results (interrater reliability). Threshold scores for reliability measures are usually targeted at &gt;.70.</p>
<p>Often no instrument meets all or the majority of the criteria listed above. Rather than set about the extensive process of instrument development, a researcher will often modify a measure from a related area or population. Changes even small may significantly change the psychometric properties of a measure and must be examined carefully (<xref ref-type="bibr" rid="bibr3-1054773812439511">Center for Drug Evaluation and Research et al., 2009</xref>).</p>
</sec>
<sec id="section4-1054773812439511">
<title>Epilogue: Case Study— Completing the Caregiver Study</title>
<p>This two-phase study was funded by the National Institutes of Health (R01 NR009651-01A1) and the Oncology Nursing Society. The first quantitative phase of this mixed-methods study was completed using telephone interviews with 187 mothers and 135 survivors. The second, qualitative, phase was completed using in-home interviews with 45 caregivers (mothers) and 41 survivors. These follow-up visit interviews allowed us to better understand the survey data collected during the telephone interviews. We are currently analyzing the study data and understanding daily the value of careful selection of measures.</p>
<p>This case study focused only on the measures of caregiver competence from this study (see <xref ref-type="table" rid="table1-1054773812439511">Table 1</xref> for decisions about the measures in the actual study). The Condition Management Ability scale of the Family Management Measure (FaMM) performed well as did the qualitative interviews. In fact, mixed methods were most helpful not only in terms of conceptual decisions during analysis but also when interpreting the results. The data from the Caregiver Competence scale of the Family Illness Beliefs Inventory (FIBI), however, were not used because the instrument had poor internal consistency reliability in our population, most likely because it had been developed with and validated in newly diagnosed parents.</p>
<p>Instrument selection is a critically important step in quantitative or mixed-methods studies. The final selection results from a series of carefully considered compromises and involves knowledge about the phenomenon being studied and the psychometric properties of the instrument. Researchers exploring novel or cutting-edge concepts or interventions are unlikely to find a highly valid and reliable instrument that meets their exact needs. The selection of measures from related concepts or phenomena is common but should be supported with documented rational for choosing one measure that might appear to be less adequate than another. Researchers studying a well-described phenomena or patient outcomes face the same decisions along with other challenges because a number of well-developed instruments may be available to capture differences among patients or within patients over time. Finally, the performance of measures during your study should be examined to determine the ultimate value of the data for your final analyses and interpretations.</p>
</sec>
<sig-block>
<sig>Janet A. Deatrick<break/>
<italic>University of Pennsylvania School of Nursing</italic>,<break/>
<italic>Philadelphia, PA, USA</italic></sig>
<sig>Thomas Hardie<break/>
<italic>University of Pennsylvania School of Nursing; Drexel University</italic>,<break/>
<italic>Philadelphia, PA, USA</italic></sig>
</sig-block>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="bibr1-1054773812439511">
<citation citation-type="book">
<collab>American Educational Research Association &amp; American Psychological Association</collab>. (<year>1999</year>). <source>National council on measurement in education: Standards for educational and psychological testing</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Educational Research Association</publisher-name>.</citation>
</ref>
<ref id="bibr2-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Archbold</surname><given-names>P. G.</given-names></name>
<name><surname>Stewart</surname><given-names>B. J.</given-names></name>
<name><surname>Greenlick</surname><given-names>M. R.</given-names></name>
<name><surname>Harvath</surname><given-names>T.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Mutuality and preparedness as predictors of caregiver role strain</article-title>. <source>Research in Nursing &amp; Health</source>, <volume>13</volume>, <fpage>375</fpage>-<lpage>384</lpage>.</citation>
</ref>
<ref id="bibr3-1054773812439511">
<citation citation-type="book">
<collab>Center for Drug Evaluation and Research, Center for Biologics Evaluation and Research, &amp; Center for Devices and Radiological Health</collab>. (<year>2009</year>). <source>Guidance for industry patient-reported outcome measures: Use in medical product development to support labeling claims</source>. <publisher-loc>Silver Spring, MD</publisher-loc>: <publisher-name>U.S. Department of Health and Human: Services Food and Drug Administration</publisher-name>.</citation>
</ref>
<ref id="bibr4-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cook</surname><given-names>D. A.</given-names></name>
<name><surname>Beckman</surname><given-names>T. J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Current concepts in validity and reliability for psychometric instruments: Theory and application</article-title>. <source>American Journal of Medicine</source>, <volume>119</volume>(<issue>2</issue>), <fpage>166.e7</fpage>-<lpage>166.e16</lpage>.</citation>
</ref>
<ref id="bibr5-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hsieh</surname><given-names>H.-F.</given-names></name>
<name><surname>Shannon</surname><given-names>S.</given-names></name>
</person-group> (<year>2005</year>, <month>November</month>). <article-title>Three approaches to qualitative content analysis</article-title>. <source>Qualitative Heath Research</source>, <volume>15</volume>, <fpage>1277</fpage>-<lpage>1288</lpage>.</citation>
</ref>
<ref id="bibr6-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kazak</surname><given-names>A.</given-names></name>
<name><surname>McClure</surname><given-names>K.</given-names></name>
<name><surname>Alderfer</surname><given-names>M.</given-names></name>
<name><surname>Hwang</surname><given-names>W.</given-names></name>
<name><surname>Crump</surname><given-names>T.</given-names></name>
<name><surname>Deatrick</surname><given-names>J.</given-names></name>
<name><surname>. . . Grossman</surname><given-names>J.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Cancer related beliefs: The Family Illness Beliefs Inventory (FIBI)</article-title>. <source>Journal of Pediatric Psychology</source>, <volume>29</volume>, <fpage>531</fpage>-<lpage>542</lpage>.</citation>
</ref>
<ref id="bibr7-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Knafl</surname><given-names>K.</given-names></name>
<name><surname>Deatrick</surname><given-names>J.</given-names></name>
<name><surname>Gallo</surname><given-names>A.</given-names></name>
<name><surname>Dixon</surname><given-names>J.</given-names></name>
<name><surname>Knafl</surname><given-names>G.</given-names></name>
<name><surname>O’Malley</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Assessment of the psychometric properties of the family management measure</article-title>. <source>Journal of Pediatric Psychology</source>, <volume>36</volume>, <fpage>494</fpage>-<lpage>505</lpage>.</citation>
</ref>
<ref id="bibr8-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Raina</surname><given-names>P.</given-names></name>
<name><surname>O’Donnell</surname><given-names>M.</given-names></name>
<name><surname>Schwellnus</surname><given-names>H.</given-names></name>
<name><surname>Rosenbaum</surname><given-names>P.</given-names></name>
<name><surname>King</surname><given-names>G.</given-names></name>
<name><surname>Brehaut</surname><given-names>J.</given-names></name>
<name><surname>. . . Wood</surname><given-names>E.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Caregiving process and caregiver burden: Conceptual models to guide research and practice</article-title>. <source>BMC Pediatrics</source>, <volume>4</volume>(<issue>1</issue>), <fpage>1</fpage>-<lpage>13</lpage>.</citation>
</ref>
<ref id="bibr9-1054773812439511">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
</person-group> (Ed.). (<year>2009</year>). <source>Foundations of mixed methods research</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr10-1054773812439511">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Waters</surname><given-names>E.</given-names></name>
<name><surname>Davis</surname><given-names>E.</given-names></name>
<name><surname>Ronen</surname><given-names>G.</given-names></name>
<name><surname>Rosenbaum</surname><given-names>P.</given-names></name>
<name><surname>Livingston</surname><given-names>M.</given-names></name>
<name><surname>Saigal</surname><given-names>S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Quality of life instruments for children and adolescents with neurodisabilities: How to choose the appropriate instrument</article-title>. <source>Developmental Medicine &amp; Child Neurology</source>, <volume>51</volume>, <fpage>660</fpage>-<lpage>669</lpage>. doi:10.1111/j.1469-8749.2009.03324<pub-id pub-id-type="doi">10.1111/j.1469-8749.2009.03324</pub-id></citation>
</ref>
</ref-list>
</back>
</article>