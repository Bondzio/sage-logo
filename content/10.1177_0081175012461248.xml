<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">SMX</journal-id>
<journal-id journal-id-type="hwp">spsmx</journal-id>
<journal-title>Sociological Methodology</journal-title>
<issn pub-type="ppub">0081-1750</issn>
<issn pub-type="epub">1467-9531</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0081175012461248</article-id>
<article-id pub-id-type="publisher-id">10.1177_0081175012461248</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neighborhoods and Structures</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Network Sampling with Memory</article-title>
<subtitle>A Proposal for More Efficient Sampling from Social Networks</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Mouw</surname><given-names>Ted</given-names></name>
<xref ref-type="aff" rid="aff1-0081175012461248">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Verdery</surname><given-names>Ashton M.</given-names></name>
<xref ref-type="aff" rid="aff1-0081175012461248">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0081175012461248"><label>1</label>University of North Carolina at Chapel Hill, USA</aff>
<author-notes>
<corresp id="corresp1-0081175012461248">Ted Mouw, University of North Carolina at Chapel Hill, Department of Sociology, CB #3210, 155 Hamilton Hall, Chapel Hill, NC 27599-3210, USA Email: <email>tedmouw@email.unc.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2012</year>
</pub-date>
<volume>42</volume>
<issue>1</issue>
<fpage>206</fpage>
<lpage>256</lpage>
<permissions>
<copyright-statement>© American Sociological Association 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">American Sociological Association</copyright-holder>
</permissions>
<abstract>
<p>Techniques for sampling from networks have grown into an important area of research across several fields. For sociologists, the possibility of sampling from a network is appealing for two reasons: (1) A network sample can yield substantively interesting data about network structures and social interactions, and (2) it is useful in situations in which study populations are difficult or impossible to survey with traditional sampling approaches because of the lack of a sampling frame. Despite its appeal, methodological concerns about the precision and accuracy of network-based sampling methods remain. In particular, recent research has shown that sampling from a network using a random walk–based approach such as respondent-driven sampling (RDS) can result in a high design effect (DE): the ratio of the sampling variance to the sampling variance of simple random sampling (SRS). A high DE means that more cases must be collected to achieve the same level of precision as SRS. In this article, we propose an alternative strategy, network sampling with memory (NSM), which collects network data from respondents to reduce DEs and, correspondingly, the number of interviews needed to achieve a given level of statistical power. NSM combines a “list” mode, in which all individuals on the revealed network list are sampled with the same cumulative probability, with a “search” mode, which gives priority to bridge nodes connecting the current sample to unexplored parts of the network. We test the relative efficiency of NSM compared with RDS and SRS on 162 school and university networks from the National Longitudinal Study of Adolescent Health and Facebook that range in size from 110 to 16,278 nodes. The results show that the average DE for NSM on these 162 networks is 1.16, which is very close to the efficiency of a simple random sample (DE = 1) and 98.5 percent lower than the average DE we observed for RDS.</p>
</abstract>
<kwd-group>
<kwd>Social networks</kwd>
<kwd>sampling</kwd>
<kwd>respondent driven sampling</kwd>
<kwd>hidden populations</kwd>
<kwd>random walks</kwd>
<kwd>graph theory</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0081175012461248" sec-type="intro">
<title>1. Introduction</title>
<p>The prospect of sampling from social networks has long intrigued social scientists (cf. <xref ref-type="bibr" rid="bibr33-0081175012461248">Goodman 1961</xref>). To fix terms, we define a sample from a social network as one in which current respondents help recruit new respondents through either active (when respondents “drive” recruitment by bringing in new subjects) or passive (when they facilitate contact between researchers and would-be subjects) means.<sup><xref ref-type="fn" rid="fn1-0081175012461248">1</xref></sup> Such an approach is a special case of a “link-tracing” sampling design that can be applied to sampling from any relational network, social or otherwise. For sociologists, the motivation to sample from social networks comes from three sources: (1) a generally accepted belief that respondents, even stigmatized ones, are more likely to participate and respond truthfully in surveys when they are referred by acquaintances or friends rather than randomly contacted; (2) an increasing desire to understand relational network structures and a growing body of theory suggesting the importance of social influence; and (3) heightened interest in understanding stigmatized populations (such as those at risk for human immunodeficiency virus [HIV] infection) that are difficult to survey with traditional methods. Although it was long thought that samples from networks could not yield unbiased results, work in graph theory on the logic of random walks (RWs) on graphs, which have been widely studied in the mathematics, physics, and computer science literatures (cf. <xref ref-type="bibr" rid="bibr50-0081175012461248">Lovasz 1993</xref>), has shown that unbiased mean estimates are attainable. A basic finding is that under certain conditions, if the RW proceeds long enough, it will eventually settle into an equilibrium state in which the sampling probability is inversely proportional to the respondent’s number of social ties (<xref ref-type="bibr" rid="bibr48-0081175012461248">Lawler and Coyle 1999</xref>), which can be used as a weight to accurately estimate sample means and proportions (<xref ref-type="bibr" rid="bibr71-0081175012461248">Volz and Heckathorn 2008</xref>). Overall, the potential appeal of link-tracing sampling methods should be growing in the current research climate as a result of declining survey participation rates and the challenge of contacting willing participants (<xref ref-type="bibr" rid="bibr4-0081175012461248">Atrostic et al. 2001</xref>), because of increased interest in social network effects and peer influence (e.g., <xref ref-type="bibr" rid="bibr15-0081175012461248">Burt 1984</xref>), and because of increased funding for studying marginalized groups, such as those at risk for HIV transmission.</p>
<p>Some of the best evidence for the effectiveness of link tracing–based sampling methods in human social networks comes from work on stigmatized, hidden, and hard-to-reach populations, which have historically been understudied because of the challenge of recruiting them. A recently developed RW-based approach, “respondent-driven sampling” (RDS), collects data on the number of ties each respondent has (<xref ref-type="bibr" rid="bibr38-0081175012461248">Heckathorn 1997</xref>; <xref ref-type="bibr" rid="bibr43-0081175012461248">Johnston 2008</xref>; <xref ref-type="bibr" rid="bibr71-0081175012461248">Volz and Heckathorn 2008</xref>; cf. <xref ref-type="bibr" rid="bibr28-0081175012461248">Gile and Handcock 2010</xref> for a recent summary of this approach). Under certain conditions—in particular, a connected component with at least one triangle and undirected ties (i.e., everyone in the population is reachable through some chain of connections from everyone else, there is at least one group of three people who are all connected to each other, and all ties are reciprocated), a sufficiently long chain of referrals, sampling with replacement, and a large study population—the probability of being sampled is proportional to the number of ties that each respondent has. As a result, the inverse of the self-reported number of ties can be used as a sampling weight. Because of the attractiveness of its hypothetical sampling properties, the RDS approach has been widely used by researchers to study hidden populations such as intravenous drug users, undocumented immigrants, jazz musicians, and so on (cf. reviews by <xref ref-type="bibr" rid="bibr1-0081175012461248">Abdul-Quader et al. 2006</xref>; <xref ref-type="bibr" rid="bibr62-0081175012461248">Ramirez-Valles et al. 2005</xref>).</p>
<p>Despite the popularity of RDS, recent research indicates that the accuracy of the approach is sensitive to the assumptions it makes about the social network of the underlying population (<xref ref-type="bibr" rid="bibr28-0081175012461248">Gile and Handcock 2010</xref>; <xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik 2010</xref>; <xref ref-type="bibr" rid="bibr51-0081175012461248">Lu et al. 2012</xref>). A fundamental problem with RW-based approaches in general, and RDS in particular, is that they have a higher sampling variance than simple random sampling (SRS). Whereas the sampling variance of a simple random sample is inversely related to sample size, the precision of RDS and RWs is a function of both sample size and the structure of the network: <xref ref-type="bibr" rid="bibr7-0081175012461248">Bassetti and Diaconis (2006)</xref> and <xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik (2009)</xref> showed that the variance of an RW is mathematically related to the eigenvalue decomposition of the network (i.e., its underlying structure) and the degree to which the dependent variable maps onto the corresponding eigenvectors. In networks with high degrees of clustering, RDS has a tendency to get stuck in segregated components of the network, which can result in inaccurate samples. In certain networks, the variance of a respondent-driven sample could be unacceptably high, but the researcher, with no knowledge of the network that he or she was sampling from, would be unable to distinguish between accurate or inaccurate results. Given this fundamental uncertainty, the ability to infer population-level prevalence from random walk-based samples is questionable. Indeed, <xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik (2010)</xref> found very high levels of sampling variance for RDS in simulated sampling using real network data.</p>
<p>In this article, we propose a new approach, “network sampling with memory” (NSM), which builds on recent developments in the mathematics and computer science literatures on sampling large networks that modify the basic random-walk approach by incorporating information on the local topography of the network, information on recently sampled cases, or multiple dependent RWs to improve sampling efficiency (<xref ref-type="bibr" rid="bibr2-0081175012461248">Alon et al. 2008</xref>; <xref ref-type="bibr" rid="bibr5-0081175012461248">Avin and Krishnamachari 2008</xref>; <xref ref-type="bibr" rid="bibr9-0081175012461248">Berenbrink et al. 2010</xref>; <xref ref-type="bibr" rid="bibr20-0081175012461248">Cooper, Frieze, and Radzik 2009</xref>; <xref ref-type="bibr" rid="bibr42-0081175012461248">Ikeda, Kubo and Yamashita 2009</xref>; <xref ref-type="bibr" rid="bibr46-0081175012461248">Kharusi 2008</xref>; <xref ref-type="bibr" rid="bibr64-0081175012461248">Ribeiro and Towsley 2010</xref>). As we discuss in this article, NSM improves the efficiency of sampling from a network by collecting network data from respondents as part of the survey, which is used to gradually reveal the list of population members. As the sample progresses, the list of people who have been nominated in the survey begins to resemble the full list of population members, which allows NSM to approximate the process of SRS.</p>
<p>NSM samples from the network list by using two modes of sampling, a “list” mode and a “search” mode. The list mode is very simple: The next person to be interviewed is selected by sampling with replacement from the list of all people who have been nominated. When a new person is added to the list (i.e., when someone is nominated for the first time), he or she is sampled at the current cumulative sampling rate (CSR, defined below) of the sample to ensure that all individuals who have been nominated have the same probability of being sampled (otherwise, cases that were sampled first would be overrepresented).</p>
<p>The search mode attempts to speed up the process of exploring large or complicated networks by identifying respondents who appear to be “bridge nodes” to unexplored clusters of the network. We define bridge nodes as respondents who have high proportions of friends who have not been nominated by anyone else in the sample collected up until that point. The search mode gives priority to the unsampled friends of these bridge nodes, which pushes the sample toward new and unexplored regions of the network. NSM combines the search and list modes together, using the search mode first until the network has been explored and then switching over to the list mode.</p>
<p>In the analysis section of this article, we test the relative precision and accuracy of NSM compared with RDS and RWs by conducting simulated sampling on 162 actual social networks, 62 school networks from the National Longitudinal Study of Adolescent Health (Add Health) and 100 large university networks from Facebook. The results indicate that NSM results in high levels of sampling precision (with sampling variances close to those of SRS), even on networks characterized by high degrees of clustering and homophily. Overall, we argue that NSM will prove useful for researchers in a variety of fields in which collecting network data on social interaction is substantively interesting and in which it is desirable to use the network data to improve the efficiency and precision of the sampling process.</p>
</sec>
<sec id="section2-0081175012461248">
<title>2. Background</title>
<sec id="section3-0081175012461248">
<title>2.1 Referral-based Sampling of Hidden Populations</title>
<p>Hidden populations are an important area of study for understanding sociological topics such as the dynamics of disease transmission, immigration, the underground economy, and homelessness. They are also a prime area for referral-based sampling approaches because they are demonstrably challenging to survey with other sampling approaches (<xref ref-type="bibr" rid="bibr45-0081175012461248">Kendall et al. 2008</xref>). Recently, the use of referral-based sampling methods in the study of hidden populations has been accompanied by important theoretical and statistical developments (<xref ref-type="bibr" rid="bibr38-0081175012461248">Heckathorn 1997</xref>, <xref ref-type="bibr" rid="bibr39-0081175012461248">2002</xref>, <xref ref-type="bibr" rid="bibr40-0081175012461248">2007</xref>; <xref ref-type="bibr" rid="bibr53-0081175012461248">Magnani et al. 2005</xref>; <xref ref-type="bibr" rid="bibr58-0081175012461248">McKnight et al. 2006</xref>; <xref ref-type="bibr" rid="bibr66-0081175012461248">Salganik and Heckathorn 2004</xref>). The key innovation, RDS, builds on the idea of taking a “random walk” on a network and has two properties that make it useful for sampling hidden populations. The first has to do with the recruitment process. In RDS, respondents are paid for their participation in the study and incentivized to recruit others. Such incentives take the form of coupons, a fixed number of which are given to members of the current wave of respondents. New respondents must present coupons obtained from prior respondents to enter the study. The use of coupons allows the tracking of recruitment chains, the payment of respondents for recruiting new members, and the maintenance of a high degree of confidentiality with minimal risk for participants and researchers (<xref ref-type="bibr" rid="bibr75-0081175012461248">Yeka et al. 2006</xref>).</p>
<p>The second important property of RDS for sampling purposes is a statistical innovation. Respondents are asked to estimate how many people they know in the hidden population, and the inverse of each person’s estimate is then used as a sampling weight. It has been shown (<xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik 2009</xref>; <xref ref-type="bibr" rid="bibr66-0081175012461248">Salganik and Heckathorn 2004</xref>; <xref ref-type="bibr" rid="bibr71-0081175012461248">Volz and Heckathorn 2008</xref>) that such weighting is a mathematically appropriate technique for characterizing recruitment probabilities in a sample from a network if respondents are able to estimate their popularity with reasonable accuracy (cf. <xref ref-type="bibr" rid="bibr60-0081175012461248">Neely 2009</xref> for how errors in this estimation influence RDS estimates).</p>
<p>RDS has become quite popular: <xref ref-type="bibr" rid="bibr44-0081175012461248">Johnston et al. (2006)</xref> cited 128 applications in countries outside of the United States, and the Centers for Disease Control and Prevention have adopted the method on a large scale to understand the dynamics of HIV in the American injection drug user community (<xref ref-type="bibr" rid="bibr1-0081175012461248">Abdul-Quader et al. 2006</xref>). As a measure of the level of endorsement of RDS by funding agencies, a search of recent National Institutes of Health grants indicates that at least $100 million in funding has been awarded to projects with “respondent driven sampling” and its variants in the keywords (<xref ref-type="bibr" rid="bibr59-0081175012461248">National Institutes of Health 2011</xref>). Overall, the recent popularity of RDS has made it the “gold standard” against which competing proposals to understand hidden and hard to reach populations (e.g., time-location sampling, targeted sampling) are evaluated.</p>
<p>However, although methods to sample hidden and hard-to-reach populations have overcome many of the challenges facing referral-based sampling, they have generated a new set of criticisms. Most critiques have focused on the unrealistic nature of the method’s assumptions (<xref ref-type="bibr" rid="bibr28-0081175012461248">Gile and Handcock 2010</xref>; <xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik 2009</xref>), though new approaches show that modifications to the method can make it less dependent on some of these (e.g., <xref ref-type="bibr" rid="bibr29-0081175012461248">Gile 2011</xref>; <xref ref-type="bibr" rid="bibr60-0081175012461248">Neely 2009</xref>). Although these are important problems, the most damaging critique is that the method is highly ineffective, even when assumptions are met. The problem is that referral-based approaches, although providing unbiased mean estimates, yield far more variable results than traditional survey sampling (<xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik 2009</xref>). This necessitates collecting larger sample sizes with referral-based sampling than would be needed from random sampling to maintain the same level of statistical power. Perhaps the most important evidence of this effect comes from an innovative study that simulated respondent-driven samples on real-world social networks (<xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik 2010</xref>). There, the authors found that results from RDS were up to 70 times more variable than would be found had comparably sized simple random samples been taken (also see <xref ref-type="bibr" rid="bibr51-0081175012461248">Lu et al. 2012</xref>). Such simulation evidence accords with other studies. For instance, repeated respondent-driven samples of the same population have shown substantial variability in socially salient traits (<xref ref-type="bibr" rid="bibr52-0081175012461248">Ma et al. 2007</xref>), and the confidence intervals of respondent-driven samples from known populations do not always not contain the true population values and can often be too wide to be of use (<xref ref-type="bibr" rid="bibr72-0081175012461248">Wejnert 2009</xref>; <xref ref-type="bibr" rid="bibr73-0081175012461248">Wejnert and Heckathorn 2008</xref>; see discussion in <xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik 2010</xref>). Of course, a large number of surveys conducted by those with deep familiarity with the populations at hand have found that RDS results are often quite reasonable (cf. <xref ref-type="bibr" rid="bibr54-0081175012461248">Malekinejad et al. 2008</xref>). However, as demonstrated by the simulation studies, there is the danger that any given RDS estimates may be far from the true population value.</p>
</sec>
<sec id="section4-0081175012461248">
<title>2.2 Network-based Sampling in Nonhuman Populations</title>
<p>Other fields have also been active in developing new network-based sampling methods. As mentioned above, a large literature has focused on the properties of RWs on graphs. <xref ref-type="bibr" rid="bibr7-0081175012461248">Bassetti and Diaconis (2006)</xref> derived the variance of an RW on the basis of a spectral decomposition of the network structure, and <xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik (2009)</xref> related this to the variance of RDS estimates. More generally, this literature (cf. <xref ref-type="bibr" rid="bibr50-0081175012461248">Lovasz 1993</xref> for a review) is focused on the mixing time (the number of steps until the sampling probabilities converge) and cover time (the time needed until all nodes are sampled) of RWs on graphs. There is a direct connection between the accuracy of a sample derived from an RW and the mixing and cover time, because the more steps that are needed, on average, to reach the equilibrium sampling distribution or to sample all of the cases, the less accurate that any given size sample will be compared with SRS. In computer science, a rapidly expanding literature focuses on practical aspects of improving the speed and accuracy of RWs to sample from the Internet, but other examples include sampling from electrical networks and map exploration (e.g., <xref ref-type="bibr" rid="bibr27-0081175012461248">Gasieniec and Radzik 2008</xref>).</p>
<p><xref ref-type="bibr" rid="bibr5-0081175012461248">Avin and Krishnamachari (2008)</xref> proposed a modification to the random-walk strategy in which, at each step, neighbors of the current node are queried, and the one with the fewest visits from the RW is selected as the next step. At each step, this pushes the RW back to nodes whose neighbors are least likely to have been explored. In a related approach, <xref ref-type="bibr" rid="bibr9-0081175012461248">Berenbrink et al. (2010)</xref> and <xref ref-type="bibr" rid="bibr76-0081175012461248">Yu and Newman (2008)</xref> allow the RW to explore the network in the vicinity of the current case before taking the next step. This collection of local information helps the walker know whether it is in a well-explored cluster or a new area. Alternatively, one can use multiple networks derived from the multiplex connections that link people to move between different parts of the network: <xref ref-type="bibr" rid="bibr30-0081175012461248">Gjoka et al. (2010)</xref> showed that problems of sampling between segregated or disconnected components of large online social networks can be reduced by using multiple types of connections between users (i.e., group or event participation), even if there is no sample frame. If there is some means of obtaining a list of nodes in the network, <xref ref-type="bibr" rid="bibr68-0081175012461248">Thompson (2006)</xref>, <xref ref-type="bibr" rid="bibr65-0081175012461248">Ribeiro, Wang, and Towsley (2010)</xref>, and <xref ref-type="bibr" rid="bibr6-0081175012461248">Avrachenkov, Ribeiro, and Towsley (2010)</xref> proposed an adaptive RW, whereby an RW is supplemented by periodic jumps to randomly selected parts of the network; a similar method was pioneered by Google to rank Web pages (<xref ref-type="bibr" rid="bibr14-0081175012461248">Brin and Page 1998</xref>). Such approaches have been shown to reduce the number of cases needed to sample the network effectively.</p>
<p>A simple modification of the basic RW is to provide a temporary restriction on nodes that can be visited. <xref ref-type="bibr" rid="bibr46-0081175012461248">Kharusi (2008)</xref> proposed an RW with memory—a “forward RW”—on the basis of preventing the walk from returning to the <italic>k</italic> most recently visited cases and found that cover times decreased dramatically compared with simple RWs in networks with high diameter (the distance between the most separated nodes of the network). Similarly, <xref ref-type="bibr" rid="bibr3-0081175012461248">Alon et al. (2007)</xref> found an improvement in the mixing rate by not allowing the walk to go back to the most recently sampled case.</p>
<p>A slightly different approach uses information about a node’s neighbors to tilt the selection probabilities in favor of visiting certain types of nodes. <xref ref-type="bibr" rid="bibr41-0081175012461248">Ikeda et al. (2003</xref>, <xref ref-type="bibr" rid="bibr42-0081175012461248">2009</xref>) showed that the cover time of an RW can be reduced by modifying the transition matrix to oversample low-degree neighbors of the current node. <xref ref-type="bibr" rid="bibr42-0081175012461248">Ikeda et al. (2009)</xref>, for example, showed that under certain conditions, the cover time for an RW can be reduced from <italic>O</italic>(<italic>G</italic><sup>3</sup>) to <italic>O</italic>(<italic>G</italic><sup>2</sup>) (where <italic>G</italic> is the number of nodes in the network) by using a biased transition matrix that weights the probability of selection of a node proportional to the inverse square root of its degree.</p>
<p>Finally, an alternative approach is to use multiple independent RWs rather than a single RW. In human populations, this is roughly comparable with starting RWs from multiple seeds. The use of multiple RWs has been found to reduce cover times (<xref ref-type="bibr" rid="bibr2-0081175012461248">Alon et al., 2008</xref>; <xref ref-type="bibr" rid="bibr20-0081175012461248">Cooper et al. 2009</xref>; <xref ref-type="bibr" rid="bibr24-0081175012461248">Elasser and Sauerwald 2010</xref>), but it is still possible for each individual RW to get stuck in subgraphs of the overall network. <xref ref-type="bibr" rid="bibr64-0081175012461248">Ribeiro and Towsley (2010)</xref> proposed an approach based on multiple dependent RWs, in which the multiple walks share the same sampling process, and showed that this approach has a faster mixing time than multiple independent walks and single RWs in simulations on several large social media networks.<sup><xref ref-type="fn" rid="fn2-0081175012461248">2</xref></sup></p>
<p>An important difference between this recent literature on improved random-walk algorithms in large networks such as the Internet, mobile networks, and electrical grids and sampling from human populations is the cost of an interview. In the former, the cost of each interview (i.e., querying a node of the network) is small, often a matter of nanoseconds of computer time. Instead, the size of the underlying networks is the key issue, and computers’ memory restrictions place limits on the collection and processing of topographic network information for large sample sizes. As a result, most of the articles discussed focus on how little extra information and memory is needed per case to improve the sampling efficiency. In contrast, in sampling from human populations, the cost in terms of time and effort in obtaining and conducting face-to-face or telephone interviews represents the key constraint, and as a result, the overall sample size may be small. This is important because the efficacy of sampling from human social networks cannot rely on surveying a large number of people; indeed, the approaches used in computer science and elsewhere to reduce cover and mixing times seem like a good starting place for devising a new approach to sampling from social networks that performs well in finite samples.</p>
<p>In the next section, we build on this recent literature in computer science to propose a method for sampling from a network that uses the collection of social network data to retain a “memory” of the network and improve the efficiency of the sampling process. At the end of the article, we argue, on the basis of classic (e.g., <xref ref-type="bibr" rid="bibr15-0081175012461248">Burt 1984</xref>; <xref ref-type="bibr" rid="bibr55-0081175012461248">McCallister and Fischer 1978</xref>) and contemporary work on interviewing people about networks (e.g., <xref ref-type="bibr" rid="bibr67-0081175012461248">Sandberg et al. 2008</xref>), that collecting data on a large number of respondents’ alters is feasible in sampling from human populations and that the gains in sampling accuracy and efficiency outweigh the added cost of the collection of network data.</p>
</sec>
</sec>
<sec id="section5-0081175012461248" sec-type="methods">
<title>3. Method</title>
<p>A key consideration of our approach is that we want a method that has desirable asymptotic and finite sample properties: Not only do we want a method that is asymptotically unbiased (like RW-based approaches such as RDS when its assumptions are met), but we want the sampling variance and mean absolute bias (MAB) to decline rapidly in the kinds of finite sample sizes actually collected in practice when sampling from human populations. In this section, we outline our proposed solution, which consists of two different modes of sampling: a list mode that guarantees asymptotic unbiased estimates and a search mode that is designed to work in tandem with the list mode to improve the precision of estimates in finite samples. To clarify the presentation of our method, <xref ref-type="table" rid="table1-0081175012461248">Table 1</xref> provides a glossary of terms used in this section of the article. In addition, in section 3.B.2 below, we provide an example of a sample drawn using the list mode to illustrate the basic mechanics that are involved.</p>
<table-wrap id="table1-0081175012461248" position="float">
<label>Table 1.</label>
<caption>
<p>Glossary of Terms Used</p>
</caption>
<graphic alternate-form-of="table1-0081175012461248" xlink:href="10.1177_0081175012461248-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Term</th>
<th align="center">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>List mode</td>
<td>The process of evenly sampling from the list L of nodes that have been nominated (see section 3.B).</td>
</tr>
<tr>
<td>Even sampling</td>
<td>Sampling all nominated nodes (all nodes ∈<italic>L</italic>) at the same rate. Newly nominated nodes are sampled at the current cumulative sampling rate of the existing sample (see section 3.B).</td>
</tr>
<tr>
<td>Search mode</td>
<td>Using bridge nodes to sample unexplored clusters of the network (see section 3.C).</td>
</tr>
<tr>
<td>Hybrid approach</td>
<td>The combination of the list and search modes (see section 3.C).</td>
</tr>
<tr>
<td>A</td>
<td>The population that is being sampled.</td>
</tr>
<tr>
<td>G</td>
<td>Number of nodes (people) in the network connecting population A.</td>
</tr>
<tr>
<td><inline-formula id="inline-formula1-0081175012461248">
<mml:math display="inline" id="math1-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>P</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>The estimated size of the network using the capture-recapture method (see <xref ref-type="disp-formula" rid="disp-formula5-0081175012461248">equation 5</xref>).</td>
</tr>
<tr>
<td>S</td>
<td>The current “step” of the sample: the number of interviews that have been completed.</td>
</tr>
<tr>
<td>L</td>
<td>The list of nodes/people that have been nominated by respondents on the network rosters.</td>
</tr>
<tr>
<td><italic>L</italic><sub><italic>S</italic></sub></td>
<td>The number of nodes that have been nominated by step S of the sample.</td>
</tr>
<tr>
<td><italic>E</italic><sub><italic>S</italic></sub></td>
<td>The number of nodes eligible for sampling via the list mode in step S of the sample (see section 3.B.1).</td>
</tr>
<tr>
<td>P1</td>
<td>The proportion of nominated nodes ∈<italic>L</italic> that have been nominated once and only once in the sample.</td>
</tr>
<tr>
<td>S1</td>
<td>The step that even sampling begins for the list mode (see section 3.B).</td>
</tr>
<tr>
<td><italic>CSR</italic><sub><italic>j</italic></sub></td>
<td>The cumulative sampling rate for node j (see <xref ref-type="disp-formula" rid="disp-formula2-0081175012461248">equation 2</xref>).</td>
</tr>
<tr>
<td><italic>ESR</italic></td>
<td>The even sampling rate. The cumulative sampling rate since the start of even sampling (see <xref ref-type="disp-formula" rid="disp-formula3-0081175012461248">equation 3</xref>).</td>
</tr>
<tr>
<td><italic>d</italic><sub><italic>i</italic></sub></td>
<td>The degree of node i. This is the number of friends that node I has in population A.</td>
</tr>
<tr>
<td>p_nom<sub>
<italic>i</italic></sub></td>
<td>The probability that node i has been nominated after S steps.</td>
</tr>
<tr>
<td>Bridge node</td>
<td>A node connecting different clusters of the network.</td>
</tr>
<tr>
<td><italic>c</italic><sub><italic>j</italic></sub></td>
<td>The number of j’s friends who have been nominated once and only once in the sample.</td>
</tr>
<tr>
<td><inline-formula id="inline-formula2-0081175012461248">
<mml:math display="inline" id="math2-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td>The proportion of j’s friends who have been nominated 1 time in the sample.</td>
</tr>
<tr>
<td>A1</td>
<td>The minimum level of P1 for the use of the search mode. If P1 &gt; A1, use the search mode; if <italic>P</italic>1 ≤<italic>A</italic>1, use the list mode. A1 = 0.4 is used in the sampling simulations.</td>
</tr>
<tr>
<td>Average bias</td>
<td>The degree to which the sample means differs from the population mean, averaged across all replications (see <xref ref-type="disp-formula" rid="disp-formula12-0081175012461248">equations 11</xref> and <xref ref-type="disp-formula" rid="disp-formula13-0081175012461248">12</xref>).</td>
</tr>
<tr>
<td>Mean absolute bias (MAB)</td>
<td>The expected magnitude of the bias on any single replication (see <xref ref-type="disp-formula" rid="disp-formula14-0081175012461248">equation 13</xref>).</td>
</tr>
<tr>
<td>Sampling variance</td>
<td>How much variance there is in the sample estimates (see <xref ref-type="disp-formula" rid="disp-formula16-0081175012461248">equation 15</xref>).</td>
</tr>
<tr>
<td>Design effect (DE)</td>
<td>The ratio of the sampling variance of the method to the sampling variance of SRS (see <xref ref-type="disp-formula" rid="disp-formula17-0081175012461248">equation 16</xref>).</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>First, imagine that we are sampling from a population, A, that consists of G individuals (“nodes”) who are connected through a social network. We assume that there is no sampling frame; that is, there is no list of the N members of the population that would allow for SRS. The basic intuition of our approach is quite simple: We use the sampling process to uncover the list of population members and then sample from that list with replacement.<sup><xref ref-type="fn" rid="fn3-0081175012461248">3</xref></sup> We call our approach “network sampling with memory” because we use name and demographic data on respondents’ network members to “remember” the network; however, other types of data about network alters could be collected (e.g., <xref ref-type="bibr" rid="bibr21-0081175012461248">Dombrowski et al. 2011</xref>).</p>
<p>The survey begins with an initial “seed” respondent.<sup><xref ref-type="fn" rid="fn4-0081175012461248">4</xref></sup> Each step in the sampling process consists of an interview with a respondent that, in addition to the substantive survey questions, asks for a network roster of the respondent’s friends or contacts who are members of population A. In each step, new network members are added to list L, which consists of all members of A who have been nominated by a respondent.<sup><xref ref-type="fn" rid="fn5-0081175012461248">5</xref></sup> L also keeps track of the cumulative number of nominations each node has received. Let S indicate the current “step” of the sample (i.e., the number of interviews that have been completed), and let L<sub>S</sub> indicate the number of people on the network roster L at step S.</p>
<sec id="section6-0081175012461248">
<title>3.1 List and Search Sampling Modes</title>
<p>NSM consists of two sampling modes, list and search. It is easiest to describe these sampling modes by beginning with what we call the “naive list” mode of sampling from the network roster.</p>
<sec id="section7-0081175012461248">
<title>3.1.A. Naive List Mode</title>
<p>In the naive list mode we sample with replacement from the accumulated network roster L. The probability that a nominated node is sampled at step S is</p>
<p>
<disp-formula id="disp-formula1-0081175012461248">
<mml:math display="block" id="math3-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>sampled</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>L</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>S</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0081175012461248" xlink:href="10.1177_0081175012461248-eq1.tif"/>
</disp-formula></p>
<p>where L<sub>S</sub> is the currently revealed size of the revealed network.</p>
<p>The problem with the naive list mode is that nodes that are nominated early in the sample will be oversampled compared with nodes that are nominated later, because the early nodes are eligible to be sampled for more steps. As early nodes are oversampled, this slows down the process of exploring the network.</p>
</sec>
<sec id="section8-0081175012461248">
<title>3.1.B. List Mode and “Even” Sampling</title>
<p>To prevent the problem of oversampling nodes that are nominated early in the sample, the list mode ensures equal sampling probabilities by sampling new nodes (i.e., people who are added to L when they are nominated for the first time) at the same CSR as previously nominated nodes. This “even sampling” starts once the revealed network L reaches a certain size: let L<sub>S</sub> indicate the currently revealed size of the network after S interviews, and let P1 equal the proportion of nominated nodes (L) that have been nominated once and only once so far in the sample. In the simulations that we conducted for this article, the even sampling of new nodes begins when either L<sub>S</sub>≥ 200 or <italic>S</italic> &gt; 50 and P1 &lt; .2 (this ensures that the list mode is turned on for small networks). Let S1 indicate the step at which even sampling begins. When S &gt; S1, nodes that are nominated for the first time in step S are subjected to the same sampling rates experienced by previously nominated nodes from step S1 to S. A node that is interviewed in this way is called a “catch-up” interview, because it was interviewed while its CSR was “catching up” to the rest of the sample. In the next subsection, we describe this process more precisely.</p>
<sec id="section9-0081175012461248">
<title>3.1.B.1. Even sampling and catch-up interviews</title>
<p>Let Q be a node that is nominated for the first time in step S, let U<sub>Z</sub> be a uniform random number between 0 and 1, and let Z = {S1, S1 + 1, . . . S} indicate the steps from S1 to the current step S, excluding steps that were catch-up interviews themselves (see steps 80 to 82 in <xref ref-type="table" rid="table2-0081175012461248">Table 2</xref> for an example). We “retroactively” sample node Q in step Z if <inline-formula id="inline-formula3-0081175012461248">
<mml:math display="inline" id="math4-0081175012461248">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>U</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>Z</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>&lt;</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>E</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>Z</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, where E<sub>Z</sub> is the number of nodes that were eligible to be sampled in step Z (see the following definition of the set of eligible nodes), repeating this process for all steps Z from S1 to S. The benefit of doing this is that it reduces the advantage that earlier nodes have of being oversampled compared with nodes that are added to L later in the sample.</p>
<table-wrap id="table2-0081175012461248" position="float">
<label>Table 2.</label>
<caption>
<p>Example of Sampling from the Test Network Using the List Mode: Step-by-step sampling rates</p>
</caption>
<graphic alternate-form-of="table2-0081175012461248" xlink:href="10.1177_0081175012461248-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th/>
<th/>
<th/>
<th align="center" colspan="4">Cumulative Sampling Rate (CSR) of Nodes<sup><xref ref-type="table-fn" rid="table-fn2-0081175012461248">a</xref></sup><hr/></th>
<th/>
</tr>
<tr>
<th align="left">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">7</th>
<th align="center">8</th>
<th align="center">9</th>
<th align="center">10</th>
</tr>
<tr>
<th align="left">“Step”</th>
<th align="center">Revealed Network Size (L)</th>
<th align="center">Number of Eligible Nodes</th>
<th align="center">ESR</th>
<th align="center">Sampling Rate for Step</th>
<th align="center">Node 1</th>
<th align="center">Node 101</th>
<th align="center">Node 201</th>
<th align="center">Node 301</th>
<th align="center">ID of Interviewed Node</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>NA</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>92 “seed”</td>
</tr>
<tr>
<td>1</td>
<td>8</td>
<td>8</td>
<td>0</td>
<td>0.125</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>25</td>
</tr>
<tr>
<td>2</td>
<td>14</td>
<td>14</td>
<td>0</td>
<td>0.071429</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>76</td>
</tr>
<tr>
<td>3</td>
<td>20</td>
<td>20</td>
<td>0</td>
<td>0.05</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>21</td>
</tr>
<tr>
<td>4</td>
<td>22</td>
<td>22</td>
<td>0</td>
<td>0.045</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>23</td>
</tr>
<tr>
<td>5</td>
<td>25</td>
<td>25</td>
<td>0</td>
<td>0.04</td>
<td>0.04</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>14</td>
</tr>
<tr>
<td colspan="10">After 5 steps, the revealed network size is 25 (i.e., 25 different nodes have been nominated). Node 1 is nominated for the first time in step 5, and node 301 is nominated for the first time in step 7.</td>
</tr>
<tr>
<td>6</td>
<td>46</td>
<td>46</td>
<td>0</td>
<td>0.021739</td>
<td>0.061739</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>378</td>
</tr>
<tr>
<td>7</td>
<td>63</td>
<td>63</td>
<td>0</td>
<td>0.015873</td>
<td>0.077612</td>
<td>0</td>
<td>0</td>
<td>0.015873</td>
<td>323</td>
</tr>
<tr>
<td>8</td>
<td>68</td>
<td>68</td>
<td>0</td>
<td>0.014706</td>
<td>0.092318</td>
<td>0</td>
<td>0</td>
<td>0.030579</td>
<td>56</td>
</tr>
<tr>
<td>9</td>
<td>73</td>
<td>73</td>
<td>0</td>
<td>0.013699</td>
<td>0.106017</td>
<td>0</td>
<td>0</td>
<td>0.044278</td>
<td>15</td>
</tr>
<tr>
<td colspan="10">After 39 steps, nodes 1 and 301 have large CSRs. They will be temporarily excluded from the pool of eligible nodes once even sampling is turned on, until their CSR is less than or equal to the ESR.</td>
</tr>
<tr>
<td>39</td>
<td>194</td>
<td>194</td>
<td>0</td>
<td>0.005155</td>
<td>0.323978</td>
<td>0</td>
<td>0</td>
<td>0.262239</td>
<td>322</td>
</tr>
<tr>
<td>40</td>
<td>199</td>
<td>199</td>
<td>0</td>
<td>0.005025</td>
<td>0.329004</td>
<td>0</td>
<td>0</td>
<td>0.267264</td>
<td>81</td>
</tr>
<tr>
<td>41</td>
<td>203</td>
<td>100</td>
<td>0.01</td>
<td>0.01</td>
<td>0.329004</td>
<td>0</td>
<td>0</td>
<td>0.267264</td>
<td>79</td>
</tr>
<tr>
<td colspan="10">“Even sampling” is turned on in step 41 because the network size is &gt;200. Now, all newly nominated nodes are sampled at the current ESR. Node 101 is nominated for the first time in step 43.</td>
</tr>
<tr>
<td>42</td>
<td>211</td>
<td>100</td>
<td>0.02</td>
<td>0.01</td>
<td>0.329004</td>
<td>0</td>
<td>0</td>
<td>0.267264</td>
<td>138</td>
</tr>
<tr>
<td>43</td>
<td>213</td>
<td>100</td>
<td>0.03</td>
<td>0.01</td>
<td>0.329004</td>
<td>0.03</td>
<td>0</td>
<td>0.267264</td>
<td>177</td>
</tr>
<tr>
<td>44</td>
<td>218</td>
<td>100</td>
<td>0.04</td>
<td>0.01</td>
<td>0.329004</td>
<td>0.04</td>
<td>0</td>
<td>0.267264</td>
<td>122</td>
</tr>
<tr>
<td colspan="10">After 44 steps, the ESR is 0.04. Nodes 1 and 301 are still excluded from sampling eligibility because their CSR is greater than the cumulative ESR.</td>
</tr>
<tr>
<td>79</td>
<td>357</td>
<td>270</td>
<td>0.205092</td>
<td>0.003704</td>
<td>0.329004</td>
<td>0.205092</td>
<td>0</td>
<td>0.267264</td>
<td>199</td>
</tr>
<tr>
<td>80</td>
<td>358</td>
<td>NA</td>
<td>0.205092</td>
<td/>
<td>0.329004</td>
<td>0.205092</td>
<td>0</td>
<td>0.267264</td>
<td>294</td>
</tr>
<tr>
<td>81</td>
<td>364</td>
<td>NA</td>
<td>0.205092</td>
<td/>
<td>0.329004</td>
<td>0.205092</td>
<td>0</td>
<td>0.267264</td>
<td>287</td>
</tr>
<tr>
<td>82</td>
<td>367</td>
<td>NA</td>
<td>0.205092</td>
<td/>
<td>0.329004</td>
<td>0.205092</td>
<td>0.205092</td>
<td>0.267264</td>
<td>217</td>
</tr>
<tr>
<td colspan="10">Node 201 is nominated for the first time in step 82. Steps 80 to 82 are “catch-up” interviews of newly nominated nodes. In Step 251, all 400 nodes have been nominated, and the sample is approximately equivalent to a simple random sample.</td>
</tr>
<tr>
<td>248</td>
<td>399</td>
<td>399</td>
<td>0.633599</td>
<td>0.002506</td>
<td>0.632375</td>
<td>0.633599</td>
<td>0.633599</td>
<td>0.633053</td>
<td>101</td>
</tr>
<tr>
<td>249</td>
<td>399</td>
<td>399</td>
<td>0.636105</td>
<td>0.002506</td>
<td>0.634881</td>
<td>0.636105</td>
<td>0.636105</td>
<td>0.63556</td>
<td>389</td>
</tr>
<tr>
<td>250</td>
<td>399</td>
<td>399</td>
<td>0.638612</td>
<td>0.002506</td>
<td>0.637388</td>
<td>0.638612</td>
<td>0.638612</td>
<td>0.638066</td>
<td>300</td>
</tr>
<tr>
<td>251</td>
<td>400</td>
<td>400</td>
<td>0.641112</td>
<td>0.0025</td>
<td>0.639888</td>
<td>0.641112</td>
<td>0.641112</td>
<td>0.640566</td>
<td>275</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0081175012461248">
<p><italic>Notes</italic>: CSR = cumulative sampling rate; ESR = even sampling rate; NA = not applicable.</p>
</fn>
<fn id="table-fn2-0081175012461248">
<label>a.</label>
<p>The inverse of this rate is used as a sampling weight; see section 3.B.3.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The reason we choose L<sub>S</sub>≥ 200 as the starting point for the sampling of new nodes is that if even sampling begins when the network size is too small, the sampling rate of catch-up interviews quickly becomes very large. On the basis of the results of simulated sampling discussed below on networks ranging in size from 110 to 16,278 nodes, L<sub>S</sub>≥ 200 worked very well, although other thresholds above or below 200 could also work. In general, for networks that are larger than the ones that we evaluate in this article, L<sub>S</sub> should be set higher to ensure that the even sampling rate (ESR) does not get too large too quickly.<sup><xref ref-type="fn" rid="fn6-0081175012461248">6</xref></sup> Moreover, in very large networks, the hybrid approach (which combines the search and list modes, discussed below) works the best, as demonstrated by the results presented later in this article.</p>

<p>In addition to ensuring that all nodes sampled after S1 are sampled at the same rate, we also want to equalize the CSR of nodes that were sampled before S1. After even sampling is turned on in step S1, we do this by excluding nodes that have high cumulative sampling probabilities until the rest of the sample catches up to them. Define each node’s CSR as</p>
<p>
<disp-formula id="disp-formula2-0081175012461248">
<mml:math display="block" id="math5-0081175012461248">
<mml:mrow>
<mml:mi>“</mml:mi>
<mml:mtext>cumulative sampling rate</mml:mtext>
<mml:mi>”</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>CS</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>R</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>j</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mtext>S</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mtext>a</mml:mtext>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mtext>S</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mtext>b</mml:mtext>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>E</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>S</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mtext>if</mml:mtext>
<mml:mspace width="0.5em"/>
<mml:mi>j</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mtext>eligible node</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>s</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0081175012461248" xlink:href="10.1177_0081175012461248-eq2.tif"/>
</disp-formula></p>
<p>where a is the step that node j was first nominated, b is the current step, “j ∈ eligible nodes<sub>S</sub>” indicates that node j was eligible to be sampled at step S, and E<sub>S</sub> is the number of nominated nodes eligible to be sampled in step S.</p>
<p>The sum of the step-by-step sampling rates since the initiation of even sampling is the ESR defined in <xref ref-type="disp-formula" rid="disp-formula3-0081175012461248">equation 3</xref> (for an example of the calculation of the ESR, see <xref ref-type="table" rid="table2-0081175012461248">Table 2</xref>). We exclude catch-up interviews in the calculation of the ESR:</p>
<p>
<disp-formula id="disp-formula3-0081175012461248">
<mml:math display="block" id="math6-0081175012461248">
<mml:mrow>
<mml:mi>“</mml:mi>
<mml:mtext>even sampling rate</mml:mtext>
<mml:mi>”</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ESR</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mtext>S</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mtext>S</mml:mtext>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mtext>S</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mtext>b</mml:mtext>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>E</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>S</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mtext>S</mml:mtext>
<mml:mo>∉</mml:mo>
<mml:mi>“</mml:mi>
<mml:mtext>catch-up interview</mml:mtext>
<mml:mi>”</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0081175012461248" xlink:href="10.1177_0081175012461248-eq3.tif"/>
</disp-formula></p>
<p>To even out the sampling rate of early nodes, after step S1, we temporarily exclude any node j from the set of nodes that are eligible to be sampled in step S if CSR<sub>j</sub> &gt; ESR. These nodes are not eligible for sampling until the ESR increases. If there are fewer than 100 nodes where CSR<sub>j</sub>≤ ESR, then the list of eligible nodes at step S consists of the 100 nodes with the lowest CSR<sub>j</sub>.</p>
<list id="list1-0081175012461248" list-type="simple">
<list-item>
<p><bold>Definition of E<sub>S</sub>:</bold> On the basis of <xref ref-type="disp-formula" rid="disp-formula2-0081175012461248">equations 2</xref> and <xref ref-type="disp-formula" rid="disp-formula3-0081175012461248">3</xref>, we define E<sub>S</sub> as the set of nodes eligible to be sampled by the list node in step S, which consists of all nominated nodes that have CSR<sub>j</sub>≤ ESR unless the total number of nominated nodes with CSR<sub>j</sub>≤ ESR is less than 100, in which case E<sub>S</sub> consists of the 100 nodes with the lowest CSR.</p>
</list-item>
</list>
<p>In summary, we list the sequence of steps involved in the list mode:</p>
<list id="list2-0081175012461248" list-type="simple">
<list-item>
<p>B1. Randomly select the next node to interview from L, sampling with replacement. If even sampling has been turned on (S ≥ S1), then only nodes ∈<italic>E</italic><sub><italic>S</italic></sub> are eligible to be sampled. Let W indicate the node that is selected in step B1.</p>
</list-item>
<list-item>
<p>B2. Interview node W, and update the network roster L.</p>
</list-item>
<list-item>
<p>B3. If even sampling has been turned on, use the catch-up procedure described in section 3.B.1 to see if any newly nominated nodes are randomly selected to be interviewed. If a new node is selected, this newly nominated node now becomes node W. Go to step B2.</p>
</list-item>
<list-item>
<p>B4. Return to step B1 until the desired sample size has been reached.</p>
</list-item>
</list>
</sec>
<sec id="section10-0081175012461248">
<title>3.1.B.2. Example of sampling using the list mode</title>
<p>To illustrate how the list mode works in practice, <xref ref-type="table" rid="table2-0081175012461248">Table 2</xref> describes the sampling process for a single sample drawn from the 400-node test network, which is discussed in detail below. <xref ref-type="table" rid="table2-0081175012461248">Table 2</xref> consists of 10 columns of information about each step of the sample. Column 1 shows the step number, and column 10 shows the ID of the node that was interviewed in that step. The current size of the revealed network, L (column 2), is updated after the interview and shown in the next step. For example, the sample begins with step 0, which is the initial seed (node 92). Node 92 has 7 friends in the network, so the size of the revealed network as we begin step 1 is 8 (the seed node + 7 friends), and the effective sampling rate for Step 1 is <inline-formula id="inline-formula4-0081175012461248">
<mml:math display="inline" id="math7-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>125</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> (column 5). By step 5, a total of 25 different nodes have been nominated (L = 25), and the sampling rate for step 5 is 0.04.</p>
<p>Columns 6 to 9 show the CSR of four of the nodes in the network (ID numbers 1, 101, 201, and 301). Node 1 is nominated for the first time by node 23 in step 4 and is eligible to be sampled for the first time in step 5 (hence, its CSR in step 5 is 0.04). Node 301 is eligible to be sampled for the first time in step 7. Note that because nodes 1 and 301 were nominated early in the sample, they accumulate a higher CSR compared with nodes 101 and 201. By step 39, for example, the CSR for node 1 is 0.323978, while nodes 101 and 201 have yet to be nominated by any of the nodes that have been interviewed so far.</p>
<p>In step 41, even sampling is turned on because the revealed network size is greater than 200. Now, all nodes that are nominated for the first time will be sampled at the ESR defined above in <xref ref-type="disp-formula" rid="disp-formula3-0081175012461248">equation 3</xref>. After the start of even sampling, only nodes with CSR (columns 6 to 9) less than or equal to the ESR (column 4) are eligible for sampling. In this example, nodes 1 and 301 are temporarily excluded from sampling starting in step 41. The only exception to this is right after the start of even sampling if there are fewer than 100 nodes with CSR ≤ ESR. In this case, the 100 nodes with the lowest CSR are eligible to be sampled.<sup><xref ref-type="fn" rid="fn7-0081175012461248">7</xref></sup></p>
<p>By Step 79, the number of revealed nodes is 357, and the ESR has risen to 0.205092, which means that newly nominated nodes have about a 20 percent chance of being interviewed. On the basis of random draws using the process described in section 3.B.1, steps 80 to 82 resulted in catch-up interviews for which nodes that were nominated for the first time were randomly selected to be interviewed themselves. The benefit of this procedure, in addition to ensuring a gradual even sampling of the network, is that the sample gets pushed toward newly discovered parts of the network.</p>
<p>Finally, in step 251, all of the nodes in the network have been nominated, and the CSR of all nodes is equal to the ESR or, for nodes that were temporarily excluded from sampling eligibility, slightly less than the ESR. In <xref ref-type="table" rid="table2-0081175012461248">Table 2</xref>, nodes 101 and 201 have a CSR equal to the ESR (0.641112), while the two nodes that were nominated early in the sample are slightly lower (0.63988 for node 1 and 0.640566 for node 301).<sup><xref ref-type="fn" rid="fn8-0081175012461248">8</xref></sup> The key point is that in step 251, the entire network has been revealed by the survey and all nodes have been “evenly” sampled, just as if they had been sampled with SRS, even though no sampling frame was available at the start of the sampling process. In the next subsection, we discuss sampling weights, and later, in section 5, we discuss diagnostics for convergence to SRS when the overall size of the network is unknown.</p>
</sec>
<sec id="section11-0081175012461248">
<title>3.1.B.3. Nomination probability weights for the list mode</title>
<p>If the network has not been completely explored (if not all of the members of population A have been nominated), then high-degree nodes are more likely to have been nominated than low-degree nodes simply because they know more people. We estimate the nomination probability on the basis of degree, assuming a random sampling of nodes. For example, in a 500-node network, the probability that node i of degree <italic>d</italic><sub><italic>i</italic></sub> will be nominated by a respondent in any single interview is <inline-formula id="inline-formula5-0081175012461248">
<mml:math display="inline" id="math8-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>500</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>. Similarly, the cumulative nomination probability for node i after S interviews is</p>
<p>
<disp-formula id="disp-formula4-0081175012461248">
<mml:math display="block" id="math9-0081175012461248">
<mml:mrow>
<mml:mtext>p</mml:mtext>
<mml:mo>_</mml:mo>
<mml:mtext>no</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>m</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>≅</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mtext>G</mml:mtext>
</mml:mrow>
</mml:mfrac>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0081175012461248" xlink:href="10.1177_0081175012461248-eq4.tif"/>
</disp-formula></p>
<p>where G is the number of nodes in the network.</p>
<p>Because G is unknown when we are sampling unknown networks, we estimate G using the capture-recapture method (see <xref ref-type="bibr" rid="bibr21-0081175012461248">Dombrowski et al. 2011</xref> for a discussion of the capture-recapture method from social networks and a data collection strategy similar to that advocated here):</p>
<p>
<disp-formula id="disp-formula5-0081175012461248">
<mml:math display="block" id="math10-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>G</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>P</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0081175012461248" xlink:href="10.1177_0081175012461248-eq5.tif"/>
</disp-formula></p>
<p>where L is the current number of nominated nodes, and P1 is the proportion of nominated nodes that have been nominated one time.<sup><xref ref-type="fn" rid="fn9-0081175012461248">9</xref></sup> See <xref ref-type="disp-formula" rid="disp-formula10-0081175012461248">equations 9</xref> and <xref ref-type="disp-formula" rid="disp-formula11-0081175012461248">10</xref> below for the use of composite weights combining p_nom and the CSR to calculate the sample mean. Note that as the sample size S becomes large, the estimated probability of being nominated from <xref ref-type="disp-formula" rid="disp-formula4-0081175012461248">equation 4</xref> will go to 1 for all nodes.</p>
</sec>
</sec>
<sec id="section12-0081175012461248">
<title>3.1.C. Search Mode</title>
<p>As we will see in the “Results” section, the list mode does a very good job by itself sampling from the Add Health and Facebook networks with a sample size of 500. However, in larger networks, the precision of the samples decreases because it takes longer to explore the network.<sup><xref ref-type="fn" rid="fn10-0081175012461248">10</xref></sup> In this section, we add the search mode, which pushes the sampling process toward unexplored parts of the network. Note that the search mode used here is not the same thing as other searching modes commonly used in graph theory, such as breadth-first or depth-first search.<sup><xref ref-type="fn" rid="fn11-0081175012461248">11</xref></sup> The search mode is not designed to be used by itself but only in combination with the list mode. We call the combination of the search and list modes the “hybrid” approach.</p>
<p>The intuition behind the search mode is based on the idea of a “bridge node” or a “structural hole” (<xref ref-type="bibr" rid="bibr16-0081175012461248">Burt 1995</xref>) that connects two clusters of the network. Imagine that node <italic>Y</italic><sub>1</sub> is in a cluster of the network Y that has not been sampled, except for node <italic>Y</italic><sub>1</sub>. As depicted in <xref ref-type="fig" rid="fig1-0081175012461248">Figure 1</xref>, node <italic>Y</italic><sub>1</sub> links across a bridge to cluster X, which has been extensively sampled. Y1’s friends on the Y side of the bridge have been nominated (by Y1)—so they appear on the network roster L—but they have not been sampled or nominated by any other respondent. These nodes represent the leading edge of an unexplored area of the network. The search mode is designed to sample from the friends of nodes like Y1 that are on the other side of a bridge to an undersampled cluster of the network.</p>
<fig id="fig1-0081175012461248" position="float">
<label>Figure 1.</label>
<caption>
<p>Illustrative network with two clusters</p>
<p><italic>Note</italic>: Hollow nodes are unsampled, and dark nodes are sampled. Circles indicate nodes nominated two or more times, squares indicate nodes nominated one time, and triangles indicate nodes nominated zero times.</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig1.tif"/>
</fig>
<p>Let <italic>d</italic><sub><italic>j</italic></sub> indicate the degree of node j, which is the number of friends that node j has in the network. Let <italic>c</italic><sub><italic>j</italic></sub> indicate the number of j’s friends who are unsampled and have been nominated once and only once so far in the survey. For example, in <xref ref-type="fig" rid="fig1-0081175012461248">Figure 1</xref>, the friends of Y1 on the Y side of the bridge (nodes Y8, Y5, and Y2) have been nominated only by Y1, whereas all nodes on the X side of the bridge that are unsampled (nodes X1, X3, and X8) have all been nominated at least two times. Define the proportion of j’s friends that have been nominated 1 time as <inline-formula id="inline-formula6-0081175012461248">
<mml:math display="inline" id="math11-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>. <italic>p</italic>1<sub><italic>j</italic></sub> is calculated for all nodes in the network that have been sampled so far. In addition to <italic>p</italic>1<sub><italic>j</italic></sub>, we calculate P1 (defined above as the overall proportion of nodes ∈<italic>L</italic> that have only one nomination). Finally, we designate A1 as the minimum value of P1 at which the search mode will be used. When P1 gets low, this means that most of the nodes have been nominated by at least two respondents, which suggests that the network is fairly well explored, and we can use the list mode without sacrificing much in the way of sampling efficiency.</p>
<p>The search mode consists of the following steps:</p>
<list id="list3-0081175012461248" list-type="simple">
<list-item>
<p>C1. (a) Calculate <italic>p</italic>1<sub><italic>j</italic></sub> for all sampled nodes, and (b) calculate P1, the proportion of nominated nodes that have been nominated only one time.</p>
</list-item>
<list-item>
<p>C2. If P1, the overall proportion of nodes ∈<italic>L</italic> with one nomination, is greater than A1, the minimum threshold for the search mode, use the search mode. If <italic>P</italic>1 ≤<italic>A</italic>1, default to the list mode. This ensures that the list mode is used when much of the network has been explored. In the sampling simulations below, we set A1 to 0.4, but we tried other settings as well. Note that the reason we choose to switch to the list mode at a specific point (i.e., when <italic>P</italic>1 ≤<italic>A</italic>1), rather than always use the search mode or “blend” the two modes together, is that the asymptotic properties of the search mode will depend on the structure of the particular network being sampled. In contrast, the list mode converges to SRS as L approaches the true size of the network.</p>
</list-item>
<list-item>
<p>C3. We want to identify bridge nodes (such as Y1 in <xref ref-type="fig" rid="fig1-0081175012461248">Figure 1</xref>) and then interview their unsampled friends who have only one nomination (i.e., nodes Y2, Y5, and Y8 in <xref ref-type="fig" rid="fig1-0081175012461248">Figure 1</xref>). To do this, we will identify the five nodes that are the most likely to be bridges and then sample one of their unsampled network ties. In this step, we calculate the probability that a particular node is a bridge node. To begin with, we argue that bridge nodes are nodes that are the largest positive outliers in terms of their observed value of <italic>c</italic><sub><italic>j</italic></sub>, that is, nodes that have unexpectedly large values of <italic>c</italic><sub><italic>j</italic></sub> given their degree and the current value of P1. First, we estimate the probability node j has <italic>c</italic><sub><italic>j</italic></sub> or more friends with only one nomination (conditional on node j being sampled), given <italic>d</italic><sub><italic>j</italic></sub> and P1, using the binomial distribution</p>
<p>
<disp-formula id="disp-formula6-0081175012461248">
<mml:math display="block" id="math12-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi>L</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>≅</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>P</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msup>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>P</mml:mi>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msup>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0081175012461248" xlink:href="10.1177_0081175012461248-eq6.tif"/>
</disp-formula></p>
</list-item>
<list-item>
<p>where, as noted above, P1 is the overall proportion of nodes ∈<italic>L</italic> with one nomination so far in the sample.</p>
</list-item>
<list-item>
<p>C4. We estimate how “unexpected” the current value of <italic>c</italic><sub><italic>j</italic></sub> is for node j by multiplying the binomial tail probability in <xref ref-type="disp-formula" rid="disp-formula6-0081175012461248">equation 6</xref> by the estimated probability that node j has been nominated by step S of the sample (from <xref ref-type="disp-formula" rid="disp-formula4-0081175012461248">equation 4</xref> above)<sup><xref ref-type="fn" rid="fn12-0081175012461248">12</xref></sup>:</p>
<p>
<disp-formula id="disp-formula7-0081175012461248">
<mml:math display="block" id="math13-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>≅</mml:mo>
<mml:mtext>p</mml:mtext>
<mml:mo>_</mml:mo>
<mml:mtext>no</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>m</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>×</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi>L</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0081175012461248" xlink:href="10.1177_0081175012461248-eq7.tif"/>
</disp-formula></p>
</list-item>
<list-item>
<p>C5. Finally, we define the relative probability of node j being a bridge node as</p>
<p>
<disp-formula id="disp-formula8-0081175012461248">
<mml:math display="block" id="math14-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>bridge</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0081175012461248" xlink:href="10.1177_0081175012461248-eq8.tif"/>
</disp-formula></p>
</list-item>
<list-item>
<p>C6. We choose the five nodes with the highest values of <italic>p</italic>(bridge) as the set of most likely bridge nodes.<sup><xref ref-type="fn" rid="fn13-0081175012461248">13</xref></sup></p>
</list-item>
<list-item>
<p>C7. Randomly select one of the top five bridge nodes from step C3, weighting the five nodes on the basis of their values of <italic>p</italic>(bridge<sub>
<italic>j</italic></sub>) from <xref ref-type="disp-formula" rid="disp-formula8-0081175012461248">equation 7b</xref>. Let BR indicate the selected bridge node.</p>
</list-item>
<list-item>
<p>C8. Let BR indicate the set of BR’s friends that are unsampled and have one and only one nomination so far in the sample. Randomly select one node from BR1 as the next interview.</p>
</list-item>
<list-item>
<p>C9. To incorporate the CSR from the search mode with the even sampling aspect of the list mode, we calculate the sampling probability of each eligible friend F from any node j that was among the top five bridge nodes in step C4. For the eligible friends of one of the top five bridge nodes j:</p>
<p>
<disp-formula id="disp-formula9-0081175012461248">
<mml:math display="block" id="math15-0081175012461248">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>node F sampled with search</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mfrac>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>bridg</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>bridg</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0081175012461248" xlink:href="10.1177_0081175012461248-eq9.tif"/>
</disp-formula></p>
</list-item>
<list-item>
<p>where <italic>c</italic><sub><italic>j</italic></sub> is how many eligible friends node j has, and <inline-formula id="inline-formula7-0081175012461248">
<mml:math display="inline" id="math16-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>bridg</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>bridg</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula> is the probability that node j is chosen from among the top five possible bridge nodes. This sampling rate in <xref ref-type="disp-formula" rid="disp-formula9-0081175012461248">equation 8</xref> is then added to the CSR for node F (see <xref ref-type="disp-formula" rid="disp-formula2-0081175012461248">equation 2</xref> above in section 3.B) each time that node F is eligible to be sampled via the search mode. As discussed above in section 3.B, the list mode ensures the uniform sampling of all nominated nodes as the sample progresses by temporarily excluding any node that has a higher CSR than the ESR defined in <xref ref-type="disp-formula" rid="disp-formula3-0081175012461248">equation 3</xref>. As a result, any oversampling of bridge nodes at the beginning of a sample will gradually disappear once the network is explored and the sampling process shifts to the list mode (i.e. after <italic>P</italic>1 ≤<italic>A</italic>1 in step C2).</p>
</list-item>
<list-item>
<p>C10. After calculating the search mode sampling rates for the eligible nodes in step C6, we update the network rosters and return to step C1 of the search mode, using the search mode when <italic>P</italic>1 &gt; <italic>A</italic>1 and the list mode when <italic>P</italic>1 ≤<italic>A</italic>1 in step C2. Repeat this process until the desired sample size is reached (see section 5 for a discussion of an ideal stopping point on the basis of convergence to SRS).</p>
</list-item>
</list>
</sec>
</sec>
<sec id="section13-0081175012461248">
<title>3.2 The Hybrid Approach</title>
<p>What we are calling the “hybrid” approach consists of the combination of the list and search modes. The sample starts out in search mode, but it defaults to the list mode when the network has been reasonably well explored, as indicated by the threshold A1 in steps C2 and C7 above.</p>
</sec>
<sec id="section14-0081175012461248">
<title>3.3 Sample Mean</title>
<p>For all of the NSM variants (naive list, list, and hybrid), the sample mean from a single sample of S cases is calculated as the weighted mean <inline-formula id="inline-formula8-0081175012461248">
<mml:math display="inline" id="math17-0081175012461248">
<mml:mover accent="true">
<mml:mi>m</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>:</p>
<p>
<disp-formula id="disp-formula10-0081175012461248">
<mml:math display="block" id="math18-0081175012461248">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>m</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mstyle displaystyle="true">
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mstyle>
<mml:mo>⋅</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0081175012461248" xlink:href="10.1177_0081175012461248-eq10.tif"/>
</disp-formula></p>
<p>where s refers to the node that was sampled in the sth step of the sample and the case specific weight, <italic>w</italic><sub>s</sub>, is defined as</p>
<p>
<disp-formula id="disp-formula11-0081175012461248">
<mml:math display="block" id="math19-0081175012461248">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>CS</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>·</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mi>_</mml:mi>
<mml:mi>no</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0081175012461248" xlink:href="10.1177_0081175012461248-eq11.tif"/>
</disp-formula></p>
<p>and CSR and p_nom are defined above (see <xref ref-type="disp-formula" rid="disp-formula2-0081175012461248">equations 2</xref>, <xref ref-type="disp-formula" rid="disp-formula4-0081175012461248">4</xref>, and <xref ref-type="disp-formula" rid="disp-formula9-0081175012461248">8</xref>).</p>
</sec>
</sec>
<sec id="section15-0081175012461248">
<title>4. Simulated Sampling</title>
<p>In this section, we test the performance of NSM (hybrid, list, and naive list), RDS, and RWs along a variety of dimensions by using simulated sampling on a test network and 162 real social networks. After these simulated tests, in section 5 we consider the question of convergence to SRS, and in section 6 we address the broader question of the feasibility of the method. Before we begin, we note that the complete computer code needed to replicate our findings (in Stata’s Mata language) with the test network described below, as well as examples of alternative approaches, is available on the first author’s Web page (<ext-link ext-link-type="uri" xlink:href="http://www.tedmouw.org">www.tedmouw.org</ext-link>).</p>
<p>In our simulated sampling, we use RDS and RW to provide a meaningful comparison to evaluate the efficiency of NSM. For RW, we start with a single, randomly selected seed, and all subsequent cases are drawn randomly from among the friends of the current case, sampling with replacement. RDS is conducted similar to RW, with the next respondent selected as a referral from among the friends of the current respondent. In these simulations, the difference between RW and RDS is that RDS allows for multiple referrals from each respondent.<sup><xref ref-type="fn" rid="fn14-0081175012461248">14</xref></sup> We follow the simulated sampling approach of <xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik (2010)</xref> whereby the probabilities of referring 0, 1, 2, or 3 new respondents in RDS are <inline-formula id="inline-formula9-0081175012461248">
<mml:math display="inline" id="math20-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula10-0081175012461248">
<mml:math display="inline" id="math21-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>6</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula11-0081175012461248">
<mml:math display="inline" id="math22-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>6</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula12-0081175012461248">
<mml:math display="inline" id="math23-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, respectively.</p>
<p>For each network, we use the different methods to collect 500 samples of 500 cases, starting at a randomly selected node and sampling with replacement. Although in practice, the RDS methodology does not sample with replacement, we simulate our respondent-driven samples with replacement because RDS has been shown to be biased when conducted without replacement as the proportion of the population sampled gets large (<xref ref-type="bibr" rid="bibr28-0081175012461248">Gile and Handcock 2010</xref>)<sup><xref ref-type="fn" rid="fn15-0081175012461248">15</xref></sup>; in this sense, sampling with replacement is necessary to allow us to observe the asymptotic properties of RDS. Furthermore, other prominent simulation work evaluating RDS has also been conducted with replacement (<xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik 2010</xref>). To maintain consistency with those results and to provide a fair comparison between our RDS, RW, and NSM results, we therefore conduct all of the simulations with replacement.</p>
<sec id="section16-0081175012461248">
<title>4.1 Test Statistics</title>
<p>We compute four different test statistics to evaluate the competing methods: average bias, MAB, standard deviation (SD), and the design effect (DE). First, define the bias (or error) of a single sample i (of size S cases) collected from network j as</p>
<p>
<disp-formula id="disp-formula12-0081175012461248">
<mml:math display="block" id="math24-0081175012461248">
<mml:mrow>
<mml:mi>bia</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0081175012461248" xlink:href="10.1177_0081175012461248-eq12.tif"/>
</disp-formula></p>
<p>where <italic>m</italic><sub><italic>j</italic></sub> is the population mean of the dependent variable in network j, and <inline-formula id="inline-formula13-0081175012461248">
<mml:math display="inline" id="math25-0081175012461248">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is the estimate of <italic>m</italic><sub><italic>j</italic></sub> in sample i. The average bias in network j (for a particular method) is</p>
<p>
<disp-formula id="disp-formula13-0081175012461248">
<mml:math display="block" id="math26-0081175012461248">
<mml:mrow>
<mml:mtext>average bia</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>s</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mtext>bia</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>s</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula13-0081175012461248" xlink:href="10.1177_0081175012461248-eq13.tif"/>
</disp-formula></p>
<p>where N is the number of different samples collected.</p>
<p>Because the average bias for any particular network could be positive or negative, we want to take the absolute value of the average bias of each network when summarizing it across different networks. Define the summary measure of average bias as</p>
<p>
<disp-formula id="disp-formula14-0081175012461248">
<mml:math display="block" id="math27-0081175012461248">
<mml:mrow>
<mml:mtext>average bias</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mi>bia</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula14-0081175012461248" xlink:href="10.1177_0081175012461248-eq14.tif"/>
</disp-formula></p>
<p>where J is the number of different networks in the study.</p>
<p>The MAB—the measure of the average magnitude of the error for each sample—is</p>
<p>
<disp-formula id="disp-formula15-0081175012461248">
<mml:math display="block" id="math28-0081175012461248">
<mml:mrow>
<mml:mtext>MA</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>B</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mtext>bia</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>s</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula15-0081175012461248" xlink:href="10.1177_0081175012461248-eq15.tif"/>
</disp-formula></p>
<p>Note that the difference between the average bias and the MAB as defined in <xref ref-type="disp-formula" rid="disp-formula14-0081175012461248">equations 13</xref> and <xref ref-type="disp-formula" rid="disp-formula15-0081175012461248">14</xref> is where the absolute value is taken, before or after averaging the bias across the N samples collected for each network. The variance of the bias, which we refer to as the “sampling variance” throughout this article (<xref ref-type="bibr" rid="bibr35-0081175012461248">Groves et al. 2009</xref>:58) is</p>
<p>
<disp-formula id="disp-formula16-0081175012461248">
<mml:math display="block" id="math29-0081175012461248">
<mml:mrow>
<mml:mtext>sampling variance</mml:mtext>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>and</mml:mtext>
<mml:mspace width="0.5em"/>
<mml:mi>S</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>D</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula16-0081175012461248" xlink:href="10.1177_0081175012461248-eq16.tif"/>
</disp-formula></p>
<p>To compare the sampling variance to SRS, we also calculate the DE, which is</p>
<p>
<disp-formula id="disp-formula17-0081175012461248">
<mml:math display="block" id="math30-0081175012461248">
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>SRSj</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula17-0081175012461248" xlink:href="10.1177_0081175012461248-eq17.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula14-0081175012461248">
<mml:math display="inline" id="math31-0081175012461248">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>SRSj</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> is the sampling variance of SRS with a sample size of S cases.</p>
</sec>
<sec id="section17-0081175012461248">
<title>4.2 Test Network Results</title>
<p>Before we sample from the Add Health and Facebook networks, we first try the methods using an artificial test network. The reason we do this is that this network is very easy to visualize, it would be simple to reproduce, and it illustrates key differences in the performance of the competing methods. The test network consists of 400 nodes divided into four clusters of 100 nodes each. Each cluster is characterized by a different degree (i.e., the number of friends each person has). In <xref ref-type="fig" rid="fig2-0081175012461248">Figure 2</xref>, all of the nodes have one tie to someone in a different cluster, with the remainder of their social ties within their cluster. The four clusters A (bottom right cluster in <xref ref-type="fig" rid="fig2-0081175012461248">Figure 2</xref>), B (bottom left), C (center), and D (top) have degrees 7, 12, 17, and 22 respectively. This is a highly connected network, because every node has a tie to someone else in a different cluster.</p>
<fig id="fig2-0081175012461248" position="float">
<label>Figure 2.</label>
<caption>
<p>The 400-node test network</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig2.tif"/>
</fig>
<p>To evaluate our simulated sampling from the test network, we examine the overall average degree in the network, which is 14.5, as the dependent variable. Because degree is clustered within the network, this should pose a problem for RW- and RDS-based approaches. Likewise, because the NSM, RDS, and RW approaches all rely on degree as either a means of exploring the network (NSM) or as a postsample weight, average degree is a measure that we suspect will be challenging for all three approaches. For the test network, we collected 1,000 samples of 1,000 cases for each method, sampling with replacement.</p>
<p><xref ref-type="fig" rid="fig3-0081175012461248">Figure 3</xref> shows the results for each method with sample sizes varying from 50 to 1,000 cases, and <xref ref-type="table" rid="table3-0081175012461248">Table 3</xref> presents the same results in tabular format for sample sizes of 250, 500, and 1,000 cases. Because of space constraints in <xref ref-type="fig" rid="fig3-0081175012461248">Figure 3</xref>, the naive list results are only displayed in <xref ref-type="table" rid="table3-0081175012461248">Table 3</xref>. Starting with the first row of <xref ref-type="fig" rid="fig3-0081175012461248">Figure 3</xref>, we see that although all of the methods are asymptotically unbiased, the NSM hybrid and list approaches get to zero much more rapidly than RDS or RW. A similar advantage is evident for the MAB, SD, and DE. The magnitude of the advantage is clear: The hybrid and list approaches do better on MAB, SD, and DE with a sample size of about 75 than the RDS and RW approaches do with a sample size of 1,000. In practical terms, this means that generalizable inferences with tighter confidence intervals can be made from far fewer respondents collected via NSM.</p>
<table-wrap id="table3-0081175012461248" position="float">
<label>Table 3.</label>
<caption>
<p>Test Network Sampling Results (400 Nodes, Dependent Variable: Average Degree)</p>
</caption>
<graphic alternate-form-of="table3-0081175012461248" xlink:href="10.1177_0081175012461248-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="5">Method<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Steps</th>
<th align="center">Hybrid</th>
<th align="center">List</th>
<th align="center">Naive List</th>
<th align="center">RDS</th>
<th align="center">Random Walk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Average bias</td>
<td>250</td>
<td>0.00036</td>
<td>0.00472</td>
<td>0.1472</td>
<td>0.1278</td>
<td>0.02825</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.000084</td>
<td>0.000014</td>
<td>0.07651</td>
<td>0.09775</td>
<td>0.01458</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>5.00e-06</td>
<td>0.001203</td>
<td>0.03781</td>
<td>0.06936</td>
<td>0.01095</td>
</tr>
<tr>
<td>Mean absolute bias</td>
<td>250</td>
<td>0.05281</td>
<td>0.05526</td>
<td>0.1831</td>
<td>0.5254</td>
<td>0.2555</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.04001</td>
<td>0.03938</td>
<td>0.09757</td>
<td>0.4568</td>
<td>0.173</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>0.02756</td>
<td>0.02808</td>
<td>0.05165</td>
<td>0.3933</td>
<td>0.1304</td>
</tr>
<tr>
<td>Design effect</td>
<td>250</td>
<td>0.8986</td>
<td>0.9615</td>
<td>5.49</td>
<td>76.95</td>
<td>20.72</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>1.015</td>
<td>0.962</td>
<td>3.221</td>
<td>119.6</td>
<td>18.8</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>0.9963</td>
<td>0.9845</td>
<td>2.066</td>
<td>181</td>
<td>21.1</td>
</tr>
<tr>
<td>Standard deviation</td>
<td>250</td>
<td>0.06711</td>
<td>0.06942</td>
<td>0.1659</td>
<td>0.6211</td>
<td>0.3223</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.05045</td>
<td>0.0491</td>
<td>0.08985</td>
<td>0.5476</td>
<td>0.2171</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>0.03533</td>
<td>0.03512</td>
<td>0.05088</td>
<td>0.4762</td>
<td>0.1626</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0081175012461248">
<p><italic>Note</italic>: RDS = respondent-driven sampling.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig3-0081175012461248" position="float">
<label>Figure 3.</label>
<caption>
<p>Test network sampling results (400 nodes, dependent variable: average degree)</p>
<p><italic>Notes</italic>: Bias = average bias; design effect (DE) = <inline-formula id="inline-formula15-0081175012461248">
<mml:math display="inline" id="math32-0081175012461248">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>method</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>SRS</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>; MAB = mean absolute bias; RDS = respondent-driven sampling; SD = standard deviation.</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig3.tif"/>
</fig>
<p><xref ref-type="table" rid="table3-0081175012461248">Table 3</xref> includes results for the naive list approach. Recall that the key difference between the list and naive list approaches is that the former chooses cases using a weighting scheme to ensure that nodes sampled early in the process are not overrepresented. Although the naive list approach is very intuitive, it does not perform as well as the list approach, with a DE of 2.066 (with a sample size of 1,000). On the other hand, it still outperforms RDS and RW, which have DEs of 181 and 21.1, respectively.</p>
<p>The hybrid and list approaches do well because once the network has been “discovered” (i.e., as the list L of nominated nodes approaches the population size G), these approaches are identical to SRS. RDS and RW have difficulty with this network because although it is highly connected, it is easy for them to get stuck in one of the clusters because they are wandering “blindly” with no accumulated network information other than a list of sampled cases. For example, for each node in cluster D (the bottom right-hand cluster), there are 19 within-cluster ties and 1 tie to someone out of the cluster. As a result, if RDS or RW is currently interviewing in cluster D, it has only a 5 percent chance of exiting to a different cluster.</p>
<p>Although, as shown in <xref ref-type="fig" rid="fig3-0081175012461248">Figure 3</xref>, the SD of RDS and RW declines as the sample size increases, it does so at a relatively slow rate compared to SRS. As a result, the DE for these two methods does not go down; it is relatively constant for RW and goes up for RDS, which indicates that RDS loses ground relative to SRS in this network as the sample size increases. In contrast, the hybrid and list approaches have DEs that rapidly approach 1 in <xref ref-type="fig" rid="fig3-0081175012461248">Figure 3</xref>, indicating increasing parity with SRS.</p>
</sec>
<sec id="section18-0081175012461248">
<title>4.3 Overview of the Add Health and Facebook Networks</title>
<p><xref ref-type="table" rid="table4-0081175012461248">Table 4</xref> shows descriptive statistics for the Add Health and Facebook networks. In all of the networks discussed here, we use only the largest connected component. This is a common and necessary approach in evaluating link-tracing samples via simulation; indeed, a key assumption of RDS is that the results are only generalizable to the “giant component” (<xref ref-type="bibr" rid="bibr71-0081175012461248">Volz and Heckathorn 2008</xref>). One of the data sets we use is the network data from Add Health. These are some of the most commonly studied network data in the world and are perfect for our evaluations because they contain numerous instantiations of the same network survey conducted at the same time in different places. The differences between networks allow us to explore how characteristics of those networks relate to biases and inefficiencies in the various methods we test. In the Add Health networks, we have treated all nominations as symmetric (i.e., we forced nonreciprocated nominations to be symmetric). <xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik (2010)</xref> considered the sensitivity of RDS results to this assumption in the Add Health data by looking only at ties that were actually reciprocated in the original data and found that the DEs were considerably worse than in the case where all ties were treated as symmetric.<sup><xref ref-type="fn" rid="fn16-0081175012461248">16</xref></sup></p>
<table-wrap id="table4-0081175012461248" position="float">
<label>Table 4.</label>
<caption>
<p>Descriptive Statistics for Add Health and Facebook Networks</p>
</caption>
<graphic alternate-form-of="table4-0081175012461248" xlink:href="10.1177_0081175012461248-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th align="left">Variable</th>
<th align="center">Mean</th>
<th align="center">25th Percentile</th>
<th align="center">Median</th>
<th align="center">75th Percentile</th>
<th align="center">Minimum</th>
<th align="center">Maximum</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="7">A. Add Health networks (<italic>J</italic> = 62)</td>
</tr>
<tr>
<td> Proportion white</td>
<td>0.562</td>
<td>0.424</td>
<td>0.632</td>
<td>0.718</td>
<td>0.215</td>
<td>0.794</td>
</tr>
<tr>
<td> Homophily</td>
<td>0.380</td>
<td>0.221</td>
<td>0.358</td>
<td>0.509</td>
<td>-0.021</td>
<td>0.816</td>
</tr>
<tr>
<td> Nodes (number of people)</td>
<td>494.8</td>
<td>247</td>
<td>395</td>
<td>586</td>
<td>110</td>
<td>1610</td>
</tr>
<tr>
<td> Edges (number of ties)</td>
<td>3,441.5</td>
<td>1,638</td>
<td>2,622</td>
<td>4,276</td>
<td>608</td>
<td>12,794</td>
</tr>
<tr>
<td> Mean degree</td>
<td>8.48</td>
<td>7.43</td>
<td>8.46</td>
<td>9.78</td>
<td>4.28</td>
<td>11.99</td>
</tr>
<tr>
<td> Y-mean degree difference</td>
<td>10.36</td>
<td>4.40</td>
<td>7.90</td>
<td>13.62</td>
<td>0.02</td>
<td>42.61</td>
</tr>
<tr>
<td colspan="7">B. Facebook networks (<italic>J</italic> = 100)</td>
</tr>
<tr>
<td> Proportion freshman</td>
<td>0.282</td>
<td>0.231</td>
<td>0.281</td>
<td>0.336</td>
<td>0.141</td>
<td>0.462</td>
</tr>
<tr>
<td> Homophily</td>
<td>0.786</td>
<td>0.745</td>
<td>0.810</td>
<td>0.846</td>
<td>0.378</td>
<td>0.900</td>
</tr>
<tr>
<td> Nodes (number of people)</td>
<td>4,635.8</td>
<td>2,186</td>
<td>3,694.5</td>
<td>6,638</td>
<td>331</td>
<td>16,278</td>
</tr>
<tr>
<td> Edges (number of ties)</td>
<td>238,916.3</td>
<td>83,517</td>
<td>207,308</td>
<td>339,513</td>
<td>6,672</td>
<td>997,614</td>
</tr>
<tr>
<td> Mean degree</td>
<td>81.14</td>
<td>66.71</td>
<td>79.95</td>
<td>93.95</td>
<td>31.99</td>
<td>156.06</td>
</tr>
<tr>
<td> Y-mean degree difference</td>
<td>1.25</td>
<td>0.29</td>
<td>0.54</td>
<td>1.29</td>
<td>0.01</td>
<td>11.33</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0081175012461248">
<p><italic>Note</italic>: Add Health = National Longitudinal Study of Adolescent Health.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In the Add Health networks, we use our simulations to obtain estimates of the proportion white students in the school. <xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik (2010)</xref> found that race had the highest DEs among the variables they tested in the Add Health data, which, we argue, makes it a good variable to use to evaluate our competing methodologies. We limit our sample to the 62 schools at which the proportion white was between 0.2 and 0.8.<sup><xref ref-type="fn" rid="fn17-0081175012461248">17</xref></sup> In <xref ref-type="table" rid="table4-0081175012461248">Table 4A</xref>, we see that the size of the Add Health networks ranges from 110 to 1,610 nodes. Because the respondents were asked to list their top 5 male and female friends, the average degree is low in these networks compared with the Facebook networks we discuss below; the global average degree is 8.48, and it ranges from a low of 4.28 to a high of 11.99. As a measure of the level of intergroup friendship taking group size into account, homophily is defined as 1 minus the ratio of the number of cross-group friends divided by the expected number of cross-group friends under random assignment.<sup><xref ref-type="fn" rid="fn18-0081175012461248">18</xref></sup> Overall, the level of white-nonwhite homophily averages 0.562 and goes from a low of −0.021 to 0.816.</p>
<p>A final descriptive measure is “Y-mean degree difference,” which is the percentage difference in the average degree by the dependent variable (white vs. nonwhite in the case of the Add Health networks). This variable is a measure of whether one group has, on average, more friends in the network than the other group. We calculate it as the absolute value of the difference in average degree among the groups divided by the overall average degree:</p>
<p>
<disp-formula id="disp-formula18-0081175012461248">
<mml:math display="block" id="math33-0081175012461248">
<mml:mrow>
<mml:mtext>y-mean degree difference</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mn>100</mml:mn>
<mml:mfrac>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula18-0081175012461248" xlink:href="10.1177_0081175012461248-eq18.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula16-0081175012461248">
<mml:math display="inline" id="math34-0081175012461248">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>A</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> represents the mean degree for group A of the dependent variable. The reason for including this variable is that we want to see whether having an imbalance in average degree across the dependent variable affects the results. <xref ref-type="bibr" rid="bibr30-0081175012461248">Gjoka et al. (2010)</xref> find that average degree is particularly challenging to estimate with link-tracing approaches, so we expect that unbiased estimation of this variable will be especially challenging for the methods we test. The test network in <xref ref-type="fig" rid="fig2-0081175012461248">Figure 2</xref> is an extreme example of a network in which average degree differs sharply across the different groups (i.e., clusters A, B, C, and D).</p>
</sec>
<sec id="section19-0081175012461248">
<title>4.4 Add Health Results</title>
<p>We start our discussion of the Add Health results by considering one of the smallest networks, network 112, which consists of 210 nodes and is 54.2 percent white. Of the 1,638 social ties in the network, 250 of them are cross-race ties, indicating that there is considerable cross-race interaction even though friendship is racially segregated.</p>
<p><xref ref-type="fig" rid="fig4-0081175012461248">Figure 4</xref> shows a picture of this network. A key observation to make from this picture is that although the total number of intergroup ties is large (250), they are not evenly distributed across students. This is a contrast with the test network, in which every node had 1 tie to a different cluster. This is important because it means that RDS and RW, which have no memory of the overall network structure, can get stuck in the interior of each of the two large clusters defined by race (white vs. nonwhite) in <xref ref-type="fig" rid="fig4-0081175012461248">Figure 4</xref>, with a limited chance of transitioning to the other cluster.</p>
<fig id="fig4-0081175012461248" position="float">
<label>Figure 4.</label>
<caption>
<p>Add Health network 112</p>
<p><italic>Note</italic>: Nodes are colored by student race (black squares = white; gray circles = nonwhite).</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig4.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig5-0081175012461248">Figure 5</xref> and <xref ref-type="table" rid="table5-0081175012461248">Table 5</xref> show the results for sampling from network 112 with 500 samples of 500 cases each. The basic pattern of the results is similar to the test network discussed above. Although all of the approaches appear to be asymptotically unbiased, the hybrid and list approaches show the most rapid approach toward zero average bias. Once again, the key result is the dramatic difference in the DEs. The hybrid and list approaches have DEs of 1 after about 200 cases (see <xref ref-type="fig" rid="fig5-0081175012461248">Figure 5</xref>), while RDS and RW do not get anywhere close to 1 after 500 cases. The naive list approach does not do as well as the list approach, with a DE of 4.697 in samples of 500 cases.</p>
<fig id="fig5-0081175012461248" position="float">
<label>Figure 5.</label>
<caption>
<p>Sampling results from National Longitudinal Study of Adolescent Health network 112</p>
<p>
<italic>Note</italic>: RDS = respondent-driven sampling.</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig5.tif"/>
</fig>
<table-wrap id="table5-0081175012461248" position="float">
<label>Table 5.</label>
<caption>
<p>Sampling Results from Add Health Network 112</p>
</caption>
<graphic alternate-form-of="table5-0081175012461248" xlink:href="10.1177_0081175012461248-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="5">Method<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Steps</th>
<th align="center">Hybrid</th>
<th align="center">List</th>
<th align="center">Naive List</th>
<th align="center">RDS</th>
<th align="center">Random Walk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Average bias</td>
<td>250</td>
<td>0.001193</td>
<td>0.001793</td>
<td>0.004337</td>
<td>0.005243</td>
<td>0.006462</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>0.001797</td>
<td>0.0006971</td>
<td>0.003917</td>
<td>0.007063</td>
<td>0.002586</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.0009851</td>
<td>0.0001629</td>
<td>0.003245</td>
<td>0.006052</td>
<td>0.002788</td>
</tr>
<tr>
<td>Mean absolute bias</td>
<td>250</td>
<td>0.02489</td>
<td>0.02484</td>
<td>0.07168</td>
<td>0.2647</td>
<td>0.1201</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>0.01988</td>
<td>0.01888</td>
<td>0.04704</td>
<td>0.2479</td>
<td>0.09969</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.01767</td>
<td>0.01759</td>
<td>0.03981</td>
<td>0.2405</td>
<td>0.09269</td>
</tr>
<tr>
<td>Design effect</td>
<td>250</td>
<td>1.002</td>
<td>0.990</td>
<td>7.554</td>
<td>89.73</td>
<td>21.47</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>1.002</td>
<td>0.9243</td>
<td>5.285</td>
<td>127.4</td>
<td>24.14</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.9961</td>
<td>0.9852</td>
<td>4.697</td>
<td>150.2</td>
<td>25.16</td>
</tr>
<tr>
<td>Standard deviation</td>
<td>250</td>
<td>0.03161</td>
<td>0.03142</td>
<td>0.0868</td>
<td>0.2992</td>
<td>0.1463</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>0.02499</td>
<td>0.024</td>
<td>0.0574</td>
<td>0.2818</td>
<td>0.1227</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.02229</td>
<td>0.02217</td>
<td>0.0484</td>
<td>0.2737</td>
<td>0.112</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0081175012461248">
<p><italic>Notes</italic>: Add Health = National Longitudinal Study of Adolescent Health; RDS = respondent-driven sampling.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Columns 1 and 2 of <xref ref-type="table" rid="table6-0081175012461248">Table 6</xref> show the overall results from sampling the 62 Add Health networks. Column 1 shows the average (and median) DE and bias with the school’s proportion white as the dependent variable, and column 2 shows the results with mean degree as the dependent variable. The overall finding in column 1 is that the NSM hybrid and list approaches do very well on these networks with proportion white as the dependent variable, with average DEs of 1.110 and 1.236, respectively. In contrast, RDS has an average DE of 66.883 (median DE = 47.766), and RW has an average DE of 12.698. A key finding in <xref ref-type="table" rid="table6-0081175012461248">Table 6</xref> is that in these relatively small networks, the list approach does very well. Because the list approach is so intuitive and simple (see section 3.B), we believe that it may have considerable appeal as an alternative to RDS when sampling from a network when the precision of the estimates is a concern and it is possible to collect basic network data. In column 2, we see a similar pattern of results with average degree as the dependent variable; the hybrid and list approaches have the lowest average DEs (1.069 and 1.132, respectively), while the average DE for RDS is considerably higher (25.206).<sup><xref ref-type="fn" rid="fn19-0081175012461248">19</xref></sup></p>
<table-wrap id="table6-0081175012461248" position="float">
<label>Table 6.</label>
<caption>
<p>Overall Add Health and Facebook Results</p>
</caption>
<graphic alternate-form-of="table6-0081175012461248" xlink:href="10.1177_0081175012461248-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="3">Network Source and Dependent Variable<hr/></th>
</tr>
<tr>
<th/>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
</tr>
<tr>
<th/>
<th align="center">Add Health<sup><xref ref-type="table-fn" rid="table-fn7-0081175012461248">a</xref></sup></th>
<th align="center">Add Health<sup><xref ref-type="table-fn" rid="table-fn7-0081175012461248">a</xref></sup></th>
<th align="center">Facebook<sup><xref ref-type="table-fn" rid="table-fn8-0081175012461248">b</xref></sup></th>
</tr>
</thead>
<tbody>
<tr>
<th align="left">Dependent variable</th>
<th align="center">Proportion white</th>
<th align="center">Average degree</th>
<th align="center">Proportion freshman</th>
</tr>
<tr>
<td colspan="4">Average design effects</td>
</tr>
<tr>
<td> NSM: hybrid</td>
<td>1.110</td>
<td>1.069</td>
<td>1.198</td>
</tr>
<tr>
<td> NSM: list</td>
<td>1.236</td>
<td>1.132</td>
<td>2.267</td>
</tr>
<tr>
<td> Naive list</td>
<td>5.605</td>
<td>2.152</td>
<td>22.85</td>
</tr>
<tr>
<td> RDS<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>83.931</td>
</tr>
<tr>
<td> RDS full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>66.883</td>
<td>25.206</td>
<td>86.135</td>
</tr>
<tr>
<td> RW<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>12.031</td>
</tr>
<tr>
<td> RW full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>12.698</td>
<td>6.652</td>
<td>19.107</td>
</tr>
<tr>
<td colspan="4">Median design effects</td>
</tr>
<tr>
<td> NSM: hybrid</td>
<td>1.055</td>
<td/>
<td>1.188</td>
</tr>
<tr>
<td> NSM: list</td>
<td>1.093</td>
<td/>
<td>1.969</td>
</tr>
<tr>
<td> Naive list</td>
<td>3.317</td>
<td/>
<td>17.507</td>
</tr>
<tr>
<td> RDS<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>78.145</td>
</tr>
<tr>
<td> RDS full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>47.766</td>
<td/>
<td>85.987</td>
</tr>
<tr>
<td> RW<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>11.517</td>
</tr>
<tr>
<td> RW full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>9.273</td>
<td/>
<td>18.294</td>
</tr>
<tr>
<td colspan="4">Average bias</td>
</tr>
<tr>
<td> NSM: hybrid</td>
<td>0.0019</td>
<td>0.0328</td>
<td>0.0048</td>
</tr>
<tr>
<td> NSM: list</td>
<td>0.0021</td>
<td>0.0424</td>
<td>0.0117</td>
</tr>
<tr>
<td> Naive list</td>
<td>0.0168</td>
<td>0.3172</td>
<td>0.0483</td>
</tr>
<tr>
<td> RDS<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>0.1363</td>
</tr>
<tr>
<td> RDS full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>0.0091</td>
<td>0.0867</td>
<td>0.018</td>
</tr>
<tr>
<td> RW<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>0.1047</td>
</tr>
<tr>
<td> RW full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>0.0032</td>
<td>0.0228</td>
<td>0.0049</td>
</tr>
<tr>
<td colspan="4">Median average bias</td>
</tr>
<tr>
<td> NSM: hybrid</td>
<td>0.0011</td>
<td/>
<td>0.0037</td>
</tr>
<tr>
<td> NSM: list</td>
<td>0.0013</td>
<td/>
<td>0.0091</td>
</tr>
<tr>
<td> Naive list</td>
<td>0.0116</td>
<td/>
<td>0.0470</td>
</tr>
<tr>
<td> RDS<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>0.1060</td>
</tr>
<tr>
<td> RDS full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>0.005</td>
<td/>
<td>0.0164</td>
</tr>
<tr>
<td> RW<sup><xref ref-type="table-fn" rid="table-fn9-0081175012461248">c</xref></sup></td>
<td/>
<td/>
<td>0.0691</td>
</tr>
<tr>
<td> RW full data<sup><xref ref-type="table-fn" rid="table-fn10-0081175012461248">d</xref></sup></td>
<td>0.0022</td>
<td/>
<td>0.0044</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-0081175012461248">
<p><italic>Notes</italic>: Add Health = National Longitudinal Study of Adolescent Health; NSM = network sampling with memory; RDS = respondent-driven sampling; RW = random walk.</p>
</fn>
<fn id="table-fn7-0081175012461248">
<label>a.</label>
<p>The Add Health networks are run on the largest connected component from the complete network data for each school.</p>
</fn>
<fn id="table-fn8-0081175012461248">
<label>b.</label>
<p>Because the average number of ties in the Facebook data was so high, the maximum number of ties was truncated at 20 for the NSM hybrid, list, and naive list methods. This makes it harder for these methods. See the text for details.</p>
</fn>
<fn id="table-fn9-0081175012461248">
<label>c.</label>
<p>RDS and RW were run on the same truncated data (maximum degree of 20) as the NSM approaches for the Facebook data.</p>
</fn>
<fn id="table-fn10-0081175012461248">
<label>d.</label>
<p>RDS and RW were run on the full data, with no limit on maximum degree. See text for details.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section20-0081175012461248">
<title>4.5 Facebook Networks</title>
<p>To test NSM on larger networks, we use data from Facebook, an online social network launched in February 2004. The data we use here were collected in 2005, when Facebook membership was available only to those affiliated with universities (i.e., those with a valid “.edu” e-mail address at schools that had been registered with the company). The data set we use contains a census of all users and the connections among them at 100 university networks that were part of Facebook in September 2005 (an overview of these data and access information is given in <xref ref-type="bibr" rid="bibr69-0081175012461248">Traud et al. 2010</xref> and <xref ref-type="bibr" rid="bibr70-0081175012461248">Traud, Mucha, and Porter 2010</xref>]).<sup><xref ref-type="fn" rid="fn20-0081175012461248">20</xref></sup></p>
<p>The bounded nature of student friendships within universities, in addition to replications over 100 social settings, is an important part of why this data set is appropriate for this analysis. Sociologists have used Facebook for a variety of research questions (<xref ref-type="bibr" rid="bibr49-0081175012461248">Lewis et al. 2008</xref>; <xref ref-type="bibr" rid="bibr74-0081175012461248">Wimmer and Lewis 2010</xref>). The most important feature of these data for our purposes is that they are reasonable representations of offline friendships within universities (<xref ref-type="bibr" rid="bibr13-0081175012461248">Boyd and Ellison 2008</xref>; <xref ref-type="bibr" rid="bibr18-0081175012461248">Clouston et al. 2009</xref>; <xref ref-type="bibr" rid="bibr37-0081175012461248">Haythornthwaite 2005</xref>; <xref ref-type="bibr" rid="bibr47-0081175012461248">Lampe, Ellison, and Steinfield 2007</xref>), though there are some nuances to this (<xref ref-type="bibr" rid="bibr25-0081175012461248">Ellison, Steinfield, and Lampe 2006</xref>). At that time, users were also relatively open about sharing information online (<xref ref-type="bibr" rid="bibr34-0081175012461248">Gross and Acquisti 2005</xref>), which allows us access to several self-reported attributes of respondents.</p>
<p>In our sampling tests using the Facebook data, the proportion of first-year students (freshmen) in the network is our dependent variable. In preparing the data, we deleted cases that were missing information on the respondent’s year in school. In addition, because the average degree of these networks was so large, we decided to test the hybrid and list approaches by limiting the number of friends that each respondent could list to a maximum of 20, a number that is below the average degree we found in the field test of collecting network data we conducted that is discussed below in section 6 and which could reasonably be collected in a survey. For NSM, more network data—in terms of the average number of friends listed on respondents’ network rosters—is always better, because it means that the network is revealed faster (i.e., <italic>L</italic>→<italic>G</italic> more quickly; see section 3.B). Thus, by limiting the number of friends each respondent can list, we are making it harder for NSM to sample from these networks. For the RDS and RW approaches, we will run the samples twice, once with a maximum of 20 friends per respondent and once with all of the friends. In the simulated samples with the networks truncated at 20 friends, before the sample begins, we randomly select 20 friends per respondent if the respondent has more than 20 friends. These 20 friends are randomly rechosen for each replication of the sample.<sup><xref ref-type="fn" rid="fn21-0081175012461248">21</xref></sup></p>
<p><xref ref-type="table" rid="table4-0081175012461248">Table 4B</xref> presents basic descriptive statistics on the 100 Facebook networks. The level of friendship homophily between freshman and nonfreshman is high in these data, averaging 0.786 and ranging from 0.378 to 0.9. The number of nodes averages 4,635, with a maximum of 16,278. The mean degree for the full data is 81.14, which is the reason we choose to limit the maximum degree for the hybrid and list approaches to 20.</p>
</sec>
<sec id="section21-0081175012461248">
<title>4.6 Facebook Results</title>
<p>We begin by discussing results for the largest Facebook university network (network 100), which has 16,280 nodes. This network is 30.3 percent freshman and has a homophily level of 0.683. The average degree is 106.4 (19.77 in the network truncated at degree 20). <xref ref-type="fig" rid="fig6-0081175012461248">Figure 6</xref> shows the results for RDS and RW using the full networks (because both RDS and RW do better on the full networks), and both the truncated and full networks are presented in <xref ref-type="table" rid="table7-0081175012461248">Table 7</xref>.</p>
<table-wrap id="table7-0081175012461248" position="float">
<label>Table 7.</label>
<caption>
<p>Sampling Results for the Largest Facebook University Network (16,280 Nodes, Dependent Variable: Proportion Freshman)</p>
</caption>
<graphic alternate-form-of="table7-0081175012461248" xlink:href="10.1177_0081175012461248-table7.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="4">Truncated Network Data (Maximum Degree = 20)<sup><xref ref-type="table-fn" rid="table-fn12-0081175012461248">a</xref></sup><hr/></th>
<th align="center" colspan="2">Full Network Data<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Steps</th>
<th align="center">Hybrid</th>
<th align="center">List</th>
<th align="center">RDS</th>
<th align="center">Random Walk</th>
<th align="center">RDS</th>
<th align="center">Random Walk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Average bias</td>
<td>250</td>
<td>0.0199</td>
<td>0.03452</td>
<td>0.4246</td>
<td>0.04032</td>
<td>0.03265</td>
<td>0.03811</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>0.006125</td>
<td>0.02586</td>
<td>0.4388</td>
<td>0.04299</td>
<td>0.03769</td>
<td>0.03649</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.0003046</td>
<td>0.02095</td>
<td>0.445</td>
<td>0.0448</td>
<td>0.03948</td>
<td>0.0359</td>
</tr>
<tr>
<td>Mean absolute bias</td>
<td>250</td>
<td>0.03642</td>
<td>0.06275</td>
<td>0.4247</td>
<td>0.06897</td>
<td>0.134</td>
<td>0.07709</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>0.02322</td>
<td>0.04476</td>
<td>0.4388</td>
<td>0.06162</td>
<td>0.1118</td>
<td>0.06553</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.01661</td>
<td>0.0378</td>
<td>0.445</td>
<td>0.05838</td>
<td>0.1035</td>
<td>0.06044</td>
</tr>
<tr>
<td>Design effect</td>
<td>250</td>
<td>1.997</td>
<td>6.182</td>
<td>26.00</td>
<td>6.575</td>
<td>32.12</td>
<td>9.75</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>1.422</td>
<td>4.616</td>
<td>28.65</td>
<td>6.992</td>
<td>35.82</td>
<td>10.48</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>1.079</td>
<td>4.379</td>
<td>29.63</td>
<td>6.893</td>
<td>38.34</td>
<td>10.61</td>
</tr>
<tr>
<td>Standard deviation</td>
<td>250</td>
<td>0.04115</td>
<td>0.07231</td>
<td>0.1483</td>
<td>0.07455</td>
<td>0.1651</td>
<td>0.09082</td>
</tr>
<tr>
<td/>
<td>400</td>
<td>0.02745</td>
<td>0.0494</td>
<td>0.1231</td>
<td>0.06078</td>
<td>0.1378</td>
<td>0.07443</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.02138</td>
<td>0.04303</td>
<td>0.1120</td>
<td>0.05397</td>
<td>0.1275</td>
<td>0.0670</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn11-0081175012461248">
<p><italic>Note</italic>: RDS = respondent-driven sampling.</p>
</fn>
<fn id="table-fn12-0081175012461248">
<label>a.</label>
<p>The truncated network data limit the number of friends each respondent can nominate to 20. This is designed to make it harder for the network sampling with memory hybrid and list approaches (see the text for details).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig6-0081175012461248" position="float">
<label>Figure 6.</label>
<caption>
<p>Sampling results for the largest facebook university network (16,280 nodes, dependent variable: proportion freshman)</p>
<p>
<italic>Note</italic>: RDS = respondent-driven sampling.</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig6.tif"/>
</fig>
<p>The important finding in network 100 is that the hybrid approach continues to do very well, with an average bias of 0.0003 after 500 steps and a MAB of 0.01661. To put the MAB result into perspective, the first row of <xref ref-type="fig" rid="fig6-0081175012461248">Figure 6</xref> shows that hybrid does better with a sample size of about 75 than either RDS or RW does with 500. In addition, while the list approach performed as well as the hybrid approach on the smaller Add Health networks, this is not the case in this large Facebook network. Although the second row of <xref ref-type="fig" rid="fig6-0081175012461248">Figure 6</xref> shows that the DE of list is declining, it does not do so as rapidly as the hybrid approach, resulting in a DE of 4.379 after 500 steps (cases), compared with 1.079 for the hybrid approach.</p>
<p>Column 3 of <xref ref-type="table" rid="table6-0081175012461248">Table 6</xref> presents the overall results for the Facebook networks. The results confirm the basic discussion from network 100 above: Hybrid and list have much lower DEs than RDS or RW. In addition, the DE of the list approach is slightly higher on the larger Facebook networks compared with the Add Health networks, and the naive list approach does not do much better than RW. In contrast to the list approach, the DE of hybrid stays low (1.198).</p>
<p>As a summary measure of the overall results combining the Add Health (with proportion white as the dependent variable) and the Facebook networks together, we note that the average DE on these 162 networks using the hybrid approach and list approaches was 1.16 and 1.87, respectively. These DEs are close to what would be expected in SRS (DE = 1) and perform significantly better compared with the DEs of 77.4 for RDS and 12.3 for RW.<sup><xref ref-type="fn" rid="fn22-0081175012461248">22</xref></sup> On all 162 of the networks, both the NSM hybrid and list approaches had lower DEs than RDS or RW.</p>
<p>Finally, to evaluate the sensitivity of the observed DE and average bias to the network characteristics from <xref ref-type="table" rid="table4-0081175012461248">Table 4</xref>, in <xref ref-type="table" rid="table8-0081175012461248">Tables 8</xref> and <xref ref-type="table" rid="table9-0081175012461248">9</xref> we combine the results of the Add Health and Facebook networks and run a regression analysis.<sup><xref ref-type="fn" rid="fn23-0081175012461248">23</xref></sup> In <xref ref-type="table" rid="table8-0081175012461248">Table 8</xref>, the dependent variable is the DE, and in <xref ref-type="table" rid="table9-0081175012461248">Table 9</xref>, the dependent variable is the average bias calculated using <xref ref-type="disp-formula" rid="disp-formula14-0081175012461248">equation 13</xref> above. The bottom two rows of each table present the mean and SD of the dependent variable as a reminder that these vary considerably across the different methods. All the models include a dummy variable indicating the source of the data (1 = Add Health, 0 = Facebook). As discussed above in reference to <xref ref-type="table" rid="table4-0081175012461248">Table 4</xref>, the variable “Y-mean degree difference” is a measure of whether the mean degree varies across categories of the dependent variable (see <xref ref-type="disp-formula" rid="disp-formula18-0081175012461248">equation 17</xref> above). We use the natural log of the number of nodes to measure network size.</p>
<table-wrap id="table8-0081175012461248" position="float">
<label>Table 8.</label>
<caption>
<p>Ordinary Least Squares Regression Results for the Design Effect, Combined Add Health and Facebook Networks</p>
</caption>
<graphic alternate-form-of="table8-0081175012461248" xlink:href="10.1177_0081175012461248-table8.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="5">Method<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Hybrid</th>
<th align="center">List</th>
<th align="center">Naive List</th>
<th align="center">RDS</th>
<th align="center">Random Walk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Homophily</td>
<td>0.158</td>
<td>−0.136</td>
<td>28.36<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>284.1<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>40.41<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
</tr>
<tr>
<td/>
<td>(0.144)</td>
<td>(0.338)</td>
<td>(5.563)</td>
<td>(15.16)</td>
<td>(2.757)</td>
</tr>
<tr>
<td>Add Health network</td>
<td>−0.182</td>
<td>0.471</td>
<td>16.67<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>71.37<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>6.933<xref ref-type="table-fn" rid="table-fn14-0081175012461248">**</xref></td>
</tr>
<tr>
<td/>
<td>(0.114)</td>
<td>(0.268)</td>
<td>(4.427)</td>
<td>(11.99)</td>
<td>(2.181)</td>
</tr>
<tr>
<td>ln(nodes)</td>
<td>−0.00576</td>
<td>0.964<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>12.14<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>−8.917<xref ref-type="table-fn" rid="table-fn14-0081175012461248">**</xref></td>
<td>−2.030<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
</tr>
<tr>
<td/>
<td>(0.0278)</td>
<td>(0.0654)</td>
<td>(1.252)</td>
<td>(2.930)</td>
<td>(0.533)</td>
</tr>
<tr>
<td>Average degree</td>
<td>−0.00111</td>
<td>−0.00451</td>
<td>−0.0159</td>
<td>−0.0950</td>
<td>0.0436</td>
</tr>
<tr>
<td/>
<td>(0.00121)</td>
<td>(0.00285)</td>
<td>(0.0494)</td>
<td>(0.127)</td>
<td>(0.0232)</td>
</tr>
<tr>
<td>Y-mean degree difference</td>
<td>0.00714</td>
<td>0.0130</td>
<td>0.00201</td>
<td>−0.139</td>
<td>0.207<xref ref-type="table-fn" rid="table-fn14-0081175012461248">**</xref></td>
</tr>
<tr>
<td/>
<td>(0.00376)</td>
<td>(0.00886)</td>
<td>(0.144)</td>
<td>(0.397)</td>
<td>(0.0722)</td>
</tr>
<tr>
<td>Constant</td>
<td>1.202<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>−5.133<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>−94.72<xref ref-type="table-fn" rid="table-fn14-0081175012461248">***</xref></td>
<td>−56.61<xref ref-type="table-fn" rid="table-fn14-0081175012461248">*</xref></td>
<td>0.0898</td>
</tr>
<tr>
<td/>
<td>(0.236)</td>
<td>(0.555)</td>
<td>(9.751)</td>
<td>(24.88)</td>
<td>(4.525)</td>
</tr>
<tr>
<td>Observations</td>
<td>162</td>
<td>162</td>
<td>162</td>
<td>162</td>
<td>162</td>
</tr>
<tr>
<td><italic>R</italic><sup>2</sup></td>
<td>.076</td>
<td>.698</td>
<td>.658</td>
<td>.718</td>
<td>.687</td>
</tr>
<tr>
<td>Mean design effect</td>
<td>1.16</td>
<td>1.85</td>
<td>15.48</td>
<td>78.76</td>
<td>16.65</td>
</tr>
<tr>
<td>SD design effect</td>
<td>0.25</td>
<td>1.05</td>
<td>15.90</td>
<td>48.54</td>
<td>8.38</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn13-0081175012461248">
<p><italic>Notes</italic>: Standard errors are in parentheses. Add Health = Add Health = National Longitudinal Study of Adolescent Health; RDS = respondent-driven sampling.</p>
</fn>
<fn id="table-fn14-0081175012461248">
<label>*</label>
<p><italic>p</italic> &lt; .05. **<italic>p</italic> &lt; .01. ***<italic>p</italic> &lt; .001.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table9-0081175012461248" position="float">
<label>Table 9.</label>
<caption>
<p>Ordinary Least Squares Regression Results for the Average Bias,<sup><xref ref-type="table-fn" rid="table-fn16-0081175012461248">a</xref></sup> Combined Add Health and Facebook Networks</p>
</caption>
<graphic alternate-form-of="table9-0081175012461248" xlink:href="10.1177_0081175012461248-table9.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="5">Method<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Hybrid</th>
<th align="center">List</th>
<th align="center">Naive List</th>
<th align="center">RDS</th>
<th align="center">Random Walk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Homophily</td>
<td>0.000602</td>
<td>0.00208</td>
<td>0.0149</td>
<td>0.0139<xref ref-type="table-fn" rid="table-fn17-0081175012461248">*</xref></td>
<td>0.00761<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
</tr>
<tr>
<td/>
<td>(0.00208)</td>
<td>(0.00387)</td>
<td>(0.00815)</td>
<td>(0.00632)</td>
<td>(0.00177)</td>
</tr>
<tr>
<td>Add Health network</td>
<td>0.00192</td>
<td>0.00429</td>
<td>−0.00768</td>
<td>−0.00190</td>
<td>−0.000757</td>
</tr>
<tr>
<td/>
<td>(0.00164)</td>
<td>(0.00306)</td>
<td>(0.00648)</td>
<td>(0.00500)</td>
<td>(0.00140)</td>
</tr>
<tr>
<td>ln(nodes)</td>
<td>0.00169<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>0.00637<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>0.0115<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>−0.00180</td>
<td>−0.00127<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
</tr>
<tr>
<td/>
<td>(0.000401)</td>
<td>(0.000748)</td>
<td>(0.00183)</td>
<td>(0.00122)</td>
<td>(0.000342)</td>
</tr>
<tr>
<td>Average degree</td>
<td>1.89e-05</td>
<td>5.38e-06</td>
<td>9.86e-05</td>
<td>0.000169<xref ref-type="table-fn" rid="table-fn17-0081175012461248">**</xref></td>
<td>1.44e-05</td>
</tr>
<tr>
<td/>
<td>(1.75e-05)</td>
<td>(3.25e-05)</td>
<td>(7.23e-05)</td>
<td>(5.31e-05)</td>
<td>(1.49e-05)</td>
</tr>
<tr>
<td>Y-mean degree difference</td>
<td>4.51e-05</td>
<td>9.72e-05</td>
<td>0.00130<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>0.000767<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>4.71e-05</td>
</tr>
<tr>
<td/>
<td>(5.44e-05)</td>
<td>(0.000101)</td>
<td>(0.000211)</td>
<td>(0.000165)</td>
<td>(4.64e-05)</td>
</tr>
<tr>
<td>Constant</td>
<td>−0.0110<xref ref-type="table-fn" rid="table-fn17-0081175012461248">**</xref></td>
<td>−0.0424<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>−0.0645<xref ref-type="table-fn" rid="table-fn17-0081175012461248">***</xref></td>
<td>0.00715</td>
<td>0.00806<xref ref-type="table-fn" rid="table-fn17-0081175012461248">**</xref></td>
</tr>
<tr>
<td/>
<td>(0.00341)</td>
<td>(0.00635)</td>
<td>(0.0143)</td>
<td>(0.0104)</td>
<td>(0.00291)</td>
</tr>
<tr>
<td>Observations</td>
<td>162</td>
<td>162</td>
<td>162</td>
<td>162</td>
<td>162</td>
</tr>
<tr>
<td><italic>R</italic><sup>2</sup></td>
<td>.241</td>
<td>.512</td>
<td>.669</td>
<td>.303</td>
<td>.238</td>
</tr>
<tr>
<td>Mean average bias</td>
<td>0.0037</td>
<td>0.0080</td>
<td>0.0348</td>
<td>0.0146</td>
<td>0.0043</td>
</tr>
<tr>
<td>SD average bias</td>
<td>0.0041</td>
<td>0.0094</td>
<td>0.0236</td>
<td>0.0128</td>
<td>0.0034</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn15-0081175012461248">
<p><italic>Notes</italic>: Standard errors are in parentheses. Add Health = National Longitudinal Study of Adolescent Health; RDS = respondent-driven sampling.</p>
</fn>
<fn id="table-fn16-0081175012461248">
<label>a.</label>
<p>“Average bias” refers to the absolute value of the average bias for 500 replications on all the networks (see the text for explanation): <inline-formula id="inline-formula17-0081175012461248">
<mml:math display="inline" id="math35-0081175012461248">
<mml:mrow>
<mml:mtext>average bias</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>500</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mi>bia</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>500</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>bias</italic><sub><italic>ij</italic></sub> is the bias (error) on the ith sample from the jth network.</p>
</fn>
<fn id="table-fn17-0081175012461248">
<label>*</label>
<p><italic>p</italic> &lt; .05. **<italic>p</italic> &lt; .01. ***<italic>p</italic> &lt; .001.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>There are three key findings in the analysis of the DE in <xref ref-type="table" rid="table8-0081175012461248">Table 8</xref>. First, for the hybrid approach, none of the variables have a significant effect (at the <italic>p</italic> = .05 level): In other words, the method does not appear to be sensitive, with samples of 500 cases, to either the level of homophily or the size of the network. Overall, the <italic>R</italic><sup>2</sup> value for the hybrid approach is .076, meaning that little of the variation in DEs is explained by these features of the networks. Second, the measure of network size, ln(nodes), has a significant positive effect on the DE for the list approach, which means that the precision of the estimates declines as the network size increases. Note that the effect is not overwhelmingly large, as going from 500 nodes (ln[nodes] = 6.21) to 10,000 nodes (ln[nodes] = 9.21) would increase the predicted DE by 0.964 × 3 = 2.892. Moreover, note that the problem of network size for the list approach can be solved by sampling a larger number of cases to reduce the sampling variance. However, a comparison of the results for the hybrid and list models indicates the reason the hybrid approach is superior: By using the search mode to explore the network, it increases the efficiency of the sampling process. Next, note that the naive list approach is very sensitive to network size, with a coefficient of 12.14 for ln(nodes) compared with 0.964 for the list approach.</p>
<p>The third key finding of <xref ref-type="table" rid="table8-0081175012461248">Table 8</xref> is that RDS, RW, and the naive list approaches are very sensitive to the level of homophily in the network. The coefficient on homophily for RDS is very large and significant (<italic>b</italic> = 284.1, <italic>SE</italic> = 15.16). In contrast, homophily has no effect on the hybrid and list approaches.</p>
<p><xref ref-type="table" rid="table9-0081175012461248">Table 9</xref> presents results for the analysis of the average bias across the 162 networks of the combined results. All five of these approaches are asymptotically unbiased, in the sense that as the sample size goes to infinity, the average bias will go to zero. As discussed above, for the hybrid, list, and naive list approaches, the asymptotic unbiased behavior derives from the fact that they are sampling from the accumulated list of network members L. However, in these finite samples of 500 cases, all five methods exhibit a small amount of bias (as indicated by the second row from the bottom in <xref ref-type="table" rid="table9-0081175012461248">Table 9</xref>). As indicated in <xref ref-type="table" rid="table9-0081175012461248">Table 9</xref>, the size of the network affects the magnitude of the finite sample bias for the hybrid, list, and naive list approaches, while homophily and average degree are significant predictors of the bias for RDS, and homophily is for RW. Notably, average degree is not associated with bias in the NSM approaches.<sup><xref ref-type="fn" rid="fn24-0081175012461248">24</xref></sup></p>
</sec>
</sec>
<sec id="section22-0081175012461248">
<title>5. Sampling Diagnostics and Convergence to Simple Random Sampling</title>
<p>Earlier in the article, we made the claim that NSM converges to SRS as the sample size increases and all individuals in the population have been nominated on the network rosters (i.e., as <italic>L</italic><sub><italic>S</italic></sub>→<italic>G</italic>). In this section, we state the assumptions that are behind this claim and show how the data from an NSM sample might be used to indicate when convergence to SRS has been achieved. To be clear about what we are claiming, by “converge,” we mean that once NSM has “converged” to SRS, the properties and characteristics of samples obtained by NSM would be indistinguishable from samples obtained from SRS with the same sample size. Although our work in this regard is preliminary, it is our belief that such a diagnostic would provide an immensely useful tool for researchers in practice, allowing them to understand and quantify the statistical validity of a sample collected via NSM as well as to facilitate comparisons across samples.</p>
<p>Requirements for convergence to SRS:</p>
<list id="list7-0081175012461248" list-type="simple">
<list-item>
<p>5.1. The network is connected. Starting from any node, all individuals can be reached by following a path of connections in the network.</p>
</list-item>
<list-item>
<p>5.2. Respondents are willing to provide network data, and the quality of the network data (i.e., partial name information, basic demographics, last three digits of telephone numbers, etc.) is sufficient to uniquely identify network members.</p>
</list-item>
<list-item>
<p>5.3. The sample size reaches a point at which the number of nominated nodes in the network, L, is equal to the estimated size of the network using the capture-recapture method (<inline-formula id="inline-formula18-0081175012461248">
<mml:math display="inline" id="math36-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> in <xref ref-type="disp-formula" rid="disp-formula5-0081175012461248">equation 5</xref>).</p>
</list-item>
<list-item>
<p>5.4. “Even” sampling has been used (see section 3.B), and all nominated nodes have the same cumulative sampling probability.<sup><xref ref-type="fn" rid="fn25-0081175012461248">25</xref></sup> See step 251 of <xref ref-type="table" rid="table2-0081175012461248">Table 2</xref> for an example.</p>
</list-item>
</list>
<p><xref ref-type="fig" rid="fig7-0081175012461248">Figures 7</xref> and <xref ref-type="fig" rid="fig8-0081175012461248">8</xref> show how convergence to SRS can be identified using Facebook network 10 as an example, using NSM’s hybrid approach with 500 replications and samples of 1,000 cases for each replication. Facebook network 10 has 1,092 nodes. <xref ref-type="fig" rid="fig7-0081175012461248">Figure 7</xref> shows the average bias, the proportion of cases that are sampled using the search mode, and P1 (the proportion of nominated nodes with only one nomination) by step (i.e., the number of cases in the sample). Because the search mode is used only when P1 &gt; 0.4 (i.e., when more than 40 percent of the nominated nodes have only been nominated once), the use of the search mode drops to zero as the average value of P1 drops below 0.4 around step 100. In addition, the value of P1 declines toward zero as the sample size increases, indicating that the network is being completely explored around step 600. In addition, the average bias declines very rapidly, and by step 300 it is very small, indicating that the sample estimate has become very accurate at this point.</p>
<fig id="fig7-0081175012461248" position="float">
<label>Figure 7.</label>
<caption>
<p>Diagnostic properties for Facebook network 10 by sample size (step)</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig7.tif"/>
</fig>
<fig id="fig8-0081175012461248" position="float">
<label>Figure 8.</label>
<caption>
<p>Number of nominated nodes and estimated network size by sample size (step), Facebook network</p>
</caption>
<graphic xlink:href="10.1177_0081175012461248-fig8.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig8-0081175012461248">Figure 8</xref> shows the estimated network size (<inline-formula id="inline-formula19-0081175012461248">
<mml:math display="inline" id="math37-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>) and number of nominated nodes by step (<italic>L</italic><sub><italic>S</italic></sub>) in this network, along with the observed 95 percent confidence intervals for both of these measures. It is easy to see in <xref ref-type="fig" rid="fig8-0081175012461248">Figure 8</xref> that they are both converging to the true value of the population size, 1,092. When <inline-formula id="inline-formula20-0081175012461248">
<mml:math display="inline" id="math38-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, then all the nodes in the network have been revealed, and requirement 5.3 has been satisfied. Provided requirements 5.1, 5.2, and 5.4 are also satisfied, then NSM is statistically equivalent to SRS. As discussed above, the basic intuition why this is true is that the even sampling component of the list mode (section 3.B) ensures that all people who are nominated in the survey are subject to the same CSR. Once everyone in population A has been nominated (<italic>L</italic><sub><italic>S</italic></sub> = <italic>N</italic>), then we have a representative sample of S cases from population A.</p>
<p>The benefit of <xref ref-type="fig" rid="fig8-0081175012461248">Figure 8</xref> is that it illustrates how the data collected in an NSM survey can be used as a diagnostic tool to evaluate how close the sample is to converging to SRS. One way to define an adequate stopping rule for an NSM sample would be to collect a sample size S* such that <inline-formula id="inline-formula21-0081175012461248">
<mml:math display="inline" id="math39-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
<p>In <xref ref-type="fig" rid="fig7-0081175012461248">Figure 7</xref>, it is clear that for this particular network, a high level of accuracy is reached around step 300, as the average bias is very close to zero. In <xref ref-type="fig" rid="fig8-0081175012461248">Figure 8</xref>, we see that L and <inline-formula id="inline-formula22-0081175012461248">
<mml:math display="inline" id="math40-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> are very close by step 300 (they differ by 7 percent), although complete convergence between L and <inline-formula id="inline-formula23-0081175012461248">
<mml:math display="inline" id="math41-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is not reached until around step 600. If we define the degree of convergence between the number of nominated cases L and the estimated population size <inline-formula id="inline-formula24-0081175012461248">
<mml:math display="inline" id="math42-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> as</p>
<p>
<disp-formula id="disp-formula19-0081175012461248">
<mml:math display="block" id="math43-0081175012461248">
<mml:mrow>
<mml:mi>q</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>100</mml:mn>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula19-0081175012461248" xlink:href="10.1177_0081175012461248-eq19.tif"/>
</disp-formula></p>
<p>then it may be the case that the marginal return in accuracy of going from q = 0.93 to q = 0.999 in general is very small. In future research, we plan on refining the definition of the optimal stopping point for an NSM sample on the basis of different values of q, allowing for a reasonable threshold of convergence between <inline-formula id="inline-formula25-0081175012461248">
<mml:math display="inline" id="math44-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> and L by testing the marginal gains in precision for a range of values of q over the 162 networks evaluated here.<sup><xref ref-type="fn" rid="fn26-0081175012461248">26</xref></sup> Because the purpose of this section is simply to illustrate that such diagnostics are possible with NSM, we leave further refinement of these issues to future work.</p>
</sec>
<sec id="section23-0081175012461248">
<title>6. Is It Feasible?</title>
<p>We envision NSM being used by two types of research projects. First, network-based sampling methods, such as RDS, are attractive when the target population is rare or hidden and there is no sampling frame available for the researcher. Second, sometimes the goal of the survey is to actually collect data about the network itself, and NSM allows the researcher to collect an accurate sample while following the links connecting people in a network together. In this section, we discuss the feasibility of collecting the network data needed to run NSM. There are three questions that must be answered to make that decision: (1) How many people can we expect individuals to nominate? (2) Can we protect confidentiality but at the same time match alters who have been nominated by multiple individuals? (3) How sensitive is the method to coding errors and other logistical problems? We consider these first two issues in depth using our experience surveying a hidden population and evidence from the literature. We then present some preliminary work on the third question.</p>
<sec id="section24-0081175012461248">
<title>6.1 Collecting Network Data</title>
<p>In the summer of 2010, we conducted a pilot study to test the feasibility of collecting network data on a difficult-to-reach population. Along with several other colleagues, we collected data on the migration network connecting a Mexican community from a medium-sized town in the state of Guanajuato to migrants from that hometown currently living in North Carolina and Houston, Texas. The resulting survey, the 2010 Network Survey of Immigration and Transnationalism (NSIT) had a sample size of 150 in North Carolina, 52 in Houston, and 407 in Guanajuato. We started the data collection with a snowball sample in North Carolina and Houston and then followed links back to Guanajuato.</p>
<p>We asked respondents to nominate network alters who were eligible to be in the survey and to whom they could refer us. To protect the privacy of respondents, we collected data on only the first four letters of the first name and last name of the respondent’s network members, along with key social and demographic information that we could use for identification: nickname, gender, age, occupation, and number of children living in the household. To identify unique individuals in the resulting network data, we wrote a matching program in Stata that tolerates slight differences in the demographic and name variables in determining whether two network nominations (from different interviews) represent the same person. We used the Levenshtein edit distance (the number of edits needed to match two strings, cf. <xref ref-type="bibr" rid="bibr63-0081175012461248">Reif 2010</xref>) to allow for reporting and coding errors in the first name, last name, and nickname.</p>
<p>The North Carolina and Houston samples asked for up to 10 friends and 5 family members currently living in the destination community in the United States, up to 6 total family and friends currently living in the origin city in Mexico, and up to 5 returned migrants currently living in the origin. Of the 150 respondents in North Carolina, the average number of network members was 21.2.<sup><xref ref-type="fn" rid="fn27-0081175012461248">27</xref></sup> The network questions were placed at the beginning of the survey and took an average of 10 minutes to complete. All of the interviews, aside from pretests, were conducted by community members. Of the 8,538 nominations of friends and family members in the survey overall, all but 19 reported a first name, 98.96 percent reported a last name, and 94.7 percent reported age.</p>
<p>In addition to the data we collected in the 2010 NSIT, there is other evidence that similar amounts of network data could realistically be collected on social surveys. A reasonable question is how many alters a given ego might nominate, because the larger the number of nominations a person can give, the quicker the search mode will be able to explore the network. In general, it is clear that over a period of time, people come into contact with far more individuals than they are aware of—<xref ref-type="bibr" rid="bibr12-0081175012461248">Boissevain (1974)</xref> and <xref ref-type="bibr" rid="bibr56-0081175012461248">McCarty et al. (2000)</xref> estimated contact networks of between 1,500 and 2,000 people—but may be only able to remember and identify a fraction of these. <xref ref-type="bibr" rid="bibr22-0081175012461248">Dunbar (1998)</xref> reported that people typically can only remember about 150 individuals. In a recent example of extensive network data collection, <xref ref-type="bibr" rid="bibr67-0081175012461248">Sandberg et al. (2008)</xref> found that residents of rural Senegal named an average of 21.4 unique network alters (the interquartile range was 17–25) when asked 15 name generating questions with open-ended numbers of potential responses. Similarly, in a classic work, <xref ref-type="bibr" rid="bibr55-0081175012461248">McCallister and Fischer (1978)</xref> found that most respondents in the Northern California Community Survey were able to name between 10 and 30 alters and the type of relation to them in 20 minutes of interview time (a pilot survey elicited an average of 20.3 names and the total survey an average of 18.5). Overall, on the basis of the results from the 2010 NSIT and other surveys that have obtained between 10 and 30 nominations per respondent, we argue that it is possible to collect enough network data to improve the accuracy of network sampling. Of course, it might not be possible for all target populations, if the actual networks are sparse, or if participants are reluctant to provide (or it is deemed unsafe to ask them to provide) information about network ties.</p>
</sec>
<sec id="section25-0081175012461248">
<title>6.2 Can We Protect Confidentiality in Stigmatized Populations?</title>
<p>Our work with the NSIT provides some evidence that it is possible to match alters using a small set of demographic characteristics that are unlikely to put respondents of stigmatized populations at risk for deductive disclosure. Other ways to achieve this are being explored in the literature. <xref ref-type="bibr" rid="bibr21-0081175012461248">Dombrowski et al. (2011)</xref> devised a method to estimate the size of hidden populations using the capture-recapture method within a respondent-driven sample. They achieved this by collecting data on respondents’ appearance (approximate height, weight, hair color, eye color, gender, and race/ethnicity) as well as a transformation of the last three digits of their telephone numbers. These digits were encoded as either being even or odd and greater than or equal to five. Such a six-bit code is highly likely to be unique within a given population but at the same time is nearly impossible to trace back to an individual person. They also solicited this information about five of each respondent’s friends who were eligible for inclusion in the study. By matching such data on the individuals at risk for being surveyed (by being friends with individuals who were surveyed and being eligible members of the population) to those who were actually interviewed, the authors were able to apply capture-recapture techniques and estimate the size of the total network.</p>
<p>Of course, not all populations of interest have mobile phones on which they can look up their acquaintances’ numbers, and there is the potential that looking up such information may add considerable time to the survey. However, other encoding schemes could be devised. For instance, one could apply the same logic to the first three letters of individuals’ first and last names (e.g., is it a vowel or consonant; is it at the beginning, in the middle, or at the end of the alphabet). Because we believe that the issues of respondent risk need to be weighed on a case-by-case basis, we do not have specific recommendations as to what is the best means of collecting such data, but we note that very promising approaches are being tested. On the basis of our experience with the NSIT and the evidence in the literature, we are confident that appropriate data collection strategies could be designed to maximize respondent anonymity while at the same time making network matching techniques feasible.</p>
</sec>
<sec id="section26-0081175012461248">
<title>6.3 Test of the Effect of Network Coding Errors</title>
<p>How robust are the results to the possibility of coding errors in the identification of network members? First, a long literature has documented problematic evidence of recall bias and underenumeration in network measurement through self-reports (e.g., <xref ref-type="bibr" rid="bibr8-0081175012461248">Bell, Montoya, and Atkinson 2000</xref>; <xref ref-type="bibr" rid="bibr10-0081175012461248">Bernard and Killworth 1977</xref>; <xref ref-type="bibr" rid="bibr11-0081175012461248">Bignami-Van Assche and Watkins 2004</xref>; <xref ref-type="bibr" rid="bibr17-0081175012461248">Cascairo, Carley, and Krackhardt 1999</xref>; <xref ref-type="bibr" rid="bibr19-0081175012461248">Coleman, Katz, and Menzel 1966</xref>; <xref ref-type="bibr" rid="bibr23-0081175012461248">Eagle, Pentland, and Lazer 2009</xref>; <xref ref-type="bibr" rid="bibr26-0081175012461248">Freeman, Romney, and Freeman 1987</xref>; <xref ref-type="bibr" rid="bibr36-0081175012461248">Hammer 1984</xref>). It is realistic, certainly, to anticipate a certain degree of coding error in identifying network members on the basis of survey data. Nonetheless, the combination of partial name data and key demographic variables may result in a fairly high level of accuracy. In the 2010 NSIT, we looked over the data for the first 1,000 nominations with the help of community members after running the matching program on first name, last name, nickname, age, gender, origin community, and number of children, and our assessment was that the program was working just as accurately as someone with a detailed knowledge of the community could do in assigning unique identifiers to the nominations. This degree of matching is especially heartening given the relative name similarities in the population and the cultural preference for nicknames.</p>
<p>Other attempts at matching network nominations to individuals in different populations have yielded similar results. <xref ref-type="bibr" rid="bibr67-0081175012461248">Sandberg et al. (2008)</xref> tested the feasibility of augmenting a large data collection project (N ≈ 30,000) with a social network survey that collected detailed relationship data from a sample of respondents. The innovation was that network alters would be linked to existing data records on them, circumventing the need to rely on ego reports of alter characteristics and greatly reducing the costs of network data collection. In field testing this approach, they found that approximately 88 percent of nominated alters could be uniquely identified with just five pieces of information that could reasonably be collected from respondents. This evidence further underscores the feasibility of our proposed approach.</p>
<p>We tested the impact of coding errors on the efficiency of NSM by used a modified algorithm that creates errors in the coding of the network data with a certain probability. Network ties that are coded in error are assigned to someone else in the currently revealed network (a sampled or unsampled, but nominated, node). We tested the impact of errors on a sample of 44 of our large university Facebook networks discussed above, using a 15 percent rate of error. Using the hybrid method with a 15 percent error rate, the average DE for these 44 networks with 500 replications of a sample size of 500 was 1.27, compared with a 1.23 average DE for the hybrid method with no errors in the coding of the network data. For the purposes of comparison, the average DE for RDS with no errors in coding on these three networks was 65.66.<sup><xref ref-type="fn" rid="fn28-0081175012461248">28</xref></sup> Overall, these results indicate that a moderate level of error in the coding of the network data has only a minimal affect the performance of NSM. At the same time, high levels of coding error would certainly reduce the efficiency of NSM, and it is crucial that careful attention be paid to collecting partial name and demographic identifiers that will facilitate a high level of accuracy in the coding of the network data.</p>
<p>Before NSM is implemented in the field, other logistical considerations should also be taken into account. These issues include developing a better understanding of how nonresponse may bias results, developing protocols to ensure respondent protection, and testing the method’s efficacy when list-based sampling is implemented only a small number of times, which would reduce the burden of recontacting respondents. For example, in future research, we plan on testing a variant of NSM that minimizes or eliminates the need for recontact by entering the respondent’s network information directly into a computer or a smart phone during the interview, updating the network, and asking for a referral at the end of the interview itself. On the basis of the updated network data, we could use the search mode to select whom we ask for a referral to among the respondent’s network roster on the basis of which node is most likely to lead to new or underexplored parts of the network. This approach would reduce the cost of conducting an NSM survey while still using the accumulated network data to make the sampling process more efficient than a conventional RW.</p>
</sec>
</sec>
<sec id="section27-0081175012461248" sec-type="discussion|conclusions">
<title>7. Discussion and Conclusion</title>
<p>RDS is an RW-based sampling approach that has become popular as a method of collecting data from hidden or rare populations. However, the sampling variance of RDS depends on the structure of the underlying social network (<xref ref-type="bibr" rid="bibr7-0081175012461248">Bassetti and Diaconis 2006</xref>; <xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik 2009</xref>), which is unknown to a researcher using RDS data that consists of only the links that were followed by the sample. Recent tests using real networks indicate that the sampling variance of respondent-driven samples may be unacceptably high (<xref ref-type="bibr" rid="bibr32-0081175012461248">Goel and Salganik 2010</xref>; <xref ref-type="bibr" rid="bibr51-0081175012461248">Lu et al. 2012</xref>; <xref ref-type="bibr" rid="bibr57-0081175012461248">McCreesh et al. 2012</xref>).</p>
<p>In this article, we propose an alternative approach, NSM, which collects network rosters as part of the survey and uses the revealed list of network members to improve the efficiency of the sampling process. NSM samples from the list of network members using two sampling modes, list and search. As discussed above, the basic innovation of the list mode is quite simple: Rather than take a randomly selected link from the current case as in RDS or an RW, in the list mode, the next node to be sampled is chosen by sampling with replacement from the complete list of all people who have been nominated in the survey. Although RDS and RWs can get stuck in segregated islands of the network, which increases the sampling variance, the list mode does not get stuck, because it draws the next case from the set of all individuals who have appeared on the network rosters. In addition, the list mode ensures that all people on the network list are sampled at the same rate by sampling newly discovered network members at the same CSR of the sample as a whole. As the survey progresses and all the members of the population are gradually added to the network list, the list mode becomes identical to the process of SRS.</p>
<p>As discussed above in section 3.C, the search mode is designed to speed up the process of exploring the network by giving priority to “bridge nodes” that connect the edges of the currently explored network to underexplored areas of the network. The hybrid approach that we test in the simulated sampling combines the list and search modes, using the search mode initially and then defaulting to the list mode once the network has been explored.</p>
<p>We test the relative performance of NSM versus RDS, RW, and SRS by conducting simulated sampling on 162 observed social networks from Add Health and Facebook. The advantage of testing the performance of the methods on so many different networks is that we can be more confident that the results are not due to the idiosyncrasies of any particular network. The networks ranged in size from 110 to 16,278 nodes, with different levels of homophily and mean degree. Moreover, because these are real social networks, they will exhibit the kinds of complex network structures that artificial test networks may not have. Overall, as discussed above, our results indicated that NSM’s hybrid and list approaches had lower DEs than RDS or RW on all 162 of the Add Health and Facebook networks, based on drawing 500 samples of 500 cases each from each network. In particular, the hybrid approach resulted in a 98.5 percent reduction in the average DE compared with RDS (1.16 vs. 77.4).</p>
<p>Although in all of our tests, NSM is a more efficient method of sampling from a social network than RDS, there is an added cost, which is the time and effort needed to collect network data as well as recontact respondents to get referrals to previously nominated cases.<sup><xref ref-type="fn" rid="fn29-0081175012461248">29</xref></sup> As discussed above in section 6, we conducted a pilot study on collecting network data from a hidden population—immigrants in North Carolina from a specific origin community in Mexico—and averaged 21.4 links per respondent in North Carolina, obtaining almost universal responses on the first four letters of the first and last names and the ages of the members of respondents’ networks. This indicates that it is feasible to collect the level of network data needed to achieve the gains in accuracy we present in this article. At the same time, it is important to emphasize that we do not anticipate that NSM will be applicable for every situation. Nonetheless, researchers are devising innovative ways to collect this type of data in even highly stigmatized populations (<xref ref-type="bibr" rid="bibr21-0081175012461248">Dombrowski et al. 2011</xref>). Indeed, <xref ref-type="bibr" rid="bibr21-0081175012461248">Dombrowski et al. (2011)</xref> demonstrated that individuals’ network alters could be uniquely identified for the purposes of capture-recapture methods while maintaining respondent confidentiality in exactly the type of population in which RDS was designed to be implemented.</p>
<p>Even if the added difficulty of collecting network data means that NSM is not universally applicable for all types of hidden or difficult to reach populations, we believe there are two reasons it represents an important addition to the literature on sampling from networks. First, if researchers can collect network data as part of their survey, our results indicate large potential gains in sampling efficiency: Simply put, it takes far fewer cases for NSM to reach a given level of precision compared with RDS. Recognition of the trade-off between the cost and precision of the survey is important even if a research project elects to use RDS or a conventional link-tracing survey design. Second, on a theoretical level, NSM provides a clear example of how gains in accuracy can result from a simple modification of the sampling algorithm compared with an RW-based approach. We seek to bridge the recent literature in mathematics and computer science on sampling large Internet-based networks with the social science literature on sampling hidden or rare populations on the basis of face-to-face or telephone interviews. Although there is a fundamental difference in the cost of conducting an interview (trivial for an Internet-based network and high for a face-to-face interview), there is likely to be considerable synergy and convergence between these two literatures in the future. In this light, we see NSM as a first step in demonstrating how collecting network data can improve the accuracy of sampling from networks.</p>
<p>In particular, we anticipate several avenues of future research. First, it is possible that with computer-assisted interviews (i.e., inputting the network data directly during the interview) the interviewer might be able to solicit referrals to newly identified nodes of the network at the conclusion of each interview, thereby reducing the frequency with which respondents would need to be recontacted to get a referral to the next person to interview. Second, we plan to explore whether it is possible to use resampling methods to infer the sampling variance of the resulting NSM sample. The idea would be to predict the ties from unsampled but nominated nodes using a statistical model of the network and then repeatedly resample the data from the predicted network to calculate bootstrap standard errors. Third, we intend to assess how the accumulated network data could be used to develop in an optimal stopping rule regarding the sample size required to reach a certain degree of sampling precision.</p>
<p>Overall, in the current article, we have presented an alternative method for sampling from network-based populations that is both transparent in terms of its underlying mechanism and, in all of our tests, considerably more accurate than the methods currently in use. Indeed, in the results presented in <xref ref-type="fig" rid="fig3-0081175012461248">Figures 3</xref>, <xref ref-type="fig" rid="fig5-0081175012461248">5</xref>, and 6, we found that a roughly equivalent level of sampling precision was achieved with 75 cases sampled using our proposed method as could be found with 500 to 1,000 cases using the currently dominant approach. Furthermore, we have offered first steps toward quantifying the extent of NSM’s results’ convergence to SRS, diagnostics that are currently unavailable or inadequate (cf. <xref ref-type="bibr" rid="bibr60-0081175012461248">Neely 2009</xref>; <xref ref-type="bibr" rid="bibr72-0081175012461248">Wejnert 2009</xref>) in the network sampling literature to date. Although our proposed method would constitute an increased logistical burden for researchers as well as other potential trade-offs, we believe it presents considerable promise. Rather than an end point, we view this as a call for future advances in improving the efficiency and precision of sampling from networks using survey data on the revealed network of the target population.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors disclosed receipt of the following financial support for the research and/or authorship of this article: The authors are grateful for the support provided by the Carolina Population Center of the University of North Carolina, Chapel Hill to both Mouw and Verdery that aided this research. This paper uses data from Add Health, a program project designed by J. Richard Udry, Peter S. Bearman, and Kathleen Mullan Harris, and funded by a grant P01-HD31921 from the National Institute of Child Health and Human Development, with cooperative funding from 17 other agencies.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0081175012461248">
<label>1.</label>
<p>For simplicity of writing, we occasionally refer to sampling from a social network as “network sampling” in this article. When we do this, we mean sampling from a social network, not the large body of work dedicated to making inferences about social network structures from more limited data (e.g., <xref ref-type="bibr" rid="bibr61-0081175012461248">Potter et al. 2011</xref>).</p>
</fn>
<fn fn-type="other" id="fn2-0081175012461248">
<label>2.</label>
<p>This discussion offers some intuition about RDS’s efficacy as it is used in practice (when its assumptions are not always met; <xref ref-type="bibr" rid="bibr28-0081175012461248">Gile and Handcock 2010</xref>). The fact that RDS is conducted without replacement adds an element of memory to the RW process, which, on the basis of these results, would suggest that it may prove more efficient in without-replacement practice than with-replacement theory (although see <xref ref-type="bibr" rid="bibr29-0081175012461248">Gile 2011</xref>). Additionally, the fact that RDS in practice starts from multiple seed individuals may also improve its efficiency, as per <xref ref-type="bibr" rid="bibr64-0081175012461248">Ribeiro and Towsley (2010)</xref>.</p>
</fn>
<fn fn-type="other" id="fn3-0081175012461248">
<label>3.</label>
<p>In our proposed approach, sampling with replacement is achieved by keeping track of how many times individuals are sampled and using this as a weight. No repeat interviews are actually conducted.</p>
</fn>
<fn fn-type="other" id="fn4-0081175012461248">
<label>4.</label>
<p>Multiple seeds can be used; in general, this is most effective if they are from different parts of the network.</p>
</fn>
<fn fn-type="other" id="fn5-0081175012461248">
<label>5.</label>
<p>L also includes the initial seed respondent(s).</p>
</fn>
<fn fn-type="other" id="fn6-0081175012461248">
<label>6.</label>
<p>One way to resolve this is to not turn on even sampling until P1 (the proportion of nominated nodes that have only one nomination) is less than 0.4, which ensures that large networks are explored before even sampling is turned on. See <xref ref-type="disp-formula" rid="disp-formula5-0081175012461248">equation 5</xref> for a discussion of estimating the network size using P1.</p>
</fn>
<fn fn-type="other" id="fn7-0081175012461248">
<label>7.</label>
<p>This is because, at the start of even sampling, all nodes that have already been nominated will have CSR &gt; ESR. Using the 100 nodes with the lowest CSR is a way to gradually “wean” the sample away from nodes with high CSRs.</p>
</fn>
<fn fn-type="other" id="fn8-0081175012461248">
<label>8.</label>
<p>The reason for this is that after the start of even sampling, nodes 1 and 301 were not eligible for sampling again until their CSR was less than or equal to the current ESR, as described in section 3.B.1. Thus, they will be within the sampling rate of one step of the ESR.</p>
</fn>
<fn fn-type="other" id="fn9-0081175012461248">
<label>9.</label>
<p>In the calculation of P1, any node that has been sampled is counted as a node that has more than one nomination.</p>
</fn>
<fn fn-type="other" id="fn10-0081175012461248">
<label>10.</label>
<p>This can be seen by looking at the effect of network size (natural log of nodes) on the design effect for the list mode in <xref ref-type="table" rid="table8-0081175012461248">Table 8</xref>.</p>
</fn>
<fn fn-type="other" id="fn11-0081175012461248">
<label>11.</label>
<p>NSM’s search mode skips to other parts of the network on the basis of a probabilistic model of where the bridge nodes are most likely to be. In contrast, breadth-first search explores all of the nodes neighboring the currently sampled node before moving down the chain, while depth-first search moves down the chain of connections as fast as possible before visiting nodes that have already been nominated.</p>
</fn>
<fn fn-type="other" id="fn12-0081175012461248">
<label>12.</label>
<p>A simpler method is just to choose among the nodes with the highest vales of <italic>p</italic>1<sub><italic>j</italic></sub>, but this gives an advantage to nodes with low degree, because it is easier to obtain higher values of <italic>p</italic>1<sub><italic>j</italic></sub> just by chance. In addition, for simplicity, we ignore the probability that j is sampled conditional on being nominated, because this will be the same for all nominated nodes after the initiation of even sampling, and the goal in <xref ref-type="disp-formula" rid="disp-formula7-0081175012461248">equation 7</xref> is a relative measure of the likelihood of a bridge node.</p>
</fn>
<fn fn-type="other" id="fn13-0081175012461248">
<label>13.</label>
<p>We also tried choosing among the top 2 and top 10 bridge nodes, and both of these alternatives seemed to work equally well. In addition, to ensure that these really are what we mean by “bridge nodes,” only nodes with <italic>p</italic>1<sub>
<italic>j</italic></sub>≥ 0.4 are eligible for consideration in <xref ref-type="disp-formula" rid="disp-formula7-0081175012461248">equation 7</xref>.</p>
</fn>
<fn fn-type="other" id="fn14-0081175012461248">
<label>14.</label>
<p>We weight both the RW and RDS results by their inverse degree. For the binary outcomes we consider here (Y), we calculate the estimated proportion of Y = 1 in our RWs as <inline-formula id="inline-formula26-0081175012461248">
<mml:math display="inline" id="math45-0081175012461248">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>rw</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>y</italic><sub><italic>j</italic></sub> is the value of variable y for individual j (either 0 or 1), <italic>d</italic><sub><italic>j</italic></sub> is individual j’s degree, and S is the number of sampled cases. Some have called an RW weighted in this fashion a reweighted RW (cf. <xref ref-type="bibr" rid="bibr30-0081175012461248">Gjoka et al. 2010</xref>). This estimator is the RDS2 estimator in current use, so we also apply it to our respondent-driven samples.</p>
</fn>
<fn fn-type="other" id="fn15-0081175012461248">
<label>15.</label>
<p>RW approaches have not been implemented in the field to our knowledge, but even if they were, it is a challenge to imagine that they would be conducted with replacement in a human population.</p>
</fn>
<fn fn-type="other" id="fn16-0081175012461248">
<label>16.</label>
<p><xref ref-type="bibr" rid="bibr31-0081175012461248">Goel and Salganik (2009)</xref> also considered how DEs varied across high schools and high school–middle school combinations and found no substantive differences. As such, we do not distinguish these types of schools in our analysis; however, we do examine how biases vary across different observed parameters of these networks.</p>
</fn>
<fn fn-type="other" id="fn17-0081175012461248">
<label>17.</label>
<p>We decided to omit schools with supermajorities by race, because these cases were extremely problematic for RDS. This is in line with <xref ref-type="bibr" rid="bibr72-0081175012461248">Wejnert’s (2009)</xref> findings that very small or very large proportions pose particular challenges for RDS.</p>
</fn>
<fn fn-type="other" id="fn18-0081175012461248">
<label>18.</label>
<p>By “random assignment,” we mean the number of cross-group friends if each person’s friends were assigned randomly to different groups. For example, in a school that is 80 percent white and 20 percent nonwhite, 20 percent of white students’ friends would be nonwhite and 80 percent of nonwhite students’ friends would be white.</p>
</fn>
<fn fn-type="other" id="fn19-0081175012461248">
<label>19.</label>
<p>In addition, we note that the average finite-sample bias in column 2 of <xref ref-type="table" rid="table6-0081175012461248">Table 6</xref> is comparable with the average bias reported in column 1, provided we take the fact that the global mean of the dependent in column 2 variable (mean degree in the school) is about 10 times larger than the global mean of proportion white.</p>
</fn>
<fn fn-type="other" id="fn20-0081175012461248">
<label>20.</label>
<p>In the year after these data were captured, Facebook expanded to allow access to nonuniversity students.</p>
</fn>
<fn fn-type="other" id="fn21-0081175012461248">
<label>21.</label>
<p>To ensure that the truncated networks are connected, we arrange the nodes sequentially by class year (freshman vs. nonfreshman) in a single line running from 1 to G and assign each node ties to their immediate neighbor in front and behind them. These are included in each instantiation of the network and are counted toward the friendship totals for each node. This procedure has little effect on the overall structure of the network, however, as the untruncated networks are highly connected.</p>
</fn>
<fn fn-type="other" id="fn22-0081175012461248">
<label>22.</label>
<p>Using the full network data, the average DEs for RDS and RW were 78.7 and 16.65, respectively.</p>
</fn>
<fn fn-type="other" id="fn23-0081175012461248">
<label>23.</label>
<p>We use the results for proportion white as the dependent variable for the Add Health data.</p>
</fn>
<fn fn-type="other" id="fn24-0081175012461248">
<label>24.</label>
<p>Overall, when evaluating these results, note that we have chosen two dependent variables (percentage nonwhite and percentage first-year students) for which there are high levels of homophily and clustering. The DE for RDS would be lower if we had chosen networks with lower levels of clustering or different dependent variables. In practice, of course, the researcher will not know how clustered the network of the target population is, and the goal here has been to test NSM on networks that are difficult for network-based sampling algorithms.</p>
</fn>
<fn fn-type="other" id="fn25-0081175012461248">
<label>25.</label>
<p>Note that the use of sampling weights (<xref ref-type="disp-formula" rid="disp-formula10-0081175012461248">equations 9</xref> and <xref ref-type="disp-formula" rid="disp-formula11-0081175012461248">10</xref>) adjusts for unequal sampling rates among nodes prior to convergence to SRS.</p>
</fn>
<fn fn-type="other" id="fn26-0081175012461248">
<label>26.</label>
<p>In general, we also note that we observed a very high level of accuracy for the predicted population size <inline-formula id="inline-formula27-0081175012461248">
<mml:math display="inline" id="math46-0081175012461248">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> using the capture-recapture method on all of the 162 networks that we tested.</p>
</fn>
<fn fn-type="other" id="fn27-0081175012461248">
<label>27.</label>
<p>In the Mexico sample, we asked for data on up to 6 friends and 6 relatives currently living in Guanajuato and up to 6 friends and family members living in North Carolina and Houston. The overall average degree was 14.13.</p>
</fn>
<fn fn-type="other" id="fn28-0081175012461248">
<label>28.</label>
<p>The average finite sample bias was .0057, compared with .0036 for the hybrid approaches with and without the 15 percent error rate with the truncated data (maximum degree of 20), compared with .297 and .0118 for RDS with the truncated and full network data.</p>
</fn>
<fn fn-type="other" id="fn29-0081175012461248">
<label>29.</label>
<p>Recontacting participants may not be feasible in some hidden populations. See the final paragraph of section 6 for a discussion of a future variant of NSM that would eliminate recontact with respondents.</p>
</fn>
</fn-group>
</notes>
<bio>
<title>Bios</title>
<p><bold>Ted Mouw</bold> is a sociologist at the University of North Carolina, Chapel Hill. His research interests are labor markets, social stratification, and immigration. His current research includes a project on the collection of social network data on immigration from origin and destination communities in Mexico and the United States and a project on the skill complementarity between immigrants and native workers using a large longitudinal data set from the Longitudinal Employer Household Data (LEHD).</p>
<p><bold>Ashton M. Verdery</bold> is a doctoral candidate in the Department of Sociology at the University of North Carolina at Chapel Hill. His research focuses on social networks, quantitative methods, and demography. His papers have been published in journals such as <italic>Social Networks</italic> and the <italic>Annals of the Association of American Geographers.</italic></p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Abdul-Quader</surname><given-names>A. S.</given-names></name>
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
<name><surname>Sabin</surname><given-names>K.</given-names></name>
<name><surname>Saidel</surname><given-names>T.</given-names></name>
</person-group> <year>2006</year>. “<article-title>Implementation and Analysis of Respondent-driven Sampling: Lessons Learned from the Field</article-title>.” <source>Journal of Urban Health: Bulletin of the New York Academy of Medicine</source> <volume>83</volume>(<issue>7</issue>):<fpage>i1</fpage>–<lpage>i5</lpage>.</citation>
</ref>
<ref id="bibr2-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Alon</surname><given-names>N.</given-names></name>
<name><surname>Avin</surname><given-names>C.</given-names></name>
<name><surname>Koucky</surname><given-names>M.</given-names></name>
<name><surname>Kozma</surname><given-names>G.</given-names></name>
<name><surname>Lotker</surname><given-names>Z.</given-names></name>
<name><surname>Tuttle</surname><given-names>M. R.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Many Random Walks Are Faster Than One</article-title>.” Pp. <fpage>119</fpage>–<lpage>28</lpage> in <conf-name>Proceedings of the Twentieth Annual Symposium on Parallelism in Algorithms and Architectures</conf-name>. <conf-loc>New York: Association for Computing Machinery</conf-loc>.</citation>
</ref>
<ref id="bibr3-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Alon</surname><given-names>N.</given-names></name>
<name><surname>Benjamini</surname><given-names>I.</given-names></name>
<name><surname>Lubetzky</surname><given-names>E.</given-names></name>
<name><surname>Sodin</surname><given-names>S.</given-names></name>
</person-group> <year>2007</year>. “<article-title>Nonbacktracking Random Walks Mix Faster</article-title>.” <source>Communications in Contemporary Mathematics</source> <volume>9</volume>:<fpage>585</fpage>–<lpage>603</lpage>.</citation>
</ref>
<ref id="bibr4-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Atrostic</surname><given-names>B. K.</given-names></name>
<name><surname>Bates</surname><given-names>Nancy</given-names></name>
<name><surname>Burt</surname><given-names>Geraldine</given-names></name>
<name><surname>Silberstein</surname><given-names>Adriana</given-names></name>
</person-group>. <year>2001</year>. “<article-title>Nonresponse in U.S. Government Household Surveys: Consistent Measures, Recent Trends and New Insights</article-title>.” <source>Journal of Official Statistics</source> <volume>17</volume>(<issue>2</issue>):<fpage>209</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr5-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Avin</surname><given-names>C.</given-names></name>
<name><surname>Krishnamachari</surname><given-names>B.</given-names></name>
</person-group> <year>2008</year>. “<article-title>The Power of Choice in Random Walks: An Empirical Study</article-title>.” <source>Computer Networks</source> <volume>52</volume>(<issue>1</issue>):<fpage>44</fpage>–<lpage>60</lpage>.</citation>
</ref>
<ref id="bibr6-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Avrachenkov</surname><given-names>K.</given-names></name>
<name><surname>Ribeiro</surname><given-names>B.</given-names></name>
<name><surname>Towsley</surname><given-names>D.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Improving Random Walk Estimation Accuracy with Uniform Restarts.” Technical Report No</article-title>. <source>7394</source>. <publisher-loc>Sophia Antipolis, France</publisher-loc>: <publisher-name>Institut National de Recherche en Informatique et en Automatique</publisher-name>.</citation>
</ref>
<ref id="bibr7-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bassetti</surname><given-names>F.</given-names></name>
<name><surname>Diaconis</surname><given-names>P.</given-names></name>
</person-group> <year>2006</year>. “<article-title>Examples Comparing Importance Sampling and the Metropolis Algorithm</article-title>.” <source>Illinois Journal of Mathematics</source> <volume>50</volume>(<issue>1–4</issue>):<fpage>67</fpage>–<lpage>91</lpage>.</citation>
</ref>
<ref id="bibr8-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bell</surname><given-names>D. C.</given-names></name>
<name><surname>Montoya</surname><given-names>I. D.</given-names></name>
<name><surname>Atkinson</surname><given-names>J. S.</given-names></name>
</person-group> <year>2000</year>. “<article-title>Partner Concordance in Reports of Joint Risk Behaviors</article-title>.” <source>Journal of Acquired Immune Deficiency Syndromes</source> <volume>25</volume>:<fpage>173</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr9-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Berenbrink</surname><given-names>P.</given-names></name>
<name><surname>Cooper</surname><given-names>C.</given-names></name>
<name><surname>Elsasser</surname><given-names>R.</given-names></name>
<name><surname>Radzik</surname><given-names>T.</given-names></name>
<name><surname>Sauerwald</surname><given-names>T.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Speeding Up Random Walks with Neighborhood Exploration</article-title>.” Pp. <fpage>1422</fpage>–<lpage>35</lpage> in <conf-name>Proceedings of the Twenty-first Annual ACM-SIAM Symposium on Discrete Algorithms</conf-name>. <conf-loc>Philadelphia, PA: Society for Industrial and Applied Mathematics</conf-loc>.</citation>
</ref>
<ref id="bibr10-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bernard</surname><given-names>H. R.</given-names></name>
<name><surname>Killworth</surname><given-names>P. D.</given-names></name>
</person-group> <year>1977</year>. “<article-title>Informant Accuracy in Social Network Data II</article-title>.” <source>Human Communications Research</source> <volume>4</volume>:<fpage>3</fpage>–<lpage>18</lpage>.</citation>
</ref>
<ref id="bibr11-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bignami-Van Assche</surname><given-names>S.</given-names></name>
<name><surname>Watkins</surname><given-names>S. C.</given-names></name>
</person-group> <year>2004</year>. “<article-title>Husband-wife Disagreement in Rural Malawi: A Longitudinal Analysis</article-title>.” <conf-name>Paper presented at the annual meeting of the Population Association of America</conf-name>, <conf-date>April</conf-date>, <conf-loc>Boston</conf-loc>.</citation>
</ref>
<ref id="bibr12-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Boissevain</surname><given-names>J.</given-names></name>
</person-group> <year>1974</year>. <source>Friends of Friends</source>. <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr13-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boyd</surname><given-names>D. M.</given-names></name>
<name><surname>Ellison</surname><given-names>N.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Social Network Sites: Definition, History, and Scholarship</article-title>.” <source>Journal of Computer-mediated Communication</source> <volume>13</volume>(<issue>1</issue>):<fpage>210</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr14-0081175012461248">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Brin</surname><given-names>S.</given-names></name>
<name><surname>Page</surname><given-names>L.</given-names></name>
</person-group> <year>1998</year>. “<article-title>The Anatomy of a Large-scale Hypertextual Web Search Engine</article-title>.” <conf-name>Paper presented at the Seventh International World-wide Web Conference (WWW 1998)</conf-name>, <month>April</month> <conf-date>14–18</conf-date>, <conf-loc>Brisbane, Australia</conf-loc>.</citation>
</ref>
<ref id="bibr15-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Burt</surname><given-names>R. S.</given-names></name>
</person-group> <year>1984</year>. “<article-title>Network Items and the General Social Survey</article-title>.” <source>Social Networks</source> <volume>6</volume>:<fpage>293</fpage>–<lpage>339</lpage>.</citation>
</ref>
<ref id="bibr16-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Burt</surname><given-names>Ronald S.</given-names></name>
</person-group> <year>1995</year>. <source>Structural Holes: The Structure of Competition</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr17-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cascairo</surname><given-names>T.</given-names></name>
<name><surname>Carley</surname><given-names>K. M.</given-names></name>
<name><surname>Krackhardt</surname><given-names>D.</given-names></name>
</person-group> <year>1999</year>. “<article-title>Positive Affectivity and Accuracy in Social Network Perception</article-title>.” <source>Motivation and Emotion</source> <volume>23</volume>:<fpage>285</fpage>–<lpage>306</lpage>.</citation>
</ref>
<ref id="bibr18-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clouston</surname><given-names>S. P.</given-names></name>
<name><surname>Verdery</surname><given-names>A. M.</given-names></name>
<name><surname>Amin</surname><given-names>S.</given-names></name>
<name><surname>Gauthier</surname><given-names>G. R.</given-names></name>
</person-group> <year>2009</year>. “<article-title>The Structure of Undergraduate Association Networks: A Quantitative Ethnography</article-title>.” <source>Connections</source> <volume>29</volume>(<issue>2</issue>):<fpage>18</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr19-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Coleman</surname><given-names>J. S.</given-names></name>
<name><surname>Katz</surname><given-names>E.</given-names></name>
<name><surname>Menzel</surname><given-names>H.</given-names></name>
</person-group> <year>1966</year>. <source>Medical Innovation: A Diffusion Study</source>. <publisher-loc>Indianapolis, IN</publisher-loc>: <publisher-name>Bobbs-Merrill</publisher-name>.</citation>
</ref>
<ref id="bibr20-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cooper</surname><given-names>C.</given-names></name>
<name><surname>Frieze</surname><given-names>A.</given-names></name>
<name><surname>Radzik</surname><given-names>T.</given-names></name>
</person-group> <year>2009</year>. “<article-title>Multiple Random Walks and Interacting Particle Systems</article-title>.” <source>Lecture Notes in Computer Science</source> <volume>5556</volume>:<fpage>399</fpage>–<lpage>410</lpage>.</citation>
</ref>
<ref id="bibr21-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dombrowski</surname><given-names>K.</given-names></name>
<name><surname>Khan</surname><given-names>B.</given-names></name>
<name><surname>Wendel</surname><given-names>T.</given-names></name>
<name><surname>McLean</surname><given-names>K.</given-names></name>
<name><surname>Curtis</surname><given-names>R.</given-names></name>
<name><surname>Drucker</surname><given-names>E.</given-names></name>
</person-group> <year>2011</year>. “<article-title>Estimating the Size of the Methamphetamine-using Population in New York City Using Network Sampling Techniques</article-title>.<source>”</source> Working Paper, <publisher-name>City University of New York</publisher-name>.</citation>
</ref>
<ref id="bibr22-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dunbar</surname><given-names>R. I. M.</given-names></name>
</person-group> <year>1998</year>. “<article-title>The Social Brain Hypothesis</article-title>.” <source>Evolutionary Anthropology: Issues, News, and Reviews</source> <volume>6</volume>(<issue>5</issue>):<fpage>178</fpage>–<lpage>90</lpage>.</citation>
</ref>
<ref id="bibr23-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Eagle</surname><given-names>N. A. S.</given-names></name>
<name><surname>Pentland</surname></name>
<name><surname>Lazer</surname><given-names>D.</given-names></name>
</person-group> <year>2009</year>. “<article-title>Inferring Friendship Network Structure by Using Mobile Phone Data</article-title>.” <source>Proceedings of the National Academy of Sciences</source> <volume>106</volume>(<issue>36</issue>):<fpage>15274</fpage>–<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr24-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Elasser</surname><given-names>R.</given-names></name>
<name><surname>Sauerwald</surname><given-names>T.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Tight Bounds for the Cover Time of Multiple Random Walks</article-title>.” <source>Theoretical Computer Science</source> <volume>412</volume>(<issue>24</issue>):<fpage>2623</fpage>–<lpage>41</lpage>.</citation>
</ref>
<ref id="bibr25-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ellison</surname><given-names>N.</given-names></name>
<name><surname>Steinfield</surname><given-names>C.</given-names></name>
<name><surname>Lampe</surname><given-names>C.</given-names></name>
</person-group> <year>2006</year>. “<article-title>Spatially Bounded Online Social Networks and Social Capital</article-title>.” Pp. <fpage>1</fpage>-<lpage>37</lpage> in <conf-name>Proceedings of the Annual Conference of the International Communication Association</conf-name>.</citation>
</ref>
<ref id="bibr26-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Freeman</surname><given-names>L. C.</given-names></name>
<name><surname>Romney</surname><given-names>A. K.</given-names></name>
<name><surname>Freeman</surname><given-names>S. C.</given-names></name>
</person-group> <year>1987</year>. “<article-title>Cognitive Structure and Informant Accuracy</article-title>.” <source>American Anthropologist</source> <volume>89</volume>:<fpage>310</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr27-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gasieniec</surname><given-names>L.</given-names></name>
<name><surname>Radzik</surname><given-names>T.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Memory Efficient Anonymous Graph Exploration</article-title>.” <source>Lecture Notes in Computer Science</source> <volume>5344</volume>:<fpage>14</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr28-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gile</surname><given-names>K. J.</given-names></name>
<name><surname>Handcock</surname><given-names>M. S.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Respondent-driven Sampling: An Assessment of Current Methodology</article-title>.” <source>Sociological Methodology</source> <volume>40</volume>:<fpage>285</fpage>–<lpage>327</lpage>.</citation>
</ref>
<ref id="bibr29-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gile</surname><given-names>Krista J.</given-names></name>
</person-group> <year>2011</year>. “<article-title>Improved Inference for Respondent-driven Sampling Data with Application to HIV Prevalence Estimation</article-title>.” <source>Journal of the American Statistical Association</source> <volume>106</volume>(<issue>493</issue>):<fpage>135</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr30-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Gjoka</surname><given-names>M.</given-names></name>
<name><surname>Kurant</surname><given-names>M.</given-names></name>
<name><surname>Butts</surname><given-names>C.</given-names></name>
<name><surname>Markopoulou</surname><given-names>A.</given-names></name>
</person-group> <year>2010</year>. “<article-title>A Walk in Facebook: A Case Study of Unbiased Sampling of Facebook</article-title>.” <conf-name>Paper presented at IEEE INFOCOM</conf-name> <year>2010</year>.</citation>
</ref>
<ref id="bibr31-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goel</surname><given-names>Sharad</given-names></name>
<name><surname>Salganik</surname><given-names>Matthew J.</given-names></name>
</person-group> <year>2009</year>. “<article-title>Respondent-driven Sampling as Markov Chain Monte Carlo</article-title>.” <source>Statistics in Medicine</source> <volume>28</volume>:<fpage>2202</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr32-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goel</surname><given-names>Sharad</given-names></name>
<name><surname>Salganik</surname><given-names>Matthew J.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Assessing Respondent-driven Sampling</article-title>.” <source>Proceedings of the National Academy of Sciences</source> <volume>107</volume>:<fpage>6743</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr33-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goodman</surname><given-names>L. A.</given-names></name>
</person-group> <year>1961</year>. “<article-title>Snowball Sampling</article-title>.” <source>Annals of Mathematical Statistics</source> <volume>32</volume>:<fpage>148</fpage>–<lpage>70</lpage>.</citation>
</ref>
<ref id="bibr34-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gross</surname><given-names>R.</given-names></name>
<name><surname>Acquisti</surname><given-names>A.</given-names></name>
</person-group> <year>2005</year>. “<article-title>Information Revelation and Privacy in Online Social Networks</article-title>.” Pp. <fpage>71</fpage>–<lpage>80</lpage> in <source>Proceedings of WPES ’05</source>. <publisher-loc>Alexandria, VA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>.</citation>
</ref>
<ref id="bibr35-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Groves</surname><given-names>R. M.</given-names></name>
<name><surname>Fowler</surname><given-names>F. J.</given-names><suffix>Jr.</suffix></name>
<name><surname>Couper</surname><given-names>M. P.</given-names></name>
<name><surname>Lepkowski</surname><given-names>J. M.</given-names></name>
<name><surname>Singer</surname><given-names>E.</given-names></name>
<name><surname>Tourangeau</surname><given-names>R.</given-names></name>
</person-group> (<year>2009</year>). <source>Survey Methodology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr36-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hammer</surname><given-names>M.</given-names></name>
</person-group> <year>1984</year>. “<article-title>Explorations into the Meaning of Social Network Interview Data</article-title>.” <source>Social Networks</source> <volume>6</volume>:<fpage>341</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr37-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haythornthwaite</surname><given-names>C.</given-names></name>
</person-group> <year>2005</year>. “<article-title>Social Networks and Internet Connectivity Effects</article-title>.” <source>Information, Communication, &amp; Society</source> <volume>8</volume>(<issue>2</issue>):<fpage>125</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr38-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
</person-group> <year>1997</year>. “<article-title>Respondent-driven Sampling: A New Approach to the Study of Hidden Populations</article-title>.” <source>Social Problems</source> <volume>44</volume>:<fpage>174</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr39-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
</person-group> <year>2002</year>. “<article-title>Respondent-driven Sampling II: Deriving Valid Population Estimates from Chain-referral Samples of Hidden Populations</article-title>.” <source>Social Problems</source> <volume>49</volume>:<fpage>11</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr40-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
</person-group> <year>2007</year>. “<article-title>Extensions of Respondent-driven Sampling: Analyzing Continuous Variables and Controlling for Differential Recruitment</article-title>.” <source>Sociological Methodology</source> <volume>49</volume>:<fpage>11</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr41-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ikeda</surname><given-names>S.</given-names></name>
<name><surname>Kubo</surname><given-names>I.</given-names></name>
<name><surname>Okumoto</surname><given-names>N.</given-names></name>
<name><surname>Yamashita</surname><given-names>M.</given-names></name>
</person-group> <year>2003</year>. “<article-title>Impact of Local Topological Information on Random Walks on Finite Graphs</article-title>.” <source>Lecture Notes in Computer Science</source> <volume>2719</volume>:<fpage>1054</fpage>–<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr42-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ikeda</surname><given-names>S.</given-names></name>
<name><surname>Kubo</surname><given-names>I.</given-names></name>
<name><surname>Yamashita</surname><given-names>M.</given-names></name>
</person-group> <year>2009</year>. “<article-title>The Hitting and Cover Times of Random Walks on Finite Graphs Using Local Degree Information</article-title>.” <source>Theoretical Computer Science</source> <volume>410</volume>:<fpage>94</fpage>–<lpage>100</lpage>.</citation>
</ref>
<ref id="bibr43-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Johnston</surname><given-names>L. G.</given-names></name>
</person-group> <year>2008</year>. <source>Behavioural Surveillance: Introduction to Respondent Driven Sampling (Participant Manual)</source>. <publisher-loc>Atlanta, GA</publisher-loc>: <publisher-name>Centers for Disease Control and Prevention</publisher-name>.</citation>
</ref>
<ref id="bibr44-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnston</surname><given-names>L. G.</given-names></name>
<name><surname>Sabin</surname><given-names>K.</given-names></name>
<name><surname>Hien</surname><given-names>M. T.</given-names></name>
<name><surname>Huong</surname><given-names>P. T.</given-names></name>
</person-group> <year>2006</year>. “<article-title>Assessment of Respondent-driven Sampling for Recruiting Female Sex Workers in Two Vietnamese Cities: Reaching the Unseen Sex Worker</article-title>.” <source>Journal of Urban Health</source> <volume>83</volume>:<fpage>16</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr45-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kendall</surname><given-names>D.</given-names></name>
<name><surname>Kerr</surname><given-names>L.R.F.</given-names></name>
<name><surname>Gondim</surname><given-names>R. C.</given-names></name>
<name><surname>Warneck</surname><given-names>G. L.</given-names></name>
<name><surname>Macena</surname><given-names>R.H.M.</given-names></name>
<name><surname>Pontes</surname><given-names>M. K.</given-names></name>
<name><surname>Johnston</surname><given-names>L. G.</given-names></name>
<name><surname>Sabin</surname><given-names>K.</given-names></name>
<name><surname>McFarland</surname><given-names>W.</given-names></name>
</person-group> <year>2008</year>. “<article-title>An Empirical Comparison of Respondent-driven Sampling, Time Location Sampling, and Snowball Sampling for Behavioral Surveillance in Men Who Have Sex with Men, Fortaleza, Brazil</article-title>.” <source>AIDS and Behavior</source> <volume>12</volume>(<issue>1</issue>):<fpage>97</fpage>–<lpage>104</lpage>.</citation>
</ref>
<ref id="bibr46-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kharusi</surname><given-names>F. A.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Experiments with Forward Random Walks</article-title>.<source>” Technical Report</source> <fpage>08</fpage>-<lpage>1</lpage>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>King’s College London, Department of Computer Science</publisher-name>.</citation>
</ref>
<ref id="bibr47-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lampe</surname><given-names>C.</given-names></name>
<name><surname>Ellison</surname><given-names>N.</given-names></name>
<name><surname>Steinfeld</surname><given-names>C.</given-names></name>
</person-group> <year>2007</year>. “<article-title>A Familiar Face(book): Profile Elements as Signals in an Online Social Network</article-title>.” Pp. <fpage>435</fpage>–<lpage>44</lpage> in <conf-name>Proceedings of Conference on Human Factors in Computing Systems</conf-name>. <conf-loc>New York: ACM Press</conf-loc>.</citation>
</ref>
<ref id="bibr48-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lawler</surname><given-names>Gregory F.</given-names></name>
<name><surname>Coyle</surname><given-names>Lester N.</given-names></name>
</person-group> <year>1999</year>. <source>Lectures on Contemporary Probability</source>. <publisher-loc>Providence, RI</publisher-loc>: <publisher-name>American Mathematical Society</publisher-name>.</citation>
</ref>
<ref id="bibr49-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lewis</surname><given-names>Kevin</given-names></name>
<name><surname>Kaufman</surname><given-names>Jason</given-names></name>
<name><surname>Gonzalez</surname><given-names>Marco</given-names></name>
<name><surname>Wimmer</surname><given-names>Andreas</given-names></name>
<name><surname>Christakis</surname><given-names>Nicholas</given-names></name>
</person-group>. <year>2008</year>. “<article-title>Tastes, Ties, and Time: A New Social Network Dataset Using Facebook.com</article-title>.” <source>Social Networks</source> <volume>30</volume>:<fpage>330</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr50-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lovasz</surname><given-names>L.</given-names></name>
</person-group> <year>1993</year>. “<article-title>Random Walks on Graphs: A Survey</article-title>.” <source>Combinatorics</source> <volume>2</volume>:<fpage>1</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr51-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lu</surname><given-names>X.</given-names></name>
<name><surname>Bengtsson</surname><given-names>L.</given-names></name>
<name><surname>Britton</surname><given-names>T.</given-names></name>
<name><surname>Camitz</surname><given-names>M.</given-names></name>
<name><surname>Kim</surname><given-names>B. J.</given-names></name>
<name><surname>Thorson</surname><given-names>A.</given-names></name>
<name><surname>Liljeros</surname><given-names>F.</given-names></name>
</person-group> <year>2012</year>. “<article-title>The Sensitivity of Respondent-driven Sampling</article-title>.” <source>Journal of the Royal Statistical Society: Series A Statistics in Society</source> <volume>175</volume>:<fpage>191</fpage>–<lpage>216</lpage>.</citation>
</ref>
<ref id="bibr52-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ma</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>Q.</given-names></name>
<name><surname>He</surname><given-names>X.</given-names></name>
<name><surname>Yue</surname><given-names>H.</given-names></name>
<name><surname>Chen</surname><given-names>S.</given-names></name>
<name><surname>Raymond</surname><given-names>H. F.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Xu</surname><given-names>M.</given-names></name>
<name><surname>Du</surname><given-names>H.</given-names></name>
<name><surname>McFarland</surname><given-names>W.</given-names></name>
</person-group> <year>2007</year>. “<article-title>Trends in Prevalence of HIV, Syphilis, Hepatitis C, Hepatitis B, and Sexual Risk Behavior among Men Who Have Sex with Men: Results of 3 Consecutive Respondent-driven Sampling Surveys in Beijing, 2004-2006</article-title>.”<source>Journal of Acquired Immune Deficiency Syndrome</source> <volume>45</volume>(<issue>5</issue>):<fpage>581</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr53-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Magnani</surname><given-names>R.</given-names></name>
<name><surname>Sabin</surname><given-names>K.</given-names></name>
<name><surname>Saidel</surname><given-names>T.</given-names></name>
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
</person-group> <year>2005</year>. “<article-title>Review of Sampling Hard-to-reach and Hidden Populations for HIV Surveillance</article-title>.” <source>AIDS</source> <volume>19</volume>:<fpage>S67</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr54-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Malekinejad</surname><given-names>M.</given-names></name>
<name><surname>Johnston</surname><given-names>L. G.</given-names></name>
<name><surname>Kendall</surname><given-names>C.</given-names></name>
<name><surname>Kerr</surname><given-names>L.R.F.S.</given-names></name>
<name><surname>Rifkin</surname><given-names>M. R.</given-names></name>
<name><surname>Rutherford</surname><given-names>G. W.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Using Respondent-driven Sampling Methodology for HIV Biological and Behavioral Surveillance in International Settings: A Systematic Review</article-title>.” <source>AIDS and Behavior</source> <volume>12</volume>:<fpage>S105</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr55-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCallister</surname><given-names>L.</given-names></name>
<name><surname>Fischer</surname><given-names>C. S.</given-names></name>
</person-group> <year>1978</year>. “<article-title>A Procedure for Surveying Personal Networks</article-title>.” <source>Sociological Methods and Research</source> <volume>7</volume>:<fpage>131</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr56-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCarty</surname><given-names>C.</given-names></name>
<name><surname>Killworth</surname><given-names>P. D.</given-names></name>
<name><surname>Bernard</surname><given-names>H. R.</given-names></name>
<name><surname>Johnsen</surname><given-names>E. C.</given-names></name>
<name><surname>Shelley</surname><given-names>G. A.</given-names></name>
</person-group> <year>2000</year>. “<article-title>Comparing Two Methods for Estimating Network Size</article-title>.” <source>Human Organization</source> <volume>60</volume>(<issue>1</issue>):<fpage>28</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr57-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCreesh</surname><given-names>N.</given-names></name>
<name><surname>Frost</surname><given-names>S.</given-names></name>
<name><surname>Seeley</surname><given-names>J.</given-names></name>
<name><surname>Seelev</surname><given-names>J.</given-names></name>
<name><surname>Katongole</surname><given-names>J.</given-names></name>
<name><surname>Tarsh</surname><given-names>M. N.</given-names></name>
<name><surname>Ndunguse</surname><given-names>R.</given-names></name>
<name><surname>Jichi</surname><given-names>F.</given-names></name>
<name><surname>Lunel</surname><given-names>N. L.</given-names></name>
<name><surname>Maher</surname><given-names>D.</given-names></name>
<name><surname>Johnston</surname><given-names>L. G.</given-names></name>
<name><surname>Sonnenberg</surname><given-names>P.</given-names></name>
<name><surname>Copas</surname><given-names>A. J.</given-names></name>
<name><surname>Hayes</surname><given-names>R. J.</given-names></name>
<name><surname>White</surname><given-names>R. G.</given-names></name>
</person-group> <year>2012</year>. “<article-title>Evaluation of Respondent-driven Sampling</article-title>.” <source>Epidemiology</source> <volume>23</volume>:<fpage>138</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr58-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McKnight</surname><given-names>C.</given-names></name>
<name><surname>Jarles</surname><given-names>D. D.</given-names></name>
<name><surname>Bramson</surname><given-names>H.</given-names></name>
<name><surname>Tower</surname><given-names>L.</given-names></name>
<name><surname>Abdul-Quader</surname><given-names>A. S.</given-names></name>
<name><surname>Nemeth</surname><given-names>C.</given-names></name>
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
</person-group> <year>2006</year>. “<article-title>Respondent-driven Sampling in a Study of Drug Users in New York City: Notes from the Field</article-title>.” <source>Journal of Urban Health</source> <volume>83</volume>:<fpage>54</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr59-0081175012461248">
<citation citation-type="gov">
<collab>National Institutes of Health</collab>. <year>2011</year>. “<article-title>Project Reporter</article-title>.<source>”</source> <access-date>Retrieved December 15, 2011</access-date> (<ext-link ext-link-type="uri" xlink:href="http://projectreporter.nih.gov/reporter.cfm">http://projectreporter.nih.gov/reporter.cfm</ext-link>).</citation>
</ref>
<ref id="bibr60-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Neely</surname><given-names>William Whipple</given-names></name>
</person-group>. <year>2009</year>. “<article-title>Statistical Theory for Respondent Driven Sampling</article-title>.” PhD Dissertation, <publisher-name>University of Wisconsin–Madison</publisher-name>.</citation>
</ref>
<ref id="bibr61-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Potter</surname><given-names>Gail E.</given-names></name>
<name><surname>Handcock</surname><given-names>Mark S.</given-names></name>
<name><surname>Longini</surname><given-names>Ira M.</given-names><suffix>Jr.</suffix></name>
<name><surname>Halloran</surname><given-names>M. Elizabeth</given-names></name>
</person-group>. <year>2011</year>. “<article-title>Estimating Within-household Contact Networks from Egocentric Data</article-title>.” <source>Annals of Applied Statistics</source> <volume>5</volume>(<issue>3</issue>):<fpage>1816</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr62-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ramirez-Valles</surname><given-names>J.</given-names></name>
<name><surname>Heckathorn</surname><given-names>D. D.</given-names></name>
<name><surname>Vazquez</surname><given-names>R.</given-names></name>
<name><surname>Diaz</surname><given-names>R. M.</given-names></name>
<name><surname>Campbell</surname><given-names>R. T.</given-names></name>
</person-group> <year>2005</year>. “<article-title>The Fit between Theory and Data in Respondent-driven Sampling: Response to Heimer</article-title>.” <source>AIDS and Behavior</source> <volume>9</volume>:<fpage>409</fpage>–<lpage>14</lpage>.</citation>
</ref>
<ref id="bibr63-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Reif</surname><given-names>Julian</given-names></name>
</person-group>. <year>2010</year>. <publisher-loc>“STRGROUP</publisher-loc>: <publisher-name>Stata Module to Match Strings Based on Their Levenshtein Edit Distance.” Statistical Software Components S457151, Boston College Department of Economics, Revised</publisher-name> <month>August</month> <volume>14</volume>, <year>2010</year>.</citation>
</ref>
<ref id="bibr64-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ribeiro</surname><given-names>B.</given-names></name>
<name><surname>Towsley</surname><given-names>D.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Estimating and Sampling Graphs with Multidimensional Random Walks</article-title>.” <conf-name>Paper presented at ACM SIGCOMM Internet Measurement Conference</conf-name>.</citation>
</ref>
<ref id="bibr65-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ribeiro</surname><given-names>B.</given-names></name>
<name><surname>Wang</surname><given-names>P.</given-names></name>
<name><surname>Towsley</surname><given-names>D.</given-names></name>
</person-group> <year>2010</year>. “<article-title>On Estimating Degree Distributions of Directed Graphs through Sampling</article-title>.” University of Massachusetts CMPSCI Technical Report UM-CS-2010-046.</citation>
</ref>
<ref id="bibr66-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Salganik</surname><given-names>Matthew J.</given-names></name>
<name><surname>Heckathorn</surname><given-names>Douglas D.</given-names></name>
</person-group> <year>2004</year>. “<article-title>Sampling and Estimation in Hidden Populations Using Respondent-driven Sampling</article-title>.” <source>Sociological Methodology</source> <volume>34</volume>:<fpage>193</fpage>–<lpage>239</lpage>.</citation>
</ref>
<ref id="bibr67-0081175012461248">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Sandberg</surname><given-names>J.</given-names></name>
<name><surname>Rytina</surname><given-names>S.</given-names></name>
<name><surname>Lalou</surname><given-names>R.</given-names></name>
<name><surname>Delaunay</surname><given-names>V.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Social Networks across the Lifecourse and the Development of the Niakhar Social Networks Survey Instrument</article-title>.” <conf-name>Paper presented at the annual meeting of the Population Association of America</conf-name>, <conf-loc>New Orleans, LA</conf-loc>.</citation>
</ref>
<ref id="bibr68-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>S. K.</given-names></name>
</person-group> <year>2006</year>. “<article-title>Targeted Random Walk Designs</article-title>.” <source>Survey Methodology</source> <volume>32</volume>:<fpage>11</fpage>–<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr69-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Traud</surname><given-names>A. L.</given-names></name>
<name><surname>Kelsic</surname><given-names>E. D.</given-names></name>
<name><surname>Mucha</surname><given-names>P. J.</given-names></name>
<name><surname>Porter</surname><given-names>M. A.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Comparing Community Structure to Characteristics in Online Collegiate Social Networks</article-title>.<source>” SIAM Review</source> <volume>53</volume>(<issue>3</issue>):<fpage>526</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr70-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Traud</surname><given-names>A. L.</given-names></name>
<name><surname>Mucha</surname><given-names>P. M.</given-names></name>
<name><surname>Porter</surname><given-names>M. A.</given-names></name>
</person-group> <year>2010</year>. “<article-title>Social Structure of Facebook Networks</article-title>.<source>”</source> Working Paper, <publisher-name>University of North Carolina at Chapel Hill, Department of Mathematics</publisher-name>.</citation>
</ref>
<ref id="bibr71-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Volz</surname><given-names>Erik</given-names></name>
<name><surname>Heckathorn</surname><given-names>Douglas D.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Probability-based Estimation Theory for Respondent-driven Sampling</article-title>.” <source>Journal of Official Statistics</source> <volume>24</volume>:<fpage>79</fpage>–<lpage>97</lpage>.</citation>
</ref>
<ref id="bibr72-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wejnert</surname><given-names>C.</given-names></name>
</person-group> <year>2009</year>. “<article-title>An Empirical Test of Respondent-driven Sampling: Point Estimates, Variance, Degree Measures, and Out-of-equilibrium Data</article-title>.” <source>Sociological Methodology</source> <volume>39</volume>(<issue>1</issue>):<fpage>73</fpage>–<lpage>116</lpage>.</citation>
</ref>
<ref id="bibr73-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wejnert</surname><given-names>Cyprian</given-names></name>
<name><surname>Heckathorn</surname><given-names>Douglas D.</given-names></name>
</person-group> <year>2008</year>. “<article-title>Web-based Network Sampling</article-title>.” <source>Sociological Methods and Research</source> <volume>37</volume>(<issue>1</issue>):<fpage>105</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr74-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wimmer</surname><given-names>Andreas</given-names></name>
<name><surname>Lewis</surname><given-names>Kevin</given-names></name>
</person-group>. <year>2010</year>. “<article-title>Beyond and below Racial Homophily: ERG Models of a Friendship Network Documented on Facebook</article-title>.” <source>American Journal of Sociology</source> <volume>116</volume>(<issue>2</issue>):<fpage>583</fpage>–<lpage>642</lpage>.</citation>
</ref>
<ref id="bibr75-0081175012461248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yeka</surname><given-names>William</given-names></name>
<name><surname>Maibani-Michie</surname><given-names>Geraldine</given-names></name>
<name><surname>Prybylski</surname><given-names>Dimitri</given-names></name>
<name><surname>Colby</surname><given-names>Donn</given-names></name>
</person-group>. <year>2006</year>. “<article-title>Application of Respondent Driven Sampling to Collect Baseline Data on FSWs and MSM for HIV Risk Reduction Interventions in Two Urban Centres in Papua New Guinea</article-title>.” <source>Journal of Urban Health</source> <volume>83</volume>(<issue>1</issue>):<fpage>60</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr76-0081175012461248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Yu</surname><given-names>I.</given-names></name>
<name><surname>Newman</surname><given-names>R.</given-names></name>
</person-group> <year>2008</year>. “<article-title>A Topology-aware Random Walk</article-title>.<source>”</source> Working Paper, <publisher-name>Department of CISE, University of Florida</publisher-name>, <publisher-loc>Gainesville</publisher-loc>.</citation>
</ref>
</ref-list>
</back>
</article>