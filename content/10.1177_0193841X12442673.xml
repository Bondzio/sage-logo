<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ERX</journal-id>
<journal-id journal-id-type="hwp">sperx</journal-id>
<journal-id journal-id-type="nlm-ta">Eval Rev</journal-id>
<journal-title>Evaluation Review</journal-title>
<issn pub-type="ppub">0193-841X</issn>
<issn pub-type="epub">1552-3926</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0193841X12442673</article-id>
<article-id pub-id-type="publisher-id">10.1177_0193841X12442673</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Meta-Analysis</article-title>
<subtitle>An Introduction Using Regression Models</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Rhodes</surname>
<given-names>William</given-names>
</name>
<xref ref-type="aff" rid="aff1-0193841X12442673">1</xref>
<xref ref-type="corresp" rid="corresp1-0193841X12442673"/>
</contrib>
<bio>
<p>
<bold>William Rhodes</bold>, (PhD, Minnesota), is a principal scientist at Abt Associates. An economist, Rhodes specializes in econometric methods, mathematical modeling and program evaluation.</p>
</bio>
</contrib-group>
<aff id="aff1-0193841X12442673">
<label>1</label>Abt Associates Inc., Cambridge, MA, USA</aff>
<author-notes>
<corresp id="corresp1-0193841X12442673">William Rhodes, Abt Associates Inc., 55 Wheeler Street, Cambridge, MA, USA Email: <email>bill_rhodes@abtassoc.com</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2012</year>
</pub-date>
<volume>36</volume>
<issue>1</issue>
<fpage>24</fpage>
<lpage>71</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Research synthesis of evaluation findings is a multistep process. An investigator identifies a research question, acquires the relevant literature, codes findings from that literature, and analyzes the coded data to estimate the average treatment effect and its distribution in a population of interest. The process of estimating the average treatment effect is meta-analysis. Meta-analysis is gaining popularity across the social sciences, but introductions and even advanced treatments of the subject are often formula-driven. Researchers, who apply formulas without understanding, risk both misapplication and misinterpretation. This article derives formulas used in meta-analysis using standard regression models so this article seeks to introduce readers with an understanding of regression analysis to meta-analysis, intending thereby to motivate and facilitate a deeper reading of the meta-analysis literature.</p>
</abstract>
<kwd-group>
<kwd>meta-analysis</kwd>
<kwd>systematic literature reviews</kwd>
<kwd>econometrics</kwd>
<kwd>research synthesis</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0193841X12442673">
<title>Introduction</title>
<p>Literature reviews are an expected component of evaluation reports, but literature reviews are selective in coverage and conclusions require a subjective weighting of reviewed studies. Consequently, two competent researchers could reach different conclusions from their literature reviews because they (1) consider the evidence from different sets of studies or (2) use the same set of studies but assign different weights regarding importance. Typical literature reviews are <italic>unprincipled</italic> in that they use no scientific standards for including studies, apply no probability-based rules for assigning weights, and cannot be replicated.</p>
<p>Led by medical researchers, social scientists have advanced research synthesis (<xref ref-type="bibr" rid="bibr54-0193841X12442673">White 2009</xref>). The advances in methodology for synthesizing research are encapsulated in the term <italic>systematic reviews</italic>. A hallmark of systematic reviews is being inclusive of relevant research reports, so the sample is unbiased, but excluding reports whose designs fail to pass minimum standards, so the synthesis itself passes validity challenges. Systematic reviews typically end with meta-analysis. A meta-analysis is a <italic>principled</italic> synopsis of findings across studies. Principled means that meta-analysis is based on statistical theory so that researchers can derive probability-based statements about summary measures—for example, what is the average treatment effect and how is it distributed over a population of interest?</p>
<p>There exist highly regarded methodology books (<xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. 2009</xref>; <xref ref-type="bibr" rid="bibr14-0193841X12442673">Cooper, Hedges, and Valentine 2009</xref>; <xref ref-type="bibr" rid="bibr28-0193841X12442673">Higgins and Green 2009</xref>) and articles (Cochrane Statistical Methods Group) for performing systematic reviews and meta-analysis, and this article does not purport to advance methodology. Rather its intention is to promote understanding by examining meta-analysis from a particular perspective: econometric theory and linear regression models. Most meta-analysis estimators can be formulated as solutions to generalized least squares (GLS) regression problems. Therefore, researchers with a good understanding of introductory regression techniques can grasp the rudiments of meta-analysis, thereby providing a platform for deeper reading into the subject and a better basis for understanding meta-analysis studies.</p>
<p>Regressions are a frequently used tool when performing meta-analysis to explain systematic variation in treatment effects across studies (<xref ref-type="bibr" rid="bibr13-0193841X12442673">Cooper 2009</xref>). Although this article touches on using regressions for that purpose, its principal focus is using regression models to explain formulas that are commonly used for meta-analysis even when there is no motivation to explain systematic variation across studies. This approach leads to a critique of meta-analysis by identifying assumptions that undergird meta-analysis estimators.</p>
<p>This article only peripherally considers the process of assembling research studies for inclusion in the meta-analysis (<xref ref-type="bibr" rid="bibr54-0193841X12442673">White 2009</xref>), although it does not altogether ignore the topic, which can be seen as a sampling problem subject to selection bias (<xref ref-type="bibr" rid="bibr51-0193841X12442673">Sutton 2009</xref>; <xref ref-type="bibr" rid="bibr36-0193841X12442673">Matt and Cook 2009</xref>). It does not consider the topic of coding studies for meta-analysis (<xref ref-type="bibr" rid="bibr52-0193841X12442673">Valentine 2009</xref>; <xref ref-type="bibr" rid="bibr56-0193841X12442673">Wilson 2009</xref>; <xref ref-type="bibr" rid="bibr39-0193841X12442673">Orwin and Vevea 2009</xref>) or dealing with missing data. It does not consider the problem of converting a sample of studies that employ different metrics (differences in means, odds ratios, correlations, etc.) into a common metric necessary for the meta-analysis (<xref ref-type="bibr" rid="bibr6-0193841X12442673">Borenstein 2009</xref>; <xref ref-type="bibr" rid="bibr17-0193841X12442673">Fleiss and Berlin 2009</xref>; <xref ref-type="bibr" rid="bibr9-0193841X12442673">Borenstein et al. 2012</xref>) nor does it consider how to interpret the substantive importance of effects (<xref ref-type="bibr" rid="bibr31-0193841X12442673">Hill et al. 2008</xref>). It does not consider the topic of updating reviews (<xref ref-type="bibr" rid="bibr29-0193841X12442673">Higgins, Green, and Scholten 2008</xref>), sometimes called cumulative reviews. Finally, its perspective is limited to systematic reviews of evaluation findings, although transferring concepts to other setting is transparent. In summary, its focus is on using regression models to learn about the distribution of treatment effects as revealed by a review of extant evaluations.</p>
<p>Readers will find most of the arguments used in this article in econometrics textbooks (<xref ref-type="bibr" rid="bibr15-0193841X12442673">Davidson and MacKinnon 1993</xref>; <xref ref-type="bibr" rid="bibr11-0193841X12442673">Cameron and Trivedi 2005</xref>; <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene 2008</xref>), although this article transfers those arguments to the context of meta-analysis. This translation is not always straightforward. At some places, the econometrics arguments require extensions, which come from consideration of the properties of the quadratic form (<xref ref-type="bibr" rid="bibr44-0193841X12442673">Searle 1982</xref>; <xref ref-type="bibr" rid="bibr16-0193841X12442673">DerSimonian and Laird 1986</xref>). Those properties will be discussed within context. Most technical discussion appears in <xref ref-type="app" rid="app1-0193841X12442673">Appendix A</xref>.</p>
</sec>
<sec id="section2-0193841X12442673">
<title>Notation and Motivating Argument</title>
<p>To introduce some essential language, <italic>treatment effects</italic> are unknown but exist for every intervention in a population of interest defined by the researcher. The objective of meta-analysis is to estimate the <italic>average treatment effect</italic>, a confidence interval for the average treatment effect, and the distribution of treatment effects in the population of interest. In deference to common usage by meta-analysts, hereafter the unknown treatment effects will be referenced as <italic>true effect sizes</italic> and the average treatment effect will be referenced as the <italic>average effect size</italic>.</p>
<p>Estimated treatment effects and their estimated standard errors are known for a sample of interventions from the population of interest. In deference to common usage, hereafter these will be referenced as <italic>estimated effect sizes</italic>. The estimated effect sizes become the data used by the meta-analysis to estimate the average effect size. As discussed subsequently, fixed-effect or random-effect regression models are used to estimate the average effect size, its confidence interval, and the distribution of true effect sizes in the population of interest.</p>
<p>The terms true effect sizes and estimated effect sizes are necessary to distinguish population parameters from estimates, but the terms are cumbersome. When there is no risk of confusion, this article will simply reference effect sizes or effects.</p>
<p>The meta-analyst defines the population. For example, it makes little sense to combine studies of treatments for cancer and treatments for substance abuse addiction. Even if the analyst studies substance abuse treatment, he or she might limit the population to male offenders who participate in within-prison therapeutic treatment communities. Basically, definition of the population is driven by the need to average estimated effect sizes across studies, so the meta-analyst avoids averaging across treatments that differ greatly from each other.</p>
<p>The concept of a population is nebulous but important (<xref ref-type="bibr" rid="bibr24-0193841X12442673">Hedges 2009</xref>; <xref ref-type="bibr" rid="bibr57-0193841X12442673">Borenstein et al. 2010</xref>). Suppose there were <italic>N</italic> interventions but only <italic>n</italic> had been evaluated so only <italic>n</italic> provided estimated effect sizes for inclusion in a meta-analysis. If an analyst wanted to estimate the average effect size for the interventions represented by the <italic>n</italic> studies and had no desire to generalize outside of those <italic>n</italic> studies, then <italic>n </italic>= <italic>N</italic>. Often meta-analysts seek to generalize to a larger population, and for them <italic>N</italic> is much larger than <italic>n</italic>. Both approaches are discussed in this article. Either way, this article takes a frequentist perspective when drawing inferences about a population; an alternative is to take a Bayesian perspective, which adopts a different way of looking at this problem (<xref ref-type="bibr" rid="bibr40-0193841X12442673">Raudenbush 2009</xref>).</p>
<p>The argument uses the following notation:</p>
<list list-type="simple">
<list-item>
<p>
<italic>N</italic>: There is a <italic>population</italic> of interventions, each of which has a true effect size. The meta-analyst must define that population to suit the research question, but once that population is defined, the objective is to describe the distribution of true effect sizes across that population. Estimation is complicated because the meta-analyst must work with extant studies that provide estimated effect sizes for a sample of interventions from the population. Use <italic>i</italic> to index the true effect sizes in the population, so <italic>i </italic>= 1 . . . <italic>N</italic>. Use the same index when referencing the sample of estimated effect sizes, but then the index runs from <italic>i </italic>= 1 . . . <italic>n</italic>. Except where otherwise noted, assume that estimates are independent of each other.<sup>
<xref ref-type="fn" rid="fn1-0193841X12442673">1</xref>
</sup>
</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula1-0193841X12442673">
<mml:math id="mml-inline1-0193841X12442673">
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>: This is the true effect size for the <italic>i</italic>th intervention in the population. This is not observable, although it has been estimated for those <italic>n</italic> studies included in the sample. The true effect size may or may not vary across the population. If it does not, the effect size is <italic>homogeneous</italic>; if it does vary, the effect size is <italic>heterogeneous</italic>. Throughout this article assume that effects are expressed in the same units across all <italic>n</italic> studies.<sup>
<xref ref-type="fn" rid="fn2-0193841X12442673">2</xref>
</sup>
</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula2-0193841X12442673">
<mml:math id="mml-inline2-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>: This is the <italic>estimated</italic> effect size for the <italic>i</italic>th intervention included in the sample. This is observable because it is collected when assembling the <italic>n</italic> studies. Except where otherwise noted, assume that <inline-formula id="inline-formula3-0193841X12442673">
<mml:math id="mml-inline3-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> is an unbiased estimate of its population counterpart <inline-formula id="inline-formula4-0193841X12442673">
<mml:math id="mml-inline4-0193841X12442673">
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>.<sup>
<xref ref-type="fn" rid="fn3-0193841X12442673">3</xref>
</sup> A collection of studies based on randomized controlled designs would typically satisfy this assumption; a collection of studies that includes quasi-experiments may not.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula5-0193841X12442673">
<mml:math id="mml-inline5-0193841X12442673">
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>: This is measurement error—the difference between the true effect size and the estimated effect size. The <italic>e<sub>i</sub>
</italic> is not observable. The relationship between the first three terms is:
<disp-formula id="disp-formula1-0193841X12442673">
<label>1</label>
<mml:math id="mml-disp1-0193841X12442673">
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula1-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq1.tif"/>
</disp-formula>
</p>
</list-item>
</list>
<p>Expanding the notation:</p>
<list list-type="simple">
<list-item>
<p>
<inline-formula id="inline-formula6-0193841X12442673">
<mml:math id="mml-inline6-0193841X12442673">
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>: This is an <italic>observable</italic> factor, measured at the study level, affecting the true effect size. For example, it might be the dose of a drug administered; the dose is the same for all those treated within a study but it varies across studies. The reader could treat <italic>X<sub>i</sub>
</italic> as multiple factors without changing the argument. The reader might also assume that <italic>X<sub>i</sub>
</italic> varies across subjects within a study, in which case <italic>X<sub>i</sub>
</italic> is a study average or some other descriptive measure.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula7-0193841X12442673">
<mml:math id="mml-inline7-0193841X12442673">
<mml:msub>
<mml:mi>Z</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>: This is an <italic>unobservable</italic> factor, conceptually measurable at the study level, affecting the true effect size. For example, it might be the inherent but unmeasured propensity to respond positively to a treatment for members of the <italic>i</italic>th intervention. It is common within an intervention but varies over interventions. The reader could treat <italic>Z</italic> as a vector of multiple unobserved factors.</p>
</list-item>
</list>
<p>With this notation, the data generation process (DGP) for the true effect size is:
<disp-formula id="disp-formula2-0193841X12442673">
<label>2</label>
<mml:math id="mml-disp2-0193841X12442673">
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>Z</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula2-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq2.tif"/>
</disp-formula>
One could contemplate more complicated, and perhaps more realistic, specifications but this simple form will suffice for present purposes. <xref ref-type="disp-formula" rid="disp-formula2-0193841X12442673">Equation 2</xref> represents a population construct. It is not ultimately a useful formulation because, except under restrictive conditions, the α parameters cannot be identified from sample data. Instead, the meta-analyst will estimate a conditional mean function written:
<disp-formula id="disp-formula3-0193841X12442673">
<label>3</label>
<mml:math id="mml-disp3-0193841X12442673">
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq3.tif"/>
</disp-formula>Unless the unobservable <italic>Z</italic> is orthogonal to <italic>X</italic>, α differs from β. This is a manifestation of omitted variable bias, which is discussed in most econometrics texts. The <italic>u<sub>i</sub> </italic>is the part of <inline-formula id="inline-formula8-0193841X12442673">
<mml:math id="mml-inline8-0193841X12442673">
<mml:msub>
<mml:mi>Z</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> that is orthogonal to <inline-formula id="inline-formula9-0193841X12442673">
<mml:math id="mml-inline9-0193841X12442673">
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>. That is, if population values of <italic>Z</italic> were regressed onto <italic>X</italic>, <italic>u<sub>i</sub>
</italic> divided by α<sub>2</sub> would be the residual from that regression. Substituting <xref ref-type="disp-formula" rid="disp-formula1-0193841X12442673">Equation 1</xref> into <xref ref-type="disp-formula" rid="disp-formula3-0193841X12442673">3</xref> gives the DGP for the estimated effect sizes:
<disp-formula id="disp-formula4-0193841X12442673">
<label>4</label>
<mml:math id="mml-disp4-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula4-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq4.tif"/>
</disp-formula>This form supports definitions of variance components:</p>
<list list-type="simple">
<list-item>
<p>
<inline-formula id="inline-formula10-0193841X12442673">
<mml:math id="mml-inline10-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: This is the total variance in the estimated effects sizes across the studies that enter into the meta-analysis. It is larger than the variance in the true effect sizes across the studies.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula11-0193841X12442673">
<mml:math id="mml-inline11-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">B</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: This is the first variance component: explained variance in the true effect sizes attributable to the observable <italic>X</italic>.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula12-0193841X12442673">
<mml:math id="mml-inline12-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: This is the second variance component: unexplained variance in the true effect sizes attributable to the part of the unobservable <italic>Z</italic> that is orthogonal to <italic>X</italic>. Readers who are familiar with meta-analysis might note that this second variance component is usually labeled <inline-formula id="inline-formula13-0193841X12442673">
<mml:math id="mml-inline13-0193841X12442673">
<mml:msup>
<mml:mi mathvariant="italic">τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:math>
</inline-formula>. Perhaps with insufficient justification (<xref ref-type="bibr" rid="bibr30-0193841X12442673">Higgins, Thompson, and Spiegelhalter 2009</xref>), meta-analysts almost always assume that <italic>u</italic> is normally distributed.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula14-0193841X12442673">
<mml:math id="mml-inline14-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>e</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: This is the third variance component: variance attributable to measurement error in the estimated effect sizes across the studies. Provided that the individual studies comprising the meta-analysis have adequate sample sizes such that the central limit theorem is applicable, <italic>e</italic> is justifiably considered to be distributed as normal.</p>
</list-item>
</list>
<p>The variance components are related and understanding that relationship is important for understanding estimation. The relationship is simple. For the estimated effect sizes:<disp-formula id="disp-formula5-0193841X12442673">
<label>5</label>
<mml:math id="mml-disp5-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">B</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>e</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula5-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq5.tif"/>
</disp-formula>The variance components are independent of each other. The first two are independent by construction; the third is independent by assumption. This article will repeatedly reference these variance components.</p>
<p>In meta-analysis, these variance components have special interpretations. The term <inline-formula id="inline-formula15-0193841X12442673">
<mml:math id="mml-inline15-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">B</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> occurs when the true effect sizes vary across the population. The term <inline-formula id="inline-formula16-0193841X12442673">
<mml:math id="mml-inline16-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>e</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> occurs because the true effect sizes are estimated with imprecision in the each of the <italic>n</italic> studies included in the analysis. The analyst is given estimates of <inline-formula id="inline-formula17-0193841X12442673">
<mml:math id="mml-inline17-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>e</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, because these are reported by researchers who conducted the <italic>n</italic> studies, but the analyst has to estimate <inline-formula id="inline-formula18-0193841X12442673">
<mml:math id="mml-inline18-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">B</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> from the data at hand. Before turning to estimation, the next section goes deeper into the meaning of a true effect size.</p>
</sec>
<sec id="section3-0193841X12442673">
<title>Homogeneous and Heterogeneous Effects</title>
<p>Although meta-analysts often use different terms, in this article effects are classified as homogeneous and heterogeneous. If the true effect size is constant across the population of interventions, it is said to be <italic>homogeneous</italic>. If it varies across the population of interventions, it is said to be <italic>heterogeneous</italic>. Heterogeneity is further distinguished as <italic>measured heterogeneity</italic> and <italic>unmeasured heterogeneity</italic>.<sup>
<xref ref-type="fn" rid="fn4-0193841X12442673">4</xref>
</sup> The names come from the fact that measured heterogeneity is attributable to the observable <italic>X</italic>, and unmeasured heterogeneity is attributable to the unobservable <italic>Z</italic>. Using these three terms leads to distinguishing four models that are prominent in meta-analysis. The four are identified and discussed below. <xref ref-type="bibr" rid="bibr21-0193841X12442673">Harbord and Higgins (2009</xref>, 73) discuss these four models but assign them different names.</p>
<p>This discussion in this section is about modeling. A subsequent section turns to estimation. When discussing estimation, this article will introduce fixed-effect and random-effect regression procedures (<xref ref-type="bibr" rid="bibr45-0193841X12442673">Shadish and Haddock 2009</xref>; <xref ref-type="bibr" rid="bibr34-0193841X12442673">Konstantopoulos and Hedges 2009</xref>; <xref ref-type="bibr" rid="bibr40-0193841X12442673">Raudenbush 2009</xref>; <xref ref-type="bibr" rid="bibr57-0193841X12442673">Borenstein et al. 2010</xref>). Thus this article distinguishes between modeling concepts (homogeneous and heterogeneous effects) and estimation procedures (fixed-effect and random-effect regressions). Other discussions of meta-analysis sometimes treat the modeling concepts and the estimation procedures as synonymous.</p>
<p>The previous section distinguished between α parameters (which may not be identified) and β parameters (which are identified given a suitable sampling scheme). Henceforth, the argument will use β exclusively even when α is identified.</p>
<sec id="section4-0193841X12442673">
<title>Model 1: Homogeneous Effects</title>
<p>A model with homogeneous true effect sizes is based on an assumed DGP that is consistent with <xref ref-type="disp-formula" rid="disp-formula6-0193841X12442673">Equation 6</xref>:<disp-formula id="disp-formula6-0193841X12442673">
<label>6</label>
<mml:math id="mml-disp6-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula6-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq6.tif"/>
</disp-formula>This model posits a homogeneous true effect size <inline-formula id="inline-formula19-0193841X12442673">
<mml:math id="mml-inline19-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula>. The homogeneous effect is readily estimated with a regression that accounts for heteroscedastic error terms (discussed in the section on Estimation). The only error in this model comes from imprecision when estimating the effect sizes for each of the <italic>n</italic> studies, so the confidence interval for <inline-formula id="inline-formula20-0193841X12442673">
<mml:math id="mml-inline20-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> depends on the precision of the estimated effect sizes for each study and the number of studies.</p>
<p>The model with homogeneous effects is a meta-analysis workhorse for two reasons. The first reason is that when effects are homogeneous, how one samples the <italic>n</italic> estimated effect sizes from the population is irrelevant for identifying the average effect size. This is useful because there is seldom justification for arguing that the <italic>n</italic> estimated effect sizes included in the meta-analysis comprise a random sample from the population. The second reason is estimation of the average effect size based on a model assuming homogeneous effects may have better small-sample properties than do more realistic models that conform more closely to the true DGP. This point is clarified in the Estimation section.</p>
</sec>
<sec id="section5-0193841X12442673">
<title>Model 2: Unmeasured Heterogeneity</title>
<p>An alternative model assumes unmeasured heterogeneity but no measured heterogeneity. The assumed DGP is consistent with <xref ref-type="disp-formula" rid="disp-formula7-0193841X12442673">Equation 7</xref>:<disp-formula id="disp-formula7-0193841X12442673">
<label>7</label>
<mml:math id="mml-disp7-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula7-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq7.tif"/>
</disp-formula>The error term <italic>u</italic> captures all heterogeneity in true effect sizes. Meta-analysts almost always assume that <italic>u</italic> is distributed as normal with mean 0 and variance <inline-formula id="inline-formula21-0193841X12442673">
<mml:math id="mml-inline21-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The variance <inline-formula id="inline-formula22-0193841X12442673">
<mml:math id="mml-inline22-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is unknown and must be estimated, and in turn that estimated <inline-formula id="inline-formula23-0193841X12442673">
<mml:math id="mml-inline23-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is used to estimate <inline-formula id="inline-formula24-0193841X12442673">
<mml:math id="mml-inline24-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> and its standard error (discussed in the section on Estimation). The confidence interval for <inline-formula id="inline-formula25-0193841X12442673">
<mml:math id="mml-inline25-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is large when <italic>n</italic> is small, so the resulting estimate for <inline-formula id="inline-formula26-0193841X12442673">
<mml:math id="mml-inline26-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> may have worse small-sample properties when based on the model with unmeasured heterogeneity than when based on the model that unrealistically assumes homogeneous effects.</p>
<p>The confidence interval for <inline-formula id="inline-formula27-0193841X12442673">
<mml:math id="mml-inline27-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> will typically be wider when the model has unmeasured heterogeneity than when the model assumes homogeneous effects. Of course, narrower confidence intervals are more desirable than wider confidence intervals, but this is not a useful criterion to judge the two models, because they estimate different parameters. One can think of the model assuming homogeneous effects as estimating the mean for a <italic>sample</italic> even if the homogeneity assumption is wrong. One can think of the model assuming unmeasured heterogeneity as estimating the mean for the <italic>population</italic>. Given that the sample of <italic>n</italic> is (presumably) a random draw from the population of <italic>N</italic>, the confidence interval for the model assuming unmeasured heterogeneity must also account for the uncertainty that comes from sampling. Indeed, the two models are sometimes distinguished by asserting that the former generalizes to the sample while the latter generalizes to the population.<sup>
<xref ref-type="fn" rid="fn5-0193841X12442673">5</xref>
</sup>
</p>
<p>Properties of the model with unmeasured heterogeneity rest on three strong assumptions. The first assumption is that estimated effect sizes from the <italic>n</italic> studies are a simple random sample from the population. This is obviously necessary because, after accounting for the imprecision when estimating the treatment effects, the estimated distribution of <italic>u</italic> in the population depends on the distribution of <italic>u</italic> in the sample. If the distribution of <italic>u</italic> in the sample is not consistent for the distribution of <italic>u</italic> in the population, the meta-analyst cannot hope to derive consistent estimates for <inline-formula id="inline-formula28-0193841X12442673">
<mml:math id="mml-inline28-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The second strong assumption is that <italic>u</italic> is distributed as normal. In theory, this assumption could be relaxed, although in practice that is not frequently done. The third assumption is that <italic>n</italic> is sufficiently large to justify asymptotic properties of the estimators, but meta-analyses are often done with 5, 10, or 15 studies, so asymptotic properties are questionable. Because of these strong assumptions, a meta-analyst might be skeptical of findings from the model with unmeasured heterogeneity especially when working with small samples.</p>
</sec>
<sec id="section6-0193841X12442673">
<title>Model 3: Measured Heterogeneity</title>
<p>A different model assumes measured heterogeneity but no unmeasured heterogeneity in the true effect sizes. The assumed DGP is consistent with <xref ref-type="disp-formula" rid="disp-formula8-0193841X12442673">Equation 8</xref>:<disp-formula id="disp-formula8-0193841X12442673">
<label>8</label>
<mml:math id="mml-disp8-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula8-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq8.tif"/>
</disp-formula>This third model has much in common with the first model. In fact, one could think of this third model as representing homogeneous treatment effects conditional on <italic>X</italic>. That insight will be useful when turning to the Estimation section.</p>
<p>Here, however, the preferred interpretation is that <inline-formula id="inline-formula29-0193841X12442673">
<mml:math id="mml-inline29-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> captures all heterogeneity in the true effect sizes. When this model corresponds to the DGP, estimates of the average effect size generalize to the population; that is, provided one knows the distribution of <italic>X</italic> in the population, the average effect size is:<disp-formula id="disp-formula9-0193841X12442673">
<label>9</label>
<mml:math id="mml-disp9-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="italic">∫</mml:mi>
<mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mi mathvariant="italic">ϕ</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>X</mml:mi>
</mml:mfenced>
<mml:mi>d</mml:mi>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula9-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq9.tif"/>
</disp-formula>
<inline-formula id="inline-formula30-0193841X12442673">
<mml:math id="mml-inline30-0193841X12442673">
<mml:mi mathvariant="italic">ϕ</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>X</mml:mi>
</mml:mfenced>
</mml:math>
</inline-formula> represents the distribution of <italic>X</italic> in the population. The confidence interval for the population mean will depend on the precision of estimation for both the β parameters and <inline-formula id="inline-formula31-0193841X12442673">
<mml:math id="mml-inline31-0193841X12442673">
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> if the latter is estimated.</p>
<p>There are at least three appealing features of this model with measured heterogeneity. After introducing <italic>X</italic> into the model, one might reason that <inline-formula id="inline-formula32-0193841X12442673">
<mml:math id="mml-inline32-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is small and ignorable. This is desirable because, as already mentioned, the confidence interval for <inline-formula id="inline-formula33-0193841X12442673">
<mml:math id="mml-inline33-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is large when <italic>n</italic> is small. The model with measured heterogeneity may have better small-sample properties than does a model that includes unmeasured heterogeneity. Another appeal of the model with measured heterogeneity is that it explains something about the systematic variation in the true effect sizes over the population while the model with unmeasured heterogeneity just estimates the size of that variation. Explanation promotes science. Third, the estimated effect sizes from the <italic>n</italic> studies may not be a random sample from the population, but <xref ref-type="disp-formula" rid="disp-formula9-0193841X12442673">Equation 9</xref> nevertheless lead to estimates that generalize to the population provided the sample is random conditional on <italic>X</italic>. Of course, one would be suspicious of estimates if the distribution of <italic>X</italic> provided insufficient support, because then the analyst would be relying on correct structural form for the model in <xref ref-type="disp-formula" rid="disp-formula8-0193841X12442673">Equation 8</xref>. The model with measured heterogeneity is no panacea because it depends on some strong assumptions, but the assumptions are weaker than those that justify the model that lacks measured heterogeneity, so Model 3 appears to be an improvement over Model 2.</p>
</sec>
<sec id="section7-0193841X12442673">
<title>Model 4: Measured and Unmeasured Heterogeneity</title>
<p>The fourth model includes both measured and unmeasured heterogeneity in the true effect sizes. The assumed DGP is consistent with <xref ref-type="disp-formula" rid="disp-formula10-0193841X12442673">Equation 10</xref>:<disp-formula id="disp-formula10-0193841X12442673">
<label>10</label>
<mml:math id="mml-disp10-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula10-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq10.tif"/>
</disp-formula>This is the most comprehensive of the four models. It incorporates both measured and unmeasured heterogeneity into the model specification. Estimating the average effect size is not much more complicated than estimating the parameters of a model with unmeasured heterogeneity but no measured heterogeneity.</p>
<p>Because this model includes unmeasured heterogeneity, it suffers from the same problems as the model that had unmeasured heterogeneity but no measured heterogeneity. However, it may be more plausible that the sample of estimated effect sizes from <italic>n</italic> studies is a random sample of the population conditional on <italic>X</italic>. It may also be more plausible that the distribution of <italic>u</italic> is normal conditional on <italic>X</italic>. Hence, this fourth model rests on slightly weaker assumptions than did its counterpart that excluded measured heterogeneity.</p>
</sec>
<sec id="section8-0193841X12442673">
<title>Sample Selection Bias</title>
<p>The purpose of statistical analysis is to estimate the characteristics of a population (population parameters) based on a sample of elements from that population. Random samples from the population are especially useful because they lead to unbiased parameter estimates. As is familiar to all sampling statisticians (<xref ref-type="bibr" rid="bibr33-0193841X12442673">Kish 1995</xref>), nonrandom samples lead to biased parameter estimates unless the statistician can adjust for the sampling mechanism (<xref ref-type="bibr" rid="bibr42-0193841X12442673">Rosenbaum 2002</xref>). The adjustment is straightforward when the statistician controls the sampling process. The adjustment is problematic in the common situation where the sampling process is outside the statistician’s control. This section discusses how this sample selection bias arises in meta-analysis.</p>
<p>In meta-analysis, sample selection bias takes at least two forms (<xref ref-type="bibr" rid="bibr36-0193841X12442673">Matt and Cook 2009</xref>). Meta-analysts seek to include a random sample of effect sizes from the interventions comprising the population, but this is a daunting task. First it requires that researchers have evaluated a random sample of interventions from that population, and if they have not, the inclusion criterion is outside the control of the meta-analyst. In fact, it seems likely that program evaluators have studied a biased sample of interventions from the population. One reason is that program administrators may be more receptive to participating in evaluations when their programs are successful, because negative evaluations threaten future funding for the administrators. In some other cases, program evaluators may choose to evaluate programs seen as being successful. For example, a practice at the National Institute of Justice has been to fund evaluations of programs seen as being successful as a <italic>demonstration of concept</italic>. From a policy perspective, nothing is wrong with this approach, but limiting evaluations to apparently successful programs does not provide suitable input for a meta-analysis that seeks to generalize to a larger population.</p>
<p>Second, even if program evaluators have conducted evaluations on a random sample of interventions comprising the population, the meta-analyst must sample randomly from that evaluator-initiated sample, but this is complicated because the meta-analyst may not know the sampling frame. Meta-analysts are aware that findings of program results that are consistent with prevailing professional wisdom are more likely to be published and that findings with statistically significant results are more likely to be published; while some tests are available for dealing with publication bias (<xref ref-type="bibr" rid="bibr46-0193841X12442673">Stanley 2005</xref>; <xref ref-type="bibr" rid="bibr47-0193841X12442673">Stanley and Jarrell, 2005</xref>), they are not infallible. Furthermore, the meta-analyst may have biased grounds for finding some studies as worthy of inclusion in a meta-analysis and other studies as unworthy.</p>
<p>What should a meta-analyst do in the face of sample selection bias? One expedient is to define the sample to be the population of interest. This may be the way that most meta-analysts think of their craft: They are using statistical procedures to summarize what an extant, accessible literature implies about a subject. When performed correctly, the meta-analysis has internal validity. There is no pretense of using statistical inference to generalize outside the sample. Of course, nothing prevents the meta-analyst from speculating about the nonsampled part of the population, but in that context the meta-analyst is no longer wearing the hat of a statistician.</p>
<p>Otherwise meta-analysts who seek to generalize outside their sample must impose assumptions on the sampling process. The previous section identified those assumptions. To summarize, when effects are homogeneous, sampling does not much matter. When effects are heterogeneous, the meta-analyst can condition his or her estimates on variables that explain that heterogeneity. This works if sample selection is exogenous: that is, the systematic part of the sampling process is all accounted for by <italic>X</italic>, and once the statistician has conditioned on <italic>X</italic>, sampling is random. It does not work if sample selection is endogenous: that is, even after accounting for <italic>X</italic>, sampling is not random. For example, if estimated effect sizes that are consistent with conventional wisdom are more likely to be reported, sampling is endogenous and parameter estimates will be biased. Unfortunately, endogenous sampling is a common problem in meta-analyses of subjects that interest economists (<xref ref-type="bibr" rid="bibr41-0193841X12442673">Roberts and Stanley 2005</xref>) and other disciplines (<xref ref-type="bibr" rid="bibr51-0193841X12442673">Sutton 2009</xref>).</p>
</sec>
</sec>
<sec id="section9-0193841X12442673">
<title>Estimation</title>
<p>Building on the modeling concepts of homogeneous and heterogeneous effects, this article turns to estimation. Meta-analysts commonly reference fixed-effect and random-effect estimators. This article explains how fixed-effect and random-effect estimators are used to estimate the conditional average effect size (where relevant) or the average effect size in each of three situations:</p>
<list list-type="bullet">
<list-item>
<p>Effects are homogeneous (Model 1 from above)</p>
</list-item>
<list-item>
<p>Effects are heterogeneous but there is no measured heterogeneity (Model 2)</p>
</list-item>
<list-item>
<p>Effects are heterogeneous and there is both measured and unmeasured heterogeneity (Model 4).</p>
</list-item>
</list>
<p>Model 3 (measured but no unmeasured heterogeneity) will not require a separate treatment because it raises no estimation issues beyond those considered for Model 1.</p>
<p>To foreshadow, the fixed-effect estimator is used when there is no unmeasured heterogeneity. The random-effect estimator is typically used when there exist unmeasured heterogeneity. However, the fixed-effect estimator might be used in the presence of unmeasured heterogeneity when samples are small because estimates based on the fixed-effect estimator can have smaller mean squared error than do estimates based on the random-effect estimator. This section will explain these assertions.</p>
<p>The argument begins by summarizing the feasible generalized least squares (FGLS) estimator. The argument then uses FGLS to develop an estimator for each of the three cases: homogeneous, only unmeasured heterogeneity, and both measured and unmeasured heterogeneity. The implications are that estimators used in meta-analysis could be reproduced from using FGLS. Although this is a useful way to think about the problem, it is not quite true when estimating Models 1 and 3. For the most part, this article ignores this minor difference.<sup>
<xref ref-type="fn" rid="fn6-0193841X12442673">6</xref>
</sup>
</p>
<sec id="section10-0193841X12442673">
<title>FGLS</title>
<p>This subsection progresses from ordinary least squares (OLS) regression to GLS regression and then to FGLS. These estimators are discussed in econometrics textbooks, for example, in <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene (2008</xref>, 148). To summarize, efficiency and consistency of standard errors in an OLS regression rest on strong distributional assumptions. GLS estimation is efficient and consistent under weaker assumptions, but GLS is principally a theoretical construct that presumes that the true error distribution is known. FGLS is a method that allows estimates of the true distributional assumptions to be substituted into the GLS solution. At least in large samples, FGLS leads to consistent and more efficient estimates of population parameters than does OLS.</p>
<p>For example, most adjustments for heteroscedasticity and autocorrelation employ the logic of FGLS. When the estimated effect sizes are independent, the FGLS estimator can often be applied by transforming the <italic>Y</italic> and <italic>X</italic> variables and then applying OLS to those transformed variables. This approach is illustrated immediately below. Dependent estimated effect sizes are considered later.</p>
<p>Intentions are to estimate β and the parameter covariance matrix VAR(β), and this seems like a familiar application of OLS regression. Let <inline-formula id="inline-formula34-0193841X12442673">
<mml:math id="mml-inline34-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> be a 1 × <italic>n</italic> column vector of dependent variables—the estimated effect sizes across the included studies. Let <italic>M</italic> represent a matrix with ones in the first column and possibly (when there is measured heterogeneity) <italic>X</italic> in the second column. Let <italic>v</italic> be a column vector of error terms. The discussion will be especially concerned with the characteristics of this column of error terms, but for now, represent the regression model generically as:<disp-formula id="disp-formula11-0193841X12442673">
<label>11</label>
<mml:math id="mml-disp11-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>M</mml:mi>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>v</mml:mi>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula11-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq11.tif"/>
</disp-formula>β represents the column vector of parameters β<sub>0</sub> and possibly β<sub>1</sub>. A familiar formula using OLS is to estimate β as:<disp-formula id="disp-formula12-0193841X12442673">
<label>12</label>
<mml:math id="mml-disp12-0193841X12442673">
<mml:msub>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">L</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula12-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq12.tif"/>
</disp-formula>Equally familiar is the formula for the covariance of β:<disp-formula id="disp-formula13-0193841X12442673">
<label>13</label>
<mml:math id="mml-disp13-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">L</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>v</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula13-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq13.tif"/>
</disp-formula>The <inline-formula id="inline-formula35-0193841X12442673">
<mml:math id="mml-inline35-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>v</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is the residual variance. The problem with this formulation is it leads to consistent estimates for β, but those estimates will be inefficient, and it leads to inconsistent estimates of <inline-formula id="inline-formula36-0193841X12442673">
<mml:math id="mml-inline36-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula>. The reason is that the error term <inline-formula id="inline-formula37-0193841X12442673">
<mml:math id="mml-inline37-0193841X12442673">
<mml:mi>v</mml:mi>
</mml:math>
</inline-formula> is heteroscedastic because the measurement error <inline-formula id="inline-formula38-0193841X12442673">
<mml:math id="mml-inline38-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> varies across the <italic>n</italic> estimated effect sizes.</p>
<p>A familiar approach to dealing with this problem is to replace OLS estimation with GLS estimation. Provided the <italic>n</italic> studies comprise <italic>n</italic> independent estimates of the true effect sizes, GLS is done by weighting <italic>Y</italic> and <italic>W</italic> and then applying OLS. (The assumption of independence is relaxed subsequently.) For this purpose, <inline-formula id="inline-formula39-0193841X12442673">
<mml:math id="mml-inline39-0193841X12442673">
<mml:msub>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>(the <italic>i</italic>th element of vector <italic>v</italic>) is drawn from a distribution with variance:<disp-formula id="disp-formula14-0193841X12442673">
<label>14</label>
<mml:math id="mml-disp14-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula14-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq14.tif"/>
</disp-formula>The GLS solution is applied using weighted least square as:<disp-formula id="disp-formula15-0193841X12442673">
<label>15</label>
<mml:math id="mml-disp15-0193841X12442673">
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula15-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq15.tif"/>
</disp-formula>After weighting, the error terms in <xref ref-type="disp-formula" rid="disp-formula15-0193841X12442673">Equation 15</xref> remain independent but are now homoscedastic; in fact, they have a common variance of 1. (The observation receives emphasis because it will be useful for understanding formulas often used in meta-analysis.) Consequently, the parameter estimates based on <xref ref-type="disp-formula" rid="disp-formula15-0193841X12442673">Equation 15</xref> have known asymptotic properties,<sup>
<xref ref-type="fn" rid="fn7-0193841X12442673">7</xref>
</sup> but there is a problem because <inline-formula id="inline-formula40-0193841X12442673">
<mml:math id="mml-inline40-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is unknown. This brings the argument to FGLS, which substitutes an estimate of <inline-formula id="inline-formula41-0193841X12442673">
<mml:math id="mml-inline41-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> for its population counterpart. The difficulty is deriving that estimate. There are several ways to estimate <inline-formula id="inline-formula42-0193841X12442673">
<mml:math id="mml-inline42-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, but the subsequent subsections follow two paths. The first is the more traditional approach for an econometrician (Estimating <inline-formula id="inline-formula43-0193841X12442673">
<mml:math id="mml-inline43-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: A Maximum Likelihood Approach subsection). It uses maximum likelihood, which in this case is weighted least squares, to estimate <inline-formula id="inline-formula44-0193841X12442673">
<mml:math id="mml-inline44-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> and hence <inline-formula id="inline-formula45-0193841X12442673">
<mml:math id="mml-inline45-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The second is more traditional for meta-analysts (Estimating <inline-formula id="inline-formula46-0193841X12442673">
<mml:math id="mml-inline46-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: A Moment-Based Approach subsection). It uses a different moment-based estimator that affords a comparison with formulas most frequently used for meta-analysis. For other approaches programmed into Stata, see <xref ref-type="bibr" rid="bibr21-0193841X12442673">Harbord and Higgins (2009)</xref>. The remainder of this Estimation section assumes estimates of <inline-formula id="inline-formula47-0193841X12442673">
<mml:math id="mml-inline47-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>.</p>
</sec>
<sec id="section11-0193841X12442673">
<title>Looking at the Standard Formulas for Meta-Analysis</title>
<p>This subsection uses the FGLS solution to derive formulas for the average treatment effect. It cross-references these formulas with their counterparts from a textbook on meta-analysis (<xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. 2009</xref>). The purpose is to show that the standard formulas used by meta-analysts can be derived using regression models.</p>
<p>
<xref ref-type="table" rid="table1-0193841X12442673">Table 1</xref> summarizes assumptions. It shows the error component assumptions and the design matrix specification for the three models: homogeneous effects, unmeasured heterogeneity, and both measured and unmeasured heterogeneity.</p>
<table-wrap id="table1-0193841X12442673" position="float">
<label>Table 1.</label>
<caption>
<p>Assumptions for the Three Models</p>
</caption>
<graphic alternate-form-of="table1-0193841X12442673" xlink:href="10.1177_0193841X12442673-table1.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>Error Components</th>
<th>Design Matrix (M)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Homogeneous true effect sizes</td>
<td>
<inline-formula id="inline-formula48-0193841X12442673">
<mml:math id="mml-inline48-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> </td>
<td>Constant</td>
</tr>
<tr>
<td>Unmeasured heterogeneity</td>
<td>
<inline-formula id="inline-formula49-0193841X12442673">
<mml:math id="mml-inline49-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mi>u</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> </td>
<td>Constant</td>
</tr>
<tr>
<td>Both measured and unmeasured heterogeneity</td>
<td>
<inline-formula id="inline-formula50-0193841X12442673">
<mml:math id="mml-inline50-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mi>u</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> </td>
<td>Constant and <italic>X</italic>
</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section12-0193841X12442673">
<title>Homogeneous Effects (Applying a Fixed-Effect Estimator)</title>
<p>Homogeneous effects are the easiest to analyze. Given the assumptions about the error components and the design matrix, <xref ref-type="disp-formula" rid="disp-formula15-0193841X12442673">Equation 15</xref> becomes:<disp-formula id="disp-formula16-0193841X12442673">
<label>16</label>
<mml:math id="mml-disp16-0193841X12442673">
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula16-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq16.tif"/>
</disp-formula>If <inline-formula id="inline-formula51-0193841X12442673">
<mml:math id="mml-inline51-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> were known, the error distribution would be homoscedastic with variance of 1. That the distribution of the residual is homoscedastic with variance of 1 was noted earlier; the observation is useful at this point in the discussion. In meta-analysis, the estimated <inline-formula id="inline-formula52-0193841X12442673">
<mml:math id="mml-inline52-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> are usually taken as known and reported as the square of the standard errors for each of the <italic>n</italic> studies. Assuming that the transformed error distribution is homoscedastic with variance of 1, applying OLS (use <xref ref-type="disp-formula" rid="disp-formula12-0193841X12442673">Equations 12</xref> and <xref ref-type="disp-formula" rid="disp-formula13-0193841X12442673">13</xref>) to these transformed data, the solution is:<disp-formula id="disp-formula17-0193841X12442673">
<label>17</label>
<mml:math id="mml-disp17-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula17-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq17.tif"/>
</disp-formula>Note the use of <italic>w</italic> to represent a weight. The weights are the inverse of the squared standard errors of the estimated effect sizes reported in the <italic>n</italic> studies sampled for the meta-analysis.<sup>
<xref ref-type="fn" rid="fn8-0193841X12442673">8</xref>
</sup> This expression of the weight and the estimates for the average effect β<sub>0</sub> and its estimated standard error <inline-formula id="inline-formula53-0193841X12442673">
<mml:math id="mml-inline53-0193841X12442673">
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> correspond to equations 11.2 through 11.4 in <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, 65).</p>
<p>Note that the estimate of the <inline-formula id="inline-formula54-0193841X12442673">
<mml:math id="mml-inline54-0193841X12442673">
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> does not come from the regression output. A regression program will produce a slightly different estimate for the variance. This is because a standard weighted least squares regression program will not assume that the variance of the residuals equals 1. Although this observation suggests that <xref ref-type="disp-formula" rid="disp-formula17-0193841X12442673">Equation 17</xref> is the better estimator, one must remember that <xref ref-type="disp-formula" rid="disp-formula17-0193841X12442673">Equation 17</xref> assumes that <inline-formula id="inline-formula55-0193841X12442673">
<mml:math id="mml-inline55-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> are measured without error, and while that is a convenient assumption, the assumption is false.</p>
</sec>
<sec id="section13-0193841X12442673">
<title>Unmeasured Heterogeneity (Applying a Random Effect Estimator)</title>
<p>Models with unmeasured heterogeneity are more difficult to estimate because the analyst is not handed estimates for <inline-formula id="inline-formula56-0193841X12442673">
<mml:math id="mml-inline56-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. Given an estimate for <inline-formula id="inline-formula57-0193841X12442673">
<mml:math id="mml-inline57-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> (derived using a methodology discussed in Estimating <inline-formula id="inline-formula58-0193841X12442673">
<mml:math id="mml-inline58-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> (Required for the Random-Effect Estimator) section), the assumptions about the error components and the design matrix, <xref ref-type="disp-formula" rid="disp-formula15-0193841X12442673">Equation 15</xref> becomes:<disp-formula id="disp-formula18-0193841X12442673">
<label>18</label>
<mml:math id="mml-disp18-0193841X12442673">
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula18-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq18.tif"/>
</disp-formula>Again assuming that the transformed error distribution is homoscedastic with variance of 1, and applying OLS to these transformed data, the solution is:<disp-formula id="disp-formula19-0193841X12442673">
<label>19</label>
<mml:math id="mml-disp19-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula19-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq19.tif"/>
</disp-formula>The weight <italic>w</italic> has changed to <italic>W</italic>. This expression of the weight and the estimates for the average effect β<sub>0</sub> and its estimated standard error <inline-formula id="inline-formula59-0193841X12442673">
<mml:math id="mml-inline59-0193841X12442673">
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> correspond to equations 12.6 through 12.8 in <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, 73). Again, a regression program will not produce the same estimate for <inline-formula id="inline-formula60-0193841X12442673">
<mml:math id="mml-inline60-0193841X12442673">
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> because the regression will not assume that the variance of the transformed error terms equals 1.</p>
</sec>
<sec id="section14-0193841X12442673">
<title>Measured and Unmeasured Heterogeneity (Using the Random-Effect Estimator)</title>
<p>Dealing with a mixture of measured and unmeasured heterogeneity raises no new issues except that the magnitude of <inline-formula id="inline-formula61-0193841X12442673">
<mml:math id="mml-inline61-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is reduced after accounting for measured heterogeneity. Nevertheless, this is not a trivial difference. Once statistical modeling takes measured heterogeneity into account, there may be no unmeasured heterogeneity, or at least there may be so little unmeasured heterogeneity that it can be practically ignored (<xref ref-type="bibr" rid="bibr34-0193841X12442673">Konstantopoulos and Hedges 2009</xref>). The regression analysis might proceed as if the effects are homogenous conditional on <italic>X</italic>. This is a strong assumption, however. Some statistical tests of the null hypothesis of conditional homogeneity are available and will be discussed later. Before considering those tests, consider how to estimate <inline-formula id="inline-formula62-0193841X12442673">
<mml:math id="mml-inline62-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. This estimate is required to implement the FGLS estimator, although using estimating equations, which will not require an estimate of <inline-formula id="inline-formula63-0193841X12442673">
<mml:math id="mml-inline63-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, will be developed as an alternative approach.</p>
</sec>
</sec>
<sec id="section15-0193841X12442673">
<title>Estimating <inline-formula id="inline-formula64-0193841X12442673">
<mml:math id="mml-inline64-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> (Required for the Random-Effect Estimator)</title>
<p>Implementing the FGLS solution requires an estimate of <inline-formula id="inline-formula65-0193841X12442673">
<mml:math id="mml-inline65-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The literature proposes alternative ways of performing this estimation (Raudenbush 2009) and this article considers two. The first is the maximum likelihood solution. It seems the most familiar from a regression standpoint because it can be implemented as a weighted least squares estimator. The second is a moment-based estimator. Attributed to <xref ref-type="bibr" rid="bibr16-0193841X12442673">DerSimonian and Laird (1986)</xref>, the moment-based estimator appears to be the estimator most commonly used by meta-analysts. After discussing these two estimators, the argument turns to what would seem to be a prior question: Is it tenable to assume that <inline-formula id="inline-formula66-0193841X12442673">
<mml:math id="mml-inline66-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> ? That assumption would make the analyst’s life easier, because he or she would have no need for <inline-formula id="inline-formula67-0193841X12442673">
<mml:math id="mml-inline67-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. After answering this question, the argument takes a different turn. Provided the analyst is willing to do without an estimate of <inline-formula id="inline-formula68-0193841X12442673">
<mml:math id="mml-inline68-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, and provided the analyst is not concerned with efficiency, the analyst can use estimating equations and robust covariance estimators. This latter approach, too, is familiar to evaluators who use regression analysis.</p>
<sec id="section16-0193841X12442673">
<title>Estimating <inline-formula id="inline-formula69-0193841X12442673">
<mml:math id="mml-inline69-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: A Maximum Likelihood Approach</title>
<p>The immediate objective is to maximize the log-likelihood with respect to β and σ<italic>
<sub>u</sub>
</italic>. Using the familiar formula for the log-likelihood of random variables that are distributed as independent normal with different means and variances:<disp-formula id="disp-formula20-0193841X12442673">
<label>20</label>
<mml:math id="mml-disp20-0193841X12442673">
<mml:mo form="prefix" movablelimits="false">ln</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>L</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:munderover>
<mml:mo movablelimits="false" stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:munderover>
</mml:mrow>
<mml:mrow>
<mml:mo form="prefix" movablelimits="false">ln</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msqrt>
<mml:mn>2</mml:mn>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:msqrt>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:msup>
<mml:mi>e</mml:mi>
<mml:mrow>
<mml:mstyle displaystyle="true" scriptlevel="0">
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:mfrac>
</mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mstyle>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula20-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq20.tif"/>
</disp-formula>Maximum likelihood is applicable because (1) the error term <italic>u</italic> is assumed to be drawn from a normal distribution, (2) the error term <italic>e</italic> is assumed to have a normal distribution with known variance <inline-formula id="inline-formula70-0193841X12442673">
<mml:math id="mml-inline70-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> for the <italic>i</italic>th estimated effect size, and (3) <italic>u</italic> and <italic>e</italic> are independent so the variance of <italic>u </italic>+ <italic>e</italic> does not require estimation of a covariance. The unknown parameters might be estimated using maximum likelihood (available through hierarchical linear model (HLM) programs for this application) or through the iterative application of least squares. The iterative procedure is straightforward and instructive even if other approaches are more practical (<xref ref-type="bibr" rid="bibr21-0193841X12442673">Harbord and Higgins 2009</xref>).</p>
<list list-type="order">
<list-item>
<p>Start with an estimate of β using weighted least squares where the weights are <italic>w<sub>i</sub>
</italic> as defined above.</p>
</list-item>
<list-item>
<p>Using this first-round estimate of β, apply the likelihood solution for <inline-formula id="inline-formula71-0193841X12442673">
<mml:math id="mml-inline71-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. This can be done using least squares. Differentiating <xref ref-type="disp-formula" rid="disp-formula20-0193841X12442673">Equation 20</xref> with respect to <inline-formula id="inline-formula72-0193841X12442673">
<mml:math id="mml-inline72-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, setting that derivative to zero, and solving for <inline-formula id="inline-formula73-0193841X12442673">
<mml:math id="mml-inline73-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> gives the first-round solution <inline-formula id="inline-formula74-0193841X12442673">
<mml:math id="mml-inline74-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mstyle displaystyle="true" scriptlevel="0">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mstyle>
</mml:math>
</inline-formula>.</p>
</list-item>
<list-item>
<p>Use this first-round estimate of <inline-formula id="inline-formula75-0193841X12442673">
<mml:math id="mml-inline75-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> to derive a second-round estimate of the weights <inline-formula id="inline-formula76-0193841X12442673">
<mml:math id="mml-inline76-0193841X12442673">
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. Following these same procedures, use this second-round weight to derive a second-round estimate of β and a second round estimate of <inline-formula id="inline-formula77-0193841X12442673">
<mml:math id="mml-inline77-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, and continue the iterations until the solution converges.</p>
</list-item>
</list>
<p>Considerable intuition surrounds this estimator. Look at the bracketed term in the solution for <inline-formula id="inline-formula78-0193841X12442673">
<mml:math id="mml-inline78-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. Given that the first and subsequent round estimates of β are consistent, the first term in the bracket has an expected value of <inline-formula id="inline-formula79-0193841X12442673">
<mml:math id="mml-inline79-0193841X12442673">
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> because the scaled sum is the variance about the regression line at <italic>X<sub>i</sub>
</italic>.<sup>
<xref ref-type="fn" rid="fn9-0193841X12442673">9</xref>
</sup> Consequently, <inline-formula id="inline-formula80-0193841X12442673">
<mml:math id="mml-inline80-0193841X12442673">
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>.</p>
<p>
<xref ref-type="bibr" rid="bibr40-0193841X12442673">Raudenbush (2009)</xref> discusses a variation on the above estimator using restricted maximum likelihood (REML). Maximum likelihood fails to take the uncertainty in <inline-formula id="inline-formula81-0193841X12442673">
<mml:math id="mml-inline81-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> into account; REML takes that uncertainty into account. REML is less efficient than maximum likelihood, so there is no clear choice; nevertheless, <xref ref-type="bibr" rid="bibr21-0193841X12442673">Harbord and Higgins (2009)</xref> argue that REML has better small-sample properties. Raudenbush offers his preferred alternative approach, but his application of Bayesian logic goes beyond the scope of this article.</p>
</sec>
<sec id="section17-0193841X12442673">
<title>Estimating <inline-formula id="inline-formula82-0193841X12442673">
<mml:math id="mml-inline82-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>: A Moment-Based Approach</title>
<p>While the maximum likelihood approach may be most familiar to an evaluator who understands regressions, a different moment-based approach is frequently used in meta-analysis. Derivations are not shown in full, but this article shows the route to those derivations, and <xref ref-type="app" rid="app1-0193841X12442673">Appendix A</xref> provides some details.<sup>
<xref ref-type="fn" rid="fn10-0193841X12442673">10</xref>
</sup> Nevertheless, this subsection is difficult and readers who are not interested in details may elect to skip it.</p>
<p>Estimation rests on a statistic <italic>Q</italic>, which plays a ubiquitous role in meta-analysis:<disp-formula id="disp-formula21-0193841X12442673">
<label>21</label>
<mml:math id="mml-disp21-0193841X12442673">
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula21-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq21.tif"/>
</disp-formula>
<italic>Q</italic> is the estimated weighted variance of <inline-formula id="inline-formula83-0193841X12442673">
<mml:math id="mml-inline83-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>. Using some notation defined below, <italic>Q</italic> can be written in <italic>quadratic form</italic>:<disp-formula id="disp-formula22-0193841X12442673">
<label>22</label>
<mml:math id="mml-disp22-0193841X12442673">
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula22-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq22.tif"/>
</disp-formula>Where:</p>
<list list-type="simple">
<list-item>
<p>
<inline-formula id="inline-formula84-0193841X12442673">
<mml:math id="mml-inline84-0193841X12442673">
<mml:mi>V</mml:mi>
</mml:math>
</inline-formula>: This is an <italic>n</italic> × <italic>n</italic> matrix whose diagonal elements are <inline-formula id="inline-formula85-0193841X12442673">
<mml:math id="mml-inline85-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> and off-diagonal elements are 0.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula86-0193841X12442673">
<mml:math id="mml-inline86-0193841X12442673">
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>: This is the inverse of <italic>V</italic>. Hence it is also an <italic>n</italic> × <italic>n</italic> matrix whose diagonal elements are <italic>w<sub>i</sub>
</italic> and whose off-diagonal elements are 0.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula87-0193841X12442673">
<mml:math id="mml-inline87-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>: This is a column vector of random variables with true mean of μ.</p>
</list-item>
<list-item>
<p>
<inline-formula id="inline-formula88-0193841X12442673">
<mml:math id="mml-inline88-0193841X12442673">
<mml:mi>E</mml:mi>
</mml:math>
</inline-formula>: This is a 1 × <italic>n</italic> column vector of ones.</p>
</list-item>
</list>
<p>The utility of writing <italic>Q</italic> in quadratic form is twofold. First, the quadratic form <italic>Q</italic> has known statistical properties, some of which require assuming that <italic>u</italic> (the random effect accounting for unmeasured heterogeneity) is normally distributed. The derivations rely on these known properties. For a discussion, see (for example) <xref ref-type="bibr" rid="bibr44-0193841X12442673">Searle (1982)</xref>. Second, <italic>Q</italic> can be estimated from the sample data, so this approach is often called a moment-based estimator. The derivation requires one more term:
<list list-type="simple">
<list-item>
<p>
<inline-formula id="inline-formula89-0193841X12442673">
<mml:math id="mml-inline89-0193841X12442673">
<mml:mi mathvariant="normal">Σ</mml:mi>
</mml:math>
</inline-formula>: This is an <italic>n</italic> × <italic>n</italic> covariance–variance matrix for <inline-formula id="inline-formula90-0193841X12442673">
<mml:math id="mml-inline90-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>. Its diagonal elements are <inline-formula id="inline-formula91-0193841X12442673">
<mml:math id="mml-inline91-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. Its off-diagonal elements are 0.</p>
</list-item>
</list>
</p>
</sec>
<sec id="section18-0193841X12442673">
<title>An Estimate of <inline-formula id="inline-formula92-0193841X12442673">
<mml:math id="mml-inline92-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>
</title>
<p>Given <italic>n</italic> estimates <inline-formula id="inline-formula93-0193841X12442673">
<mml:math id="mml-inline93-0193841X12442673">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>, an evaluator might estimate <inline-formula id="inline-formula94-0193841X12442673">
<mml:math id="mml-inline94-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> from these <italic>n</italic> estimates using the usual formula for estimating a variance. This is intuitive, and for some problems it is the preferred approach (<xref ref-type="bibr" rid="bibr45-0193841X12442673">Shadish and Haddock 2009</xref>, 271), but a formulation based on the quadratic form is more frequently used.</p>
<p>A property of the quadratic form is:<disp-formula id="disp-formula23-0193841X12442673">
<label>23</label>
<mml:math id="mml-disp23-0193841X12442673">
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mi>Q</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:msup>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi>E</mml:mi>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula23-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq23.tif"/>
</disp-formula>Here <inline-formula id="inline-formula95-0193841X12442673">
<mml:math id="mml-inline95-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> denotes the trace of the matrix formed from multiplying <inline-formula id="inline-formula96-0193841X12442673">
<mml:math id="mml-inline96-0193841X12442673">
<mml:mi mathvariant="normal">Λ</mml:mi>
</mml:math>
</inline-formula> by <inline-formula id="inline-formula97-0193841X12442673">
<mml:math id="mml-inline97-0193841X12442673">
<mml:mi mathvariant="normal">Σ</mml:mi>
</mml:math>
</inline-formula>. Although this equation looks formidable, <xref ref-type="app" rid="app1-0193841X12442673">Appendix A</xref> shows that it simplifies to a single equation that can be solved for <inline-formula id="inline-formula98-0193841X12442673">
<mml:math id="mml-inline98-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. Of course, μ is unknown, but substituting the estimated μ gives an estimate of <italic>Q</italic> and thus an estimate of <inline-formula id="inline-formula99-0193841X12442673">
<mml:math id="mml-inline99-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The formula is:<disp-formula id="disp-formula24-0193841X12442673">
<label>24</label>
<mml:math id="mml-disp24-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula24-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq24.tif"/>
</disp-formula>This moment-based estimator has its counterpart in equations 12.2 through 12.5 in <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, 72). Also see the original formulation (<xref ref-type="bibr" rid="bibr16-0193841X12442673">DerSimonian and Laird 1986</xref>).</p>
</sec>
<sec id="section19-0193841X12442673">
<title>An Estimate of <inline-formula id="inline-formula100-0193841X12442673">
<mml:math id="mml-inline100-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi>V</mml:mi>
<mml:mi>A</mml:mi>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula>
</title>
<p>This derivation relies on another property of the quadratic form as well as an application of the delta method for approximating variances. According to the delta method, <inline-formula id="inline-formula101-0193841X12442673">
<mml:math id="mml-inline101-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> can be approximated as:<disp-formula id="disp-formula25-0193841X12442673">
<label>25</label>
<mml:math id="mml-disp25-0193841X12442673">
<mml:mrow>
<mml:mtext>VAR</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi>σ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>

<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≈</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>Q</mml:mi>
<mml:mo>−</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>

</mml:mrow>
</mml:mstyle>
</mml:mrow>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>

</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>Q</mml:mi>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mtext>VAR</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Q</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>

</mml:mrow>
</mml:mstyle>
</mml:mrow>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>

</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mtext>VAR</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Q</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula25-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq25.tif"/>
</disp-formula>The derivation requires an estimate for the variance of <italic>Q</italic>. The properties of the quadratic form are again useful because:<disp-formula id="disp-formula26-0193841X12442673">
<label>26</label>
<mml:math id="mml-disp26-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mi>Q</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>4</mml:mn>
<mml:msup>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi>E</mml:mi>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula26-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq26.tif"/>
</disp-formula>Solving <xref ref-type="disp-formula" rid="disp-formula26-0193841X12442673">Equation 26</xref> involves tedious bookkeeping but the solution is:<disp-formula id="disp-formula27-0193841X12442673">
<label>27</label>
<mml:math id="mml-disp27-0193841X12442673">
<mml:mtable columnalign="left">
<mml:mtr>
<mml:mtd>
<mml:mtext>VAR</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Q</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mrow>
<mml:mo>[</mml:mo> <mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>+</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>2</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:msup>
<mml:mn>2</mml:mn>
<mml:mn>2</mml:mn>
</mml:msup>

</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:msup>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msup>

</mml:mrow>
</mml:mfrac>

</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>4</mml:mn>
</mml:msubsup>

</mml:mrow> <mml:mo>]</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>1</mml:mn>
<mml:mo>=</mml:mo>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>

</mml:mrow>
</mml:mstyle>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>2</mml:mn>
<mml:mo>=</mml:mo>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>

</mml:mrow>
</mml:mstyle>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mi>s</mml:mi>
<mml:mi>w</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>=</mml:mo>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo> <mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>3</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mstyle>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula27-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq27.tif"/>
</disp-formula>Substituting <xref ref-type="disp-formula" rid="disp-formula27-0193841X12442673">Equation 27</xref> into <xref ref-type="disp-formula" rid="disp-formula25-0193841X12442673">25</xref> and using <inline-formula id="inline-formula102-0193841X12442673">
<mml:math id="mml-inline102-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> from <xref ref-type="disp-formula" rid="disp-formula26-0193841X12442673">Equation 26</xref> leads to the estimate <inline-formula id="inline-formula103-0193841X12442673">
<mml:math id="mml-inline103-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula>. This corresponds to Equations 16.11 through 16.12 in <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, 122). Estimates of <inline-formula id="inline-formula104-0193841X12442673">
<mml:math id="mml-inline104-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> are of independent scientific interest because they estimate the extent of unmeasured heterogeneity in a population; an estimate of <inline-formula id="inline-formula105-0193841X12442673">
<mml:math id="mml-inline105-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> therefore leads to a useful confidence interval, although its construction is complicated by the practice of truncating negative estimates of to <inline-formula id="inline-formula106-0193841X12442673">
<mml:math id="mml-inline106-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> zero.</p>
</sec>
<sec id="section20-0193841X12442673">
<title>Testing the Null of No Unmeasured Heterogeneity</title>
<p>The world of meta-analysis would be simpler if effects were homogeneous (perhaps after conditioning on <italic>X</italic>), which raises the question: Is the null hypothesis of homogeneous effects testable? The answer is “yes” and the test is straightforward: under the null hypothesis, the statistic <italic>Q</italic> is distributed as chi-square with <italic>n</italic> − 1 degrees of freedom (see <xref ref-type="app" rid="app1-0193841X12442673">Appendix A</xref>). This is a suitable statistics for testing the null hypothesis that the treatment effect is homogeneous.</p>
<p>A problem often noted in meta-analysis is that this test of the null hypothesis lacks power. Intuitively, this results because the variation across true effect sizes tends to be much smaller than the measurement error of estimated effect sizes. The estimate of <inline-formula id="inline-formula107-0193841X12442673">
<mml:math id="mml-inline107-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> gets swamped by error in measurement of <italic>Y</italic>. Given low power, the meta-analyst is unlikely to reject the null that <inline-formula id="inline-formula108-0193841X12442673">
<mml:math id="mml-inline108-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>. However, failure to reject the null is not justification for accepting the null of homogeneous effects.</p>
<p>This raises the question: What should an applied researcher do? One response may be that the applied researcher should always assume that effects have unmeasured heterogeneity and consequently use the estimated value <inline-formula id="inline-formula109-0193841X12442673">
<mml:math id="mml-inline109-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> in the FGLS solution provided, of course, that it is positive. (Negative estimates are set to zero.) The problem is that the applied researcher has to work with an estimate of <inline-formula id="inline-formula110-0193841X12442673">
<mml:math id="mml-inline110-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, which can have a high sampling variance, especially when <italic>n</italic> is small. In this case, the FGLS solution can perform worse that a solution that presumes <inline-formula id="inline-formula111-0193841X12442673">
<mml:math id="mml-inline111-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>.</p>
<p>This raises the question of whether the FGLS solution that uses the best estimate for <inline-formula id="inline-formula112-0193841X12442673">
<mml:math id="mml-inline112-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> (e.g., the random-effect estimator) is better than the FGLS approximate solution that presumes <inline-formula id="inline-formula113-0193841X12442673">
<mml:math id="mml-inline113-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> (e.g., the fixed-effect estimator). From a mean squared error perspective, it may not be better. <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene (2008</xref>, 162) provides a discussion. Some authorities argue that for small samples, where the estimation of <inline-formula id="inline-formula114-0193841X12442673">
<mml:math id="mml-inline114-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is especially uncertain, the meta-analyst might choose to be content to make sample-based estimates rather than seek to generalize outside the sample (<xref ref-type="bibr" rid="bibr34-0193841X12442673">Konstantopoulos and Hedges 2009</xref>).</p>
</sec>
<sec id="section21-0193841X12442673">
<title>Using a Robust Covariance Estimator</title>
<p>A researcher does not need to estimate <inline-formula id="inline-formula115-0193841X12442673">
<mml:math id="mml-inline115-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> to derive consistent estimates of β and hence the average effect. There are three reasons to go to the trouble of estimating <inline-formula id="inline-formula116-0193841X12442673">
<mml:math id="mml-inline116-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The first reason is that the estimates of β may be more efficient when the weights <italic>W</italic> are used instead of the weights <italic>w</italic>. However, if <inline-formula id="inline-formula117-0193841X12442673">
<mml:math id="mml-inline117-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is small relative to <inline-formula id="inline-formula118-0193841X12442673">
<mml:math id="mml-inline118-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>e</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, there will be little efficiency gain from using <italic>W</italic> instead of <italic>w</italic>, and in fact efficiency may be lessened given an imprecise estimate of <inline-formula id="inline-formula119-0193841X12442673">
<mml:math id="mml-inline119-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The second reason is that <inline-formula id="inline-formula120-0193841X12442673">
<mml:math id="mml-inline120-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is of intrinsic interest because it represents the distribution of the true treatment effects, but if it is measured with great imprecision, there is some question about whether it is worth estimating. Hence the first two reasons for estimating <inline-formula id="inline-formula121-0193841X12442673">
<mml:math id="mml-inline121-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> may not seem compelling.</p>
<p>The third reason for estimating <inline-formula id="inline-formula122-0193841X12442673">
<mml:math id="mml-inline122-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is to correct for inconsistency in the estimated covariance matrix for the estimated β. Still, both the maximum likelihood estimator and the moment-based estimator for <inline-formula id="inline-formula123-0193841X12442673">
<mml:math id="mml-inline123-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> rest on a strong assumption that every study draws <italic>u</italic> from the same normal distribution.<sup>
<xref ref-type="fn" rid="fn11-0193841X12442673">11</xref>
</sup> Although conditioning the estimates on <italic>X</italic> may make this strong assumption more plausible, it is still strong, so an analyst might ask: Given willingness to sacrifice an estimate for <inline-formula id="inline-formula124-0193841X12442673">
<mml:math id="mml-inline124-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, is there any other way to estimate the covariance matrix for β?</p>
<p>
<xref ref-type="bibr" rid="bibr40-0193841X12442673">Raudenbush (2009</xref>, 313) suggests using a robust covariance matrix estimator, sometimes called a sandwich estimator. However, the comments in this current article follow the discussion in <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene (2008</xref>, 164) and <xref ref-type="bibr" rid="bibr15-0193841X12442673">Davidson and MacKinnon (1993</xref>, 553), because they propose a robust covariance matrix estimator with better small-sample properties. The logic is to derive the estimates for β using any consistent estimator. Estimates based on <xref ref-type="disp-formula" rid="disp-formula15-0193841X12442673">Equation 15</xref>, where the analyst (incorrectly) assumes that <inline-formula id="inline-formula125-0193841X12442673">
<mml:math id="mml-inline125-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, will nevertheless be consistent. The problem is that the parameter covariance matrix will be inconsistent, but this is where the estimator for a robust covariance matrix enters the picture.</p>
<p>Call these consistent parameter estimates <inline-formula id="inline-formula126-0193841X12442673">
<mml:math id="mml-inline126-0193841X12442673">
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>. They can be used to estimate the residuals. Call the residuals <italic>r<sub>i</sub>
</italic>. Thus:<disp-formula id="disp-formula28-0193841X12442673">
<label>28</label>
<mml:math id="mml-disp28-0193841X12442673">
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula28-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq28.tif"/>
</disp-formula>Note that this residual is estimating <inline-formula id="inline-formula127-0193841X12442673">
<mml:math id="mml-inline127-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. The distribution of this residual will be heteroscedastic.</p>
<p>Following the argument made by <xref ref-type="bibr" rid="bibr53-0193841X12442673">White (1980)</xref>, but extended to the peculiarities of meta-analysis, let <italic>M</italic> be an <italic>n</italic> × 2 matrix with <inline-formula id="inline-formula128-0193841X12442673">
<mml:math id="mml-inline128-0193841X12442673">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> as the <italic>i</italic>th element in the first column and <inline-formula id="inline-formula129-0193841X12442673">
<mml:math id="mml-inline129-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mrow>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> as the <italic>i</italic>th element in the second column. Let <italic>m<sub>k</sub>
</italic> represent the<italic> k</italic>th column of <italic>M</italic>. Then, in matrix algebra form, the White heteroscedasticity consistent estimator can be written:<disp-formula id="disp-formula29-0193841X12442673">
<label>29</label>
<mml:math id="mml-disp29-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mfenced close=")" open="(">
<mml:mi mathvariant="italic">β</mml:mi>
</mml:mfenced>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">a</mml:mi>
<mml:mi mathvariant="normal">s</mml:mi>
<mml:mi mathvariant="normal">y</mml:mi>
<mml:mi mathvariant="normal">m</mml:mi>
<mml:mi mathvariant="normal">p</mml:mi>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">o</mml:mi>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">c</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:munderover>
<mml:mo movablelimits="false" stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:munderover>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:msub>
<mml:mi>m</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mi>m</mml:mi>
<mml:mi>k</mml:mi>
<mml:mo>′</mml:mo>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula29-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq29.tif"/>
</disp-formula>The problem with this solution is that the covariance matrix has an asymptotic justification, but meta-analyses typically have samples that are sufficiently small that asymptotic properties may lack credibility. Davidson and MacKinnon provide some adjustments that have better small-sample properties and are easy to implement.</p>
<p>Specifically, let <italic>P</italic> represent the projection matrix <inline-formula id="inline-formula130-0193841X12442673">
<mml:math id="mml-inline130-0193841X12442673">
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>M</mml:mi>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:msup>
<mml:mi>M</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
</mml:math>
</inline-formula> and let <italic>h<sub>i</sub> </italic>represent the <italic>i</italic>th diagonal element of this matrix. Then Davidson and MacKinnon suggest replacing <inline-formula id="inline-formula131-0193841X12442673">
<mml:math id="mml-inline131-0193841X12442673">
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> in <xref ref-type="disp-formula" rid="disp-formula27-0193841X12442673">Equation 27</xref> with <inline-formula id="inline-formula132-0193841X12442673">
<mml:math id="mml-inline132-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>h</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>h</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. Essentially, the Davidson and MacKinnon adjustment “corrects” for the fact that a regression will underestimate the residual.</p>
</sec>
</sec>
<sec id="section22-0193841X12442673">
<title>Rethinking the Regressions</title>
<p>It has been convenient to think of a simple linear regression because this is prominent in regression analysis. Furthermore, it has been convenient to use the regression-based approach to motivate derivation of an asymptotically justified parameter covariance matrix with small-sample adjustments. Motivating the derivation of the parameter estimates has not been the principal reason why meta-analysts use regressions, however, and it is worthwhile to briefly examine the use of regressions for different purposes.</p>
<sec id="section23-0193841X12442673">
<title>Analysis of Variance</title>
<p>Given the important role of variance components in meta-analysis, it is not surprising that meta-analysts frequently employ analysis of variance (ANOVA) techniques. Modifying the regression approach to become an ANOVA approach is straightforward. The <italic>X</italic> is replaced by group membership with <italic>G</italic> dummy variables representing each of the <italic>G</italic> groups. Examining meta-analysis from the perspective of ANOVA offers insights or at least clarifications for the three models adopted above: homogeneity, measured heterogeneity, and unmeasured heterogeneity.</p>
<p>If there are <italic>G</italic> groups, and if the average effect is the same for each group, and if there is no variation in effects within each group, then the analyst has homogeneity. If there is heterogeneity across the <italic>G</italic> groups but none within each of the <italic>G</italic> groups, then the analyst has measured heterogeneity but no unmeasured heterogeneity. If there is no heterogeneity across the <italic>G</italic> groups and there is heterogeneity within one of more of the <italic>G</italic> groups, then the analyst has unmeasured heterogeneity. Of course, unmeasured and measured heterogeneity can be combined in the same ANOVA model.</p>
<p>Although there is likely to be limited power when there are few studies, the analyst can test for heterogeneity across the <italic>G</italic> groups and heterogeneity within any or all of the <italic>G</italic> groups (<xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. 2009</xref>, chap. 19; <xref ref-type="bibr" rid="bibr34-0193841X12442673">Konstantopoulos and Hedges 2009</xref>) using standard ANOVA procedures with minor adaptation to account for the fact that <inline-formula id="inline-formula133-0193841X12442673">
<mml:math id="mml-inline133-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is treated as known. An alternative might be to use a group-wise robust covariance matrix such as procedures implemented in Stata (<xref ref-type="bibr" rid="bibr12-0193841X12442673">Cameron and Trivedi 2009</xref>).</p>
</sec>
<sec id="section24-0193841X12442673">
<title>A Regression</title>
<p>From an econometric perspective, there is little difference between ANOVA and FGLS. In ANOVA, the <italic>X</italic> variables are discrete; in FGLS, the <italic>X</italic> variables are continuous. However, nothing prevents blending discrete and continuous variables except perhaps degrees of freedom restrictions. For a discussion, see <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, chap. 20).</p>
<p>There are three reasons to use a regression for meta-analysis. This article has discussed the first at some length: the analyst expects that <inline-formula id="inline-formula134-0193841X12442673">
<mml:math id="mml-inline134-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> will be near zero after conditioning on <italic>X</italic>. The second purpose is to draw inferences from the estimated β. One must be cautious about those inferences. As noted, <inline-formula id="inline-formula135-0193841X12442673">
<mml:math id="mml-inline135-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula> estimates the conditional mean. While <italic>X</italic> may account for variance, the ultimate explanation may rest with the omitted <italic>Z</italic>. Clinical trials may be able to eliminate <italic>Z</italic> as a confounder, but justifying an argument that there is no omitted <italic>Z</italic> seems difficult for social science research.</p>
<p>So far, this article has implicitly (and sometimes explicitly) assumed that the <italic>n</italic> estimated effect sizes entering into the meta-analysis are consistent for their population counterparts (the true treatment effects). Often this is not so, especially in social science research where a corpus of literature is often based on studies that use observational data. To discuss this problem, some authorities further classify heterogeneity as <italic>factual</italic> or <italic>methodological</italic> depending on whether the heterogeneity is a true characteristic of the population or an artifact of the different methods using by primary researchers to estimate effect sizes (<xref ref-type="bibr" rid="bibr35-0193841X12442673">Lipsey 2009</xref>).</p>
<p>This is an important topic for which a short article can only provide a summary. The summary gives a new role to the <italic>X</italic> variables. Now one or more of the <italic>X</italic> variables capture methodological differences across the <italic>n</italic> studies that provided estimated effect sizes. For example, some of the estimated effect sizes may have come from randomized controlled trials (RCT); other may have come from using instrumental variables (IV); still others may have come from using a regression discontinuity design (RDD). Given heterogeneous treatment effects within an intervention, the RCT, IV, and RDD estimators will be consistent for different parameters (<xref ref-type="bibr" rid="bibr32-0193841X12442673">Imbens and Wooldridge 2009</xref>). The <italic>X</italic> would account for this confounding factor, and the parameters associated with <italic>X</italic> would identify how methodological differences affect estimates of the average effect size.</p>
<p>More broadly, when estimating effect sizes, researchers use a variety of model specifications. For example, some use linear models; others use log-linear models; still others use double-log models. Differences across effect sizes may be attributable to choices about model specification. One of more of the <italic>X</italic> would account for differences in model specification, and the parameters associated with <italic>X</italic> would identify how choices about model specification affect estimates of the average effect size.</p>
<p>Again, this short article cannot provide a longer treatment of this important topic. Interested readers are encouraged to consult <xref ref-type="bibr" rid="bibr41-0193841X12442673">Roberts and Stanley (2005)</xref>.</p>
</sec>
<sec id="section25-0193841X12442673">
<title>Dependent Effect Sizes</title>
<p>To this point, this article has assumed that the <italic>n</italic> studies report independent effect sizes. This was convenient for fixing ideas, but it is not essential and meta-analysis often requires relaxing the assumption (<xref ref-type="bibr" rid="bibr26-0193841X12442673">Hedges, Tipton, and Johnson 2010</xref>). There are at least two important ways that the <italic>n</italic> effect sizes can depart from the simplifying assumption of independence.</p>
<p>First, the <italic>n</italic> studies may report treatment effects using the same outcome measure, but there may be clustering. <xref ref-type="bibr" rid="bibr19-0193841X12442673">Gleser and Olkin (2009)</xref> provide a transparent example: An evaluation study randomly assigns study subjects to three conditions—control, low-dose treatment, and high-dose treatment. The evaluation study uses the same control group to estimate separate effects for the low-dose and high-dose treatments. Because the estimated effect sizes share a common control group, they will not be independent. Dependence occurs in other ways: Different investigators may study the same intervention; the same investigator may report different estimated effect sizes for the same study; over time, a research team with the same perceptional bias may contribute multiple studies. This list is not comprehensive of how clustered estimated effect sizes enter into meta-analysis. The subsection that immediately follows discusses estimation when independence across estimated effect sizes is untenable.</p>
<p>Second, a single study may report estimated effect sizes for <italic>k </italic>= 1, 2 . . . <italic>K</italic> different outcomes. An analyst could handle each outcome separately, in which case nothing would change from what was written above. Alternatively, the analyst might want to combine effects after estimation, for example, by averaging the average treatment effects for mathematics scores and reading scores in a study of an education intervention. The mathematics and reading scores are unlikely to be independent. A subsection on multiple outcomes deals with estimation when there are multiple outcomes and the meta-analyst wants to average them.</p>
<sec id="section26-0193841X12442673">
<title>Estimated effect sizes are dependent</title>
<p>Although dropping the assumption of independence raises complications, weighting the data still provides a solution. The problem is that the weights become more complicated and necessarily carry the reader deeper into matrix algebra. Previously the error terms <inline-formula id="inline-formula136-0193841X12442673">
<mml:math id="mml-inline136-0193841X12442673">
<mml:msub>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> were independent across the estimated effect sizes, so that the <italic>n</italic> by <italic>n</italic> matrix <inline-formula id="inline-formula137-0193841X12442673">
<mml:math id="mml-inline137-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:msub>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
<mml:mo>′</mml:mo>
</mml:msubsup>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> was diagonal with the <italic>i</italic>th diagonal element being <inline-formula id="inline-formula138-0193841X12442673">
<mml:math id="mml-inline138-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. This led to a simple weight of <inline-formula id="inline-formula139-0193841X12442673">
<mml:math id="mml-inline139-0193841X12442673">
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mfenced close="" open="/">
<mml:mrow>
<mml:mpadded width="0">
<mml:mphantom>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mphantom>
</mml:mpadded>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:msqrt>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. But when the estimated effect sizes are not independent, Ω is not diagonal: within clusters of estimated effect sizes, the off-diagonal terms are covariances; otherwise, the off-diagonal terms are zeros. Weighting is not so simple and matrix algebra is necessary.</p>
<p>Using matrix decomposition let <inline-formula id="inline-formula140-0193841X12442673">
<mml:math id="mml-inline140-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>C</mml:mi>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:msup>
<mml:mi>C</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
</mml:math>
</inline-formula> where <inline-formula id="inline-formula141-0193841X12442673">
<mml:math id="mml-inline141-0193841X12442673">
<mml:mi>C</mml:mi>
</mml:math>
</inline-formula> comprises the characteristic vectors of Ω and Λ is a diagonal matrix whose elements are the characteristic roots of Ω. Let <inline-formula id="inline-formula142-0193841X12442673">
<mml:math id="mml-inline142-0193841X12442673">
<mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>/</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula> represent a diagonal matrix whose elements are the inverses of the square roots of the characteristics roots, and let <inline-formula id="inline-formula143-0193841X12442673">
<mml:math id="mml-inline143-0193841X12442673">
<mml:msup>
<mml:mi>P</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>C</mml:mi>
<mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>/</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>. Then <inline-formula id="inline-formula144-0193841X12442673">
<mml:math id="mml-inline144-0193841X12442673">
<mml:msup>
<mml:mi>P</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mi mathvariant="normal">Ω</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula> and the GLS solution is to estimate the weighted regression:<disp-formula id="disp-formula30-0193841X12442673">
<label>30</label>
<mml:math id="mml-disp30-0193841X12442673">
<mml:mi>P</mml:mi>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>P</mml:mi>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>P</mml:mi>
<mml:mi>v</mml:mi>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula30-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq30.tif"/>
</disp-formula>
<xref ref-type="disp-formula" rid="disp-formula18-0193841X12442673">Equations 18</xref> and <xref ref-type="disp-formula" rid="disp-formula19-0193841X12442673">19</xref> represented the statistical model using a subscript <italic>i</italic> to represent the <italic>i</italic>th estimated effect size. <xref ref-type="disp-formula" rid="disp-formula30-0193841X12442673">Equation 30</xref> uses matrix algebra to represent analogous calculations. (As before, <italic>W</italic> is a matrix with ones in the first column and <italic>X</italic> is the second column.) This notational switch is necessary because for the earlier models, where estimated effect sizes were independent, <italic>P</italic> was a diagonal matrix, and hence the matrix multiplication <inline-formula id="inline-formula145-0193841X12442673">
<mml:math id="mml-inline145-0193841X12442673">
<mml:mi>P</mml:mi>
<mml:mi>Y</mml:mi>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula146-0193841X12442673">
<mml:math id="mml-inline146-0193841X12442673">
<mml:mi>P</mml:mi>
<mml:mi>W</mml:mi>
</mml:math>
</inline-formula> could be represented by multiplying the individual elements of <italic>Y</italic> and <italic>W</italic> by a specific constant. However, in the present context, <inline-formula id="inline-formula147-0193841X12442673">
<mml:math id="mml-inline147-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
</mml:math>
</inline-formula> is block diagonal, meaning that off-diagonal terms are nonzero within clusters of studies whose treatment effects are not independent. <italic>P</italic> is also block diagonal, so matrix algebra is required to perform the multiplication.</p>
<p>In either case—whether the estimated effect sizes are independent or not independent—pre-multiplication by <italic>P</italic> accomplishes the same thing. Prior to the transformation, the error term <italic>v</italic> has a distribution that is normal but heteroscedastic and dependent within clusters. After applying the transformation, the error term <italic>Pv</italic> has a distribution that is normal, homoscedastic (with variance of 1), and independent across the transformed observations. That is, <inline-formula id="inline-formula148-0193841X12442673">
<mml:math id="mml-inline148-0193841X12442673">
<mml:msup>
<mml:mi>P</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi mathvariant="normal">Ω</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula149-0193841X12442673">
<mml:math id="mml-inline149-0193841X12442673">
<mml:mi>I</mml:mi>
</mml:math>
</inline-formula> is the identity matrix.</p>
<p>It is unlikely that an analyst would actually perform the matrix decomposition represented by <inline-formula id="inline-formula150-0193841X12442673">
<mml:math id="mml-inline150-0193841X12442673">
<mml:msup>
<mml:mi>P</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>C</mml:mi>
<mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>/</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>. The more traditional formula, which simply uses the inverse <inline-formula id="inline-formula151-0193841X12442673">
<mml:math id="mml-inline151-0193841X12442673">
<mml:msup>
<mml:mi mathvariant="normal">Ω</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>, appears in <xref ref-type="bibr" rid="bibr19-0193841X12442673">Gleser and Olkin (2009)</xref> and <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene (2008)</xref> as well as other sources. However, the matrix decomposition approach is mathematically equivalent to the traditional formula and has the advantage of illustrating why the traditional formula works.</p>
<p>The conceptualization of the estimation problem is straightforward. The application is difficult because the analyst does not know <inline-formula id="inline-formula152-0193841X12442673">
<mml:math id="mml-inline152-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
</mml:math>
</inline-formula> and must substitute an estimated <inline-formula id="inline-formula153-0193841X12442673">
<mml:math id="mml-inline153-0193841X12442673">
<mml:mover accent="true">
<mml:mi mathvariant="normal">Ω</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>. Perhaps, the original investigator provided an estimate of covariance terms. If not, <xref ref-type="bibr" rid="bibr19-0193841X12442673">Gleser and Olkin (2009)</xref> discuss approaches for estimating robust covariance terms. Also see <xref ref-type="bibr" rid="bibr26-0193841X12442673">Hedges, Tipton, and Johnson (2010)</xref>.</p>
<p>Many analysts with training in econometrics and regression analysis will see a more familiar way to proceed (<xref ref-type="bibr" rid="bibr38-0193841X12442673">Nelson and Kennedy 2009</xref>). When a meta-analysis has multiple observations of the same treatment effect, or when the meta-analysis has multiple observations that are otherwise correlated, the observations are clustered. In other contexts, when faced with clustering, the analyst might turn to multilevel/hierarchical models (<xref ref-type="bibr" rid="bibr18-0193841X12442673">Gelman and Hill 2007</xref>) or models based on the analysis of panel data (<xref ref-type="bibr" rid="bibr2-0193841X12442673">Baltagi 2005</xref>). A meta-analyst would typically ignore the time-series nature of panel data, but otherwise these models transfer to the meta-analysis context. Or, the time-series nature of the data may be of interest, perhaps because slowly changing “conventional wisdom” leads to studies whose estimated effect sizes have autocorrelation. Fortunately, conventional computing software offers easily accessible solutions (<xref ref-type="bibr" rid="bibr12-0193841X12442673">Cameron and Trivedi 2009</xref>). A meta-analyst with a solid grasp of estimation procedures for dealing with multilevel/hierarchical models and models used to study panels (including models with errors that are correlated over time) will find a rich set of procedures for dealing with dependent effect sizes.</p>
</sec>
<sec id="section27-0193841X12442673">
<title>Multiple outcomes<sup>
<xref ref-type="fn" rid="fn12-0193841X12442673">12</xref>
</sup>
</title>
<p>Many studies report results for more than one outcome. Evaluations of educational interventions might report gains in reading achievement scores and gains in math achievement scores. If the researcher were willing to perform separate analyses on both outcomes, dealing with multiple outcomes raises few new issues. If there were many outcomes, then one might begin to worry about making multiple comparisons (<xref ref-type="bibr" rid="bibr43-0193841X12442673">Schochet 2009</xref>), but this really seems like a minor concern given that few outcomes are likely to enter the analysis, and one could make Bonferroni-type adjustments to the test statistics to take multiple comparisons into account. Stata also provides adjustments based on permutation tests (<xref ref-type="bibr" rid="bibr21-0193841X12442673">Harbord and Higgins 2009</xref>).</p>
<p>However, the researcher may want to estimate the true effect size for each outcome and then average across the outcomes. Whether combining outcomes is sensible is a substantive question, but suppose taking a weighted average was justified. For example, one might take a weighted average of gain in reading and math achievement scores. How might an analyst compute the standard error for a weighted average?</p>
<p>The generic solution is clear. Let <inline-formula id="inline-formula154-0193841X12442673">
<mml:math id="mml-inline154-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> be the estimated mean effect size for the first outcome and let <inline-formula id="inline-formula155-0193841X12442673">
<mml:math id="mml-inline155-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> be the estimated mean effect size for the second outcome. Let <inline-formula id="inline-formula156-0193841X12442673">
<mml:math id="mml-inline156-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula157-0193841X12442673">
<mml:math id="mml-inline157-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>2</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula158-0193841X12442673">
<mml:math id="mml-inline158-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> be the parameter variances and covariance, respectively. Then if λ is the weight, the weighted average is <inline-formula id="inline-formula159-0193841X12442673">
<mml:math id="mml-inline159-0193841X12442673">
<mml:mi mathvariant="italic">λ</mml:mi>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi mathvariant="italic">λ</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> and its sampling variance is:<disp-formula id="disp-formula31-0193841X12442673">
<label>31</label>
<mml:math id="mml-disp31-0193841X12442673">
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mi mathvariant="italic">λ</mml:mi>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi mathvariant="italic">λ</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>2</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mi mathvariant="italic">λ</mml:mi>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi mathvariant="italic">λ</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula31-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq31.tif"/>
</disp-formula>
<xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, part 5) provide computational formulas for implementing this estimator. They suggest that the analyst derive estimates for σ<sub>12</sub> from external sources or even guess at an estimate and then conduct sensitivity testing.</p>
<p>Econometrics provides a different route by employing seemingly unrelated regressions (SUR) estimation procedures (<xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene 2008</xref>, 252). One might estimate <inline-formula id="inline-formula160-0193841X12442673">
<mml:math id="mml-inline160-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula161-0193841X12442673">
<mml:math id="mml-inline161-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:math>
</inline-formula>,<inline-formula id="inline-formula162-0193841X12442673">
<mml:math id="mml-inline162-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula163-0193841X12442673">
<mml:math id="mml-inline163-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>2</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula164-0193841X12442673">
<mml:math id="mml-inline164-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> jointly after expressing <inline-formula id="inline-formula165-0193841X12442673">
<mml:math id="mml-inline165-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
</mml:math>
</inline-formula> appropriately. The matrix decomposition discussed immediately above would again be applicable, so the idea of using weighted regressions carries over to this context.<sup>
<xref ref-type="fn" rid="fn13-0193841X12442673">13</xref>
</sup> However, it is unlikely that an analyst would go to this trouble.</p>
<p>In most applications, <italic>W</italic> will comprise a column of ones, or <italic>X</italic> will be the same across outcomes. When that is the case, there is no efficiency gain from joint estimation. The analyst might then estimate each outcome separately using the procedures already discussed. This leads to estimates of <inline-formula id="inline-formula166-0193841X12442673">
<mml:math id="mml-inline166-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula167-0193841X12442673">
<mml:math id="mml-inline167-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula168-0193841X12442673">
<mml:math id="mml-inline168-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula169-0193841X12442673">
<mml:math id="mml-inline169-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mn>2</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The remaining problem is to estimate <inline-formula id="inline-formula170-0193841X12442673">
<mml:math id="mml-inline170-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> and an estimate comes from using the residuals from the individual meta-regressions. See <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene (2008</xref>, 252) for a discussion. The approach is easily extended to more than two outcomes. Modern computing software facilitates application of the SUR estimator. Interested readers might consult Stata documentation.</p>
</sec>
</sec>
</sec>
<sec id="section28-0193841X12442673">
<title>Monte Carlo Simulations</title>
<p>Theoretical and practical properties of these estimators are demonstrable with a Monte Carlo simulation (<xref ref-type="bibr" rid="bibr12-0193841X12442673">Cameron and Trivedi 2009</xref>) performed using Stata software for meta-analysis (<xref ref-type="bibr" rid="bibr49-0193841X12442673">Sterne 2009</xref>).</p>
<sec id="section29-0193841X12442673">
<title>Model 1 (Homogeneous Effects)</title>
<p>To simulate the DGP when effects are homogeneous, assume that the actual effect size is 0.5 for all studies and that the true standard errors for the estimated effect sizes are uniformly distributed between 0.5 and 1.5. To reflect the fact that the standard errors “known” to the meta-analyst are estimated by the original researchers, the simulation adds a disturbance to the true standard errors. The disturbance is a multiplier equal to a random number between 1 and 1.1. These specific assumptions are not important to the argument; they merely prime the simulation.</p>
<p>The simulation assumed ten studies and it generated 10,000 replications for those 10 studies. The simulation applied three estimators:<list list-type="bullet">
<list-item>
<p>OLS</p>
</list-item>
<list-item>
<p>FGLS</p>
</list-item>
<list-item>
<p>The meta-analysis procedure for fixed-effects in Stata (called metan). This estimator assumes that Model 1 conforms to the DGP.</p>
</list-item>
</list>
<xref ref-type="table" rid="table2-0193841X12442673">Table 2</xref> summarizes results. The table identifies the three estimators in its rows. The columns report (1) the mean of the average effect size across the 10,000 replications, (2) the standard deviation based on the 10,000 replications, and (3) the mean of the estimated standard errors across the 10,000 replications.</p>
<table-wrap id="table2-0193841X12442673" position="float">
<label>Table 2.</label>
<caption>
<p>Estimates When Model 1 is Correct</p>
</caption>
<graphic alternate-form-of="table2-0193841X12442673" xlink:href="10.1177_0193841X12442673-table2.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>Average Effect Size</th>
<th>
<italic>SD</italic>
</th>
<th>Mean Standard Error</th>
</tr>
</thead>
<tbody>
<tr>
<td>OLS</td>
<td>0.496</td>
<td>0.329</td>
<td>0.320</td>
</tr>
<tr>
<td>FGLS</td>
<td>0.496</td>
<td>0.278</td>
<td>0.273</td>
</tr>
<tr>
<td>Metan (fixed)</td>
<td>0.496</td>
<td>0.278</td>
<td>0.292</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0193841X12442673">
<p>
<italic>Note.</italic> OLS = ordinary least squares; FGLS = feasible generalized least squares.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Each of the three estimators is consistent for the average effect size, so over 10,000 replications they all provide an estimated average effect size that is close (on average) to the true value of 0.5. The second column shows that the FGLS and metan (a Stata estimation procedure) estimates are more efficient than the OLS estimate and that they are equally efficient (because they are computationally the same). FGLS and metan produce different estimates for the standard error, presumably because metan assumes that the variance across the residuals equals 1. As anticipated, FGLS does not provide the same estimated standard errors as do the formulas usually employed by meta-analyst as embodied into metan.</p>
</sec>
<sec id="section30-0193841X12442673">
<title>Model 2 (Unmeasured Heterogeneous Effects)</title>
<p>The next simulation is similar to the previous one, except that <italic>u</italic> is drawn from a normal distribution with mean 0 and variance of 0.25. Applying the estimator for Model 1 even when it is inappropriate produces the results reported in <xref ref-type="table" rid="table3-0193841X12442673">Table 3</xref>. <xref ref-type="table" rid="table3-0193841X12442673">Table 3</xref> also reports the estimator for a random effects model.</p>
<table-wrap id="table3-0193841X12442673" position="float">
<label>Table 3.</label>
<caption>
<p>Estimates When Model 2 is Correct</p>
</caption>
<graphic alternate-form-of="table3-0193841X12442673" xlink:href="10.1177_0193841X12442673-table3.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>Average Effect Size</th>
<th>
<italic>SD</italic>
</th>
<th>Mean Standard Error</th>
</tr>
</thead>
<tbody>
<tr>
<td>OLS</td>
<td>0.492</td>
<td>0.367</td>
<td>0.352</td>
</tr>
<tr>
<td>FGLS<sup>a</sup>
</td>
<td>0.495</td>
<td>0.337</td>
<td>0.312</td>
</tr>
<tr>
<td>Metan (fixed)</td>
<td>0.495</td>
<td>0.337</td>
<td>0.293</td>
</tr>
<tr>
<td>Metan (random)</td>
<td>0.494</td>
<td>0.336</td>
<td>0.330</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0193841X12442673">
<p>
<sup>a</sup>This is the FGLS for the fixed effect model.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>As before, all estimation methods yield estimates for the average effect size that are roughly the same on average across the 10,000 simulations. FGLS (fixed) and metan (fixed and random) are more efficient than the OLS solution. Interestingly, the random effect model is about as efficient as the fixed effect model. One possible explanation is that the random effect model must estimate <inline-formula id="inline-formula171-0193841X12442673">
<mml:math id="mml-inline171-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> and this estimate is imprecise.</p>
<p>To reinforce this last point, in the above simulation, a 90% empirical confidence interval for the estimate of <inline-formula id="inline-formula172-0193841X12442673">
<mml:math id="mml-inline172-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is 0 to 1.145. Observations are clustered at 0 (more than 25% of the estimates) because if the estimate of <inline-formula id="inline-formula173-0193841X12442673">
<mml:math id="mml-inline173-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is negative, Stata will follow conventional practices and set the estimate to zero. If one used a statistical test of the null <inline-formula id="inline-formula174-0193841X12442673">
<mml:math id="mml-inline174-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, one would reject the null in only 75% of the 10,000 replications when the <italic>p</italic> value is .663, in 50% of the replications with a <italic>p</italic> value of .354, and in 25% of the replications with a <italic>p</italic> value of .129. As often noted in the meta-analysis literature, testing the statistical significance of <inline-formula id="inline-formula175-0193841X12442673">
<mml:math id="mml-inline175-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> lacks power; <inline-formula id="inline-formula176-0193841X12442673">
<mml:math id="mml-inline176-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is estimated with considerable precision; and there is little gain in estimation efficiency. Estimates of the standard error are consistent for the random effect model, but this is of little consolation since it results from having 10,000 replications.</p>
<p>There are efficiency gains when the sample size increases from 10 to 100 (not shown in the table). With a sample size of 100, the 90% empirical confidence interval for <inline-formula id="inline-formula177-0193841X12442673">
<mml:math id="mml-inline177-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is 0 to 0.427. If one used a statistical test of the null <inline-formula id="inline-formula178-0193841X12442673">
<mml:math id="mml-inline178-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, one would reject the null in 75% of the 10,000 replications when the <italic>p </italic>value is .254, in 50% of the replications with a <italic>p</italic>-value of 0.082, and in 25% of the replications with a <italic>p</italic>-value of 0.017.</p>
</sec>
<sec id="section31-0193841X12442673">
<title>Model 4 (Measured and Unmeasured Heterogeneous Effects)</title>
<p>The final simulation extends the previous simulation by adding an additional variable <italic>X</italic>. <italic>X</italic> is uniformly distributed between −0.5 and +0.5. It has a parameter β<sub>1</sub> = 2. This choice for <italic>X</italic> centers the <italic>X</italic> distribution on 0, so that β<sub>0</sub> is (in expectation) the average effect size. The Stata routine metareg yields estimates.</p>
<p>The only interesting contrast is between Model 2 (unmeasured heterogeneity but no measured heterogeneity) and Model 4 (both measured and unmeasured heterogeneity). Both are consistent for the average effect size, and in fact, both yield estimates of the average effect size averaged over the 10,000 replications that are close to 0.5. In Model 2, unmeasured heterogeneity is not normally distributed, because the unmeasured heterogeneity includes the (unmeasured) <italic>X</italic>, which has a uniform distribution. Nevertheless, the estimated standard error for the average effect size (0.121) is close to the observed standard deviation over the 10,000 replications (0.122). For Model 4, the estimated standard error for β<sub>0</sub> is 0.105 while the standard deviation is 0.104. As would be expected, introducing <italic>X</italic> as an explanatory variable increases efficiency.</p>
</sec>
</sec>
<sec id="section32-0193841X12442673">
<title>Drawing Inferences From the FGLS Regression</title>
<p>An analyst might seek to answer one or more of three questions:</p>
<list list-type="order">
<list-item>
<p>What is the average effect size in the sample? A variation on this question asks: What is the average effect size conditional on <italic>X </italic>? Either way, the answer takes the form of a point estimate and a confidence interval.</p>
</list-item>
<list-item>
<p>What is the average effect size in the population? If <inline-formula id="inline-formula179-0193841X12442673">
<mml:math id="mml-inline179-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, then the questions posed in the first and second bullets are the same. If <inline-formula id="inline-formula180-0193841X12442673">
<mml:math id="mml-inline180-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, then the answers to the questions posed in the first and second bullets will have the same point estimates but different confidence intervals.</p>
</list-item>
<list-item>
<p>What is the expected value of an estimated effect size in a new study? The point estimate that answers this question is the same as the point estimate that answered the previous questions, but the confidence intervals would be even larger.</p>
</list-item>
</list>
<p>This section explains these points from a regression perspective.</p>
<p>Consider the first question. Based on the regression analysis, the analyst has estimates of β and COV(β). The point estimate for the average effect size and its standard error are:<disp-formula id="disp-formula32-0193841X12442673">
<label>32</label>
<mml:math id="mml-disp32-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">G</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">G</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mn>1</mml:mn>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mi>C</mml:mi>
<mml:mi>O</mml:mi>
<mml:mi>V</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mn>1</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula32-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq32.tif"/>
</disp-formula>If there were no <italic>X</italic>, then the expression would simplify to the estimated variance for <inline-formula id="inline-formula181-0193841X12442673">
<mml:math id="mml-inline181-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula>. Substituting a different <inline-formula id="inline-formula182-0193841X12442673">
<mml:math id="mml-inline182-0193841X12442673">
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula> for <inline-formula id="inline-formula183-0193841X12442673">
<mml:math id="mml-inline183-0193841X12442673">
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> would yield a point estimate and variance that is conditioned on that specified value of <inline-formula id="inline-formula184-0193841X12442673">
<mml:math id="mml-inline184-0193841X12442673">
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>. If a researcher wanted to summarize the average effect size from an extant literature, he or she might use the estimates from <xref ref-type="disp-formula" rid="disp-formula32-0193841X12442673">Equation 32</xref>.</p>
<p>
<xref ref-type="disp-formula" rid="disp-formula32-0193841X12442673">Equation 32</xref> is straightforward but there is a wrinkle. The <inline-formula id="inline-formula185-0193841X12442673">
<mml:math id="mml-inline185-0193841X12442673">
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> is the mean for the population, not the sample. This may be unknown. If it is estimated (perhaps after assuming a random sample of estimated effect sizes), then the estimate of <inline-formula id="inline-formula186-0193841X12442673">
<mml:math id="mml-inline186-0193841X12442673">
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> would have its own measurement error. One might use the delta method to account for that additional variance, so that would add <inline-formula id="inline-formula187-0193841X12442673">
<mml:math id="mml-inline187-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mrow>
<mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> to the variance term is <xref ref-type="disp-formula" rid="disp-formula32-0193841X12442673">Equation 32</xref>.</p>
<p>Consider the second question. The point estimate and its standard error are:<disp-formula id="disp-formula33-0193841X12442673">
<label>33</label>
<mml:math id="mml-disp33-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">E</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">T</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">E</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">T</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mn>1</mml:mn>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">V</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mn>1</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula33-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq33.tif"/>
</disp-formula>If there were no <italic>X</italic>, then the expression would simplify to the estimated variance for <inline-formula id="inline-formula188-0193841X12442673">
<mml:math id="mml-inline188-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> plus <inline-formula id="inline-formula189-0193841X12442673">
<mml:math id="mml-inline189-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. As before, substituting a different <inline-formula id="inline-formula190-0193841X12442673">
<mml:math id="mml-inline190-0193841X12442673">
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula> for <inline-formula id="inline-formula191-0193841X12442673">
<mml:math id="mml-inline191-0193841X12442673">
<mml:mover accent="true">
<mml:mi>X</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> would yield a point estimate and variance that is conditioned on that different value for <inline-formula id="inline-formula192-0193841X12442673">
<mml:math id="mml-inline192-0193841X12442673">
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>. What has happened? The results from the regression again provide the best estimate of the average effect size, but the variance now captures both the uncertainty resulting from imprecision in the estimated regression and the variance in the true effect sizes.</p>
<p>There is a new wrinkle. The <inline-formula id="inline-formula193-0193841X12442673">
<mml:math id="mml-inline193-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is necessarily an estimate. Typically the sampling variance for <inline-formula id="inline-formula194-0193841X12442673">
<mml:math id="mml-inline194-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is large, so the coverage of the confidence interval based on <inline-formula id="inline-formula195-0193841X12442673">
<mml:math id="mml-inline195-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">E</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">T</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> may be misleading. If a researcher sought to generalize the effect to a population, for which the extant literature provides a representative sample, he or she might use the estimates based on <xref ref-type="disp-formula" rid="disp-formula33-0193841X12442673">Equation 33</xref>.</p>
<p>Consider the third question. It makes a prediction about the estimated effect size from a new study. Presumably <italic>X</italic> will be known for the new study (call this <inline-formula id="inline-formula196-0193841X12442673">
<mml:math id="mml-inline196-0193841X12442673">
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>). The point estimate and its standard error are:<disp-formula id="disp-formula34-0193841X12442673">
<label>34</label>
<mml:math id="mml-disp34-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">E</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">T</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">E</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">T</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mn>1</mml:mn>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mi mathvariant="normal">O</mml:mi>
<mml:mi mathvariant="normal">V</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mfenced>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mn>1</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula34-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq34.tif"/>
</disp-formula>The variance for the estimate is even larger than it was for the first two estimates. Furthermore, there is still a new wrinkle: the squared standard error for the new study <inline-formula id="inline-formula197-0193841X12442673">
<mml:math id="mml-inline197-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>N</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is unknown. This is not an insurmountable problem, however. Because the analysts knows <inline-formula id="inline-formula198-0193841X12442673">
<mml:math id="mml-inline198-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula199-0193841X12442673">
<mml:math id="mml-inline199-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> . . . <inline-formula id="inline-formula200-0193841X12442673">
<mml:math id="mml-inline200-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>n</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, there is a basis for estimating <inline-formula id="inline-formula201-0193841X12442673">
<mml:math id="mml-inline201-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>N</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, given knowledge of study design—especially sample size, division of the sample between treated and controls, and perhaps <italic>X</italic>.</p>
<p>The reason for posing and answering the questions from the first two bullets is they address important research questions. The question posed by the third bullet answers no research question, so one might ask: Why bother? A simple response to this question is that the answer is instrumental for power analysis. An analyst designing a new study would want to take into account heterogeneity across effects and heterogeneity within a specific study.</p>
</sec>
<sec id="section33-0193841X12442673">
<title>Closing Observations</title>
<p>The purpose of this article was to apply estimation tools that are familiar to social scientists to estimation problems that arise in meta-analysis. One might even use these tools to perform the meta-analysis, but software that is specialized to performing meta-analysis provides estimators and diagnostics that are tailored for meta-analysis, so application was not the article’s focus. Rather, the author hopes that starting with what is familiar (regression analysis) and applying it to what is less familiar (meta-analysis) will advance understanding of the latter and motivate a deeper reading into meta-analysis.</p>
<p>This article has covered ground familiar to seasoned meta-analysts. It has explained the importance of identifying the population of interest and thinking carefully about how estimated effect sizes are sampled from that population. It has defined modeling concepts (homogeneous and heterogeneous treatment effects) and has expanded the latter to discuss special circumstances (measured and unmeasured heterogeneity; true heterogeneity and artifactual heterogeneity). It has explained basic estimation procedures (fixed-effect and random-effect estimators) and has suggested some expansions of the basic estimator to deal with dependent effects and multiple outcomes.</p>
<p>This article was prepared for researchers who are new to meta-analysis, and yet some seasoned meta-analysts may benefit from reconsidering their statistical analysis. Based on his lengthy and distinguished experience as a program evaluator, the former editor of this journal warned against “junk science,” and he placed meta-analysis into this category (<xref ref-type="bibr" rid="bibr4-0193841X12442673">Berk 2011</xref>). In fact, Berk was not warning that something was wrong with the statistical theory undergirding meta-analysis nor was he criticizing the motivation for performing meta-analysis. His criticism was that even seasoned meta-analysts fail to appreciate, or at least fail to communicate, the limitations of their craft.</p>
<p>Berk’s criticism should be familiar to readers of this article. First, Berk asserted that many meta-analyses conglomerate studies that provide no meaningful average. His example was combining studies of job training and job counseling programs; his complaint was that the average explains nothing about either job training or job counseling because the component parts of that average cannot be disentangled. The criticism applies especially to fields where insufficient research exists to provide comparable studies, so to perform meta-analyses, the researcher selects and combines incomparable studies.</p>
<p>Second, he is concerned that the sample available to the meta-analyst is unrepresentative of the population about which the meta-analyst purports to make inferences. Presumably he has no disagreement with meta-analysts who make inferences about the sample itself, but especially when meta-analysts seek to inform public policy, Berk is concerned that meta-analysis lacks external validity but misleading implies the opposite. This article has discussed the foundation for that concern.</p>
<p>Third, Berk is concerned that in many applications, meta-analysts use poor data. The refrain is familiar to researchers: garbage in/garbage out. If a sample of <italic>n</italic> studies comprises quasi-experiments with serious validity challenges, there is no reason to think that bias will average to zero. This article has suggested that regression procedures can help explain biases that are artifacts of methodology used in the <italic>n</italic> studies, but lacking some anchor with truth (perhaps from a few randomized design studies that provide unbiased estimates of treatment effectiveness), regressions that explain bias cannot by themselves lead to an unbiased estimate of treatment effectiveness. Perhaps overstating his case, Berk concludes that “A conventional literature review will often be better” (2011, 199). The author and most meta-analysts would disagree with this extreme view, but the sentiment motivating that view is understandable.</p>
<p>Finally, in a general comment on evaluation methodology, Berk is concerned that the wide availability of computing software and inexpensive computing hardware has promoted inappropriate and uncritical use of statistical inference. Consistent with this view, for example, meta-analysis is frequently used in environmental and natural resource economics, but the Environmental Protection Agency has expressed skepticism about the quality of those meta-analyses. This skepticism motivated a study by <xref ref-type="bibr" rid="bibr38-0193841X12442673">Nelson and Kennedy (2009)</xref> to assess the quality of 140 meta-analyses covering 17 topic areas in environmental and resource economics. Their findings are sobering.</p>
<list list-type="bullet">
<list-item>
<p>Of the 140 meta-analyses, only 61 provided statements of selection criteria, and many of these were sketchy.</p>
</list-item>
<list-item>
<p>Of the 140 meta-analyses, 46 failed to account for heteroscedasticity, and another 7 used what Nelson and Kennedy deemed an inappropriate approach.</p>
</list-item>
</list>
<p>Of the 140 meta-analyses, 47 applied no adjustments for data dependencies. Of the 140 meta-analyses, 21 ignored both heteroscedasticity and dependencies.</p>
<p>Consistent with Berk’s assertion, <xref ref-type="bibr" rid="bibr38-0193841X12442673">Nelson and Kennedy (2009</xref>, 372) summarize:<disp-quote>
<p>Amongst a “flood of numbers,” the promise of meta-analysis is to provide a life boat that creates order and gives substance to numerous empirical studies, which often present conflicting or wide-ranging estimates . . . the main problem . . . is that the lifeboat can be improperly guided or manned, so as to threaten the success of the enterprise.</p>
</disp-quote>
</p>
<p>Nelson and Kennedy have identified fundamental problems in a large number of meta-analyses, and while their assessment is limited to environmental economics, Berk warns that faulty practice occurs in other disciplines and subject areas.</p>
<p>The purpose of inferential statistical analysis is to make inferences about population parameters—here the average effect size, its confidence interval, and the distribution of true effect sizes in a population of interest. If the meta-analyst fails to provide a description of his or her sampling process, he or she fails to identify the population of interest. This is a fundamental error that is similar to a sampling statistician failing to report a study’s frame and sampling design.</p>
<p>Nelson and Kennedy’s findings that many meta-analyses failed to account for heteroscedasticity is startling. Perhaps, heteroscedasticity is seen as a fine point when estimating regressions. After all, slope parameter estimates are consistent given heteroscedasticity, and modern practice is to estimate the covariance matrix using robust estimators. However, the logic of meta-analysis is to assign greater weight to studies that provide more precise estimates of treatment effects, and failure to take that step seems inexplicable given readily available software. The use of estimating equations and robust covariance estimation alone ignores concerns with efficiency and cannot provide the desired weights.</p>
<p>Dependence among effect sizes is common and pernicious. As before, slope parameters may be estimated consistently, but if the meta-analysis ignores the dependencies, estimates will be inefficient and standard errors can be grossly biased. Nelson and Kennedy’s report that more than one-third of meta-analyses ignored dependence among treatment effects is perplexing. The consequences of failing to deal with clustering are widely appreciate by social statisticians, and remedies are widely available. Why were suitable solutions not applied?</p>
<p>We cannot know for sure, but one speculation is that social science statisticians and econometricians, who understand linear models, have failed to translate that knowledge into meta-analysis. Likely no one would dispute that these social scientists and econometricians should read deeper into the methodology of meta-analysis. Perhaps, this article can serve as a bridge.</p>
<p>According to both Berk and Nelson and Kennedy, meta-analysis is often poorly done. Even when meta-analysis is done well, it has critics and defenders. This article does not review the debate, but it does consider some large challenges. Returning to the discussion of the average effect sizes, deriving unbiased estimates of treatment effectiveness places demands on sampling that are difficult to justify. Publication bias is frequently considered by those performing meta-analysis, but this is not the only way that literature reviews can lead to a sample of studies that are unrepresentative of the population that they purport to represent. Consider practical problems in social science research:</p>
<list list-type="bullet">
<list-item>
<p>Some funding agencies tend to fund program evaluations when programs show promise of being successful. Often this is known as “demonstration of concept.” However well intentioned, this practice leads to a collection of studies that pertain to treatment provided in settings that are atypical.</p>
</list-item>
<list-item>
<p>Rigorous evaluations are difficult to implement. Programs with strong infrastructure that employ evidence-based practices may be most amenable to randomized control trials or they may be selected because they have information systems that are required for cost-effective program evaluation. Such programs are more likely to be evaluated but they may not represent the universe of programs, the majority of which have weak infrastructures and an inability to integrate evidence-based practices into program operations.</p>
</list-item>
<list-item>
<p>Although strong evidence is lacking, the author’s impression is that researchers who report positive treatment effects are more likely to be funded for future grants than are researchers who report no treatment effects. Researchers face pressure to report something positive about the programs that they evaluate. The positive gets highlighted; the negative gets neglected. The reported evidence is shifted to accentuate the positive, which may in fact be the only results published in the professional literature.</p>
</list-item>
</list>
<p>Although some precautionary tests exist (<xref ref-type="bibr" rid="bibr51-0193841X12442673">Sutton 2009</xref>; <xref ref-type="bibr" rid="bibr27-0193841X12442673">Higgins and Altman 2008</xref>; <xref ref-type="bibr" rid="bibr50-0193841X12442673">Sterne, Egger, and Moher 2008</xref>; <xref ref-type="bibr" rid="bibr46-0193841X12442673">Stanley 2005</xref>) that may reduce the problem, it is difficult to see how meta-analysts prevent these biases. The author is sympathetic to the argument (<xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. 2009</xref>) that this bias is just as much of a problem in narrative literature reviews and that thoughtful assembly and analysis of data can mitigate the worst of the problems. Still, even in a world where every program evaluation is based on random assignment, meta-analysis is itself based on techniques that are common to observational studies: sample selection bias will lead to inconsistent parameter estimates.</p>
<p>An honest assessment of meta-analysis as applied to social science problems is that estimates of average effect sizes are likely to be biased. This follows because the samples that enter into the meta-analysis are likely to be biased. Skillful analysts can help mitigate sample selection bias, but it is unlikely that they can altogether overcome the validity challenge. Estimates of confidence intervals are likely to be biased, especially when estimation incorporates a small number of studies into the estimation. This seems unavoidable when estimation rests on asymptotic properties and only a few primary studies exist, and while small-sample adjustments may be helpful, there is no strong basis for asserting that confidence intervals closely approximate reality.</p>
<p>Estimated effect size heterogeneity caused by methodology used in the primary studies further limits interpretations of meta-analyses, but given methodological heterogeneity only a cynic would see limitations but no opportunities. Stand-alone studies are almost always subject to validity challenges that arise from data sources, estimation procedures and model specification. These validity challenges are difficult to detect in individual studies, but meta-analysis provides a means to examine studies as a collective. Within the limitations of sampling variation, a researcher can answer important questions: Does the estimated treatment effect vary with data sources? Is it sensitive to estimation procedures? Does it vary with model specification? This is a practical application of meta-analysis (<xref ref-type="bibr" rid="bibr46-0193841X12442673">Stanley 2005</xref>) that stands to make a significant contribution toward distinguishing fact from fiction and, in general, toward advancing science (<xref ref-type="bibr" rid="bibr35-0193841X12442673">Lipsey 2009</xref>).</p>
<p>Meta-analysis is valuable when applied correctly. That value is enhanced rather than lessened by understanding limitations. Good meta-analysis is better than bad meta-analysis. Thoughtful interpretation of meta-analysis is better than mechanical interpretation. Hopefully, this article has provided researchers with a better understanding of what differentiates good from bad meta-analysis and with the means to substitute thoughtful interpretation of meta-analysis for mechanical interpretation.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0193841X12442673">
<title>Appendix A</title>
<p>This appendix has three sections. The first derives a moment-based estimator for <inline-formula id="inline-formula202-0193841X12442673">
<mml:math id="mml-inline202-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The second derives the standard error and confidence interval for that estimate. The third derives the asymptotic properties of the test statistics <italic>Q</italic>. Throughout this appendix, the statistic <italic>Q</italic> is:<disp-formula id="disp-formula35-0193841X12442673">
<mml:math id="mml-disp35-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:msup>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula35-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq35.tif"/>
</disp-formula>
</p>
<sec id="section35-0193841X12442673">
<title>Unmeasured Heterogeneity<sup>
<xref ref-type="fn" rid="fn14-0193841X12442673">14</xref>
</sup>
</title>
<p>The intention of this section is to derive a moment-based estimator for <inline-formula id="inline-formula203-0193841X12442673">
<mml:math id="mml-inline203-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The derivation converts the statistic <italic>Q</italic> into a quadratic form, takes the expected value of that quadratic form, and estimates <inline-formula id="inline-formula204-0193841X12442673">
<mml:math id="mml-inline204-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> based on the properties of that expectation. For the statistical theory behind this derivation, see <xref ref-type="bibr" rid="bibr44-0193841X12442673">Searle (1982)</xref>. Notation used in this appendix is defined in the main text.</p>
<p>Start with <italic>Q</italic>. As above, it is written as:<disp-formula id="disp-formula36-0193841X12442673">
<label>A1</label>
<mml:math id="mml-disp36-0193841X12442673">
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula36-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq36.tif"/>
</disp-formula>This can be written in the quadratic form as:<disp-formula id="disp-formula37-0193841X12442673">
<label>A2</label>
<mml:math id="mml-disp37-0193841X12442673">
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula37-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq37.tif"/>
</disp-formula>Given that <italic>Q</italic> is expressed in quadratic form, its expectation can be written:<disp-formula id="disp-formula38-0193841X12442673">
<label>A3</label>
<mml:math id="mml-disp38-0193841X12442673">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Q</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi>μ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
<mml:mo>'</mml:mo>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>E</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo> <mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:mi>E</mml:mi>
<mml:mo>'</mml:mo>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mi>I</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>V</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow> <mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula38-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq38.tif"/>
</disp-formula>The term in the first parentheses evaluates to zero. This leaves the trace:<disp-formula id="disp-formula39-0193841X12442673">
<label>A4</label>
<mml:math id="mml-disp39-0193841X12442673">
<mml:mi>E</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>Q</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mi>I</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>V</mml:mi>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula39-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq39.tif"/>
</disp-formula>Evaluating the trace of the first term in parentheses multiplied by <inline-formula id="inline-formula205-0193841X12442673">
<mml:math id="mml-inline205-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mi>I</mml:mi>
</mml:math>
</inline-formula>:<disp-formula id="disp-formula40-0193841X12442673">
<label>A5</label>
<mml:math id="mml-disp40-0193841X12442673">
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula40-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq40.tif"/>
</disp-formula>Evaluating the trace of the first term in parentheses multiplied by <italic>V</italic>:<disp-formula id="disp-formula41-0193841X12442673">
<label>A6</label>
<mml:math id="mml-disp41-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mi>E</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mi>V</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>K</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1.</mml:mn>
</mml:math>
<graphic alternate-form-of="disp-formula41-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq41.tif"/>
</disp-formula>Putting <xref ref-type="disp-formula" rid="disp-formula39-0193841X12442673">Equations A4</xref>, <xref ref-type="disp-formula" rid="disp-formula40-0193841X12442673">A5</xref>, and <xref ref-type="disp-formula" rid="disp-formula41-0193841X12442673">A6</xref> together:<disp-formula id="disp-formula42-0193841X12442673">
<label>A7</label>
<mml:math id="mml-disp42-0193841X12442673">
<mml:mi>E</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>Q</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula42-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq42.tif"/>
</disp-formula>Rearranging:<disp-formula id="disp-formula43-0193841X12442673">
<label>A8</label>
<mml:math id="mml-disp43-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>Q</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula43-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq43.tif"/>
</disp-formula>The actual estimate uses <italic>Q</italic> in place of <italic>E</italic>(<italic>Q</italic>) so:<disp-formula id="disp-formula44-0193841X12442673">
<label>A9</label>
<mml:math id="mml-disp44-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula44-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq44.tif"/>
</disp-formula>Readers can compare <xref ref-type="disp-formula" rid="disp-formula46-0193841X12442673">Equation A9</xref> with equation 12.2 in <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. 2009</xref>. There are some notational differences. Using notation that is conventional in meta-analysis, <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. 2009</xref> use <inline-formula id="inline-formula206-0193841X12442673">
<mml:math id="mml-inline206-0193841X12442673">
<mml:msup>
<mml:mi mathvariant="italic">τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:math>
</inline-formula> instead of <inline-formula id="inline-formula207-0193841X12442673">
<mml:math id="mml-inline207-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula208-0193841X12442673">
<mml:math id="mml-inline208-0193841X12442673">
<mml:msup>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:math>
</inline-formula> instead of <inline-formula id="inline-formula209-0193841X12442673">
<mml:math id="mml-inline209-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. They use <italic>k</italic> instead of <italic>n</italic> to represent the number of studies. They use <italic>W</italic> instead of <italic>w</italic> as the weights. The differences are cosmetic.</p>
</sec>
<sec id="section36-0193841X12442673">
<title>A Sampling Variance for <inline-formula id="inline-formula210-0193841X12442673">
<mml:math id="mml-inline210-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>
</title>
<p>The intention of this section is to derive the sampling variance for <inline-formula id="inline-formula211-0193841X12442673">
<mml:math id="mml-inline211-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. The derivation converts the statistic <italic>Q</italic> into a quadratic form, applies the formula for the variance of a quadratic form, and then applies the delta method to approximate the sampling variance for <inline-formula id="inline-formula212-0193841X12442673">
<mml:math id="mml-inline212-0193841X12442673">
<mml:msubsup>
<mml:mover accent="true">
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>.</p>
<p>
<xref ref-type="disp-formula" rid="disp-formula37-0193841X12442673">Equation A2</xref> represents <italic>Q</italic> in quadratic form. Applying the properties of the quadratic form, the variance of <italic>Q</italic> can be written as:<disp-formula id="disp-formula45-0193841X12442673">
<label>A10</label>
<mml:math id="mml-disp45-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mi>Q</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>4</mml:mn>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi mathvariant="normal">Σ</mml:mi>
<mml:mi mathvariant="normal">Λ</mml:mi>
<mml:mi>E</mml:mi>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula45-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq45.tif"/>
</disp-formula>The algebra is formidable. We solved this expression using Maple and assuming three studies. The general solution is given in <xref ref-type="bibr" rid="bibr8-0193841X12442673">Borenstein et al. (2009</xref>, 122, formula 16.11).</p>
</sec>
<sec id="section37-0193841X12442673">
<title>Distribution of <italic>Q</italic>
</title>
<p>Under the null hypothesis of homogeneous treatment effects, the FGLS regression specification is:<disp-formula id="disp-formula46-0193841X12442673">
<label>A10</label>
<mml:math id="mml-disp46-0193841X12442673">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula46-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq46.tif"/>
</disp-formula>The transformed error term has a distribution that is standard normal because <italic>e<sub>i</sub>
</italic> is drawn from a distribution with mean of zero and standard deviation of <inline-formula id="inline-formula213-0193841X12442673">
<mml:math id="mml-inline213-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. Assuming that <italic>e</italic> is drawn from the normal distribution, the sum of <italic>n</italic> standard normal independent variables is <inline-formula id="inline-formula214-0193841X12442673">
<mml:math id="mml-inline214-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">χ</mml:mi>
<mml:mi>n</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. In fact this sum of squares is not observable and must be estimated as:<disp-formula id="disp-formula47-0193841X12442673">
<label>A10</label>
<mml:math id="mml-disp47-0193841X12442673">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mi>Q</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:msup>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msubsup>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula47-0193841X12442673" xlink:href="10.1177_0193841X12442673-eq47.tif"/>
</disp-formula>
<italic>Q</italic> is distributed as <inline-formula id="inline-formula215-0193841X12442673">
<mml:math id="mml-inline215-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">χ</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> because estimating <inline-formula id="inline-formula216-0193841X12442673">
<mml:math id="mml-inline216-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:math>
</inline-formula> costs one degree of freedom.</p>
</sec>
</app>
</app-group>
<fn-group>
<fn fn-type="conflict" id="fn15-0193841X12442673">
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn16-0193841X12442673">
<p>The author disclosed receipt of the following financial support for the research, authorship and/or publication of this article: The author appreciates comments from anonymous reviewers and from members of the Journal Authors Support Group at Abt Associates Inc.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0193841X12442673">
<label>1.</label>
<p>With this assumption, the argument can assume that the error terms are independent across the <italic>n</italic> observations that enter into the analysis. The assumption is violated in many meta-analyses, but dependence can be accommodated (<xref ref-type="bibr" rid="bibr24-0193841X12442673">Hedges 2009</xref>; <xref ref-type="bibr" rid="bibr26-0193841X12442673">Hedges, Tipton, and Johnson 2010</xref>), and this article will briefly consider estimation where observations are dependent. This article ignores problems that arise when one of more of the studies are based on nested or hierarchical designs. These raise issued of computational complexity and interpretation (<xref ref-type="bibr" rid="bibr24-0193841X12442673">Hedges 2009</xref>) that are best ignored in an introduction to the subject.</p>
</fn>
<fn fn-type="other" id="fn2-0193841X12442673">
<label>2.</label>
<p>Meta-analysts often deal with outcomes that have been measured in different units across studies. This is almost certainly the case when different analysts use different scales to study the effectiveness of an intervention. As a result, the effect sizes reported across <italic>n</italic> studies are also measured in different scales, and they must be converted to a common metric before deriving an average effect size. Procedures for standardizing effects are well known (<xref ref-type="bibr" rid="bibr9-0193841X12442673">Borenstein et al. 2012</xref>).</p>
</fn>
<fn fn-type="other" id="fn3-0193841X12442673">
<label>3.</label>
<p>Meta-analysts often use regression to adjust for estimated treatment effects that may be biased because they are based on quasi-experiments rather than random assignment (<xref ref-type="bibr" rid="bibr46-0193841X12442673">Stanley 2005</xref>). To avoid dealing with this issue until later, assume that the estimated treatment effects are unbiased estimates of the true underlying treatment effects.</p>
</fn>
<fn fn-type="other" id="fn4-0193841X12442673">
<label>4.</label>
<p>As examples of different uses of the same terms, some authorities prefer the terms singular effects and plural effects to homogeneous effects and heterogeneous effects (<xref ref-type="bibr" rid="bibr57-0193841X12442673">Borenstein et al. 2010</xref>). Others use the terms homogeneous and heterogeneous but prefer the terms unexplainable heterogeneity and explainable heterogeneity to measured heterogeneity and unmeasured heterogeneity (<xref ref-type="bibr" rid="bibr38-0193841X12442673">Nelson and Kennedy 2009</xref>).</p>
</fn>
<fn fn-type="other" id="fn5-0193841X12442673">
<label>5.</label>
<p>Sometimes the argument is advanced that assuming homogenous effects is suitable even when effects are heterogeneous when the meta-analyst wants to estimate the effect for the sample and not generalize outside that sample. However, when that argument is advanced, typically the recommendation is to use weights that assume that the effect is homogenous (even when it is not), and this is questionable advice.</p>
</fn>
<fn fn-type="other" id="fn6-0193841X12442673">
<label>6.</label>
<p>The difference is difficult to grasp without some additional understanding of the estimators. The basic formulas for estimating Model 1 and Model 3 assume that <inline-formula id="inline-formula217-0193841X12442673">
<mml:math id="mml-inline217-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> is known, so the errors about the regression line are homoscedastic with mean of zero and variance of 1. Given this assumption, there is no need to estimate the variance about the regression, and the standard error for estimated treatment effect is a direct calculation using the assumed value of <inline-formula id="inline-formula218-0193841X12442673">
<mml:math id="mml-inline218-0193841X12442673">
<mml:msub>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>. The Stata software provides an illustration (<xref ref-type="bibr" rid="bibr10-0193841X12442673">Bradburn, Deeks, and Altman 2009</xref>, 25).</p>
</fn>
<fn fn-type="other" id="fn7-0193841X12442673">
<label>7.</label>
<p>If the analyst were willing to assume that <italic>u</italic> was drawn from a normal distribution (an assumption that is often maintained in meta-analysis) and that <italic>X</italic> is non-stochastic (a more questionable assumption in social science research, but possible), then the regression has known small-sample properties.</p>
</fn>
<fn fn-type="other" id="fn8-0193841X12442673">
<label>8.</label>
<p>There is a simple way to see that this result is correct. Let <inline-formula id="inline-formula219-0193841X12442673">
<mml:math id="mml-inline219-0193841X12442673">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
<mml:mi mathvariant="italic">ω</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> be the weighted mean for the <italic>n</italic> estimated effect sizes where ω<italic>
<sub>i</sub>
</italic> is some unspecified weight constrained so that all the weights are nonnegative and sum to one. The variance for this weighted mean is <inline-formula id="inline-formula220-0193841X12442673">
<mml:math id="mml-inline220-0193841X12442673">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">V</mml:mi>
<mml:mi mathvariant="normal">A</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˉ</mml:mo>
</mml:mover>
<mml:mi mathvariant="italic">ω</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. The problem is to minimize this variance subject to the constraint that <inline-formula id="inline-formula221-0193841X12442673">
<mml:math id="mml-inline221-0193841X12442673">
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula>. Using a Lagrange multiplier to impose the constraint, minimize <inline-formula id="inline-formula222-0193841X12442673">
<mml:math id="mml-inline222-0193841X12442673">
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi mathvariant="italic">λ</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula> with respect to the ω. Differentiating with respect to the <italic>n</italic> ω and λ and setting the <italic>n</italic> + 1 equations to zero yields a solution such that <inline-formula id="inline-formula223-0193841X12442673">
<mml:math id="mml-inline223-0193841X12442673">
<mml:mstyle displaystyle="true" scriptlevel="0">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mstyle>
</mml:math>
</inline-formula> for the <italic>j</italic>th and <italic>k</italic>th weight. The weights that minimize the variance for the weighted mean are the reciprocals of the squared standard error.</p>
</fn>
<fn fn-type="other" id="fn9-0193841X12442673">
<label>9.</label>
<p>In fact, the maximum likelihood solution is biased but consistent. In practice, an analyst would introduce adjustments that depend on the number of parameters entering the model.</p>
</fn>
<fn fn-type="other" id="fn10-0193841X12442673">
<label>10.</label>
<p>Many textbooks and paper shows the formulas that appear in this section but do not show the derivation for those formulas. This is even true of the seminal paper (<xref ref-type="bibr" rid="bibr16-0193841X12442673">DerSimonian and Laird 1986</xref>). The author presumes that some readers would appreciate a derivation.</p>
</fn>
<fn fn-type="other" id="fn11-0193841X12442673">
<label>11.</label>
<p>We will amend this statement later. Sometimes meta-analysts use analysis of variance when <italic>X</italic> identifies categories: men and women, for example. Then one might assume that <inline-formula id="inline-formula224-0193841X12442673">
<mml:math id="mml-inline224-0193841X12442673">
<mml:msubsup>
<mml:mi mathvariant="italic">σ</mml:mi>
<mml:mi>u</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> varies across groups and derive separate group-specific estimates. When <italic>X</italic> is continuous, one might estimate a scedastic function and use this in the analysis.</p>
</fn>
<fn fn-type="other" id="fn12-0193841X12442673">
<label>12.</label>
<p>In meta-analysis, multiple outcomes is often called multiple endpoints (<xref ref-type="bibr" rid="bibr19-0193841X12442673">Gleser and Olkin 2009</xref>). For a general discussion, see <xref ref-type="bibr" rid="bibr3-0193841X12442673">Bender et al. (2008)</xref>.</p>
</fn>
<fn fn-type="other" id="fn13-0193841X12442673">
<label>13.</label>
<p>The matrix <inline-formula id="inline-formula225-0193841X12442673">
<mml:math id="mml-inline225-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
</mml:math>
</inline-formula> has a checkerboard appearance. The checkerboard has <italic>J</italic>
<sup>2</sup> squares where <italic>J</italic> is the number of outcomes. Assuming that each of the studies reports estimates for all the outcomes, each of the squares is an <italic>n</italic> × <italic>n</italic> diagonal matrix comprising variance and covariance terms. <inline-formula id="inline-formula226-0193841X12442673">
<mml:math id="mml-inline226-0193841X12442673">
<mml:mi mathvariant="normal">Ω</mml:mi>
</mml:math>
</inline-formula> is best represented as a Kronecker product and it is unnecessary that each study reports all outcomes. Interested readers might consult <xref ref-type="bibr" rid="bibr20-0193841X12442673">Greene (2008</xref>, 256).</p>
</fn>
<fn fn-type="other" id="fn14-0193841X12442673">
<label>14.</label>
<p>The author is indebted to Steven Kennedy, Chief Scientist at Abt Associates Inc., for help with this derivation.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr2-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Baltagi</surname>
<given-names>B</given-names>
</name>
</person-group>. <year>2005</year>. <source>Econometric Analysis of Panel Data</source>, <edition>3rd ed</edition>. <publisher-name>West Sussex, United Kingdom: John Wiley &amp; Sons</publisher-name>.</citation>
</ref>
<ref id="bibr3-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bender</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Bunce</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Clark</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Gates</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Lange</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Pace</surname>
<given-names>N.</given-names>
</name>
<etal/>
</person-group>. (<year>2008</year>). <article-title>“Attention Should Be Given to the Multipicity Issues in Systematic Reviews.”</article-title> <source>Journal of Clinical Epidemiology</source> <volume>61</volume>:<fpage>857</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr4-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Berk</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>2011</year>. <article-title>“Evidence-Based Versus Junk-Based Evaluation Research: Some Lessons Learned from 35 Years of the Evaluation Review.”</article-title> <source>Evaluation Review</source> <volume>35</volume>:<fpage>191</fpage>–<lpage>203</lpage>.</citation>
</ref>
<ref id="bibr6-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Borenstein</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Effect Sizes for Continuous Data.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedge</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd ed</edition>., <fpage>221</fpage>–<lpage>35</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr8-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Borenstein</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rothstein</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>2009</year>. <source>Introduction to Meta-Analysis</source>. <publisher-loc>West Sussex, United Kingdom</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>.</citation>
</ref>
<ref id="bibr57-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Borenstein</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Higgiens</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rothstein</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>2010</year>. <article-title>“A Basic Introduction to Fixed-Effect and Random-Effects Models for Meta-Analysis.”</article-title> <source>Research Synthesis Methods</source> <volume>1</volume>:<fpage>97</fpage>–<lpage>111</lpage>.</citation>
</ref>
<ref id="bibr9-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Borenstein</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rothstein</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>2012</year>. <source>Computing Effect Sizes for Meta-Analysis</source>. <publisher-loc>Chichester, United Kingdom</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>.</citation>
</ref>
<ref id="bibr10-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bradburn</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Deeks</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Altman</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Metan—A Command for Meta-Analysis in Stata.”</article-title> In <source>Meta-Analysis in Stata: An Updated Collection from the Stata Journal</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Sterne</surname>
<given-names>J.</given-names>
</name>
</person-group>, <fpage>3</fpage>–<lpage>28</lpage>. <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>Stata Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr11-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cameron</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Trivedi</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2005</year>. <source>Microeconometrics: Methods and Applications</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr12-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cameron</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Trivedi</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2009</year>. <source>Microeconometrics using Stata</source>. <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>Stata Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Hypotheses and Problems in Research Systhesis.”</article-title> In <source>The Handbook of Research Sysnthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>19</fpage>–<lpage>36</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russel Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr14-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <source>The Handbook of Research Synthesis and Meta-Analysis</source>, <edition>2nd edn</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr15-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Davidson</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>MacKinnon</surname>
<given-names>J. G.</given-names>
</name>
</person-group> <year>1993</year>. <source>Estimation and Inference in Econometrics</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr16-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>DerSimonian</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Laird</surname>
<given-names>N.</given-names>
</name>
</person-group> <year>1986</year>. <article-title>“Meta-Analysis in Clinical Trials.”</article-title> <source>Controlled Clinical Trials</source> <volume>7</volume>:<fpage>177</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr17-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Fleiss</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Berlin</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Effect Sizes for Dichotomous Data.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>237</fpage>–<lpage>53</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr18-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gelman</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2007</year>. <source>Data Analysis: Using Regression and Multilevel/Hierarchical Models</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr19-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gleser</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Olkin</surname>
<given-names>I.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Stochastically Dependent Effect Sizes.”</article-title> In <source>The Handbook of Research Sythesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>358</fpage>–<lpage>76</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr20-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Greene</surname>
<given-names>W.</given-names>
</name>
</person-group> <year>2008</year>. <source>Econometric Analysis</source>, <edition>6th edn</edition>. <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation>
</ref>
<ref id="bibr21-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Harbord</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Meta-Regression in Stata.”</article-title> In <source>Meta-Analysis in Stata: An Updated Collection from the Stata Journal</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Sterne</surname>
<given-names>J.</given-names>
</name>
</person-group>, <fpage>70</fpage>–<lpage>96</lpage>. <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>StataCorp</publisher-name>.</citation>
</ref>
<ref id="bibr24-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Effect Sizes in Nested Designs.”</article-title> In <source>The Handbook of Research Systhesis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>337</fpage>–<lpage>55</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr25-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Statistical Considerations.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>37</fpage>–<lpage>47</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr26-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Tipton</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2010</year>. <article-title>“Robust Variance Estimation in Meta-Regression with Dependent Effect Size Estimates.”</article-title> <source>Research Synthesis Methods</source> <volume>1</volume>:<fpage>39</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr27-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Altman</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Assessing Risk of Bias in Included Studies.”</article-title> In <source>Cochrane Handbook for Systematic Reviews of Interventions</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>S.</given-names>
</name>
</person-group>, <fpage>187</fpage>–<lpage>241</lpage>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley-Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr28-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>2009</year>. <source>Cochrane Handbook for Systematic Reviews of Interventions</source>. <publisher-loc>West Sussex, England</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>.</citation>
</ref>
<ref id="bibr29-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Scholten</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Maintaining Reviews: Updates, Amendments and Feedback.”</article-title> In <source>Cochrane Handbook for Systematic Reviews of Interventions</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>S.</given-names>
</name>
</person-group>, <fpage>31</fpage>–<lpage>49</lpage>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley-Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr30-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Thompson</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Spiegelhalter</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“A Re-Evaluation of Random Effects Meta-Analysis.”</article-title> <source>Journal of the Royal Statistical Society</source> <volume>172</volume>:<fpage>137</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr31-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hill</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Bloom</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Black</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Lipsey</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Empirical Benchmarks for Interpreting Effect Sizes in Research.”</article-title> <source>Child Development Perspectives</source> <volume>2</volume>:<fpage>172</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr32-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Imbens</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Wooldridge</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Recent Developments in the Econometrics of Program Evaluation.”</article-title> <source>Journal of Economic Literature</source> <volume>47</volume>:<fpage>5</fpage>–<lpage>86</lpage>.</citation>
</ref>
<ref id="bibr33-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kish</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>1995</year>. <source>Survey Sampling</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>.</citation>
</ref>
<ref id="bibr34-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Konstantopoulos</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L. V.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Analyzing Effect Sizes: Fixed-Effects Models.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L. V.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>279</fpage>–<lpage>315</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr35-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lipsey</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Identifying Interesting Variables and Analysis Opportunities.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L. V.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>147</fpage>–<lpage>58</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr36-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Matt</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Cook</surname>
<given-names>T.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Threats to the Validity of Generalized Inferences.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L. V.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>537</fpage>–<lpage>59</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr38-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nelson</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Kennedy</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“The Use (and Abuse) of Meta-Analysis in Environmental and Natural Resource Economics: An Assessment.”</article-title> <source>Environmental Resource Economics</source> <volume>42</volume>:<fpage>345</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr39-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Orwin</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Vevea</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Evaluating Coding Decisions.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis, 2nd Edition</source> (pp. <fpage>177</fpage>–<lpage>203</lpage>). <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr40-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Raudenbush</surname>
<given-names>S. W.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>Analyzing Effect Sizes: Random-Effects Models</article-title>. In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L. V.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>295</fpage>–<lpage>333</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr41-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Roberts</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Stanley</surname>
<given-names>T.</given-names>
</name>
</person-group> <year>2005</year>. <source>Meta-Regression Analysis: Issues of Publication Bias in Economics</source>. <publisher-loc>Malden, MA</publisher-loc>: <publisher-name>Blackwell Publishing</publisher-name>.</citation>
</ref>
<ref id="bibr42-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rosenbaum</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2002</year>. <source>Observational Studies</source>, <edition>2nd edn</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr43-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schochet</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“An Approach for Addressing the Mutiple Testing Problem in Social Policy Evaluations.”</article-title> <source>Evaluation Review</source> <volume>33</volume>:<fpage>539</fpage>–<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr44-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Searle</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>1982</year>. <source>Matrix Algebra Useful for Statistics</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>.</citation>
</ref>
<ref id="bibr45-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Shadish</surname>
<given-names>W. R.</given-names>
</name>
<name>
<surname>Haddock</surname>
<given-names>C. K.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Combining Estimates of Effect Size.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L. V.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, pp. <fpage>257</fpage>–<lpage>93</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr46-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Stanley</surname>
<given-names>T.</given-names>
</name>
</person-group> <year>2005</year>. <article-title>“Beyond Publication Bias.”</article-title> In <source>Meta-Regression Analysis: Issues of Publication Bias in Economics</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Roberts</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Stanley</surname>
<given-names>T.</given-names>
</name>
</person-group>, <fpage>15</fpage>–<lpage>52</lpage>. <publisher-loc>Malden, MA</publisher-loc>: <publisher-name>Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr47-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Stanley</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Jarrell</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>2005</year>. <article-title>“Meta-Regression Analysis: A Quantitiative Analysis of Literature Surveys.”</article-title> In <source>Meta-Regression Analysis: Issues of Publication Bias in Economics</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Roberts</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Stanley</surname>
<given-names>T.</given-names>
</name>
</person-group>, <fpage>5</fpage>–<lpage>14</lpage>. <publisher-loc>Malden, MA</publisher-loc>: <publisher-name>Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr49-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sterne</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <source>Meta-Analysis in Stata: An Updated Collection from the Stata Journal</source>. <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>StataCorp</publisher-name>.</citation>
</ref>
<ref id="bibr50-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sterne</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Egger</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Moher</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Addressing Reporting Bias.”</article-title> In <source>Cochrane Handbook for Systematic Reviews of Interventions</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Higgins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>S.</given-names>
</name>
</person-group>, <fpage>297</fpage>–<lpage>333</lpage>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley-Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr51-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sutton</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Publication Bias.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedge</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn.</edition>, <fpage>435</fpage>–<lpage>52</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage</publisher-name>.</citation>
</ref>
<ref id="bibr52-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Judging the Quality of Primary Research.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentne</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn</edition>., <fpage>129</fpage>–<lpage>46</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr53-0193841X12442673">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>White</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>1980</year>. <article-title>“Heteroscedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroscedasticity.”</article-title> <source>Econometrica</source> <volume>48</volume>:<fpage>817</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr54-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>White</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Scientific Communications and Literature Reviews.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J.</given-names>
</name>
</person-group>, <edition>2nd edn</edition>., <fpage>51</fpage>–<lpage>72</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr56-0193841X12442673">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wilson</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Systematic Coding.”</article-title> In <source>The Handbook of Research Synthesis and Meta-Analysis</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Cooper</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Hedges</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Valentine</surname>
<given-names>J. C.</given-names>
</name>
</person-group>, <edition>2nd edn</edition>., <fpage>159</fpage>–<lpage>76</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>