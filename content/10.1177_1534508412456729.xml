<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AEI</journal-id>
<journal-id journal-id-type="hwp">spaei</journal-id>
<journal-title>Assessment for Effective Intervention</journal-title>
<issn pub-type="ppub">1534-5084</issn>
<issn pub-type="epub">1938-7458</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1534508412456729</article-id>
<article-id pub-id-type="publisher-id">10.1177_1534508412456729</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Measurement Properties of DIBELS Oral Reading Fluency in Grade 2</article-title>
<subtitle>Implications for Equating Studies</subtitle>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Petscher</surname><given-names>Yaacov</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Cummings</surname><given-names>Kelli D.</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Biancarosa</surname><given-names>Gina</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Fien</surname><given-names>Hank</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Stoolmiller</surname><given-names>Michael</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508412456729">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Biancarosa</surname><given-names>Gina</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508412456729">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Fien</surname><given-names>Hank</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508412456729">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1534508412456729"><label>1</label>University of Oregon, Eugene, OR, USA</aff>
<author-notes>
<corresp id="corresp1-1534508412456729">Michael Stoolmiller, College of Education, Center on Teaching and Learning, 5292 University of Oregon, Eugene, OR 97403-5292, USA Email: <email>stoolmil@uoregon.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>38</volume>
<issue>2</issue>
<issue-title>Special Series: Measurement Issues in the Assessment of Reading Fluency</issue-title>
<fpage>76</fpage>
<lpage>90</lpage>
<permissions>
<copyright-statement>© 2013 Hammill Institute on Disabilities</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="society">Hammill Institute on Disabilities</copyright-holder>
</permissions>
<abstract>
<p>Lack of psychometric equivalence of oral reading fluency (ORF) passages used within a grade for screening and progress monitoring has recently become an issue with calls for the use of equating methods to ensure equivalence. To investigate the nature of the nonequivalence and to guide the choice of equating method to correct for nonequivalence, the authors fit linear and nonlinear confirmatory factor analytic measurement models to Dynamic Indicators of Basic Early Literacy Skills (DIBELS) second-grade ORF passages routinely used for spring testing. They found evidence of nonlinear relations among passage scores that indicated equipercentile equating would be the best choice of equating method compared with mean or linear equating. The standard error of equating (SEE) with a sample of 600 participants was acceptable and less then two correct words per minute for equated scores from 0 to 150, which covers 95% and the useful range of scores. Consistent with the small SEE, the equating table also successfully removed all form differences in an independent sample of second graders. Given the widespread adoption of DIBELS in thousands of schools serving millions of students, equating all passages within a grade would substantially improve the quality of the tool and dramatically lower the assessment burden on school personnel.</p>
</abstract>
<kwd-group>
<kwd>reading/literacy</kwd>
<kwd>test construction</kwd>
<kwd>curriculum-based measurement</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>For learning to read in Grades K-3, regular screening of students for reading problems and monitoring student progress has proven to be useful for improving reading outcomes (<xref ref-type="bibr" rid="bibr31-1534508412456729">Stecker, Fuchs, &amp; Fuchs, 2005</xref>). As a result, an increasing number of screening and progress-monitoring tools are available to schools. In this work, we focus on one such tool, the <italic>Dynamic Indicators of Basic Early Literacy Skills</italic> (DIBELS) system (<xref ref-type="bibr" rid="bibr15-1534508412456729">Good &amp; Kaminski, 2002</xref>), a widely used progress-monitoring system, and in particular, we focus on the psychometric properties of oral reading fluency (ORF), which is commonly used for screening and progress-monitoring purposes from the winter of Grade 1 onward.</p>
<p>As one of the older curriculum-based measurement (CBM) systems available, DIBELS has been widely adopted and its psychometric properties are widely studied. Over the last decade, however, several studies have called into question the once lauded reliability and validity of ORF measures produced by CBM systems like DIBELS (e.g., <xref ref-type="bibr" rid="bibr2-1534508412456729">Ardoin, Williams, Christ, Klubnik, &amp; Wellborn, 2010</xref>; <xref ref-type="bibr" rid="bibr9-1534508412456729">Christ &amp; Ardoin, 2009</xref>; <xref ref-type="bibr" rid="bibr10-1534508412456729">Christ &amp; Silberglitt, 2007</xref>; <xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>; <xref ref-type="bibr" rid="bibr24-1534508412456729">Poncy, Skinner, &amp; Axtell, 2005</xref>). Prominent among these critiques is the issue of passage effects or the nonequivalence of passage difficulty despite the careful use of readability formulas and standardized administration of measures. Some have suggested that psychometric equating of passages is needed to remedy the problem (e.g., <xref ref-type="bibr" rid="bibr2-1534508412456729">Ardoin et al., 2010</xref>; <xref ref-type="bibr" rid="bibr9-1534508412456729">Christ &amp; Ardoin, 2009</xref>; <xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>; <xref ref-type="bibr" rid="bibr24-1534508412456729">Poncy et al., 2005</xref>). The present study extends these studies by examining linear and curvilinear measurement (confirmatory factor) models for ORF that are useful for studying passage equivalence as well as other measurement issues with a large sample of second-grade students. In addition, the measurement models are used to inform the choice of equating methods, and the effectiveness of the different equating methods is compared.</p>
<sec id="section1-1534508412456729">
<title>Dibels ORF</title>
<p>The DIBELS ORF assessment is a 1-min timed measure with 1 point being earned for each word correctly read out loud to the examiner. DIBELS recommends that ORF be assessed in the winter and spring of first grade and then three times per year, fall, winter, and spring, for Grades 2 through 5. These assessments for the entire student body are referred to as benchmark assessments. In the DIBELS system, a student reads three passages and the middle score is taken as the indicator of the student’s current level of reading proficiency. DIBELS recommends more frequent progress monitoring, up to once per week for students who do not reach established criteria (i.e., benchmarks) at any of the three assessments during the year. More frequent progress monitoring, however, is typically done using a single passage at each assessment.</p>
<p>DIBELS ORF is one of the most studied DIBELS assessments and one of the most studied ORF assessments, and as a result reliability and validity correlations for it have been produced from a number of sources, not limited to the test’s creators. The alternate form reliability of DIBELS ORF is very good; the average correlation among the three passage scores at a benchmark assessment is usually between .90 and .95 (<xref ref-type="bibr" rid="bibr5-1534508412456729">Baker et al., 2008</xref>; <xref ref-type="bibr" rid="bibr7-1534508412456729">Biancarosa, Bryk, &amp; Dexter, 2010</xref>; <xref ref-type="bibr" rid="bibr11-1534508412456729">Dynamic Measurement Group, 2008</xref>; <xref ref-type="bibr" rid="bibr25-1534508412456729">Roberts, Good, &amp; Corcoran, 2005</xref>). The validity of DIBELS ORF is also very good, the typical concurrent correlation in Grades 1 through 3 is about .60 to .85 with norm-referenced tests of reading achievement (<xref ref-type="bibr" rid="bibr5-1534508412456729">Baker et al., 2008</xref>; <xref ref-type="bibr" rid="bibr7-1534508412456729">Biancarosa et al., 2010</xref>; <xref ref-type="bibr" rid="bibr25-1534508412456729">Roberts et al., 2005</xref>; <xref ref-type="bibr" rid="bibr26-1534508412456729">Roehrig, Petscher, Nettles, Hudson, &amp; Torgesen, 2008</xref>; <xref ref-type="bibr" rid="bibr29-1534508412456729">Schilling, Carlisle, Scott, &amp; Zeng, 2007</xref>) and the typical predictive correlation with end-of-year comprehensive tests of reading proficiency is about .60 to .75 (<xref ref-type="bibr" rid="bibr5-1534508412456729">Baker et al., 2008</xref>; <xref ref-type="bibr" rid="bibr26-1534508412456729">Roehrig et al., 2008</xref>; <xref ref-type="bibr" rid="bibr29-1534508412456729">Schilling et al., 2007</xref>). DIBELS is clearly a sound measurement system but it is just a measurement system. The implication, however, of using a measurement system like DIBELS is that if a student, class, or entire school is performing below benchmark cut-points or not making adequate progress as indicated by ORF assessments, school personnel will make changes in reading instruction to remedy the situation.</p>
</sec>
<sec id="section2-1534508412456729">
<title>Passage Nonequivalence</title>
<p>Evidence has started to emerge, however, that despite the best efforts of developers of these screening and progress-monitoring tools such as DIBELS, and despite the high reliability and validity correlations, passages used within a grade level for assessing ORF frequently show significant and substantial differences in terms of their difficulty level (<xref ref-type="bibr" rid="bibr2-1534508412456729">Ardoin et al., 2010</xref>; <xref ref-type="bibr" rid="bibr9-1534508412456729">Christ &amp; Ardoin, 2009</xref>; <xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>; <xref ref-type="bibr" rid="bibr24-1534508412456729">Poncy et al., 2005</xref>). This means that a student might appear to be reading significantly and meaningfully faster or slower 1 week but in reality, it was only because the passage difficulty used that week was lower or higher than previous passages. This volatility is an undesirable measurement property and reduces the instructional utility of ORF measures. Ideally, all the passages for use in a particular grade would be equivalent in terms of difficulty and other important measurement properties so that regardless of which passage was administered at any point in the year, the score would be a highly accurate representation of the student’s current reading level.</p>
<p>The likely culprit for nonequivalence is the reliance by developers solely on readability formulas to create ORF passages for a particular grade level. The extant literature indicates that although readability formulas provide a useful tool for developing candidate passages, they are not capable of creating psychometrically equivalent passages (<xref ref-type="bibr" rid="bibr1-1534508412456729">Ardoin, Suldo, Witt, Aldrich, &amp; McDonald, 2005</xref>; <xref ref-type="bibr" rid="bibr6-1534508412456729">Betts, Pickart, &amp; Heistad, 2009</xref>; <xref ref-type="bibr" rid="bibr24-1534508412456729">Poncy et al., 2005</xref>), nor for explaining differences in student performance between passages (<xref ref-type="bibr" rid="bibr2-1534508412456729">Ardoin et al., 2010</xref>).</p>
<p>The nonequivalence of passages substantially increases the workload of teachers and school personnel tasked with administering DIBELS ORF. Three times per year, three passages must be given to each child to obtain a single score. Likewise, the nonequivalence of passages also increases the workload for more frequent progress monitoring because it requires administering enough passages so that trends across time emerge that are large enough to overcome random measurement errors, which are due in part to passage nonequivalence (<xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>). The extra time and effort involved becomes tremendous at the national level because of the widespread adoption of DIBELS and CBM oral fluency assessments like DIBELS in thousands of schools across the country serving millions of students. If the passages were all equivalent, only a single passage would be necessary during benchmark testing and progress monitoring would not need to be as frequent.</p>
<p>One traditional way to deal with differences in difficulty, scaling, or both in alternative test forms that are carefully designed to measure the same underlying construct is to use statistical equating techniques (<xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen &amp; Brennan, 2004</xref>). In fact, several studies (<xref ref-type="bibr" rid="bibr6-1534508412456729">Betts et al., 2009</xref>; <xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>) have used equating techniques in attempts to make ORF passages more equivalent. However, only one study has specifically focused on DIBELS ORF (<xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>), and the sample was small, consisting of 134 second-grade students in only two schools. Despite the small sample, this study found considerable form effects for the estimation of ORF with dramatic implications for conclusions drawn from progress-monitoring data, and further found that equating helped to minimize those effects. The present study extends this earlier work by using the largest equating sample to date for DIBELS ORF.</p>
</sec>
<sec id="section3-1534508412456729">
<title>Evaluating Equating Approaches</title>
<p>Three important steps in equating are (a) deciding what type of equating is necessary to create equivalent passages; (b) given a choice of equating method, what type of equating design is feasible; and (c) given a choice of method and design, what sample size is required to ensure that there is a net gain in equivalence after equating (<xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen &amp; Brennan, 2004</xref>). We focus on issues related to Steps 1 and 3 because as we describe later the equating design was fixed in the present study.</p>
<p>Of all the different types of equating that have been developed, we focus on three different types that are likely to be of the most practical value for equating ORF passages, mean, linear, and equipercentile, which are listed in order of increasing complexity and power. These three types of equating focus on observed test scores, do not rely on any underlying measurement model or assumptions about latent true scores and hence have the virtue of simplicity, which has traditionally been prized by developers of CBM. Mean equating is suitable when the alternate passage score distributions differ only in mean level. Linear equating is suitable when passage score distributions differ only in mean level and variance. Equipercentile equating is the most general approach and corrects for any kind of difference between distributions.</p>
<p>Ideally, equating would be carried out on the whole population but this is almost never feasible and instead, a representative sample must be recruited. The standard error of equating (SEE) is an index of the amount of random noise created by working with a representative sample rather than the whole population (<xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen &amp; Brennan, 2004</xref>). Thus, equating contributes to random noise in the test scores but if done carefully, it eliminates more noise than it creates and the alternative test forms are thereby rendered more equivalent. None of the existing studies that have equated ORF passages reported any information on the SEE. Our work extends the existing literature by providing detailed information about the SEE.</p>
<p>Because the three equating methods, mean, linear, and equipercentile, are successively more complex, they require successively larger samples to keep the SEE at a given, acceptable level (<xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen &amp; Brennan, 2004</xref>). The increase in required sample size can be dramatic, which is why it would be unwise to just use equipercentile equating under the assumption that as it is the most powerful and general method, it will handle whatever form of nonequivalence happens to exist. Unless large samples are easily available, the SEE for equipercentile equating may be unacceptable. Although the three observed score equating methods do not depend on latent variable measurement models, fitting such models before equating can be a valuable exercise to find the most parsimonious measurement model that still has an acceptable fit (<xref ref-type="bibr" rid="bibr6-1534508412456729">Betts et al., 2009</xref>; <xref ref-type="bibr" rid="bibr21-1534508412456729">Moses, 2008</xref>). It could make a substantial difference in the time and effort required to mount an equating study if, for example, a measurement model that supported the use of mean equating was adequate as compared with a more complex measurement model that supported the use of equipercentile equating.</p>
<p>To our knowledge, only <xref ref-type="bibr" rid="bibr6-1534508412456729">Betts et al. (2009)</xref> have followed a similar approach, and our work here extends their results in several important ways. First, we focus specifically on DIBELS ORF. Second, our work is based on a primary sample of just over 600 students. No other measurement study of DIBELS ORF that we are aware of is based on a large sample, and the Betts et al. study seems to be the only other equating study of any ORF measures based on a large sample. Finally, we fit measurement models that allow for nonlinear relations between latent true scores and passages, which is an undesirable measurement property that has implications for equating methods, which to our knowledge has not been previously done with any ORF measure.</p>
<p>We will focus on measurement models, as illustrated in <xref ref-type="fig" rid="fig1-1534508412456729">Figure 1</xref>, that fit to the three passages used for benchmark testing in second grade. Ideally a “strict parallel reliability” model that constrains all factor loadings to 1, forces all passage-specific intercepts to 0 and all passage-specific error variances to be equal, would fit well indicating that the passages are equivalent and that no equating is necessary. Such a model implies that the passages all have the same mean and standard deviation and are all intercorrelated at the same magnitude. <xref ref-type="fig" rid="fig1-1534508412456729">Figure 1</xref> shows the parameter constraints necessary to fit the strict parallel reliability model. If, however, the measurement models indicate that the alternative passages differ only in their means (i.e., the specific intercepts are not all 0), then the simplest of the equating methods, mean equating, can be used. However, if the measurement models indicate that there are scaling differences among the passages (i.e., that the factor loadings are not all 1), then the more complex approach of linear equating would be required to ensure equivalence. Finally, if the measurement models indicate that the passages have nonlinear relations (i.e., load on a latent quadratic factor as illustrated in <xref ref-type="fig" rid="fig2-1534508412456729">Figure 2</xref>), then equipercentile equating would be the best choice to ensure equivalence.</p>
<fig id="fig1-1534508412456729" position="float">
<label>Figure 1.</label>
<caption>
<p>Path diagram for linear CFA measurement model for three ORF passages showing measurement equations.</p>
<p><italic>Note</italic>. CFA = confirmatory factor analysis; ORF = oral reading fluency. Diagram shows parameter restrictions necessary to fit the “strict parallel reliability” model (i.e., <italic>L</italic><sub>1</sub> = <italic>L</italic><sub>2</sub> = 1 and <italic>I</italic><sub>1</sub> = <italic>I</italic><sub>2</sub> = 0). <italic>L</italic> indicates factor loading, <italic>I</italic> indicates intercept or mean, <italic>d</italic> and <italic>e</italic>1, <italic>e</italic>2, and <italic>e</italic>3 are multinormally distributed latent variables, with <italic>d</italic> representing factor scores and the <italic>e</italic>s representing passage-specific residual influences.</p>
</caption>
<graphic xlink:href="10.1177_1534508412456729-fig1.tif"/></fig>
<fig id="fig2-1534508412456729" position="float">
<label>Figure 2.</label>
<caption>
<p>Path diagram for quadratic CFA measurement model for three ORF passages showing measurement equations.</p>
<p><italic>Note</italic>. CFA = confirmatory factor analysis; ORF = oral reading fluency. <italic>L</italic> and <italic>Q</italic> indicate linear and quadratic factor loadings, respectively; <italic>I</italic> indicates intercept or mean; <italic>d</italic><sub><italic>L</italic></sub> and <italic>e</italic>1, <italic>e</italic>2, and <italic>e</italic>3 are multinormally distributed latent variables, with <italic>d</italic><sub><italic>L</italic></sub> representing factor scores and the <italic>e</italic>s representing passage-specific residual influences.</p>
</caption>
<graphic xlink:href="10.1177_1534508412456729-fig2.tif"/></fig>
<p>The measurement model in <xref ref-type="fig" rid="fig2-1534508412456729">Figure 2</xref>, which shows a second latent factor that represents the square of the true scores and hence represents a quadratic effect of the true scores on the indicators, may not be familiar. Although the idea and method of nonlinear factor analysis goes back quite some time (e.g., <xref ref-type="bibr" rid="bibr20-1534508412456729">McDonald, 1967</xref>), better methods (e.g., <xref ref-type="bibr" rid="bibr17-1534508412456729">Klein &amp; Moosbrugger, 2000</xref>) and easily available software (Mplus; <xref ref-type="bibr" rid="bibr22-1534508412456729">Muthén &amp; Muthén, 2010</xref>) to estimate these types of models are more recent. Such methods benefit equating studies because they offer a way to make formal statistical comparisons between models that imply linear equating would be adequate and models that imply equipercentile equating is required.</p>
<sec id="section4-1534508412456729">
<title>Heteroscedastic Variance</title>
<p>The models in <xref ref-type="fig" rid="fig1-1534508412456729">Figures 1</xref> and <xref ref-type="fig" rid="fig2-1534508412456729">2</xref> are based on distributional assumptions that may not be reasonable for fluency measures such as ORF. Typically, the latent variables are assumed multivariate normally distributed, which implies that the observed data are also multivariate normal, which implies that all possible regressions among the observed indicators are linear with constant residual variance (homoscedastic). A corollary is that the standard error of measurement (SEM) of ORF is constant. The model in <xref ref-type="fig" rid="fig2-1534508412456729">Figure 2</xref> relaxes the assumption that the observed indicators will be linearly related but it still implies homoscedasticity. Count measures in general, however, often have a pattern where the counts become more variable as the underlying rate increases (<xref ref-type="bibr" rid="bibr13-1534508412456729">Gelman &amp; Hill, 2007</xref>). That is, the measurement errors tend to be associated with the latent rate and increase as the latent rate goes up implying that the SEM is not constant.</p>
<p>If such a pattern of increasing residual variance does in fact characterize ORF, it is unlikely to be an issue for progress-monitoring applications in schools because the overall reliability of ORF is already quite high and high-performing students who might have a larger SEM are not typically progress monitored. Rather it is an issue that could have substantive implications when ORF is used for research purposes if high- and low-performing students are contrasted. In this case, the ORF scores for the high-performing students could have systematically lower reliability then ORF scores for low-performing students and differential reliability or low reliability or both are well known but correctable problems for regression models.</p>
<p>The strict parallel reliability measurement model can be extended to include a variance function that allows the residual variance to change as a function of the fitted values or equivalently, the latent true scores (<xref ref-type="bibr" rid="bibr23-1534508412456729">Pinheiro &amp; Bates, 2000</xref>), which is the final way the current work extends the existing literature. To our knowledge, this is the first demonstration of heteroscedasticity for CBM measures of ORF. We focus on two different variance functions for use with ORF. The first is a power function where the residual variance, var(<italic>e</italic>), is allowed to increase according to the absolute value of the latent true scores, <italic>f</italic>, raised to a constant power, delta, where delta is estimated from the data,</p>
<p><disp-formula id="disp-formula1-1534508412456729">
<mml:math display="block" id="math1-1534508412456729">
<mml:mrow>
<mml:mtext>var</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>e</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mtext>σ</mml:mtext>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>f</mml:mi>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mtext>δ</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-1534508412456729" xlink:href="10.1177_1534508412456729-eq1.tif"/>
</disp-formula></p>
<p>The second is an exponential function where the residual variance is allowed to increase according to an exponential of a constant, delta, times the latent true scores where delta is estimated from the data,</p>
<p><disp-formula id="disp-formula2-1534508412456729">
<mml:math display="block" id="math2-1534508412456729">
<mml:mrow>
<mml:mtext>var</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>e</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mtext>σ</mml:mtext>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mtext>δ</mml:mtext>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-1534508412456729" xlink:href="10.1177_1534508412456729-eq2.tif"/>
</disp-formula></p>
<p>Thus, the study is organized as follows. In our primary sample, first, we fit a series of measurement models to determine the most parsimonious model that would indicate which equating method will be optimal. Second, for all three methods of equating, we equate the passages and determine whether the SEE is within acceptable bounds (see <xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen &amp; Brennan, 2004</xref>, for discussion). Third, we refit the strict parallel reliability model to the equated passages from the three equating methods to determine which methods best create passage equivalence. Fourth, we apply the equating table to a new and independent replication sample of second-grade students to confirm that the SEE is within acceptable bounds. Finally, in our primary sample, we extend the measurement models for the equated passages to test for and accommodate residual variance that tends to increase with higher latent ORF rates.</p>
</sec>
</sec>
<sec id="section5-1534508412456729" sec-type="methods">
<title>Method</title>
<sec id="section6-1534508412456729">
<title>Participants</title>
<p>Participants in the primary study were 649 second-grade students from a subset of 9 out of 51 schools taking part in the Oregon Reading First (RFO) program; these 9 schools were located in 6 school districts throughout Oregon. For our analyses, we used student data from the academic year 2006–2007.</p>
<p>Schools eligible for RFO met specific criteria for student poverty level and reading performance. During the year prior to RFO implementation (2002–2003), 69% of students across all RFO schools qualified for free or reduced lunch rates, and 27% of third graders did not pass minimum proficiency standards on the Oregon Statewide Reading Assessment. The overall state average for free- or reduced-cost lunch in 2002–2003 was 44%, and 18% of the third-grade students did not pass the third-grade test.</p>
<p>For students included in the primary study, 10% received special education services, 21% were English learners, and 50% were female, with gender missing for 3% of students. The racial/ethnic composition was 43% White, 30% Hispanic, 14% Black, and 10% other non-White ethnic groups with race/ethnicity missing for 4% of students.</p>
<p>Participants in the replication study were 209 second-grade students from a subset of 4 schools in a school district in Western Oregon during the academic year 2009–2010. The schools in this replication sample were not eligible to participate in RFO because of substantially higher levels of achievement and lower levels of poverty (i.e., 34% of students qualified for free- or reduced-cost lunch). In addition, 9% received special education services, 12% were English learners, and 53% were female. The racial/ethnic composition was 67% White, 20% Hispanic, 2% Black, and 11% other non-White ethnic groups. The means for spring ORF Passages 1, 2, and 3 were 113, 96, and 111, respectively, and standard deviations were 35, 34, and 40, respectively. The interpassage correlations ranged from .92 to .93.</p>
</sec>
<sec id="section7-1534508412456729">
<title>Measures</title>
<p>In the fall, winter, and spring, students were administered DIBELS measures as part of benchmark testing (<xref ref-type="bibr" rid="bibr15-1534508412456729">Good &amp; Kaminski, 2002</xref>). For our analyses, we used the spring benchmark assessment. ORF Passages 1, 2, and 3 were administered in that order for all students. The ORF passages have Flesch–Kincaid readability scores of 2.1, 3.1, and 3.9, respectively.</p>
</sec>
<sec id="section8-1534508412456729">
<title>Data Collection Procedures</title>
<p>ORF measures were administered to students by school-based assessment teams. Each assessment team received a day of training on DIBELS administration and scoring. In addition, a reading coach at each school continued the assessment training by conducting calibration practice sessions with assessment team members that involved student participation. To maintain consistency across testers, the coaches conducted individual checks with each assessment team member before data collection. The adequacy of these procedures was checked by sending research teams out to get retest reliability data on a random subsample of students 2 weeks after schools conducted their benchmark assessments. The test–retest correlation between the median ORF score obtained by the school assessment and research personnel was .97 in Grade 1 and .93 in Grade 3.</p>
</sec>
</sec>
<sec id="section9-1534508412456729" sec-type="results">
<title>Results</title>
<p><xref ref-type="table" rid="table1-1534508412456729">Table 1</xref> shows descriptive statistics for the three ORF passage scores and for comparison, the traditional DIBELS ORF score, which is the middle score of the three. Students with partial data were few, 13 of 649 (2%), and most (8%) appeared to have partial data due to the discontinue rule of not administering additional passages to students who score 10 or lower. These students were included in all the models. The mean for Passage 3 was 85, intermediate between the means for Passages 1 and 2, which were 87 and 73, respectively. To parallel the standard DIBELS practice of using a student’s median score of the three passages administered for benchmark assessments, we adopted Passage 3 as the reference passage for the modeling and equating. The standard deviation for Passage 3 was 43, larger then Passages 1 and 2, which were 41 and 37, respectively. Note that the biggest pairwise difference in means is about 14 points, which corresponds to an effect size of .33 to .38 depending on which standard deviation we use.</p>
<table-wrap id="table1-1534508412456729" position="float">
<label>Table 1.</label>
<caption>
<p>Descriptive Statistics for Spring Grade-2 ORF Passage Scores</p>
</caption>
<graphic alternate-form-of="table1-1534508412456729" xlink:href="10.1177_1534508412456729-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">ORF Passage</th>
<th align="center"><italic>M</italic> (<italic>SD</italic>)</th>
<th align="center">Skew</th>
<th align="center">Kurtosis</th>
<th align="center">Minimum</th>
<th align="center">Maximum</th>
<th align="center"><italic>n</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>87.19 (40.57)</td>
<td>−0.11</td>
<td>−0.33</td>
<td>1</td>
<td>219</td>
<td>649</td>
</tr>
<tr>
<td>2</td>
<td>73.35 (36.87)</td>
<td>0.28</td>
<td>−0.01</td>
<td>0</td>
<td>190</td>
<td>642</td>
</tr>
<tr>
<td>3</td>
<td>84.69 (43.06)</td>
<td>0.08</td>
<td>−0.55</td>
<td>2</td>
<td>217</td>
<td>636</td>
</tr>
<tr>
<td>Median</td>
<td>82.83 (40.02)</td>
<td>0.03</td>
<td>−0.48</td>
<td>3</td>
<td>195</td>
<td>636</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1534508412456729">
<p><italic>Note</italic>. ORF = oral reading fluency.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The top row of <xref ref-type="fig" rid="fig3-1534508412456729">Figure 3</xref> shows scatterplots for Passages 1 versus 2 and for Passages 1 and 2 versus 3. Each scatterplot has a fitted nonparametric regression (lowess) that tracks nonlinear trends. The simple correlations among the passages are quite high, .95 to .96. Despite the high correlations, two features are still apparent. First, the dispersion of the points about the fitted regression lines increases for higher predictor values, and second, there is a slight degree of curvilinearity in all three plots.</p>
<fig id="fig3-1534508412456729" position="float">
<label>Figure 3.</label>
<caption>
<p>Scatter plots among the three ORF passages.</p>
<p><italic>Note</italic>. ORF = oral reading fluency; OLS = ordinary least squares. Top row are scatterplots for indicated ORF passages, solid line is a lowess fit. Middle row are residuals from a linear regression using the variable on the horizontal axis as the predictor and the variable on the vertical axis as the outcome, solid line is a lowess fit. Bottom row are the fitted values from a linear regression versus the square root of the absolute value of the residuals, solid line is a fitted, OLS linear regression. A trend indicates a violation of the homoscedasticity assumption.</p>
</caption>
<graphic xlink:href="10.1177_1534508412456729-fig3.tif"/></fig>
<p>The second row of plots in <xref ref-type="fig" rid="fig3-1534508412456729">Figure 3</xref> takes out the dominant linear trend to make the nature of the curvilinear trends more apparent. Using Passage 3 as the reference passage, the curvilinearity appears to be quadratic in nature and in opposite directions for Passage 1 (negative) versus Passage 2 (positive), which explains why the quadratic trend is most pronounced in the relation between Passages 2 and 1. In other words, if we view Passage 3 as a proxy for the unobserved true score, then we would expect Passages 1 and 2 to have significant loadings on a quadratic true score factor in opposite directions, negative and positive, respectively.</p>
<p>The third row addresses the possibility of heteroscedastic variance. An updated version of an old test for heteroscedastic residual variance in ordinary least squares (OLS) regression (i.e., <xref ref-type="bibr" rid="bibr8-1534508412456729">Breusch &amp; Pagan, 1979</xref>) is to make a scatterplot of the square root (to reduce skew) of the absolute value of the residuals against the fitted values and to add a fitted linear regression and a fitted nonparametric regression (e.g., lowess). If the standard assumption of homoscedastic variance holds, both fits will be straight, flat lines. For the pattern we are investigating, if the residual variance tends to increase at higher levels of ORF ability, we would expect the linear fit to have a significant positive upward trend and we would expect the nonparametric fit to look about the same. More complex patterns are possible and the nonparametric fit aids in their detection. In the bottom row of <xref ref-type="fig" rid="fig3-1534508412456729">Figure 3</xref>, only the linear fit is shown to avoid cluttering the plots because the nonparametric fit was similar, and in all three cases, the trend is significant and upward suggesting that the residual variance does tend to increase with higher latent ORF ability.</p>
<p><xref ref-type="table" rid="table2-1534508412456729">Table 2</xref> shows results, parameter estimates, and fit indices for a series of nested measurement models. With nonlinear factor models, it is no longer reasonable to assume the observed data will be multivariate normally distributed (<xref ref-type="bibr" rid="bibr18-1534508412456729">Klein &amp; Muthén, 2007</xref>), and thus, standard errors and chi-square values in <xref ref-type="table" rid="table2-1534508412456729">Tables 2</xref> and <xref ref-type="table" rid="table3-1534508412456729">3</xref> are based on robust maximum likelihood (ML) estimation, which corrects for departures from multivariate normality (<xref ref-type="bibr" rid="bibr28-1534508412456729">Satorra &amp; Bentler, 2001</xref>). The scale factors in <xref ref-type="table" rid="table2-1534508412456729">Tables 2</xref> and <xref ref-type="table" rid="table3-1534508412456729">3</xref> indicate the degree of departure and are used to compute nested chi-square tests, which is why the nested chi-squares are not the usual simple difference in chi-square (<xref ref-type="bibr" rid="bibr3-1534508412456729">Asparouhov &amp; Muthen, 2010</xref>). In addition, the usual saturated model is no longer the only standard against which the fit of more restricted models can be judged. This is because if nonlinear relations are seriously considered, then the latent variables no longer have a multivariate normal distribution and thus the observed indicators no longer have a multivariate normal distribution. Because higher order moments like skew and kurtosis do not necessarily vanish for nonnormal distributions, there are more degrees of freedom available as compared with the usual saturated normal model, which has degrees of freedom equal to the number of unique elements in the mean vector and covariance matrix of the observed indicators (see <xref ref-type="bibr" rid="bibr18-1534508412456729">Klein &amp; Muthén, 2007</xref>, for more technical details). For comparison, we will present fit statistics using both the saturated normal model and the nonlinear factor model as alternative models.</p>
<table-wrap id="table2-1534508412456729" position="float">
<label>Table 2.</label>
<caption>
<p>CFA Measurement Models for Raw ORF Passage Scores</p>
</caption>
<graphic alternate-form-of="table2-1534508412456729" xlink:href="10.1177_1534508412456729-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Model<hr/></th>
</tr>
<tr>
<th align="center">Effect</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="5">Passage</td>
</tr>
<tr>
<td> 1. Linear loading</td>
<td>1</td>
<td>1</td>
<td>0.921<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>1.062</td>
</tr>
<tr>
<td> 2. Linear loading</td>
<td>1</td>
<td>1</td>
<td>0.848<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>0.712<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td> 1. Quadratic loading</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>−0.001<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td> 2. Quadratic loading</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.001<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td>Linear factor mean</td>
<td>81.189<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>83.668<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>83.567<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>83.607<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td colspan="5">Passage</td>
</tr>
<tr>
<td> 1. Intercept</td>
<td>0</td>
<td>3.518<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>10.240<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>5.743<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td> 2. Intercept</td>
<td>0</td>
<td>−11.171<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>1.671<xref ref-type="table-fn" rid="table-fn3-1534508412456729">*</xref></td>
<td>6.063<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td>Linear factor variance</td>
<td>1,540.611<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>1,572.281<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>1,852.758</td>
<td>1,846.983<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td colspan="5">Passage</td>
</tr>
<tr>
<td> 1. Residual</td>
<td>140.339<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>80.959<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>70.684<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>67.227<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td> 2. Residual</td>
<td>140.339<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>80.959<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>70.684<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>67.227<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td> 3. Residual</td>
<td>140.339<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>80.959<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>70.684<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
<td>67.227<xref ref-type="table-fn" rid="table-fn3-1534508412456729">***</xref></td>
</tr>
<tr>
<td>χ<sup>2</sup></td>
<td>700.123</td>
<td>132.807</td>
<td>0.860</td>
<td/>
</tr>
<tr>
<td><italic>df</italic></td>
<td>6</td>
<td>4</td>
<td>2</td>
<td/>
</tr>
<tr>
<td><italic>p</italic></td>
<td>.000</td>
<td>.000</td>
<td>.651</td>
<td/>
</tr>
<tr>
<td>Scale factor</td>
<td>1.242</td>
<td>1.289</td>
<td>1.274</td>
<td/>
</tr>
<tr>
<td>RMSEA</td>
<td>.422</td>
<td>.223</td>
<td>.000</td>
<td/>
</tr>
<tr>
<td> 90% CI LL</td>
<td>0.396</td>
<td>0.191</td>
<td>0.000</td>
<td/>
</tr>
<tr>
<td> 90% CI UL</td>
<td>0.449</td>
<td>0.256</td>
<td>0.061</td>
<td/>
</tr>
<tr>
<td> <italic>p</italic> (RMSEA ≤ .05)</td>
<td>.000</td>
<td>.000</td>
<td>.906</td>
<td/>
</tr>
<tr>
<td>vs. Model 4, χ<sup>2</sup></td>
<td>728.850</td>
<td>173.185</td>
<td>45.164</td>
<td/>
</tr>
<tr>
<td> <italic>df</italic></td>
<td>6</td>
<td>4</td>
<td>2</td>
<td/>
</tr>
<tr>
<td> <italic>p</italic></td>
<td>.000</td>
<td>.000</td>
<td>.000</td>
<td/>
</tr>
<tr>
<td> Scale factor</td>
<td>1.277</td>
<td>1.342</td>
<td>1.379</td>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1534508412456729">
<p><italic>Note</italic>. CFA = confirmatory factor analysis; ORF = oral reading fluency; scale factor = robust maximum likelihood (ML) correction scaling factor for departure from multivariate normality; RMSEA = root mean square error of approximation; CI = confidence interval; LL = lower limit; UL = upper limit. 1s or 0s with no decimals indicate parameters fixed to these values. Estimated factor loadings were tested against the null hypothesis that they were equal to 1.</p>
</fn>
<fn id="table-fn3-1534508412456729">
<label>*</label>
<p>.01 &lt; <italic>p</italic> &lt; .05. **.001 &lt; <italic>p</italic> &lt; .01. ***0 &lt; <italic>p</italic> &lt; .001.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table3-1534508412456729" position="float">
<label>Table 3.</label>
<caption>
<p>Measurement Models for Equated ORF Passage Scores</p>
</caption>
<graphic alternate-form-of="table3-1534508412456729" xlink:href="10.1177_1534508412456729-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="5">Model<hr/></th>
</tr>
<tr>
<th/>
<th align="center">5<hr/></th>
<th align="center">6<hr/></th>
<th align="center">7<hr/></th>
<th align="center">8<hr/></th>
<th align="center">9<hr/></th>
</tr>
<tr>
<th/>
<th align="center" colspan="3">Strict Parallel Reliability<hr/></th>
<th align="center" colspan="2">Quadratic<hr/></th>
</tr>
<tr>
<th align="left">Type of Equating</th>
<th align="center">ME</th>
<th align="center">LE</th>
<th align="center">EE</th>
<th align="center">LE</th>
<th align="center">EE</th>
</tr>
</thead>
<tbody>
<tr>
<td>χ<sup>2</sup></td>
<td>147.121</td>
<td>9.449</td>
<td>8.037</td>
<td/>
<td/>
</tr>
<tr>
<td><italic>df</italic></td>
<td>6</td>
<td>6</td>
<td>6</td>
<td/>
<td/>
</tr>
<tr>
<td><italic>p</italic></td>
<td>.000</td>
<td>.150</td>
<td>.235</td>
<td/>
<td/>
</tr>
<tr>
<td>Scale factor</td>
<td>1.195</td>
<td>1.171</td>
<td>1.072</td>
<td/>
<td/>
</tr>
<tr>
<td>RMSEA</td>
<td>.190</td>
<td>.030</td>
<td>.023</td>
<td/>
<td/>
</tr>
<tr>
<td> 90% CI LL</td>
<td>0.164</td>
<td>0.000</td>
<td>0.000</td>
<td/>
<td/>
</tr>
<tr>
<td> 90% CI UL</td>
<td>0.218</td>
<td>0.064</td>
<td>0.059</td>
<td/>
<td/>
</tr>
<tr>
<td> <italic>p</italic> (RMSEA ≤ .05)</td>
<td>.000</td>
<td>.807</td>
<td>.873</td>
<td/>
<td/>
</tr>
<tr>
<td>Model 8 vs. 6, χ<sup>2</sup></td>
<td/>
<td/>
<td/>
<td>65.746</td>
<td/>
</tr>
<tr>
<td> <italic>df</italic></td>
<td/>
<td/>
<td/>
<td>6</td>
<td/>
</tr>
<tr>
<td> <italic>p</italic></td>
<td/>
<td/>
<td/>
<td>.000</td>
<td/>
</tr>
<tr>
<td> Scale factor</td>
<td/>
<td/>
<td/>
<td>1.193</td>
<td/>
</tr>
<tr>
<td>Model 9 vs. 7, χ<sup>2</sup></td>
<td/>
<td/>
<td/>
<td/>
<td>7.239</td>
</tr>
<tr>
<td> <italic>df</italic></td>
<td/>
<td/>
<td/>
<td/>
<td>6</td>
</tr>
<tr>
<td> <italic>p</italic></td>
<td/>
<td/>
<td/>
<td/>
<td>.299</td>
</tr>
<tr>
<td> Scale factor</td>
<td/>
<td/>
<td/>
<td/>
<td>1.057</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-1534508412456729">
<p><italic>Note</italic>. ORF = oral reading fluency; ME = mean equating; LE = linear equating; EE = equipercentile equating; scale factor = robust maximum likelihood (ML) correction factor for departure from multivariate normality; RMSEA = root mean square error of approximation; CI = confidence interval; LL = lower limit; UL = upper limit; CFA = confirmatory factor analysis. Chi-squares for the fit of Models 5, 6, and 7 are obtained by comparing with their respective saturated models (linear CFAs assuming multivariate normality).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Without considering the possibility of curvilinear relations and using the saturated normal model as the basis for comparison, it is apparent that Model 1 (no mean or scaling differences) and Model 2 (mean differences only) are inadequate (both the chi-square fit statistics and the root mean square error of approximation [RMSEA] indicate poor fit) but Model 3 fits the data well. Model 3 indicates that the passages have both significant intercept differences and factor loading differences (the factor loadings are tested against the null hypothesis that they are equal to 1, the fixed loading on the reference Passage 3), which suggests both differences in scaling and difficulty. Model 4, however, reveals that Passages 1 and 2 have significant loadings on the quadratic factor, consistent with evidence in <xref ref-type="fig" rid="fig1-1534508412456729">Figure 1</xref>. When Model 4 is used as the “saturated” model to which all other more restrictive models are compared, the nested chi-square tests in <xref ref-type="table" rid="table2-1534508412456729">Table 2</xref> indicate that Models 1, 2, and 3 all fit significantly worse.</p>
<p>Given the results of the measurement models, equipercentile equating would be the best choice because only equipercentile equating can equate test scores that have curvilinear relations. We will demonstrate this by refitting the same measurement models to the equated passage scores after using mean, linear, and equipercentile equating. First, however, we present a series of plots that clarify the nature of the corrections produced by each method of equating and the SEE for each method.</p>
<p>The easier (Passage 1) and harder (Passage 2) passages were equated to the middle passage (Passage 3) using the mean, linear, and presmoothed equipercentile methods. Polynomial (4th degree) loglinear presmoothing (<xref ref-type="bibr" rid="bibr16-1534508412456729">Holland &amp; Thayer, 2000</xref>) was used to help minimize random sampling error. Scores on all three passages greater than 200 were recoded back to 200 to prevent undue distortion to equating functions. Only 2 scores, 1 each for Passages 1 and 3, were recoded.</p>
<p>The nature of the corrections to the easier first passage and harder second passage to equate both to the third passage is indicated on the left and right of the top row of <xref ref-type="fig" rid="fig4-1534508412456729">Figure 4</xref>, respectively, for each individual value of the raw passages (before equating). For mean equating, the correction for Passages 1 and 2 is to subtract about 2.5 points and add about 11 points, respectively, regardless of the original scores on the raw passages. For linear equating, the correction factor varies from −7 points at an original score of 0 on Passage 1 to 7 for an original score of 200. For Passage 2, the correction factor varies from −1 point at an original score of 0 to 33 for an original score of 200. For presmoothed equipercentile equating, the corrections for Passages 1 and 2 are highly variable as is apparent in <xref ref-type="fig" rid="fig4-1534508412456729">Figure 4</xref>.</p>
<fig id="fig4-1534508412456729" position="float">
<label>Figure 4.</label>
<caption>
<p>Equating correction factors and SEEs.</p>
<p><italic>Note</italic>: ORF = oral reading fluency; SEEs = standard errors of equating. Top row are raw ORF scores versus equating correction factor (equated score minus raw score) for three methods of equating, mean, linear, and equipercentile. Bottom row are SEEs for three methods of equating, mean, linear, and equipercentile.</p>
</caption>
<graphic xlink:href="10.1177_1534508412456729-fig4.tif"/></fig>
<p>The SEEs for each type of equating are shown at each individual value of the raw passage (before equating) in the bottom row of <xref ref-type="fig" rid="fig4-1534508412456729">Figure 4</xref>. SEEs for mean and linear equating were obtained using standard formulas for a single group equating design (<xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen &amp; Brennan, 2004</xref>). For example, the SEE for mean equating of Passage 1 (ORF1) to Passage 3 (ORF3) is</p>
<p><disp-formula id="disp-formula3-1534508412456729">
<mml:math display="block" id="math3-1534508412456729">
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ORF</mml:mtext>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ORF</mml:mtext>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>×</mml:mo>
<mml:mi>cov</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ORF</mml:mtext>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mtext>ORF</mml:mtext>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:mfrac>
</mml:mrow>
</mml:msqrt>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-1534508412456729" xlink:href="10.1177_1534508412456729-eq3.tif"/>
</disp-formula></p>
<p>where var indicates the sample variance, cov indicates sample covariance, and <italic>N</italic> is the total sample size. Other SEEs have different formulas that are not presented here in the interests of space, and SEEs for equipercentile equating were obtained by bootstrap resampling. Interested readers can consult <xref ref-type="bibr" rid="bibr19-1534508412456729">Kolen and Brennan (2004)</xref> for details. What is immediately apparent in <xref ref-type="fig" rid="fig4-1534508412456729">Figure 4</xref> is the larger standard errors for equipercentile equating compared with the other types of equating over most of the raw score distribution. Equipercentile equating offers the most general and comprehensive approach to equating but it also comes at a price of more random error. More importantly, however, with just over 600 students in our primary sample, the SEE is always less than 4 cwpm (correct words per minute) for both passages for raw scores from 0 to 200 and less than 2 cwpm for scores in the range of 0 to 150, which covers the range of the vast majority of scores (about 95%).</p>
<p><xref ref-type="table" rid="table3-1534508412456729">Table 3</xref> shows results of fitting the strict parallel reliability model and the quadratic measurement model to the equated scores for Passages 1 and 2 and the raw scores for Passage 3. As is clear, the strict parallel reliability model fits adequately for the linear (Model 6) and equipercentile (Model 7) equated scores, but poorly for mean (Model 5) equated scores (RMSEA of .19) compared with the saturated normal model. <xref ref-type="table" rid="table3-1534508412456729">Table 3</xref> also shows nested chi-square tests comparing the strict parallel model with the quadratic measurement model for linear and equipercentile equated scores. For linear equated scores, the quadratic model fits significantly better (Model 8 vs. Model 6) and the quadratic loadings (data not shown) are significant and essentially unchanged compared with results in <xref ref-type="table" rid="table2-1534508412456729">Table 2</xref>. For equipercentile equated scores, however, the quadratic model does not fit significantly better (Model 9 vs. Model 7) and parameter estimates (data not shown) indicate that the quadratic loadings are not significantly different from zero. Thus, only equipercentile equating eliminates the quadratic effects of the true scores on Passages 1 and 2. These results essentially verify that the three different equating methods do what they are intended to do when applied to the ORF passages.</p>
<p>The SEE for equipercentile equating with the primary sample of 600 indicates that the equating table from this sample will make the passage scores more equivalent when used in independent replication samples. We can test this directly by using the equating table derived from the primary sample to equate Passages 1 and 2 to Passage 3 in our replication sample and fitting the strict parallel reliability model before and after equating. If the fit of the model improves substantially then the equating has achieved its purpose. First, we note that the pattern of passage effects is the same in the replication sample (Passage 1, easiest; Passage 2, hardest; and Passage 3 in the middle), despite the substantially higher mean levels of ORF (23–26 cwpm). More importantly, the strict parallel model fit to the raw passages had a robust chi-square of 186.41 (<italic>df</italic> = 6, <italic>p</italic> &lt; .001) and an RMSEA of .379 (90% confidence interval [CI] = [.334, .427]), clearly a poor fit. The strict parallel reliability model fit to the equipercentile equated measures (Passages 1 and 2 equated to Passage 3) had a robust chi-square of 6.72 (<italic>df</italic> = 6, <italic>p</italic> = .348) and an RMSEA of .024 (90% CI = [0, .095]), an acceptable fit. This small replication study suggests that the current equating was successful and could be widely applied to other students in other schools.</p>
<sec id="section10-1534508412456729">
<title>Heteroscedasticity</title>
<p>Preliminary results in <xref ref-type="fig" rid="fig3-1534508412456729">Figure 3</xref> suggest that the regression of the passages on the latent ORF true scores is not homoscedastic (constant variance), and in fact, the residual variance tends to increase with higher latent ORF ability. Here, we address the question about whether equipercentile equating eliminates the increase in residual variance. First, <xref ref-type="fig" rid="fig5-1534508412456729">Figure 5</xref> shows the same type of residual diagnostic plots as in the bottom row of <xref ref-type="fig" rid="fig3-1534508412456729">Figure 3</xref> for the standard strict parallel reliability model fit to the equated scores. Fitted values for the model include empirical Bayes’s estimates of latent ORF for each student, and these are computed using standard formulas. The increase in the dispersion shows up as a significant upward trend in the data in the top left of <xref ref-type="fig" rid="fig5-1534508412456729">Figure 5</xref>. Thus, although equipercentile equating does make the passages equivalent in the sense of all having the same distribution, and therefore the same means and standard deviations, it does not eliminate the heteroscedastic variance.</p>
<fig id="fig5-1534508412456729" position="float">
<label>Figure 5.</label>
<caption>
<p>Residual diagnostic plots.</p>
<p><italic>Note</italic>. ORF = oral reading fluency; OLS = ordinary least squares. Top left plot shows fitted values versus the square root of the absolute value of the standardized residuals for a standard strict parallel reliability model fit to equated ORF passage scores, solid line is a fitted, OLS linear regression. The trend indicates a violation of the homoscedasticity assumption. Top right plot is the same plot as top left but for strict parallel reliability model with a power variance function. Lack of trend indicates homoscedastic variance. Bottom left plot shows fitted standard error of measurement for the model with a power variance function. Bottom right plot shows standardized residuals plotted against standard normal quantiles for the power variance function model. Top and bottom dashed lines indicate quartiles and middle dashed line indicates median.</p>
</caption>
<graphic xlink:href="10.1177_1534508412456729-fig5.tif"/></fig>
<p><xref ref-type="table" rid="table4-1534508412456729">Table 4</xref> shows results from strict parallel reliability models extended to include either the power or exponential variance function. Either of the variance functions significantly and substantially improved the fit over the standard strict parallel reliability model. The power model and the exponential model are not nested but the <italic>Bayesian information criterion</italic> (BIC) definitely favors the power (BIC = 16,446.69) over exponential (BIC = 16,508.99) variance function. Parameter estimates for the power function model are shown in <xref ref-type="table" rid="table5-1534508412456729">Table 5</xref>. The estimated power coefficient is .46, quite close to .50, which suggests that a square root transformation of the raw data would also work to stabilize the residual variance. The power function model, however, has the advantage of not changing the scaling of the other estimates, the factor mean and variance.</p>
<table-wrap id="table4-1534508412456729" position="float">
<label>Table 4.</label>
<caption>
<p>Standard Versus Variance Function Model Comparisons for Equipercentile Equated Passages</p>
</caption>
<graphic alternate-form-of="table4-1534508412456729" xlink:href="10.1177_1534508412456729-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Description</th>
<th align="center">Model</th>
<th align="center"><italic>fp</italic></th>
<th align="center">Log-L</th>
<th align="center">Test</th>
<th align="center">χ<sup>2</sup></th>
<th align="center"><italic>df</italic></th>
<th align="center"><italic>p</italic> Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Standard</td>
<td>10</td>
<td>3</td>
<td>−8,299.62</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Exponential</td>
<td>11</td>
<td>4</td>
<td>−8,239.37</td>
<td>10 vs. 11</td>
<td>120.49</td>
<td>1</td>
<td>.0000</td>
</tr>
<tr>
<td>Power</td>
<td>12</td>
<td>4</td>
<td>−8,208.22</td>
<td>10 vs. 12</td>
<td>182.80</td>
<td>1</td>
<td>.0000</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-1534508412456729">
<p><italic>Note</italic>. <italic>fp</italic> = free parameters; Log-L = log likelihood.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table5-1534508412456729" position="float">
<label>Table 5.</label>
<caption>
<p>Estimated Parameters for Power Variance Versus Standard Measurement Model for Equipercentile Equated ORF Passages</p>
</caption>
<graphic alternate-form-of="table5-1534508412456729" xlink:href="10.1177_1534508412456729-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Model<hr/></th>
</tr>
<tr>
<th/>
<th align="center" colspan="2">Power<hr/></th>
<th align="center" colspan="2">Standard<hr/></th>
</tr>
<tr>
<th align="left">Parameter</th>
<th align="center">Estimated</th>
<th align="center"><italic>SE</italic></th>
<th align="center">Estimated</th>
<th align="center"><italic>SE</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Factor mean</td>
<td>83.81</td>
<td>1.68</td>
<td>84.12</td>
<td>1.68</td>
</tr>
<tr>
<td>Factor <italic>SD</italic></td>
<td>42.53</td>
<td>1.20</td>
<td>42.49</td>
<td>1.20</td>
</tr>
<tr>
<td>Residual <italic>SD</italic></td>
<td>1.15</td>
<td>0.15</td>
<td>8.79</td>
<td>0.17</td>
</tr>
<tr>
<td>Power</td>
<td>0.46</td>
<td>0.03</td>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-1534508412456729">
<p><italic>Note</italic>. ORF = oral reading fluency.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The top right part of <xref ref-type="fig" rid="fig5-1534508412456729">Figure 5</xref> shows the same diagnostic plot but after the residuals have been standardized to incorporate the power variance function. As is clear, the significant upward trend due to the increase in residual variance is now gone. For comparison purposes, <xref ref-type="table" rid="table4-1534508412456729">Table 4</xref> shows the parameter estimates for the standard model. The only parameter that changes appreciably is the residual standard deviation. In the power function model, the estimate of the residual standard deviation is the estimate for fitted ORF value of 1. The bottom left of <xref ref-type="fig" rid="fig5-1534508412456729">Figure 5</xref> shows the estimated residual standard deviation (i.e., the SEM) plotted against the fitted ORF value for ORF fitted values from 1 to 200 overlaid on the raw residuals. The standard deviation is about 1.5 at a fitted ORF value of 1 and increases to about 13 at a fitted ORF value of 200. Finally, in the lower right of <xref ref-type="fig" rid="fig5-1534508412456729">Figure 5</xref>, the standardized residuals are plotted against normal quantiles, and as the figure makes apparent, they follow a normal distribution quite closely.</p>
</sec>
</sec>
<sec id="section11-1534508412456729" sec-type="discussion">
<title>Discussion</title>
<sec id="section12-1534508412456729">
<title>Lack of Psychometric Equivalence</title>
<p>Evidence is accumulating that existing methods for creating grade-level passages for ORF assessments that rely solely on readability formulas do not produce psychometrically equivalent passages. Despite the best efforts of developers, passages vary significantly in terms of both difficulty and scaling. Evidence reported here indicates that this appears to be true for DIBELS ORF as well, a widely adopted progress-monitoring system used in thousands of schools serving millions of students.</p>
<p>One way to deal with difficulty and scaling differences among alternative forms of the same test is to use statistical equating techniques. A key part of any successful equating, however, is an appropriate design, which subsumes such issues as sample recruitment design, sample size, assignment of participants to alternative forms, and the proposed equating method. Fitting measurement models to the alternative forms can help narrow down the range of equating design parameters by revealing the nature of the form differences that have to be eliminated. In addition, measurement models can reveal other properties of the scores, such as heteroscedastic residual variance, that might have implications for analyses that use ORF as a predictor or outcome.</p>
<p>Results reported here indicate that the three DIBELS ORF passages used for the spring of second-grade assessment have significant differences in difficulty and scaling and also have significant nonlinear relations with the underlying true scores. We found that a strict parallel reliability measurement model, which implies that the passages are psychometrically equivalent, did not fit the data. Further model fitting revealed that the factor loadings were significantly different from 1 indicating scaling differences, and the specific intercepts were significantly different from 0 indicating difficulty differences. Finally, advances in methodology for fitting nonlinear factor models allowed us to show that the passages had significant loadings on a quadratic true score factor. All these results indicate that equipercentile equating would be the best choice for a more comprehensive equating study.</p>
<p>When the scores were actually equated using smoothed equipercentile equating, refitting the same measurement models indicated that all form differences (i.e., difficulty, scaling, and nonlinear relations) were eliminated, which is not surprising and merely indicates that the equating methods work as intended. Also as expected, simpler equating approaches such as mean equating did not eliminate scaling differences, and linear equating did not eliminate nonlinear relations.</p>
<p>In the present study, standard errors of smoothed equipercentile equating with the primary sample of 600 were less than 2 cwpm over most of the useful range of the ORF scale (i.e., 0–150) and were still less than 4 cwpm for 150 to 200 cwpm. These SEEs indicate that an equating study carried out with 600 participants who are representative of the general population is likely to be successful in making the passages more equivalent assuming other relevant design issues are addressed. We verified this by using the equating table from the primary sample on an independent replication sample and fitting a strict parallel reliability model to the raw and equated passages. The model fit the raw passages poorly, the improvement in fit after equating the passages was substantial, and model fit with the equated passages was good. Thus, despite substantial differences in time frame (3 years), achievement level (23–26 cwpm) and educational context (eligible for Reading First vs. ineligible) between the two samples, our basic results appear to be rather robust.</p>
</sec>
<sec id="section13-1534508412456729">
<title>Heteroscedastic Residual Variance</title>
<p>The residual error variance of ORF assessments appears to increase as the latent ORF ability goes up. Equipercentile equating does nothing to change this. Substantively, the heteroscedastic model indicates that students who can read faster are also more variable in their higher level of performance, which implies that the reliability of ORF is lower for higher performing students. Or in terms of the SEM of ORF, it is not constant but increases with latent ORF level. To illustrate the phenomenon, suppose we compare the theoretical reliability of ORF for two subsets of students, those who score 1 standard deviation above and below the mean, which represents the top and bottom 16% of the population, respectively, assuming ORF is normally distributed. At the spring of Grade-2 assessment, the high-scoring students would have a latent ORF score of 126 or higher, and the low-scoring students would have a score of 41 or lower. For both groups, the variance of the ORF true scores would be about 20% of the full variance or about 362. For the high-scoring group, the residual variance would range from about 121 to 169, leading to a reliability between .68 and .75. For the low-scoring group, the residual variance would range from 1.5 to 7.5, leading to a reliability between .87 and .99. Part of the attenuation for either group is due to the restricted range of ORF true scores, but for the high group, most of the attenuation is due to the increase in residual variance at higher levels of true ORF. The reliability for the high group is low enough to be of concern for some types of analyses, and if so, a latent variable model would be recommended to prevent attenuation of estimated effects.</p>
</sec>
<sec id="section14-1534508412456729">
<title>Practical Implications</title>
<p>Lack of psychometric equivalence for DIBELS ORF has important implications. It represents a form of error or noise in the DIBELS assessment system. Traditionally, to protect against such sources of error, three passages are administered at each benchmark assessment (fall, winter, and spring), the high and low scores are excluded, and the middle score is taken as the indicator of proficiency. This procedure is probably adequate to protect against random errors of measurement including those due to lack of psychometric equivalence. However, it substantially increases the assessment burden on the school personnel and teachers who have to administer ORF compared with a system in which the passages are equivalent and only a single passage at each occasion is required. In addition, more frequent progress monitoring is typically done using a single passage at each assessment. In this context, lack of invariance could produce misleading results as has been previously demonstrated (<xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>), and it will increase the number of assessments required for true improvement to overcome the random noise and emerge as a discernible trend in the data. Once again, the burden of increased assessments falls on school personnel and teachers. In a time of shrinking resources for schools, reducing the assessment burden on schools as low as possible is highly desirable. Currently, many schools enter their DIBELS data in the DIBELS data system (DDS), a computerized system that generates a variety of reports useful to educators who want to monitor reading achievement levels. The DDS could easily be extended to handle all the mechanics of equating alternate forms so that equating imposes no extra burden on school personnel. Thus, equating passages has implications for making data collection more efficient and economical.</p>
<p>A related implication of equating passages for educators is the resultant increase in the precision and reliability of students’ ORF scores and importantly ORF growth estimates. This could increase the validity of instructional decision making based on student ORF progress. Models of response to instruction and intervention (RtI) are based on the use of student growth data to determine whether students are making adequate progress or require more intensive intervention (<xref ref-type="bibr" rid="bibr14-1534508412456729">Gersten et al., 2009</xref>). Schools currently use student ORF progress-monitoring data to inform both low-stakes (e.g., providing an additional small-group instruction) and high-stakes decisions (e.g., making specific learning disability determination decisions; <xref ref-type="bibr" rid="bibr4-1534508412456729">Baker, Fien, &amp; Baker, 2010</xref>). Although the amount of error in growth estimates associated with unequated passages may be acceptable for low-stakes decision making, it is quite unacceptable for making high-stakes decisions (<xref ref-type="bibr" rid="bibr27-1534508412456729">Salvia, Ysseldyke, &amp; Bolt, 2010</xref>). For example, misidentifying students for special education services is an extremely expensive error, both in terms of school resources and negative unintended outcomes for children (<xref ref-type="bibr" rid="bibr30-1534508412456729">Skiba et al., 2008</xref>). It should be noted that making errors with lower stakes decisions also have resource implications. Providing small-group instruction is not inexpensive and can exert a major fiscal burden on schools and school districts. Thus, equating passages has the potential to greatly increase the validity of a number of instructional decisions within an RtI model of instruction and intervention.</p>
<p>Perhaps the most pressing implication, and our more pointed recommendation, is targeted to developers of CBM assessments in general, and ORF in particular. We contend that it simply remains untenable to continue to create ORF passages using readability formulas alone. One could argue, on the basis of this study and previous studies (<xref ref-type="bibr" rid="bibr2-1534508412456729">Ardoin et al., 2010</xref>; <xref ref-type="bibr" rid="bibr9-1534508412456729">Christ &amp; Ardoin, 2009</xref>; <xref ref-type="bibr" rid="bibr12-1534508412456729">Francis et al., 2008</xref>; <xref ref-type="bibr" rid="bibr24-1534508412456729">Poncy et al., 2005</xref>), that the use of statistical equating methods is a necessary step in the development process. This would require that CBM developers know how to apply proper equating methods and know the pros and cons of each particular approach. As we show in this article, decisions about what type of equating to use can be enhanced by fitting measurement models to alternative ORF passages. This shift in CBM development would require that developers have an advanced knowledge of measurement and statistical equating methodologies. It would also require a substantial investment in research and development activities that occur prior to measures being disseminated widely. However, we believe the cost for such an enterprise would be well worth the increase in both the precision of ORF growth estimates and the validity of instructional decision making.</p>
</sec>
<sec id="section15-1534508412456729">
<title>Limitations</title>
<p>The present study includes several limitations that future studies should address. First, we only examined three DIBELS ORF passages, those used for the spring benchmark assessment of second grade. Future research will need to investigate the ORF passages for the other benchmark and progress-monitoring assessments in Grade 2 and other grades, of which there are many.</p>
<p>Second, we could not address the issue of order effects in the current analyses. The existing evidence on order effects is mixed; however, sample sizes in the existing studies tend to be modest so it is possible that order effects are significant but not large in magnitude compared with difficulty differences.</p>
<p>Third, we also chose not to address the issue of school effects, mostly because none of our research questions were school-level questions and our primary sample of nine schools is too small to be of much use. In addition, standard errors from the models for student-level parameters would not be strongly affected by school-level differences. Finally, in sensitivity analyses (not reported here), we found that including school effects as a collection of eight dummy variables did not change any of the conclusions nor did fitting multilevel measurement models although due to the limited sample size of nine schools, it was not possible to fit a multilevel quadratic measurement model.</p>
<p>Finally, the primary sample we used for the measurement models was a convenience sample derived from nine schools participating in RFO. The generality of our results, therefore, may not be as broad as would be desirable. We did, however, verify in an independent replication sample that the same pattern of passage effects replicated and the equating table derived from our RFO sample was effective in removing the passage effects, which helps mitigate concerns about generalizability.</p>
</sec>
</sec>
<sec id="section16-1534508412456729" sec-type="conclusions">
<title>Conclusion</title>
<p>The present study addressed the issue of passage nonequivalence in the measurement of ORF. Comparing a series of measurement models, results indicated that compared to mean and linear equating equipercentile equating is preferable for its ability to accommodate the curvilinear relationships among passages while maintaining a desirably low standard error across the range of student ability.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by an Oregon Reading First subcontract from the Oregon Department of Education to the University of Oregon (8948). The original Oregon Reading First grant was made from the U.S. Department of Education to the Oregon Department of Education (S357A0020038).</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ardoin</surname><given-names>S. P.</given-names></name>
<name><surname>Suldo</surname><given-names>S. M.</given-names></name>
<name><surname>Witt</surname><given-names>J.</given-names></name>
<name><surname>Aldrich</surname><given-names>S.</given-names></name>
<name><surname>McDonald</surname><given-names>E.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Accuracy of readability estimates’ predictions of CBM performance</article-title>. <source>School Psychology Quarterly</source>, <volume>20</volume>, <fpage>1</fpage>–<lpage>22</lpage>. doi:<pub-id pub-id-type="doi">10.1521/scpq.20.1.1.64193</pub-id></citation>
</ref>
<ref id="bibr2-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ardoin</surname><given-names>S. P.</given-names></name>
<name><surname>Williams</surname><given-names>J. C.</given-names></name>
<name><surname>Christ</surname><given-names>T. J.</given-names></name>
<name><surname>Klubnik</surname><given-names>C.</given-names></name>
<name><surname>Wellborn</surname><given-names>C.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Examining readability estimates’ predictions of students’ oral reading rate: Spache, Lexile, and Forcast</article-title>. <source>School Psychology Review</source>, <volume>39</volume>, <fpage>277</fpage>–<lpage>285</lpage>.</citation>
</ref>
<ref id="bibr3-1534508412456729">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Asparouhov</surname><given-names>T.</given-names></name>
<name><surname>Muthen</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <source>Computing the strictly positive Satorra–Bentler chi-square test in Mplus</source> (Mplus Web Notes No. 12). <publisher-loc>Los Angeles, CA</publisher-loc>: <publisher-name>Muthen &amp; Muthen</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.statmodel.com/examples/webnote.shtml#web12">http://www.statmodel.com/examples/webnote.shtml#web12</ext-link></citation>
</ref>
<ref id="bibr4-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Baker</surname><given-names>S. K.</given-names></name>
<name><surname>Fien</surname><given-names>H.</given-names></name>
<name><surname>Baker</surname><given-names>D. L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Robust reading instruction in the early grades: Conceptual and practical issues in the integration and evaluation of tier 1 and tier 2 instructional supports</article-title>. <source>Focus on Exceptional Children</source>, <volume>42</volume>, <fpage>1</fpage>–<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr5-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Baker</surname><given-names>S. K.</given-names></name>
<name><surname>Smolkowski</surname><given-names>K.</given-names></name>
<name><surname>Katz</surname><given-names>R.</given-names></name>
<name><surname>Fien</surname><given-names>H.</given-names></name>
<name><surname>Seeley</surname><given-names>J.</given-names></name>
<name><surname>Kame’enui</surname><given-names>E. J.</given-names></name>
<name><surname>Thomas Beck</surname><given-names>C.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Reading fluency as a predictor of reading proficiency in low-performing high poverty schools</article-title>. <source>School Psychology Review</source>, <volume>37</volume>, <fpage>18</fpage>–<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr6-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Betts</surname><given-names>J.</given-names></name>
<name><surname>Pickart</surname><given-names>M.</given-names></name>
<name><surname>Heistad</surname><given-names>D.</given-names></name>
</person-group> (<year>2009</year>). <article-title>An investigation of the psychometric evidence of CBM-R passage equivalence: Utility of readability statistics and equating for alternate forms</article-title>. <source>Journal of School Psychology</source>, <volume>47</volume>, <fpage>1</fpage>–<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jsp.2008.09.001</pub-id></citation>
</ref>
<ref id="bibr7-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Biancarosa</surname><given-names>G.</given-names></name>
<name><surname>Bryk</surname><given-names>A. S.</given-names></name>
<name><surname>Dexter</surname><given-names>E. R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Assessing the value-added effects of literacy collaborative professional development on student learning</article-title>. <source>Elementary School Journal</source>, <volume>111</volume>, <fpage>7</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr8-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Breusch</surname><given-names>T. S.</given-names></name>
<name><surname>Pagan</surname><given-names>A. R.</given-names></name>
</person-group> (<year>1979</year>). <article-title>A simple test for heteroscedasticity and random coefficient variation</article-title>. <source>Econometrica</source>, <volume>47</volume>, <fpage>1287</fpage>–<lpage>1294</lpage>.</citation>
</ref>
<ref id="bibr9-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Christ</surname><given-names>T. J.</given-names></name>
<name><surname>Ardoin</surname><given-names>S. P.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Curriculum-based measurement of oral reading: Passage equivalence and probe-set development</article-title>. <source>Journal of School Psychology</source>, <volume>47</volume>, <fpage>55</fpage>–<lpage>75</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jsp.2008.09.004</pub-id></citation>
</ref>
<ref id="bibr10-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Christ</surname><given-names>T. J.</given-names></name>
<name><surname>Silberglitt</surname><given-names>B.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Curriculum-based measurement of oral reading fluency: The standard error of measurement</article-title>. <source>School Psychology Review</source>, <volume>36</volume>, <fpage>130</fpage>–<lpage>146</lpage>.</citation>
</ref>
<ref id="bibr11-1534508412456729">
<citation citation-type="book">
<collab>Dynamic Measurement Group</collab>. (<year>2008</year>). <source>DIBELS 6th edition technical adequacy information</source>. (Technical Report No. 6). <publisher-loc>Eugene, OR</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr12-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Francis</surname><given-names>D. J.</given-names></name>
<name><surname>Santi</surname><given-names>K. L.</given-names></name>
<name><surname>Barr</surname><given-names>C.</given-names></name>
<name><surname>Fletcher</surname><given-names>J. M.</given-names></name>
<name><surname>Varisco</surname><given-names>A.</given-names></name>
<name><surname>Foorman</surname><given-names>B. R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Form effects on the estimation of students’ oral reading fluency using DIBELS</article-title>. <source>Journal of School Psychology</source>, <volume>46</volume>, <fpage>315</fpage>–<lpage>342</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jsp.2007.06.003</pub-id></citation>
</ref>
<ref id="bibr13-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gelman</surname><given-names>A.</given-names></name>
<name><surname>Hill</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <source>Data analysis using regression and multilevel/hierarchical models</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr14-1534508412456729">
<citation citation-type="gov">
<person-group person-group-type="author">
<name><surname>Gersten</surname><given-names>R. M.</given-names></name>
<name><surname>Compton</surname><given-names>D.</given-names></name>
<name><surname>Connor</surname><given-names>C. M.</given-names></name>
<name><surname>Dimino</surname><given-names>J.</given-names></name>
<name><surname>Santoro</surname><given-names>L.</given-names></name>
<name><surname>Linan-Thompson</surname><given-names>S.</given-names></name>
<name><surname>Tilly</surname><given-names>W. D.</given-names></name>
</person-group> (<year>2009</year>). <source>Assisting students struggling with reading: Response to Intervention and multi-tier intervention for reading in the primary grades: A practice guide</source> (No. NCE 2009-4045). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Center for Education Evaluation and Regional Assistance, Institute of Education Sciences, U.S. Department of Education</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://ies.ed.gov/ncee/wwc/publications/practiceguides/">http://ies.ed.gov/ncee/wwc/publications/practiceguides/</ext-link></citation>
</ref>
<ref id="bibr15-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Good</surname><given-names>R. H.</given-names></name>
<name><surname>Kaminski</surname><given-names>R.</given-names></name>
</person-group> (<year>2002</year>). <source>Dynamic Indicators of Basic Early Literacy Skills</source> (<edition>6th ed.</edition>). <publisher-loc>Eugene, OR</publisher-loc>: <publisher-name>Institute for the Development of Education Achievement</publisher-name>.</citation>
</ref>
<ref id="bibr16-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Holland</surname><given-names>P. W.</given-names></name>
<name><surname>Thayer</surname><given-names>D. T.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Univariate and bivariate loglinear models for discrete test score distributions</article-title>. <source>Journal of Educational and Behavioral Statistics</source>, <volume>25</volume>, <fpage>133</fpage>–<lpage>183</lpage>. doi:<pub-id pub-id-type="doi">10.3102/10769986025002133</pub-id></citation>
</ref>
<ref id="bibr17-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klein</surname><given-names>A.</given-names></name>
<name><surname>Moosbrugger</surname><given-names>H.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Maximum likelihood estimation of latent interaction effects with the LMS method</article-title>. <source>Psychometrika</source>, <volume>65</volume>, <fpage>457</fpage>–<lpage>474</lpage>. doi:<pub-id pub-id-type="doi">10.1007/bf02296338</pub-id></citation>
</ref>
<ref id="bibr18-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klein</surname><given-names>A.</given-names></name>
<name><surname>Muthén</surname><given-names>B. O.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Quasi-maximum likelihood estimation of structural equation models with multiple interaction and quadratic effects</article-title>. <source>Multivariate Behavioral Research</source>, <volume>42</volume>, <fpage>647</fpage>–<lpage>673</lpage>.</citation>
</ref>
<ref id="bibr19-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kolen</surname><given-names>M. J.</given-names></name>
<name><surname>Brennan</surname><given-names>R. L.</given-names></name>
</person-group> (<year>2004</year>). <source>Test equating, scaling, and linking: Methods and practices</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr20-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McDonald</surname><given-names>R. P.</given-names></name>
</person-group> (<year>1967</year>). <source>Nonlinear factor analysis</source> (Psychometric Monograph No. 15). <publisher-loc>Richmond, VA</publisher-loc>: <publisher-name>William Byrd Press</publisher-name>.</citation>
</ref>
<ref id="bibr21-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Moses</surname><given-names>T.</given-names></name>
</person-group> (<year>2008</year>). <source>An evaluation of statistical strategies for making equating function selections</source> (Research Report No. ETS RR-08-60). <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>ETS</publisher-name>.</citation>
</ref>
<ref id="bibr22-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Muthén</surname><given-names>L. K.</given-names></name>
<name><surname>Muthén</surname><given-names>B. O.</given-names></name>
</person-group> (<year>2010</year>). <source>Mplus user’s guide (version 6)</source>. <publisher-loc>Los Angeles, CA</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr23-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Pinheiro</surname><given-names>J. C.</given-names></name>
<name><surname>Bates</surname><given-names>D. M.</given-names></name>
</person-group> (<year>2000</year>). <source>Mixed-effects models in S and S-PLUS</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr24-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Poncy</surname><given-names>B. C.</given-names></name>
<name><surname>Skinner</surname><given-names>C. H.</given-names></name>
<name><surname>Axtell</surname><given-names>P. K.</given-names></name>
</person-group> (<year>2005</year>). <article-title>An investigation of the reliability and standard error of measurement of words read correctly per minute using curriculum-based measurement</article-title>. <source>Journal of Psychoeducational Assessment</source>, <volume>23</volume>, <fpage>326</fpage>–<lpage>338</lpage>.</citation>
</ref>
<ref id="bibr25-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roberts</surname><given-names>G.</given-names></name>
<name><surname>Good</surname><given-names>R.</given-names></name>
<name><surname>Corcoran</surname><given-names>S.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Story retell: A fluency-based indicator of reading comprehension</article-title>. <source>School Psychology Quarterly</source>, <volume>20</volume>, <fpage>304</fpage>–<lpage>317</lpage>.</citation>
</ref>
<ref id="bibr26-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roehrig</surname><given-names>A. D.</given-names></name>
<name><surname>Petscher</surname><given-names>Y.</given-names></name>
<name><surname>Nettles</surname><given-names>S. M.</given-names></name>
<name><surname>Hudson</surname><given-names>R. F.</given-names></name>
<name><surname>Torgesen</surname><given-names>J. K.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Accuracy of the DIBELS oral reading fluency measure for predicting third grade reading comprehension outcomes</article-title>. <source>Journal of School Psychology</source>, <volume>46</volume>, <fpage>343</fpage>–<lpage>366</lpage>.</citation>
</ref>
<ref id="bibr27-1534508412456729">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Salvia</surname><given-names>J.</given-names></name>
<name><surname>Ysseldyke</surname><given-names>J. E.</given-names></name>
<name><surname>Bolt</surname><given-names>S.</given-names></name>
</person-group> (<year>2010</year>). <source>Assessment in special and inclusive education</source> (<edition>11th ed.</edition>). <publisher-loc>Belmont, CA</publisher-loc>: <publisher-name>Wadsworth</publisher-name>.</citation>
</ref>
<ref id="bibr28-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Satorra</surname><given-names>A.</given-names></name>
<name><surname>Bentler</surname><given-names>P.</given-names></name>
</person-group> (<year>2001</year>). <article-title>A scaled difference chi-square test statistic for moment structure analysis</article-title>. <source>Psychometrika</source>, <volume>66</volume>, <fpage>507</fpage>–<lpage>514</lpage>.</citation>
</ref>
<ref id="bibr29-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schilling</surname><given-names>S.</given-names></name>
<name><surname>Carlisle</surname><given-names>J.</given-names></name>
<name><surname>Scott</surname><given-names>S. E.</given-names></name>
<name><surname>Zeng</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Are fluency measures accurate predictors of reading achievement?</article-title> <source>Elementary School Journal</source>, <volume>107</volume>, <fpage>429</fpage>–<lpage>448</lpage>.</citation>
</ref>
<ref id="bibr30-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Skiba</surname><given-names>R.</given-names></name>
<name><surname>Simmons</surname><given-names>A.</given-names></name>
<name><surname>Ritter</surname><given-names>S.</given-names></name>
<name><surname>Gibb</surname><given-names>A.</given-names></name>
<name><surname>Rausch</surname><given-names>M.</given-names></name>
<name><surname>Cuadrado</surname><given-names>J.</given-names></name>
<name><surname>Chung</surname><given-names>C.-G.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Achieving equity in special education: History, status, and current challenges</article-title>. <source>Exceptional Children</source>, <volume>74</volume>, <fpage>264</fpage>–<lpage>288</lpage>.</citation>
</ref>
<ref id="bibr31-1534508412456729">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stecker</surname><given-names>P. M.</given-names></name>
<name><surname>Fuchs</surname><given-names>L. S.</given-names></name>
<name><surname>Fuchs</surname><given-names>D.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Using curriculum-based measurement to improve student achievement: Review of research</article-title>. <source>Psychology in the Schools</source>, <volume>42</volume>, <fpage>795</fpage>–<lpage>819</lpage>. doi:<pub-id pub-id-type="doi">10.1002/pits.20113</pub-id></citation>
</ref>
</ref-list>
</back>
</article>