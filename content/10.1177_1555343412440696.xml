<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EDM</journal-id>
<journal-id journal-id-type="hwp">spedm</journal-id>
<journal-title>Journal of Cognitive Engineering and Decision Making</journal-title>
<issn pub-type="ppub">1555-3434</issn>
<issn pub-type="epub">XXXX-XXXX</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1555343412440696</article-id>
<article-id pub-id-type="publisher-id">10.1177_1555343412440696</article-id>
<title-group>
<article-title>Evaluation of an Ecological Interface Design for Military Command and Control</article-title>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Bisantz</surname><given-names>Ann M.</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Bass</surname><given-names>Ellen J.</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Ockerman</surname><given-names>Jennifer J.</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Hall</surname><given-names>Daniel S.</given-names></name>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Shattuck</surname><given-names>Lawrence G.</given-names></name>
</contrib>
<aff id="aff1-1555343412440696">Naval Postgraduate School</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Bennett</surname><given-names>Kevin B.</given-names></name>
</contrib>
<aff id="aff2-1555343412440696">Wright State University</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1555343412440696">Lawrence G. Shattuck, Naval Postgraduate School, 32676 Coast Ridge Rd., Carmel, CA 93923-9742, <email>lgshattu@nps.edu</email>.</corresp>
<fn fn-type="other" id="bio1-1555343412440696">
<p>Daniel S. Hall is an instructor of engineering psychology at the U.S. Military Academy, West Point, New York. He received his MS in human systems integration from the Naval Postgraduate School in 2007. He is an Armor/Cavalry Officer in the U.S. Army.</p>
</fn>
<fn fn-type="other" id="bio2-1555343412440696">
<p>Lawrence G. Shattuck is a senior lecturer and codirector of the Human Systems Integration Program at the Naval Postgraduate School. He received his PhD in cognitive systems engineering from The Ohio State University in 1995. He is a retired U.S. Army Colonel with 30 years of military service.</p>
</fn>
<fn fn-type="other" id="bio3-1555343412440696">
<p>Kevin B. Bennett is a professor of psychology at Wright State University, Dayton, Ohio. He received a PhD from the Catholic University of America in 1984. He is a fellow of the Human Factors and Ergonomics Society and an editorial board member of <italic>Human Factors</italic>. His research interests lie in the use of cognitive systems engineering and ecological interface design to improve human-computer interaction.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>6</month>
<year>2012</year>
</pub-date>
<volume>6</volume>
<issue>2</issue>
<issue-title>Special Issue: Innovations in Cognitive Engineering and Decision Making, Part II</issue-title>
<fpage>165</fpage>
<lpage>193</lpage>
<permissions>
<copyright-statement>© 2012 Human Factors and Ergonomics Society</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Human Factors and Ergonomics Society</copyright-holder>
</permissions>
<abstract>
<p>Two alternative interfaces developed for military command and control were evaluated. The theoretical frameworks and concepts used during their development are discussed, and the findings are related to larger issues in display, interface, and system design. Key aspects of cognitive systems engineering (CSE) and ecological interface design (EID) are discussed. An ecological interface was designed with principles of direct perception, direct manipulation, and visual momentum. An experimental version of an existing interface was also developed. An experiment was conducted with a synthetic task environment that incorporated scenarios of tactical operations. Participants were experienced army officers. Dependent variables included status reports for friendly and enemy resources and activities, subjective workload, and information access. Significant results favoring the ecological interface were obtained for six of seven dependent measures. The ecological interface was easy to learn, easy to use, and dramatically more effective than the existing interface. The results are interpreted from the CSE-EID perspective, but insights from naturalistic decision making and situation awareness are also described. The specific design features of the ecological interface are directly applicable to military command and control and similar domains; the overall CSE-EID approach is applicable to interface design for all work domains.</p>
</abstract>
<kwd-group>
<kwd>cognitive systems engineering</kwd>
<kwd>visual displays</kwd>
<kwd>ecological interface design</kwd>
<kwd>tactical operations</kwd>
<kwd>direct perception</kwd>
<kwd>direct manipulation</kwd>
<kwd>visual momentum</kwd>
<kwd>decision support</kwd>
<kwd>distributed supervisory control systems</kwd>
<kwd>military command and control</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1555343412440696" sec-type="intro">
<title>Introduction</title>
<p>A<sc>dvances in computational hardware and software provide system designers with</sc> the potential to build displays and interfaces that leverage the powerful perception, action, and cognitive capabilities of human agents. However, this potential is not being realized on a regular basis, as evidenced by the complicated and inefficient interfaces that confront workers in sociotechnical systems daily. Cognitive systems engineering (CSE; <xref ref-type="bibr" rid="bibr23-1555343412440696">Rasmussen, Pejtersen, &amp; Goodstein, 1994</xref>) is a comprehensive conceptual framework for the analysis, design, and evaluation of systems. Ecological interface design (EID; <xref ref-type="bibr" rid="bibr24-1555343412440696">Rasmussen &amp; Vicente, 1989</xref>, <xref ref-type="bibr" rid="bibr31-1555343412440696">1990</xref>; Vicente &amp; <xref ref-type="bibr" rid="bibr25-1555343412440696">Rasmussen, 1990</xref>, <xref ref-type="bibr" rid="bibr32-1555343412440696">1992</xref>) is a complementary framework that focuses on the design of effective displays and interfaces. The primary purpose of the CSE-EID approach is to provide decision-making and problem-solving support for a user who is completing work in a domain, thereby closing the gap alluded to previously. The ultimate goal is to design interfaces that (a) are tailored to specific work demands, (b) leverage the powerful perception-action skills of the human, and (c) use powerful interface technologies wisely.</p>
<p>An overview of the CSE-EID approach from a systems-level perspective is illustrated in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref>. <xref ref-type="bibr" rid="bibr5-1555343412440696">Bennett and Flach (2011)</xref> have described this approach as “triadic,” referring to the three components (work domain, interface, agent) that form its core. Each of these three components contributes a set of mutually interacting constraints that determine the overall effectiveness of the system. Ultimately, success or failure depends on the quality of a very specific set of mappings that arise between these three sets of constraints (symbolically represented by the pie-shaped wedges representing puzzle pieces that must fit together well).</p>
<fig id="fig1-1555343412440696" position="float">
<label>Figure 1.</label>
<caption>
<p>The three sets of behavioral-shaping constraints in a sociotechnical system. Adapted from <italic>Display and Interface Design: Subtle Science, Exact Art</italic> (p. 112), by <xref ref-type="bibr" rid="bibr5-1555343412440696">K. B. Bennett and J. M. Flach, 2011</xref>, Boca Raton, FL: CRC Press. Copyright 2011 by the Taylor and Francis Group. Adapted with permission.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig1.tif"/>
</fig>
<p>As its name implies, the starting point for EID is an understanding of the work domain itself. CSE provides a set of analytical tools (i.e., abstraction and aggregation hierarchies) that are used to conduct work domain analyses (WDA; <xref ref-type="bibr" rid="bibr23-1555343412440696">Rasmussen et al., 1994</xref>; <xref ref-type="bibr" rid="bibr30-1555343412440696">Vicente, 1999</xref>). The end result is a description of the kinds of information and relationships in the domain that must be considered for effective control to be achieved (i.e., the “affordances” of the domain). Human perception, action, and cognitive capabilities and limitations must also be considered in light of the critical role of system supervisor and controller. In many ways, the ultimate purpose of EID is focused on respecting the constraints of the human as a system component (e.g., leveraging powerful perception-action skills; avoiding mental computations when possible).</p>
<p>The interface in computer-mediated systems also contributes a set of constraints on performance, since it is the medium through which the agent views (display surfaces) and acts on (control surfaces) the work domain. As the positioning of the interface component in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref> suggests, there are two sets of mappings that are critical. One relationship involves the mapping between the ecology and the informational content of the interface: Is critical information regarding the work domain present in the interface? Are required control inputs supported? A second relationship involves the mapping between the domain practitioner and informational formats in the interface: Do the display representations allow domain information to be picked up easily? Do the control surfaces allow inputs to be executed efficiently? There are three global principles of EID that can be used to ensure that these mappings are effective: direct perception, direct manipulation, and visual momentum (<xref ref-type="bibr" rid="bibr5-1555343412440696">Bennett &amp; Flach, 2011</xref>). More detailed descriptions and examples of these principles will be provided in the next section.</p>
<sec id="section2-1555343412440696">
<title>EID for Military Command and Control</title>
<p>The Representation Aiding Portrayal of Tactical Operations Resources (RAPTOR) interface was designed to support mobile army commanders during tactical operations. The project began more than a decade ago and from its inception has used the CSE-EID approach to guide analysis, design, and evaluation efforts. The project has engaged army personnel extensively and in a variety of roles, which include project investigators (four army officers), scientific advisors (numerous researchers in army laboratories), and subject matter experts (officers serving as consultants and participants). <xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett, Posey, and Shattuck (2008)</xref> provide a detailed description of the work domain analyses that were conducted as well as the ways in which the products of these analyses were used to inform design. In this article, we describe the capstone evaluation of the RAPTOR interface. We begin with a more complete description of the three principles of EID that were introduced in the previous section and the ways in which they were realized in the RAPTOR interface.</p>
<sec id="section3-1555343412440696">
<title>Direct perception</title>
<p>The principle of direct perception refers to the quality of mappings between the display surfaces in the interface, the domain, and the agent (see <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref>). Issues in achieving direct perception have been investigated extensively for analogical displays that are used to represent higher-order relationships (those between variables, properties, goals, and boundaries) in a work domain. The term <italic>configural</italic> has been used to refer to displays that use analog representations (e.g., geometrical forms) to represent domain variables or properties that have continuous incremental changes. These displays will produce higher-order visual properties, often referred to as emergent features (e.g., horizontal and vertical extent, parallelism, symmetry). The key to effective configural display design involves the mapping between display and agent constraints: The emergent features that the display produces must be salient to the observer (i.e., conspicuous or readily perceived), and they must reflect underlying domain constraints (<xref ref-type="bibr" rid="bibr3-1555343412440696">Bennett &amp; Flach, 1992</xref>, <xref ref-type="bibr" rid="bibr5-1555343412440696">2011</xref>; <xref ref-type="bibr" rid="bibr6-1555343412440696">Bennett, Nagy, &amp; Flach, 1997</xref>). When these mappings are effective, there will be a one-to-one correspondence between changes in the visual appearance of the display and changes in the underlying work domain. Thus, achieving direct perception means that it is possible for agents to easily perceive the state of the system through consistent patterns in the displays. A variety of configural displays contributed to the realization of direct perception in the RAPTOR interface (see <xref ref-type="fig" rid="fig2-1555343412440696">Figure 2</xref>). We will discuss one example in detail.</p>
<fig id="fig2-1555343412440696" position="float">
<label>Figure 2.</label>
<caption>
<p>Overview of Representation Aiding Portrayal of Tactical Operations Resources (RAPTOR) interface. Adapted from “Ecological Interface Design for Military Command and Control,” by <xref ref-type="bibr" rid="bibr7-1555343412440696">K. B. Bennett, S. M. Posey, and L. G. Shattuck, 2008</xref>, <italic>Journal of Cognitive Engineering and Decision Making, 2</italic>(4), p. 362. Copyright 2008 by the Human Factors and Ergonomics Society. Adapted with permission.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig2.tif"/>
</fig>
<p>The work domain analyses (<xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett et al., 2008</xref>) revealed that a fundamental consideration during tactical operations is “force ratio”: the relative amount of combat power that exists between two opposing forces at any point in time. Commanders and their staff develop detailed estimates of planned force ratios during an engagement and monitor actual values for discrepancies across the course of an engagement. Thus, force ratio also constitutes an affordance of the domain: Decisions to initiate, continue, alter (e.g., choose another course of action [COA]), or abort a mission will be based on its value. Two complementary displays were developed to represent this critical information.</p>
<p>The force ratio display is illustrated in <xref ref-type="fig" rid="fig3-1555343412440696">Figure 3</xref>, on the right. The primary graphical format used in this display is the “contribution” bar graph. Each bar graph contains segments that represent the contributions to combat power made by tanks and armored personnel carriers (actually, “force equivalence” is used, a rating system that provides a “common denominator” across different types of friendly and enemy combat vehicles). There is a contribution bar graph for both friendly (top) and enemy (bottom) combat power. Each bar graph also distinguishes between available (left segments) and disabled vehicles (right segments, offset in space). Each bar graph display specifies friendly and enemy force equivalence through the fundamental emergent feature of horizontal extent. The horizontal extent of two bar graphs relative to each other is a higher-order emergent feature that specifies force ratio. Thus, a force ratio of approximately 3 to 1 is specified in <xref ref-type="fig" rid="fig3-1555343412440696">Figure 3</xref> by the fact that the friendly force equivalence bar graph (top) is approximately 3 times longer than the enemy bar graph.</p>
<fig id="fig3-1555343412440696" position="float">
<label>Figure 3.</label>
<caption>
<p>Force ratio and force ratio trend displays. Adapted from “Ecological Interface Design for Military Command and Control,” by <xref ref-type="bibr" rid="bibr7-1555343412440696">K. B. Bennett, S. M. Posey, and L. G. Shattuck, 2008</xref>, <italic>Journal of Cognitive Engineering and Decision Making, 2</italic>(4), p. 366. Copyright 2008 by the Human Factors and Ergonomics Society. Adapted with permission.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig3.tif"/>
</fig>
<p>The force ratio trend display (left side of <xref ref-type="fig" rid="fig3-1555343412440696">Figure 3</xref>) specifies the actual and planned values of force ratio over time. The display is scaled toward a vanishing point to the left according to the laws of perspective geometry. The trend lines produce emergent features that specify the direction and the rate of change for actual and planned values of force ratio across the engagement. The degree of spatial separation between these trend lines is a higher-order emergent feature that visually specifies discrepancy from plan. This visual property could serve as an early warning that alternative COAs need to be considered or that replanning needs to be initiated.</p>
<p>The display geometries of the force ratio and force ratio trend displays were designed to produce a more detailed visual explanation of force ratio. A force ratio “reflecting line” is connected to the two contribution bar graphs via graphical “ball” joints (<xref ref-type="bibr" rid="bibr29-1555343412440696">Vicente, 1991</xref>). Changes in the horizontal extent of the smaller bar graph (the enemy bar graph in <xref ref-type="fig" rid="fig3-1555343412440696">Figure 3</xref>) push (or pull) the endpoint of the line, thereby changing its orientation (an emergent feature that also specifies force ratio). Changes in the horizontal extent of the larger bar graph push (or pull) the entire force ratio trend display away (or toward) the force ratio display. The end result of these display geometries is that the force ratio reflecting line always intersects the <italic>y</italic>-axis of the force ratio trend display at the exact spot that corresponds to the current value of force ratio.</p>
<p>An example of the dynamic behavior of these displays over time is provided in <xref ref-type="fig" rid="fig4-1555343412440696">Figure 4</xref>. The enemy begins with an advantage in force ratio of approximately 2.5 to 1 (expressed as 1:2.5 in <xref ref-type="fig" rid="fig4-1555343412440696">Figure 4a</xref>). During the course of the engagement (slightly more than 3 hr), this advantage is lost, and in <xref ref-type="fig" rid="fig4-1555343412440696">Figure 4d</xref>, friendly forces have an advantage in force ratio of approximately 4:1.</p>
<fig id="fig4-1555343412440696" position="float">
<label>Figure 4.</label>
<caption>
<p>Force ratio and force ratio trend displays during the course of a 3-hr engagement. Adapted from “Ecological Interface Design for Military Command and Control,” by <xref ref-type="bibr" rid="bibr7-1555343412440696">K. B. Bennett, S. M. Posey, and L. G. Shattuck, 2008</xref>, <italic>Journal of Cognitive Engineering and Decision Making, 2</italic>(4), p. 368. Copyright 2008 by the Human Factors and Ergonomics Society. Adapted with permission.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig4.tif"/>
</fig>
<p><xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett et al. (2008)</xref> provide detailed descriptions of all of the specifically crafted displays that support direct perception in the RAPTOR interface; we provide only a brief overview here. The friendly combat resources display format allows the commander to monitor friendly resources throughout the engagement at all levels of the organizational structure (via the primary and secondary display slots). The enemy combat resource display supports the same general capability for enemy forces, including uncertainty. Commanders also need to monitor the status of these resources within the context of planned mission activities (i.e., planned vs. actual expenditures). A review mode was provided to meet these needs, including specialized modifications of normal displays and the capability to view graphical “replays” and “preplays” of the engagement. The commander also needs to coordinate and synchronize the activities of the various units across both space and time. This need is supported by the spatial and temporal synchronization matrix displays, which provide coordinated information, including battlefield geography and critical landmarks, unit locations and activities, weapons and travel ranges, spatial routes and synchronization points, and alternative COAs.</p>
</sec>
<sec id="section4-1555343412440696">
<title>Direct manipulation</title>
<p>The principle of direct manipulation maintains that the control surfaces of an interface should allow the agent to execute control input directly (and perhaps “naturally”) using powerful perceptual motor skills. An example of direct manipulation is the familiar “point, click, drag, and drop” action sequence that is commonly required to delete a file on personal computers. The agent acts directly on an object of interest in the interface. Compare this action to the execution of control input via a command line or pull-down menu. In such an instance, the agent is essentially providing a description of the action to be performed to the computer.</p>
<p>Direct manipulation was achieved in the RAPTOR interface (<xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett et al., 2008</xref>) through a variety of control input mechanisms. There is no command line; there are no pull-down menus. The agent executes all actions directly on objects in the interface. For example, the agent can point at, click on, and drag a representation of the spatial (i.e., a labeled circle) or temporal (i.e., a vertical line) parameters that define a synchronization point (see <xref ref-type="fig" rid="fig2-1555343412440696">Figure 2</xref>) to change its value. Similarly, the agent can point-click-drag a graphical slider to view a graphical summary of the tactical engagement as it unfolded over time (i.e., the location of the slider on its track corresponds to a point in time). The agent can also point and click on a variety of icons or buttons to execute discrete control inputs that produce categorical changes in the information that is displayed. This input includes the selection of alternative maps, weapons or logistic overlays, COAs, and displays of unit-related information (e.g., battalion-, company-, platoon-, vehicle-, or soldier-level resources).</p>
</sec>
<sec id="section5-1555343412440696">
<title>Visual momentum</title>
<p>The principle of visual momentum (e.g., <xref ref-type="bibr" rid="bibr34-1555343412440696">Woods, 1984</xref>) refers to the extent to which an interface supports the agent in perceptual and cognitive transitions that occur between display screens, within a display screen, or within a display itself. Visual momentum will be high if the interface resources in the first scene (i.e., window or view) create expectancies that are realized in the second scene; smoothly coordinated transitions will ensue. Conversely, clumsy transitions (e.g., the “getting lost” phenomenon and the “keyhole” effect) will occur when interface resources create expectancies that are subsequently violated. <xref ref-type="bibr" rid="bibr34-1555343412440696">Woods (1984</xref>; <xref ref-type="bibr" rid="bibr33-1555343412440696">Watts-Perotti &amp; Woods, 1999</xref>) proposed a number of general design techniques that can be used to increase visual momentum. All of these techniques do so through the design of interface resources that provide effective <italic>cognitive couplings</italic> between agent and work domain. A number of these techniques were used in the RAPTOR interface to increase visual momentum.</p>
<p>For example, an integrated design solution was required for a particularly difficult problem: viewing friendly combat resources. This information constitutes a complex database: The five combat resources (tanks, Bradleys, ammunition, fuel, personnel) need to be viewed at a variety of hierarchically nested levels (one battalion, four companies, 12 platoons, approximately 50 vehicles, and hundreds of soldiers). Of course, limited display real estate precludes the simultaneous presentation of all information in the database; interface resources that allow the commander to choose between selective “glances” into this database (and to smooth the segues between these glances) were required.</p>
<p>Visual momentum was increased via the implementation of several of <xref ref-type="bibr" rid="bibr34-1555343412440696">Woods’s (1984</xref>; <xref ref-type="bibr" rid="bibr33-1555343412440696">Watts-Perotti &amp; Woods, 1999</xref>) techniques. The control tree (see <xref ref-type="fig" rid="fig2-1555343412440696">Figure 2</xref>) is a combined display and control surface that provides an example of the “long shot” technique. It provides a structural overview of the battalion’s combat resources (i.e., a “road map” display of the units and their organizational relationships), illustrating where the agent is (i.e., the highlighted node) and where he or she might navigate to (i.e., the remaining nodes). Navigation through the database is accomplished by pointing at (i.e., rolling over) or clicking on an alternative node (i.e., the control component); this action changes the combat resource information that is currently being displayed in the primary and secondary display slots (see following paragraph). Thus, this combined display and control increases visual momentum by mitigating the getting-lost phenomenon.</p>
<p>The primary and secondary display slots include two additional design techniques to increase visual momentum. The primary slot displays the combat resources of a superordinate unit (e.g., battalion), and the secondary slot displays those of its subordinate units (e.g., companies). These two displays include both the “fixed-format data replacement” (i.e., dedicated display real estate with variable content) and the “display overlap” (i.e., simultaneously displaying two levels of aggregation) techniques. Visual momentum is increased by providing a consistent viewing context that avoids the need for cognitive reorientation across successive glances (i.e., similar formats across the various units) and a “widening of the keyhole” through which the agent is able to view the underlying database (i.e., simultaneous presentation of both superordinate and subordinate units). See <xref ref-type="bibr" rid="bibr4-1555343412440696">Bennett and Flach (2012)</xref> for a more detailed discussion of how visual momentum is supported in the RAPTOR interface (and in other interfaces as well).</p>
</sec>
</sec>
<sec id="section6-1555343412440696">
<title>Gratuitously Graphical User Interface (GGUI)</title>
<p>A study was conducted to evaluate the RAPTOR interface and a second interface (see <xref ref-type="fig" rid="fig5-1555343412440696">Figure 5</xref> for an overview). This second interface was based on the army’s Force XXI Battle Command Brigade and Below (FBCB2) interface; the experimental version used in this study replicates all fundamental aspects (i.e., representational forms and information structures) of the FBCB2 interface with only superficial differences in appearance. The buttons on the right side of the interface (e.g., “FIPR 16”) are used to initiate information access. For example, pointing and clicking on the FIPR 16 button produces the FIPR Messages window (see <xref ref-type="fig" rid="fig6-1555343412440696">Figure 6a</xref>), containing four tabs (“flash,” “immediate,” “priority,” “routine”) and a list of messages (e.g., “LOGSTAT CO B . . .”) associated with the activated tab (e.g., ROUTINE). Pointing and clicking on one of these messages produces a window containing a report that uses alphanumeric data fields (see <xref ref-type="fig" rid="fig6-1555343412440696">Figure 6b</xref>) to represent information (e.g., combat resources) for a combat unit. Examples of the various report types and information templates associated with the FIPR tabs are illustrated in <xref ref-type="fig" rid="fig6-1555343412440696">Figure 6c</xref>.</p>
<fig id="fig5-1555343412440696" position="float">
<label>Figure 5.</label>
<caption>
<p>The default appearance of the gratuitously graphical user interface. This experimental interface replicates all of the fundamental aspects of the army’s Force XXI Battle Command Brigade and Below interface (i.e., representational forms and information structures) with some superficial differences in visual appearance.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig5.tif"/>
</fig>
<fig id="fig6-1555343412440696" position="float">
<label>Figure 6.</label>
<caption>
<p>The gratuitously graphical user interface during a typical information search. Pointing and clicking on buttons and tabs (<xref ref-type="fig" rid="fig6-1555343412440696">Figure 6a</xref>) produces a variety of pop-up windows (<xref ref-type="fig" rid="fig6-1555343412440696">Figure 6b</xref>) that contain a variety of alphanumeric data fields (<xref ref-type="fig" rid="fig6-1555343412440696">Figure 6c</xref>).</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig6.tif"/>
</fig>
<p>This interface is a GUI in the sense that it requires interaction with a “model world” (e.g., <xref ref-type="bibr" rid="bibr16-1555343412440696">Hutchins, Hollan, &amp; Norman, 1986</xref>) as opposed to a “linguistic conversation” (e.g., command-line interfaces, such as DOS or UNIX). As illustrated in <xref ref-type="fig" rid="fig5-1555343412440696">Figures 5</xref> and <xref ref-type="fig" rid="fig6-1555343412440696">6</xref>, the user points and clicks on buttons and tabs, ultimately producing windows that contain the information of interest (e.g., the combat resources of a specific unit). However, the powerful graphical capabilities are squandered on these windows, tabs, and buttons; all critical domain information is represented alphanumerically as opposed to graphically. For example, all current levels of combat resources are represented by alphanumeric labels and digital values (see <xref ref-type="fig" rid="fig6-1555343412440696">Figure 6c</xref>) as opposed to analogical representations (see the bar graphs in the primary and secondary display slots of <xref ref-type="fig" rid="fig3-1555343412440696">Figure 3</xref>). Thus, the meaning behind these representations must be mentally calculated, as opposed to being perceived directly. Elsewhere (<xref ref-type="bibr" rid="bibr8-1555343412440696">Bennett &amp; Shattuck, 2009</xref>) we have referred to this interface and the class of design solutions that it represents as a GGUI, since its graphics are essentially uncalled for, lacking good reason, or unwarranted (i.e., the definition of the word <italic>gratuitous</italic>).</p>
</sec>
</sec>
<sec id="section7-1555343412440696" sec-type="methods">
<title>Method</title>
<sec id="section8-1555343412440696">
<title>Participants</title>
<p>Sixteen male U.S. Army officers (2 lieutenant colonels, 14 majors) volunteered to participate. All were assigned to Maneuver, Fires, and Effects specialty branches (10 to 25 years of active-duty service) and ranged from 32 to 49 years of age. Fifteen had combat experience in either Iraq or Afghanistan (average of 15 months). All participants had previous command experience (average of 29 months). Twelve had previous experience using the FBCB2 interface either during tactical exercises or combat operations.</p>
</sec>
<sec id="section9-1555343412440696">
<title>Apparatus</title>
<p>All experimental events were controlled by identical computers (Dell Precision M6300 laptops, 777 MHz) with identical color displays (Dell UltraSharp WUXGA monitor, 17 in., 1,920 × 1,200 resolution).</p>
</sec>
<sec id="section10-1555343412440696">
<title>Synthetic Task Environment</title>
<p>The tactical scenarios were developed and implemented with the use of commercial simulation software (DDD 4.0, Aptima). All aspects of these scenarios (e.g., forces, missions, personnel, vehicles, weapons, sensors, terrain) were carefully constructed to be as realistic as possible. Friendly and enemy forces had mission goals and alternative COAs. Each scenario was a dynamic, continuous operation in which the exact sequence of unfolding events (e.g., resource expenditure, progress toward goals) depended on both global decisions (e.g., choice of a particular COA) and local interactions (e.g., engagement outcomes based on lethality and survivability of specific forces involved). The simulation parameters were quite detailed. For example, the functional capabilities of friendly and enemy vehicles (e.g., munitions, combat loads, fuel capacity and economy, maneuverability, speed, survivability) and weapons (e.g., range, number of rounds, reload times, lethality) were modeled after their real-world counterparts. Detailed descriptions of these simulations are provided in <xref ref-type="bibr" rid="bibr15-1555343412440696">Hall (2009)</xref>; we focus on global aspects of the tactical scenarios.</p>
<p>Three tactical scenarios were simulated. The offensive and defensive scenarios emulated conventional high-intensity conflicts in desert terrain based on training exercises conducted at the U.S. Army’s National Training Center. The counterinsurgency (COIN) scenario emulated a low-intensity conflict in urban terrain based on combat operations routinely conducted by U.S. Army forces in Iraq and Afghanistan. The friendly forces in each scenario consisted of a battalion-sized element configured as a task force (TF). The TF consisted of four company teams (TM A, B, C, and D) each with three platoons (e.g., PLT A1) containing various combinations of Abrams tanks and Bradley fighting vehicles. The TF also included a mortar platoon (four 120-mm self-propelled mortars) and a scout platoon (four high-mobility, multipurpose, wheeled vehicles). The offensive and COIN scenarios were used during the evaluation phase, and they will be described in greater detail.</p>
<p>The TF mission during the offensive scenario was to destroy enemy forces located within the battlespace. Tactical tasks included locating the forward edge of the enemy’s obstacle belt, establishing an attack-by-fire position with TM D, establishing multiple breach lanes through the enemy obstacle belt, conducting a forward passage of lines, and completing the destruction of enemy forces within a specified time frame. Three possible friendly COAs were planned. For a particular COA to be chosen, it had to meet specific criteria (i.e., critical events) at a decision point (DP). The first team to establish a breach lane through the enemy obstacle belt was the DP criterion. COA A (the default COA) was predicated on TM B’s establishing the first breach lane, thereby allowing TM D to assault the objective from the center. COA B (the preferred COA) was predicated on TM C’s establishing the first breach lane, thereby allowing TM D to assault the objective from the south. COA C was predicated on TM A’s establishing the first breach lane, thereby allowing TM D to assault the objective from the north.</p>
<p>The enemy force in the offensive scenario consisted of a company-sized element with additional capabilities. The company contained three platoons of infantry fighting vehicles (BMP-2) reinforced by one platoon of T-72 tanks. Each platoon contained three tactical vehicles (either all tanks or all BMP-2s). The enemy’s command vehicle (BMP-2) was also present on the battlefield. The enemy mission during the offensive scenario was to deny friendly forces the ability to continue their offensive operation to the west. The enemy conducted a defense in depth from dug-in fighting positions to increase its survivability. It employed its reserve T-72 tank platoon on the battlefield and conducted a counteroffensive into the friendly force’s exposed northern flank. The enemy also established a large, complex obstacle belt consisting of antitank mines and concertina wire to reduce friendly-force numerical superiority.</p>
<p>The TF mission during the COIN scenario was to disrupt enemy insurgent operations within the fictional town of Al Icia Maria. Tactical tasks included conducting raids against multiple specified objectives, destroying insurgent activity centers, clearing numerous avenues of approach, neutralizing a high-value individual (HVI), and exfiltrating from the battlespace. Three COAs were also planned for friendly forces in the COIN scenario. The DP criteria for implementing a given COA in this scenario were dependent on the HVI’s location within the battlespace. COA A (the default COA) was predicated on the HVI’s being located at Objective Dylan and required TM D to neutralize the HVI while TM B completed the enemy disruption by raiding Objective Bruce. COA B was predicated on the HVI’s not being located within Al Icia Maria and required TM C to complete the enemy disruption by raiding Objective Bruce. COA C (preferred COA) was predicated on the HVI’s being located in the vicinity of Objective Bruce and required TM A to neutralize the HVI at this objective.</p>
<p>The enemy force in the COIN scenario also consisted of a company-sized element with additional capabilities. However, unlike the offensive scenario, the enemy in the COIN scenario is an unconventional insurgent force operating either as individuals or in small teams consisting of three to four personnel. Lone enemy elements employed suicide attacks using vehicle-borne improvised explosive devices (VBIEDs; car bombs). Enemy teams conducted anti-armor ambushes and limited indirect-fire engagements. The enemy mission during the COIN scenario was to enable the HVI to exfiltrate from the battlespace by delaying friendly-force penetration into insurgent support zones. The enemy conducted multiple anti-armor ambushes from prepared fighting positions located within several structures to increase their survivability. The enemy attacked friendly forces with VBIEDs and indirect mortar fires. The enemy also employed antitank mines and numerous IEDs (roadside bombs) to reduce friendly-force numerical and technological superiority.</p>
</sec>
<sec id="section11-1555343412440696">
<title>Interfaces</title>
<p>A detailed description of the RAPTOR interface is provided in <xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett et al. (2008)</xref>. All fundamental aspects of the controls and displays of the RAPTOR interface remain the same in the present study; the only modifications involved the incorporation of more detailed information required to accommodate the expanded scenarios. Fundamental aspects of the representational conventions (alphanumeric) and information access (buttons, tabs, windows, data fields) procedures for the GGUI are provided in the Introduction (see <xref ref-type="fig" rid="fig5-1555343412440696">Figures 5</xref> and <xref ref-type="fig" rid="fig6-1555343412440696">6</xref>). A complete description can be found in <xref ref-type="bibr" rid="bibr15-1555343412440696">Hall (2009)</xref>.</p>
<p>Information in the interfaces was supplemented by a binder containing a hard copy of the operations order (OPORD) for each scenario. These OPORDs were designed according to accepted army practices. They contained information regarding the organization of the TF, situation, mission, execution (e.g., COAs), service support, command and signal, and six appendices (e.g., Enemy Situation template). The information necessary to complete all experimental tasks correctly was always available in either the interface or the OPORD.</p>
</sec>
<sec id="section12-1555343412440696">
<title>Dependent Variables</title>
<p>Participants completed four information assessment tasks during testing. These tasks were developed to be consistent with standardized army reporting procedures and formats when possible. The Tactical Rating of Awareness for Combat Environments (TRACE) report emulated army situation reports. It contained 22 data fields associated with various quantitative (e.g., current number of operational friendly tanks), categorical (e.g., category status of fuel), and logical (e.g., current COA) facts that characterize past, present, and predicted status of friendly and enemy resources and activities. The Commander’s Critical Information Report (CCIR) contained fields for four critical events (and associated information) that were identified in the OPORD as particularly important to mission success (e.g., “What is the enemy’s remaining combat power for both RPG Teams and VBIEDs . . . once TM C reaches PL TIGRIS?”). The DP report contained fields for alternative COAs and the set of events in an engagement that should trigger their adoption (also identified in the OPORD). Subjective workload estimates were obtained via a 7-point Likert-type scale with endpoints labeled <italic>very low</italic> and <italic>very high</italic>. A hard copy information access (HIA) measure was used to assess the number of times participants referred to the printed OPORD.</p>
</sec>
<sec id="section13-1555343412440696">
<title>Procedure</title>
<p>Participants completed three sessions of approximately 1 hr on three consecutive days. On Day 1, each participant was provided with a brief description of the project and completed a demographic survey. A random number generator was used to assign participants to one of four groups varying in interface (RAPTOR or GGUI) and scenario order during testing (offensive-COIN or COIN-offensive). A scripted slideshow provided participants with a detailed description of the appropriate interface during a tutorial session. Participants completed the defensive scenario during a training session. Participants were then required to complete an interface proficiency test with a perfect score; additional interface training and testing were provided when needed.</p>
<p>Participants completed the appropriate scenarios during the testing sessions on Days 2 and 3. Participants reviewed the OPORD, received clarification when needed, and provided a mission “back brief” to ensure they understood it completely. Participants were instructed to complete all experimental tasks as accurately and quickly as possible. Participants were instructed to reference the hard copy OPORD as needed during an engagement but to close the binder afterward.</p>
<p>The simulation was paused during the administration of a TRACE report. A prerecorded audio prompt was played, participants interacted with the interface while searching for information and completing the form, they rated their confidence, and the simulation was resumed (either manually after the TRACE report was submitted or automatically after 5 min). Participants completed three TRACE reports during each session. There were no experimental prompts for the CCIR and the DP reports. The simulation was not paused during their completion; participants monitored the unfolding engagement for critical events and completed the associated reports when they were detected. The Likert-type scale appeared on the screen and was removed (either after the completion of a rating or automatically after 30 s if no rating was provided). Participants completed these ratings every 5 min. Performance measures were collected with paper-based reports, synchronized digital audio and video records, and computer-generated records. Participants completed an exit survey at the end of Day 3. More detailed methodological descriptions are provided in <xref ref-type="bibr" rid="bibr15-1555343412440696">Hall (2009)</xref>.</p>
</sec>
</sec>
<sec id="section14-1555343412440696" sec-type="results">
<title>Results</title>
<p>A 2 (interface, between subjects: RAPTOR or GGUI) × 2 (order, between subjects: offensive-COIN or COIN-offensive) × 2 (scenario, within subjects: offensive and COIN) mixed-factor repeated-measures ANOVA was conducted for each dependent variable. We analyzed all significant interaction effects by conducting contrasts for simple interaction effects and simple main effects of interface.</p>
<sec id="section15-1555343412440696">
<title>TRACE</title>
<p>We computed TRACE accuracy scores (percentage correct) by summing the number of correct item responses across the three TRACE forms and dividing by the total number of responses (66). The main effects of interface, <italic>F</italic>(1, 12) = 117.14, <italic>p</italic> &lt; .000001, and scenario, <italic>F</italic>(1, 12) = 7.50, <italic>p</italic> &lt; .02; the two-way interactions between interface and scenario, <italic>F</italic>(1, 12) = 7.50, <italic>p</italic> &lt; .02, and between scenario and order, <italic>F</italic>(1, 12) = 11.30, <italic>p</italic> &lt; .006; and the three-way interaction between interface, scenario, and order, <italic>F</italic>(1, 12) = 6.84, <italic>p</italic> &lt; .03, were significant.</p>
<p>The main effect of interface indicated significantly higher levels of accuracy with the RAPTOR interface than with the GGUI. The main effect of scenario indicated significantly lower levels of accuracy with the COIN scenario than with the offensive scenario. We analyzed the interaction effect between interface and scenario by conducting contrasts for the simple main effect of scenario at each interface. The contrast for the RAPTOR interface indicated no significant differences between scenarios. The contrast for the GGUI revealed significantly lower accuracy for the COIN scenario, <italic>F</italic>(1, 12) = 15.01, <italic>p</italic> &lt; .003. We analyzed the three-way interaction between interface, scenario, and order (see <xref ref-type="fig" rid="fig7-1555343412440696">Figure 7</xref> for means) by conducting contrasts for the simple interaction effect between scenario and order for each interface. This interaction was not significant for the RAPTOR interface. It was significant for the GGUI, <italic>F</italic>(1, 12) = 17.86, <italic>p</italic> &lt; .002. Subsequent contrasts for simple main effects of scenario revealed no significant differences with the GGUI when the offensive scenario was completed first. Significant differences were obtained with the GGUI when the COIN scenario was completed first, <italic>F</italic>(1, 12) = 32.81, <italic>p</italic> &lt; .0001: Performance was significantly less accurate for the COIN scenario. Contrasts for the simple main effect of interface for the three-way interaction (i.e., interface at each of the four Scenario × Order combinations) revealed performance advantages for the RAPTOR interface: <italic>F</italic>(1, 12) = 41.77, <italic>p</italic> &lt; .00004; <italic>F</italic>(1, 12) = 77.84, <italic>p</italic> &lt; .000001; <italic>F</italic>(1, 12) = 24.43, <italic>p</italic> &lt; .0004; <italic>F</italic>(1, 12) = 97.06, <italic>p</italic> &lt; .000001.</p>
<fig id="fig7-1555343412440696" position="float">
<label>Figure 7.</label>
<caption>
<p>Mean Tactical Rating of Awareness for Combat Environments accuracy scores (i.e., situation reports) for the three-way interaction between scenario, order, and interface.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig7.tif"/>
</fig>
<p>We calculated TRACE latency scores by averaging the length of time required to complete the three TRACE reports. The main effect of interface was significant, <italic>F</italic>(1, 12) = 129.80, <italic>p</italic> &lt; .000001, and indicated that performance was significantly faster with the RAPTOR interface (see <xref ref-type="fig" rid="fig8-1555343412440696">Figure 8</xref> for associated means). The main effect of scenario was significant, <italic>F</italic>(1, 12) = 8.21, <italic>p</italic> &lt; .02, and indicated that performance was significantly slower with the COIN scenario. The Scenario × Order interaction was significant, <italic>F</italic>(1, 12) = 38.63, <italic>p</italic> &lt; .00005, and indicated that latencies for both scenarios improved when it appeared as the second scenario. The improvement was significant for the offensive scenario, <italic>F</italic>(1, 12) = 7.54, <italic>p</italic> &lt; .02, but not for the COIN scenario.</p>
<fig id="fig8-1555343412440696" position="float">
<label>Figure 8.</label>
<caption>
<p>Mean Tactical Rating of Awareness for Combat Environments latency scores (i.e., situation reports) for the main effect of interface.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig8.tif"/>
</fig>
</sec>
<sec id="section16-1555343412440696">
<title>CCIR</title>
<p>We computed CCIR accuracy scores by summing the number of events that were detected and reported correctly and dividing by the total number of responses (4 maximum). Only the main effect of interface was significant, <italic>F</italic>(1, 12) = 37.07, <italic>p</italic> &lt; .00006. Performance with the RAPTOR interface was significantly more accurate than performance with the GGUI. We computed a CCIR latency score by averaging the length of time required to report the four events. Only the main effect of interface was significant, <italic>F</italic>(1, 12) = 13.82, <italic>p</italic> &lt; .003. Performance with the RAPTOR interface was significantly faster than performance with the GGUI. The mean scores (both accuracy and latency) for the main effects of interface are illustrated in <xref ref-type="fig" rid="fig9-1555343412440696">Figure 9</xref>.</p>
<fig id="fig9-1555343412440696" position="float">
<label>Figure 9.</label>
<caption>
<p>Mean Commander’s Critical Information Report scores (i.e., monitoring for critical events) for the main effects of interface (accuracy and latency).</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig9.tif"/>
</fig>
</sec>
<sec id="section17-1555343412440696">
<title>DP Report</title>
<p>We calculated a DP latency score by determining the time interval between the point at which all critical-event criteria for choosing an alternative COA were met in the simulation and the point at which the participant chose an alternative COA. The Interface × Scenario interaction effect, <italic>F</italic>(1, 12) = 10.23, <italic>p</italic> &lt; .009, and the Scenario × Order effect, <italic>F</italic>(1, 12) = 6.63, <italic>p</italic> &lt; .03, were the only significant effects. We analyzed the interaction effect between interface and scenario by conducting contrasts for the simple main effect of scenario for each interface. The contrast for the RAPTOR interface indicated no significant differences between scenarios. The contrast for the GGUI revealed significantly better performance for the COIN scenario, <italic>F</italic>(1, 12) = 5.88, <italic>p</italic> &lt; .04. Contrasts for the simple main effect of interface at each scenario were not significant. We analyzed the interaction effect between scenario and order by conducting contrasts for the simple main effect of scenario for each order. Neither contrast was significant.</p>
</sec>
<sec id="section18-1555343412440696">
<title>HIA</title>
<p>We computed an HIA score by summing the number of times a participant accessed the hard copy OPORD during a test session. The main effects of interface, <italic>F</italic>(1, 12) = 176.51, <italic>p</italic> &lt; .000001, and scenario, <italic>F</italic>(1, 12) = 25.91, <italic>p</italic> &lt; .0003; the two-way interactions between interface and scenario, <italic>F</italic>(1, 12) = 5.65, <italic>p</italic> &lt; .04, and between scenario and order, <italic>F</italic>(1, 12) = 5.65, <italic>p</italic> &lt; .04; and the three-way interaction between interface, scenario, and order, <italic>F</italic>(1, 12) = 8.44, <italic>p</italic> &lt; .02, were significant.</p>
<p>The main effect of interface indicated significantly lower levels of hard copy access with the RAPTOR interface than with the GGUI. The main effect of scenario indicated significantly higher levels of hard copy access with the COIN scenario than with the offensive scenario. We analyzed the interaction effect between interface and scenario by conducting contrasts for the simple main effect of scenario for each interface. The contrast for the RAPTOR interface indicated no significant differences between scenarios. The contrast for the GGUI revealed significantly higher levels of information access for the COIN scenario, <italic>F</italic>(1, 12) = 27.35, <italic>p</italic> &lt; .0003. We analyzed the three-way interaction between interface, scenario, and order (see <xref ref-type="fig" rid="fig10-1555343412440696">Figure 10</xref> for means) by conducting contrasts for the simple interaction between scenario and order for each interface. This interaction was not significant for the RAPTOR interface but was significant for the GGUI, <italic>F</italic>(1, 12) = 13.95, <italic>p</italic> &lt; .003. Subsequent contrasts for the simple main effects revealed no significant differences between scenarios when the offensive scenario was completed first with the GGUI. Significant effects were obtained when the COIN scenario was completed first, <italic>F</italic>(1, 12) = 40.19, <italic>p</italic> &lt; .00004: Significantly higher levels of hard copy access were obtained with the COIN scenario. Contrasts for the simple main effects of interface for the three-way interaction (i.e., interface at each of the four Scenario × Order combinations) revealed significant performance advantages for the RAPTOR interface: <italic>F</italic>(1, 12) = 58.78, <italic>p</italic> &lt; .000006; <italic>F</italic>(1, 12) = 70.83, <italic>p</italic> &lt; .000002; <italic>F</italic>(1, 12) = 40.11, <italic>p</italic> &lt; .00004; <italic>F</italic>(1, 12) = 123.07, <italic>p</italic> &lt; .000001.</p>
<fig id="fig10-1555343412440696" position="float">
<label>Figure 10.</label>
<caption>
<p>Mean hard copy information access scores (i.e., counts of hard copy operations order access) for the three-way interaction between scenario, order, and interface.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig10.tif"/>
</fig>
</sec>
<sec id="section19-1555343412440696">
<title>Subjective Workload</title>
<p>We computed scores for subjective workload by averaging the workload ratings. The only significant effect was the main effect of interface, <italic>F</italic>(1, 12) = 26.06, <italic>p</italic> &lt; .0003. Subjective workload was significantly lower with the RAPTOR interface than with the GGUI. The mean scores for the main effect of interface are illustrated in <xref ref-type="fig" rid="fig11-1555343412440696">Figure 11</xref>.</p>
<fig id="fig11-1555343412440696" position="float">
<label>Figure 11.</label>
<caption>
<p>Mean subjective workload scores for the main effect of interface.</p>
</caption>
<graphic xlink:href="10.1177_1555343412440696-fig11.tif"/>
</fig>
</sec>
</sec>
<sec id="section20-1555343412440696" sec-type="discussion">
<title>Discussion</title>
<p>Overall, the experimental results indicate very clearly that the RAPTOR interface was more effective in supporting performance at experimental tasks than the GGUI. Significant results favoring the RAPTOR interface were obtained for all statistical comparisons between interfaces (i.e., main effects or simple main effects) in six of the seven dependent measures.</p>
<p>The results provide evidence that the RAPTOR interface supported participants in their efforts to obtain information about the ongoing engagement more effectively than the GGUI. Participants completed significantly more accurate and timely TRACE reports. Likewise, participants completed more accurate and timely CCIRs. The differences in performance were quite pronounced. The general pattern obtained for both TRACE (<xref ref-type="fig" rid="fig7-1555343412440696">Figures 7</xref> and <xref ref-type="fig" rid="fig8-1555343412440696">8</xref>) and CCIR (<xref ref-type="fig" rid="fig9-1555343412440696">Figure 9</xref>) dependent measures indicates that reports were completed with the RAPTOR interface in approximately half the time (differences on the order of minutes, not milliseconds) and with approximately twice the accuracy (100% vs. 50%) relative to the GGUI.</p>
<p>Results obtained for scenario and order effects across several dependent measures also testify with regard to the superiority of the RAPTOR interface. The significant main effects for TRACE accuracy, latency, and HIA suggest that the COIN scenario was more difficult than the offensive scenario. The associated Scenario × Order interaction effects indicated that performance with the COIN scenario was significantly worse only when it was the first scenario that participants completed. For two of these dependent measures (TRACE accuracy and HIA), the associated Scenario × Order × Interface interaction effects indicated that this pattern of results was obtained only with the GGUI (see <xref ref-type="fig" rid="fig7-1555343412440696">Figures 7</xref> and <xref ref-type="fig" rid="fig10-1555343412440696">10</xref>). Thus, the effects of scenario and order were generally mitigated with the RAPTOR interface. Our interpretation of these results is that the COIN scenario was more difficult than the offensive scenario (perhaps because it was less like the defensive training scenario). However, the RAPTOR interface allowed participants to meet these challenges in a more effective manner than the GGUI.</p>
<p>Several other aspects of the evaluation indicate that the RAPTOR interface was easy to learn and use. This interface is a complicated one that incorporates a great deal of information about the underlying work domain (see the brief description in the Introduction; a more detailed description in <xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett et al., 2008</xref>; and the HIA results indicating that participants rarely needed to consult written hard copies of the OPORDs). Participants using this interface had no prior experience with it and extremely limited training in its use. In contrast, 6 of 8 participants using the GGUI had extensive experience and training with the army interface (FBCB2) after which the GGUI was modeled. The extremely proficient levels of performance obtained with the RAPTOR interface suggests that it was easy to learn. The subjective workload ratings for the RAPTOR interface suggest that it is easy to use (see <xref ref-type="fig" rid="fig11-1555343412440696">Figure 11</xref>).</p>
<p>It is possible that differences in the experience levels of the officers randomly assigned to the two interface groups may have contributed to the performance differences that were obtained (as opposed to the interpretation that these performance differences were attributable to the quality of the interfaces). We analyzed the extensive demographic survey data (e.g., rank or time spent in various activities, such as in service, as a commander, in combat, with FBCB2, or in various occupational roles) to check this possibility. None of the <italic>t</italic> tests revealed significant differences in experience between officers assigned to the RAPTOR and GGUI groups. In general, officers using the GGUI actually had slightly higher levels of experience.</p>
<p>These results will be interpreted from the CSE-EID perspective, with a focus on the three principles of interface design that were outlined in the Introduction section. The interface design goal of direct perception was achieved in the RAPTOR interface by the development of a variety of graphical representations (i.e., analogies and metaphors) that were specifically tailored to the constraints of this work domain. Thus, the affordances of the domain were specified in the interface and available to be picked up directly. The goal of direct manipulation was achieved via interface controls that allowed participants to execute input directly (e.g., selectively view portions of the complex underlying informational database) and efficiently. The goal of visual momentum was supported by a variety of interface resources that supported smooth transitions between the various viewing contexts. In short, the results suggest that the RAPTOR interface leveraged powerful perception-action skills, thereby providing effective support for complicated and realistic domain tasks. In terms of the conceptual overview presented in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref>, the constraints contributed by the interface were well matched to both work domain constraints and agent constraints.</p>
<p>In contrast, the design of the GGUI failed to achieve these three goals, thereby imposing a severe set of constraints on interaction. A primary contributor to the poor performance obtained in the present evaluation is the failure to achieve direct perception. Critical domain information was represented ineffectively (i.e., alphanumerically), and participants were forced to derive some information mentally (see <xref ref-type="bibr" rid="bibr6-1555343412440696">Bennett et al., 1997</xref>; <xref ref-type="bibr" rid="bibr3-1555343412440696">Bennett &amp; Flach, 1992</xref>; <xref ref-type="bibr" rid="bibr9-1555343412440696">Bennett &amp; Walters, 2001</xref>, for more detailed discussion of similar points). Similarly, the GGUI failed to achieve high levels of visual momentum. Interface resources to support navigation of the complex informational database were ineffective or missing altogether. As a result, the cognitive coupling between alternative glances into the database were poor, and the agents were unable to locate relevant subsets of data quickly.</p>
<p>In summary, the results of the present evaluation provide clear evidence favoring the RAPTOR interface. At the same time, these results are somewhat puzzling. From an objective standpoint, the RAPTOR interface is a complicated one. Furthermore, participants in the study had no prior experience with the interface and very limited amounts of training. Yet participants demonstrated clear proficiency in its use. The puzzle is how can an interface be very complicated and yet easy to learn to use? Potential explanations will be explored in the following section.</p>
</sec>
<sec id="section21-1555343412440696">
<title>General Discussion</title>
<p>We will now broaden the discussion by considering the current evaluation and the CSE-EID approach within the context of two additional and complementary theoretical perspectives: naturalistic decision making (NDM) and situation awareness (SA). <xref ref-type="bibr" rid="bibr12-1555343412440696">Endsley (1988)</xref> defines SA as “the perception of <italic>elements in the environment</italic> within a volume of time and space, the comprehension of <italic>their meaning</italic>, and the <italic>projection of their status</italic> in the near future” (p. 97, emphasis added). Endsley views SA as “a state of knowledge” and differentiates it from situation assessment, which is defined as “the process of achieving, acquiring, or maintaining SA” (<xref ref-type="bibr" rid="bibr13-1555343412440696">Endsley, 1995</xref>, p. 36). One primary message from this perspective is that good SA is a requirement for effective performance.</p>
<p>There is a reasonably direct relationship between SA and several of the dependent measures in the present evaluation. Recall that the TRACE dependent measure required participants to report the status of friendly and enemy resources and activities and that the CCIR dependent measure required participants to monitor the ongoing tactical operations for designated critical events. Thus, one interpretation of these findings is that participants using the RAPTOR interface maintained more effective SA than those using the GGUI (or at least that the resources it provided supported participants in completing their situation assessment activities in a more effective fashion).</p>
<p>NDM provides an alternative to traditional theories about decision making and problem solving. Traditional approaches viewed decision making as a highly cognitive and analytical process wherein experts consider all problem dimensions and derive an optimal solution. In contrast, naturalistic approaches (e.g., recognition-primed decision making; <xref ref-type="bibr" rid="bibr17-1555343412440696">Klein, 1989a</xref>) view decision making as a highly perceptual process wherein experts use perceptual cues (hence the term <italic>recognition primed</italic>), in conjunction with their prior experience to recognize a small number of solutions that are likely to work.</p>
<p><xref ref-type="bibr" rid="bibr18-1555343412440696">Klein (1989b</xref>) wrote an article appearing in the journal <italic>Military Review</italic> in which he discussed recognition-primed decision making and the design of interfaces for military command and control. He summarized the goals of interface design from the NDM perspective:</p>
<p><disp-quote>
<p>We must insist that the designers of these systems have appropriate respect for the expertise of proficient operators and ensure that their systems and interfaces do not compromise this expertise. We must find ways to present operators with displays that will make situation assessment easier and more accurate. We also want displays that will make it easier for operators to assess options in order to discover potential problems. In other words, we want to build decision support systems that enhance recognitional as well as analytical decision strategies. (<xref ref-type="bibr" rid="bibr18-1555343412440696">Klein, 1989b</xref>, p. 64)</p>
</disp-quote></p>
<p>The results of the present evaluation suggest that the RAPTOR interface was designed to be consistent with these recommendations. The RAPTOR interface supported recognitional strategies on the part of participants by providing perceptual cues that were specifically crafted to represent critical domain constraints directly. In contrast, the representational forms and information structures of the GGUI forced analytical strategies: Participants were required to analyze and interpret alphanumeric information in the context of their knowledge about the domain.</p>
<p>The recommendation to “respect” and to “not compromise” domain expertise points to an interpretation of the puzzle we left at the end of the Discussion section: How could army officers perform so proficiently with the RAPTOR interface given that they had such limited training and experience with it? We believe that the only explanation for this pattern of results is that the interface “tapped into” existing expertise in an effective way. In terms of <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref>, the work domain analyses uncovered critical domain constraints (affordances); the interface representations specified these affordances directly and in a way that complemented natural perception-action skills (specificity). As a result, officers did not need extensive periods of training to locate and interpret the information. Stated alternatively, it is very unlikely that the same pattern of results would have been obtained with college freshmen as participants. In fact, it appears that the RAPTOR interface not only respected, but leveraged, existing expertise.</p>
<p>These interpretations, framed in terms of the complementary theoretical perspectives of NDM and SA, underscore the need to consider display and interface design efforts from the triadic framework illustrated in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref>. SA is normally viewed as something that resides inside the head of a domain practitioner (i.e., a state of knowledge). However, as the name itself suggests (also, see the italicized parts of the previously quoted definition), SA really involves the relationship between an ecology (i.e., the situation component) and a domain practitioner (i.e., the awareness component) embedded within that ecology (e.g., <xref ref-type="bibr" rid="bibr14-1555343412440696">Flach, 1995</xref>). This relationship corresponds directly to the outer two components illustrated in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref>.</p>
<p>However, it is important to note that domain practitioners will not be able to observe the state of the ecology directly in many, if not most, of today’s increasingly “computer-mediated” work domains; information about the situation will actually be <italic>representations</italic> of the ecology that reside in the interface. It follows logically that the quality of SA will be heavily influenced by how well the interface represents critical elements in the environment (as in the present evaluation). Or in terms of NDM, the extent to which NDM is supported will be determined by the quality of the representations in the interface, since these representations provide the perceptual cues that will prime decisions. These observations emphasize the merits of the systems-level, semiotic-based, triadic perspective of the CSE-EID approach that is presented in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref> (i.e., situations, interface, awareness; for extensive discussions of these and related points, see <xref ref-type="bibr" rid="bibr5-1555343412440696">Bennett &amp; Flach, 2011</xref>).</p>
<p>In summary, NDM and SA are two powerful and popular theoretical perspectives that have shed new light on old problems in human factors, particularly on issues surrounding the nature of expertise. However, when considered as frameworks for design, there may be some inherent limitations (<xref ref-type="bibr" rid="bibr23-1555343412440696">Rasmussen et al., 1994</xref>; <xref ref-type="bibr" rid="bibr26-1555343412440696">Shattuck &amp; Miller, 2006</xref>; <xref ref-type="bibr" rid="bibr30-1555343412440696">Vicente, 1999</xref>). In <xref ref-type="bibr" rid="bibr30-1555343412440696">Vicente’s (1999)</xref> terms, both NDM and SA are “descriptive” approaches that focus on the study of current practice (i.e., domain practitioners and their expertise as it is expressed in existing systems). However, the activities that are observed in computer-mediated work domains will be heavily influenced by existing interfaces. Thus, although these and similar observational approaches may inform us about what domain practitioners are currently doing, they tend to shed less light on what they could be doing (i.e., how new computational resources could be used to help them accomplish their work).</p>
</sec>
<sec id="section22-1555343412440696">
<title>CSE and EID: Comprehensive and Generic Approach</title>
<p>In this final section, we will discuss how the CSE-EID approach supports these needs and review research that illustrates its application in military settings. One of the major theoretical contributions of this approach is the insight that work domain constraints must be considered independently of the interface or current work practices (in contrast to, for example, traditional task analysis methodologies). Thus, during the analysis phase, it is critical to separate out those constraints that are inherently part of the work domain from those that have been designed into it. A few articles describing work domain analyses for military settings have appeared in recent years (<xref ref-type="bibr" rid="bibr10-1555343412440696">Burns, Bisantz, &amp; Roth, 2004</xref>; <xref ref-type="bibr" rid="bibr11-1555343412440696">Burns, Bryant, &amp; Chalmers, 2005</xref>; <xref ref-type="bibr" rid="bibr19-1555343412440696">Naikar, Moylan, &amp; Pearce, 2006</xref>; <xref ref-type="bibr" rid="bibr22-1555343412440696">Rasmussen, 1998</xref>; <xref ref-type="bibr" rid="bibr27-1555343412440696">Torenvliet, Jamieson, &amp; Chow, 2008</xref>).</p>
<p>The products of these work domain analyses provide the foundation for interface design (i.e., EID). Principles of design (i.e., direct perception, direct manipulation, visual momentum) can then be used to translate the ensuing models into more effective decision-making and problem-solving support. A few articles describing both work domain analysis and ecological interfaces for military settings have also appeared. Amelink and colleagues (<xref ref-type="bibr" rid="bibr1-1555343412440696">Amelink, 2002</xref>; <xref ref-type="bibr" rid="bibr2-1555343412440696">Amelink, Mulder, van Paassen, &amp; Flach, 2005</xref>) describe an ecological flight display; <xref ref-type="bibr" rid="bibr28-1555343412440696">Van Dam, Mulder, and van Passen (2008)</xref> describe an ecological interface for maintaining airborne separation (both examples are for general aviation but relevant to military settings). Potter and his colleagues (<xref ref-type="bibr" rid="bibr20-1555343412440696">Potter, Elm, Roth, Gualtieri, &amp; Easter, 2002</xref>; <xref ref-type="bibr" rid="bibr21-1555343412440696">Potter, Gualtieri, &amp; Elm, 2003</xref>) developed a combat power display (similar in intent to the force ratio display in <xref ref-type="fig" rid="fig3-1555343412440696">Figures 3</xref> and <xref ref-type="fig" rid="fig4-1555343412440696">4</xref>) for military command and control. As mentioned previously, <xref ref-type="bibr" rid="bibr7-1555343412440696">Bennett et al. (2008)</xref> describe how work domain analysis informed the design of the displays and controls that appear in the RAPTOR interface.</p>
<p>The third major activity in the CSE-EID approach is evaluation. The present study is a rare example of a comprehensive evaluation for a military ecological interface. In terms of <xref ref-type="bibr" rid="bibr23-1555343412440696">Rasmussen et al.’s (1994)</xref> CSE evaluation framework, this evaluation was conducted at Boundary Level 3 (controlled task situation). Evaluations of this type are “more complex experiments focused on actual task situations” that use “simulations . . . designed as replicas of actual work scenarios” (<xref ref-type="bibr" rid="bibr23-1555343412440696">Rasmussen et al., 1994</xref>, pp. 222-223). The evaluation we conducted is a very representative one. More specifically, the experimental versions of each of the three system components illustrated in <xref ref-type="fig" rid="fig1-1555343412440696">Figure 1</xref> are reasonable approximations of their real-world counterparts: The synthetic task environment incorporated realistic tactical scenarios, the comparison interface was modeled after an existing army interface, and participants were army officers with extensive service and combat experience.</p>
<sec id="section23-1555343412440696">
<title>Summary</title>
<p>The present evaluation is the culmination of a research project that has contributed to a small, but growing, literature on the application of the CSE-EID approach to military settings. From a broad perspective, the project provides examples of work domain analyses, the translation of these results into displays and controls, and the development of synthetic task environments for evaluation. Thus, it has provided generic templates for similar research and development efforts. More specifically, the controls and displays of the RAPTOR interface are innovative and radically different from those found in existing interfaces. The results of the present evaluation provide an important validation of their effectiveness. Furthermore, the representativeness of the evaluation suggests that the results have a reasonable chance of generalizing to the real world. These displays and controls are specifically tailored to address the challenges facing army commanders during tactical operations. However, they also represent general solutions that can be readily adapted for other military settings and for other work domains with similar constraints (e.g., flexible manufacturing, inventory control). The results provide a strong indication that the CSE-EID approach to analysis, design, and evaluation provides a comprehensive framework that can be used to realize the potential that interface technologies provide to improve decision-making and problem-solving support for computer-mediated work domains.</p>
</sec>
</sec>
</body>
<back>
<ack>
<p>The study reported in this article was completed in partial fulfillment of the requirements for the master of science degree for Daniel Hall. The Representation Aiding Portrayal of Tactical Operations Resources (RAPTOR) project was funded via the Advanced Decision Architectures Collaborative Technology Alliance Consortium, sponsored by the U.S. Army Research Laboratory (ARL) under Cooperative Agreement DAAD19-01-2-0009. Special thanks to LTC David Hudak and the army officers from TRAC Monterey, the Naval Postgraduate School (NPS) Operations Research Department, and the NPS National Security Affairs Program for assisting and participating. Aptima’s Daniel Serfaty and Kevin Gildea provided the DDD® simulation software and expertise in its use. Randy Green was the software programmer. Finally, thanks to all of the ARL researchers, army officers, and members of the U.S. Military Academy who kindly contributed to the development of RAPTOR throughout the years.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="bibr1-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Amelink</surname><given-names>M. H. J.</given-names></name>
</person-group> (<year>2002</year>). <source>Visual control augmentation by presenting energy management information in the primary flight display: An ecological approach</source>. <publisher-loc>Delft, Netherlands</publisher-loc>: <publisher-name>Delft University of Technology, Faculty of Aerospace Engineering</publisher-name>.</citation>
</ref>
<ref id="bibr2-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Amelink</surname><given-names>M. H. J.</given-names></name>
<name><surname>Mulder</surname><given-names>M.</given-names></name>
<name><surname>van Paassen</surname><given-names>M. M.</given-names></name>
<name><surname>Flach</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Theoretical foundations for a total energy-based perspective flight-path display</article-title>. <source>International Journal of Aviation Psychology</source>, <volume>15</volume>, <fpage>205</fpage>–<lpage>231</lpage>.</citation>
</ref>
<ref id="bibr3-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Flach</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Graphical displays: Implications for divided attention, focused attention, and problem solving</article-title>. <source>Human Factors</source>, <volume>34</volume>, <fpage>513</fpage>–<lpage>533</lpage>.</citation>
</ref>
<ref id="bibr4-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Flach</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2012</year>). <source>Visual momentum redux. International Journal of Human Computer Studies</source>, <volume>70</volume>, <fpage>399</fpage>–<lpage>414</lpage>.</citation>
</ref>
<ref id="bibr5-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Flach</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2011</year>). <source>Display and interface design: Subtle science, exact art</source>. <publisher-loc>Boca Raton, FL</publisher-loc>: <publisher-name>CRC Press</publisher-name>.</citation>
</ref>
<ref id="bibr6-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Nagy</surname><given-names>A. L.</given-names></name>
<name><surname>Flach</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Visual displays</article-title>. In <person-group person-group-type="editor">
<name><surname>Salvendy</surname><given-names>G.</given-names></name>
</person-group> (Ed.), <source>Handbook of human factors and ergonomics</source> (<edition>2nd ed.</edition>, pp. <fpage>659</fpage>–<lpage>696</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr7-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Posey</surname><given-names>S. M.</given-names></name>
<name><surname>Shattuck</surname><given-names>L. G.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Ecological interface design for military command and control</article-title>. <source>Journal of Cognitive Engineering and Decision Making</source>, <volume>2</volume>, <fpage>349</fpage>–<lpage>385</lpage>.</citation>
</ref>
<ref id="bibr8-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Shattuck</surname><given-names>L. G.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Advancing the state-of-the-art in military command and control interfaces: Ecological interface design</article-title>. In <person-group person-group-type="editor">
<name><surname>McDermott</surname><given-names>P.</given-names></name>
<name><surname>Allender</surname><given-names>L.</given-names></name>
</person-group> (Eds.), <source>Advanced decision architectures for the warfigher: Foundation and technology</source> (pp. <fpage>123</fpage>–<lpage>142</lpage>). <publisher-loc>Boulder, CO</publisher-loc>: <publisher-name>Partners of the Army Research Laboratories Advanced Decision Architectures Collaborative Technology Alliance</publisher-name>.</citation>
</ref>
<ref id="bibr9-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>K. B.</given-names></name>
<name><surname>Walters</surname><given-names>B.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Configural display design techniques considered at multiple levels of evaluation</article-title>. <source>Human Factors</source>, <volume>43</volume>, <fpage>415</fpage>–<lpage>434</lpage>.</citation>
</ref>
<ref id="bibr10-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Burns</surname><given-names>C. M.</given-names></name>
<name><surname>Bisantz</surname><given-names>A. M.</given-names></name>
<name><surname>Roth</surname><given-names>E. M.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Lessons from a comparison of work models: Representational choices and their implications</article-title>. <source>Human Factors</source>, <volume>46</volume>, <fpage>711</fpage>–<lpage>727</lpage>.</citation>
</ref>
<ref id="bibr11-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Burns</surname><given-names>C. M.</given-names></name>
<name><surname>Bryant</surname><given-names>D. B.</given-names></name>
<name><surname>Chalmers</surname><given-names>B. A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Boundary, purpose and values in work domain models: Models of naval command and control</article-title>. <source>IEEE Transactions on Systems, Man and Cybernetics–Part A</source>, <volume>35</volume>, <fpage>603</fpage>–<lpage>616</lpage>.</citation>
</ref>
<ref id="bibr12-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Endsley</surname><given-names>M. R.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Design and evaluation for situation awareness</article-title>. In <source>Proceedings of Proceedings of the Human Factors Society 32nd Annual Meeting</source> (pp. <fpage>97</fpage>–<lpage>101</lpage>). <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>Human Factors Society</publisher-name>.</citation>
</ref>
<ref id="bibr13-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Endsley</surname><given-names>M. R.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Toward a theory of situation awareness in dynamic systems</article-title>. <source>Human Factors</source>, <volume>37</volume>, <fpage>32</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr14-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Flach</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Situation awareness: Proceed with caution</article-title>. <source>Human Factors</source>, <volume>37</volume>, <fpage>149</fpage>–<lpage>157</lpage>.</citation>
</ref>
<ref id="bibr15-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hall</surname><given-names>D. S.</given-names></name>
</person-group> (<year>2009</year>). <source>RAPTOR: An empirical evaluation of an ecological interface designed to increase warfighter cognitive performance</source>. <publisher-loc>Monterey, CA</publisher-loc>: <publisher-name>Naval Postgraduate School</publisher-name>.</citation>
</ref>
<ref id="bibr16-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hutchins</surname><given-names>E. L.</given-names></name>
<name><surname>Hollan</surname><given-names>J. D.</given-names></name>
<name><surname>Norman</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1986</year>). <article-title>Direct manipulation interfaces</article-title>. In <person-group person-group-type="editor">
<name><surname>Norman</surname><given-names>D. A.</given-names></name>
<name><surname>Draper</surname><given-names>S. W.</given-names></name>
</person-group> (Eds.), <source>User centered system design</source> (pp. <fpage>87</fpage>–<lpage>124</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr17-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klein</surname><given-names>G. A.</given-names></name>
</person-group> (<year>1989a</year>). <article-title>Recognition-primed decisions</article-title>. <source>Advances in Man-Machine Systems Research</source>, <volume>5</volume>, <fpage>47</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr18-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klein</surname><given-names>G. A.</given-names></name>
</person-group> (<year>1989b</year>, <month>May</month>). <article-title>Strategies of decision making</article-title>. <source>Military Review</source>, pp. <fpage>56</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr19-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Naikar</surname><given-names>N.</given-names></name>
<name><surname>Moylan</surname><given-names>A.</given-names></name>
<name><surname>Pearce</surname><given-names>B.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Analysing activity in complex systems with cognitive work analysis: Concepts, guidelines, and case study for control task analysis</article-title>. <source>Theoretical Issues in Ergonomics Science</source>, <volume>7</volume>, <fpage>371</fpage>–<lpage>394</lpage>.</citation>
</ref>
<ref id="bibr20-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Potter</surname><given-names>S. S.</given-names></name>
<name><surname>Elm</surname><given-names>W. C.</given-names></name>
<name><surname>Roth</surname><given-names>E. M.</given-names></name>
<name><surname>Gualtieri</surname><given-names>J. W.</given-names></name>
<name><surname>Easter</surname><given-names>J. R.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Using intermediate design artifacts to bridge the gap between cognitive analysis and cognitive engineering</article-title>. In <person-group person-group-type="editor">
<name><surname>McNeese</surname><given-names>M.</given-names></name>
<name><surname>Vidulich</surname><given-names>M. A.</given-names></name>
</person-group> (Eds.), <source>Cognitive systems engineering in military aviation environments: Avoiding cogminutia fragmentosa!</source> (pp. <fpage>137</fpage>–<lpage>168</lpage>). <publisher-loc>Wright Patterson Air Force Base, OH</publisher-loc>: <publisher-name>Human Systems Information Analysis Center</publisher-name>.</citation>
</ref>
<ref id="bibr21-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Potter</surname><given-names>S. S.</given-names></name>
<name><surname>Gualtieri</surname><given-names>J. W.</given-names></name>
<name><surname>Elm</surname><given-names>W. C.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Case studies: Applied cognitive work analysis in the design of innovative decision support</article-title>. In <person-group person-group-type="editor">
<name><surname>Hollnagel</surname><given-names>E.</given-names></name>
</person-group> (Ed.), <source>Cognitive task design</source> (pp. <fpage>653</fpage>–<lpage>677</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr22-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rasmussen</surname><given-names>J.</given-names></name>
</person-group> (<year>1998</year>). <source>Ecological interface design for complex systems: An example. SEAD-UAV systems</source> (<comment>EOARD-Contract: F61708-97-W0211</comment>). <publisher-loc>Smorum, Denmark</publisher-loc>: <publisher-name>HURECON</publisher-name>.</citation>
</ref>
<ref id="bibr23-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rasmussen</surname><given-names>J.</given-names></name>
<name><surname>Pejtersen</surname><given-names>A. M.</given-names></name>
<name><surname>Goodstein</surname><given-names>L. P.</given-names></name>
</person-group> (<year>1994</year>). <source>Cognitive systems engineering</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr24-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rasmussen</surname><given-names>J.</given-names></name>
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Coping with human errors through system design: Implications for ecological interface design</article-title>. <source>International Journal of Man-Machine Studies</source>, <volume>31</volume>, <fpage>517</fpage>–<lpage>534</lpage>.</citation>
</ref>
<ref id="bibr25-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rasmussen</surname><given-names>J.</given-names></name>
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Ecological interfaces: A technological imperative in high tech systems?</article-title> <source>International Journal of Human-Computer Interaction</source>, <volume>2</volume>, <fpage>93</fpage>–<lpage>111</lpage>.</citation>
</ref>
<ref id="bibr26-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shattuck</surname><given-names>L. G.</given-names></name>
<name><surname>Miller</surname><given-names>N. L.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Extending naturalistic decision making to complex organizations: A dynamic model of situated cognition</article-title>. <source>Organization Studies</source>, <volume>27</volume>, <fpage>989</fpage>–<lpage>1009</lpage>.</citation>
</ref>
<ref id="bibr27-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Torenvliet</surname><given-names>G. L.</given-names></name>
<name><surname>Jamieson</surname><given-names>G. A.</given-names></name>
<name><surname>Chow</surname><given-names>R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Object worlds in work domain analysis: A model of naval damage control</article-title>. <source>IEEE Transactions on Systems Man and Cybernetics–Part A: Systems and Humans</source>, <volume>38</volume>, <fpage>1030</fpage>–<lpage>1040</lpage>.</citation>
</ref>
<ref id="bibr28-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Van Dam</surname><given-names>S. B. J.</given-names></name>
<name><surname>Mulder</surname><given-names>M.</given-names></name>
<name><surname>van Paassen</surname><given-names>M. M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Ecological interface design of a tactical airborne separation assistance tool</article-title>. <source>IEEE Transactions on Systems Man and Cybernetics–Part A: Systems and Humans</source>, <volume>38</volume>, <fpage>1221</fpage>–<lpage>1233</lpage>.</citation>
</ref>
<ref id="bibr29-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1991</year>). <source>Supporting knowledge-based behavior through ecological interface design</source> (<comment>No. EPRL-91-02</comment>). <publisher-loc>Urbana-Champaign, IL</publisher-loc>: <publisher-name>University of Illinois, Department of Mechanical Engineering, Engineering Psychology Research Laboratory</publisher-name>.</citation>
</ref>
<ref id="bibr30-1555343412440696">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1999</year>). <source>Cognitive work analysis: Toward safe, productive, and healthy computer-based work</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr31-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
<name><surname>Rasmussen</surname><given-names>J.</given-names></name>
</person-group> (<year>1990</year>). <article-title>The ecology of human-machine systems II: Mediating “direct perception” in complex work domains</article-title>. <source>Ecological Psychology</source>, <volume>2</volume>, <fpage>207</fpage>–<lpage>249</lpage>.</citation>
</ref>
<ref id="bibr32-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
<name><surname>Rasmussen</surname><given-names>J.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Ecological interface design: Theoretical foundations</article-title>. <source>IEEE Transactions on Systems Man and Cybernetics</source>, <volume>22</volume>, <fpage>589</fpage>–<lpage>606</lpage>.</citation>
</ref>
<ref id="bibr33-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Watts-Perotti</surname><given-names>J.</given-names></name>
<name><surname>Woods</surname><given-names>D. D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>How experienced users avoid getting lost in large display networks</article-title>. <source>International Journal of Human-Computer Interaction</source>, <volume>11</volume>, <fpage>269</fpage>–<lpage>299</lpage>.</citation>
</ref>
<ref id="bibr34-1555343412440696">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Woods</surname><given-names>D. D.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Visual momentum: A concept to improve the cognitive coupling of person and computer</article-title>. <source>International Journal of Man-Machine Studies</source>, <volume>21</volume>, <fpage>229</fpage>–<lpage>244</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>