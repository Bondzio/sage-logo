<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TAP</journal-id>
<journal-id journal-id-type="hwp">sptap</journal-id>
<journal-title>Theory &amp; Psychology</journal-title>
<issn pub-type="ppub">0959-3543</issn>
<issn pub-type="epub">1461-7447</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0959354311423435</article-id>
<article-id pub-id-type="publisher-id">10.1177_0959354311423435</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Psychological complexity and the cost of information processing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Aksentijevic</surname><given-names>Aleksandar</given-names></name>
<aff id="aff1-0959354311423435">University of Roehampton</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Gibson</surname><given-names>Keith</given-names></name>
<aff id="aff2-0959354311423435">Birkbeck College</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0959354311423435">Aleksandar Aksentijevic, Department of Psychology, University of Roehampton, Holybourne Avenue, London SW15 4JD, UK. Email: <email>a.aksentijevic@roehampton.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>22</volume>
<issue>5</issue>
<fpage>572</fpage>
<lpage>590</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Traditionally, theories of complexity used in psychology have been based on geometric, probabilistic, and algorithmic paradigms. While these have been useful in highlighting the importance of complexity for psychology, they have not, in general, addressed the relationship between complexity and processing cost. In this paper, we review some of the classic and current complexity theories in psychology and suggest that psychological complexity and processing cost can be quantified using the notion of hierarchical change. Finally, we discuss the relationship between change, complexity, and the Gestalt principles of perceptual organization.</p>
</abstract>
<kwd-group>
<kwd>complexity</kwd>
<kwd>change</kwd>
<kwd>entropy</kwd>
<kwd>information</kwd>
<kwd>structure</kwd>
<kwd>pattern</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Complexity is an all-embracing term that underpins most forms of human activity. From mathematics and science (<xref ref-type="bibr" rid="bibr26-0959354311423435">Gell-Mann, 1995</xref>; <xref ref-type="bibr" rid="bibr27-0959354311423435">Grassberger, 1986</xref>) to psychology (e.g., <xref ref-type="bibr" rid="bibr15-0959354311423435">Donderi, 2006</xref>), complexity defines a boundary of what is perceivable, knowable and expressible. The aim of the current paper is to discuss some classical and current approaches to complexity in psychology. We give a partial overview of the main theoretical treatments and point out their strengths and weaknesses and argue that thus far, most psychological theories have, in general, ignored the relationship between complexity and processing cost. In order to address this issue, we propose that psychological complexity is best defined in terms of change. We illustrate our argument using a computational example and conclude by suggesting how our approach could advance the understanding of the long-debated issue of perceptual organization.</p>
<sec id="section1-0959354311423435">
<title>Information-theoretic approach to complexity</title>
<p>Intensive study of complexity within psychology began with the introduction of Shannon’s information theory (<xref ref-type="bibr" rid="bibr46-0959354311423435">Shannon, 1948</xref>) into psychology in the 1950s. The principal exponents of this approach were <xref ref-type="bibr" rid="bibr5-0959354311423435">Attneave (1954)</xref>, <xref ref-type="bibr" rid="bibr28-0959354311423435">Hick (1952)</xref>, <xref ref-type="bibr" rid="bibr39-0959354311423435">Miller (1953)</xref>, and <xref ref-type="bibr" rid="bibr43-0959354311423435">Pollack (1952)</xref>, who adapted information-theoretic concepts of entropy/redundancy in order to address different perceptual and cognitive issues. Although initially influential in psychology, information theory has not fulfilled its initial promise (<xref ref-type="bibr" rid="bibr37-0959354311423435">Luce, 2003</xref>). Nevertheless, it has stimulated and inspired a number of attempts to quantify the amount of information in different contexts including perception and language. Generally, the uncertainty of a particular outcome is a function of the size of a source, which determines the predictability of emitted information. Redundancy of a message emitted by a known random source represents the difference in the amount of information that the source is capable of emitting and that of the message. In order to calculate the entropy of a pattern or a message, one has to know the prior probabilities of individual symbols, and these depend on the size of the source. To illustrate, the entropy of the message “01010010,” the source of which is a Turing machine capable of outputting only two symbols, is different from the entropy of a message generated by a digital computer capable of producing all ASCII symbols.</p>
<p>Since the human observer rarely understands the source of any kind of novel information, little benefit can be gained from speculating about its origin, as indicated by the problem of ergodicity—the assumption or requirement that the underlying stochastic process does not change during the production of a message. In order to estimate the entropy of a sequence, one has to assume that the same laws of probability operate on the entire sequence. Otherwise, in Attneave’s words, “…the reader can readily appreciate the difficulty which would be created if, for example, the bias on the coin which we have discussed were changed in an erratic manner between throws” (<xref ref-type="bibr" rid="bibr6-0959354311423435">Attneave, 1959</xref>, p. 13). It is clear from Attneave’s appeal that the difficulty is completely due to the limitation of the human observer. In other words, one has to believe that a single unchanging process is in operation; otherwise simple stochastic models are of little use. But how is it possible to know whether a process is ergodic if all that can be accessed is its output? The answer is the same as the answer to the question “how can we know whether a particular source is random”—never.</p>
<p>Another problem for the information-theoretic approach is the meaning of information. From the very beginning, two conflicting interpretations of information have co-existed within Shannon’s paradigm. To illustrate, <xref ref-type="bibr" rid="bibr6-0959354311423435">Attneave (1959)</xref> began his exposition by defining information as something which “removes or reduces uncertainty” (p. 1). This meaning of information refers to its usefulness as well as its statistical rarity. Yet, later in the text, a concept of redundancy is introduced, which represents a probabilistic analog of regularity and the opposite of entropy. We quote: “At the opposite extreme, at 100 percent redundancy, symbols are generated in an altogether lawful and regular sequence, such that one can predict with complete certainty what the next symbol will be” (<xref ref-type="bibr" rid="bibr6-0959354311423435">Attneave, 1959</xref>, p. 14). Under the previous definition, total redundancy should be maximally informative because it reduces uncertainty to zero. Yet, a maximally redundant sequence contains no information at all, since a maximally redundant sequence is 111111111… or 00000000…. This is corroborated by <xref ref-type="bibr" rid="bibr42-0959354311423435">Palmer (1983)</xref>, who equates predictable structure with “little information” (p. 283). This statement is not completely correct, because the two sequences do contain some information. The length of the sequence tells us something about the process as does the symbol chosen, although these factors are ignored by information theory. What is missing is structure—relations between symbols. This point was alluded to by <xref ref-type="bibr" rid="bibr37-0959354311423435">Luce (2003)</xref> in his comments on the impact of information theory on psychology.</p>
<p>The same ambiguous treatment of information can be found in <xref ref-type="bibr" rid="bibr15-0959354311423435">Donderi’s (2006)</xref> comprehensive review of visual complexity. Discussing Shannon’s basic idea, he states that an “unlikely symbol conveys more information than a likely one” (p. 75). Yet, on the same page, he says “uncertainty reduced is information gained” (p. 75). This should be interpreted in the sense that highly redundant messages reveal little about the source. As we discussed at the beginning, this relies on the (in our view unsustainable) assumption that the statistical properties of the source are known. Thus, information is unpredictable and complex while at the same time being simple and predictable. It is here that the fundamental incompatibility between information theory and psychology is revealed. Information theory does not consider the amount of information contained in individual patterns. If one thinks of exhaustive sets of finite patterns, it is obvious that simple patterns are statistically rare and highly unlikely to be generated by a random process (<xref ref-type="bibr" rid="bibr30-0959354311423435">Ichikawa, 1985</xref>). Consequently, we arrive at an apparent paradox that a source outputting unexpected (improbable) simple patterns is significantly reducing uncertainty while at the same time providing the receiver with highly predictable redundant patterns, which convey little information about the variability of the source.</p>
<p>Notwithstanding the shortcomings of information-theoretic approach in terms of psychology (see <xref ref-type="bibr" rid="bibr11-0959354311423435">Chater, 1996</xref> for a detailed discussion), the notion of redundancy goes some way towards quantifying regularity. The relationship between structure and quantity was implicitly addressed by the original application of information theory. Specifically, if a pattern contains any form of structure (e.g., periodicity), the frequencies of occurrence of different combinations of symbols are uneven and there is a preponderance of only a few n-grams (<xref ref-type="bibr" rid="bibr6-0959354311423435">Attneave, 1959</xref>; <xref ref-type="bibr" rid="bibr16-0959354311423435">Falk &amp; Konold, 1997</xref>). Similarly, a regular geometric figure will have fewer turns, different angles, or sides of different length. The failure of information theory-based approach to apply this insight was due to the assumption of statistical independence of different levels of structure. In the words of <xref ref-type="bibr" rid="bibr37-0959354311423435">Luce (2003)</xref>, “. . .the stimuli of psychological experiments are to some degree structured, and so, in a fundamental way, they are not in any sense interchangeable” (p. 185). In other words, different levels of structural organization within a pattern should not be treated as mutually independent statistical events.</p>
<p>The notion of interdependence of different levels of structure represents one of the cornerstones of Gestalt psychology, whose impact on complexity research in psychology cannot be overestimated (e.g., <xref ref-type="bibr" rid="bibr29-0959354311423435">Hochberg &amp; McAllister, 1953</xref>). The first serious attempt to quantify pattern goodness was offered by Gestalt psychologists in the 1920s and 1930s. They proposed that human observers organized sensory/perceptual and cognitive information according to a number of simple rules. Fundamentally, an individual perceptual scene is organized in such a way as to minimize the expenditure (or rather conversion) of energy. This is what the Gestaltists named the “law of Prägnanz” or “minimum principle” (e.g., <xref ref-type="bibr" rid="bibr31-0959354311423435">Koffka, 1935</xref>). Patterns are considered “good” if they are compact, symmetrical, repetitive, or predictable. By contrast, “poor” patterns are complex, asymmetrical, and defy easy description. The relationships between elements as well as the relationship between objects and the background are crucial for perceptual and cognitive functioning. The original proponents of information theory in psychology did not, perhaps understandably, consider the implication of Gestalt notions of the minimization of energy expenditure and the relationship between the whole and its parts. This prevented Attneave and others from offering general observations on structure beyond indicating a certain degree of patterning at a particular level of structure. As we show later in the text, Gestalt principles are intimately related to change.</p>
</sec>
<sec id="section2-0959354311423435">
<title>Wendell Garner: Reconciling probability and structure</title>
<p>Information theory was primarily focused on the quantitative aspect of entropy. The primary determinant of information is the size of the source or the frequency of occurrence of different outcomes. This aspect of information has been described as “metrical” (<xref ref-type="bibr" rid="bibr38-0959354311423435">MacKay, 1950</xref>). The other, “structural” aspect, describes the relationship between units of information. Although the structural aspect of information cannot be isolated from the metric aspect, there is a sense in which pattern structure possesses properties that cannot be captured by enumerating frequencies of different outcomes. Rather, the essence of structure lies in the interrelatedness of pattern elements. Symmetry, orderliness, harmony, balance, and simplicity have a profound influence on all aspects of human life from politics to science, logic, and art and conceptually precede mathematical formalization. The connection between the two aspects of information lies in the fact that by definition, good patterns are simple, that is, contain few elements or require little space or time to be described. The fact that complex patterns are the most numerous and consequently most probable reflects the limited analytical ability of the human observer.</p>
<p>One of the most important contributions to the study of complexity in psychology was made by Wendell Garner, whose work related pattern goodness to the probabilistic, information-theoretic concept of redundancy. Starting with what was known at the time namely that simple regular structures are also statistically rare, <xref ref-type="bibr" rid="bibr23-0959354311423435">Garner (1974)</xref> attempted to show that psychological complexity had its objective origin in statistical uncertainty. He began his exposition with a discussion of stimulus structure by citing a dictionary definition, according to which, structure is “. . .a complex system considered from the point of view of the whole rather than of any single part” (p. 2). Although Garner considered information and structure to be identical, he did not offer an explicit definition of information. Garner also distinguished between intrinsic and extrinsic structure, with the former term referring to the inherent structural properties of the stimulus which can be “defined independently of a user-organism” (p. 3). By contrast, extrinsic structure is only associated with the stimulus, often arbitrarily, and the stimulus “signifies something other than itself” (p. 3).</p>
<p>Garner began his exposition with defining “total sets” of patterns. These represent full factorizations of pattern properties along n dimensions each with x levels, producing x<sup>n</sup> patterns. Such total sets possess zero redundancy and contain maximum information. The definition of a total set is arbitrary and depends solely on the choice of relevant variables/ dimensions. According to Garner, redundancy is created by the selection of a subset from the total set. This is exemplified by the fact that in any subset of a non-redundant total set there is a certain amount of correlation between dimensions. This is what Garner calls “correlational” structure. Any subset of an exhaustive parent set possesses a degree of correlational structure, which can be more or less salient.</p>
<p>In an attempt to reconcile the quantitative basis of redundancy with the notion of pattern goodness, Garner started from two premises. First, he posited that “the properties of a single stimulus cannot be specified except in relation to the properties of sets within which it exists” (<xref ref-type="bibr" rid="bibr23-0959354311423435">1974</xref>, p. 9). Here, Garner implicitly linked the information-theoretic focus on populations/sets with the observation that regular patterns are invariant under transformations. At the same time, he rejected the possibility that individual patterns could possess intrinsic structure. Second, he proposed that each stimulus created an “inferred set” in the mind of the observer. Presumably, this contains all possible transformations of the perceived pattern. The meaning of the inferred set is ambiguous because, according to Garner, such a set could include not only structural transformations but also symbolic/semantic considerations. Nevertheless, he suggested that pattern goodness should be inversely proportional to the size of such an inferred set. In other words, since good patterns come from small total sets, they lead to the creation of small inferred sets. To test this hypothesis, <xref ref-type="bibr" rid="bibr24-0959354311423435">Garner and Clement (1963)</xref> compared participants’ judgments of goodness of simple dot patterns with the way in which the participants grouped the patterns into similar sets. The selected samples were members of an exhaustive set of 90 patterns constructed by marking five dots in a 3 x 3 grid. The only constraint was that each row and column should contain at least one dot. Set size was determined by the number of perceptually different patterns obtained by reflection and rotation, resulting in three distinct transformational sets. The participants were presented with all 90 possible patterns and asked (a) to rate them for goodness and (b) to divide them into arbitrary sets of similar patterns. There was a significant correlation between these two variables, prompting the authors to conclude that the perceived pattern uncertainty, which was associated with the size of the transformational set, represented the most important factor in determining pattern goodness.</p>
<p>This study has been influential in motivating thinking about complexity (see e.g., <xref ref-type="bibr" rid="bibr42-0959354311423435">Palmer, 1983</xref>) but a closer inspection gives some cause for questioning the validity of the original conclusions. The patterns employed in the study possess considerable symbolic value. Inspection of the original stimuli indicates that many of the good patterns resemble letters and familiar symbols. As the patterns became more complex, they had fewer associations (see <xref ref-type="bibr" rid="bibr12-0959354311423435">Corcoran, 1971</xref>, p. 50, for a similar criticism). This suggests that with small sampling spaces (e.g., 3 x 3 grids), participants resort to “non-structural” strategies to discriminate structurally similar patterns. A later study by <xref ref-type="bibr" rid="bibr30-0959354311423435">Ichikawa (1985)</xref> demonstrated that Equivalence Set Size (the size of a set of patterns formed by reflection and 90-degree rotation) was not a good predictor of 2-D pattern complexity.</p>
<p>Garner’s theorizing on structure, complexity, and goodness has had considerable impact on subsequent research in areas of perception and attention. This is obvious when one considers theories of feature integration which conceptualize visual stimuli in terms of multidimensional collections of features. Even more important is Garner’s contribution to the transformational approach to the study of pattern goodness. At the same time, his argument relating complexity to probability cannot be seen as a genuine advance with regard to the original information-theoretic approach. Rather than the complexity or goodness of a pattern being a consequence of the size of its parent set (or an inferred set), set size could equally be defined in terms of the complexity of the pattern. The more complex a pattern is the more perceptually different patterns it can generate by means of mathematical transformations. We propose that it is an inherent property of simple patterns/forms that they <italic>do not change</italic> under transformation. This poses a problem for the idea of a set as a causal factor. As stated earlier with regard to information theory, quantity cannot capture structure.</p>
<p>Notwithstanding potential problems, Garner’s work offers a crucial insight into the relationship between structure and quantity. His statement that “good patterns have few alternatives” (<xref ref-type="bibr" rid="bibr23-0959354311423435">1974</xref>, p. 21) elucidates the fact that simple, symmetrical and “good” patterns are statistically rare and impervious to change.</p>
</sec>
<sec id="section3-0959354311423435">
<title>Algorithmic Information Theory and descriptive coding languages</title>
<p>The difficulties of information theory coincided with developments in computational complexity theory which were paralleled in the psychological domain. The development of the Algorithmic Information Theory (AIT) represents an attempt to reconcile structural complexity with the probabilistic nature of information theory. Since good overviews are available elsewhere (e.g., <xref ref-type="bibr" rid="bibr36-0959354311423435">Li &amp; Vitanyi, 1997</xref>), only a very brief outline is given here. On the computational side, an important advance in the study of complexity was made by the work by <xref ref-type="bibr" rid="bibr32-0959354311423435">Kolmogorov (1965)</xref>, <xref ref-type="bibr" rid="bibr49-0959354311423435">Solomonoff (1964)</xref>, and <xref ref-type="bibr" rid="bibr9-0959354311423435">Chaitin (1969)</xref>. The theory of algorithmic complexity combines information theory with the theory of computation. Algorithmic complexity is defined in terms of the length of the shortest algorithm in any programming language, which computes a particular binary string. A string of length x is incompressible if the shortest program that can produce it is at least x bits long. The fundamental postulate of AIT is that the Kolmogorov complexity (Kx) of a sequence is roughly equivalent to the shortest algorithm that generates it. For simple structures it is clear what such algorithms should look like [e.g., 010101010… =&gt; x*(01)].</p>
<p>The measure makes it possible, at least theoretically, to compute the complexity of an individual string. Since structurally simple sequences (e.g., 010101010101010…) require simple descriptions, they also possess low Kolmogorov complexity. Conversely, random strings possess high Kolmogorov complexity—a property, which agrees with our view that randomness equals high complexity. Maximum Kolmogorov complexity is given by log n + C, that is, the description of a string equals its length (n) plus a constant (instruction to print). The positive contribution of Kolmogorov was his focus on the idea of compressibility, namely, the property of simple structures which enables them to be described or reproduced using short, simple instructions. The notion of compressibility is related to structural descriptors such as simplicity, periodicity, and symmetry.</p>
<p>Information-theoretic and AIT approaches attempt to relate the outcome (message or output) to a known agent (source or algorithm). In the case of the former, the entropy of a string cannot be known without the knowledge of the appropriate probability distribution of its source. In AIT approach, patterns are viewed as outputs of algorithms. However, when faced with a novel structure, human observers (scientists) usually have little information about its source—the very definition of novelty. They are compelled to study it from scratch and attempt to relate it to the information in their possession. At the same time, given sufficient time and effort, any structure can be compressed so that its initial form becomes unrecognizable. We propose that pattern rather than its source should represent the starting point for defining psychological complexity. We address this problem by pointing out the difficulty of describing a structure in terms of its generating process. We view the human observer as the ultimate reference point and all other generators (stochastic processes or algorithms) as results of human abstractive compression.</p>
<p>In the case of algorithmic approach, the input/output problem is reflected in the fact that apparently simple algorithms (e.g., expansion of π) can produce vastly complex outputs and perceptually and intuitively simple structures (e.g., fractals) often require complex and apparently interminable calculations. Measures of algorithmic complexity treat algorithms as “input” ignoring the fact that algorithms themselves represent outputs of vastly complex compression processes. The only way in which a correspondence between the information in the input and output can be established is to “unravel” the input to the point where it is completely transparent, that is, to decompress or “unfold” it fully (<xref ref-type="bibr" rid="bibr8-0959354311423435">Bennett, 1988</xref>). The problem is that no process can be completely isolated from its environment. The overall cost of compression can be expressed only in terms of the effort of generations of mathematicians and scientists, many unknown, who have devoted their lives to providing elegant and efficient abstract descriptions of different phenomena. Their effort, as well as many other factors, has to be taken into account when estimating the amount of compressed information. Thus, a fundamental problem for all algorithmic approaches can be succinctly formulated in two statements:</p>
<list id="list1-0959354311423435" list-type="order">
<list-item><p>Algorithms appear simple because the compressed information is “discarded” (<xref ref-type="bibr" rid="bibr7-0959354311423435">Bennett, 1987</xref>, <xref ref-type="bibr" rid="bibr8-0959354311423435">1988</xref>).</p></list-item>
<list-item><p>Algorithms are simple because apparently simple actions often have complex consequences.</p></list-item>
</list>
<p>The first statement refers to the problem of treating an algorithm as a starting point for complexity analysis. In the process of arriving at an algorithm (compressive abstraction) a great deal of information contained in the original phenomenon is hidden. This after all is the purpose of algorithms. Yet, this discarded information has not disappeared and can be assumed to equal the cost involved in arriving at the algorithm. The second statement refers to the universal irreversibility of most processes in accordance with the Second Law of Thermodynamics (e.g., <xref ref-type="bibr" rid="bibr18-0959354311423435">Feynman, Leighton, &amp; Sands, 1977</xref>). In either case, it is clear that simple (or apparently simple) algorithms can generate complex outputs. This can happen either because algorithms themselves contain large amounts of hidden information or because they tap into processes over which we have little control and cannot easily reverse. Equally, algorithms generating simple outputs can be made arbitrarily complex. Consequently, appealing to algorithms is not particularly helpful for understanding psychological complexity.</p>
<p>The above problems notwithstanding, many pattern-coding languages have been proposed based on algorithmic compression, which are widely used in psychology for describing structure. These models (<xref ref-type="bibr" rid="bibr47-0959354311423435">Simon, 1972</xref>) involve different kinds of algorithmic notation aimed at providing compact description of patterns. As pointed out by Simon, different coding languages produce relatively similar results irrespective of notation. This is because a simple pattern is by definition more compressible than a complex one. Specifically, both computational (<xref ref-type="bibr" rid="bibr32-0959354311423435">Kolmogorov, 1965</xref>) and psychological (e.g., <xref ref-type="bibr" rid="bibr16-0959354311423435">Falk &amp; Konold, 1997</xref>) formulations suggest that complexity represents the inverse of compressibility, either computational or psychological. In a sense, all pattern languages represent translations of the available information contained in a pattern into ultimately similar codes. These codes retain the structural information contained within the pattern but also add idiosyncratic coding information. Simon analyzed different pattern coding schemes (e.g., <xref ref-type="bibr" rid="bibr44-0959354311423435">Restle, 1970</xref>; <xref ref-type="bibr" rid="bibr48-0959354311423435">Simon &amp; Kotovsky, 1963</xref>; <xref ref-type="bibr" rid="bibr54-0959354311423435">Vitz &amp; Todd, 1969</xref>) and provided translations from one into another. Although certain schemes are suited to particular contexts, there appears to be a conceptual “common core” that all of these measures possess, resulting in high correlation with subjective perception of complexity.</p>
<p>Perhaps the most important such language is Leeuwenberg’s Structural Information Theory (SIT; <xref ref-type="bibr" rid="bibr33-0959354311423435">1969</xref>) and its modifications (e.g., <xref ref-type="bibr" rid="bibr51-0959354311423435">van der Helm, 2000</xref>). Leeuwenberg’s coding scheme produced impressive correlations with experimental data and has been influential in guiding psychologists’ treatment of complexity. The rationale behind this approach, which is shared by other authors, is that the complexity of (or structural information contained in) a pattern is compressible and expressible in a formal coding language. This approach is very similar to the AIT approach in that the complexity of a string equals the length of the shortest statement that can encode it. Its strengths are the development of a formal language, applicable to different types of structure, insensitivity to alphabet size, sensitivity to the hierarchical nature of structure, and high correlation with experimental data. However, in common with other attempts of this kind, Leeuwenberg’s and related schemes face conceptual and practical problems.</p>
<p>Leeuwenberg’s scheme represents a lexical system—a formal language in which the structure of patterns can be expressed. In this sense, his attempt is representative of a number of similar languages which translate a structure into a set of formal statements. How useful are such languages? On the one hand, they represent ingenious exercises in algorithmic compression, which often help bring to light certain aspects of structure. The importance of this line of thinking has been accentuated by the development of various computer-programming languages. On the other hand, a critic could argue that they represent formal translation of what is perceived and processed in the first place. If a pattern is complex, it is not surprising that its encoding will be complex. As noted by <xref ref-type="bibr" rid="bibr47-0959354311423435">Simon (1972)</xref>, most of the classic schemes correlate highly with one another, suggesting a same underlying principle, namely compressive or algorithmic translation—a same structural content is expressed in different ways, some of which are more efficient than others (in agreement with AIT; <xref ref-type="bibr" rid="bibr15-0959354311423435">Donderi, 2006</xref>, p. 79). What is missing is a clear definition of psychological information/complexity that avoids this kind of circularity.</p>
<p>SIT and similar schemes have provided interesting and ingenious ways of encoding structure. However, they generally face the same problems that face AIT (but see <xref ref-type="bibr" rid="bibr52-0959354311423435">van der Helm, 2004</xref>). They begin with a simple code (algorithm) for a given sequence and use the code to produce it. The possible forms of regularity are given in advance and used to specify different sequences. However, going in the opposite direction, that is, inferring the code from the pattern is difficult if not impossible for patterns of reasonably high complexity. As remarked elsewhere, Leeuwenberg “never suggested that complexity was captured by his coding scheme, only simplicity” (<xref ref-type="bibr" rid="bibr14-0959354311423435">Cutting &amp; Garvin, 1987</xref>, p. 370). The codes themselves are often as complex if not more so than the original sequences (with multiple levels of nesting and arbitrary chunkings). Despite the caveat that the number of different symbols in the code is what matters (<xref ref-type="bibr" rid="bibr34-0959354311423435">Leeuwenberg &amp; van der Helm, 1991</xref>), the “infrastructure” of the code (levels of nesting and operators) must be taken into account because it reflects the cost of compression. In our opinion, different codes represent a trade-off between encoding effort and apparent code complexity. Specifically, codes containing fewer symbols contain more levels of nested structure and vice versa. This means that even with simple strings it is possible to alternate between different codes of approximately equal complexity. If the most efficient code is the one containing the fewest structural units, this could be because one has ignored the cost of arriving at such a code.</p>
<p>A further point concerns the definition of complexity in SIT-based schemes. According to <xref ref-type="bibr" rid="bibr53-0959354311423435">van der Helm &amp; Leeuwenberg (1996)</xref>, pattern complexity can be defined as “the minimum amount of pattern information necessary to describe the pattern” (p. 444). This definition is circular—it does not point at any specific quantities that could be measured independently leaving the interpretation of information vague. This can be clearly demonstrated by considering a complex pattern of reasonable length. The more effort the investigators invest in finding and encoding possible regularities, the simpler the descriptions they are likely to come up with (see <xref ref-type="bibr" rid="bibr41-0959354311423435">Olivers, Chater, &amp; Watson, 2004</xref>, for related criticism). A question one needs to ask at this point is: “Does the brain really search for the most efficient encoding?” If so, the brain’s quest would be a never-ending one. For any structure of nontrivial complexity, it would have to cycle among countless alternatives, without ever coming to a decision (which is what happens in the case of intractable “random” patterns). Alternatively, if such a solution were found, it might rely on non-structural (semantic) factors or a novel, more general, structural rule. The brain would start by reading the string and attempting to compress it. If a structure is simple (e.g., symmetric or periodic), it is assimilated almost instantly and if it is complex, the brain searches for patterns, shortcuts, and heuristics in order to “break down” the complexity or “squeeze out” regularity (<xref ref-type="bibr" rid="bibr51-0959354311423435">van der Helm, 2000</xref>). If a structure is highly complex (“random” according to AIT), the brain (or computer) eventually gives up and the pattern is treated as “noise” which is inaccessible to analysis (e.g., SETI signal, “junk” DNA). This insight is highlighted by the study by <xref ref-type="bibr" rid="bibr3-0959354311423435">Alberoni (1962)</xref> in which subjects treated patterns as random only after failing to find any regularities in them.</p>
</sec>
<sec id="section4-0959354311423435">
<title>Information and its cost</title>
<p>In order to provide a consistent definition of psychological information, which overcomes the ambiguities of the classical approaches, we suggest a subject-centered distinction between two types of information. On the one hand there is <italic>available information</italic>, which corresponds to the totality of information contained in the pattern. In terms of information theory, this is provided by the set of frequency distributions of all possible combinations of symbols within a pattern, while in terms of AIT, this is given by its uncompressed form. This should be contrasted to <italic>accessible information</italic>, which is defined by the limited analytical ability of the observer. This might also be termed useful or meaningful information. The amount of accessible information depends on the properties of the stimulus (complexity) as well as a number of extrinsic factors in sense of Garner (<xref ref-type="bibr" rid="bibr23-0959354311423435">1974</xref>; e.g., individual differences and task demands). As shown in <xref ref-type="fig" rid="fig1-0959354311423435">Figure 1</xref>, the potentially infinite increase in complexity reflects increase in available information. This is true of accessible information only up to a point. As the complexity increases, the distance between the available and accessible information begins to increase too. Eventually, the observer has to abandon attempting to interpret the pattern and labels it random until a new regularity is discovered and the boundary of ignorance (boundary between available and accessible information) is shifted.</p>
<fig id="fig1-0959354311423435" position="float">
<label>Figure 1.</label>
<caption>
<p>Relationship between available and accessible information and complexity. See text for details.</p>
</caption>
<graphic xlink:href="10.1177_0959354311423435-fig1.tif"/>
</fig>
<p>The figure could be interpreted as showing that in any set of patterns there is much more available than accessible information (there are many more complex “intractable” patterns). It also elucidates the point that in any exhaustive set of patterns, only a few are perceived as simple. The corollary is that human observers operate with simple (statistically rare) patterns because they cannot access the wealth of available information hidden in more complex patterns and assimilate it into extant schemas. Available information is made accessible through a process of compression, pattern extraction, and relating the available information to the information in our possession. As we invest effort into studying and describing complex patterns, we eventually assimilate them and treat them as meaningful. One consequence of the increase in disparity between available and accessible information is the widely noted inverse relationship between pattern discriminability and its complexity.</p>
<p>What is often ignored is that these processes involve effort and cost (<xref ref-type="bibr" rid="bibr16-0959354311423435">Falk &amp; Konold, 1997</xref>). As proposed by <xref ref-type="bibr" rid="bibr7-0959354311423435">Bennett (1987)</xref> in the context of computation, the complexity of a message should be measured based on the amount of work that has gone into creating it. The problem with applying this clearly important concept to psychology is that the cost of abstraction and compression is difficult to quantify. In the case of classical information theory, the cost of locating a cell in a grid or the correct answer to “20 questions” is directly related to the magnitude of the context—the larger the grid, the longer it takes to locate the cell. The cost of transforming the available (all possible positions of a cell) into accessible information (the exact solution) provides an implicit measure of the effort invested into searching through the problem space until the solution is found.</p>
<p>The problem arises when one focuses on the structural aspect of information. Here, one has to measure the informational distance between the available information and a useful contraction/algorithm. As has been shown (<xref ref-type="bibr" rid="bibr10-0959354311423435">Chaitin, 2001</xref>), for sequences of a certain level of complexity, it is not possible to know if a better (more efficient) algorithm does not exist. For reasonably complex patterns the distance between available and accessible information is so large that the latter can never equal the former. The process of transforming potentially available into useful information is highly complex and irreversible. Any simple structure can be encoded in a complex way but at the same time, any encoding can hide almost infinitely many meanings. Alternatively, one can attempt to measure the amount of structural information present in an individual string and use this as a predictor of the ease with which such a string could be compressed using a general, psychologically valid principle.</p>
</sec>
<sec id="section5-0959354311423435">
<title>Complexity as change</title>
<p>In the light of the above discussion, there is a need to define complexity in a way which restores the link between the psychological and physico-mathematical domains. Such a definition should be based on a simple, primitive, and general notion that underpins human perception and cognition. Perhaps the most primitive is the notion of change. Change is of fundamental importance for psychology. Study of changes in sensation represents the basis of experimental psychology and psychophysics. Any textbook on the subject clearly demonstrates that enquiry into perception and cognition must begin with change. Similarly, there is overwhelming evidence that the primary role of the brain is to process change. Any account of visual and auditory processing stresses the importance of changes in physical parameters of the stimulus for its sensory encoding. Neurons fire in response to stimulus onset and changes in stimulus contour. Changes in stimulus structure are detected pre-attentionally and are reliably reflected in brain responses (e.g., Mismatch Negativity; <xref ref-type="bibr" rid="bibr40-0959354311423435">Näätänen &amp; Alho, 1995</xref>).</p>
<p>Change allows direct quantification of the relationship between pattern elements. As already stated, one of the reasons for the failure of information theory to capture the structural aspect of complexity/entropy was due to its focus on individual symbols (objects) and their frequencies at the expense of a description of their relationship. It is here that the importance of change becomes clear. Structural information (relationship between elements) is contained in the <italic>transition</italic> from one symbol (or element) to another and not in the symbols themselves. The idea that change might represent an important (if not the most important) source of psychological information was hinted at by <xref ref-type="bibr" rid="bibr5-0959354311423435">Attneave (1954)</xref>. He described a mental experiment, the focus of which was a simple image consisting of clearly defined areas of three different colors (an inkwell on a desk in a room; <xref ref-type="fig" rid="fig1-0959354311423435">Figure 1</xref>, p. 183). The image was divided into 4000 cells (pixels). In describing how observers would guess the colors by scanning the image pixel by pixel, Attneave hypothesized that errors would occur at the points of transition between areas of different color. The rest of the image would be highly redundant because once the observers settled on a correct color, they would make correct predictions most of the time. In other words, most of the time, the image was highly predictable. The exceptions were the boundaries between areas of different color. In addition, Attneave described a simple experiment in which participants were asked to reproduce an irregular closed figure by drawing 10 dots which resembled the shape as closely as possible (<xref ref-type="fig" rid="fig2-0959354311423435">Figure 2</xref>, p. 185). The participants were then asked to indicate the places on the original figure which the dots were supposed to represent. In most cases the dots were placed at points of the greatest change in direction of the contour. These were the points at which most information was concentrated (see also <xref ref-type="bibr" rid="bibr35-0959354311423435">Leyton, 1987</xref>).</p>
<fig id="fig2-0959354311423435" position="float">
<label>Figure 2.</label>
<caption>
<p>Hypothetical physical entropy curve elicited by an unchanging pattern (top panel) and a pattern containing change (bottom panel).</p>
</caption>
<graphic xlink:href="10.1177_0959354311423435-fig2.tif"/>
</fig>
<p>Despite this suggestive evidence, change has not been explicitly addressed in the study of complexity. This is perhaps because complexity research in psychology has been inspired by probability and geometry. While the former approach focuses on enumeration and quantification of different outcomes (e.g., symbols and their combinations), the latter stresses the importance of invariance (the inverse of variance/change). Invariance could be viewed as the opposite of change in the same way that complexity is the opposite of simplicity. If viewed in this way, the two perspectives are interchangeable. This is implicitly represented in the entropy/redundancy distinction, which views the former as the opposite of the latter (entropy = 1 – redundancy; <xref ref-type="bibr" rid="bibr5-0959354311423435">Attneave, 1954</xref>). Yet, psychological research has indicated that change is more difficult to process than the absence of change and that symmetrical information-theoretic probability distributions that treat change and its absence as equiprobable do not agree with distributions of scores on a number of complexity and randomness-related tasks, which are negatively skewed (<xref ref-type="bibr" rid="bibr16-0959354311423435">Falk &amp; Konold, 1997</xref>, p. 306). Briefly, observers consider as most random or complex those patterns which contain a large amount of change as long as the change itself is not regular.</p>
<p>Transformational approaches to pattern goodness/complexity (e.g., <xref ref-type="bibr" rid="bibr42-0959354311423435">Palmer, 1983</xref>) start with certain prescribed forms of invariance and assume that these govern the perception of structure. Many influential mathematical theories are founded on the notion of invariance (e.g., <xref ref-type="bibr" rid="bibr55-0959354311423435">Weyl, 1952</xref>) and invariance has been given a special place in psychological theorizing on complexity and goodness. The main problem with accepting structural invariance as the starting point is that it is very difficult if not impossible to define regularity because it is multifaceted and could be defined in different ways (e.g., symmetry, regularity, periodicity, monotonicity, invariance under motion or growth, etc.). We choose change rather than invariance because there is a sense in which change conceptually precedes invariance. <xref ref-type="bibr" rid="bibr13-0959354311423435">Cutting (1998)</xref> referred to invariance as absence of change and transformations as “ways of invoking a change” (p. 75). According to Weyl (as cited in <xref ref-type="bibr" rid="bibr19-0959354311423435">Feynman, 1999</xref>): “a thing is symmetrical if one can subject it to a certain operation and it appears exactly the same after the operation” (p. 1). Thus, invariance can easily be defined as resistance to change whereas the converse is not straightforward. The precedence of change extends to the way in which the brain processes sensory stimuli. While change is clearly important in the early processing stages (e.g., luminance and orientation differences) research has shown that invariance (symmetry) is exclusively encoded in the higher (extra-retinotopic) regions of the visual cortex (<xref ref-type="bibr" rid="bibr50-0959354311423435">Tyler et al., 2005</xref>).</p>
<p>Furthermore, change allows direct measurement of complexity/entropy in the sense that any action by an agent, human or nonhuman, involves change, and any conceivable action is accompanied by an irreversible conversion of energy. In other words, change equals increase in entropy, and this in turn equals cost. We propose that any action, however trivial, by an agent of limited life span must incur cost and that this cost is reflected in an increase in (physical or computational) entropy. In other words, and in the context of what follows, we are assuming that all computing (human or nonhuman) is thermodynamically irreversible in the sense of <xref ref-type="bibr" rid="bibr7-0959354311423435">Bennett (1987)</xref>. Registering change always costs more than registering no change. However trivial an operation might be, it requires some form of irreversible energy conversion. This means that in its interaction with the environment, the agent will have converted a certain amount of available energy, irrespective of its scale or apparent inactivity. This formulation brings together physical, computational, and psychological meanings of complexity and entropy.</p>
<p>In order to elucidate the physical/computational rationale behind our argument we describe a simple physical computing device, which reads a binary string one symbol at a time. Its physical entropy is assumed to increase monotonically (a necessary simplification, which does not affect the argument). Its algorithm is also assumed to be fully “unraveled” in the sense that no compression has been performed. It consists of a set of explicit instructions that could be carried out by the human observer. The algorithm instructs the machine to read the string and register change every time a zero changes into 1 or vice versa. Every time it does register a change, the machine performs extra work relative to a “blind” or inactive machine. This work increases the wear and tear of the physical parts of the machine (e.g., head and counter) and accelerates its dissipation. Even if the physical aspect of computing is ignored, the algorithm which instructs the machine to register and count instances of change is more complex than an algorithm that instructs the machine only to scan the string. Writing a “complex” algorithm costs more than writing a “simple” one. The actions associated with the more complex algorithm result in higher physical entropy.</p>
<p><xref ref-type="fig" rid="fig2-0959354311423435">Figure 2</xref> shows the hypothetical physical entropy curve of such a machine scanning a binary sequence as a function of time. In the top panel, the entropy rate is assumed to be constant because reading each zero costs the same amount of converted energy. We wish to stress that we do not know the shape of the empirical entropy function and are assuming it to be linear for the sake of simplicity. The bottom panel illustrates the increase in entropy rate caused by the presence of change in the string. Whenever the head encounters change, its entropy rate increases due to the additional work the computer has to perform in order to register it. This extra energy conversion accelerates the physical entropy rate of the machine. This example could easily be extrapolated to sensory coding. Above-threshold changes in stimulus intensity cause sensory neurons to fire above their background rate. This in turn increases the overall physical entropy of the neural network. The above discussion allows us to redefine some of the classical terms used in psychological complexity research which have thus far lacked formal definition. Runs (e.g., <xref ref-type="bibr" rid="bibr22-0959354311423435">Gambino &amp; Myers, 1967</xref>) explicitly refer to the portions of a string which do not contain change and alternations to the transitions between runs (instances of change). Number of alternations equals the number of changes and the number of runs in a pattern equals the number of changes plus one.</p>
<p>This example only applies to computers which possess a very limited memory capacity. Clearly, for such devices, the most complex string is 01010101… since it contains more instances of change than any other string. The situation is different with regard to human observers who have the capacity to retain and analyze higher-level structural information. There is a great deal of evidence that in both simultaneous (e.g., <xref ref-type="bibr" rid="bibr4-0959354311423435">Alexander &amp; Carey, 1968</xref>) and sequential (<xref ref-type="bibr" rid="bibr21-0959354311423435">Galanter &amp; Smith, 1958</xref>; <xref ref-type="bibr" rid="bibr25-0959354311423435">Garner &amp; Gottwald, 1967</xref>; <xref ref-type="bibr" rid="bibr45-0959354311423435">Royer &amp; Garner, 1966</xref>) modes of presentation of binary patterns, human participants consider higher levels of structure in the form of sub-patterns, which do not need to consist of runs of identical symbols (<xref ref-type="bibr" rid="bibr17-0959354311423435">Feldman &amp; Hanna, 1966</xref>). This is corroborated by substantial neurological evidence that the brain processes sensory and perceptual information hierarchically. Primate perceptual systems possess an interdependent hierarchical structure, with the primary centers, responsible for the processing of low-level information such as pitch or luminance difference. These pass on their outputs to higher centers which exhibit progressively greater levels of generality (high-level structural information; see, e.g., <xref ref-type="bibr" rid="bibr20-0959354311423435">Frackowiak et al., 2003</xref>, p. 177). Consequently, a plausible model of psychological complexity must accommodate the fact that the brain encodes change, that is, the relational aspect of psychological information, at different hierarchical levels. A complexity model based on a simple premise outlined in this paper (i.e., hierarchical change) correlated significantly with 25 out of 28 subjective and objective complexity data sets generated over 50 years of psychological complexity research (<xref ref-type="bibr" rid="bibr2-0959354311423435">Aksentijevic &amp; Gibson, in press</xref>).</p>
</sec>
<sec id="section6-0959354311423435">
<title>From Gestalt to complexity and back</title>
<p>The conceptualization of complexity in terms of change allows us to link the psychological, computational, and physical meanings of complexity and entropy. At the same time, it has implications for the Gestalt principle of Prägnanz or Minimum Principle according to which, the perceptual system seeks states which minimize expenditure (or conversion) of energy. The principle of proximity refers to the metric information (<xref ref-type="bibr" rid="bibr38-0959354311423435">MacKay, 1950</xref>)—the distance between elements determines the goodness of grouping. The principles of similarity and good continuation implicitly address change. One of the most important Gestalt laws is the principle of good continuation, according to which the simplest perceptual path through a structure is the straight line. <xref ref-type="fig" rid="fig3-0959354311423435">Figure 3</xref> demonstrates this principle: an X is commonly perceived as a crossing of two straight lines (the framed example in panel A), rather than two arrowheads or arcs facing each other (the adjacent example). We can hypothesize that the former is less complex in the sense that it minimizes energy conversion—the perception follows the shortest and simplest path (geodesic; <xref ref-type="bibr" rid="bibr1-0959354311423435">Aksentijevic, Elliott, &amp; Barber, 2001</xref>). However, the change in the stimulus forces the perceptual system to adopt a new, more complex, solution (panel B).</p>
<fig id="fig3-0959354311423435" position="float">
<label>Figure 3.</label>
<caption>
<p>Good continuation and change. Panel A: The perceptual system chooses the simplest interpretation (linear geodesics). Panel B: A change in the stimulus forces perception to adopt a more complex solution.</p>
</caption>
<graphic xlink:href="10.1177_0959354311423435-fig3.tif"/>
</fig>
<p>A change-based approach to complexity has the potential to provide the “missing link” between the phenomenological aspects of Gestalt principles and the early theorizing on the underlying mechanisms of perceptual grouping (<xref ref-type="bibr" rid="bibr31-0959354311423435">Koffka, 1935</xref>). Specifically, change represents a phenomenal/psychological analogue of energy. Perhaps, it might be more accurate to say that energy represents an abstract analogue of perceptual change. The principal task of the perceptual (and cognitive) systems is to interact with the environment and interpret it efficiently using limited resources. Perceptual and cognitive constraints caused by the limited energetic potential of the cognitive system necessitate search for pattern and regularity (absence of change). The need for the minimization of energy expenditure manifests itself as a predilection for grouping—for interpreting the perceptual (and cognitive) stimuli in the simplest possible way (<xref ref-type="bibr" rid="bibr11-0959354311423435">Chater, 1996</xref>).</p>
<p>The requirement that change should be considered at all levels is motivated by the Gestalt notion that a whole does not equal the sum of its parts. From the psychological perspective, the complexity of a whole can only be assessed if interrelated contributions of many levels are taken into account. Different accounts of perceptual grouping indicate that the goodness of a pattern is determined by the amount of change. In agreement with the Law of Prägnanz, goodness represents the state of minimum change (or minimum complexity) in a particular context. The laws of proximity and similarity could be said to represent the two aspects of entropy: magnitude and structural. The former law addresses the limited magnitude resolution of the human observer. Objects perceived as being close to one another will be grouped provided they are sufficiently similar. The dynamics of grouping depend on the magnitude of the objects and their mutual distance. It is clear that there is a grouping region—a range of distances and magnitudes that allows grouping to occur. Proximity reduces the amount of effort necessary to compare objects and/or discriminate between them. The law of similarity refers to redundancy, that is, structural simplicity. Objects that are structurally similar are automatically assigned to a group provided they are sufficiently close. Again, less effort is needed to compare and categorize them and redirect attention to the rest of the scene. When a visual (or auditory) scene consists of similar objects, its dynamics are simple, however we decide to describe them. The fundamental quality determining the simplicity of a scene is the amount of change.</p>
<p>In conclusion, we propose that psychological complexity is best explained and quantified in terms of change. Patterns that contain little change possess little information and have low entropy. Simple or regular patterns or objects are impervious to change. They are predictable, resistant to disruption, structurally stable, and easy to process, assimilate, and memorize. Part of the aesthetic appeal of periodicity and symmetry might lie in the fact that they appear to defy entropy (increase in disorder). A complex pattern contains more information than a simple pattern and is less predictable. It is less symmetric and will change if subjected to various operations. The human observer searches for informational shortcuts provided by the notions of symmetry, similarity, and regularity in order to <italic>minimize the expenditure (conversion) of energy</italic> associated with understanding.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p>
</fn>
</fn-group>
<bio>
<p>Aleksandar Aksentijevic is a senior lecturer in Psychology at the University of Roehampton, London. He is an experimental psychologist with interest in complexity, perceptual organization, auditory and cross-modal perception, psychology of music and the relationship between psychology, mathematics and science. Address: Department of Psychology, University of Roehampton, Holybourne Avenue, London SW15 4JD, UK. Email: <email>a.aksentijevic@roehampton.ac.uk</email></p>
<p>Keith Gibson sadly passed away prior to publication of this article. He was a lecturer in Computer Science at Birkbeck College, London. His interests included cryptography, especially the use of error correcting codes, and complexity.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aksentijevic</surname><given-names>A.</given-names></name>
<name><surname>Elliott</surname><given-names>M. A.</given-names></name>
<name><surname>Barber</surname><given-names>P. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Dynamics of perceptual grouping: Similarities in the organization of visual and auditory groups</article-title>. <source>Visual Cognition</source>, <volume>8</volume>, <fpage>349</fpage>–<lpage>358</lpage>.</citation>
</ref>
<ref id="bibr2-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aksentijevic</surname><given-names>A.</given-names></name>
<name><surname>Gibson</surname><given-names>K.</given-names></name>
</person-group> (<year>in press</year>). <article-title>Complexity equals change</article-title>. <source>Cognitive Systems Research</source>.</citation>
</ref>
<ref id="bibr3-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Alberoni</surname><given-names>F.</given-names></name>
</person-group> (<year>1962</year>). <article-title>Contribution to the study of subjective probability: I</article-title>. <source>Journal of General Psychology</source>, <volume>66</volume>, <fpage>261</fpage>–<lpage>264</lpage>.</citation>
</ref>
<ref id="bibr4-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Alexander</surname><given-names>C.</given-names></name>
<name><surname>Carey</surname><given-names>S.</given-names></name>
</person-group> (<year>1968</year>). <article-title>Subsymmetries</article-title>. <source>Perception &amp; Psychophysics</source>, <volume>4</volume>, <fpage>73</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr5-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Attneave</surname><given-names>F.</given-names></name>
</person-group> (<year>1954</year>). <article-title>Some informational aspects of visual perception</article-title>. <source>Psychological Review</source>, <volume>61</volume>, <fpage>183</fpage>–<lpage>193</lpage>.</citation>
</ref>
<ref id="bibr6-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Attneave</surname><given-names>F.</given-names></name>
</person-group> (<year>1959</year>). <source>Applications of information theory to psychology: A summary of basic concepts, methods, and results</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Henry Holt</publisher-name>.</citation>
</ref>
<ref id="bibr7-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>C. H.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Demons, engines and the second law</article-title>. <source>Scientific American</source>, <volume>257</volume>, <fpage>88</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr8-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>C. H.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Logical depth and physical complexity</article-title>. In <person-group person-group-type="editor">
<name><surname>Herken</surname><given-names>R.</given-names></name>
</person-group> (Ed.), <source>The universal Turing machine, a half-century survey</source> (pp. <fpage>227</fpage>–<lpage>257</lpage>). <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr9-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chaitin</surname><given-names>G. J.</given-names></name>
</person-group> (<year>1969</year>). <article-title>On the length of the programs for computing finite binary sequences: Statistical considerations</article-title>. <source>Journal of the Association for Computing Machinery</source>, <volume>16</volume>, <fpage>145</fpage>–<lpage>159</lpage>.</citation>
</ref>
<ref id="bibr10-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chaitin</surname><given-names>G. J.</given-names></name>
</person-group> (<year>2001</year>). <source>Exploring randomness</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr11-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chater</surname><given-names>N.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Reconciling simplicity and likelihood principles in perceptual organization</article-title>. <source>Psychological Review</source>, <volume>103</volume>, <fpage>566</fpage>–<lpage>581</lpage>.</citation>
</ref>
<ref id="bibr12-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Corcoran</surname><given-names>D. J. W.</given-names></name>
</person-group> (<year>1971</year>). <source>Pattern recognition</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Penguin Books</publisher-name>.</citation>
</ref>
<ref id="bibr13-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cutting</surname><given-names>J. E.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Information from the world around us</article-title>. In <person-group person-group-type="editor">
<name><surname>Hochberg</surname><given-names>J.</given-names></name>
</person-group> (Ed.), <source>Perception and cognition at century’s end: History, philosophy and theory</source> (pp. <fpage>69</fpage>–<lpage>93</lpage>). <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr14-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cutting</surname><given-names>J. E.</given-names></name>
<name><surname>Garvin</surname><given-names>J. J.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Fractal curves and complexity</article-title>. <source>Perception &amp; Psychophysics</source>, <volume>42</volume>, <fpage>365</fpage>–<lpage>370</lpage>.</citation>
</ref>
<ref id="bibr15-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Donderi</surname><given-names>D. C.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Visual complexity: A review</article-title>. <source>Psychological Bulletin</source>, <volume>132</volume>, <fpage>73</fpage>–<lpage>97</lpage>.</citation>
</ref>
<ref id="bibr16-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Falk</surname><given-names>R.</given-names></name>
<name><surname>Konold</surname><given-names>C.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Making sense of randomness: Implicit encoding as a bias for judgment</article-title>. <source>Psychological Review</source>, <volume>104</volume>, <fpage>301</fpage>–<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr17-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Feldman</surname><given-names>J.</given-names></name>
<name><surname>Hanna</surname><given-names>J. F.</given-names></name>
</person-group> (<year>1966</year>). <article-title>The structure of responses to a sequence of binary events</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>3</volume>, <fpage>371</fpage>–<lpage>387</lpage>.</citation>
</ref>
<ref id="bibr18-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Feynman</surname><given-names>R. P.</given-names></name>
<name><surname>Leighton</surname><given-names>R. B.</given-names></name>
<name><surname>Sands</surname><given-names>M.</given-names></name>
</person-group> (<year>1977</year>). <source>The Feynman lectures on physics</source>. <publisher-loc>Reading, MA</publisher-loc>: <publisher-name>Addison-Wesley</publisher-name>.</citation>
</ref>
<ref id="bibr19-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Feynman</surname><given-names>R. P.</given-names></name>
</person-group> (<year>1999</year>). <source>Six not-so-easy pieces: Einstein’s relativity, symmetry, and space-time</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Penguin</publisher-name>.</citation>
</ref>
<ref id="bibr20-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Frackowiak</surname><given-names>R. S. J.</given-names></name>
<name><surname>Friston</surname><given-names>K. J.</given-names></name>
<name><surname>Frith</surname><given-names>C.</given-names></name>
<name><surname>Dolan</surname><given-names>R.</given-names></name>
<name><surname>Price</surname><given-names>C. J.</given-names></name>
<name><surname>Zeki</surname><given-names>S.</given-names></name>
<name><surname>. . .Penny</surname><given-names>W. D.</given-names></name>
</person-group> (<year>2003</year>). <source>Human brain function</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr21-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Galanter</surname><given-names>E. H.</given-names></name>
<name><surname>Smith</surname><given-names>W. A. S.</given-names></name>
</person-group> (<year>1958</year>). <article-title>Some experiments on a simple thought-problem</article-title>. <source>American Journal of Psychology</source>, <volume>71</volume>, <fpage>359</fpage>–<lpage>366</lpage>.</citation>
</ref>
<ref id="bibr22-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gambino</surname><given-names>B.</given-names></name>
<name><surname>Myers</surname><given-names>J. L.</given-names></name>
</person-group> (<year>1967</year>). <article-title>Role of event runs in probability learning</article-title>. <source>Psychological Review</source>, <volume>74</volume>, <fpage>410</fpage>–<lpage>419</lpage>.</citation>
</ref>
<ref id="bibr23-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Garner</surname><given-names>W. R.</given-names></name>
</person-group> (<year>1974</year>). <source>The processing of information and structure</source>. <publisher-loc>Potomac, MD</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr24-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garner</surname><given-names>W. R.</given-names></name>
<name><surname>Clement</surname><given-names>D. E.</given-names></name>
</person-group> (<year>1963</year>). <article-title>Goodness of pattern and pattern uncertainty</article-title>. <source>Journal of Verbal Learning and Verbal Behavior</source>, <volume>2</volume>, <fpage>446</fpage>–<lpage>452</lpage>.</citation>
</ref>
<ref id="bibr25-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garner</surname><given-names>W. R.</given-names></name>
<name><surname>Gottwald</surname><given-names>R. L.</given-names></name>
</person-group> (<year>1967</year>). <article-title>Some perceptual factors in the learning of sequential patterns of binary events</article-title>. <source>Journal of Verbal Learning and Verbal Behavior</source>, <volume>6</volume>, <fpage>582</fpage>–<lpage>589</lpage>.</citation>
</ref>
<ref id="bibr26-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gell-Mann</surname><given-names>M.</given-names></name>
</person-group> (<year>1995</year>). <article-title>What is complexity?</article-title> <source>Complexity</source>, <volume>1</volume>, <fpage>1</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr27-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Grassberger</surname><given-names>P.</given-names></name>
</person-group> (<year>1986</year>). <article-title>How to measure self-generated complexity</article-title>. <source>Physica A: Statistical Mechanics and its Applications</source>, <volume>140</volume>, <fpage>319</fpage>–<lpage>325</lpage>.</citation>
</ref>
<ref id="bibr28-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hick</surname><given-names>W. E.</given-names></name>
</person-group> (<year>1952</year>). <article-title>On the rate of gain of information</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>4</volume>, <fpage>11</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr29-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hochberg</surname><given-names>J.</given-names></name>
<name><surname>McAlister</surname><given-names>E.</given-names></name>
</person-group> (<year>1953</year>). <article-title>A quantitative approach to figural “goodness”</article-title>. <source>Journal of Experimental Psychology</source>, <volume>46</volume>, <fpage>361</fpage>–<lpage>364</lpage>.</citation>
</ref>
<ref id="bibr30-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ichikawa</surname><given-names>S.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Quantitative and structural factors in the judgment of pattern complexity</article-title>. <source>Perception &amp; Psychophysics</source>, <volume>38</volume>, <fpage>101</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr31-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Koffka</surname><given-names>K.</given-names></name>
</person-group> (<year>1935</year>). <source>Principles of Gestalt psychology</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Lund Humphries</publisher-name>.</citation>
</ref>
<ref id="bibr32-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kolmogorov</surname><given-names>A. N.</given-names></name>
</person-group> (<year>1965</year>). <article-title>Three approaches to the quantitative definition of information</article-title>. <source>Problems in Information Transmission</source>, <volume>1</volume>, <fpage>1</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr33-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Leeuwenberg</surname><given-names>E. L. J.</given-names></name>
</person-group> (<year>1969</year>). <article-title>Quantitative specification of information in sequential patterns</article-title>. <source>Psychological Review</source>, <volume>76</volume>, <fpage>216</fpage>–<lpage>220</lpage>.</citation>
</ref>
<ref id="bibr34-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Leeuwenberg</surname><given-names>E. L. J.</given-names></name>
<name><surname>van der Helm</surname><given-names>P. A.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Accessibility, a criterion for regularity and hierarchy in visual pattern codes</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>35</volume>, <fpage>151</fpage>–<lpage>213</lpage>.</citation>
</ref>
<ref id="bibr35-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Leyton</surname><given-names>M.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Symmetry-curvature duality</article-title>. <source>Computer Vision, Graphics, and Image Processing</source>, <volume>38</volume>, <fpage>327</fpage>–<lpage>341</lpage>.</citation>
</ref>
<ref id="bibr36-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>M.</given-names></name>
<name><surname>Vitanyi</surname><given-names>P.</given-names></name>
</person-group> (<year>1997</year>). <source>An introduction to Kolmogorov complexity and its applications</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr37-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Luce</surname><given-names>R. D.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Whatever happened to information theory in psychology?</article-title> <source>Review of General Psychology</source>, <volume>7</volume>, <fpage>183</fpage>–<lpage>188</lpage>.</citation>
</ref>
<ref id="bibr38-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>MacKay</surname><given-names>D.</given-names></name>
</person-group> (<year>1950</year>). <article-title>Quantal aspects of scientific information</article-title>. <source>Philosophical Magazine</source>, <volume>41</volume>, <fpage>289</fpage>–<lpage>301</lpage>.</citation>
</ref>
<ref id="bibr39-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Miller</surname><given-names>G. A.</given-names></name>
</person-group> (<year>1953</year>). <article-title>What is information measurement?</article-title> <source>American Psychologist</source>, <volume>8</volume>, <fpage>3</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr40-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Näätänen</surname><given-names>R.</given-names></name>
<name><surname>Alho</surname><given-names>K.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Mismatch negativity: A unique measure of sensory processing in audition</article-title>. <source>International Journal of Neuroscience</source>, <volume>80</volume>, <fpage>317</fpage>–<lpage>337</lpage>.</citation>
</ref>
<ref id="bibr41-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Olivers</surname><given-names>C. N. L.</given-names></name>
<name><surname>Chater</surname><given-names>N.</given-names></name>
<name><surname>Watson</surname><given-names>D. G.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Holography does not account for goodness: A critique of van der Helm and Leeuwenberg (1996)</article-title>. <source>Psychological Review</source>, <volume>111</volume>, <fpage>242</fpage>–<lpage>260</lpage>.</citation>
</ref>
<ref id="bibr42-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Palmer</surname><given-names>S. E.</given-names></name>
</person-group> (<year>1983</year>). <article-title>The psychology of perceptual organization: A transformational approach</article-title>. In <person-group person-group-type="editor">
<name><surname>Beck</surname><given-names>J.</given-names></name>
<name><surname>Hope</surname><given-names>B.</given-names></name>
<name><surname>Rosenfeld</surname><given-names>A.</given-names></name>
</person-group> (Eds.), <source>Human and machine vision</source> (pp. <fpage>269</fpage>–<lpage>339</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr43-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pollack</surname><given-names>I.</given-names></name>
</person-group> (<year>1952</year>). <article-title>The information of elementary auditory displays</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>24</volume>, <fpage>745</fpage>–<lpage>749</lpage>.</citation>
</ref>
<ref id="bibr44-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Restle</surname><given-names>F.</given-names></name>
</person-group> (<year>1970</year>). <article-title>Theory of serial pattern learning: Structural trees</article-title>. <source>Psychological Review</source>, <volume>77</volume>, <fpage>481</fpage>–<lpage>495</lpage>.</citation>
</ref>
<ref id="bibr45-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Royer</surname><given-names>F. L.</given-names></name>
<name><surname>Garner</surname><given-names>W. R.</given-names></name>
</person-group> (<year>1966</year>). <article-title>Response uncertainty and perceptual difficulty of auditory temporal patterns</article-title>. <source>Perception &amp; Psychophysics</source>, <volume>1</volume>, <fpage>41</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr46-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shannon</surname><given-names>C.</given-names></name>
</person-group> (<year>1948</year>). <article-title>A mathematical theory of communication</article-title>. <source>The Bell Technical Journal</source>, <volume>27</volume>, <fpage>623</fpage>–<lpage>656</lpage>.</citation>
</ref>
<ref id="bibr47-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>H. A.</given-names></name>
</person-group> (<year>1972</year>). <article-title>Complexity and the representation of patterned sequences of symbols</article-title>. <source>Psychological Review</source>, <volume>79</volume>, <fpage>369</fpage>–<lpage>382</lpage>.</citation>
</ref>
<ref id="bibr48-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>H. A.</given-names></name>
<name><surname>Kotovsky</surname><given-names>K.</given-names></name>
</person-group> (<year>1963</year>). <article-title>Human acquisition of concepts for sequential patterns</article-title>. <source>Psychological Review</source>, <volume>70</volume>, <fpage>534</fpage>–<lpage>546</lpage>.</citation>
</ref>
<ref id="bibr49-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Solomonoff</surname><given-names>R. J.</given-names></name>
</person-group> (<year>1964</year>). <article-title>A formal theory of inductive inference, part 1 and part 2</article-title>. <source>Information &amp; Control</source>, <volume>7</volume>, <fpage>224</fpage>–<lpage>254</lpage>.</citation>
</ref>
<ref id="bibr50-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tyler</surname><given-names>C. W.</given-names></name>
<name><surname>Baseler</surname><given-names>H. A.</given-names></name>
<name><surname>Kontsevich</surname><given-names>L. L.</given-names></name>
<name><surname>Likova</surname><given-names>L. T.</given-names></name>
<name><surname>Wade</surname><given-names>A. R.</given-names></name>
<name><surname>Wandell</surname><given-names>B. A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Predominantly extra-retinotopic cortical response to pattern symmetry</article-title>. <source>Neuroimage</source>, <volume>24</volume>, <fpage>306</fpage>–<lpage>314</lpage>.</citation>
</ref>
<ref id="bibr51-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van der Helm</surname><given-names>P. A.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Simplicity versus likelihood in visual perception: From surprisals to precisals</article-title>. <source>Psychological Bulletin</source>, <volume>126</volume>, <fpage>770</fpage>–<lpage>800</lpage>.</citation>
</ref>
<ref id="bibr52-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van der Helm</surname><given-names>P. A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Transparallel processing by hyperstrings</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>101</volume>, <fpage>10862</fpage>–<lpage>10867</lpage>.</citation>
</ref>
<ref id="bibr53-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van der Helm</surname><given-names>P. A.</given-names></name>
<name><surname>Leeuwenberg</surname><given-names>E. L. J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Goodness of visual regularities: A nontransformational approach</article-title>. <source>Psychological Review</source>, <volume>103</volume>, <fpage>429</fpage>–<lpage>456</lpage>.</citation>
</ref>
<ref id="bibr54-0959354311423435">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vitz</surname><given-names>P. C.</given-names></name>
<name><surname>Todd</surname><given-names>R. C.</given-names></name>
</person-group> (<year>1969</year>). <article-title>A coded element model of the perceptual processing of sequential stimuli</article-title>. <source>Psychological Review</source>, <volume>76</volume>, <fpage>433</fpage>–<lpage>449</lpage>.</citation>
</ref>
<ref id="bibr55-0959354311423435">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Weyl</surname><given-names>H.</given-names></name>
</person-group> (<year>1952</year>). <source>Symmetry</source>. <publisher-loc>Princeton, CA</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>