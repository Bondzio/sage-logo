<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">SMM</journal-id>
<journal-id journal-id-type="hwp">spsmm</journal-id>
<journal-id journal-id-type="nlm-ta">Stat Methods Med Res</journal-id>
<journal-title>Statistical Methods in Medical Research</journal-title>
<issn pub-type="ppub">0962-2802</issn>
<issn pub-type="epub">1477-0334</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0962280212448975</article-id>
<article-id pub-id-type="publisher-id">10.1177_0962280212448975</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Comparison of four shape features for detecting hippocampal shape changes in early Alzheimer's</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Beg</surname><given-names>Mirza Faisal</given-names></name>
<xref ref-type="aff" rid="aff1-0962280212448975">1</xref>
<xref ref-type="corresp" rid="corresp1-0962280212448975"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Raamana</surname><given-names>Pradeep Reddy</given-names></name>
<xref ref-type="aff" rid="aff1-0962280212448975">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Barbieri</surname><given-names>Sebastiano</given-names></name>
<xref ref-type="aff" rid="aff2-0962280212448975">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wang</surname><given-names>Lei</given-names></name>
<xref ref-type="aff" rid="aff3-0962280212448975">3</xref>
</contrib>
<aff id="aff1-0962280212448975"><label>1</label>Medical Image Analysis Laboratory, School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada</aff>
<aff id="aff2-0962280212448975"><label>2</label>Fraunhofer MEVIS – Institute for Medical Image Computing, Bremen, Germany</aff>
<aff id="aff3-0962280212448975"><label>3</label>Departments of Psychiatry and Behavioral Sciences and Radiology, Northwestern University Feinberg School of Medicine, Chicago, IL, USA</aff>
</contrib-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Nathoo</surname><given-names>Farouk</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Lawson</surname><given-names>Andrew B</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Dean</surname><given-names>Charmaine B</given-names></name>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0962280212448975">Mirza Faisal Beg, Medical Image Analysis Laboratory, School of Engineering Science, Simon Fraser University, Burbnaby, BC, Canada. Email: <email>mfbeg.pkr1@sfu.ca</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2013</year>
</pub-date>
<volume>22</volume>
<issue>4</issue>
<issue-title>Special Issue: GEOMED 2011 Imaging</issue-title>
<fpage>439</fpage>
<lpage>462</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>We compare four methods for generating shape-based features from 3D binary images of the hippocampus for use in group discrimination and classification. The first method we investigate is based on decomposing the hippocampal binary segmentation onto an orthonormal basis of spherical harmonics, followed by computation of shape invariants by tensor contraction using the Clebsch–Gordan coefficients. The second method we investigate is based on the classical 3D moment invariants; these are a special case of the spherical harmonics-based tensor invariants. The third method is based on solving the Helmholtz equation on the geometry of the binary hippocampal segmentation, and construction of shape-descriptive features from the eigenvalues of the Fourier-like modes of the geometry represented by the Laplacian eigenfunctions. The fourth method investigates the use of initial momentum obtained from the large-deformation diffeomorphic metric mapping method as a shape feature. Each of these shape features is tested for group differences in the control (Clinical Dementia Rating Scale CDR 0) and the early (very mild) Alzheimer's (CDR 0.5) population. Classification of individual shapes is performed via a linear support vector machine based classifer with leave-one-out cross validation to test for overall performance. These experiments show that all of these feature computation approaches gave stable and reasonable classification results on the same database, and with the same classifier. The best performance was achieved with the shape-features constructed from large-deformation diffeomorphic metric mapping-based initial momentum.</p>
</abstract>
<kwd-group>
<kwd>Alzheimer's disease</kwd>
<kwd>classification</kwd>
<kwd>invariants</kwd>
<kwd>Laplacian</kwd>
<kwd>large-deformation diffeomorphic metric mapping</kwd>
<kwd>principal component analysis</kwd>
<kwd>spherical harmonics</kwd>
<kwd>support vector machines</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="sec1-0962280212448975"><title>1 Introduction</title>
<p>Shape plays an important and central role in object recognition. Specially, in applications to medical image analysis, shape of subcortical neuro-anatomical structures is a direct indicator of the presence and severity of underlying neuro-degenerative pathologies such as Alzheimer's or Parkinson's.<sup><xref ref-type="bibr" rid="bibr1-0962280212448975">1</xref>,<xref ref-type="bibr" rid="bibr2-0962280212448975">2</xref></sup> Medical imaging technologies such as magnetic resonance (MR) imaging now allow the non-invasive imaging of internal anatomy from which sufficiently high resolution object delineations can be achieved to make recognition and classification via shape-based techniques feasible.<sup><xref ref-type="bibr" rid="bibr3-0962280212448975">3</xref></sup> In this particular application area, several morphometric shape analysis models for quantifying the MRI-visible morphological variability of the human brain have been proposed that are sensitive to subtle changes in neuroanatomical shape, complexity and tissue characteristics.<sup><xref ref-type="bibr" rid="bibr2-0962280212448975">2</xref>–<xref ref-type="bibr" rid="bibr13-0962280212448975">13</xref></sup> The first step in shape-based classification involves the computation of a feature (scalar) or a set of features (vector) that are invariant to the pose of the object i.e. rotation and translation. The resulting feature measurements, either scalar, or vector, are fed into a classifier for detecting the presence of systematic group differences in the populations being analyzed, and to generate a classification system for assigning individual shapes into classes.</p>
<p>While shape-based techniques can be classified in several different ways,<sup><xref ref-type="bibr" rid="bibr14-0962280212448975">14</xref>–<xref ref-type="bibr" rid="bibr16-0962280212448975">16</xref></sup> a broad classification is to group these methods as being either <italic>intrinsic</italic>, or <italic>extrinsic</italic> approaches. In the intrinsic approach, shape descriptors are computed for each object in the database independently of all the others albeit using an approach common for all; these quantities could be physically meaningful scalar measurements such as volume of a structure, or they could be decompositions of the object in some carefully chosen basis, and feature vectors formed from some combinations of the basis coefficients. An example of this group of methods are the 3D moment invariants (3DMI) formed from binary segmentations of subcortical anatomical structures.<sup><xref ref-type="bibr" rid="bibr6-0962280212448975">6</xref></sup> In the extrinsic approach, shape-descriptive features are computed for each shape in the database with reference to a fixed reference shape. An example of this is the deformable template model, where shape is encoded via the spatial transformations (or, in turn, displacement vector fields) that, acting on the template, would transform the template to match the target object.<sup><xref ref-type="bibr" rid="bibr17-0962280212448975">17</xref>–<xref ref-type="bibr" rid="bibr20-0962280212448975">20</xref></sup> Group comparison and individual subject classification is then performed by analyzing the individual deformable transformations.</p>
<p>While there are many choices for both the feature space to represent the neuroanatomical shapes, and classifiers to apply to these features for discrimination, the particular choice made for these two stages in the classification system determines its overall accuracy, sensitivity and specificity. In this article, we fixed the classifier to be the now commonly used linear support vector machine (SVM) based classifier, fixed the database of MR images to be analyzed to one cohort of left hippocampal segmentations from very mild AD (CDR 0.5) and age-matched controls (CDR 0), and investigate the performance of four shape-descriptive feature techniques for shape-based classification of the hippocampus in identifying very mild Alzheimer's disease from controls. Although both intrinsic and extrinsic approaches have shown to provide stable shape analysis results, there is no comparison available of these approaches with a common classifier on a common database with a common classifier.</p>
<p>The four methods for calculating feature vectors that we investigate are:
<list id="list1-0962280212448975" list-type="order">
<list-item><p>Decomposition of the binary shape segmentation into a basis of spherical harmonics, followed by tensor contraction to construct 3D shape features invariant to rotation, translation and scale.<sup><xref ref-type="bibr" rid="bibr21-0962280212448975">21</xref></sup> We denote the shape-descriptive features thus obtained as the 3D tensor invariant (3DTI) features.</p></list-item>
<list-item><p>The standard 3D moment invariant (3DMI) based shape features.<sup><xref ref-type="bibr" rid="bibr6-0962280212448975">6</xref></sup></p></list-item>
<list-item><p>Shape features based on solving the Helmholtz equation (Δ<italic>u</italic> + λ<italic>u</italic> = 0) over the domain of the object, and using the eigenvalues to generate feature vectors.<sup><xref ref-type="bibr" rid="bibr22-0962280212448975">22</xref>,<xref ref-type="bibr" rid="bibr23-0962280212448975">23</xref></sup> Solving the eigenvalue problem for a general domain is intractable, and for subcortical shapes, we solve this problem by diagonalizing the integral operator which commutes with the Laplacian as has been shown.<sup><xref ref-type="bibr" rid="bibr24-0962280212448975">24</xref></sup> We denote these as 3D Laplacian invariant (3DLI) features.</p></list-item>
<list-item><p>Shape features based on the initial momenta of large-deformation diffeomorphic metric mapping (LDDMM) in the coordinates of a given template.<sup><xref ref-type="bibr" rid="bibr25-0962280212448975">25</xref>,<xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> In this case, a diffeomorphic geodesic mapping is computed that maps the target object to a given template, and through the conservation property of the momentum,<sup><xref ref-type="bibr" rid="bibr27-0962280212448975">27</xref></sup> the template and the momentum in the coordinates of the template represent the target object completely. We denote these as 3D geodesic shape invariants (3DGSI) features.</p></list-item>
</list></p>
<p>Before we set out describing various shape features and how they are constructed, we briefly introduce SVMs in <xref ref-type="sec" rid="sec2-0962280212448975">Section 2</xref>. In <xref ref-type="sec" rid="sec3-0962280212448975">Sections 3</xref> and <xref ref-type="sec" rid="sec4-0962280212448975">4</xref>, we discuss the 3DTI and the 3DMI features respectively. In <xref ref-type="sec" rid="sec5-0962280212448975">Section 5</xref>, we discuss the 3DLI features based on the eigenvalues of the Laplacian. In <xref ref-type="sec" rid="sec6-0962280212448975">Section 6</xref>, we summarize the methodology for constructing 3DGSI derived from the initial-momenta from the LDDMM algorithm. In <xref ref-type="sec" rid="sec7-0962280212448975">Section 7</xref>, we describe how the classification system based on SVM was applied in the current study. Next, in <xref ref-type="sec" rid="sec8-0962280212448975">Section 8</xref> we describe the common data set of left hippocampal segmentations from very mild AD (CDR 0.5) subjects and controls (CDR 0) on which we tested the system of computed features with SVM classification. Results are provided in <xref ref-type="sec" rid="sec9-0962280212448975">Section 9</xref>. We conclude this work with comparison to existing state-of-art and some final remarks in the last <xref ref-type="sec" rid="sec10-0962280212448975">Section 10</xref>.</p>
</sec>
<sec id="sec2-0962280212448975"><title>2 Support vector machines</title>
<p>Our aim in this work is to bring out insight into the comparative performance of different shape features using a common classifer. We have chosen SVM as the classifier as it is rooted firmly in statistical learning theory and has been very successful as a classification method across a diverse set of research fields e.g. image analysis, genomics, drug design, protein structure and function prediction outperforming traditional learning methods.<sup><xref ref-type="bibr" rid="bibr28-0962280212448975">28</xref>,<xref ref-type="bibr" rid="bibr29-0962280212448975">29</xref></sup> To set the context for our study, we briefly explain how an SVM works here, and refer the reader to thorough tutorials in the literature for a more detailed treatment.<sup><xref ref-type="bibr" rid="bibr30-0962280212448975">30</xref></sup></p>
<p>SVM is a binary non-parametric supervised learning technique that takes a set of labelled instances <inline-formula id="ilm1-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math1-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> where the <italic>y</italic><sub><italic>i</italic></sub> is either +1 or −1 indicating the class membership of the sample, and <bold>x</bold><sub><italic>i</italic></sub> ∈ ℝ<sup><italic>p</italic></sup>, a point in <italic>p</italic>-dimensional Euclidean space. When the two classes <italic>y</italic><sub><italic>i</italic></sub> ∈ {−1, 1} are linearly separable, SVM tries to find a hyperplane that separates the samples from class <italic>y</italic><sub><italic>i</italic></sub> = 1 from the class <italic>y</italic><sub><italic>i</italic></sub> = −1. The hyperplane is found so that it maximizes the margin between the two classes. This type of SVM is called a linear SVM taking the form <italic>f</italic>(<bold>x</bold>) = <bold>w</bold> · <bold>x</bold> + <italic>b</italic>, <italic>b</italic> ∈ ℝ<sup><italic>p</italic></sup> and <bold>w</bold> is the normal vector to the optimal separating hyperplane. The test sample <bold>x</bold> is assigned to one of the two classes <italic>y</italic><sub><italic>i</italic></sub> ∈ {−1, 1} depending on which side of the hyperplane the prediction <italic>f</italic>(<bold>x</bold>) falls for the test sample.</p>
<p>When the training data are linearly separable, SVM tries to maximize the margin in a way that there are no misclassified samples. However, in practice this is not always the case. In order to allow for few mislabelled examples, a soft-margin method is introduced, which will choose a hyperplane that separates the samples as cleanly as possible, simultaneously maximizing the distance to the nearest examples cleanly separated. A penalty constant <italic>C</italic> is introduced to control the trade-off between degree of misclassification and size of the margin. When the two classes are linearly inseparable, the data are mapped to a high-dimensional space via a kernel function and an optimal separating hyperplane is found in the transformed feature space. The classifier is a hyperplane in the transformed feature space and is non-linear in the original input space. In this study, we use a linear SVM (with soft-margin constraints) in order to focus on the comparative performance of biomarkers.</p>
</sec>
<sec id="sec3-0962280212448975"><title>3 Construction of feature vectors using spherical harmonics</title>
<p>In this section we summarize the shape analysis method presented earlier.<sup><xref ref-type="bibr" rid="bibr21-0962280212448975">21</xref></sup> Let us denote a 3D object by a function <italic>I</italic>(<italic>x</italic>, <italic>y</italic>, <italic>z</italic>) : ℝ<sup>3</sup> → ℝ. In the case of binary images such as those corresponding to binary segmentations of the left (or right) hippocampus, the function would simply be of value 1 inside the object, and 0 outside. We aim at finding a feature vector that is invariant with respect to translation and rotation of the object. Translation invariance is easily achieved by placing the origin of the 3D coordinates at the centroid <inline-formula id="ilm2-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math2-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> of the object, given by
<disp-formula id="disp-formula1-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math1-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1/</mml:mn><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>000</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>010</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>001</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula1-0962280212448975" xlink:href="10.1177_0962280212448975-eq1.tif"/></disp-formula>
where the <italic>m</italic><sub><italic>fgh</italic></sub> are moments of order <italic>n</italic> = <italic>f</italic> + <italic>g</italic> + <italic>h</italic>, <italic>n</italic> ∈ ℕ defined by
<disp-formula id="disp-formula2-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math2-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>fgh</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>∞</mml:mi> </mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>∞</mml:mi> </mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>∞</mml:mi> </mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msup><mml:mtext>d</mml:mtext><mml:mi>x</mml:mi><mml:mtext>d</mml:mtext><mml:mi>y</mml:mi><mml:mtext>d</mml:mtext><mml:mi>z</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula2-0962280212448975" xlink:href="10.1177_0962280212448975-eq2.tif"/></disp-formula>
</p>
<p>In order to achieve rotation invariance, the binary image is represented in spherical coordinates, using the coordinate transformations <italic>x</italic> = <italic>r</italic> sin θ cos φ, <italic>y</italic> = <italic>r</italic> sin θ sin φ, and <italic>z</italic> = <italic>r</italic> cos θ with 0 ≤ <italic>r</italic>, 0 ≤ θ ≤ π, and 0 ≤ φ ≤ 2π. Let us denote the space of all such differentiable functions with finite energy by ℱ. Following<sup><xref ref-type="bibr" rid="bibr21-0962280212448975">21</xref></sup> ℱ can be decomposed onto a direct sum of orthogonal subspaces, each of which is globally invariant under rotation. The functions {Ω<sub><italic>klm</italic></sub>}, given by
<disp-formula id="disp-formula3-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math3-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>lm</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula3-0962280212448975" xlink:href="10.1177_0962280212448975-eq3.tif"/></disp-formula>
form an orthonormal basis of ℱ.<sup><xref ref-type="bibr" rid="bibr21-0962280212448975">21</xref></sup> Here, the functions <italic>Y</italic><sub><italic>lm</italic></sub> are known as ‘spherical harmonics’ and are defined for <italic>l</italic> = 0, 1,…, ∞, and <italic>m</italic> = −<italic>l</italic>, (−<italic>l</italic> + 1),…, <italic>l</italic>. <italic>R</italic><sub><italic>kl</italic></sub>(<italic>r</italic>), <italic>k</italic> ≥ 1 is analogous to an integration constant and it can be proven that <italic>R</italic><sub><italic>kl</italic></sub>(<italic>r</italic>) does not depend on <italic>m</italic>.<sup><xref ref-type="bibr" rid="bibr31-0962280212448975">31</xref>,<xref ref-type="bibr" rid="bibr32-0962280212448975">32</xref></sup> While many functions <italic>R</italic><sub><italic>kl</italic></sub>(<italic>r</italic>) could be chosen to satisfy the orthonormality constraint on the basis {Ω<sub><italic>klm</italic></sub>}, we choose
<disp-formula id="disp-formula4-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math4-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msqrt><mml:mi>sin/</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mi>k</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula4-0962280212448975" xlink:href="10.1177_0962280212448975-eq4.tif"/></disp-formula>
so that the radial component of our basis is represented by harmonic functions. This way, by varying the parameter <italic>k</italic>, we can determine up to which frequency we want to analyze the shape.</p>
<sec id="sec4-0962280212448975"><title>3.1 Construction of invariants</title>
<p>In order to construct rotational invariants, the first step is to decompose the image <italic>I</italic>(<italic>r</italic>, θ, φ) onto the basis {Ω<sub><italic>klm</italic></sub>} of spherical harmonics by taking the inner product between the binary image and the basis functions
<disp-formula id="disp-formula5-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math5-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>〈</mml:mo><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo>〉</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn> </mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn> </mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn> </mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>klm</mml:mi> </mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi><mml:mtext>d</mml:mtext><mml:mi>r</mml:mi><mml:mtext>d</mml:mtext><mml:mi>θ</mml:mi><mml:mtext>d</mml:mtext><mml:mi>φ</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula5-0962280212448975" xlink:href="10.1177_0962280212448975-eq5.tif"/></disp-formula>
The <inline-formula id="ilm3-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math3-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are tensors of contravariant rank 1. Note that only <italic>m</italic> is a tensorial index, whereas <italic>k</italic> and <italic>l</italic> are simply parameters indexing the subspace ℰ<sub><italic>kl</italic></sub> to which the tensor belongs. Through tensor contraction (multiplication with tensors of covariant rank 1) we obtain tensors of order 0, which are rotational invariants. Since {Ω<sub><italic>klm</italic></sub>} is orthonormal, the variance of <inline-formula id="ilm4-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math4-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> can be modified by taking its conjugate. This way, we can define the following first set of rotational invariants
<disp-formula id="disp-formula6-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math6-0962280212448975"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>l</mml:mi> </mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula6-0962280212448975" xlink:href="10.1177_0962280212448975-eq6.tif"/></disp-formula>
If <inline-formula id="ilm5-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math5-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is a tensor of ℰ<sub><italic>kl</italic></sub>, then
<disp-formula id="disp-formula7-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math7-0962280212448975"><mml:mrow><mml:mrow><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mo>〈</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>lm</mml:mi><mml:mo>〉</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow/><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mo>〈</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>lm</mml:mi><mml:mo>〉</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub> </mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula7-0962280212448975" xlink:href="10.1177_0962280212448975-eq7.tif"/></disp-formula>
is also a tensor of ℰ<sub><italic>kl</italic></sub>, and this allows the construction of new tensors.<sup><xref ref-type="bibr" rid="bibr32-0962280212448975">32</xref>,<xref ref-type="bibr" rid="bibr33-0962280212448975">33</xref></sup> Here, 〈<italic>l</italic><sub>1</sub><italic>m</italic><sub>1</sub><italic>l</italic><sub>2</sub><italic>m</italic><sub>2</sub>|<italic>lm</italic>〉 are Clebsch–Gordan coefficients. In quantum mechanics, they are the coefficients relating the angular momentum of two particles. They can be computed using recursive formulas.<sup><xref ref-type="bibr" rid="bibr21-0962280212448975">21</xref></sup> We can thus use the tensors defined as above to construct further sets of invariants
<disp-formula id="disp-formula8-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math8-0962280212448975"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow/><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>l</mml:mi> </mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math><graphic alternate-form-of="disp-formula8-0962280212448975" xlink:href="10.1177_0962280212448975-eq8.tif"/></disp-formula>

<disp-formula id="disp-formula9-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math9-0962280212448975"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>lm</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow/><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>l</mml:mi> </mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>Π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:math><graphic alternate-form-of="disp-formula9-0962280212448975" xlink:href="10.1177_0962280212448975-eq9.tif"/></disp-formula>
Many symmetrical properties of the Clebsch–Gordan coefficients can be extended to apply to the invariants. These various symmetries allow us to define a set of ‘reduced invariants’ and restrict our computation in the following way
<disp-formula id="disp-formula10-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="math10-0962280212448975">  <mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>ReN</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow>  </mml:math><graphic alternate-form-of="disp-formula10-0962280212448975" xlink:href="10.1177_0962280212448975-eq10.tif"/></disp-formula>
where <inline-formula id="ilm6-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math6-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>sign</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mi>a</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mi/><mml:mrow/></mml:msup><mml:mn>1/</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>, and <italic>Re</italic> indicates the real part.</p>
</sec>
</sec>
<sec id="sec5-0962280212448975"><title>4 Shape features using 3D moment invariants</title>
<p>The 3D moment invariants<sup><xref ref-type="bibr" rid="bibr34-0962280212448975">34</xref>,<xref ref-type="bibr" rid="bibr35-0962280212448975">35</xref></sup> can be seen as a special case of the approach we just presented. Consider the set of functions
<disp-formula id="disp-formula11-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math11-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mi>~</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1/</mml:mn><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msqrt><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>lm</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula11-0962280212448975" xlink:href="10.1177_0962280212448975-eq11.tif"/></disp-formula>
with the restriction <italic>k</italic> = <italic>l</italic> + 2<italic>n</italic>, <italic>n</italic> ≥ 0. This set of functions is not a basis of ℱ and only orthonormal for a fixed <italic>k</italic>. It can be shown<sup><xref ref-type="bibr" rid="bibr21-0962280212448975">21</xref></sup> that the spherical harmonic <italic>Y</italic><sub><italic>lm</italic></sub> is a linear combination of terms of the form sin<sup><italic>m</italic></sup> θ cos<sup><italic>a</italic></sup> θ sin<sup><italic>m</italic>−<italic>b</italic></sup> φ cos<sup><italic>b</italic></sup> φ, where <italic>a</italic> ∈ {<italic>l</italic> − <italic>m</italic> − 2<italic>q</italic>}, <italic>a</italic> ≥ 0, <italic>q</italic> ≥ 0, and 0 ≤ <italic>b</italic> ≤ <italic>m</italic>. Thanks to the relation between (<italic>x</italic>, <italic>y</italic>, <italic>z</italic>) and (<italic>r</italic>, θ, φ) presented at the beginning of this section, we have
<disp-formula id="disp-formula12-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math12-0962280212448975"><mml:mrow><mml:mi>sin</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:mi>θ</mml:mi><mml:mi>cos</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mi>θ</mml:mi><mml:mi>sin</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:mi>φ</mml:mi><mml:mi>cos</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula12-0962280212448975" xlink:href="10.1177_0962280212448975-eq12.tif"/></disp-formula>
Given <italic>r</italic><sup><italic>k</italic>−<italic>m</italic>−<italic>a</italic></sup> = (<italic>x</italic><sup>2</sup> + <italic>y</italic><sup>2</sup> + <italic>z</italic><sup>2</sup>)<sup><italic>q</italic>+<italic>n</italic></sup>, the scalar product <inline-formula id="ilm7-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math7-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>kl</mml:mi> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>〈</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mi>~</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:math></inline-formula> can be represented as a linear sum of terms of the form
<disp-formula id="disp-formula13-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math13-0962280212448975"><mml:mrow><mml:mo>∭</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mi>q</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>d</mml:mtext><mml:mi>x</mml:mi><mml:mtext>d</mml:mtext><mml:mi>y</mml:mi><mml:mtext>d</mml:mtext><mml:mi>z</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula13-0962280212448975" xlink:href="10.1177_0962280212448975-eq13.tif"/></disp-formula>
which are moments of order 2(<italic>q</italic> + <italic>n</italic>) + <italic>b</italic> + (<italic>m</italic> − <italic>b</italic>) + <italic>a</italic> = <italic>l</italic> + 2<italic>n</italic> = <italic>k</italic>. We can thus obtain moment invariants using the tensor-based method, since the tensor contraction step only requires the basis functions for a given <italic>k</italic> to be orthonormal. There are a few potential drawbacks to moment invariants when compared to the tensor based approach presented earlier. For example, since <inline-formula id="ilm8-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math8-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> does not form a basis of ℱ, there are many shapes that will yield the same moment invariants. Moreover, since the functions <inline-formula id="ilm9-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math9-0962280212448975"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mi>~</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>klm</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> are not orthonormal, there can be a larger correlation of information between moment invariants.</p>
</sec>
<sec id="sec6-0962280212448975"><title>5 Construction of feature vectors using Laplacian eigenvalues</title>
<p>Given a bounded domain Ω of general shape in ℝ<sup>3</sup>, the eigenfunctions/eigenvalues of the domain found from solving the Helmholtz equation Δ<italic>u</italic> + λ<italic>u</italic> = 0 in Ω with Dirichlet boundary condition <italic>u</italic> = 0 on its boundary Γ give the Fourier-like modes based only on the geometry of the domain. Although the sequence of eigenvalues 0 &lt; λ<sub>1</sub> &lt; λ<sub>2</sub> ≤ … ≤ λ<sub><italic>k</italic></sub> ≤ … → ∞ of the Laplacian on the domain Ω is not enough to completely and exactly specify the shape of the domain Ω,<sup><xref ref-type="bibr" rid="bibr36-0962280212448975">36</xref></sup> thanks to some key properties of these Laplacian eigenvalues, they are shown to provide a very useful set of features to discriminate and cluster shapes.<sup><xref ref-type="bibr" rid="bibr22-0962280212448975">22</xref>,<xref ref-type="bibr" rid="bibr37-0962280212448975">37</xref>–<xref ref-type="bibr" rid="bibr39-0962280212448975">39</xref></sup> For example, the eigenvalues are preserved if the underlying domain Ω is translated or rotated,<sup><xref ref-type="bibr" rid="bibr40-0962280212448975">40</xref>,<xref ref-type="bibr" rid="bibr41-0962280212448975">41</xref></sup> and based on a property of <italic>domain monotonicity</italic>, the ratio of two eigenvalues is found to be invariant with respect to scaling of the underlying domain.<sup><xref ref-type="bibr" rid="bibr22-0962280212448975">22</xref></sup> Accordingly, for a given binary image Ω, three sets of pose and scale invariant features have been suggested<sup><xref ref-type="bibr" rid="bibr22-0962280212448975">22</xref></sup>
<disp-formula id="disp-formula14-0962280212448975"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math14-0962280212448975"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula14-0962280212448975" xlink:href="10.1177_0962280212448975-eq14.tif"/></disp-formula>
and
<disp-formula id="disp-formula15-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math15-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>λ/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d/</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula15-0962280212448975" xlink:href="10.1177_0962280212448975-eq15.tif"/></disp-formula>
where <italic>n</italic> is the number of features we wish to use for our recognition scheme, and <italic>d</italic><sub>1</sub> &lt; <italic>d</italic><sub>2</sub> ≤ <italic>d</italic><sub>3</sub> ≤ … ≤ <italic>d</italic><sub><italic>n</italic></sub> are the first <italic>n</italic> eigenvalues (counting multiplicity) of a sphere. The values of <italic>F</italic><sub>1</sub>(Ω) and <italic>F</italic><sub>2</sub>(Ω) are in the unit cube, and those of <italic>F</italic><sub>3</sub>(Ω) are in the interval [−1, 1]. The descriptor <italic>F</italic><sub>3</sub> can be interpreted as a measure of the deviation of the shape Ω from a sphere. The optimal number <italic>n</italic> of computed features depends on the problem being addressed and is determined experimentally. These sets of features have been shown to be tolerant of boundary noise and deformation and to have good inter-class discrimination capabilities.<sup><xref ref-type="bibr" rid="bibr22-0962280212448975">22</xref></sup> We use these shape-descriptive features computed on the left hippocampus for classifying very mild AD subjects from controls for the first time.</p>
<sec id="sec7-0962280212448975"><title>5.1 Computing eigenvalues of the Laplacian</title>
<p>The direct computations of the eigensystem of the Laplace operator ℒ is difficult since ℒ is unbounded. In Saito et al.<sup><xref ref-type="bibr" rid="bibr24-0962280212448975">24</xref></sup> this difficulty is avoided by finding an integral operator commuting with the Laplacian, without imposing a strict boundary condition a priori. This integral operator is given by
<disp-formula id="disp-formula16-0962280212448975"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math16-0962280212448975"><mml:mrow><mml:mi>K</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≜</mml:mo><mml:msub><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow></mml:msub><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>d</mml:mtext><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>   </mml:mi><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>Ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula16-0962280212448975" xlink:href="10.1177_0962280212448975-eq16.tif"/></disp-formula>
where <italic>K</italic> is the <italic>fundamental solution of the Laplacian</italic> or the <italic>harmonic kernel</italic>, which in 3D is given by
<disp-formula id="disp-formula17-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math17-0962280212448975"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1/4</mml:mn><mml:mi>π</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula17-0962280212448975" xlink:href="10.1177_0962280212448975-eq17.tif"/></disp-formula>
Thanks to the following two theorems (see e.g. Friedman<sup><xref ref-type="bibr" rid="bibr42-0962280212448975">42</xref></sup> and Saito,<sup><xref ref-type="bibr" rid="bibr24-0962280212448975">24</xref></sup> pp. 63–67 for the respective proofs) we know that ℒ has the same eigenfunctions as <inline-graphic xlink:href="10.1177_0962280212448975-img1.tif"/>, for which the eigen decomposition is much easier.</p><statement>
<title>Theorem 1</title>
<p>Let <inline-graphic xlink:href="10.1177_0962280212448975-img2.tif"/> and ℒ be operators on L<sup>2</sup>(Ω). Suppose <inline-graphic xlink:href="10.1177_0962280212448975-img3.tif"/> and ℒ commute and one of them has an eigenvalue with finite multiplicity. Then <inline-graphic xlink:href="10.1177_0962280212448975-img4.tif"/> and ℒ share the same eigenfunction corresponding to that eigenvalue, i.e. there exists a function <italic>u</italic> ∈ L<sup>2</sup>(Ω) such that <inline-graphic xlink:href="10.1177_0962280212448975-img5.tif"/><italic>u</italic> = λ<italic>u</italic> and ℒ<italic>u</italic> = μ<italic>u</italic>.</p></statement><statement>
<title>Theorem 2</title>
<p>The integral operator <inline-graphic xlink:href="10.1177_0962280212448975-img6.tif"/> as defined in (<xref ref-type="disp-formula" rid="disp-formula16-0962280212448975">2</xref>) commutes with the Laplacian ℒ = −Δ with the following non-local boundary condition
<disp-formula id="disp-formula18-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math18-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mi>Γ</mml:mi></mml:mrow></mml:msub><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∂/</mml:mo><mml:mi>u</mml:mi><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>d</mml:mtext><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>1/2</mml:mn><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>pv</mml:mtext><mml:msub><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mi>Γ</mml:mi></mml:mrow></mml:msub><mml:mo>∂/</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>d</mml:mtext><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula18-0962280212448975" xlink:href="10.1177_0962280212448975-eq18.tif"/></disp-formula>
for all <italic>x</italic> ∈ Γ, where ∂/∂ν<sub><italic>y</italic></sub> is the normal derivative operator at the point <italic>y</italic> ∈ Γ and d<italic>s</italic>(<italic>y</italic>) is the surface measure on Γ.</p></statement>
<p>Finally, in order to expand and represent the data supported on Ω in a basis {<italic>u</italic><sub><italic>j</italic></sub>}<sub><italic>j</italic>∈ℕ</sub> we need the following:<sup><xref ref-type="bibr" rid="bibr43-0962280212448975">43</xref></sup></p><statement>
<title>Theorem 3</title>
<p>The integral operator <inline-graphic xlink:href="10.1177_0962280212448975-img7.tif"/> is compact and self-adjoint on L<sup>2</sup>(Ω). Thus, the kernel <italic>K</italic>(<italic>x</italic>, <italic>y</italic>) has the following eigenfunction expansion (in the sense of mean convergence)
<disp-formula id="disp-formula19-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math19-0962280212448975"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>~</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math><graphic alternate-form-of="disp-formula19-0962280212448975" xlink:href="10.1177_0962280212448975-eq19.tif"/></disp-formula>
and {<italic>u</italic><sub><italic>j</italic></sub>}<sub><italic>j</italic>∈ℕ</sub> forms an orthonormal basis of L<sup>2</sup>(Ω).</p></statement>
</sec>
<sec id="sec8-0962280212448975"><title>5.2 Discretizing the eigenvalue computation</title>
<p>Since we want to analyze discrete binary images (3D volumes) we need to discretize the eigenvalue computation problem. Let us assume that the object Ω consists of a subset of voxels sampled on a regular grid, and that each sampling cell is a box of size <inline-formula id="ilm10-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math10-0962280212448975"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>Π</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:munderover><mml:mi>Δ</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Let <inline-formula id="ilm11-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math11-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>⊂</mml:mo><mml:mi>Ω</mml:mi></mml:mrow></mml:math></inline-formula> be the center of those cells in Ω. We can then approximate the integral eigenvalue problem <inline-graphic xlink:href="10.1177_0962280212448975-img8.tif"/><italic>u</italic> = λ<italic>u</italic>, where <inline-graphic xlink:href="10.1177_0962280212448975-img9.tif"/> is defined as in (<xref ref-type="disp-formula" rid="disp-formula16-0962280212448975">2</xref>), using the midpoint rule
<disp-formula id="disp-formula20-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math20-0962280212448975"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>w</mml:mi><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>   </mml:mi><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula20-0962280212448975" xlink:href="10.1177_0962280212448975-eq20.tif"/></disp-formula>
Let <italic>K</italic><sub><italic>i</italic>,<italic>j</italic></sub> ≜ <italic>wK</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>j</italic></sub>), <italic>u</italic><sub><italic>i</italic></sub> ≜ <italic>u</italic>(<italic>x</italic><sub><italic>i</italic></sub>), and <italic>u</italic> ≜ (<italic>u</italic><sub>1</sub>,…, <italic>u</italic><sub><italic>N</italic></sub>)<sup><italic>T</italic></sup> ∈ ℝ<sup><italic>N</italic></sup>. This way, the above equation can be written in a matrix-vector form as: <italic>Ku</italic> = λ<italic>u</italic>, where <italic>K</italic> = (<italic>K</italic><sub><italic>i</italic>,<italic>j</italic></sub>) ∈ ℝ<sup><italic>N</italic>,<italic>N</italic></sup> is a symmetric matrix. The largest eigenvalues of <italic>K</italic> then correspond to the smallest eigenvalues of the Laplacian computed over the domain Ω.</p>
</sec>
</sec>
<sec id="sec9-0962280212448975"><title>6 Construction of feature vectors using initial momenta of LDDMM</title>
<p>In this section, we summarize the shape analysis method based on the initial momentum obtained from the LDDMM algorithm.<sup><xref ref-type="bibr" rid="bibr25-0962280212448975">25</xref>,<xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> In contrast to the two previously described intrinsic approaches, this is an extrinsic approach that relies on shape features with respect to a given template shape. Let us define Ω ⊂ ℝ<sup>3</sup> as the template coordinate space, and <inline-graphic xlink:href="10.1177_0962280212448975-img10.tif"/> : Ω ↔ Ω as the set of diffeomorphic transformations on Ω. Large-deformation diffeomorphic metric mapping<sup><xref ref-type="bibr" rid="bibr25-0962280212448975">25</xref></sup> seeks a geodesic φ : [0, 1] → <inline-graphic xlink:href="10.1177_0962280212448975-img11.tif"/> where each point φ<sub><italic>t</italic></sub> ∈ <inline-graphic xlink:href="10.1177_0962280212448975-img12.tif"/>, <italic>t</italic> ∈ [0, 1] is a diffeomorphism of the domain Ω. Then the template image <italic>I</italic><sub>0</sub> evolves along the path to the target image <italic>I</italic><sub>1</sub> according to <inline-formula id="ilm12-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math12-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. At the endpoint <italic>t</italic> = 1 the template <italic>I</italic><sub>0</sub> is connected to the target image via <inline-formula id="ilm13-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math13-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The associated velocity field <italic>v</italic>, taken from the space of smooth velocity fields <italic>V</italic> on the domain Ω ⊂ ℝ<sup>3</sup>, is a solution to the differential equation <inline-formula id="ilm14-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math14-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mi>·</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> satisfying
<disp-formula id="disp-formula21-0962280212448975"><label>(3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math21-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>̂</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mo>·</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mover><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>arg</mml:mi><mml:mo>min</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn> </mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1/</mml:mn><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> </mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula21-0962280212448975" xlink:href="10.1177_0962280212448975-eq21.tif"/></disp-formula>
</p>
<p>By integrating the optimizer <inline-formula id="ilm15-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math15-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover></mml:mrow></mml:math></inline-formula> of this cost function we get the optimal change of coordinates <inline-formula id="ilm16-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math16-0962280212448975"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The superscript <italic>v</italic> in φ<sup><italic>v</italic></sup> is used to explicitly denote the dependence of φ on the associated velocity field <italic>v</italic>. The mapping <inline-formula id="ilm17-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math17-0962280212448975"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is guaranteed to be a diffeomorphism by enforcing a sufficient amount of smoothness on the elements of <italic>V</italic>.<sup><xref ref-type="bibr" rid="bibr44-0962280212448975">44</xref>,<xref ref-type="bibr" rid="bibr45-0962280212448975">45</xref></sup> We do this by defining a norm on <italic>V</italic> through a 3 × 3 differential operator <italic>L</italic> of the type <italic>L</italic> = (−αΔ + γ)<sup>α</sup> <italic>I</italic><sub>3×3</sub> where α &gt; 1.5 in 3D space such that ∥<italic>f</italic>∥<sub><italic>V</italic></sub> = ∥<italic>Lf</italic>∥<sub><italic>L</italic><sub>2</sub></sub>, and ∥ · ∥<sub><italic>L</italic><sub>2</sub></sub> is the standard <italic>L</italic><sub>2</sub> norm for square integrable functions defined on Ω. The gradient of the cost function (<xref ref-type="disp-formula" rid="disp-formula21-0962280212448975">3</xref>) is given by the following Freché derivative in <italic>V</italic>:
<disp-formula id="disp-formula22-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math22-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mn>2/</mml:mn><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:mi>D</mml:mi><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>∇</mml:mo><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula22-0962280212448975" xlink:href="10.1177_0962280212448975-eq22.tif"/></disp-formula>
where <inline-formula id="ilm18-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math18-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="ilm19-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math19-0962280212448975"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, |<italic>Dg</italic>| is the determinant of the Jacobian matrix and <italic>K</italic> is a compact self-adjoint operator <italic>K</italic> : <italic>L</italic><sub>2</sub>(Ω, ℝ<sup>3</sup>) → <italic>V</italic> uniquely defined by 〈<italic>a</italic>, <italic>b</italic>〉<sub><italic>L</italic><sub>2</sub></sub> = 〈<italic>Ka</italic>, <italic>b</italic>〉<sub><italic>V</italic></sub> such that for any smooth vector field <italic>f</italic> ∈ <italic>V</italic>, <italic>K</italic>(<italic>L</italic><sup>†</sup><italic>L</italic>)<italic>f</italic> = <italic>f</italic> holds. Also <italic>L</italic><sup>†</sup> is the adjoint of <italic>L</italic> and the notation <inline-formula id="ilm20-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math20-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi> </mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is employed. Finally the parameter 1/σ<sup>2</sup> provides weighted optimization between the regularization and data matching components, and is chosen to be the same for all matchings.</p>
<p>In order to compute <italic>v</italic>, this variational gradient is used in a standard gradient descent procedure, yielding the update
<disp-formula id="disp-formula23-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math23-0962280212448975"><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:mi>ɛ</mml:mi><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mi>E</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula23-0962280212448975" xlink:href="10.1177_0962280212448975-eq23.tif"/></disp-formula>
where <italic>n</italic> denotes the simulation number.</p>
<sec id="sec10-0962280212448975"><title>6.1 Initial momentum conservation</title>
<p>An important property of LDDMM is that momentum is conserved. This characteristic takes the form
<disp-formula id="disp-formula24-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math24-0962280212448975"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic alternate-form-of="disp-formula24-0962280212448975" xlink:href="10.1177_0962280212448975-eq24.tif"/></disp-formula>
where (<italic>L</italic><sup>†</sup><italic>L</italic>)<italic>v</italic><sub><italic>t</italic></sub> denotes the momentum of the evolving template transformation at time <italic>t</italic>. Therefore, the initial momentum (<italic>L</italic><sup>†</sup><italic>L</italic>)<italic>v</italic><sub>0</sub> completely specifies the full geodesic connecting the given template and target image<sup><xref ref-type="bibr" rid="bibr27-0962280212448975">27</xref></sup> and hence encodes the shape and form of the target. The feature vector corresponding to a target image <italic>I</italic><sub>1</sub> is thus given by the quantity <italic>Lv</italic><sub>0</sub>.</p>
</sec>
</sec>
<sec id="sec11-0962280212448975"><title>7 Group difference and classification</title>
<sec id="sec12-0962280212448975"><title>7.1 Testing differences</title>
<p>In order to perform shape classification, we start by computing a feature vector for each shape according to the methods described above. Each shape is therefore placed as a point in ℝ<sup><italic>p</italic></sup> (where <italic>p</italic> can be large). Prior to testing for group differences, the principal component analysis (PCA) approach is used to reduce the dimensionality of the point cloud.<sup><xref ref-type="bibr" rid="bibr46-0962280212448975">46</xref></sup> For the features obtained from the <italic>N</italic> shapes, these are first centered around the mean by subtracting the mean from each point. These centered feature vectors are then organized into a <italic>N</italic> × <italic>p</italic> matrix <italic>Y</italic>, where <italic>p</italic> is the size of the feature vectors. PCA can be computed by doing a singular value decomposition (SVD) of <italic>Y</italic>, defined as <italic>Y</italic> = <italic>PDQ</italic><sup><italic>T</italic></sup>, where <italic>P</italic><sup><italic>T</italic></sup> <italic>P</italic> = <italic>Id</italic>, <italic>Q</italic><sup><italic>T</italic></sup> <italic>Q</italic> = <italic>Id</italic> and <italic>D</italic> is a diagonal matrix consisting of the singular values of <italic>Y</italic>, in this case ordered in non-increasing fashion, are zero beyond the rank(Y)=N. The PCA is then given by <italic>Y</italic>′ = <italic>PD</italic>. A reduced number of the first <italic>M</italic>, <italic>M</italic> &lt; <italic>N</italic>, principal components are retained. These represent the original set of points in ℝ<sup><italic>M</italic></sup>, a reduced <italic>M</italic> dimensional space. These are then used in a non-parametric permutation test to determine if this reduced feature vector is statistically different between the two subject groups.</p>
<p>To test for the presence of group differences between the control group (group 1) and the disease group (group 2, or CDR 0.5 group in our case) with the computed feature vectors, let us define
<disp-formula id="disp-formula25-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math25-0962280212448975"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi> </mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G roup</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic alternate-form-of="disp-formula25-0962280212448975" xlink:href="10.1177_0962280212448975-eq25.tif"/></disp-formula>
and
<disp-formula id="disp-formula26-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math26-0962280212448975"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi> </mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic alternate-form-of="disp-formula26-0962280212448975" xlink:href="10.1177_0962280212448975-eq26.tif"/></disp-formula>
as the sample means of the first <italic>M</italic> principal component values for each group, and <inline-formula id="ilm21-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math21-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover></mml:mrow></mml:math></inline-formula> as the pooled (common) sample covariance. We want to test the null hypothesis that the two groups have equivalent distributions. This is done by measuring the significance of group variation in a permutation test as follows. Monte Carlo simulations are used to generate a large number (a typical number is 10,000) of uniformly distributed group membership labels. For each permutation, new group means and covariances are calculated, and PCA performed. The coefficients along the reduced PCs are then used to compute Hötelling's <italic>T</italic><sup>2</sup> statistic,<sup><xref ref-type="bibr" rid="bibr47-0962280212448975">47</xref></sup> which for two samples takes the form
<disp-formula id="disp-formula27-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math27-0962280212448975"><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>≐</mml:mo><mml:msub><mml:mrow><mml:mi>N/</mml:mi></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mo>̂</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>Group</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula27-0962280212448975" xlink:href="10.1177_0962280212448975-eq27.tif"/></disp-formula>
The collection of <italic>T</italic><sup>2</sup> statistics from each permutation gives rise to an empirical distribution <inline-formula id="ilm22-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math22-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> according to
<disp-formula id="disp-formula28-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math28-0962280212448975"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N/</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>G</mml:mtext><mml:mi>roup</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>M</mml:mi><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula28-0962280212448975" xlink:href="10.1177_0962280212448975-eq28.tif"/></disp-formula>
The null hypothesis that the two groups have equal distributions is rejected when
<disp-formula id="disp-formula29-0962280212448975"><label>(4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math29-0962280212448975"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup> </mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mover><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>d</mml:mtext><mml:mi>f</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula29-0962280212448975" xlink:href="10.1177_0962280212448975-eq29.tif"/></disp-formula>
falls below a predefined significance level, e.g. 0.05.</p>
</sec>
<sec id="sec13-0962280212448975"><title>7.2 Classification of individual shapes using SVM</title>
<p>After testing for the presence of group differences, the set of features are fed into a linear SVM<sup><xref ref-type="bibr" rid="bibr48-0962280212448975">48</xref></sup> and tested for their ability to classify the individual subjects according to their correct membership into the two groups. Cross-validation is performed using leave-one-out trials. In each trial, one subject is set aside, PCA is performed on the remaining subjects from the training set. Features from the <italic>N</italic> − 1 subjects are projected on to principal components and SVM trained in the projected space. The test subject is projected onto the same principal components obtained from training set alone, which would be used by the trained SVM. Classification of the test subject by the SVM is noted. This process is repeated until each subject has been excluded from training once, and tested for classification by an SVM trained on the rest. This ascertains the generalization capability of the classifier. The mean accuracy over all the trials is taken to be the accuracy of this particular classifier architecture. A receiver operating characteristic (ROC) curve<sup><xref ref-type="bibr" rid="bibr49-0962280212448975">49</xref></sup> is generated using prediction scores output by SVM for all test subjects and the total area under the ROC curve (AUC) is also measured to rate the classification performance.</p>
<p>There are two free parameters in this classifier system – (1) the number of principal components <italic>M</italic> chosen at the dimensionality reduction stage, and, (2) the soft-margin penalization constant <italic>C</italic>. Model selection is performed through a grid parameter search to determine the optimal values for <italic>C</italic> and <italic>M</italic>, in the following ranges log<sub>10</sub><italic>C</italic> = −5, −4,…, +4, +5 and <italic>M</italic> = 1… <italic>rank</italic>(<italic>T</italic>). Here <italic>T</italic> = <italic>T</italic><sub><italic>N</italic>−1×<italic>p</italic></sub> being the feature matrix used for training, where <italic>p</italic> is the number of features obtained for each type of computed invariants. For each set of <italic>C</italic> and <italic>M</italic>, leave-one-out cross validation is performed to measure the classification accuracy and the AUC. The optimal values for <italic>C</italic> and <italic>M</italic> are chosen based on the highest AUC, which is a more stable measure than the decision-threshold-dependent accuracy.<sup><xref ref-type="bibr" rid="bibr49-0962280212448975">49</xref></sup> The training and validation were performed using the MATLAB statistics, bioinformatics and optimization Toolboxes.<sup><xref ref-type="bibr" rid="bibr50-0962280212448975">50</xref></sup> The results are presented in <xref ref-type="sec" rid="sec9-0962280212448975">Section 9</xref>.</p>
</sec>
</sec>
<sec id="sec14-0962280212448975"><title>8 Application to an Alzheimer's study</title>
<sec id="sec15-0962280212448975"><title>8.1 Data set</title>
<p>We test the methods described above in a dataset of hippocampal segmentations used in a previously published study<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref>,<xref ref-type="bibr" rid="bibr51-0962280212448975">51</xref></sup> of 18 very mild dementia of the Alzheimer type (DAT) (Clinical Dementia Rating Scale,<sup><xref ref-type="bibr" rid="bibr52-0962280212448975">52</xref></sup> CDR 0.5) subjects and 26 non-demented (CDR 0) controls. Binary hippocampal segmentations were generated using Christensen's matching algorithm.<sup><xref ref-type="bibr" rid="bibr53-0962280212448975">53</xref></sup> To obtain the CDR, an experienced clinician conducted semi-structured interviews with an informant and the subject to assess the subjects cognitive and functional performance; a neurological examination also was obtained. The clinician determined the presence or absence of dementia and, when present, its severity with the Clinical Dementia Rating (CDR), where CDR 0 indicated no dementia and CDR 0.5 indicated very mild dementia. The clinical diagnosis of DAT was in accordance with standard criteria and was verified by the neuropathologic diagnosis of AD in 93% of cases.<sup><xref ref-type="bibr" rid="bibr54-0962280212448975">54</xref></sup> Although elsewhere the CDR 0.5 individuals in our sample may be considered to have mild cognitive impairment,<sup><xref ref-type="bibr" rid="bibr55-0962280212448975">55</xref></sup> they fulfill our diagnostic criteria for very mild DAT and at autopsy overwhelmingly have neuropathologic AD.<sup><xref ref-type="bibr" rid="bibr56-0962280212448975">56</xref></sup> The mean ± standard deviation (SD) age for the CDR 0 group is 73± 7.0 years, and for the CDR 0.5 group is 74 ± 4.4 years. The gender distribution (M/F) of the subjects is CDR 0: 12/14, CDR 0.5: 11/7. The template used for LDDMM is obtained from the same source as the other subjects in the study, and is the same as previously used,<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> but is not otherwise included in the data analysis.</p>
</sec>
<sec id="sec16-0962280212448975"><title>8.2 Shape feature computation</title>
<p>We used the left hippocampus for feature computation and subsequent discrimination using the above four methods. The right hippocampus can be similarly computed. However, the left hippocampal volume has been shown to be better at discriminating mild cognitive impaired (MCI) status<sup><xref ref-type="bibr" rid="bibr57-0962280212448975">57</xref></sup> and also offers better predictive power for conversion from MCI to AD<sup><xref ref-type="bibr" rid="bibr58-0962280212448975">58</xref></sup> as compared to the right hippocampal volume. Our own previous work<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> showed a larger group difference using 3DGSI shape features of the left (<italic>p</italic> = 0.007) than the right hippocampus (<italic>p</italic> = 0.06).</p>
<p>The 3DTI invariants computed by decomposing the hippocampi onto a basis of spherical harmonics were obtained by using the parameters <italic>k</italic> = 3 and <italic>l</italic> = 6. These parameters were chosen empirically. A larger value of <italic>l</italic> implies a more precise description of the shape, at the cost of computational time. The parameter <italic>k</italic> determines up to which frequency we want to analyze the shape. In our implementation, the Clebsch–Gordan coefficients 〈<italic>l</italic><sub>1</sub><italic>m</italic><sub>1</sub><italic>l</italic><sub>2</sub><italic>m</italic><sub>2</sub>|<italic>lm</italic>〉 were computed by using their relation to the Wigner 3-j symbol:
<disp-formula id="disp-formula30-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math30-0962280212448975"><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>lm</mml:mi><mml:mo>〉</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msqrt><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula30-0962280212448975" xlink:href="10.1177_0962280212448975-eq30.tif"/></disp-formula>
The Wigner 3-j symbols are in turn computed by using the GNU scientific library function gsl_sf_coupling_3j_e. Note that the arguments of this function are given in half-integer units.</p>
<p>For the 3DLI method where the feature vector is computed using the eigenvalues of the Laplacian, <italic>F</italic><sub>1</sub> from equation (<xref ref-type="disp-formula" rid="disp-formula14-0962280212448975">1</xref>) is computed with <italic>n</italic> = 1000. As an example, <xref ref-type="fig" rid="fig1-0962280212448975">Figure 1</xref> shows the first three Laplacian eigenfunctions computed on three randomly selected hippocampal shapes. For the 3DMI features, we computed the 12 moment invariants up to order three, using the BRAINVISA package.<sup><xref ref-type="bibr" rid="bibr59-0962280212448975">59</xref></sup>
<fig id="fig1-0962280212448975" position="float"><label>Figure 1.</label><caption><p>Shown in the first three rows are the first three Laplacian eigenfunctions computed on three different hippocampal shapes, where each column contains the eigenfunctions on one chosen hippocampal shape. In the last row, also shown are the voxels where the third eigenfunction changes sign. As per the well-known property of the <italic>n</italic>th Laplacian eigenfunctions to divide the domain into at most <italic>n</italic> divisions, the third eigenfunction is used for dividing the hippocampus into three parts that can be used for various other morphometric analyses.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig1.tif"/>
</fig></p>
<p>For the 3DGSI method, the features computed were the initial momentum reported previously.<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup></p>
</sec>
<sec id="sec17-0962280212448975"><title>8.3 Studying the robustness of each feature set</title>
<p>We have described four different shape features that we have used for this study. Each of these feature sets has one or more parameters associated with it. For example, 3dTI has two parameters <italic>k</italic> and <italic>l</italic>. Feature set 3dLI has two paramers: Type of invariants( <italic>F</italic><sub>1</sub>/<italic>F</italic><sub>2</sub>) and number of eigenvalues <italic>n</italic> used to compute invariants. The parameter associated with 3dGSI is the template to compute initial momentum. There are no parameters associated with 3dMI. Ideally we would like the classification performance of each feature set to be robust with respect to its associated parameters. In order to study the robustness of a feature set, we computed features corresponding to different values of parameters and repeated the classification tests and evaluated their discrimination performance.</p>
<p>We have chosen the following ranges for different parameters associated with different feature sets. For 3dTI, we varied the parameter <italic>l</italic> = 3, 6 and 9 which captures the 3dTI features at different levels of precision. From our previous experience, we believe <italic>k</italic> = 3 is a suitable frequency associated with hippocampal shape analysis. For 3dLI, we computed the features for <italic>n</italic> = 199, 999, 3999 and 10,000 for both <italic>F</italic><sub>1</sub> and <italic>F</italic><sub>2</sub>. For 3dGSI, we have chosen two different templates: HASD5827 and ADRC10038. The template HASD5827 is chosen from the same cohort and ADRC10038 is from a different cohort. Both of these templates have not been included in this study otherwise.</p>
</sec>
</sec>
<sec id="sec18-0962280212448975"><title>9 Results</title>
<sec id="sec19-0962280212448975"><title>9.1 Features tested for group differences</title>
<p>After performing principal component analysis on the feature vectors computed by using the different methods, we retained the set of principal components that accounted for 95% of the total variance. The distribution of eigenvalues corresponding to the principal eigenfunctions is shown in <xref ref-type="fig" rid="fig2-0962280212448975">Figure 2</xref>, and the number of components accounting for 95% of the total variance are listed in <xref ref-type="table" rid="table1-0962280212448975">Table 1</xref>.
<fig id="fig2-0962280212448975" position="float"><label>Figure 2.</label><caption><p>Distribution of eigenvalues for all PCA eigenfunctions computed using the feature vectors on the data obtained from (a) tensors, (b) moments, (c) Laplacian eigenvalues and (d) LDDMM's initial momenta. PCA: principal component analysis; LDDMM: large-deformation diffeomorphic metric mapping; 3DTI: 3D tensor invariant; 3DMI: 3D moment invariant; 3DLI: 3D Laplacian invariant; 3DGSI: 3D geodesic shape invariant.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig2.tif"/>
</fig>
<table-wrap id="table1-0962280212448975" position="float"><label>Table 1.</label><caption><p>The number of components accounting for 95% of the total variance for each feature method.</p></caption>
<graphic alternate-form-of="table1-0962280212448975" xlink:href="10.1177_0962280212448975-table1.tif"/>
<table frame="hsides"><thead>
<tr><th>3DTI</th>
<th>3DMI</th>
<th>3DLI</th>
<th>3DGSI</th>
</tr></thead>
<tbody>
<tr>
<td>No. of components</td>
<td>31</td>
<td>2</td>
<td>1</td>
<td>34</td>
</tr>
<tr>
<td>Total no. of features</td>
<td>≥1.9e5</td>
<td>12</td>
<td>998</td>
<td>≥1.3e6</td>
</tr>
</tbody>
</table>
<table-wrap-foot><fn id="table-fn1-0962280212448975"><p>3DTI: 3D tensor invariant; 3DMI: 3D moment invariant; 3DLI: 3D Laplacian invariant; 3DGSI: 3D geodesic shape invariant.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table2-0962280212448975" position="float"><label>Table 2.</label><caption><p>Classification performances for the four shape features for discriminating very mild AD from age-matched controls.</p></caption><graphic alternate-form-of="table2-0962280212448975" xlink:href="10.1177_0962280212448975-table2.tif"/>
<table frame="hsides" rules="groups"><thead>
<tr><th>Features</th><th>AUC</th><th>Accuracy (%)</th><th>Specificity (%)</th><th>Sensitivity (%)</th><th><italic>M</italic></th><th><italic>C</italic></th>
</tr></thead>
<tbody>
<tr>
<td>3DMI</td>
<td>0.69</td>
<td>68.1</td>
<td>69.2</td>
<td>66.6</td>
<td>1</td>
<td>0.01</td>
</tr>
<tr>
<td>3DTI</td>
<td>0.79</td>
<td>75</td>
<td>76.9</td>
<td>72.2</td>
<td>17</td>
<td>0.01</td>
</tr>
<tr>
<td>3DLI</td>
<td>0.83</td>
<td>77.2</td>
<td>84.6</td>
<td>66.6</td>
<td>14</td>
<td>1000</td>
</tr>
<tr>
<td>3DGSI</td>
<td>0.87</td>
<td>86.3</td>
<td>77.7</td>
<td>92.3</td>
<td>27</td>
<td>1000</td>
</tr>
</tbody>
</table>
<table-wrap-foot><fn id="table-fn2-0962280212448975"><p>3DTI: 3D tensor invariant; 3DMI: 3D moment invariant; 3DLI: 3D Laplacian invariant; 3DGSI: 3D geodesic shape invariant; AVC: area under ROC.</p></fn>
</table-wrap-foot>
</table-wrap></p>
<p>It is interesting to note that for the feature vectors computed using Laplacian eigenvalues the first principal component already accounts for 99.8% of the total variance. Indeed, Laplacian eigenvalues have been successfully used for data compression and dimensionality reduction.<sup><xref ref-type="bibr" rid="bibr60-0962280212448975">60</xref>,<xref ref-type="bibr" rid="bibr61-0962280212448975">61</xref></sup></p>
<p>The results of the permutation test for group differences is shown in <xref ref-type="fig" rid="fig3-0962280212448975">Figure 3</xref>. It revealed that the <italic>T</italic><sup>2</sup> statistic calculated from the two groups (CDR 0 and CDR 0.5) was unlikely to be obtained by chance for each of the methods used for calculating the feature vectors. The group separation was more pronounced for the 3DLI features (<italic>p</italic> = 0.0026), 3DGSI features (<italic>p</italic> = 0.0053) and 3DTI features (<italic>p</italic> = 0.049) as compared to the 3DMI features (<italic>p</italic> = 0.0941). Note that 3DMI features did not achieve significance at the <italic>p</italic> = 0.05 level, 3DTI barely achieved the significance at <italic>p</italic> = 0.05 level, whereas 3DLI and 3DGSI were both significant even at <italic>p</italic> = 0.01.
<fig id="fig3-0962280212448975" position="float"><label>Figure 3.</label><caption><p>Permutation tests for group differences using the first 20 principal components (12 for the moments based method). The plots correspond to feature vectors computed using (a) 3DTI features, (b) 3DMI features, (c) 3DLI features, and (d), the 3DGSI features. Also shown are: <inline-formula id="ilm23-0962280212448975"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math23-0962280212448975"><mml:mrow><mml:mover><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>∧</mml:mi></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> value (solid blue line) of the CDR0 and the CDR0.5 group comparison; theoretical <italic>F</italic>-distribution (solid red curve) with (20, 23) degrees of freedom superimposed on the empirical distribution histogram; <italic>p</italic> = 0.05 (red dotted line) and <italic>p</italic> = 0.01 (red-dot-dash line) for reference. The <italic>T</italic><sup>2</sup> value from the actual group memberships shows stronger group differences using the 3DLI and the 3DGSI features than the 3DTI and the 3DMI features. 3DTI: 3D tensor invariant; 3DMI: 3D moment invariant; 3DLI: 3D Laplacian invariant; 3DGSI: 3D geodesic shape invariant.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig3.tif"/>
</fig></p>
</sec>
<sec id="sec20-0962280212448975"><title>9.2 SVM-based classification results</title>
<p>The classification performance for each feature set has been evaluated with a grid search as described in <xref ref-type="sec" rid="sec13-0962280212448975">Section 7.2</xref>. This grid search is repeated for diffent values of parameters for each method. The receiver operating characteristic (ROC) curve is obtained for each combination of parameters during the grid search. The performance is ranked by the area under ROC (AUC). The ROC curves associated with the best AUC for different feature sets are shown in <xref ref-type="fig" rid="fig4-0962280212448975">Figures 4</xref> to <xref ref-type="fig" rid="fig7-0962280212448975">7</xref>.
<fig id="fig4-0962280212448975" position="float"><label>Figure 4.</label><caption><p>Receiver operating characteristic (ROC) curves SVM classification of the 3DTI features for different values of <italic>l</italic>=3, 6, and 9. We notice similar performances with different values of <italic>l</italic>. SVM: support vector machine; 3DTI: 3D tensor invariant; AVC: area under ROC.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig4.tif"/>
</fig>
<fig id="fig5-0962280212448975" position="float"><label>Figure 5.</label><caption><p>Receiver operating characteristic (ROC) curves SVM classification of the Type 1 (<italic>F</italic><sub>1</sub>) 3DLI features for different number of eigenvalues used to compute invariants <italic>n</italic>=199, 999, 3999 and 10,000. We notice 3DLI features perform well. The performance for different number of eigenvalues is similar, except for <italic>n</italic> = 1000 where the performance is reduced considerably. This reduction could possibly be due redundant and irrelevant features obtained with <italic>n</italic> = 10,000 eigenvalues. SVM: support vector machine; 3DLI: 3D Laplacian invariant; AVC: area under ROC.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig5.tif"/>
</fig>
<fig id="fig6-0962280212448975" position="float"><label>Figure 6.</label><caption><p>Receiver operating characteristic (ROC) curves SVM classification of the Type 2 (<italic>F</italic><sub>2</sub>) 3DLI features for different number of eigenvalues used to compute invariants <italic>n</italic>=199, 999, 3999 and 10,000. We notice poor performance with Type 2 3DLI features indicating poor discrimination power. SVM: support vector machine; 3DLI: 3D Laplacian invariant; AVC: area under ROC.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig6.tif"/>
</fig>
<fig id="fig7-0962280212448975" position="float"><label>Figure 7.</label><caption><p>Receiver operating characteristic (ROC) curves SVM classification of 3DGSI features for different templates used to compute invariants. We notice similar performances using the two templates. SVM: support vector machine; 3DSGI: 3D geodesic shape invariant; AVC: area under ROC.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig7.tif"/>
</fig></p>
<p>These results indicate that both 3DGSI based on LDDMM initial momentum and the 3DLI features resulted in large AUCs and overall accuracy. The features calculated with 3DTI and 3DMI methods both gave performances that are reasonable and acceptable, but were lower than 3DGSI and 3DLI features. The ROC curves for each of these feature/classifier architectures is presented in <xref ref-type="fig" rid="fig8-0962280212448975">Figure 8</xref>. The ROC curves offer a comprehensive assessment of classification performance, at various levels of specificity. Particularly in this case, when the ROC curves cross, the total AUC is not a reliable measurement of performance; two tests may have the same AUC but each may offer higher sensitivity at different choices of specificity. Thus, the choice of the best performing feature/classifier architecture would depend on (1) the specificity (or sensitivity) required for the particular clinical application, and (2) the costs associated to false positives or misses.<sup><xref ref-type="bibr" rid="bibr49-0962280212448975">49</xref></sup> If specificity of 85% or more is desired, than 3DLI method performs the best, although the sensitivity of all the methods investigated is observed to be below 60% for that specificity range. This is likely because the two groups being studied are very similar to each other to have both high specificity and sensitivity – the changes caused by very mild AD (disease group in the study) in the brain are subtle and the differences are not pronounced compared to the healthy group. If the range of specificities is set to be 50–85%, than 3DGSI would offer the best sensitivity for this application with sensitivity reaching in the early 90% for this range. At a specificity level of 80% for comparison, 3DGSI feature classification attains 92.3% sensitivity compared to 3DLI (66.7%), 3DMI (61.11%) and 3DTI (55.56%) feature classification.
<fig id="fig8-0962280212448975" position="float"><label>Figure 8.</label><caption><p>Receiver operating characteristic (ROC) curves for SVM classification of features computed using the four feature construction methods (a) the 3DTI, (b) the 3DMI, (c) the 3DLI and (d) the 3DGSI. If specificity of 85% or more is desired, than 3DLI method performs the best, although the sensitivity of all the methods investigated is observed to be below 60% for that specificity range. If the range of specificities is set to be 50–85%, than 3DGSI would offer the best sensitivity for this application with sensitivity reaching in the early 90% for this range. At a specificity level of 80% for comparison, 3DGSI feature classification attains 92.3% sensitivity compared to 3DLI (66.7%), 3DMI (61.11%) and 3DTI (55.56%) feature classification. SVM: support vector machine; 3DTI: 3D tensor invariant; 3DMI: 3D moment invariant; 3DLI: 3D Laplacian invariant; 3DGSI: 3D geodesic shape invariant; AVC: area under ROC.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig8.tif"/>
</fig></p>
</sec>
<sec id="sec21-0962280212448975"><title>9.3 Performance on an independent test set</title>
<p>The performance of the shape invariant features presented so far are based on leave-one-out cross-validation on the same dataset. Although this is a good way to test how well the shape features can generalize, the test case in each iteration of the cross-validation still has characteristics similar to the rest. In order to assess the generalizability of the presented shape features, we assess their performance on an independent test set. For this purpose, we gathered a set of 10 controls and 10 DAT subjects from a different dataset. The four shape features from the left hippocampi were extracted for this test set.</p>
<p>The optimal classifier obtained from the cross-validation for each feature is trained on the whole dataset (18 DAT and 26 controls) and its performance is evaluated on the test set. This would assess the ability of each feature type to <italic>classify unseen data</italic>. The ROC curves obtained from the test set are shown in <xref ref-type="fig" rid="fig9-0962280212448975">Figure 9</xref>. We notice that the AUCs for the different feature types are slightly lower on the test set. This is not surprising as the subjects being classified are from an independent test set. We note that the ranking of the performance is in the same order: AUC of 3dGSI &gt; 3dLI &gt; 3dTI and random classification from 3dMI (AUC=0.5 is equivalent to a random classifier). Moment invariants could not generalize at all to an unseen test set. This is not surprising as they are not as comprehensive (dimensionality is only 12) compared to the rest. 3dTI features produced a test set AUC of 0.56 which is only slightly better than random. But 3dLI and 3dGSI both produced reasonable performance. As the AUC is based on an independent test set, it represents the generalizability of the shape features presented.
<fig id="fig9-0962280212448975" position="float"><label>Figure 9.</label><caption><p>Receiver operating characteristic (ROC) curves for SVM classification on an <italic>independent test set</italic> of features computed using the four feature construction methods. We notice that the performances are slightly lower on the test set, as the subjects being classified are from an independent test set. Also interesting to note is that the ranking of the performance is in the same order: best generalization offered by 3DGSI, followed by 3DLI, then by 3DTI and the worst performance from 3DMI. Moment invariants could not generalize at all (AUC=0.5 is equivalent to a random classifier) to an unseen test set. This is expected as they are not as comprehensive (dimensionality is only 12) compared to the rest. 3DTI features produced a test set AUC of 0.56 which is only slightly better than random. But 3DLI and 3DGSI both produced reasonable performance. As the AUC is based on an independent test set, it represents the generalizability of the shape features presented. SVM: support vector machine; 3DTI: 3D tensor invariant; 3DMI: 3D moment invariant; 3DLI: 3D Laplacian invariant; 3DGSI: 3D geodesic shape invariant; AVC: area under ROC.</p></caption><graphic xlink:href="10.1177_0962280212448975-fig9.tif"/>
</fig></p>
</sec>
<sec id="sec22-0962280212448975"><title>9.4 Using nonlinear SVM</title>
<p>We have evaluated the performance of different biomarkers using linear SVM in order to gain insight into the comparative performance using the simplest of classifers. We have also repeated the whole study using non-linear SVM (with a non-linear radial basis Kernel using leave-one-out cross-validation) and learnt that these features produce close to perfect classification. This result could be due to the small sample size studied here, for which SVM can find a highly non-linear surface that can separate two groups. We would like to, as part of future work, repeat this study on a larger dataset.</p>
</sec>
</sec>
<sec id="sec23-0962280212448975"><title>10Discussion</title>
<p>Given a common database of left hippocampal segmentations generated using an automated image registration technique from a control (CDR 0) and a very mild Alzheimer's group (CDR 0.5), and having set a common classifier based on SVMs, we have presented here the results of group discrimination and individual classification using left hippocampal-shape-based features. In these four shape-based features, the overall accuracy of classification was found to be 68.1% for the 3DMI features, 75% for the 3DTI features, 77.3% for 3DLI features, and 86.3% for 3DGSI features. The sensitivity for each of these methods was found to be highest for 3DGSI method in the specificity range 50–85%, where a sensitivity of 92.3% was achieved for specificity of 80%. These compare quite favorably to performances reported in published literature in separating very early AD from age-matched dementia free controls. In addition to the results from leave-one-out cross-validation, we have reported the performances of these shape features on an independent test set. The test set results indicate that the 3DGSI feature results seem to generalize and can classify unseen test data well with an AUC=0.74.</p>
<p>Gutman et al.<sup><xref ref-type="bibr" rid="bibr5-0962280212448975">5</xref></sup> used SPHARM coefficients as feature vectors and tested ability to discriminate 49 AD patients and 63 controls.<sup><xref ref-type="bibr" rid="bibr5-0962280212448975">5</xref></sup> They reported 82.1% accuracy, 75.5% sensitivity and 87.3% specificity, and they also noted that these results may have been slightly biased since the same subgroup was used in setting the selection threshold as was used in classification testing. From the ROC curve they presented in <xref ref-type="fig" rid="fig3-0962280212448975">Figure 3</xref>,<sup><xref ref-type="bibr" rid="bibr5-0962280212448975">5</xref></sup> at 80% specificity, the sensitivity achieved by their classifier is approximately 80%. Hence, our best sensitivity of 92.3% is better at comparable specificity. Since their features were computed from hippocampi in AD patients, the likely presence of pronounced degenerative shape changes in AD would be comparatively easier to assess than using our data from the very mild AD (CDR 0.5) subject group. One interesting feature of their study is that the features from those of the left and the right hippocampus that best discriminate the groups are all from the right hippocampus. This is in contrast to the presence of stronger group differences found in the 3DGSI features of the left hippocampus (<italic>p</italic> = 0.007) in our precursor study<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> as compared to those from the right (<italic>p</italic> = 0.06), including larger differences observed in left side compared to the right in other reports.<sup><xref ref-type="bibr" rid="bibr57-0962280212448975">57</xref>,<xref ref-type="bibr" rid="bibr58-0962280212448975">58</xref></sup></p>
<p>Another comparable study<sup><xref ref-type="bibr" rid="bibr8-0962280212448975">8</xref></sup> utilizing SPHARM coefficients of both left and right hippocampus achieved accuracy of 83%, sensitivity of 83% and specificity of 84% for discriminating mild cognitive impaired group (MCI) from controls, and accuracy of 94%, sensitivity of 96% and specificity of 92% for discriminating AD from controls. There are two points to note for these results. The first is that the classifier performance on AD patients is better, as expected, likely due to the presence of pronounced degenerative shape changes in AD and hence are not comparable to results from our very mild AD (CDR 0.5) subject group. Secondly, since they have not shown the ROC curves for their classifier, it is not possible to fully evaluate the performance of their features and classifier architecture. However, based only on the specificity and sensitivity they have reported, comparing their MCI vs controls discrimination results to our results, our 3DGSI results show higher accuracy at 86.3% for 3DGSI features from left hippocampus alone, and considerably better sensitivity of 92.3% for comparable specificity with an overall AUC of 0.87 demonstrating the classification system stability.</p>
<p>The use of volumetric Laplacian in solving the Helmholtz equation, and subsequent shape analysis of the eigenvalues has been previously proposed<sup><xref ref-type="bibr" rid="bibr23-0962280212448975">23</xref></sup> for analysis of the caudate shape in Schizophrenia. We have applied the same approach here for the first time for the analysis of the hippocampal shape in early Alzheimer's. However, there is a key difference in the implementation proposed previously<sup><xref ref-type="bibr" rid="bibr23-0962280212448975">23</xref></sup> and the implementation that we have chosen for shape-description here. In Reuter et al.,<sup><xref ref-type="bibr" rid="bibr23-0962280212448975">23</xref></sup> the variational formulation of the problem is discretized in a finite element method (FEM) setting and the resulting system is solved, with directly specifying the boundary conditions in the process to be either Dirichlet or Neumann. We avoid the FEM formulation, and the explicit provision of a choice of boundary conditions by taking the elegant route shown by Saito<sup><xref ref-type="bibr" rid="bibr24-0962280212448975">24</xref></sup> in which the integral operator commuting with the Laplacian is used to find the common eigenfunctions (with corresponding eigenvalues of the Laplacian being the reciprocal of those found). One property of the formulation proposed by Saito is that the boundary condition need not be explicitly specified, and turns out to be neither the Dirichlet nor the Neumann type, but a mixed non-local kind of boundary condition. This incidentally helps avoid the Dirichlet boundary condition, which, as was shown,<sup><xref ref-type="bibr" rid="bibr23-0962280212448975">23</xref></sup> can be problematic in representing structures, such as the caudate, with thin tails.</p>
<p>The 3DGSI features, being dependent on template-target registration, are not invariant to rotation and translation, as was noted.<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> This is a limitation that is characteristic of all deformable template-based shape classification methods in general. We aligned the target shapes to the template by a rigid rotation and translation calculated from a minimum mean-squares error kind of algorithm, and therefore, these results are, in this limited sense, not dependent on relative rotation and translation of the pair.</p>
<p>Besides the choice of the method to generate features, and the type of data to employ (whole brain texture, ROI measurements, binary segmentations of subcortical structures implicated in the disease process), the choice of the classifier also influences the performance of the overall system. As an example, the 3DGSI features classified with SVM in this study were used with a logistic regression procedure for classification in our previous study.<sup><xref ref-type="bibr" rid="bibr26-0962280212448975">26</xref></sup> In that study, using both the left and the right hippocampus, 3DGSI features enabled correct classification for 12 out of 18 CDR 0.5 subjects (sensitivity of 66.7%) and 22 out of 26 CDR 0 subjects (specificity of 84.6%) for a total accuracy of 77.3%. The use of a SVM-based classifier on the same shape-descriptive features improved the classification performance, although for the current study, we used only the left hippocampus 3DGSI features alone (Table 2). This indicates that performances obtained depend on the classifier system. We would also like to emphasize that the performances reported pertain to this current dataset and the findings could be different depending on the size of the dataset and the type of classifier being used. Hence an optimization study over different classifiers would be useful to perform and could provide clues on which classifier is to be selected for a particular method of calculating features.</p>
<p>Early detection of AD pathology from MR scans, and discrimination of AD from controls is a thriving topic of research. The work presented here is specifically focussed on the use of automatically derived hippocampal shape features for very early AD discrimination, and complements the several other promising avenues being explored and reported for achieving good classification of very early AD from controls and diagnosis of AD from normal aging. On the whole brain level approaches, Kloppel et al. showed 96% accuracy in classification of AD scans using whole brain gray matter, and 89% accuracy for mild AD.<sup><xref ref-type="bibr" rid="bibr3-0962280212448975">3</xref></sup> Vemuri et al. used tissue densities obtained from grayscale images to give Structural abnormality index (STAND) score and additionally used demographics and ApoE genotype in the classification process of probably AD vs controls. They have reported accuracy of around 89%.<sup><xref ref-type="bibr" rid="bibr7-0962280212448975">7</xref></sup> Desikan et al. have used multidimensional measurements consisting of entorhinal cortex thickness, hippocampal volume and supramarginal gyrus thickness demonstrated an AUC of 0.91 (specificity 94%, sensitivity 74%).<sup><xref ref-type="bibr" rid="bibr9-0962280212448975">9</xref></sup> Aljabar et al. used graph Laplacian-based spectral analysis with resulting subject features derived from volumes, Fiedler vectors from volume differences or dice overlaps between binary subcortical segmentations of the subjects, from the probable AD and control groups. Using features from single or multiple structures, this approach gave supervised classification accuracy rates in the range of 81–84%, sensitivity of 77–82% and specificity of 89% when using Fiedler features derived from dice overlaps.<sup><xref ref-type="bibr" rid="bibr10-0962280212448975">10</xref></sup> Using features derived from other modalities is also a promising area being explored. As an example, Ramirez et. al report accuracy of 90.38% in the early diagnosis of the AD using features derived from functional SPECT images.<sup><xref ref-type="bibr" rid="bibr62-0962280212448975">62</xref></sup> PCA followed by linear discriminant analysis of these images gave 95.5% accuracy of correctly classifying probable AD when using 13 PCs with corresponding sensitivity and specificity were 92.4% and 99.5%.<sup><xref ref-type="bibr" rid="bibr63-0962280212448975">63</xref></sup></p>
<p>It would also be interesting to study the effect of the segmentation procedure (here used to obtain hippocampi segmentations) on the shape features (and in turn on classification results). Using multi-modality-based features derived from several structures measuring different aspects of pathology (such as incorporating DTI metrics and functional measurements in addition to structure), possibly on a larger dataset for improved statistical power, would be highly desirable. Combining optimized classifiers for classification of each of these biomarkers holds considerable promise in the early detection of Alzheimer's pathology.</p>
</sec>
</body>
<back><ack>
<title>Acknowledgment</title>
<p>We are grateful to Professor Naoki Saito for helping us with suggestions regarding the solving of the Helmholtz equation and for his interest and discussions on the topic of this paper.</p></ack>
<sec id="sec24-0962280212448975"><title>Funding</title>
<p>We gratefully acknowledge funding support from Alzheimer Society Canada for both M. F. Beg and P. K. Raamana. We also acknowledge funding support from NSERC Discovery grant 31-611387, Pacific Alzheimer Research Foundation grant 31-869294, the Michael Smith Foundation for Health Research 13-876670, the National Health Medical Research Council grant 31-579057 for the research.</p></sec>
<ref-list><title>References</title>
<ref id="bibr1-0962280212448975"><label>1</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Csernansky</surname><given-names>JG</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Joshi</surname><given-names>S</given-names></name><etal/></person-group>. <article-title>Early DAT is distinguished from aging by high dimensional mapping of the hippocampus</article-title>. <source>Neurology</source> <year>2000</year>; <volume>55</volume>: <fpage>1636</fpage>–<lpage>1643</lpage>.</citation></ref>
<ref id="bibr2-0962280212448975"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>McKeown</surname><given-names>M</given-names></name><name><surname>Uthama</surname><given-names>A</given-names></name><name><surname>Abugharbieh</surname><given-names>R</given-names></name><etal/></person-group>. <article-title>MRI in Parkinson's disease identifies shape, but not volume, changes in the thalamus</article-title>. <source>Parkinson Relat Disord</source> <year>2007</year>; <volume>13</volume>: <fpage>S153</fpage>–<lpage>S153</lpage>.</citation></ref>
<ref id="bibr3-0962280212448975"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kloppel</surname><given-names>S</given-names></name><name><surname>Stonnington</surname><given-names>CM</given-names></name><name><surname>Chu</surname><given-names>C</given-names></name><etal/></person-group>. <article-title>Automatic classification of MR scans in Alzheimer's disease</article-title>. <source>Brain</source> <year>2008</year>; <volume>131</volume>(<issue>3</issue>): <fpage>681</fpage>–<lpage>689</lpage>.</citation></ref>
<ref id="bibr4-0962280212448975"><label>4</label><citation citation-type="other"><person-group person-group-type="author"><name><surname>Gerig</surname><given-names>G</given-names></name><name><surname>Styner</surname><given-names>M</given-names></name><name><surname>Jones</surname><given-names>D</given-names></name><etal/></person-group>. <article-title>Shape analysis of brain ventricles using SPHARM. In: Proceedings of the IEEE workshop on <italic>Mathematical Methods in Biomedical Image Analysis</italic>, IEEE Computer Society</article-title>. <comment>Washington DC, USA, 2001</comment>.</citation></ref>
<ref id="bibr5-0962280212448975"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Boris</surname><given-names>G</given-names></name><name><surname>Yalin</surname><given-names>W</given-names></name><name><surname>Jonathan</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>Disease classification with hippocampal shape invariants</article-title>. <source>Hippocampus</source> <year>2009</year>; <volume>19</volume>(<issue>6</issue>): <fpage>572</fpage>–<lpage>578</lpage>.</citation></ref>
<ref id="bibr6-0962280212448975"><label>6</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mangin</surname><given-names>JF</given-names></name><name><surname>Poupon</surname><given-names>F</given-names></name><name><surname>Duchesnay</surname><given-names>E</given-names></name><etal/></person-group>. <article-title>Brain morphometry using 3D moment invariants</article-title>. <source>Med Image Anal</source> <year>2004</year>; <volume>8</volume>(<issue>3</issue>): <fpage>187</fpage>–<lpage>196</lpage>.</citation></ref>
<ref id="bibr7-0962280212448975"><label>7</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vemuri</surname><given-names>P</given-names></name><name><surname>Gunter</surname><given-names>JL</given-names></name><name><surname>Senjem</surname><given-names>ML</given-names></name><etal/></person-group>. <article-title>Alzheimer's disease diagnosis in individual subjects using structural MR images: validation studies</article-title>. <source>NeuroImage</source> <year>2008</year>; <volume>39</volume>(<issue>3</issue>): <fpage>1186</fpage>–<lpage>1197</lpage>.</citation></ref>
<ref id="bibr8-0962280212448975"><label>8</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gerardin</surname><given-names>E</given-names></name><name><surname>Chételat</surname><given-names>G</given-names></name><name><surname>Chupin</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>Multidimensional classification of hippocampal shape features discriminates Alzheimer's disease and mild cognitive impairment from normal aging</article-title>. <source>NeuroImage</source> <year>2009</year>; <volume>47</volume>(<issue>4</issue>): <fpage>1476</fpage>–<lpage>1486</lpage>.</citation></ref>
<ref id="bibr9-0962280212448975"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname><given-names>RS</given-names></name><name><surname>Cabral</surname><given-names>HJ</given-names></name><name><surname>Hess</surname><given-names>CP</given-names></name><etal/></person-group>. <article-title>Automated MRI measures identify individuals with mild cognitive impairment and Alzheimer's disease</article-title>. <source>Brain</source> <year>2009</year>; <volume>132</volume>(<issue>8</issue>): <fpage>2048</fpage>–<lpage>2057</lpage>.</citation></ref>
<ref id="bibr10-0962280212448975"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Aljabar</surname><given-names>P</given-names></name><name><surname>Rueckert</surname><given-names>D</given-names></name><name><surname>Crum</surname><given-names>WR</given-names></name></person-group>. <article-title>Automated morphological analysis of magnetic resonance brain imaging using spectral analysis</article-title>. <source>NeuroImage</source> <year>2008</year>; <volume>43</volume>(<issue>2</issue>): <fpage>225</fpage>–<lpage>235</lpage>.</citation></ref>
<ref id="bibr11-0962280212448975"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Magnin</surname><given-names>B</given-names></name><name><surname>Mesrob</surname><given-names>L</given-names></name><name><surname>Kinkingnéhun</surname><given-names>S</given-names></name><etal/></person-group>. <article-title>Support vector machinebased classification of Alzheimer's disease from whole-brain anatomical MRI</article-title>. <source>Neuroradiology</source> <year>2009</year>; <volume>51</volume>(<issue>2</issue>): <fpage>73</fpage>–<lpage>83</lpage>.</citation></ref>
<ref id="bibr12-0962280212448975"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Y</given-names></name><name><surname>Shen</surname><given-names>D</given-names></name><name><surname>Davatzikos</surname><given-names>C</given-names></name></person-group>. <article-title>Classification of structural images via high-dimensional image warping, robust feature extraction, and SVM</article-title>. <source>Med Image Comput Comput-Assist Interv</source> <year>2005</year>; <volume>8</volume>: <fpage>1</fpage>–<lpage>8</lpage>.</citation></ref>
<ref id="bibr13-0962280212448975"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jonathan</surname><given-names>HM</given-names></name><name><surname>Zhuowen</surname><given-names>T</given-names></name><name><surname>Liana</surname><given-names>GA</given-names></name><etal/></person-group>. <article-title>Automated 3D mapping of hippocampal atrophy and its clinical correlates in 400 subjects with Alzheimer's disease, mild cognitive impairment, and elderly controls</article-title>. <source>Human Brain Map</source> <year>2009</year>; <volume>30</volume>(<issue>9</issue>): <fpage>2766</fpage>–<lpage>2788</lpage>.</citation></ref>
<ref id="bibr14-0962280212448975"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Loncaric</surname><given-names>S</given-names></name></person-group>. <article-title>A survey of shape analysis techniques</article-title>. <source>Pattern Recog</source> <year>1998</year>; <volume>31</volume>(<issue>8</issue>): <fpage>983</fpage>–<lpage>1001</lpage>.</citation></ref>
<ref id="bibr15-0962280212448975"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dengsheng</surname><given-names>Z</given-names></name><name><surname>Guojun</surname><given-names>L</given-names></name></person-group>. <article-title>Review of shape representation and description techniques</article-title>. <source>Pattern Recog</source> <year>2004</year>; <volume>37</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>19</lpage>.</citation></ref>
<ref id="bibr16-0962280212448975"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Iyer</surname><given-names>N</given-names></name><name><surname>Jayanti</surname><given-names>S</given-names></name><name><surname>Lou</surname><given-names>K</given-names></name><etal/></person-group>. <article-title>Three-dimensional shape searching: state-of-the-art review and future trends</article-title>. <source>Comput-Aid Des</source> <year>2005</year>; <volume>37</volume>(<issue>5</issue>): <fpage>509</fpage>–<lpage>530</lpage>.</citation></ref>
<ref id="bibr17-0962280212448975"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davatzikos</surname><given-names>C</given-names></name><name><surname>Vaillant</surname><given-names>M</given-names></name><name><surname>Resnick</surname><given-names>S</given-names></name><etal/></person-group>. <article-title>A computerized method formorphological analysis of the corpus callosum</article-title>. <source>J Comp Assist Tomogr</source> <year>1996</year>; <volume>20</volume>: <fpage>88</fpage>–<lpage>97</lpage>.</citation></ref>
<ref id="bibr18-0962280212448975"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name><name><surname>Grenader</surname><given-names>U</given-names></name></person-group>. <article-title>On the geometry and shape of brain sub-manifolds</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <year>1997</year>; <volume>11</volume>: <fpage>1317</fpage>–<lpage>1343</lpage>.</citation></ref>
<ref id="bibr19-0962280212448975"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Csernansky</surname><given-names>JG</given-names></name><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><etal/></person-group>. <article-title>Hippocampal morphometry in schizophrenia via high dimensional brain mapping</article-title>. <source>Proc Natl Acad Sci USA</source> <year>1998</year>; <volume>95</volume>: <fpage>11406</fpage>–<lpage>11411</lpage>.</citation></ref>
<ref id="bibr20-0962280212448975"><label>20</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Csernansky</surname><given-names>JG</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jones</surname><given-names>DJ</given-names></name><etal/></person-group>. <article-title>Hippocampal deformities in schizophrenia characterized by high dimensional brain mapping</article-title>. <source>Am J Psychiatry</source> <year>2002</year>; <volume>159</volume>: <fpage>1</fpage>–<lpage>7</lpage>.</citation></ref>
<ref id="bibr21-0962280212448975"><label>21</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burel</surname><given-names>G</given-names></name><name><surname>Hénocq</surname><given-names>H</given-names></name></person-group>. <article-title>Three-dimensional invariants and their application to object recognition</article-title>. <source>J Signal Process</source> <year>1995</year>; <volume>45</volume>: <fpage>1</fpage>–<lpage>22</lpage>.</citation></ref>
<ref id="bibr22-0962280212448975"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Khabou</surname><given-names>MA</given-names></name><name><surname>Hermi</surname><given-names>L</given-names></name><name><surname>Rhouma</surname><given-names>MBH</given-names></name></person-group>. <article-title>Shape recognition using eigenvalues of the dirichlet Laplacian</article-title>. <source>J Pattern Recog</source> <year>2007</year>, pp. <fpage>141</fpage>–<lpage>153</lpage>. <comment>it 40</comment>.</citation></ref>
<ref id="bibr23-0962280212448975"><label>23</label><citation citation-type="other"><comment>Reutre M, Niethammer M, Wolter FE, et al. Global medical shape analysis using the volumetric Laplace spectrum. In: <italic>Proceedings of the 2007 International Conference on Cyberworlds, NASA-GEM workshop</italic>, IEEE Computer Society, 2007, pp. 417–426</comment>.</citation></ref>
<ref id="bibr24-0962280212448975"><label>24</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Saito</surname><given-names>N</given-names></name></person-group>. <article-title>Data analysis and representation on a general domain using eigenfunctions of Laplacian</article-title>. <source>Appl Comput Harmon Anal</source> <year>2007</year>; <volume>25</volume>: <fpage>68</fpage>–<lpage>97</lpage>.</citation></ref>
<ref id="bibr25-0962280212448975"><label>25</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Beg</surname><given-names>MF</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name><name><surname>Trouvé</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>Computing large deformation metric mappings via geodesic flows of diffeomorphism</article-title>. <source>Int J Comput Vis</source> <year>2005</year>; <volume>61</volume>(<issue>2</issue>): <fpage>139</fpage>–<lpage>157</lpage>.</citation></ref>
<ref id="bibr26-0962280212448975"><label>26</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Beg</surname><given-names>MF</given-names></name><name><surname>Ratnanather</surname><given-names>JT</given-names></name><etal/></person-group>. <article-title>Large deformation diffeomorphism and momentum based hippocampal shape discrimination in dementia of the Alzheimer type</article-title>. <source>IEEE Trans Med Imaging</source> <year>2007</year>; <volume>26</volume>(<issue>4</issue>): <fpage>462</fpage>–<lpage>470</lpage>.</citation></ref>
<ref id="bibr27-0962280212448975"><label>27</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>MI</given-names></name><name><surname>Trouvé</surname><given-names>A</given-names></name><name><surname>Younes</surname><given-names>L</given-names></name></person-group>. <article-title>Geodesic shooting for computational anatomy</article-title>. <source>J Math Imag Vis</source> <year>2006</year>; <volume>24</volume>: <fpage>209</fpage>–<lpage>228</lpage>.</citation></ref>
<ref id="bibr28-0962280212448975"><label>28</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>VN</given-names></name></person-group>. <source>The nature of statistical learning theory</source>, <publisher-loc>New York Inc.</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>, <year>2000</year>.</citation></ref>
<ref id="bibr29-0962280212448975"><label>29</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Cristianini</surname><given-names>N</given-names></name><name><surname>Shawe-Taylor</surname><given-names>J</given-names></name></person-group>. <source>An introduction to support vector machines and other kernel-based learning methods</source>, <publisher-name>Cambridge: Cambridge University Press</publisher-name>, <year>2000</year>.</citation></ref>
<ref id="bibr30-0962280212448975"><label>30</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Smola</surname><given-names>AJ</given-names></name><name><surname>Schölkopf</surname><given-names>B</given-names></name></person-group>. <article-title>A tutorial on support vector regression</article-title>. <source>Stat Comput</source> <year>2004</year>; <volume>14</volume>(<issue>3</issue>): <fpage>199</fpage>–<lpage>222</lpage>.</citation></ref>
<ref id="bibr31-0962280212448975"><label>31</label><citation citation-type="other"><comment>Cohen-Tanoudji C, Diu B, Laloë F. <italic>Mécanique Quantique, Tomes 1 and 2</italic>. Paris: Hermann, 1973</comment>.</citation></ref>
<ref id="bibr32-0962280212448975"><label>32</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Edmons</surname><given-names>AR</given-names></name></person-group>. <source>Angular momentum in quantum mechanics</source>, <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>, <year>1974</year>.</citation></ref>
<ref id="bibr33-0962280212448975"><label>33</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Elbatz</surname><given-names>E</given-names></name></person-group>. <source>Mécanique Quantique</source>, <publisher-loc>Paris</publisher-loc>: <publisher-name>Editions Marketing</publisher-name>, <year>1985</year>.</citation></ref>
<ref id="bibr34-0962280212448975"><label>34</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lo</surname><given-names>CH</given-names></name><name><surname>Don</surname><given-names>HS</given-names></name></person-group>. <article-title>3D moment forms: their construction and application to object identification and positioning</article-title>. <source>IEEE PAMI</source> <year>1989</year>; <volume>11</volume>: <fpage>1053</fpage>–<lpage>1064</lpage>.</citation></ref>
<ref id="bibr35-0962280212448975"><label>35</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sadjadi</surname><given-names>FA</given-names></name><name><surname>Hall</surname><given-names>EL</given-names></name></person-group>. <article-title>Three-dimensional moment invariants</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <year>1980</year> <volume>2</volume>: <fpage>127</fpage>–<lpage>136</lpage>.</citation></ref>
<ref id="bibr36-0962280212448975"><label>36</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>C</given-names></name><name><surname>Webb</surname><given-names>D</given-names></name><name><surname>Wolpert</surname><given-names>S</given-names></name></person-group>. <article-title>One cannot hear the shape of a drum</article-title>. <source>Bull Am Math Soc</source> <year>1992</year> <volume>27</volume>: <fpage>134</fpage>–<lpage>138</lpage>.</citation></ref>
<ref id="bibr37-0962280212448975"><label>37</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Reuter</surname><given-names>M</given-names></name><name><surname>Wolter</surname><given-names>FE</given-names></name><name><surname>Peinecke</surname><given-names>N</given-names></name></person-group>. <article-title>Laplace-Beltrami spectra as ‘Shape-DNA’ of surfaces and solids</article-title>. <source>Comput Aid Des</source> <year>2006</year>; <volume>38</volume>(<issue>4</issue>): <fpage>342</fpage>–<lpage>366</lpage>.</citation></ref>
<ref id="bibr38-0962280212448975"><label>38</label><citation citation-type="other"><comment>Lévy B. Laplace-Beltrami eigenfunctions towards an algorithm that “understands” geometry. In: <italic>Proceedings of the IEEE International Conference on Shape Modeling and Applications</italic>, Matsushima, Japan, 2006, p. 13</comment>.</citation></ref>
<ref id="bibr39-0962280212448975"><label>39</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Rustamov</surname><given-names>RM</given-names></name></person-group>. <article-title>Laplace-Beltrami eigenfunctions for deformation invariant shape representation</article-title>. <source>In: SGP '07: Proceedings of the Fifth Eurographics Symposium on Geometry Processing, Aire-la-Ville, Switzerland</source>, <publisher-loc>Switzerland</publisher-loc>: <publisher-name>Eurographics Association</publisher-name>, <year>2007</year>, pp. <fpage>225</fpage>–<lpage>233</lpage>.</citation></ref>
<ref id="bibr40-0962280212448975"><label>40</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zuliani</surname><given-names>M</given-names></name><name><surname>Kenney</surname><given-names>C</given-names></name><name><surname>Bhagavathy</surname><given-names>S</given-names></name><etal/></person-group>. <source>Drums and curve descriptors</source> <year>2004</year>. <comment>UCSB Visition Research Lab Preprint, <ext-link ext-link-type="uri" xlink:href="http://vision.ece.ucsb.edu/publications/04BMVCMarco.pdf">http://vision.ece.ucsb.edu/publications/04BMVCMarco.pdf</ext-link> (accessed on January 2010</comment>.</citation></ref>
<ref id="bibr41-0962280212448975"><label>41</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Courant</surname><given-names>R</given-names></name><name><surname>Hilbert</surname><given-names>D</given-names></name></person-group>. <source>Methods of mathematical physics</source>, <edition>2nd edn</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Interscience Publishers</publisher-name>, <year>1965</year>.</citation></ref>
<ref id="bibr42-0962280212448975"><label>42</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>B</given-names></name></person-group>. <source>Principles and techniques of applied mathematics</source>, <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley and Sons, Inc.</publisher-name>, <year>1990</year>. <comment>republished by Dover Publications, Inc.</comment>.</citation></ref>
<ref id="bibr43-0962280212448975"><label>43</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>D</given-names></name><name><surname>Stirling</surname><given-names>DSG</given-names></name></person-group>. <article-title>Integral equations: a practical treatment from spectral theory to applications</article-title>. <source>Cambridge Texts in Applied Mathematics</source>, <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>, <year>1990</year>.</citation></ref>
<ref id="bibr44-0962280212448975"><label>44</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dupuis</surname><given-names>P</given-names></name><name><surname>Grenander</surname><given-names>U</given-names></name><name><surname>Miller</surname><given-names>M</given-names></name></person-group>. <article-title>Variational problems on flows of diffeomorphisms via tangent space representations</article-title>. <source>Quart Appl Math</source> <year>1998</year>; <volume>LVI</volume>: <fpage>587</fpage>–<lpage>600</lpage>.</citation></ref>
<ref id="bibr45-0962280212448975"><label>45</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Trouvé</surname><given-names>A</given-names></name></person-group>. <article-title>An infinite dimensional group approach for physics based models in patterns recognition</article-title>. <source>Int J Comput Vis</source> <year>1995</year>; <volume>28</volume>(<issue>3</issue>): <fpage>213</fpage>–<lpage>221</lpage>.</citation></ref>
<ref id="bibr46-0962280212448975"><label>46</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jolliffe</surname><given-names>IT</given-names></name></person-group>. <article-title>Principal component analysis</article-title>. <source>Springer Series in Statistics</source>, <edition>2nd edn</edition>. <publisher-loc>New York, USA</publisher-loc>: <publisher-name>Springer</publisher-name>, <year>2002</year>.</citation></ref>
<ref id="bibr47-0962280212448975"><label>47</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>TW</given-names></name></person-group>. <source>An introduction to multivariate statistical analysis</source>, <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>, <year>1958</year>.</citation></ref>
<ref id="bibr48-0962280212448975"><label>48</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group>. <article-title>Support vector networks</article-title>. <source>Machine learning</source> <year>1995</year>; <volume>20</volume>: <fpage>273</fpage>–<lpage>297</lpage>.</citation></ref>
<ref id="bibr49-0962280212448975"><label>49</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Metz</surname><given-names>CE</given-names></name></person-group>. <article-title>Receiver operating characteristic analysis: a tool for the quantitative evaluation of observer performance and imaging systems</article-title>. <source>J Am Coll Radiol</source> <year>2006</year>; <volume>3</volume>(<issue>6</issue>): <fpage>413</fpage>–<lpage>422</lpage>.</citation></ref>
<ref id="bibr50-0962280212448975"><label>50</label><citation citation-type="other"><comment>MATLAB version 7.9. Natick, Massachusetts: The MathWorks Inc., 2009</comment>.</citation></ref>
<ref id="bibr51-0962280212448975"><label>51</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Swank</surname><given-names>JS</given-names></name><name><surname>Glick</surname><given-names>IE</given-names></name><etal/></person-group>. <article-title>Changes in hippocampal volume and shape across time distinguish dementia of the Alzheimer type from healthy aging</article-title>. <source>NeuroImage</source> <year>2003</year>; <volume>20</volume>(<issue>2</issue>): <fpage>667</fpage>–<lpage>682</lpage>.</citation></ref>
<ref id="bibr52-0962280212448975"><label>52</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JC</given-names></name></person-group>. <article-title>The clinical dementia rating (CDR): current version and scoring rules</article-title>. <source>Neurology</source> <year>1993</year> <volume>43</volume>: <fpage>2412</fpage>–<lpage>2414</lpage>.</citation></ref>
<ref id="bibr53-0962280212448975"><label>53</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>GE</given-names></name><name><surname>Joshi</surname><given-names>SC</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name></person-group>. <article-title>Volumetric transformation of brain anatomy</article-title>. <source>IEEE Trans Med Imaging</source> <year>1997</year>; <volume>16</volume>(<issue>6</issue>): <fpage>864</fpage>–<lpage>877</lpage>.</citation></ref>
<ref id="bibr54-0962280212448975"><label>54</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname><given-names>L</given-names></name><name><surname>McKeel</surname><given-names>J</given-names></name><name><surname>Daniel</surname><given-names>W</given-names></name><etal/></person-group>. <article-title>Clinicopathologic studies in cognitively healthy aging and alzheimer disease: relation of histologic markers to dementia severity, age, sex, and apolipoprotein E genotype</article-title>. <source>Arch Neurol</source> <year>1998</year>; <volume>55</volume>(<issue>3</issue>): <fpage>326</fpage>–<lpage>335</lpage>.</citation></ref>
<ref id="bibr55-0962280212448975"><label>55</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>RC</given-names></name><name><surname>Doody</surname><given-names>R</given-names></name><name><surname>Kurz</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>Current concepts in mild cognitive impairment</article-title>. <source>Arch Neurol</source> <year>2001</year>; <volume>58</volume>(<issue>12</issue>): <fpage>1985</fpage>–<lpage>1992</lpage>.</citation></ref>
<ref id="bibr56-0962280212448975"><label>56</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Storandt</surname><given-names>M</given-names></name><name><surname>Grant</surname><given-names>EA</given-names></name><name><surname>Miller</surname><given-names>JP</given-names></name><etal/></person-group>. <article-title>Longitudinal course and neuropathologic outcomes in original vs revised MCI and in pre-MCI</article-title>. <source>Neurology</source> <year>2006</year>; <volume>67</volume>(<issue>3</issue>): <fpage>467</fpage>–<lpage>473</lpage>.</citation></ref>
<ref id="bibr57-0962280212448975"><label>57</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Matthias</surname><given-names>JM</given-names></name><name><surname>Dirk</surname><given-names>G</given-names></name><name><surname>Carsten</surname><given-names>W</given-names></name><etal/></person-group>. <article-title>Diagnostic utility of hippocampal size and mean diffusivity in amnestic MCI</article-title>. <source>Neurobiol Aging</source> <year>2007</year>; <volume>28</volume>(<issue>3</issue>): <fpage>398</fpage>–<lpage>403</lpage>.</citation></ref>
<ref id="bibr58-0962280212448975"><label>58</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Eckerström</surname><given-names>C</given-names></name><name><surname>Olsson</surname><given-names>E</given-names></name><name><surname>Borga</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>Small baseline volume of left hippocampus is associated with subsequent conversion of MCI into dementia: the Göteborg MCI study</article-title>. <source>J Neurol Sci</source> <year>2008</year>; <volume>272</volume>(<issue>1–2</issue>): <fpage>48</fpage>–<lpage>59</lpage>.</citation></ref>
<ref id="bibr59-0962280212448975"><label>59</label><citation citation-type="other"><person-group person-group-type="author"><name><surname>Suite</surname><given-names>B</given-names></name></person-group>. <source>BrainVisa anatomist</source> <year>2000</year>. <comment><ext-link ext-link-type="uri" xlink:href="Http://brainvisa.info">http://brainvisa.info</ext-link> (2000). (accessed on December 2009)</comment>.</citation></ref>
<ref id="bibr60-0962280212448975"><label>60</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Belkin</surname><given-names>M</given-names></name><name><surname>Niyogi</surname><given-names>P</given-names></name></person-group>. <article-title>Laplacian eigenmaps for dimensionality reduction and data representation</article-title>. <source>Neural Computation</source> <year>2003</year>; <volume>15</volume>(<issue>6</issue>): <fpage>1373</fpage>–<lpage>1396</lpage>.</citation></ref>
<ref id="bibr61-0962280212448975"><label>61</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peinecke</surname><given-names>N</given-names></name><name><surname>Wolter</surname><given-names>FE</given-names></name><name><surname>Reuter</surname><given-names>M</given-names></name></person-group>. <article-title>Laplace spectra as fingerprints for image recognition</article-title>. <source>Comput Aid Des</source> <year>2007</year>; <volume>39</volume>(<issue>6</issue>): <fpage>460</fpage>–<lpage>476</lpage>.</citation></ref>
<ref id="bibr62-0962280212448975"><label>62</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ramírez</surname><given-names>J</given-names></name><name><surname>Górriz</surname><given-names>JM</given-names></name><name><surname>Salas-Gonzalez</surname><given-names>D</given-names></name><etal/></person-group>. <article-title>Computer-aided diagnosis of Alzheimer's type dementia combining support vector machines and discriminant set of features</article-title>. <source>Inform Sci</source> <year>2009</year>. <comment>(In Press</comment>.</citation></ref>
<ref id="bibr63-0962280212448975"><label>63</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Markiewicz</surname><given-names>PJ</given-names></name><name><surname>Matthews</surname><given-names>JC</given-names></name><name><surname>Declerck</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>Robustness of multivariate image analysis assessed by resampling techniques and applied to FDG-PET scans of patients with Alzheimer's disease</article-title>. <source>NeuroImage</source> <year>2009</year>; <volume>46</volume>(<issue>2</issue>): <fpage>472</fpage>–<lpage>485</lpage>.</citation></ref>
</ref-list>
</back>
</article>