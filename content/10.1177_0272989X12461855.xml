<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MDM</journal-id>
<journal-id journal-id-type="hwp">spmdm</journal-id>
<journal-id journal-id-type="nlm-ta">Med Decis Making</journal-id>
<journal-title>Medical Decision Making</journal-title>
<issn pub-type="ppub">0272-989X</issn>
<issn pub-type="epub">1552-681X</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0272989X12461855</article-id>
<article-id pub-id-type="publisher-id">10.1177_0272989X12461855</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Identifying Individual Changes in Performance With Composite Quality Indicators While Accounting for Regression to the Mean</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Gajewski</surname><given-names>Byron J.</given-names></name>
<degrees>PhD</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Dunton</surname><given-names>Nancy</given-names></name>
<degrees>PhD</degrees>
</contrib>
</contrib-group>
<aff id="aff1-0272989X12461855">Department of Biostatistics, University of Kansas School of Medicine, Kansas City, Kansas (BJG)</aff>
<aff id="aff2-0272989X12461855">University of Kansas School of Nursing, Kansas City, Kansas (ND)</aff>
<author-notes>
<corresp id="corresp1-0272989X12461855">Byron J. Gajewski, Department of Biostatistics, University of Kansas School of Medicine, Mail Stop 1026, 3901 Rainbow Blvd., Kansas City, KS 66160; e-mail: <email>bgajewski@kumc.edu</email>.</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2013</year>
</pub-date>
<volume>33</volume>
<issue>3</issue>
<issue-title>Special Issue: Health Technology Assessment to Inform Policy</issue-title>
<fpage>396</fpage>
<lpage>406</lpage>
<history>
<date date-type="received">
<day>24</day>
<month>5</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>1</month>
<year>2012</year>
</date>
</history>
<abstract>
<p>Almost a decade ago Morton and Torgerson indicated that perceived medical benefits could be due to “regression to the mean.” Despite this caution, the regression to the mean “effects on the identification of changes in institutional performance do not seem to have been considered previously in any depth” (Jones and Spiegelhalter). As a response, Jones and Spiegelhalter provide a methodology to adjust for regression to the mean when modeling recent changes in institutional performance for one-variable quality indicators. Therefore, in our view, Jones and Spiegelhalter provide a breakthrough methodology for performance measures. At the same time, in the interests of parsimony, it is useful to aggregate individual quality indicators into a composite score. Our question is, can we develop and demonstrate a methodology that extends the “regression to the mean” literature to allow for composite quality indicators? Using a latent variable modeling approach, we extend the methodology to the composite indicator case. We demonstrate the approach on 4 indicators collected by the National Database of Nursing Quality Indicators. A simulation study further demonstrates its “proof of concept.”</p>
</abstract>
<kwd-group>
<kwd>provider profiling</kwd>
<kwd>individual changes</kwd>
<kwd>National Database of Nursing Quality Indicators</kwd>
<kwd>regression to the mean</kwd>
<kwd>Bayesian analysis</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>One of the first policy responses to the Institute of Medicine reports<sup><xref ref-type="bibr" rid="bibr1-0272989X12461855">1</xref>,<xref ref-type="bibr" rid="bibr2-0272989X12461855">2</xref></sup> by governments and regulatory organizations was the requirement for health care providers, including nurses, to define, collect, and monitor health care quality indicators relative to peers and track individual improvement over time. Several indicators may reflect the quality of care. In the interests of parsimony, it is useful to aggregate individual quality indicators into a composite score.<sup><xref ref-type="bibr" rid="bibr3-0272989X12461855">3</xref></sup> To that end, we are interested in developing a methodology for providing guidance regarding when a provider has significantly improved or declined on overall quality as measured by several indicators.</p>
<p>There have been several methodological approaches to developing composite quality indicators. One example of measuring quality with several indicators includes a multilevel, multidimensional latent variable model that examines the performance of a network of hospitals.<sup><xref ref-type="bibr" rid="bibr4-0272989X12461855">4</xref></sup> Another cross-sectional approach is a model-based score developed with a latent variable model using item response theory.<sup><xref ref-type="bibr" rid="bibr5-0272989X12461855">5</xref></sup> An extension of Teixeira-Pinto and Normand5 discusses the merits of an item response theory latent variable approach to modeling multivariate indicators.<sup><xref ref-type="bibr" rid="bibr6-0272989X12461855">6</xref></sup> Serial dependence among latent variables is modeled through pairwise correlations.<sup><xref ref-type="bibr" rid="bibr7-0272989X12461855">7</xref></sup> We use a latent variable approach that extends the “regression to the mean” literature to allow for multiple variables.</p>
<p>Jones and Spiegelhalter<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref></sup> provide a methodology to adjust for regression to the mean when modeling recent changes in institutional performance for 1 variable. More on the history of regression to the mean, including its connection to test–retest literature, is found in Jones and Spiegelhalter. The methodology relies on an analysis of covariance–type argument by predicting a particular institution’s performance using its time 1 outcome to predict what would have happened at time 2. The standardized difference between the observed and the prediction provides the test statistic for determining the institutions that have significant improvement or decline. Note that one can use an appropriate cut point for this test statistic to adjust for false discovery rates.<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref></sup></p>
<p>We examine quality on individual acute care nursing units (“institution”) to track their quality improvement. The individual nursing unit does not necessarily care about adjusting for all units across the nation. Therefore, if the unit wants a 0.05 type I error for an indicator, it can use a usual 2-sided cut point of <italic>Z</italic> = 1.96. If units are interested in tracking several quality indicators at once—in our case, there are 4—they will likely be interested in controlling for an individual nursing unit’s type I error rate. To control for the error rate, the unit can use a Bonferoni adjustment (.05/4 = .0125) or, alternatively, the multivariate approach that we propose here.</p>
<p>The research question that we address is, can we develop and demonstrate a methodology that extends the “regression to the mean” literature to allow for composite quality indicators? To account for multivariate data, we propose to take advantage of a single latent variable that may represent the nursing unit’s quality. Latent variable models (or structural equation modeling) have become popular methods for multivariate health care data modeling.<sup><xref ref-type="bibr" rid="bibr9-0272989X12461855">9</xref>,<xref ref-type="bibr" rid="bibr10-0272989X12461855">10</xref></sup> They are most useful when one can define a finite number of constructs (usually smaller than number of variables) to summarize the multiple dimensions. We will show that the construct unit <italic>quality</italic> adequately explains the variation when the appropriate distributions are used. For example, total nursing hours per patient day (TNHPPD) tends to resemble log-normal distribution; job enjoyment (JE), a normal distribution; fall rates, a Poisson distribution; and pressure ulcers (PrUs), a binomial distribution. After these technical modeling details are established, we show that all temporal quality improvement (or decline) can be monitored on the construct unit <italic>quality</italic>. Not only does this approach control for type I error and provide a parsimonious interpretation, but it also adjusts for regression to the mean.</p>
<sec id="section1-0272989X12461855">
<title>Methods: General Modeling and Data</title>
<p>In this section we lay the groundwork for adjusting for regression to the mean of the construct unit <italic>quality.</italic> We review the univariate version of the test, further introduce the American Nurses Association’s National Database of Nursing Quality Indicators (NDNQI; see <ext-link ext-link-type="uri" xlink:href="http://www.nursingquality.org/">http://www.nursingquality.org/</ext-link>), and show an example of a univariate test from the NDNQI.</p>
<p>This article focuses on the development of composite quality indicators for hospital-based nursing care using data from the NDNQI. Today, over 1800 hospitals with more than 17,000 nursing units participate in the database. Nursing care is provided on the individual unit or ward, and so the quality of care is assessed at the unit level. The types of quality indicators that the NDNQI develops and monitors are reflective of Donabedian’s quality improvement model, in which the structure and process of care influence the outcomes of care.<sup><xref ref-type="bibr" rid="bibr11-0272989X12461855">11</xref></sup> An example of a structural indicator is the number of nursing hours per patient day. The number of nurses assigned to care for patients is determined by state policy (in some cases), professional standards, institutional resources, and, arguably, the general structural dedication to the quality of care in a unit. An example of a process measure is registered nurse JE. Two sample patient outcomes include the fall rate and the hospital-acquired PrU rate. A fall is an “unplanned decent to the floor,” and a PrU is also known as a “bed sore.” We define <italic>quality</italic> as a nursing unit’s commitment to quality. High staffing, happy staff, and safe patients reflect a commitment to high quality. We focus the rest of this article on these 4 quality indicators. The NDNQI routinely demonstrates the reliability and validity of these indicators through carefully designed and analyzed studies.<sup><xref ref-type="bibr" rid="bibr12-0272989X12461855">12</xref><xref ref-type="bibr" rid="bibr13-0272989X12461855"/><xref ref-type="bibr" rid="bibr14-0272989X12461855"/><xref ref-type="bibr" rid="bibr15-0272989X12461855"/>–<xref ref-type="bibr" rid="bibr16-0272989X12461855">16</xref></sup></p>
<sec id="section2-0272989X12461855">
<title>Univariate Adjustment for Regression to the Mean: Jones and Spiegelhalter</title>
<p>Using Jones and Spiegelhalter notation,<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref></sup> let <italic>Y<sub>i1</sub></italic> and <italic>Y<sub>i2</sub></italic> be 2 realizations of a performance indicator for the <italic>i</italic>th institution at time 1 and time 2, respectively. Under the null hypothesis of no change, the “true” unit performance is denoted by <italic>θ<sub>i</sub></italic>, and the distributions of <italic>Y<sub>i1</sub></italic>|<italic>θ<sub>i</sub></italic> and <italic>Y<sub>i2</sub></italic>|<italic>θ<sub>i</sub></italic> are conditionally independent, N (<italic>θ<sub>i</sub>, σ</italic><sup>2</sup>). Via hierarchical model, we can set <italic>θ<sub>i</sub></italic> = <italic>µ</italic>+<italic>d<sub>i</sub></italic> where <italic>d<sub>i</sub></italic> ~ N (0, <italic>τ</italic><sup>2</sup>). Thus, the marginal distribution of <italic>Y<sub>i1</sub></italic> and <italic>Y<sub>i2</sub></italic> are both N (<italic>µ, τ</italic><sup>2</sup>+<italic>σ</italic><sup>2</sup>) and intraclass (i.e., between period) correlation <italic>ρ = τ</italic><sup>2</sup>/(<italic>τ</italic><sup>2</sup>+<italic>σ</italic><sup>2</sup>). Note that this approach assumes constant <italic>σ</italic><sup>2</sup>, both across units and across time. Jones and Spiegelhalter also present a test statistic for the case of nonconstant <italic>σ</italic><sup>2</sup>. The alternative hypothesis is that <italic>θ<sub>i</sub></italic> does change over time. The adjusted test statistic, under the null hypothesis, is conditioned on observing the institution’s first value: <inline-formula id="inline-formula1-0272989X12461855">
<mml:math display="inline" id="math1-0272989X12461855">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>Z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">|</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula2-0272989X12461855">
<mml:math display="inline" id="math2-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>µ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula3-0272989X12461855">
<mml:math display="inline" id="math3-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is the adjusted measure of individual change (i.e., adjusted for regression to the mean). Jones and Spiegelhalter indicate the test static is superior to the naïve version of <inline-formula id="inline-formula4-0272989X12461855">
<mml:math display="inline" id="math4-0272989X12461855">
<mml:mrow>
<mml:mi>Z</mml:mi>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula> because unlike <italic>Z, Z</italic>* is uncorrelated with <italic>Y<sub>i1</sub></italic>, so it adjusts for the classic “regression to the mean.” While Jones and Spiegelhalter mainly use a frequentist justification for this test based on the sampling distribution of <inline-formula id="inline-formula5-0272989X12461855">
<mml:math display="inline" id="math5-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, they briefly point out that the same test statistic has predictive distribution justification: “Equivalently, this tests the “surprisingness” of <italic>Y</italic><sub>2</sub> based on a simple random effects predictive distribution, whereas <italic>Z</italic> is the test statistic based on a fixed effects (independent) predictive distribution.”<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref>(p1649)</sup> Their article has frequentist foundation, but we believe that it can be conceptualized from a Bayesian point of view. Specifically, <inline-formula id="inline-formula6-0272989X12461855">
<mml:math display="inline" id="math6-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> (posterior predictive distribution given <inline-formula id="inline-formula7-0272989X12461855">
<mml:math display="inline" id="math7-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>) has mean <inline-formula id="inline-formula8-0272989X12461855">
<mml:math display="inline" id="math8-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>µ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula> and variance <inline-formula id="inline-formula9-0272989X12461855">
<mml:math display="inline" id="math9-0272989X12461855">
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula>. A frequentist would plug in point estimates of ρ, µ, and <inline-formula id="inline-formula10-0272989X12461855">
<mml:math display="inline" id="math10-0272989X12461855">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
<p>A fully Bayesian approach involves accounting for uncertainty in the population-level parameters in each predictive distribution. The test statistic itself, <italic>Z</italic>*, is not what would arise from a fully Bayesian approach. One way to accomplish a fully Bayesian approach is to use a software program tailored for such models (e.g., WinBUGS). This allows <italic>σ</italic><sup>2</sup> and <italic>µ</italic> to vary, as well as <italic>ρ</italic> and <italic>τ</italic><sup>2</sup>, although <italic>ρ</italic> = <italic>τ</italic><sup>2</sup>/(<italic>τ</italic><sup>2</sup>+<italic>σ</italic><sup>2</sup>). We accomplish such a fit in the univariate case after introducing the data. The univariate case motivates the multivariate model.</p>
</sec>
<sec id="section3-0272989X12461855">
<title>Data: NDNQI</title>
<p>The NDNQI reports that are generated for member units are stratified by bed size and unit type (as well as other hospital characteristics). We focus on unit type in this article. The different unit types include critical care, step down, medical, surgical, combined medical–surgical, and rehabilitation. Our example focuses on combined medical–surgical units aggregated up to the unit level for the years 2006 and 2007. We focus on the NDNQI indicators: TNHPPD, registered nurse JE, fall rates, and PrU rates.</p>
<p>The relative nursing effort in a unit is indicated as a ratio: TNHPP. JE data are from a survey of registered nurses. This indicator is an average of 7 questions on a 6-point Likert scale (1, strongly disagree; 6, strongly agree). Sample items include “Nurses are satisfied with jobs” and “Find real enjoyment in their job.” The number of falls per thousand patient days defines fall rates. The number of patients in a 24-hour period that have at least 1 hospital-acquired PrU as a proportion of all patients assessed is the PrU rate. Note that, as discussed in Gajewski et al.,<sup><xref ref-type="bibr" rid="bibr17-0272989X12461855">17</xref></sup> we are not performing risk adjustment for our modeling, which is consistent with how NDNQI reports are presented to members. <xref ref-type="table" rid="table1-0272989X12461855">Table 1</xref> indicates that across the 2-year average, TNHPPD is about 8 hours per patient day. That converts to about 3 patients for every registered nurse. The mean JE is close to the midpoint (1–6 scale). The fall rates’ mean is about 4 falls for every 1000 patient days. The mean percentage of patients with PrUs is about 5.5%.</p>
<table-wrap id="table1-0272989X12461855" position="float">
<label>Table 1</label>
<caption><p>Medical–Surgical Summary Statistics</p></caption>
<graphic alternate-form-of="table1-0272989X12461855" xlink:href="10.1177_0272989X12461855-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Measure</th>
<th align="center">Year</th>
<th align="center">Min</th>
<th align="center">Max</th>
<th align="center"><inline-formula id="inline-formula11-0272989X12461855">
<mml:math display="inline" id="math11-0272989X12461855">
<mml:mover accent="true">
<mml:mi>x</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>
</th>
<th align="center"><italic>s</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">Total nursing hours per patient day</td>
</tr>
<tr>
<td> exp(<italic>Y<sub>11</sub></italic>)</td>
<td>2006</td>
<td>5.50</td>
<td>13.94</td>
<td>8.24</td>
<td>1.40</td>
</tr>
<tr>
<td> exp(<italic>Y<sub>12</sub></italic>)</td>
<td>2007</td>
<td>5.66</td>
<td>13.84</td>
<td>8.41</td>
<td>1.39</td>
</tr>
<tr>
<td colspan="6">Job enjoyment</td>
</tr>
<tr>
<td> <italic>Y<sub>21</sub></italic></td>
<td>2006</td>
<td>2.00</td>
<td>4.62</td>
<td>3.49</td>
<td>0.49</td>
</tr>
<tr>
<td> <italic>Y<sub>22</sub></italic></td>
<td>2007</td>
<td>1.70</td>
<td>5.11</td>
<td>3.55</td>
<td>0.51</td>
</tr>
<tr>
<td colspan="6">Fall rate</td>
</tr>
<tr>
<td> <italic>Y<sub>31</sub>/w<sub>1</sub></italic></td>
<td>2006</td>
<td>0.00</td>
<td>8.45</td>
<td>4.01</td>
<td>1.53</td>
</tr>
<tr>
<td> <italic>Y<sub>32</sub>/w<sub>2</sub></italic></td>
<td>2007</td>
<td>0.19</td>
<td>8.37</td>
<td>4.01</td>
<td>1.45</td>
</tr>
<tr>
<td colspan="6">Pressure ulcer rate</td>
</tr>
<tr>
<td> <italic>Y<sub>41</sub>/n<sub>1</sub></italic></td>
<td>2006</td>
<td>0.00</td>
<td>0.46</td>
<td>0.06</td>
<td>0.05</td>
</tr>
<tr>
<td> <italic>Y<sub>42</sub>/n<sub>2</sub></italic></td>
<td>2007</td>
<td>0.00</td>
<td>0.33</td>
<td>0.05</td>
<td>0.04</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0272989X12461855">
<p>Note: <italic>n</italic> = 290 units, with full data from 2006 (time 1) to 2007 (time 2).</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section4-0272989X12461855">
<title>Example: TNHPPD</title>
<p>To illustrate Jones and Spiegelhalter’s method on our data, as well as its Bayesian analog discussed above, we examine the log-transformed version of TNHPPD: <inline-formula id="inline-formula12-0272989X12461855">
<mml:math display="inline" id="math12-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>log</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>TNHPPD</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mo>.</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula13-0272989X12461855">
<mml:math display="inline" id="math13-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>log</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>TNHPPD</mml:mtext>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. We fitted a one-way random effects analysis of variance (ANOVA) model and estimated parameters using ANOVA-expected mean squared error<sup><xref ref-type="bibr" rid="bibr18-0272989X12461855">18</xref>(p133–34)</sup> as <inline-formula id="inline-formula14-0272989X12461855">
<mml:math display="inline" id="math14-0272989X12461855">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>µ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula15-0272989X12461855">
<mml:math display="inline" id="math15-0272989X12461855">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0032</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula16-0272989X12461855">
<mml:math display="inline" id="math16-0272989X12461855">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>τ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0240</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula17-0272989X12461855">
<mml:math display="inline" id="math17-0272989X12461855">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0240</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0240</mml:mn>
<mml:mo>+</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0032</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mo>.</mml:mo>
<mml:mn>8824</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. Note that while Jones and Spiegelhalter found that the increase in power due to the adjustment was very small with <italic>ρ</italic> as large as 0.8, we simply illustrate the approach on TNHPPD. The value for <italic>ρ</italic> is much smaller in the multivariate example. We then flagged all of the units as significantly improving or declining that had <italic>Z</italic>* &gt; 1.96 or <italic>Z</italic>* &lt; −1.96, respectively. There are only 2 units out of 290 that are significantly decreasing. Unit A dropped from 10.4 to 8.2 TNHPPD (<italic>Z</italic>* = −2.74), while unit B dropped from 6.8 to 5.8 (<italic>Z</italic>* = −2.22). This is depicted on the log scale in <xref ref-type="fig" rid="fig1-0272989X12461855">Figure 1</xref>. Unit A started above the overall mean, so part of its drop is explained by regression to the mean. Unit B had only a 1-point drop, but it is significant because it is trending opposite the overall mean. There are 11 units that had significant improvement. The unit with the largest improvement started with a rate of 6.9 and improved to 10.3 (<italic>Z</italic>* = 4.9). As theory dictates, corr (<italic>Y<sub>i1</sub></italic>, Z*) = −.035 ~ 0 and corr (<italic>Y<sub>i1</sub></italic>, Z) = −.288 &lt; 0, illustrating advantage of <italic>Z</italic>* over <italic>Z</italic>. Note that as mentioned earlier, from NDNQI viewpoint, we are controlling for an individual nursing unit’s type I error rate. However, we warn here that from an overall perspective, for the 290 units, 1 in 20 (~15 units) is expected to be “significant” by chance alone. We also applied a Bayesian calculation via WinBUGS. We essentially placed flat priors on all unknown parameters and then calculated the posterior predictive distribution at each iteration of simulation to be <inline-formula id="inline-formula18-0272989X12461855">
<mml:math display="inline" id="math18-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo>,</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> and then calculated <italic>Z</italic>*<sup>P</sup> = (<italic>Y<sub>i1</sub></italic>–<inline-formula id="inline-formula19-0272989X12461855">
<mml:math display="inline" id="math19-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>)/<italic>s</italic> ((<italic>Y<sub>i1</sub></italic>–<inline-formula id="inline-formula20-0272989X12461855">
<mml:math display="inline" id="math20-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>)). Note that, theoretically, <italic>s</italic> ((<italic>Y<sub>i1</sub></italic>–<inline-formula id="inline-formula21-0272989X12461855">
<mml:math display="inline" id="math21-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>)) &gt; <inline-formula id="inline-formula22-0272989X12461855">
<mml:math display="inline" id="math22-0272989X12461855">
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula> because of the propagation of error from posterior distributions of <italic>ρ</italic> and <italic>σ</italic><sup>2</sup>. But because of the relative large sample size, this propagation is negligible. We burned in 1000 iterations and used the next 10,000 for inference. The Bayes estimates were very similar to the ANOVA-based estimates, <inline-formula id="inline-formula23-0272989X12461855">
<mml:math display="inline" id="math23-0272989X12461855">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula24-0272989X12461855">
<mml:math display="inline" id="math24-0272989X12461855">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0033</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula25-0272989X12461855">
<mml:math display="inline" id="math25-0272989X12461855">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>τ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0242</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula26-0272989X12461855">
<mml:math display="inline" id="math26-0272989X12461855">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>8801</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. The same units were significant under both approaches (<italic>Z</italic>*<sup>P</sup> or <italic>Z</italic>*). Note that in both approaches it is likely that the assumption of multivariate log-normal distribution is important. Examination of the marginal q-q plots indicates that this assumption is valid.</p>
<fig id="fig1-0272989X12461855" position="float">
<label>Figure 1</label>
<caption>
<p>Similar to plot in Jones and Spieglhalter demonstrating the effect of baseline deviation from the mean on the adjusted change for nursing units A and B.</p>
</caption>
<graphic xlink:href="10.1177_0272989X12461855-fig1.tif"/>
</fig>
</sec>
</sec>
<sec id="section5-0272989X12461855">
<title>Methods: Composite Indicator (Multivariate) Adjustment for Regression to the Mean</title>
<p>Almost a decade ago, Morton and Torgerson<sup><xref ref-type="bibr" rid="bibr19-0272989X12461855">19</xref>(p1084)</sup> indicated that perceived medical benefits could be due to “regression to the mean.” Despite this caution, Jones and Spiegelhalter indicate that “the phenomenon’s effects on the identification of changes in institutional performance do not seem to have been considered previously in any depth.”<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref>(p1646)</sup> Therefore, in our view, Jones and Spiegelhalter provide a breakthrough methodology for performance measures. We expand this methodology for composite indicators.</p>
<p>The previous section illustrates the univariate approach for recognizing a unit’s significant improvement or decline. Now that we have a goal to create a reflective-type model, we use the same idea for recognition of significant units from a composite indicator (multivariate) approach via latent variable modeling.</p>
<sec id="section6-0272989X12461855">
<title>Composite Indicators via a Multivariate Latent Variable Model</title>
<p>Building from the univariate model described above, we begin the multivariate model by letting <italic>Y<sub>jit</sub></italic> be the <italic>j</italic>th variable where <italic>j</italic> = 1, 2, 3, 4; <italic>i</italic> is the <italic>i</italic>th unit where <italic>i</italic> = 1, 2, 3, . . . , 290; and <italic>t</italic> = 1, 2 where <italic>t</italic> = 1 is from 2006 and <italic>t</italic> = 2 is 2007. The sampling distribution of each is</p>
<p>
<disp-formula id="disp-formula1-0272989X12461855">
<mml:math display="block" id="math27-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0272989X12461855" xlink:href="10.1177_0272989X12461855-eq1.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula27-0272989X12461855">
<mml:math display="inline" id="math28-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is a location parameter such that</p>
<p>
<disp-formula id="disp-formula2-0272989X12461855">
<mml:math display="block" id="math29-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ji</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0272989X12461855" xlink:href="10.1177_0272989X12461855-eq2.tif"/>
</disp-formula>
</p>
<p>and <inline-formula id="inline-formula28-0272989X12461855">
<mml:math display="inline" id="math30-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> is the variance of the sampling distribution. Equation 2 is the single-factor measurement model that allows for the <italic>i</italic>th unit’s <italic>t</italic>th time point to correlate with latent variable <italic>f<sub>it</sub></italic>. The <italic>a<sub>j</sub></italic> represents the intercept for <italic>j</italic>th variable. The <italic>b<sub>j</sub></italic> represents the respective regression coefficient (loading) between latent construct (<italic>f<sub>it</sub></italic>) and the transformed location parameter <inline-formula id="inline-formula29-0272989X12461855">
<mml:math display="inline" id="math31-0272989X12461855">
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. The <italic>g<sub>j</sub></italic> is a link function to the measurement model via usual generalize linear model.<sup><xref ref-type="bibr" rid="bibr20-0272989X12461855">20</xref></sup> The <italic>g<sub>j</sub></italic> link function can vary in form, such as logistic or exponential transformations. One clear advantage of this transformation is that it forces the parameters to be in the correct space. For example, logistic keeps probabilities between 0 and 1, and exponential keeps fall rates positive. We allow the latent factor to correlate across time points using the same idea as in the univariate model with 2 normal distributions, <inline-formula id="inline-formula30-0272989X12461855">
<mml:math display="inline" id="math32-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula31-0272989X12461855">
<mml:math display="inline" id="math33-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. This latter constraint <inline-formula id="inline-formula32-0272989X12461855">
<mml:math display="inline" id="math34-0272989X12461855">
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> is imposed for identification purposes such that the unconditional <inline-formula id="inline-formula33-0272989X12461855">
<mml:math display="inline" id="math35-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. Therefore, <inline-formula id="inline-formula34-0272989X12461855">
<mml:math display="inline" id="math36-0272989X12461855">
<mml:mrow>
<mml:mi>ρ</mml:mi>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. Data will show that latent factor correlation does not explain enough of the correlation within measures across time. Therefore, the correlations are further modeled with <inline-formula id="inline-formula35-0272989X12461855">
<mml:math display="inline" id="math37-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ji</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. The distributions defined in equation 1 and the link in equation 2 vary across the 4 variables.</p>
<p>For each of the 4 manifest variables, we need to define the variance components (<inline-formula id="inline-formula36-0272989X12461855">
<mml:math display="inline" id="math38-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>jit</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>), sampling distribution (<inline-formula id="inline-formula37-0272989X12461855">
<mml:math display="inline" id="math39-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>), and link function (<inline-formula id="inline-formula38-0272989X12461855">
<mml:math display="inline" id="math40-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>).</p>
<sec id="section7-0272989X12461855">
<title>Variable 1: TNHPPD</title>
<p>As discussed in the TNHPPD example, the TNHPPD is justifiably modeled by a lognormal distribution. Therefore the variance, distribution, and link will be defined as <inline-formula id="inline-formula39-0272989X12461855">
<mml:math display="inline" id="math41-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>≡</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula40-0272989X12461855">
<mml:math display="inline" id="math42-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
<mml:mi>LN</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula41-0272989X12461855">
<mml:math display="inline" id="math43-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, respectively. The symbol <italic>LN</italic> stands for log-normal distribution. The average TNHPPD for the <italic>i</italic>th unit is thus <inline-formula id="inline-formula42-0272989X12461855">
<mml:math display="inline" id="math44-0272989X12461855">
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</sec>
<sec id="section8-0272989X12461855">
<title>Variable 2: Registered Nurse JE</title>
<p>Let <italic>Y<sub>2it</sub></italic> be the observed average score for unit <italic>i</italic> at time <italic>t</italic>, and <inline-formula id="inline-formula43-0272989X12461855">
<mml:math display="inline" id="math45-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>, the standard deviation for <italic>n<sub>i</sub></italic> registered nurses in unit <italic>i</italic>. We assume that <italic>Y<sub>2it</sub></italic> is normally distributed, which is substantiated in Gajewski et al.<sup><xref ref-type="bibr" rid="bibr17-0272989X12461855">17</xref></sup> We set <inline-formula id="inline-formula44-0272989X12461855">
<mml:math display="inline" id="math46-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>≡</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula45-0272989X12461855">
<mml:math display="inline" id="math47-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula46-0272989X12461855">
<mml:math display="inline" id="math48-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, respectively. Note that based on previous studies, <inline-formula id="inline-formula47-0272989X12461855">
<mml:math display="inline" id="math49-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>726873</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>.<sup><xref ref-type="bibr" rid="bibr17-0272989X12461855">17</xref></sup> Note that the variance of the sampling distribution is weighted by the number of registered nurses in each unit for the sampling time frame. The average registered nurse JE for the <italic>i</italic>th unit is thus <inline-formula id="inline-formula48-0272989X12461855">
<mml:math display="inline" id="math50-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</sec>
<sec id="section9-0272989X12461855">
<title>Variable 3: Fall Rate</title>
<p>For fall rates, we assume that <italic>Y<sub>3it</sub></italic> is the number of falls for the <italic>t</italic>th year and <italic>w<sub>it</sub></italic> represents the respective number of patient days divided by 1000. We assume that <italic>Y<sub>3it</sub></italic> follows a Poisson distribution and that <italic>θ</italic><sub><italic>3it</italic></sub> is the average fall rate (per 1000 patient days) for the <italic>i</italic>th unit and <italic>t</italic>th year. Therefore, <italic>Y<sub>3it</sub></italic> |<italic>θ</italic><sub><italic>3it</italic></sub> ~ <inline-formula id="inline-formula49-0272989X12461855">
<mml:math display="inline" id="math51-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>Poisson (<italic>θ<sub>3it</sub> w<sub>it</sub></italic>), which is substantiated in Gajewski et al.<sup><xref ref-type="bibr" rid="bibr17-0272989X12461855">17</xref></sup> The link function is <inline-formula id="inline-formula50-0272989X12461855">
<mml:math display="inline" id="math52-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
<mml:mi>ln</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where we are setting <inline-formula id="inline-formula51-0272989X12461855">
<mml:math display="inline" id="math53-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>≡</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. The average fall rate for the <italic>i</italic>th unit is thus <inline-formula id="inline-formula52-0272989X12461855">
<mml:math display="inline" id="math54-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</sec>
<sec id="section10-0272989X12461855">
<title>Variable 4: PrU Rate</title>
<p>The final variable involves hospital-acquired PrUs. Let <italic>Y<sub>4it</sub></italic> be the number of patients out of <italic>n<sub>it</sub></italic> who have a hospital acquired PrU. We assume that <italic>Y<sub>4it</sub></italic> is a binomial distribution with <italic>n<sub>j</sub></italic> trials and that <italic>θ<sub>j</sub></italic> is the average PrU rate for unit <italic>j</italic>. Therefore, <italic>Y<sub>4it</sub></italic>|<italic>θ<sub>4it</sub></italic>~Bin (<italic>θ<sub>4it</sub>, n<sub>it</sub></italic>), also substantiated in Gajewski et al.<sup><xref ref-type="bibr" rid="bibr17-0272989X12461855">17</xref></sup> The link function is <inline-formula id="inline-formula53-0272989X12461855">
<mml:math display="inline" id="math55-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≡</mml:mo>
<mml:mtext>logit</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where we are setting <inline-formula id="inline-formula54-0272989X12461855">
<mml:math display="inline" id="math56-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>≡</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. The proportion of PrUs for the <italic>i</italic>th unit is thus <inline-formula id="inline-formula55-0272989X12461855">
<mml:math display="inline" id="math57-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</sec>
<sec id="section11-0272989X12461855">
<title>Overall Model: Testing Improvement or Decline</title>
<p>The overall latent variable model is summarized in <xref ref-type="fig" rid="fig2-0272989X12461855">Figure 2</xref> using standard graphical descriptions—ovals for latent variables and squares for manifest variables. The <italic>f</italic>’s represent the univariate latent variable <italic>quality</italic>, which manifests itself as <italic>θ</italic>’s after transformation using the intercepts (<italic>a</italic>’s) and slopes (<italic>b</italic>’s). The <italic>f</italic>’s are allowed to vary through the variation in <italic>d</italic>’s (random effect of units). The manifest variables (<italic>Y</italic>’s) vary from the <italic>θ</italic>’s and sampling distributions. Before we can test for improvement in the <italic>i</italic>th unit, all of the nonrealized parameters in this model need estimation. We accomplish this estimation via Bayesian modeling, which we articulate further in the Computation, Model Fit, and Simulation section. We test the multivariate significant improvement or decline of a unit using the conditional distribution of the latent variable <inline-formula id="inline-formula56-0272989X12461855">
<mml:math display="inline" id="math58-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>ρ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>ρ = <inline-formula id="inline-formula57-0272989X12461855">
<mml:math display="inline" id="math59-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula></italic> and recall <inline-formula id="inline-formula58-0272989X12461855">
<mml:math display="inline" id="math60-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. Therefore, our multivariate Bayesian test statistic is <inline-formula id="inline-formula59-0272989X12461855">
<mml:math display="inline" id="math61-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>Z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">/</mml:mo>
<mml:mtext>sd</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, which properly adjusts for “regression to the mean” in a manner similar to that of Jones and Spiegelhalter. While <italic>f<sub>i2</sub></italic> and <italic>f<sub>i1</sub></italic> are unknown (latent variable), like the other unknown parameters in the model, we are monitoring their posterior distributions in WinBUGS at each iteration.</p>
<fig id="fig2-0272989X12461855" position="float">
<label>Figure 2</label>
<caption><p>Overall latent variable model.</p></caption>
<graphic xlink:href="10.1177_0272989X12461855-fig2.tif"/>
</fig>
<p>Some may argue that a Jones and Speigelhalter–type correction does not do anything, as it is applied to a latent variable as opposed to observed values. Since latent variables represent some underlying “true value,” it may seem that they are not subject to regression to the mean in the same way. However, as pointed out to us by reviewer, this fear is unjustified in the context of the model for the latent variables. A simple model, one that sets <italic>d<sub>ji</sub></italic> = 0, is strictly analogous to the model given by Jones and Speigelhalter for random variables in section 2.1 (basic assumptions) and section 2.2 of their article. A simple latent variable model has E (<italic>f<sub>i1</sub></italic>|<italic>d<sub>i</sub></italic>) = E (<italic>f<sub>i2</sub></italic>|<italic>d<sub>i</sub></italic> ) = <italic>d<sub>i</sub></italic> and Var (<italic>f<sub>i1</sub></italic>|<italic>d<sub>i</sub></italic>) = Var (<italic>f<sub>i2</sub></italic>|<italic>d<sub>i</sub></italic>) = 1 -<inline-formula id="inline-formula60-0272989X12461855">
<mml:math display="inline" id="math62-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. Furthermore, in the population, E (<italic>d<sub>i</sub></italic>) = 0 and Var (<italic>d<sub>i</sub></italic>) = <inline-formula id="inline-formula61-0272989X12461855">
<mml:math display="inline" id="math63-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. So, unconditionally, we have Var (<italic>f<sub>i1</sub></italic>) = Var (<italic>f<sub>i1</sub></italic>) = 1 and Cov (<italic>f<sub>i1</sub>, f<sub>i2</sub></italic>) = <inline-formula id="inline-formula62-0272989X12461855">
<mml:math display="inline" id="math64-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. So <italic>ρ</italic> = Corr (<italic>f<sub>i1</sub>, f<sub>i2</sub></italic>) = <inline-formula id="inline-formula63-0272989X12461855">
<mml:math display="inline" id="math65-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. Given the assumption that the distributions are normal and that 0 ≤<italic>ρ</italic>≤ 1, then E (<italic>f<sub>i2</sub></italic>|<italic>f<sub>i1</sub></italic>) = <italic>ρf<sub>i1</sub></italic>+ (1 –<italic>ρ</italic>) <italic>µ</italic> = <italic>ρf<sub>i1</sub></italic>, since <italic>µ</italic> = 0. Therefore, E (<italic>f<sub>i2</sub></italic>|<italic>f<sub>i1</sub></italic>) lies between <italic>f<sub>i1</sub></italic> and <italic>µ</italic> = 0. We later show that the value of the latent variable on the second occasion (year 2007 for the data set used) has regressed toward the mean, precisely as in section 2.2 of Jones and Spieghalter.<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref>(p1648–49)</sup> We have <italic>f<sub>i1</sub></italic> and <italic>f<sub>i2</sub></italic> analogous to Jones and Speiglehalter’s <italic>Y<sub>i1</sub></italic> and <italic>Y<sub>i2</sub>, d<sub>i</sub></italic> analogous to Jones and Speigelhalter’s <italic>θ<sub>i</sub></italic>, and so on. Furthermore, even for the more complex latent variable model (e.g., <italic>d<sub>ji</sub></italic>≠ 0), this issue is clarified in both the substantive example and the proof-of-concept simulation, where we show that the latent variable model does in fact suffer from regression to the mean because estimates of <inline-formula id="inline-formula64-0272989X12461855">
<mml:math display="inline" id="math66-0272989X12461855">
<mml:mrow>
<mml:mi>corr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> are much closer to 0 than estimates of <inline-formula id="inline-formula65-0272989X12461855">
<mml:math display="inline" id="math67-0272989X12461855">
<mml:mrow>
<mml:mi>corr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</sec>
</sec>
<sec id="section12-0272989X12461855">
<title>Priors</title>
<p>The final step of the Bayesian model requires the prior distributions, which we specify to be approximately “flat” or noninformative. The intercepts and slopes have the distributions <inline-formula id="inline-formula66-0272989X12461855">
<mml:math display="inline" id="math68-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>100</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula67-0272989X12461855">
<mml:math display="inline" id="math69-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>100</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. All the variance components <inline-formula id="inline-formula68-0272989X12461855">
<mml:math display="inline" id="math70-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:mtext>and</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> have a prior of <inline-formula id="inline-formula69-0272989X12461855">
<mml:math display="inline" id="math71-0272989X12461855">
<mml:mrow>
<mml:mi>IG</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>01</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>01</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>IG</italic> is the inverse-gamma distribution.</p>
</sec>
</sec>
<sec id="section13-0272989X12461855">
<title>Methods: Computation, Model Fit, and Simulation</title>
<p>WinBUGS<sup><xref ref-type="bibr" rid="bibr21-0272989X12461855">21</xref></sup> was used to fit a Bayesian estimation via Markov chain Monte Carlo (MCMC). Following a burn-in of 5000 iterations, the posterior distributions were monitored over a further 10,000 iterations of the MCMC. Sensitivity analysis of the specification of the priors for the variance components<sup><xref ref-type="bibr" rid="bibr22-0272989X12461855">22</xref></sup> indicated negligible change in the posterior distributions. Therefore, we report only the posterior distribution using the priors above. For all parameters in the model, the 2.5 percentile, the median, and the 97.5% percentile were used to summarize the posterior distributions. For calculating significant improvement or decline in quality, we calculate the proportion of times that <inline-formula id="inline-formula70-0272989X12461855">
<mml:math display="inline" id="math72-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is larger than <inline-formula id="inline-formula71-0272989X12461855">
<mml:math display="inline" id="math73-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>, calling it <italic>Pr<sub>i</sub></italic>. For reporting purposes, Bayesian <italic>P</italic> value<sub><italic>i</italic></sub> = min (<italic>Pr<sub>i</sub></italic>, 1 –<italic>Pr<sub>i</sub></italic>), which reflects the one-sided Bayesian probability that there is significant improvement or decline.</p>
<p>Model assessment was accomplished through a relative fit as well as a goodness of fit of the correlation matrix of 2 models. An alternative model did not include the variance components that modeled the direct error correlations between indicators (specifically, <inline-formula id="inline-formula72-0272989X12461855">
<mml:math display="inline" id="math74-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> but <inline-formula id="inline-formula73-0272989X12461855">
<mml:math display="inline" id="math75-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>). That is, all of the correlations among variables were modeled only through the quality latent variables. The second model was the model described in the Methods: Composite Indicator section, which fits all variance components (specifically, <inline-formula id="inline-formula74-0272989X12461855">
<mml:math display="inline" id="math76-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, and <inline-formula id="inline-formula75-0272989X12461855">
<mml:math display="inline" id="math77-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>). First, for relative fit, we compare the deviance information criteria (DIC)<sup><xref ref-type="bibr" rid="bibr23-0272989X12461855">23</xref></sup> for both models. Second, we calculate the correlation matrix among all indicators across 2 periods and compare it to correlation matrices generated from posterior draws from the 2 models.</p>
<p>Finally, as a “proof of concept, ” we simulate data to understand the properties of our basic approach. We would like to 1) demonstrate that our approach properly estimates parameters from simulated data and 2) understand how well the approach detects true change in quality (power). Pseudo–random numbers, using Matlab software, are used for all simulations. Our basic data set involves <italic>n</italic> = 100 nursing units and is simulated using the model in the Methods: Composite Indicator section and corresponding median of the posterior distribution of the parameters listed in <xref ref-type="table" rid="table2-0272989X12461855">Table 2</xref> (Estimation of Full Model Parameters section below). Note that we are simulating a scenario in which there are no temporal changes—that is, <inline-formula id="inline-formula76-0272989X12461855">
<mml:math display="inline" id="math78-0272989X12461855">
<mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>~</mml:mo>
<mml:mi>MVN</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. We fit the MCMC algorithm and compare posterior distributions to this truth, demonstrating part 1.</p>
<table-wrap id="table2-0272989X12461855" position="float">
<label>Table 2</label>
<caption><p>Posterior Distribution Summaries for Parameters From Multivariate Model of Medical–Surgical Units</p></caption>
<graphic alternate-form-of="table2-0272989X12461855" xlink:href="10.1177_0272989X12461855-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th/>
<th align="center">2.50%</th>
<th align="center">Mdn</th>
<th align="center">97.50%</th>
<th align="center"><inline-formula id="inline-formula77-0272989X12461855">
<mml:math display="inline" id="math79-0272989X12461855">
<mml:mover accent="true">
<mml:mi>y</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> Observed</th>
</tr>
</thead>
<tbody>
<tr>
<td>exp(<italic>a</italic><sub><italic>1</italic></sub>)</td>
<td>Total nursing hours per patient day</td>
<td>8.06</td>
<td>8.21</td>
<td>8.36</td>
<td>8.33</td>
</tr>
<tr>
<td><italic>a</italic><sub><italic>2</italic></sub></td>
<td>Job enjoyment</td>
<td>3.48</td>
<td>3.53</td>
<td>3.58</td>
<td>3.52</td>
</tr>
<tr>
<td>exp(<italic>a<sub>3</sub></italic>)</td>
<td>Fall rate</td>
<td>3.65</td>
<td>3.80</td>
<td>3.96</td>
<td>4.01</td>
</tr>
<tr>
<td>logit<sup>−1</sup>(<italic>a<sub>4</sub></italic>)</td>
<td>Pressure ulcer rate</td>
<td>0.04</td>
<td>0.05</td>
<td>0.05</td>
<td>0.06</td>
</tr>
<tr>
<td><italic>b</italic><sub>1</sub></td>
<td>Total nursing hours per patient day</td>
<td>0.0046</td>
<td>0.0156</td>
<td>0.0282</td>
<td/>
</tr>
<tr>
<td><italic>b</italic><sub>2</sub></td>
<td>Job enjoyment</td>
<td>0.1792</td>
<td>0.2370</td>
<td>0.3023</td>
<td/>
</tr>
<tr>
<td><italic>b</italic><sub>3</sub></td>
<td>Fall rate</td>
<td>−0.1641</td>
<td>−0.1221</td>
<td>−0.0787</td>
<td/>
</tr>
<tr>
<td><italic>b</italic><sub>4</sub></td>
<td>Pressure ulcer rate</td>
<td>−0.4851</td>
<td>−0.3758</td>
<td>−0.2766</td>
<td/>
</tr>
<tr>
<td><inline-formula id="inline-formula78-0272989X12461855">
<mml:math display="inline" id="math80-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td/>
<td>0.0027</td>
<td>0.0032</td>
<td>0.0037</td>
<td/>
</tr>
<tr>
<td><inline-formula id="inline-formula79-0272989X12461855">
<mml:math display="inline" id="math81-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td/>
<td>0.0198</td>
<td>0.0236</td>
<td>0.0283</td>
<td/>
</tr>
<tr>
<td><inline-formula id="inline-formula80-0272989X12461855">
<mml:math display="inline" id="math82-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td/>
<td>0.0926</td>
<td>0.1276</td>
<td>0.1654</td>
<td/>
</tr>
<tr>
<td><inline-formula id="inline-formula81-0272989X12461855">
<mml:math display="inline" id="math83-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td/>
<td>0.0737</td>
<td>0.0931</td>
<td>0.1169</td>
<td/>
</tr>
<tr>
<td>
<inline-formula id="inline-formula82-0272989X12461855">
<mml:math display="inline" id="math84-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>4</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td/>
<td>0.2772</td>
<td>0.3718</td>
<td>0.4876</td>
<td/>
</tr>
<tr>
<td><inline-formula id="inline-formula83-0272989X12461855">
<mml:math display="inline" id="math85-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>d</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>=</mml:mo><mml:mi>ρ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td/>
<td>0.1453</td>
<td>0.4404</td>
<td>0.6459</td>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0272989X12461855">
<p>Note: <italic>n</italic> = 290, with full data from 2006 (time 1) to 2007 (time 2).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Part 2 adds some complexity to the basic data set by randomly selecting a unit (index it as <italic>i</italic> = 100) and taking it out of the sample. We replace the data from that unit with data using the following two-way factor design. The factors involve the assumption regarding the quality at time 1 (<italic>f<sub>1</sub></italic>), and the other, the difference in quality from time 1 to time 2 (<italic>f<sub>2</sub></italic>–<italic>f<sub>1</sub></italic>). The first factor varies the starting point of where the unit’s quality begins, either at the mean (<italic>f<sub>1</sub></italic> = 0) or far from the mean (<italic>f<sub>1</sub></italic> = 3). The second factor varies in how much the quality of the unit increases across time (<italic>f<sub>2</sub></italic>–<italic>f<sub>1</sub></italic> = 0.0, 0.50, 1.00, . . . , 5.0). This second simulation involves 5 iterations for each combination of the 2 factors. Thus, separate simulations are run for 2 × 11 = 22 combinations of factors.</p>
<p>The main outcome in this simulation is <italic>P</italic> value<italic><sub>i</sub></italic> described above, which is calculated for each combination. A multiple regression—including quality at time 1 (binary) and an interaction between the difference in quality from time 1 and time 2 (continuous) and the quality at time 1—will be estimated after a logit transformation to understand how <italic>P</italic> value varies across the 2 factors. Specifically, logit (<italic>P</italic> value<italic><sub>i</sub></italic>) = B<sub>0</sub>+ B<sub>1</sub><italic>x<sub>i</sub></italic>+ B<sub>2</sub> (1 –<italic>x<sub>i</sub></italic>) (<italic>f<sub>2i</sub></italic>–<italic>f<sub>1i</sub></italic>) + B<sub>3</sub><italic>x</italic><sub>i</sub> (<italic>f<sub>2i</sub></italic>–<italic>f<sub>1i</sub></italic>) +<italic>e<sub>i</sub></italic>, where <italic>x<sub>i</sub></italic> = 0 if <italic>f<sub>1i</sub></italic> = 0 and <italic>x<sub>i</sub></italic> = 1 if <italic>f<sub>1i</sub></italic> = 3. After estimation, we will plot <inline-formula id="inline-formula84-0272989X12461855">
<mml:math display="inline" id="math86-0272989X12461855">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mtext>logit</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> as a function of <italic>x<sub>i</sub></italic> and (<italic>f<sub>2i</sub></italic>–<italic>f<sub>1i</sub></italic>).</p>
</sec>
<sec id="section14-0272989X12461855" sec-type="results">
<title>Results</title>
<sec id="section15-0272989X12461855">
<title>Model Fit</title>
<p>The full proposed model, DIC = 8130.2 (all variance components), is much smaller than the alternative model, DIC = 11310.1 (some variance components set to 0). Call <italic>Rn</italic> the sample correlation matrix from the observed indicators—that is, correlation matrix from exp (<italic>Y<sub>11</sub></italic>), <italic>Y<sub>21</sub>, Y<sub>31</sub></italic>/<italic>w<sub>1</sub>, Y<sub>41</sub></italic>/<italic>n<sub>1</sub></italic> in <xref ref-type="table" rid="table1-0272989X12461855">Table 1</xref>—and <italic>Rp</italic> and <italic>RpA</italic>, posterior predictive correlations (one iteration each) from full model and alternative, respectively, which comes from posterior predictive data from the respective models. The mean absolute error (MAE) was calculated as <inline-formula id="inline-formula85-0272989X12461855">
<mml:math display="inline" id="math87-0272989X12461855">
<mml:mrow>
<mml:mi>MA</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>np</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>R</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mi>R</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">/</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>−</mml:mo>
<mml:mn>8</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula86-0272989X12461855">
<mml:math display="inline" id="math88-0272989X12461855">
<mml:mrow>
<mml:mi>MA</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>npA</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>R</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mi>Rp</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">/</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>−</mml:mo>
<mml:mn>8</mml:mn>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, respectively. As with the DIC, the full proposed model’s MAE was lower than the alternative model’s (<italic>MAE<sub>np</sub></italic> = 0.05 and <italic>MAE<sub>npA</sub></italic> = 0.22). The fit analysis clearly indicates that modeling the extra variance components is well worth the effort.</p>
</sec>
<sec id="section16-0272989X12461855">
<title>Estimation of Full Model Parameters: Univariate and Multivariate</title>
<p>The model’s intercepts (<italic>a</italic>’s) across indicators have median values and intervals—after appropriate back-transformation to the original scale of quality indicators (<xref ref-type="table" rid="table2-0272989X12461855">Table 2</xref>)—that either cover or are close to covering the mean observed values (<xref ref-type="table" rid="table1-0272989X12461855">Table 1</xref>). This indicates a reasonable fit and is an appropriate comparison since the median value of <inline-formula id="inline-formula87-0272989X12461855">
<mml:math display="inline" id="math89-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>it</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ji</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula88-0272989X12461855">
<mml:math display="inline" id="math90-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
<p>Regarding the relationship between indicators and quality, all slopes (<italic>b</italic>) are significant since the posterior probability that the slopes are bigger than 0 is greater or less than 0.95; <italic>Pr</italic> (<italic>b</italic> &gt; 0) &gt; .95, (TNHPPD and JE) or <italic>Pr</italic> (<italic>b</italic> &lt; 0) &gt; .95 (fall and PrU rates). Taking the ratio of posterior mean and standard deviation indicates the relative absolute strength of the association between quality and JE (|<italic>Z</italic>| = 7.6), PrU rates (|<italic>Z</italic>| = 7.1), fall rates (|<italic>Z</italic>| = 5.5), and TNHPPD (|<italic>Z</italic>| = 2.6). Thus JE and PrU rates are the most influential factors for the empirical definition of quality in nursing units.</p>
<p>The temporal associations across time are all significant (<inline-formula id="inline-formula89-0272989X12461855">
<mml:math display="inline" id="math91-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:mtext>and</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>), as indicated in the analysis of the alternative model in the Model Fit section. The correlation across time for the quality variable runs from small to large since its 95% credible interval is .14 to .65, indicating a clear need for adjustment for regression to the mean.</p>
</sec>
<sec id="section17-0272989X12461855">
<title>Multivariate Profiling: Testing Improvement or Decline</title>
<p>As theory dictates, <inline-formula id="inline-formula90-0272989X12461855">
<mml:math display="inline" id="math92-0272989X12461855">
<mml:mrow>
<mml:mi>corr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> = −0.23, which is much closer to 0 than <inline-formula id="inline-formula91-0272989X12461855">
<mml:math display="inline" id="math93-0272989X12461855">
<mml:mrow>
<mml:mi>corr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> = −0.67, where <inline-formula id="inline-formula92-0272989X12461855">
<mml:math display="inline" id="math94-0272989X12461855">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, thereby illustrating advantage of <italic>Z</italic>* over <italic>Z</italic>; thus, the regression adjustment is an improvement. <xref ref-type="fig" rid="fig3-0272989X12461855">Figure 3</xref> shows the unit (call it unit A) with the largest adjusted increase in quality (<italic>P</italic> = 0.0195) from 2006 to 2007. Depicted in the plot is the predicted regression up toward mean quality (0); what is subtracted is this value from the estimated quality at 2007.</p>
<fig id="fig3-0272989X12461855" position="float">
<label>Figure 3</label>
<caption><p>Multivariate “quality” demonstrating the effect of baseline deviation from the mean on the adjusted change for nursing units A (improving) and B (declining).</p></caption>
<graphic xlink:href="10.1177_0272989X12461855-fig3.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig3-0272989X12461855">Figure 3</xref> additionally shows the unit (call it unit B) with the largest adjusted decrease in quality (<italic>P</italic> = 0.0644) from 2006 to 2007. Also depicted in the plot is the predicted regression down toward mean quality (0).</p>
</sec>
<sec id="section18-0272989X12461855">
<title>Simulation</title>
<p><xref ref-type="table" rid="table3-0272989X12461855">Table 3</xref> indicates that for all of the parameters except one (<italic>a<sub>3</sub></italic>), the 95% credible intervals cover the true parameter. This suggests “proof of concept” for our approach. Details regarding the estimates for quality also have promising properties. First, as theory dictates, <inline-formula id="inline-formula93-0272989X12461855">
<mml:math display="inline" id="math95-0272989X12461855">
<mml:mrow>
<mml:mi>corr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> = −0.11, which is much closer to 0 than <inline-formula id="inline-formula94-0272989X12461855">
<mml:math display="inline" id="math96-0272989X12461855">
<mml:mrow>
<mml:mi>corr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> = −0.55, where <inline-formula id="inline-formula95-0272989X12461855">
<mml:math display="inline" id="math97-0272989X12461855">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, thereby illustrating advantage of <italic>Z</italic>* over <italic>Z</italic>. Second, there were 0 values of <italic>Pr<sub>i</sub></italic> larger than 0.95 and 1 value smaller than 0.05 (<italic>Pr<sub>i</sub></italic> = 0.0383). Since the simulation came from no change, this last value is considered a false positive.</p>
<table-wrap id="table3-0272989X12461855" position="float">
<label>Table 3</label>
<caption><p>Posterior Distribution Summaries for Parameters From Multivariate Model of Simulated Medical–Surgical Units</p></caption>
<graphic alternate-form-of="table3-0272989X12461855" xlink:href="10.1177_0272989X12461855-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="center">Truth</th>
<th align="center">2.50%</th>
<th align="center">Mdn</th>
<th align="center">97.50%</th>
</tr>
</thead>
<tbody>
<tr>
<td><italic>a</italic><sub><italic>1</italic></sub></td>
<td>2.105+</td>
<td>2.103</td>
<td>2.133</td>
<td>2.163</td>
</tr>
<tr>
<td><italic>a</italic><sub><italic>2</italic></sub></td>
<td>3.532+</td>
<td>3.477</td>
<td>3.562</td>
<td>3.655</td>
</tr>
<tr>
<td><italic>a</italic><sub><italic>3</italic></sub></td>
<td>1.335–</td>
<td>1.180</td>
<td>1.252</td>
<td>1.332</td>
</tr>
<tr>
<td><italic>a</italic><sub><italic>4</italic></sub></td>
<td>−3.035+</td>
<td>−3.263</td>
<td>−3.082</td>
<td>−2.905</td>
</tr>
<tr>
<td><italic>b</italic><sub>1</sub></td>
<td>0.016+</td>
<td>−0.001</td>
<td>0.020</td>
<td>0.043</td>
</tr>
<tr>
<td><italic>b</italic><sub>2</sub></td>
<td>0.239+</td>
<td>0.209</td>
<td>0.303</td>
<td>0.399</td>
</tr>
<tr>
<td><italic>b</italic><sub>3</sub></td>
<td>−0.127+</td>
<td>−0.245</td>
<td>−0.178</td>
<td>−0.120</td>
</tr>
<tr>
<td><italic>b</italic><sub>4</sub></td>
<td>−0.366+</td>
<td>−0.583</td>
<td>−0.397</td>
<td>−0.233</td>
</tr>
<tr>
<td><inline-formula id="inline-formula96-0272989X12461855">
<mml:math display="inline" id="math98-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.003+</td>
<td>0.003</td>
<td>0.005</td>
<td>0.006</td>
</tr>
<tr>
<td><inline-formula id="inline-formula97-0272989X12461855">
<mml:math display="inline" id="math99-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.024+</td>
<td>0.014</td>
<td>0.019</td>
<td>0.027</td>
</tr>
<tr>
<td><inline-formula id="inline-formula98-0272989X12461855">
<mml:math display="inline" id="math100-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.128+</td>
<td>0.051</td>
<td>0.106</td>
<td>0.173</td>
</tr>
<tr>
<td><inline-formula id="inline-formula99-0272989X12461855">
<mml:math display="inline" id="math101-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.094+</td>
<td>0.067</td>
<td>0.100</td>
<td>0.146</td>
</tr>
<tr>
<td><inline-formula id="inline-formula100-0272989X12461855">
<mml:math display="inline" id="math102-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>4</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.374+</td>
<td>0.337</td>
<td>0.520</td>
<td>0.783</td>
</tr>
<tr>
<td><inline-formula id="inline-formula101-0272989X12461855">
<mml:math display="inline" id="math103-0272989X12461855">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>d</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>=</mml:mo><mml:mi>ρ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.426+</td>
<td>0.038</td>
<td>0.501</td>
<td>0.726</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0272989X12461855">
<p>Note: <italic>n</italic> = 100, with data from 2006 (time 1) to 2007 (time 2). +, 95% credible interval covers truth; –, does not.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The results for part 2 of the simulation are summarized in <xref ref-type="fig" rid="fig4-0272989X12461855">Figure 4</xref>: the inverse logit of the expected value from the multiple regression, <inline-formula id="inline-formula102-0272989X12461855">
<mml:math display="inline" id="math104-0272989X12461855">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mtext>logit</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>B</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>. Neither regression line has a significant intercept different from 0 (<inline-formula id="inline-formula103-0272989X12461855">
<mml:math display="inline" id="math105-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> = −.37, <italic>s<sub>¯</sub></italic> = .335, <italic>P</italic> = 0.274, and <inline-formula id="inline-formula104-0272989X12461855">
<mml:math display="inline" id="math106-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> = −.032, <italic>s<sub>¯</sub></italic> = .277, <italic>P</italic> = 0.910), nor are the intercepts different from each other (<inline-formula id="inline-formula105-0272989X12461855">
<mml:math display="inline" id="math107-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> = .34, <italic>s<sub>¯</sub></italic> = .435, <italic>P</italic> = .440). However, the <italic>f<sub>1</sub></italic> = 3 slope is significantly negative (<inline-formula id="inline-formula106-0272989X12461855">
<mml:math display="inline" id="math108-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> = −1.37, <italic>s<sub>¯</sub></italic> = .108, <italic>P</italic> &lt; .001) and the <italic>f<sub>1</sub></italic> = 0 slope is significantly higher than the <italic>f<sub>1</sub></italic> = 3 slope (<inline-formula id="inline-formula107-0272989X12461855">
<mml:math display="inline" id="math109-0272989X12461855">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> = .54, <italic>s<sub>¯</sub></italic> = .143, <italic>P</italic> &lt; .001). This demonstrates that it is faster to detect significant change when a unit’s quality starts away from the mean and continues “against the grain.”</p>
<fig id="fig4-0272989X12461855" position="float">
<label>Figure 4</label>
<caption>
<p>Average <italic>P</italic> values for the <italic>n</italic> = 100 simulation study for variations in starting point (<italic>f<sub>1</sub></italic>) and difference (<italic>f<sub>2</sub></italic>–<italic>f</italic><sub><italic>1</italic></sub>). The bottom line represents <italic>P</italic> = 0.05.</p>
</caption>
<graphic xlink:href="10.1177_0272989X12461855-fig4.tif"/>
</fig>
</sec>
</sec>
<sec id="section19-0272989X12461855" sec-type="discussion|conclusions">
<title>Discussion and Conclusion</title>
<p>The NDNQI is used for monitoring indicators of nursing quality, such as TNHPPD, average registered nurse JE, fall rates, and PrU rates. From an NDNQI data repository, data are summarized and published in reports that enable nursing units to compare results of their units for each quality indicator with comparable units in other hospitals. There are 2 disadvantages to this reporting scheme. First, the sampling variability is not explicit. Second, the correlation among indicators is not reflected in the reporting. In previous work,<sup><xref ref-type="bibr" rid="bibr17-0272989X12461855">17</xref></sup> we proposed a Bayesian report card system that involved reporting credible intervals as well as smoothed point estimates for a single time point. Jones and Spiegelhalter<sup><xref ref-type="bibr" rid="bibr8-0272989X12461855">8</xref></sup> provide a methodology to adjust for regression to the mean when modeling recent changes in institutional performance for 1 variable at 2 time points. We extend this model to allow for the 4 indicators above to be correlated via a latent variable model across time while adjusting for regression to the mean. Generalizing this approach for other indicators, allowing multiple constructs, and automating the approach to handle large databases would be welcome improvements and topics suitable for future research.</p>
<p>In this article, we argue that the observed indicators are “reflective” (not “causal”) because they are measured by the latent variable <italic>quality</italic>. A classical view of quality manifesting itself as reflective of structure, process, and outcomes is conceptually attractive.</p>
<p>However, some may believe that there are theoretical reasons to question the case study model structure as specified. In the Methods: General Modeling and Data section, we argue on treating the indicators as reflective rather than causal of quality of care. However, one may disagree with our choice in treating TNHPPD as a reflective indicator of quality. We are specifically saying that improvement in the latent variable <italic>quality of care</italic> causes a change in TNHPPD. One may argue that it may be that an increase in TNHPPD would lead to an improvement in the quality (e.g., more nurses leading to fewer falls).</p>
<p>However, fall rates and PrUs seem to be clear reflective indicators. One may argue that JE is less clear than fall and PrU rates but more than TNHPPD. It seems reasonable that working on a quality unit influences JE.</p>
<p>So what is the point of this part of the discussion? Two major points:<disp-quote>
<p><italic>There are alternative models to the pure reflective approach</italic>. For example, a model with TNHPPD as a causal indicator and the others as reflective is an option to be considered. Other possible approaches include a cross-lag effect from TNHPPD at time 1 on quality at time 2. To empirically test these different models, one may want to consider performed the vanishing tetrad tests described in Bollen, Lennox, and Dahly.<sup><xref ref-type="bibr" rid="bibr9-0272989X12461855">9</xref></sup></p>
<p><italic>Alternative models may lead to new approaches to adjusting for regression to the mean</italic>. If a model is a mix of causal and reflective indicators, then we would need to slightly adjust the overall approach that we present. A major strength of this article is that we considered the reflective model with 4 variables and demonstrated it with a case study and simulation. At the same time, a major limitation of the current work is that we did not develop the methodology for other types of composite indicators. This, too, is a topic for future research. Further reading on the issue of causal and reflective can be found in Fayers et al.<sup><xref ref-type="bibr" rid="bibr24-0272989X12461855">24</xref></sup> as well as Bollen.<sup><xref ref-type="bibr" rid="bibr25-0272989X12461855">25</xref></sup></p>
</disp-quote></p>
<p>Recent policy indicates a need for methodology that simultaneously builds composite indicators and adjusts for regression to the mean. Our approach addresses this for reflective models and can be applied very generally to perform performance measurement. After careful composite indicator development and decisions, the methodology can be used now.</p>
</sec>
</body>
<back>
<ack>
<p>We thank the editor, the associate editor, and the reviewers for comments that greatly improved our article. Specifically, one reviewer’s comments improved focus; the second provided valuable detailed corrections to notation and text; and the third contributed greatly to the conceptualization of choosing reflective variables.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure">
<p>This work was supported in part by the National Database of Nursing Quality Indicators<sup>®</sup> (NDNQI<sup>®</sup>), from a contract with the American Nurses Association<sup>®</sup> and Frontiers: The Heartland Institute for Clinical and Translational Research CTSA UL1RR033179 which is now UL1TR000001 (BJG). The contents are solely the responsible of the authors and do not necessarily represent the official views of the NIH and ANA.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0272989X12461855">
<label>1.</label>
<citation citation-type="book">
<collab>Institute of Medicine</collab>. <article-title>To Err Is Human: Building a Safer Health System</article-title>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academies Press</publisher-name>; <year>2001</year>.</citation>
</ref>
<ref id="bibr2-0272989X12461855">
<label>2.</label>
<citation citation-type="book">
<collab>Institute of Medicine</collab>. <article-title>Keeping Patients Safe: Transforming the Work Environment of Nurses</article-title>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academies Press</publisher-name>; <year>2004</year>.</citation>
</ref>
<ref id="bibr3-0272989X12461855">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shwartz</surname><given-names>M</given-names></name>
<name><surname>Burgess</surname><given-names>JF</given-names></name>
<name><surname>Berlowitz</surname><given-names>D</given-names></name>
</person-group>. <article-title>Benefit-of-the-doubt approaches for calculating a composite measure of quality</article-title>. <source>Health Serv Outcomes Res Methodol</source>. <year>2009</year>;<volume>9</volume>:<fpage>234</fpage>–<lpage>51</lpage>.</citation>
</ref>
<ref id="bibr4-0272989X12461855">
<label>4.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Landrum</surname><given-names>MB</given-names></name>
<name><surname>Normand</surname><given-names>SLT</given-names></name>
<name><surname>Rosenheck</surname><given-names>RA</given-names></name>
</person-group>. <article-title>Selection of related multivariate means: monitoring psychiatric care in the Department of Veterans Affairs</article-title>. <source>J Am Stat Assoc</source>. <year>2003</year>;<volume>98</volume>(<issue>461</issue>):<fpage>7</fpage>–<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr5-0272989X12461855">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Teixeira-Pinto</surname><given-names>A</given-names></name>
<name><surname>Normand</surname><given-names>SLT</given-names></name>
</person-group>. <article-title>Statistical methodology for classifying units on the basis of multiple-related measures</article-title>. <source>Stat Med</source>. <year>2008</year>;<volume>27</volume>:<fpage>1329</fpage>–<lpage>1350</lpage>.</citation>
</ref>
<ref id="bibr6-0272989X12461855">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>TT</given-names></name>
<name><surname>Lai</surname><given-names>MS</given-names></name>
<name><surname>Lin</surname><given-names>IC</given-names></name>
<name><surname>Chung</surname><given-names>KP</given-names></name>
</person-group>. <article-title>Exploring and comparing the characteristics of nonlatent and latent composite scores: implications for pay-for-performance incentive design</article-title>. <source>Med Decis Making</source>. <year>2012</year>;<volume>32</volume>:<fpage>132</fpage>–<lpage>144</lpage>.</citation>
</ref>
<ref id="bibr7-0272989X12461855">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Daniels</surname><given-names>MJ</given-names></name>
<name><surname>Normand</surname><given-names>SLT</given-names></name>
</person-group>. <article-title>Longitudinal profiling of health care units based on continuous and discrete patient outcomes</article-title>. <source>Biostatistics</source>. <year>2006</year>;<volume>7</volume>:<fpage>1</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr8-0272989X12461855">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jones</surname><given-names>HE</given-names></name>
<name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name>
</person-group>. <article-title>Accounting for regression-to-the-mean in tests for recent changes in institutional performance: analysis and power</article-title>. <source>Stat Med</source>. <year>2009</year>;<volume>28</volume>:<fpage>1645</fpage>–<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr9-0272989X12461855">
<label>9.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bollen</surname><given-names>KA</given-names></name>
<name><surname>Lennox</surname><given-names>RD</given-names></name>
<name><surname>Dahly</surname><given-names>DL</given-names></name>
</person-group>. <article-title>Practical application of the vanishing tetrad test for causal indicator measurement models: an example from health-related quality of life</article-title>. <source>Stat Med</source>. <year>2009</year>;<volume>28</volume>:<fpage>1524</fpage>–<lpage>36</lpage>.</citation>
</ref>
<ref id="bibr10-0272989X12461855">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cai</surname><given-names>JH</given-names></name>
<name><surname>Song</surname><given-names>XY</given-names></name>
<name><surname>Hser</surname><given-names>YI</given-names></name>
</person-group>. <article-title>A Bayesian analysis of mixture structural equation models with non-ignorable missing responses and covariates</article-title>. <source>Stat Med</source>. <year>2010</year>;<volume>29</volume>:<fpage>1861</fpage>–<lpage>74</lpage>.</citation>
</ref>
<ref id="bibr11-0272989X12461855">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Donabedian</surname><given-names>A</given-names></name>
</person-group>. <article-title>The quality of care: how can it be assessed?</article-title> <source>J Am Med Assoc</source>. <year>1988</year>;<volume>260</volume>:<fpage>1743</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr12-0272989X12461855">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hart</surname><given-names>S</given-names></name>
<name><surname>Bergquist</surname><given-names>S</given-names></name>
<name><surname>Gajewski</surname><given-names>B</given-names></name>
<name><surname>Dunton</surname><given-names>N</given-names></name>
</person-group>. <article-title>Reliability testing of the National Database of Nursing Quality Indicator’s pressure ulcer indicator</article-title>. <source>J Nurs Care Qual</source>. <year>2006</year>;<volume>21</volume>:<fpage>256</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr13-0272989X12461855">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gajewski</surname><given-names>BJ</given-names></name>
<name><surname>Hart</surname><given-names>S</given-names></name>
<name><surname>Bergquist</surname><given-names>S</given-names></name>
<name><surname>Dunton</surname><given-names>N</given-names></name>
</person-group>. <article-title>Inter-rater reliability of pressure ulcer staging: ordinal probit Bayesian hierarchical model that allows for uncertain rater response</article-title>. <source>Stat Med</source>. <year>2007</year>;<volume>26</volume>:<fpage>4602</fpage>–<lpage>18</lpage>.</citation>
</ref>
<ref id="bibr14-0272989X12461855">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gajewski</surname><given-names>BJ</given-names></name>
<name><surname>Boyle</surname><given-names>DK</given-names></name>
<name><surname>Miller</surname><given-names>P</given-names></name>
<name><surname>Oberhelman</surname><given-names>F</given-names></name>
<name><surname>Dunton</surname><given-names>N</given-names></name>
</person-group>. <article-title>A multilevel confirmatory factor analysis of the practice environment scale (PES): a case study</article-title>. <source>Nurs Res</source>. <year>2010</year>;<volume>59</volume>:<fpage>147</fpage>–<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr15-0272989X12461855">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>M</given-names></name>
<name><surname>Yankovskyy</surname><given-names>E</given-names></name>
<name><surname>Klaus</surname><given-names>S</given-names></name>
<name><surname>Gajewski</surname><given-names>B</given-names></name>
<name><surname>Dunton</surname><given-names>N</given-names></name>
</person-group>. <article-title>Midnight census revisited: reliability of patient day measurement and its impact on nursing quality indicators</article-title>. <source>Int J Nurs Stud.</source> <year>2012</year>;<volume>48</volume>(<issue>1</issue>):<fpage>56</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr16-0272989X12461855">
<label>16.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>M</given-names></name>
<name><surname>Klaus</surname><given-names>S</given-names></name>
<name><surname>Gajewski</surname><given-names>B</given-names></name>
<name><surname>Dunton</surname><given-names>N</given-names></name>
</person-group>. <article-title>Falls Reliability Study</article-title>. In preparation.</citation>
</ref>
<ref id="bibr17-0272989X12461855">
<label>17.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gajewski</surname><given-names>BJ</given-names></name>
<name><surname>Mahnken</surname><given-names>JD</given-names></name>
<name><surname>Dunton</surname><given-names>N</given-names></name>
</person-group>. <article-title>Improving quality indicator report cards through Bayesian modeling</article-title>. <source>BMC Med Res Methodol</source>. <year>2008</year>;<volume>8</volume>:<fpage>77</fpage>.</citation>
</ref>
<ref id="bibr18-0272989X12461855">
<label>18.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kuehl</surname><given-names>RO</given-names></name>
</person-group>. <article-title>Statistical Principles of Research Design and Analysis</article-title>. <publisher-loc>Belmont, CA</publisher-loc>: <publisher-name>Duxbury Press</publisher-name>; <year>1994</year>.</citation>
</ref>
<ref id="bibr19-0272989X12461855">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Morton</surname><given-names>V</given-names></name>
<name><surname>Torgerson</surname><given-names>DJ</given-names></name>
</person-group>. <article-title>Effect of regression to the mean on decision making in health care</article-title>. <source>Br Med J</source>. <year>2003</year>;<volume>326</volume>:<fpage>1083</fpage>–<lpage>4</lpage>.</citation>
</ref>
<ref id="bibr20-0272989X12461855">
<label>20.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Skrondal</surname><given-names>A</given-names></name>
<name><surname>Rabe-Hesketh</surname><given-names>S</given-names></name>
</person-group>. <article-title>Generalized Latent Variable Modeling: Multilevel, Longitudinal, and Structural Equation Models</article-title>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Chapman &amp; Hall/CRC;</publisher-name> <year>2004</year>.</citation>
</ref>
<ref id="bibr21-0272989X12461855">
<label>21.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilks</surname><given-names>WR</given-names></name>
<name><surname>Thomas</surname><given-names>A</given-names></name>
<name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name>
</person-group>. <article-title>A language and program for complex Bayesian modelling</article-title>. <source>Statistician</source>. <year>1994</year>;<volume>43</volume>:<fpage>169</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr22-0272989X12461855">
<label>22.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gelman</surname><given-names>A</given-names></name>
</person-group>. <article-title>Prior distributions for variance parameters in hierarchical models</article-title>. <source>Bayesian Anal</source>. <year>2006</year>;<volume>1</volume>:<fpage>515</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr23-0272989X12461855">
<label>23.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name>
<name><surname>Best</surname><given-names>NG</given-names></name>
<name><surname>Carlin</surname><given-names>BP</given-names></name>
<name><surname>van der Linde</surname><given-names>A</given-names></name>
</person-group>. <article-title>Bayesian measures of model complexity and fit</article-title>. <source>J Royal Stat Soc B</source>. <year>2002</year>;<volume>64</volume>:<fpage>583</fpage>–<lpage>640</lpage>.</citation>
</ref>
<ref id="bibr24-0272989X12461855">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fayers</surname><given-names>PM</given-names></name>
<name><surname>Hand</surname><given-names>DJ</given-names></name>
<name><surname>Bjordal</surname><given-names>K</given-names></name>
<name><surname>Groenvold</surname><given-names>M</given-names></name>
</person-group>. <article-title>Causal indicators in quality of life research</article-title>. <source>Qual Life Res</source>. <year>1997</year>;<volume>6</volume>:<fpage>393</fpage>–<lpage>406</lpage>.</citation>
</ref>
<ref id="bibr25-0272989X12461855">
<label>25.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bollen</surname><given-names>KA</given-names></name>
</person-group>. <article-title>Evaluating effect, composite, and causal indicators in structural equation models</article-title>. <source>MIS Quart</source>. <year>2011</year>;<volume>35</volume>:<fpage>359</fpage>–<lpage>72</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>