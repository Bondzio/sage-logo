<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JVC</journal-id>
<journal-id journal-id-type="hwp">spjvc</journal-id>
<journal-title>Journal of Vibration and Control</journal-title>
<issn pub-type="ppub">1077-5463</issn>
<issn pub-type="epub">1741-2986</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1077546310395966</article-id>
<article-id pub-id-type="publisher-id">10.1177_1077546310395966</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Single channel surface electromyography blind recognition model based on watermarking</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Yina</surname><given-names>Guo</given-names></name>
<xref ref-type="aff" rid="aff1-1077546310395966">1</xref>
<xref ref-type="corresp" rid="corresp1-1077546310395966"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Dawei</surname><given-names>Zhou</given-names></name>
<xref ref-type="aff" rid="aff2-1077546310395966">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-1077546310395966"><label>1</label>Department of Electronic and Communication, Taiyuan University of Science and Technology, People’s Republic of China</aff>
<aff id="aff2-1077546310395966"><label>2</label>Department of Electronic Engineering, Naval University of Engineering, People’s Republic of China</aff>
<author-notes>
<corresp id="corresp1-1077546310395966">Guo Yina, Department of Electronic and Communication, Taiyuan University of Science and Technology, ShanXi Taiyuan 030024, People’s Republic of China Email: <email>zulibest@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>18</volume>
<issue>1</issue>
<fpage>42</fpage>
<lpage>47</lpage>
<history>
<date date-type="received"><day>24</day><month>3</month><year>2010</year></date>
<date date-type="accepted"><day>6</day><month>10</month><year>2010</year></date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2011 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>A single channel electromyography blind recognition model based on watermarking is proposed in this paper. Single Channel Independent Component Analysis is adopted to avoid complicated circuit connection and the unreliability of hardware and reduce the noise which accompanied with surface Electromyography (sEMG) signals. Embedded watermarking is applied to solve the problem of blind source separation disorder. A self adaptive neural network and some eigenvectors are applied in sEMG features classification. From the classification results, hand gestures can be recognized. In consideration of time-scale synchronization attack, the host sEMG signals are transformed into wavelet domain and the synchronization codes are embedded. The experiment results show that the model proposed in this paper is penetrable against most common signal processing, and can recognize the hand gesture accurately.</p>
</abstract>
<kwd-group>
<kwd>Discrete Wavelet Transform (DWT)</kwd>
<kwd>surface Electromyography (sEMG)</kwd>
<kwd>Independent Component Analysis (ICA)</kwd>
<kwd>pattern recognition</kwd>
<kwd>watermarking</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="sec1-1077546310395966" sec-type="intro"><title>1. Introduction</title>
<p>A sign language is a language which uses visually transmitted sign patterns (manual communication, body language and lip patterns) to convey meaning - simultaneously combining hand shapes, orientation and movement of the hands, arms or body, and facial expressions to fluidly express a speaker’s thoughts. Recently, the sign language as an important interaction method of body languages is paid attention by many scientists from all over the world. From the recognition signals, the recognition methods of the sign language are mainly divided into hand gesture signal and surface Electromyography (sEMG) signal. In 2008, Ganesh N. Naik, Dinesh K. Kumar and Sridhar P. Arjunan of RMIT University proposed a multi run Independent Component Analysis (ICA) and sEMG based signal processing system for recognizing hand gestures. This method improved the offline hand gesture recognizing rate to 99% (<xref ref-type="bibr" rid="bibr6-1077546310395966">Hyvärinen et al., 2001</xref>; <xref ref-type="bibr" rid="bibr10-1077546310395966">Naik et al., 2008</xref>). However, the separated signals of Blind Source Separation (BSS) based ICA are in disorder and not available for online hand gesture recognition. It is therefore imperative to have good methods to explore a more suitable online choice, which can avoid the problems mentioned above as much as possible.</p>
<p>A single channel sEMG blind recognition model based on watermarking theory is proposed in this paper. With a view to avoiding complicated circuit connection and unreliability of hardware and reducing the noises which are accompanied with sEMG, Single Channel Independent Component Analysis (SCICA) is adopted in the model. In consideration of solving the disorder problem of BSS, embedded watermarking which is produced by a semi-fragile watermarking scheme and Arnold transform, are embedded in sEMG. In view of the time scale synchronization attack, the host sEMG is transformed into a wavelet domain and the synchronization codes are embedded in the host sEMG. The experiment results show that the single channel sEMG blind recognition model proposed in this paper is transparent against most common signal processing, and can recognize the hand gesture accurately.</p>
</sec>
<sec id="sec2-1077546310395966"><title>2. The model structure</title>
<p>As shown in <xref ref-type="fig" rid="fig1-1077546310395966">Figure 1</xref> below, the binary de-dimension watermarking images, which are produced by semi-fragile watermarking scheme and Arnold transform, are embedded in sEMG by Discrete Wavelet Transform (DWT).</p>
<p>The secret sEMG signals are a convolution mixed by linear matrix. The mixed signals are separated into three channel signals by applying SCICA.</p>
<p>The separated secret sEMG signals are arranged in order by using secret key watermarking. The eigenvectors of the ordered sEMG signals are calculated. Some of the eigenvectors are adopted to train a self-adaptive neural network and the other eigenvectors are applied in an online test of recognition (<xref ref-type="bibr" rid="bibr5-1077546310395966">Guo and Li, 2011</xref>).
<fig id="fig1-1077546310395966" position="float"><label>Figure 1.</label><caption><p>Structure of model.</p></caption><graphic xlink:href="10.1177_1077546310395966-fig1.tif"/></fig></p></sec>
<sec id="sec3-1077546310395966"><title>3. Generation of encryption semg signals</title>
<p>In this part, three encryption sEMG signals are generated by DWT, Inverse Discrete Wavelet Transform (IDWT) and the watermarking scheme (<xref ref-type="bibr" rid="bibr8-1077546310395966">Luo and Li, 2009</xref>; <xref ref-type="bibr" rid="bibr9-1077546310395966">Ma and Sun, 2008</xref>).</p>
<p><xref ref-type="fig" rid="fig2-1077546310395966">Figure 2</xref> describes one encryption sEMG signal generation progress as an example. The generation progresses of the other two encryption sEMG signals are similar.
<fig id="fig2-1077546310395966" position="float"><label>Figure 2.</label><caption><p>Generation of one encryption sEMG signal.</p></caption><graphic xlink:href="10.1177_1077546310395966-fig2.tif"/></fig></p>
<sec id="sec4-1077546310395966"><title>3.1. Generation of watermarking signals</title>
<p>With a view to removing the pixel correlation of binary watermarking images, enhancing the security of watermarking and insuring the recovery of watermarking signals when they are attacked, Arnold transform is adopted in accordance with the semi-fragile watermarking scheme (<xref ref-type="bibr" rid="bibr13-1077546310395966">Tian and Wang, 2007</xref>).</p>
<p>The original watermarking images are binary images. The binary image pixel value at pixel location (<italic>i, j</italic>) is defined by
<disp-formula id="disp-formula1-1077546310395966"><label>(1)</label><graphic xlink:href="10.1177_1077546310395966-eq1.tif"/></disp-formula>
</p>
<p>The binary watermarking image <italic>W</italic> is scrambling encrypted to safe watermarking matrix <italic>W</italic>1. The scrambling encryption binary image pixel value at pixel location (<italic>i, j</italic>) is defined by <xref ref-type="bibr" rid="bibr9-1077546310395966">Ma and Sun (2008)</xref> and <xref ref-type="bibr" rid="bibr7-1077546310395966">Lie and Li (2006)</xref>.
<disp-formula id="disp-formula2-1077546310395966"><label>(2)</label><graphic xlink:href="10.1177_1077546310395966-eq2.tif"/></disp-formula>
</p>
</sec>
<sec id="sec5-1077546310395966"><title>3.2. Embedment of watermarking signals</title>
<p>In order to embed three watermarking signals to three sEMG signals respectively, three sEMG signals are transformed by DWT. In <xref ref-type="fig" rid="fig3-1077546310395966">Figure 3</xref>, one sEMG signal is applied as an example to transform by DWT. The transform progresses of the other two sEMG signals are similar.
<fig id="fig3-1077546310395966" position="float"><label>Figure 3.</label><caption><p>DWT of one sEMG signal.</p></caption><graphic xlink:href="10.1177_1077546310395966-fig3.tif"/></fig></p>
<p><xref ref-type="fig" rid="fig3-1077546310395966">Figure 3</xref> depicts it clearly that one sEMG signal <italic>S</italic><sub>1</sub> is transformed by three level wavelet transform. The wavelet coefficients <inline-formula id="ilm1-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math1-1077546310395966"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> are obtained. The wavelet coefficient <inline-formula id="ilm2-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math2-1077546310395966"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the three level approach component of the sEMG signal <italic>S</italic><sub>1</sub>. The wavelet coefficients <inline-formula id="ilm3-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math3-1077546310395966"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> are the precise components for one to three level of the sEMG signal <italic>S</italic><sub>1</sub>.</p>
<p>In <xref ref-type="fig" rid="fig2-1077546310395966">Figure 2</xref>, for the sake of precise location of watermarking, one short segment of synchronized code is embedded in the transformed sEMG signal.</p>
<p>Then the watermarking signal is embedded by adaptive coefficients. The embedded progress of m array example is defined by
<disp-formula id="disp-formula3-1077546310395966"><label>(3)</label><graphic xlink:href="10.1177_1077546310395966-eq3.tif"/></disp-formula>
</p>
<p>In <xref ref-type="disp-formula" rid="disp-formula3-1077546310395966">equation (3)</xref>, {<italic>c</italic><sub><italic>n</italic></sub>} is three level wavelet coefficients and {<italic>m</italic><sub><italic>n</italic></sub>} is m array. <inline-formula id="ilm4-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math4-1077546310395966"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:msup><mml:mi>c</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the approach component whose embedded synchronized code and <italic>α</italic> is nonzero. When the synchronized code is embedded, the coefficient which has the maximum absolute value of thereafter coefficients is selected to construct a signal <italic>s</italic>. Watermarking signal <italic>w</italic> and the signal <italic>s</italic> are linear mixed. The mixed progress is realized by
<disp-formula id="disp-formula4-1077546310395966"><label>(4)</label><graphic xlink:href="10.1177_1077546310395966-eq4.tif"/></disp-formula>
</p>
<p><italic>A</italic><sub>2</sub> is a full rank matrix. In consideration of signal penetrability, coefficients need to satisfy <inline-formula id="ilm5-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math5-1077546310395966"><mml:mrow><mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="ilm6-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math6-1077546310395966"><mml:mrow><mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. In the two output signals, <italic>sw</italic><sub>1</sub> is applied to instead of the embedded coefficient. After IDWT of <italic>sw</italic><sub>1</sub>, encryption signal <inline-formula id="ilm7-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math7-1077546310395966"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is achieved. <italic>sw</italic><sub>2</sub> is saved as the secret key <bold>K</bold><sub>1</sub>.</p>
</sec>
<sec id="sec6-1077546310395966"><title>3.3. Generation of single channel signal</title>
<p>The encryption signals <inline-formula id="ilm8-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math8-1077546310395966"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> which are transformed by IDWT are linear mixed into one channel signal <italic>x(t)</italic>. <xref ref-type="disp-formula" rid="disp-formula5-1077546310395966">Equation (5)</xref> displays the mixed progress.
<disp-formula id="disp-formula5-1077546310395966"><label>(5)</label><graphic xlink:href="10.1177_1077546310395966-eq5.tif"/></disp-formula>
</p>
<p>In <xref ref-type="disp-formula" rid="disp-formula5-1077546310395966">equation (5)</xref>, <italic>x</italic>(t) ∈ <italic>R</italic><sup><italic>N</italic></sup> and <italic>x = [x(t), x(t - 1),…, x(t - N + 1)]<sup>T</sup></italic>. x is the single channel mixed signal. <italic>A = [a<sub>1</sub>(t) a<sub>2</sub>(t) a<sub>3</sub>(t)]</italic> depicts the mixed matrix.</p>
</sec>
</sec>
<sec id="sec7-1077546310395966"><title>4. Recognition of encryption semg signals</title>
<sec id="sec8-1077546310395966"><title>4.1. Separation of single channel BSS</title>
<p>The blind source separation of encryption sEMG signals is taking advantage of SCICA. The separation progress is described as <xref ref-type="disp-formula" rid="disp-formula6-1077546310395966">equation (6)</xref>.
<disp-formula id="disp-formula6-1077546310395966"><label>(6)</label><graphic xlink:href="10.1177_1077546310395966-eq6.tif"/> </disp-formula>
</p>
<p><inline-formula id="ilm9-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math9-1077546310395966"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is the <italic>j</italic>th separated source signal. The <xref ref-type="disp-formula" rid="disp-formula6-1077546310395966">equation 6</xref> is expanded to free aliasing situation (<xref ref-type="disp-formula" rid="disp-formula7-1077546310395966">equation (7)</xref>) (<xref ref-type="bibr" rid="bibr3-1077546310395966">Davies and James, 2007</xref>).</p>
<p><disp-formula id="disp-formula7-1077546310395966"><label>(7)</label><graphic xlink:href="10.1177_1077546310395966-eq7.tif"/></disp-formula>
</p>
<p>According to integral shift invariant, each segments of the <italic>j</italic>th separated source signal are evaluated by cycle-spinning. Then the separated signal <inline-formula id="ilm10-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math10-1077546310395966"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is attained as shown in <xref ref-type="disp-formula" rid="disp-formula8-1077546310395966">equation (8)</xref> (<xref ref-type="bibr" rid="bibr4-1077546310395966">Guo, 2010</xref>).
<disp-formula id="disp-formula8-1077546310395966"><label>(8)</label><graphic xlink:href="10.1177_1077546310395966-eq8.tif"/></disp-formula>
</p>
</sec>
<sec id="sec9-1077546310395966"><title>4.2. Extraction of encryption sEMG signals</title>
<p>The extraction of encryption sEMG signals is the inverse progress of embedment of encryption sEMG signals. <xref ref-type="fig" rid="fig4-1077546310395966">Figure 4</xref> describes the extraction progress of one encryption sEMG signal. The extraction progresses of the other two encryption sEMG signals are similar.
<fig id="fig4-1077546310395966" position="float"><label>Figure 4.</label><caption><p>Extraction of one encryption sEMG signal.</p></caption><graphic xlink:href="10.1177_1077546310395966-fig4.tif"/></fig></p>
<p>In <xref ref-type="fig" rid="fig4-1077546310395966">Figure 4</xref>, one encryption sEMG signal <inline-formula id="ilm11-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math11-1077546310395966"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>1</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is transformed by three level wavelet transform. The wavelet coefficients <inline-formula id="ilm12-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math12-1077546310395966"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mrow><mml:mo>∗</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>∗</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>∗</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>D</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>∗</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are obtained. The synchronized codes are affirmed by applying the binary method to the approach component. The observed signal is constructed by saved secret keys <italic>K</italic><sub>1</sub>, <italic>K</italic><sub>2</sub>, <italic>K</italic><sub>3</sub> and coefficient vector <italic>sŵ</italic><sub>1</sub> which has watermarking information in terms of the inverse order of embedment order respectively. The observed signal <inline-formula id="ilm13-1077546310395966"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math13-1077546310395966"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>∗</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is ascertained order by comparing the three different secret keys and watermarking signals. <xref ref-type="fig" rid="fig4-1077546310395966">Figure 4</xref> shows an example. The output sEMG signal is not the original order and becomes the second needed sEMG signal <italic>Ŝ</italic><sub>2</sub>.</p>
</sec>
<sec id="sec10-1077546310395966"><title>4.3. Recognition of sEMG signals</title>
<p>The RMS of sEMG signals in 4.2 results is calculated. 80% of the RMS is used to train the self-adaptive neural network. 20% of the RMS is examined in online test. The self-adaptive neural network is an adaptive system that changes its structure based on layers, weights and information that flows through the network during the training phase.</p>
<p>The sEMG recognition model can be represented through an Artificial Neural Network (ANN) formulation:
<disp-formula id="disp-formula9-1077546310395966"><label>(9)</label><graphic xlink:href="10.1177_1077546310395966-eq9.tif"/></disp-formula>
</p>
<p><italic>ζ</italic><sub><italic>i</italic></sub> is the state probability for the ith state. (1 ≤ <italic>i</italic> ≤ <italic>N</italic>, <italic>N</italic> is the number of states in the model), <italic>f</italic>() is a non-linear function, wij represents the effect of the jth state on the ith state (1 ≤ <italic>i</italic>, <italic>j</italic> ≤<italic>N</italic>), <italic>τ</italic> is the time constant, <italic>β</italic> is the bias term, and <italic>λ</italic> is the decay rate parameter. A negative value of <italic>w</italic><sub><italic>ij</italic></sub> represents the inhibition of the <italic>j</italic>th state on the ith state, whereas a positive value indicates the activation controls. When <italic>w<sub>ij</sub></italic> is zero, there is no influence of the <italic>j</italic>th state on the expression change of the <italic>i</italic>th state. The effects of other factors can be added into the formula based on the specific situation.</p>
<p>When the self-adaptive neural network has trained, the RMS of tested signals can be classified. Then the different hand gestures are recognized by the self-adaptive neural network.</p>
</sec>
</sec>
<sec id="sec11-1077546310395966" sec-type="results"><title>5. Test result</title>
<p>Four volunteers participated in the experiments. Each participant tested one kind of flexion five times. Electrodes were placed on the forearm muscles of Brachioradialis, Flexor Carpi Radialis (FCR) and Flexor Digitorum Superficialis (FDS) (<xref ref-type="bibr" rid="bibr10-1077546310395966">Naik et al., 2008</xref>). sEMG signals were recorded when the participant maintained specific finger flexions of middle finger flexion, all fingers flexion and so on. The flexions were performed without any resistance (<xref ref-type="bibr" rid="bibr1-1077546310395966">Arjunan et al., 2010</xref>). These flexions chosen were very convenient for, and easily reproducible by, the participant. The order of the flexions was arbitrary and each flexion was maintained for about 8–10 secs to record sEMG and the duration of each run of the experiment was about 60 secs. The model is tested from penetrability and recognition rate.</p>
<sec id="sec12-1077546310395966"><title>5.1. Penetrability test</title>
<p>Take middle finger flexion as an example. The three host sEMG signals and encryption sEMG signals of three different muscle locations are depicted in <xref ref-type="fig" rid="fig5-1077546310395966">Figure 5</xref>. The mean RMS values of three different muscle locations are illustrated in <xref ref-type="table" rid="table1-1077546310395966">Table 1</xref>. From <xref ref-type="fig" rid="fig5-1077546310395966">Figure 5</xref> and <xref ref-type="table" rid="table1-1077546310395966">Table 1</xref>, the three host sEMG signals and encryption sEMG signals of three different muscle locations are similar and have good penetrability.
<fig id="fig5-1077546310395966" position="float"><label>Figure 5.</label><caption><p>Example of one participant sEMG signal. (a) Host sEMG signal; (b) Encryption sEMG signal.</p></caption><graphic xlink:href="10.1177_1077546310395966-fig5.tif"/></fig>
<table-wrap id="table1-1077546310395966" position="float"><label>Table 1.</label><caption><p>Average root mean square of sEMG signals</p></caption>
<graphic alternate-form-of="table1-1077546310395966" xlink:href="10.1177_1077546310395966-table1.tif"/>
<table frame="hsides">
<thead align="left">
<tr>
<th/>
<th colspan="3">Host sEMG RMS (mV)<hr/></th>
<th colspan="3">Encryption sEMG RMS (mV)<hr/></th>
</tr>
<tr>
<th/>
<th>Brachioradialis</th>
<th>Flexor Carpi Radialis (FCR)</th>
<th>Flexor Digitorum Superficialis (FDS)</th>
<th>Brachioradialis</th>
<th>Flexor Carpi Radialis (FCR)</th>
<th>Flexor Digitorum Superficialis (FDS)</th>
</tr>
</thead>
<tbody align="left">
<tr>
<td>Participant 1</td>
<td>0.4500</td>
<td>1.2583</td>
<td>1.4567</td>
<td>0.4516</td>
<td>1.2626</td>
<td>1.4658</td>
</tr>
<tr>
<td>Participant 2</td>
<td>0.3897</td>
<td>1.0874</td>
<td>1.3552</td>
<td>0.3887</td>
<td>1.0632</td>
<td>1.3288</td>
</tr>
<tr>
<td>Participant 3</td>
<td>0.3960</td>
<td>1.2128</td>
<td>1.3536</td>
<td>0.3873</td>
<td>1.1990</td>
<td>1.3265</td>
</tr>
<tr>
<td>Participant 4</td>
<td>0.3839</td>
<td>0.8125</td>
<td>1.3240</td>
<td>0.3809</td>
<td>0.8281</td>
<td>1.3867</td>
</tr>
</tbody>
</table>
</table-wrap></p>
</sec>
<sec id="sec13-1077546310395966"><title>5.2. Recognizing test</title>
<p>There are three specific finger flexions of middle/ring finger flexion, all fingers flexion and wrist flexion in the test. The test feature is chosen RMS and the test classifier is selected Bp-NN. <xref ref-type="table" rid="table2-1077546310395966">Table 2</xref> illustrates it obviously that the online recognition rate is lower than the offline recognition rate normally and offline recognition rate can reach 99%. When the model which is proposed in the paper is adopted, the online recognition rate may increase to 91%.
<table-wrap id="table2-1077546310395966" position="float"><label>Table 2.</label><caption><p>Recognition result table</p></caption>
<graphic alternate-form-of="table2-1077546310395966" xlink:href="10.1177_1077546310395966-table2.tif"/>
<table frame="hsides">
<thead align="left">
<tr>
<th colspan="2" rowspan="2"/>
<th colspan="6">Hand gesture<hr/></th>
</tr>
<tr>
<th colspan="2">All finger<hr/></th>
<th colspan="2">Middle/ring finger<hr/></th>
<th colspan="2">Wrist<hr/></th>
</tr>
<tr>
<th>Offline</th>
<th>Online</th>
<th>Offline</th>
<th>Online</th>
<th>Offline</th>
<th>Online</th>
</tr>
</thead>
<tbody align="left">
<tr>
<td rowspan="3">Without model</td>
<td>Participant 1</td>
<td>99%</td>
<td>64%</td>
<td>99%</td>
<td>68%</td>
<td>95%</td>
<td>62%</td>
</tr>
<tr>
<td>Participant 2</td>
<td>98%</td>
<td>65%</td>
<td>99%</td>
<td>69%</td>
<td>96%</td>
<td>62%</td>
</tr>
<tr>
<td>Participant 3</td>
<td>98%</td>
<td>65%</td>
<td>99%</td>
<td>69%</td>
<td>95%</td>
<td>63%</td>
</tr>
<tr>
<td>Participant 4</td>
<td>98%</td>
<td>65%</td>
<td>99%</td>
<td>68%</td>
<td>95%</td>
<td>64%</td>
</tr>
<tr>
<td rowspan="3">With model</td>
<td>Participant 1</td>
<td>98%</td>
<td>88%</td>
<td>99%</td>
<td>90%</td>
<td>97%</td>
<td>85%</td>
</tr>
<tr>
<td>Participant 2</td>
<td>98%</td>
<td>90%</td>
<td>98%</td>
<td>90%</td>
<td>96%</td>
<td>88%</td>
</tr>
<tr>
<td>Participant 3</td>
<td>99%</td>
<td>90%</td>
<td>99%</td>
<td>91%</td>
<td>97%</td>
<td>87%</td>
</tr>
<tr>
<td>Participant 4</td>
<td>99%</td>
<td>91%</td>
<td>99%</td>
<td>91%</td>
<td>98%</td>
<td>89%</td>
</tr>
</tbody>
</table>
</table-wrap></p>
</sec>
</sec>
<sec id="sec14-1077546310395966" sec-type="conclusion"><title>6. Conclusions</title>
<p>A single channel electromyography blind recognition model based on watermarking is proposed in this paper. SCICA is adopted to avoid a complicated circuit connection and unreliability of hardware and to reduce the noise which accompanies a sEMG signal. Embedded watermarking is applied to solve the problem of blind source separation disorder. In consideration of a time-scale synchronization attack, the host sEMG signals are transformed into wavelet domain and the synchronization codes are embedded.</p>
<p>The experiment results show that the model proposed in this paper is penetrable against most common signal processing, and can recognize the hand gesture accurately online. However, the delay of the online separation and recognition exist for the reason of adding algorithm transform and signal process. The online recognition rate cannot attach 99%.</p>
<p>For the sEMG recognition model, we consider several further extensions. First, time delay is an important property of the model. Recurrent neural networks are powerful in dealing with temporal information and fast convergence. Secondly, Recurrent Neural Networks (RNN) will introduce more parameters well suited to handling this type of problem into the model and asks for more training data. Here, we propose using a different training strategy, particle swarm optimization (PSO), to determine the unknown network parameters (<xref ref-type="bibr" rid="bibr2-1077546310395966">Cai and Wunsch, 2005</xref>; <xref ref-type="bibr" rid="bibr12-1077546310395966">Settles et al., 2003</xref>).</p>
</sec>
</body>
<back>
<sec id="sec15-1077546310395966"><title>Funding</title>
<p>Funding for this work was provided by the grants of Study Abroad of Shanxi Scholarship Council of China [No. 20101069] and Youth Foundation of Taiyuan University of Science and Technology of China [No. 20103004].</p>
</sec>
<ref-list>
<title>References</title>
<ref id="bibr1-1077546310395966"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Arjunan</surname><given-names>SP</given-names></name><name><surname>Kumar</surname><given-names>DK</given-names></name><name><surname>Naik</surname><given-names>GR</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Shimada</surname><given-names>H</given-names></name></person-group> (<year>2010</year>) <source>A framework towards real time control of virtual robotic hand: interface based on low-level forearm muscle movements</source>, <conf-name>Proceedings of Second IEEE International Conference on Intelligent Human Computer Interaction</conf-name>. <conf-loc>Allahabad, India</conf-loc>, <fpage>78</fpage>–<lpage>85</lpage>.</citation></ref>
<ref id="bibr2-1077546310395966"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Wunsch</surname><given-names>D</given-names></name></person-group> (<year>2005</year>) <source>Engine data classification with simultaneous recurrent network using a hybrid PSO-EA algorithm</source>, <conf-name>Proceedings of IEEE International Joint Conference on Neural Networks, IJCNN 2005</conf-name>, <conf-loc>Montréal, Québec, Canada</conf-loc>, <conf-date>July 2005</conf-date>, <volume>4</volume>, <fpage>2319</fpage>–<lpage>2323</lpage>.</citation></ref>
<ref id="bibr3-1077546310395966"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davies</surname><given-names>ME</given-names></name><name><surname>James</surname><given-names>CJ</given-names></name></person-group> (<year>2007</year>) <article-title>Source separation using single channel ICA</article-title>. <source>Signal Processing</source> <volume>87</volume>: <fpage>1819</fpage>–<lpage>1832</lpage>.</citation></ref>
<ref id="bibr4-1077546310395966"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Y</given-names></name></person-group> (<year>2010</year>) <source>Research of hand gesture identification of sEMG based on SCICA</source>, <conf-name>IEEE The Second International Conference on Signal Processing Systems (ICSPS 2010)</conf-name>. <conf-date>July 5–7</conf-date>, <conf-loc>Dalian, People’s Republic of China</conf-loc>, <volume>1</volume>, <fpage>350</fpage>–<lpage>353</lpage>.</citation></ref>
<ref id="bibr5-1077546310395966"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name></person-group> (<year>2011</year>) <article-title>Wireless surface electromyography sensor network based on rapid prototyping equipments</article-title>. <source>Sensor Letters</source> <month>October</month>, <volume>9</volume>(<issue>5</issue>) <comment>(Accepted September 2010)</comment>.</citation></ref>
<ref id="bibr6-1077546310395966"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hyvärinen</surname><given-names>A</given-names></name><name><surname>Karhunen</surname><given-names>J</given-names></name><name><surname>Oja</surname><given-names>E</given-names></name></person-group> (<year>2001</year>) <source>Independent Component Analysis</source>. <publisher-name>A Wiley-Interscience Publication, Copyright © Wiley</publisher-name>. <isbn>ISBN 0-471-22131-7</isbn>. <fpage>15</fpage>–<lpage>18</lpage>.</citation></ref>
<ref id="bibr7-1077546310395966"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lie</surname><given-names>WN</given-names></name><name><surname>Li</surname><given-names>CC</given-names></name></person-group> (<year>2006</year>) <article-title>Robust and high-quantity time-domain audio watermarking based on low-frequency amplitude modification</article-title>. <source>IEEE Transactions on Multimedia</source> <volume>8</volume>(<issue>1</issue>): <fpage>46</fpage>–<lpage>59</lpage>.</citation></ref>
<ref id="bibr8-1077546310395966"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>W</given-names></name></person-group> (<year>2009</year>) <article-title>A method of multi-channel EMG disposal based on wavelet transform and blind signal separation</article-title>. <source>Acta Electronica Sinica</source> <volume>37</volume>(<issue>4</issue>): <fpage>823</fpage>–<lpage>827</lpage>.</citation></ref>
<ref id="bibr9-1077546310395966"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>X</given-names></name><name><surname>Sun</surname><given-names>C</given-names></name></person-group> (<year>2008</year>) <article-title>A DWT domain multiple watermarking scheme based on blind source separation</article-title>. <source>Journal of Electronics and Information Technology</source> <volume>30</volume>(<issue>10</issue>): <fpage>2307</fpage>–<lpage>2310</lpage>.</citation></ref>
<ref id="bibr10-1077546310395966"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Naik</surname><given-names>GR</given-names></name><name><surname>Kumar</surname><given-names>DK</given-names></name><name><surname>Palaniswami</surname><given-names>M</given-names></name></person-group> (<year>2008</year>) <source>Multi run ICA and surface EMG based signal processing system for recognising hand gestures</source>. <conf-name>Proceedings – 2008 IEEE 8th International Conference on Computer and Information Technology, CIT 2008</conf-name>, <conf-loc>Sydney, NSW</conf-loc>, <conf-date>8–11 July 2008</conf-date>, <fpage>700</fpage>–<lpage>705</lpage>.</citation></ref>
<ref id="bibr11-1077546310395966"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Naik</surname><given-names>GR</given-names></name><name><surname>Kumar</surname><given-names>DK</given-names></name><name><surname>Weghorn</surname><given-names>H</given-names></name></person-group> (<year>2008</year>) <source>Performance comparison of ICA algorithms for isometric hand gesture identification using surface EMG</source>. <conf-name>Proceedings of Computer and Information Technology, CIT 2008. Eighth IEEE International Conference</conf-name>. <conf-loc>Sydney, Australia</conf-loc>, <conf-date>July 8–11</conf-date>, <fpage>700</fpage>–<lpage>705</lpage>.</citation></ref>
<ref id="bibr12-1077546310395966"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Settles</surname><given-names>M</given-names></name><name><surname>Rodebaugh</surname><given-names>B</given-names></name><name><surname>Soule</surname><given-names>T</given-names></name></person-group> (<year>2003</year>) <source>Comparison of genetic algorithm and particle swarm optimizer when evolving a recurrent neural network</source>. <conf-name>Proceedings of Genetic and Evolutionary Computation Conference</conf-name>, <conf-loc>Chicago, IL, USA</conf-loc>, <conf-date>12–16 July 2003</conf-date>, <fpage>148</fpage>–<lpage>149</lpage>.</citation></ref>
<ref id="bibr13-1077546310395966"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name></person-group> (<year>2007</year>) <article-title>New semi-fragile watermarking for JPEG image authentication</article-title>. <source>Journal of Computer Applications</source> <volume>27</volume>(<issue>1</issue>): <fpage>132</fpage>–<lpage>134</lpage>.</citation></ref>
</ref-list>
</back>
</article>