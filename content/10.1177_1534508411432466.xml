<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AEI</journal-id>
<journal-id journal-id-type="hwp">spaei</journal-id>
<journal-title>Assessment for Effective Intervention</journal-title>
<issn pub-type="ppub">1534-5084</issn>
<issn pub-type="epub">1938-7458</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1534508411432466</article-id>
<article-id pub-id-type="publisher-id">10.1177_1534508411432466</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Barriers to Implementing Treatment Integrity Procedures in School Psychology Research</article-title>
<subtitle>Survey of Treatment Outcome Researchers</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Sanetti</surname><given-names>Lisa M. Hagermoser</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508411432466">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>DiGennaro Reed</surname><given-names>Florence D.</given-names></name>
<degrees>PhD, BCBA</degrees>
<xref ref-type="aff" rid="aff2-1534508411432466">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-1534508411432466"><label>1</label>University of Connecticut, Storrs, CT, USA</aff>
<aff id="aff2-1534508411432466"><label>2</label>University of Kansas, Lawrence, KS, USA</aff>
<author-notes>
<corresp id="corresp1-1534508411432466">Lisa M. Hagermoser Sanetti, University of Connecticut, Department of Educational Psychology, U-2064, Storrs, CT 06269-2064, USA Email: <email>lisa.sanetti@uconn.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2012</year>
</pub-date>
<volume>37</volume>
<issue>4</issue>
<fpage>195</fpage>
<lpage>202</lpage>
<permissions>
<copyright-statement>Â© 2012 Hammill Institute on Disabilities</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Hammill Institute on Disabilities</copyright-holder>
</permissions>
<abstract>
<p>Treatment integrity data are essential to drawing valid conclusions in treatment outcome studies. Such data, however, are not always included in peer-reviewed research articles in school psychology or related fields. To gain a better understanding of why treatment integrity data are lacking in the school psychology research, we surveyed the authors of the 210 treatment outcome articles published in four school psychology journals from 1995 through 2008 regarding their perceptions of barriers to implementing treatment integrity procedures. Results indicated that (a) lack of theory and specific guidelines on treatment integrity procedures; (b) lack of general knowledge about treatment integrity; (c) time, cost, and labor demands; and (d) lack of editorial requirement were broadly perceived as barriers by school psychology researchers to implementing treatment integrity procedures. Implications for future research are discussed.</p>
</abstract>
<kwd-group>
<kwd>treatment integrity</kwd>
<kwd>procedural fidelity</kwd>
<kwd>procedural reliability</kwd>
<kwd>barriers</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Treatment integrity is generally defined as the extent to which an intervention is implemented as planned (e.g., <xref ref-type="bibr" rid="bibr7-1534508411432466">Gresham, 1989</xref>; <xref ref-type="bibr" rid="bibr31-1534508411432466">Yeaton &amp; Sechrest, 1981</xref>). Although recent conceptual models of treatment integrity (e.g., <xref ref-type="bibr" rid="bibr22-1534508411432466">Power et al., 2005</xref>) dissect this construct into multiple dimensions (e.g., adherence, exposure, participant responsiveness, and others), the focus remains on the quantity (i.e., what percentage of the component intervention steps were implemented) and quality (i.e., how well component intervention steps were implemented) of intervention implementation (<xref ref-type="bibr" rid="bibr26-1534508411432466">Sanetti &amp; Kratochwill, 2009</xref>).</p>
<p>A number of studies have documented a positive correlation between treatment integrity and student outcomes (e.g., <xref ref-type="bibr" rid="bibr4-1534508411432466">DiGennaro, Martens, &amp; Kleinmann, 2007</xref>; <xref ref-type="bibr" rid="bibr5-1534508411432466">DiGennaro, Martens, &amp; McIntyre, 2005</xref>). More recently, researchers have conducted parametric analyses wherein treatment integrity levels are experimentally manipulated to examine the impact on client outcomes. For example, <xref ref-type="bibr" rid="bibr28-1534508411432466">St. Peter Pipkin, Vollmer, and Sloman (2010)</xref> showed that certain types of integrity errors (i.e., reinforcement of problem behavior [commission error]) are more detrimental than other types of errors (i.e., not implementing intervention components [omission error]). The findings of <xref ref-type="bibr" rid="bibr6-1534508411432466">DiGennaro Reed, Reed, Baez, and Maguire (2011)</xref> revealed that treatment integrity commission errors produced low levels of acquisition during instruction in young children with disabilities. Relatedly, <xref ref-type="bibr" rid="bibr18-1534508411432466">Noell, Gresham, and Gansle (2002)</xref> and <xref ref-type="bibr" rid="bibr12-1534508411432466">Hirschstein and colleagues (2007)</xref> showed that decrements in treatment integrity (i.e., omission errors) negatively affected student performance on computerized mathematics tasks and social skills, respectively. These and other studies comprise a growing body of experimental literature supporting the notion that treatment integrity is worthy of measurement during academic, behavioral, and social-emotional intervention in applied settings. However, despite these findings, treatment integrity may be infrequently measured in applied settings. For example, in a survey of individuals with the Nationally Certified School Psychologist (NCSP) credential, <xref ref-type="bibr" rid="bibr1-1534508411432466">Cochrane and Laux (2008)</xref> documented that few respondents measure treatment integrity and that, when they do measure it, they rely on indirect methods (e.g., teacher interview or self-report). These findings were observed despite nearly all of the respondents indicating agreement that treatment integrity measurement is important within a Response-to-Intervention (RTI) model and in evaluating success of an intervention. The latter findings are alarming given that student eligibility determinations and intervention decisions rest on the premise that the intervention was delivered as intended (see <xref ref-type="bibr" rid="bibr17-1534508411432466">Noell &amp; Gansle, 2006</xref>, and <xref ref-type="bibr" rid="bibr26-1534508411432466">Sanetti &amp; Kratochwill, 2009</xref>, for more detailed discussions).</p>
<p>Treatment integrity and student outcome data are not only important in school and clinical settings but they are also essential to drawing valid conclusions in treatment outcome research (<xref ref-type="bibr" rid="bibr27-1534508411432466">Shadish, Cook, &amp; Campbell, 2002</xref>). The goal of experimental research designs is to isolate and measure the effects of independent variables on dependent variables (<xref ref-type="bibr" rid="bibr8-1534508411432466">Gresham, 1997</xref>). Failure to ensure accurate implementation of the independent variable (i.e., treatment integrity) influences experimental validity and thus poses threats to any inferences made in treatment outcome research. Treatment integrity influences all four types of experimental validity that allow researchers to draw conclusions from experiments: internal validity, external validity, construct validity, and statistical conclusion validity. <italic>Internal validity</italic> refers to conclusions about the degree to which changes in the dependent variable can be ascribed to the manipulations of the independent variable. When there is significant student behavior change and treatment integrity is not assessed, then the validity of inferences regarding this causal relation may be compromised. Likewise, if there is no behavior change and treatment integrity is not monitored, it becomes difficult to differentiate between an ineffective treatment and an effective treatment implemented with low levels of treatment integrity. Without question, assessing and ensuring high levels of treatment integrity is essential to drawing valid conclusions in the social and behavioral sciences. <italic>External validity</italic> refers to conclusions about the extent to which the causal relation between the independent and dependent variables generalizes to conditions beyond those of the experiment. Such inferences are influenced by treatment integrity as poorly defined, described, or implemented interventions make the replication, evaluation, and generalization of treatments difficult, if not impossible (<xref ref-type="bibr" rid="bibr15-1534508411432466">Moncher &amp; Prinz, 1991</xref>). <italic>Construct validity</italic> refers to conclusions about the higher order constructs represented by the persons, treatments, outcomes, and settings studied and is essential to ruling out any potential confounds that could compromise interpretation of study results. Monitoring treatment integrity throughout intervention implementation may provide the data needed to either rule out or identify such confounds. <italic>Statistical conclusion validity</italic> refers to conclusions about whether the treatment and outcome covary and the strength of the covariation that result from the quantitative evaluation of a study. For example, a researcher comparing two treatments would like to conclude that any differences between treatment conditions are due to true differences between the groups. Yet the standard deviation, a measure of variability, is taken into account in the denominator of the equation when calculating an effect size. There are various potential sources of variability, including differences in treatment integrity. Thus, inconsistency in treatment integrity can increase measures of variability which can then result in lower effect sizes, creating a threat to statistical conclusion validity. Without question, assessing and ensuring high levels of treatment integrity is essential to drawing valid conclusions in the social and behavioral sciences.</p>
<p>Although necessary for drawing valid conclusions from research, treatment integrity data are not always included in peer-reviewed research articles in school psychology or related fields (see <xref ref-type="bibr" rid="bibr25-1534508411432466">Sanetti &amp; Kratochwill, 2008</xref>, for a review). Results of a review of school-based behavioral interventions published between 1980 and 1990 indicated that only 14.4% of included studies reported quantitative treatment integrity data (<xref ref-type="bibr" rid="bibr10-1534508411432466">Gresham, Gansle, Noell, &amp; Cohen, 1993</xref>). Other reviews have documented similar findings of school-based treatment studies in the <italic>Journal of Applied Behavior Analysis</italic> (<xref ref-type="bibr" rid="bibr9-1534508411432466">Gresham, Gansle, &amp; Noell, 1993</xref>; <xref ref-type="bibr" rid="bibr14-1534508411432466">McIntyre, Gresham, DiGennaro, &amp; Reed, 2007</xref>; <xref ref-type="bibr" rid="bibr21-1534508411432466">Peterson, Homer, &amp; Wonderlich, 1982</xref>). Results of a more recent review of treatment outcome studies published in four school psychology journals (<italic>School Psychology Review, School Psychology Quarterly, Journal of School Psychology, Psychology in the Schools</italic>) between 1995 and 2008 indicated that 50.2% of included studies reported quantitative treatment integrity data (<xref ref-type="bibr" rid="bibr24-1534508411432466">Sanetti, Gritter, &amp; Dobey, 2011</xref>). The increase in the prevalence of treatment integrity data is encouraging. However, there is significant room for improvement as nearly half of the treatment outcomes studies in the field of school psychology do not include such data.</p>
<p>An examination of the potential barriers to implementing treatment integrity assessment procedures in treatment outcome research may provide a better understanding of why treatment integrity data continue to be lacking in the school psychology literature base. Such an examination was conducted in the clinical psychology literature by <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova, Hilt, Chereji, and Kazdin (2009)</xref>. The purpose of the current study is to conduct a survey informed by the work of <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova et al. (2009)</xref> and evaluate school psychology treatment outcome researchersâ perceived barriers to implementing treatment integrity procedures. Recognition of these barriers may guide future research endeavors or help to identify practical solutions to measuring and reporting treatment integrity data in experimental research studies.</p>
<sec id="section1-1534508411432466" sec-type="methods">
<title>Method</title>
<sec id="section2-1534508411432466">
<title>Participants</title>
<p>Participants in this study were authors of the 210 treatment outcome articles published in <italic>School Psychology Review</italic> (SPR), <italic>School Psychology Quarterly</italic> (SPQ), <italic>Journal of School Psychology</italic> (JSP), or <italic>Psychology in the Schools</italic> (PITS) from 1995 through 2008. Articles were located through a serial search of the table of contents of PITS, JSP, SPQ, and SPR as part of a larger study evaluating the quantity and quality of treatment integrity data in treatment outcome studies (<xref ref-type="bibr" rid="bibr24-1534508411432466">Sanetti et al., 2011</xref>). These journals were deemed to be influential to the field because they (a) publish at least four issues per year, (b) target psychology practitioners and researchers, and (c) have higher impact factors than other journals meeting the first two criteria. To be included in the larger study, an article had to (a) have been published between 1995 and 2008, (b) have all participants younger than 19 years of age, (c) employ an experimental or quasi-experimental design, and (d) be longer than three pages. The years 1995 through 2008 were chosen because reviews in related fields (e.g., <xref ref-type="bibr" rid="bibr14-1534508411432466">McIntyre et al., 2007</xref>) indicated an increasing trend in reporting treatment integrity data after 1995. For additional details about the literature search and study selection procedures, see <xref ref-type="bibr" rid="bibr24-1534508411432466">Sanetti et al. (2011)</xref>.</p>
<p>For the 210 included treatment outcome studies, there were 153 unique first authors (i.e., several individuals authored more than one treatment outcome study during the 13 years reviewed). Of these 153 first authors, valid email addresses were not available for 46 (30.1%). When a valid email address was not available for the first author, we contacted the second author, if the author was not already a participant because of being a first author of an included study. Twenty-eight second authors were contacted; two email addresses were not valid. In all, we contacted 133 unique authors (first authors, <italic>n</italic> = 107, 80.5%; second authors, <italic>n</italic> = 26, 19.5%) via email and asked them to participate in an online survey on a secure website (<ext-link ext-link-type="uri" xlink:href="http://surveymonkey.com">surveymonkey.com</ext-link>). Authors received three email prompts to complete the survey over 3 months. Of the 133 contacted authors, 44 (33.1%) responded to the survey. The 39 (29.3%) authors who completed the entire anonymous survey constitute the final sample. Respondents averaged 48.47 years of age (<italic>SD</italic> = 10.29, range = 31â66), and 52.6% (<italic>n</italic> = 20) were male. A majority of participants indicated that research (<italic>n</italic> = 33) and teaching (<italic>n</italic> = 27) were their primary and secondary professional activities, respectively. Participants (97.4%, <italic>n</italic> = 37) worked in a university or college setting and reported a mean of 17.39 years (<italic>SD</italic> = 8.25, range 6â38 years) in the treatment outcome research field. When asked to indicate a theoretical orientation, 87.2% (<italic>n</italic> = 34) endorsed skill-building approaches (e.g., cognitive-behavioral) and the remaining endorsed non-skill-building approaches (e.g., psychoanalytic, eclectic).</p>
</sec>
<sec id="section3-1534508411432466">
<title>Measure</title>
<p>The <italic>Barriers to Treatment Integrity Implementation Survey</italic> (BTIIS) was developed by <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova and colleagues (2009)</xref> to âassess possible impediments to addressing treatment integrity of psychosocial interventionsâ (p. 213). The BTIIS has 30 questions rated on a 6-point Likert-type scale (<italic>always disagree, mostly disagree, sometimes disagree, sometimes agree, mostly agree</italic>, and <italic>always agree</italic>). Total scores range from 30 to 180, with higher scores being indicative of more perceived barriers. The BTIIS items cover five domains of potential barriers to addressing treatment integrity: (a) lack of appreciation of treatment integrity (four items); (b) lack of general knowledge about treatment integrity (eight items); (c) lack of theory and specific guidelines on treatment integrity procedures (seven items); (d) the time, cost, and labor demands (five items); and (e) lack of editorial requirement (six items) (see <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova et al., 2009</xref>, for more detailed information about the development of the BTIIS). Ten BTIIS items were revised to better align with school-based intervention delivery, resulting in the BTIIS-R. More specifically, for Items 16, 17, 24, 25, and 29, âtherapistâ was replaced with âinterventionistâ; for Items 9, 13, and 20, âadherence and competenceâ was replaced with âtreatment integrityâ; for Item 2, âprocedural fidelityâ was added as a term used to refer to treatment integrity; and for Item 11, âtreatment manualsâ was replaced with âcritical components of treatments.â In our experience, this terminology is more consistent with the language used in the published school psychology literature and school-based practice. In addition, we modified the scale from 6 to 5 points with a neutral central position (i.e., <italic>always disagree, mostly disagree, sometimes agree, mostly agree</italic>, and <italic>always agree</italic>) given recent findings documenting that researchers prefer a 5-point scale (<xref ref-type="bibr" rid="bibr11-1534508411432466">Gwinner, n.d</xref>.). As a result, total scores for the revised scale could range from 30 to 150; mean item ratings greater than 2.5 represent perceived barriers.</p>
</sec>
</sec>
<sec id="section4-1534508411432466" sec-type="results">
<title>Results</title>
<p><xref ref-type="table" rid="table1-1534508411432466">Table 1</xref> displays the mean rating of each barrier on the BTIIS-R. Total scores for the survey ranged from 56 to 117 (<italic>M</italic> = 81.08, <italic>SD</italic> = 12.32). The internal consistency reliability estimate using Cronbachâs alpha was .84, which indicates a high level of internal consistency for our scale with this particular sample of respondents. Because we modified the number of points in the survey, we adjusted the cut-point in the present study from that used in <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova and colleagues (2009)</xref>. Ratings equal to or less than 2.5 indicate that a survey item is perceived as not a barrier; greater than 2.5 and equal to or less than 3.3 indicate that a survey item is perceived as a barrier; and greater than 3.3 indicate that a survey item is perceived as a strong barrier. In the present study, 21 of the 30 survey items (70%) were rated greater than 2.5 (i.e., barriers or strong barriers). There are 9 items (30%) in the not barriers category, 15 items (50%) in the barriers category, and 6 items (20%) in the strong barriers category.</p>
<table-wrap id="table1-1534508411432466" position="float">
<label>Table 1.</label>
<caption>
<p>Mean Item Ratings for <italic>Barriers to Treatment Integrity Implementation SurveyâRevised</italic></p>
</caption>
<graphic alternate-form-of="table1-1534508411432466" xlink:href="10.1177_1534508411432466-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Barrier Domain</th>
<th align="center">Survey Item</th>
<th align="center"><italic>n</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="5">Not Barriers</td>
</tr>
<tr>
<td>âA</td>
<td>25. Once the training of the interventionists is completed, supervision and monitoring of treatment implementation does not justify the time and labor costs.</td>
<td>39</td>
<td>1.78</td>
<td>0.76</td>
</tr>
<tr>
<td>âB</td>
<td>13. Once established, treatment integrity is believed to be stable and does not fluctuate over time.</td>
<td>39</td>
<td>1.86</td>
<td>0.76</td>
</tr>
<tr>
<td>âA</td>
<td>8. Report of the treatment integrity procedures is not considered to enhance the credibility of the treatment outcome results.</td>
<td>38</td>
<td>1.89</td>
<td>0.82</td>
</tr>
<tr>
<td>âA</td>
<td>27. The cost of implementing treatment integrity procedures outweighs the possible benefits.</td>
<td>39</td>
<td>1.94</td>
<td>0.86</td>
</tr>
<tr>
<td>âA</td>
<td>1. Treatment integrity is not regarded as imperative for ensuring adequate experimental control.</td>
<td>39</td>
<td>2.03</td>
<td>1.10</td>
</tr>
<tr>
<td>âE</td>
<td>4. Because there are no specific requirements for reporting integrity, just mentioning that treatment integrity was monitored without providing quantitative information is regarded as sufficient.</td>
<td>39</td>
<td>2.22</td>
<td>0.89</td>
</tr>
<tr>
<td>âE</td>
<td>19. Limited journal space precludes adequate report of treatment integrity procedures.</td>
<td>39</td>
<td>2.33</td>
<td>0.79</td>
</tr>
<tr>
<td>âB</td>
<td>20. Performing manipulation checks on the treatment integrity of treatment implementation may be risky as treatment integrity may be lower than desired (e.g., credibility of results may be compromised by reporting low levels of treatment integrity).</td>
<td>39</td>
<td>2.42</td>
<td>0.87</td>
</tr>
<tr>
<td colspan="5">Barriers</td>
</tr>
<tr>
<td>âB</td>
<td>10. The requirements of Internal Review Board hinder implementation of treatment integrity procedures (e.g., limiting how data are handled and linked to specific interventionists, pushing for audio instead of videotaping).</td>
<td>39</td>
<td>2.56</td>
<td>0.97</td>
</tr>
<tr>
<td>âB</td>
<td>23. Treatments are presumed to be effective if significant changes on the dependent measures are obtained regardless of the treatment integrity level of intervention implementation.</td>
<td>39</td>
<td>2.56</td>
<td>1.00</td>
</tr>
<tr>
<td>âB</td>
<td>24. Treatment manuals/protocols are not widely employed because they are thought to limit interventionist flexibility in addressing studentsâ problems and tailoring of treatment to the individual needs.</td>
<td>39</td>
<td>2.58</td>
<td>0.91</td>
</tr>
<tr>
<td>âB</td>
<td>11. The critical components of treatments have not been sufficiently identified to permit adequate treatment integrity implementation.</td>
<td>39</td>
<td>2.72</td>
<td>0.94</td>
</tr>
<tr>
<td>âC</td>
<td>21. There are no established criteria or principles by which treatment integrity may be judged.</td>
<td>39</td>
<td>2.64</td>
<td>0.90</td>
</tr>
<tr>
<td>âB</td>
<td>17. Interventionists resist close supervision and monitoring of treatment implementation.</td>
<td>39</td>
<td>2.72</td>
<td>0.82</td>
</tr>
<tr>
<td>âE</td>
<td>3. Journal editors do not require the description of treatment integrity procedures for the article to be accepted.</td>
<td>39</td>
<td>2.81</td>
<td>0.82</td>
</tr>
<tr>
<td>âE</td>
<td>5. Careful implementation and assessment of treatment integrity are not necessary to get a study published.</td>
<td>39</td>
<td>2.78</td>
<td>0.90</td>
</tr>
<tr>
<td>âD</td>
<td>7. Insufficient resources due to the constrained funding from grants hinder the adequate implementation of treatment integrity procedures.</td>
<td>39</td>
<td>2.72</td>
<td>1.09</td>
</tr>
<tr>
<td>âC</td>
<td>9. The definition of treatment integrity in the literature is ambiguous.</td>
<td>39</td>
<td>2.86</td>
<td>1.05</td>
</tr>
<tr>
<td>âE</td>
<td>26. Most treatment outcome research articles are accepted without treatment integrity being adequately addressed.</td>
<td>39</td>
<td>2.92</td>
<td>0.91</td>
</tr>
<tr>
<td>âD</td>
<td>22. High labor costs may preclude researchers from employing or training treatment integrity raters.</td>
<td>39</td>
<td>2.94</td>
<td>0.92</td>
</tr>
<tr>
<td>âB</td>
<td>28. It is generally believed that treatment integrity procedures can be implemented primarily with academic or behavioral interventions but not with other approaches, such as psychodynamic or interpersonal treatments.</td>
<td>39</td>
<td>2.81</td>
<td>0.95</td>
</tr>
<tr>
<td>âC</td>
<td>15. The guidelines for evaluating psychometric properties (validity and reliability) of the treatment integrity measures are unclear.</td>
<td>39</td>
<td>3.00</td>
<td>0.89</td>
</tr>
<tr>
<td>âE</td>
<td>30. There is a lack of editorial insistence/enforcement on the need to implement treatment integrity procedures.</td>
<td>39</td>
<td>3.11</td>
<td>0.85</td>
</tr>
<tr>
<td>âC</td>
<td>14. There are no conventional criteria that specify acceptable levels of treatment integrity.</td>
<td>39</td>
<td>3.11</td>
<td>1.00</td>
</tr>
<tr>
<td colspan="5">Strong Barriers</td>
</tr>
<tr>
<td>âC</td>
<td>2. There is an inconsistency in the terminology of the aspects of treatment integrity (e.g., procedural fidelity, treatment adherence, competence, treatment differentiation).</td>
<td>38</td>
<td>3.36</td>
<td>1.10</td>
</tr>
<tr>
<td>âC</td>
<td>6. The literature does not agree as to what is the appropriate method of treatment integrity assessment.</td>
<td>39</td>
<td>3.50</td>
<td>0.88</td>
</tr>
<tr>
<td>âD</td>
<td>12. Designing and validating treatment integrity measures is labor-intensive and time-consuming.</td>
<td>38</td>
<td>3.42</td>
<td>1.11</td>
</tr>
<tr>
<td>âD</td>
<td>16. It is expensive and time-consuming to provide direct training of interventionists (e.g., viewing tapes, providing feedback, having regular meetings with staff, role-playing techniques).</td>
<td>39</td>
<td>3.42</td>
<td>1.06</td>
</tr>
<tr>
<td>âC</td>
<td>29. Interventionist competence is not clearly defined in the literature.</td>
<td>39</td>
<td>3.58</td>
<td>0.77</td>
</tr>
<tr>
<td>âD</td>
<td>18. There is a considerable time requirement in obtaining accurate representation of treatment integrity data (collection of data across interventionists, situations, cases, and sessions).</td>
<td>39</td>
<td>3.75</td>
<td>0.94</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1534508411432466">
<p><italic>Note.</italic> Items with mean rating of â¤2.5 are considered ânot barriers,â items with mean rating &gt;2.5 and â¤3.3 are considered âbarriers,â and items with mean rating &gt;3.3 are considered âstrong barriers.â A = lack of appreciation of treatment integrity; B = lack of general knowledge about treatment integrity; C = lack of theory and specific guidelines on treatment integrity procedures; D = time, cost, and labor demands; E = lack of editorial requirements.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The items endorsed as strong barriers were clustered in two of the five barrier domains: (a) lack of theory and specific guidelines on treatment integrity procedures and (b) time, cost, and labor demands. Items endorsed as perceived barriers include both of these domains as well as lack of general knowledge about treatment integrity and lack of editorial requirements. Participants did not report lack of appreciation of treatment integrity to be a barrier to its implementation.</p>
</sec>
<sec id="section5-1534508411432466" sec-type="discussion">
<title>Discussion</title>
<p>This study evaluated perceived barriers to implementing treatment integrity procedures as reported by researchers who publish in the area of school psychology treatment outcomes. Survey respondents identified barriers within all but one domain; respondents did not report lack of appreciation of treatment integrity to be a barrier to measuring treatment integrity. Although the current study documented two fewer overall barriers than <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova et al. (2009)</xref>, eight of the nine highest rated items were identical across both studies. Moreover, seven of the nine lowest ranked items were similar across both studies. The same domains were identified as barriers and strong barriers in both studies. In addition, the internal consistency reliability in our study (Î± = .84) was similar to the estimate reported by Perepletchikova et al. (Î± = .80). These findings suggest that researchers in both clinical and school psychology identify similar barriers to assessing treatment integrity. The perceived barriers include criteria that specify acceptable levels of treatment integrity and interventionist competence, inconsistent use of terminology, appropriate assessment methods, and the time requirements for designing protocols, training interventionists, and assessing integrity.</p>
<p>Researchers in both fields also perceive that knowledge about treatment integrity is not a barrier to its implementation and generally agree on the importance of this aspect of conducting research. The differences in the perceived barriers across the two studies were few. School psychology researchers endorsed Items 18 (i.e., there is a considerable time requirement in obtaining accurate representation of treatment integrity data) and 11 (i.e., the critical components of treatments have not been sufficiently identified to permit adequate treatment integrity implementation) as a strong barrier and a barrier, respectively, whereas clinical psychology researchers did not perceive these to be barriers. Clinical psychology researchers endorsed Items 4, 20, and 19 as barriers, but these items were not perceived as barriers by school psychology researchers. An interesting pattern was that some of the findings from the current study are consistent with those from <xref ref-type="bibr" rid="bibr1-1534508411432466">Cochrane and Laux (2008)</xref>. Specifically, school psychology practitioners also perceived time requirements and training interventionists as significant barriers to treatment integrity assessment as well as treatment integrity as highly important to intervention evaluation (<xref ref-type="bibr" rid="bibr1-1534508411432466">Cochrane &amp; Laux, 2008</xref>). Overall, findings across these studies reflect growing consensus regarding both the importance of treatment integrity in intervention evaluation and the barriers to treatment integrity assessment (<xref ref-type="bibr" rid="bibr26-1534508411432466">Sanetti &amp; Kratochwill, 2009</xref>).</p>
<p>We were not surprised that a lack of theory and guidelines was perceived to be a strong barrier or that lack of general knowledge about treatment integrity was perceived to be a barrier to treatment integrity implementation. Treatment integrity involves much more than assessing adherence to an intervention protocol; however, school psychology researchers and practitioners commonly measure only this aspect of integrity if they measure treatment integrity at all (see <xref ref-type="bibr" rid="bibr24-1534508411432466">Sanetti et al., 2011</xref>, for a review). Treatment integrity has been described as a multidimensional construct (<xref ref-type="bibr" rid="bibr3-1534508411432466">Dane &amp; Schneider, 1998</xref>; <xref ref-type="bibr" rid="bibr13-1534508411432466">Jones, Clarke, &amp; Power, 2008</xref>; <xref ref-type="bibr" rid="bibr16-1534508411432466">Noell, 2008</xref>; <xref ref-type="bibr" rid="bibr19-1534508411432466">OâDonnell, 2008</xref>; <xref ref-type="bibr" rid="bibr22-1534508411432466">Power et al., 2005</xref>; <xref ref-type="bibr" rid="bibr26-1534508411432466">Sanetti &amp; Kratochwill, 2009</xref>; <xref ref-type="bibr" rid="bibr29-1534508411432466">Waltz, Addis, Koerner, &amp; Jacobson, 1993</xref>) with numerous conceptual models that identify the varied dimensions. Those outlined by <xref ref-type="bibr" rid="bibr3-1534508411432466">Dane and Schneider (1998)</xref> include adherence, competence, exposure, quality, responsiveness, and program differentiation. However, <xref ref-type="bibr" rid="bibr29-1534508411432466">Waltz and colleagues (1993)</xref> differentiate between unique and essential behaviors, essential but not unique behaviors, acceptable but not necessary behaviors, and others. In behavioral medicine, <xref ref-type="bibr" rid="bibr23-1534508411432466">Resnick et al. (2005)</xref> summarize components of treatment fidelity evaluated in the studies included in their review including design (study features that allow adequate hypothesis testing), training (formative evaluation of interventionists), delivery (ensuring treatment is delivered as planned), receipt (ensuring participant is able to perform skills/strategies required by treatment), and enactment (skills/strategies received by participant are performed outside of the treatment setting). Although there is overlap among these and other models, research has not supported a particular model over another, nor has it arrived at a comprehensive definition of treatment integrity. This directly affects the development of appropriate measurement procedures and how best to assess treatment integrity, which were also raised as barriers in this study. To complicate matters further, varied language is used interchangeably with the term âtreatment integrityâ (e.g., âtreatment implementation integrity,â âintervention integrity,â âtreatment fidelity,â and âprocedural reliabilityâ). To address these barriers, the aforementioned conceptual models must be evaluated scientifically so that the varied dimensions acquire empirical support across studies and researchers. A logical extension of this important work is the development of an empirically supported, comprehensive definition of treatment integrity that incorporates the relevant dimensions.</p>
<p>Time, cost, and labor demands were reported to be another strong barrier to treatment integrity implementation, which supports the findings of <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova et al. (2009)</xref> and <xref ref-type="bibr" rid="bibr1-1534508411432466">Cochrane and Laux (2008)</xref>. Thus, it appears there is continued support for the notion that resource demands affect behavior of researchers and school-based practitioners. Again, we are not surprised by this result considering the emerging state of the science of treatment integrity. Many of the barriers that increase the resource demands of treatment integrity implementation will be decreased as the science of treatment integrity evolves. For example, the lack of consensus about (a) how to measure treatment integrity, (b) the aspects of treatment integrity need to be assessed, (c) the frequency of assessment needed to obtain representative data, and (d) how to efficiently train interventionists were identified as strong barriers and can all be addressed empirically as research in this area grows. Funding agencies (e.g., Institute of Education Sciences, U.S. Department of Education) have begun to recognize the need to support treatment integrity research, as evidenced by requirements to develop treatment integrity measures for intervention efficacy trials and analyze outcome data in relation to treatment integrity. Such grant requirements could, for example, simultaneously (a) allow researchers to allocate time, personnel, and financial resources to the development of psychometrically sound treatment integrity measures; (b) provide practitioners with measure to use in practice; (c) build the literature base related to treatment integrity assessment practices; and (d) inform training practices.</p>
<p>To build a literature base around treatment integrity, it is essential that treatment integrity information is published in peer-reviewed journals. However, lack of editorial requirements for inclusion of such information was perceived to be a barrier to implementing treatment integrity procedures. This finding is similar to those of <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova et al. (2009)</xref> and provides further evidence of the âcurious double standardâ described in previous research (e.g., <xref ref-type="bibr" rid="bibr14-1534508411432466">McIntyre et al. 2007</xref>; <xref ref-type="bibr" rid="bibr21-1534508411432466">Peterson et al., 1982</xref>) wherein measurement of the independent variables (i.e., reliability of the intervention procedures) is not required for publication in the same way it is for dependent variables. More recent research has documented infrequent independent variable reliability across school psychology journals (<xref ref-type="bibr" rid="bibr24-1534508411432466">Sanetti et al., 2011</xref>). Without question, to build a knowledge base related to treatment integrity, and thereby potentially decrease some barriers to treatment integrity implementation, it is essential that journal editors and reviewers not only require authors to provide quantitative treatment integrity data but also require a description of treatment integrity assessment procedures equal to that of the dependent variable measures.</p>
<p>Several limitations exist and should be addressed in future research. First, our sample of respondents represented only 29% of the individuals who were asked to complete the survey. Although this response percentage is similar to those obtained in other studies (e.g., <xref ref-type="bibr" rid="bibr2-1534508411432466">Costenbader, Swartz, &amp; Petrix, 1992</xref>), we had hoped to sample a larger percentage of researchers examining treatment outcomes. The perceived barriers rated by the current survey respondents may not represent the perceptions of the larger sample. Respondents completed the survey anonymously and, as a result, we are unable to statistically evaluate relations between demographic variables, study features, and perceived barriers. The extent to which respondentsâ experiences with academic or behavioral interventions differ and how these experiences interact with their survey ratings is unknown. In addition, the focus of our study was to examine perceived barriers without examining actual treatment integrity implementation practices. Previous research has documented a significant relation between these two variables (<xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova et al., 2009</xref>) such that poorer procedural implementation was associated with higher numbers of perceived barriers. The extent to which this relationship exists in our current sample is unknown and is a valuable area for future research. Moreover, several studies have demonstrated that client gains are highest when interventions are implemented with integrity (e.g., <xref ref-type="bibr" rid="bibr5-1534508411432466">DiGennaro et al., 2005</xref>; <xref ref-type="bibr" rid="bibr4-1534508411432466">DiGennaro et al., 2007</xref>; <xref ref-type="bibr" rid="bibr18-1534508411432466">Noell et al., 2002</xref>; <xref ref-type="bibr" rid="bibr30-1534508411432466">Wilder, Atwell, &amp; Wine, 2006</xref>). The relation between perceived barriers, actual barriers, and client outcomes has not been formally evaluated. It makes conceptual sense that a relation exists, but this has not yet been documented empirically. Last, the psychometric properties of the survey are limited; future research might calculate testâretest reliability and establish validity of the scale. The current study only assessed respondentsâ perceptions on one occasion; other sources for assessing barriers to treatment integrity measurement were not used to validate the current scale. Although internal consistency reliability was relatively high across our study and the study published by <xref ref-type="bibr" rid="bibr20-1534508411432466">Perepletchikova and colleagues (2009)</xref>, the items are conceptually derived, not empirically derived. Future research might directly measure and quantify the barrier domains of the scale (e.g., editorial requirements; time, cost, and labor demands; and others), rather than rely on perceptions alone.</p>
<p>In sum, the present study evaluated perceived barriers to implementing treatment integrity procedures. Results indicated that (a) lack of theory and specific guidelines on treatment integrity procedures; (b) lack of general knowledge about treatment integrity; (c) time, cost, and labor demands; and (d) lack of editorial requirement were broadly perceived as barriers to implementing treatment integrity procedures by school psychology researchers. Future research could address perceived and actual barriers as well as experimentally validating a conceptual model of treatment integrity. The impact on both research and practice could be substantial.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: Preparation of this article was supported in part by a grant from the University of Connecticut Research Foundation. Opinions expressed herein do not necessarily reflect the position of the University of Connecticut, and such endorsements should not be inferred.</p></fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cochrane</surname><given-names>W. S.</given-names></name>
<name><surname>Laux</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>A survey investigating school psychologistsâ measurement of treatment integrity in school-based interventions and their beliefs about its importance</article-title>. <source>Psychology in the Schools</source>, <volume>45</volume>, <fpage>499</fpage>â<lpage>507</lpage>.</citation>
</ref>
<ref id="bibr2-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Costenbader</surname><given-names>V.</given-names></name>
<name><surname>Swartz</surname><given-names>J.</given-names></name>
<name><surname>Petrix</surname><given-names>L.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Consultation in the schools: The relationship between preservice training, perception of consultative skills, and actual time spent in consultation</article-title>. <source>School Psychology Review</source>, <volume>21</volume>, <fpage>95</fpage>â<lpage>108</lpage>.</citation>
</ref>
<ref id="bibr3-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dane</surname><given-names>A. V.</given-names></name>
<name><surname>Schneider</surname><given-names>B. H.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Program integrity in primary and early secondary prevention: Are implementation effects out of control?</article-title> <source>Clinical Psychology Review</source>, <volume>18</volume>, <fpage>23</fpage>â<lpage>45</lpage>.</citation>
</ref>
<ref id="bibr4-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DiGennaro</surname><given-names>F. D.</given-names></name>
<name><surname>Martens</surname><given-names>B. K</given-names></name>
<name><surname>Kleinmann</surname><given-names>A. E.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A comparison of performance feedback procedures on teachersâ treatment implementation integrity and studentsâ inappropriate behavior in special education classrooms</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>40</volume>, <fpage>447</fpage>â<lpage>461</lpage>.</citation>
</ref>
<ref id="bibr5-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DiGennaro</surname><given-names>F. D.</given-names></name>
<name><surname>Martens</surname><given-names>B. K.</given-names></name>
<name><surname>McIntyre</surname><given-names>L. L.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Increasing treatment integrity through negative reinforcement: Effects on teacher and student behavior</article-title>. <source>School Psychology Review</source>, <volume>34</volume>, <fpage>220</fpage>â<lpage>231</lpage>.</citation>
</ref>
<ref id="bibr6-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DiGennaro Reed</surname><given-names>F. D.</given-names></name>
<name><surname>Reed</surname><given-names>D. D.</given-names></name>
<name><surname>Baez</surname><given-names>C.</given-names></name>
<name><surname>Maguire</surname><given-names>H.</given-names></name>
</person-group> (<year>2011</year>). <article-title>A parametric analysis of errors of commission during discrete trial teaching</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>44</volume>, <fpage>611</fpage>â<lpage>615</lpage>.</citation>
</ref>
<ref id="bibr7-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Assessment of treatment integrity in school consultation and prereferral intervention</article-title>. <source>School Psychology Review</source>, <volume>18</volume>, <fpage>37</fpage>â<lpage>50</lpage>.</citation>
</ref>
<ref id="bibr8-1534508411432466">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Treatment integrity in single-subject research</article-title>. In <person-group person-group-type="editor">
<name><surname>Franklin</surname><given-names>R. D.</given-names></name>
<name><surname>Allison</surname><given-names>D. B.</given-names></name>
<name><surname>Gorman</surname><given-names>B. S.</given-names></name>
</person-group> (Eds.), <source>Design and analysis of single-case research</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr9-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
<name><surname>Gansle</surname><given-names>K.</given-names></name>
<name><surname>Noell</surname><given-names>G. H.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Treatment integrity in applied behavior analysis with children</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>26</volume>, <fpage>257</fpage>â<lpage>263</lpage>.</citation>
</ref>
<ref id="bibr10-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
<name><surname>Gansle</surname><given-names>K. A.</given-names></name>
<name><surname>Noell</surname><given-names>G. H.</given-names></name>
<name><surname>Cohen</surname><given-names>S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Treatment integrity of school-based behavioral intervention studies: 1980-1990</article-title>. <source>School Psychology Review</source>, <volume>22</volume>, <fpage>254</fpage>â<lpage>272</lpage>.</citation>
</ref>
<ref id="bibr11-1534508411432466">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Gwinner</surname><given-names>C.</given-names></name>
</person-group> (<comment>n.d.</comment>). <article-title>5-point versus 6-point likert scales (Infosurv white paper)</article-title>. <comment>Retrieved from Infosurv website: <ext-link ext-link-type="uri" xlink:href="http://www.infosurv.com/resourcecenter/white-papers/">http://www.infosurv.com/resourcecenter/white-papers/</ext-link></comment></citation>
</ref>
<ref id="bibr12-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hirschstein</surname><given-names>M. K.</given-names></name>
<name><surname>Edstrom</surname><given-names>L. V.</given-names></name>
<name><surname>Frey</surname><given-names>K. S.</given-names></name>
<name><surname>Snell</surname><given-names>J. L.</given-names></name>
<name><surname>MacKenzie</surname><given-names>E. P.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Walking the talk in bully prevention: Teacher implementation variable related to initial impact of the Steps to Respect program</article-title>. <source>School Psychology Review</source>, <volume>36</volume>, <fpage>3</fpage>â<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr13-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jones</surname><given-names>H. A.</given-names></name>
<name><surname>Clarke</surname><given-names>A. T.</given-names></name>
<name><surname>Power</surname><given-names>T. J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Expanding the concept of intervention integrity: A multidimensional model of participant engagement</article-title>. <source>In Balance</source>, <volume>23</volume>, <fpage>4</fpage>â<lpage>5</lpage>.</citation>
</ref>
<ref id="bibr14-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McIntyre</surname><given-names>L. L.</given-names></name>
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
<name><surname>DiGennaro</surname><given-names>F. D.</given-names></name>
<name><surname>Reed</surname><given-names>D. D.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Treatment integrity of school-based interventions with children in the <italic>Journal of Applied Behavior Analysis</italic> 1991-2005</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>40</volume>, <fpage>659</fpage>â<lpage>672</lpage>.</citation>
</ref>
<ref id="bibr15-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moncher</surname><given-names>F. J.</given-names></name>
<name><surname>Prinz</surname><given-names>R. J.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Treatment fidelity in outcome studies</article-title>. <source>Clinical Psychology Review</source>, <volume>11</volume>, <fpage>247</fpage>â<lpage>266</lpage>.</citation>
</ref>
<ref id="bibr16-1534508411432466">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Noell</surname><given-names>G. H.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Research examining the relationships among consultation process, treatment integrity, and outcomes</article-title>. In <person-group person-group-type="editor">
<name><surname>Erchul</surname><given-names>W. P.</given-names></name>
<name><surname>Sheridan</surname><given-names>S. M.</given-names></name>
</person-group> (Eds.), <source>Handbook of research in school consultation: Empirical foundations for the field</source> (pp. <fpage>315</fpage>â<lpage>334</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr17-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Noell</surname><given-names>G. H.</given-names></name>
<name><surname>Gansle</surname><given-names>K. A.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Assuring the form has substance: Treatment plan implementation as the foundation of assessing response to intervention</article-title>. <source>Assessment for Effective Intervention</source>, <volume>32</volume>, <fpage>32</fpage>â<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr18-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Noell</surname><given-names>G. H.</given-names></name>
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
<name><surname>Gansle</surname><given-names>K. A.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Does treatment integrity matter? A preliminary investigation of instructional implementation and mathematics performance</article-title>. <source>Journal of Behavioral Education</source>, <volume>11</volume>, <fpage>51</fpage>â<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr19-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>OâDonnell</surname><given-names>C. L.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Defining, conceptualizing, and measuring fidelity of implementation and its relationship to outcomes in K-12 curriculum intervention research</article-title>. <source>Review of Educational Research</source>, <volume>78</volume>, <fpage>33</fpage>â<lpage>84</lpage>.</citation>
</ref>
<ref id="bibr20-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Perepletchikova</surname><given-names>F.</given-names></name>
<name><surname>Hilt</surname><given-names>L. M.</given-names></name>
<name><surname>Chereji</surname><given-names>E.</given-names></name>
<name><surname>Kazdin</surname><given-names>A. E.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Barriers to implementing treatment integrity procedures: Survey of treatment outcome researchers</article-title>. <source>Journal of Consulting and Clinical Psychology</source>, <volume>77</volume>, <fpage>212</fpage>â<lpage>218</lpage>.</citation>
</ref>
<ref id="bibr21-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peterson</surname><given-names>L.</given-names></name>
<name><surname>Homer</surname><given-names>A.</given-names></name>
<name><surname>Wonderlich</surname><given-names>S.</given-names></name>
</person-group> (<year>1982</year>). <article-title>The integrity of independent variables in behavior analysis</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>15</volume>, <fpage>477</fpage>â<lpage>492</lpage>.</citation>
</ref>
<ref id="bibr22-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Power</surname><given-names>T. J.</given-names></name>
<name><surname>Blom-Hoffman</surname><given-names>J.</given-names></name>
<name><surname>Clarke</surname><given-names>A. T.</given-names></name>
<name><surname>Riley-Tillman</surname><given-names>T. C.</given-names></name>
<name><surname>Kellerher</surname><given-names>C.</given-names></name>
<name><surname>Manz</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Reconceptualizing intervention integrity: A partner-based framework for linking research with practice</article-title>. <source>Psychology in the Schools</source>, <volume>42</volume>, <fpage>495</fpage>â<lpage>507</lpage>.</citation>
</ref>
<ref id="bibr23-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Resnick</surname><given-names>B.</given-names></name>
<name><surname>Bellg</surname><given-names>A. J.</given-names></name>
<name><surname>DeFrancesco</surname><given-names>C.</given-names></name>
<name><surname>Breger</surname><given-names>R.</given-names></name>
<name><surname>Hecht</surname><given-names>J.</given-names></name>
<name><surname>Sharp</surname><given-names>D. L.</given-names></name>
<name><surname>. . . Czajkowski</surname><given-names>S.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Examples of implementation and evaluation of treatment fidelity in the BCC studies: Where we are and where we need to go</article-title>. <source>Annals of Behavioral Medicine</source>, <volume>29</volume>, <fpage>46</fpage>â<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr24-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sanetti</surname><given-names>L. M. H.</given-names></name>
<name><surname>Gritter</surname><given-names>K. L.</given-names></name>
<name><surname>Dobey</surname><given-names>L.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Treatment integrity of interventions with children in the school psychology literature from 1995 to 2008</article-title>. <source>School Psychology Review</source>, <volume>40</volume>, <fpage>72</fpage>â<lpage>84</lpage>.</citation>
</ref>
<ref id="bibr25-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sanetti</surname><given-names>L. M. H.</given-names></name>
<name><surname>Kratochwill</surname><given-names>T. R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Treatment integrity in behavioral consultation: Measurement, promotion, and outcomes</article-title>. <source>International Journal of Behavioral Consultation and Therapy</source>, <volume>4</volume>, <fpage>95</fpage>â<lpage>114</lpage>.</citation>
</ref>
<ref id="bibr26-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sanetti</surname><given-names>L. M. H.</given-names></name>
<name><surname>Kratochwill</surname><given-names>T. R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Toward developing a science of treatment integrity: Introduction to the special series</article-title>. <source>School Psychology Review</source>, <volume>38</volume>, <fpage>445</fpage>â<lpage>459</lpage>.</citation>
</ref>
<ref id="bibr27-1534508411432466">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Shadish</surname><given-names>W. R.</given-names></name>
<name><surname>Cook</surname><given-names>T. D.</given-names></name>
<name><surname>Campbell</surname><given-names>D. T.</given-names></name>
</person-group> (<year>2002</year>). <source>Experimental and quasi-experimental designs for generalized causal inference</source>. <publisher-loc>Boston</publisher-loc>: <publisher-name>Houghton Mifflin</publisher-name>.</citation>
</ref>
<ref id="bibr28-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>St. Peter Pipkin</surname><given-names>C.</given-names></name>
<name><surname>Vollmer</surname><given-names>T. R.</given-names></name>
<name><surname>Sloman</surname><given-names>K. N.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Effects of treatment integrity failures during differential reinforcement of alternative behavior: A translational model</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>43</volume>, <fpage>47</fpage>â<lpage>70</lpage>.</citation>
</ref>
<ref id="bibr29-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Waltz</surname><given-names>J.</given-names></name>
<name><surname>Addis</surname><given-names>M. E.</given-names></name>
<name><surname>Koerner</surname><given-names>K.</given-names></name>
<name><surname>Jacobson</surname><given-names>N. S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Testing the integrity of a psychotherapy protocol: Assessment of adherence and competence</article-title>. <source>Journal of Consulting and Clinical Psychology</source>, <volume>61</volume>, <fpage>620</fpage>â<lpage>630</lpage>.</citation>
</ref>
<ref id="bibr30-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilder</surname><given-names>D. A.</given-names></name>
<name><surname>Atwell</surname><given-names>J.</given-names></name>
<name><surname>Wine</surname><given-names>B.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The effects of varying levels of treatment integrity on child compliance during treatment with a three-step prompting procedure</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>39</volume>, <fpage>369</fpage>â<lpage>373</lpage>.</citation>
</ref>
<ref id="bibr31-1534508411432466">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yeaton</surname><given-names>W. H.</given-names></name>
<name><surname>Sechrest</surname><given-names>L.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Critical dimensions in the choice and maintenance of successful treatments: Strength, integrity, and effectiveness</article-title>. <source>Journal of Consulting and Clinical Psychology</source>, <volume>49</volume>, <fpage>156</fpage>â<lpage>167</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>