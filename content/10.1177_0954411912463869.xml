<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PIH</journal-id>
<journal-id journal-id-type="hwp">sppih</journal-id>
<journal-title>Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine</journal-title>
<issn pub-type="ppub">0954-4119</issn>
<issn pub-type="epub">2041-6518</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0954411912463869</article-id>
<article-id pub-id-type="publisher-id">10.1177_0954411912463869</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Computer-aided modelling of three-dimensional maxillofacial tissues through multi-modal imaging</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Barone</surname><given-names>Sandro</given-names></name>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Paoli</surname><given-names>Alessandro</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Razionale</surname><given-names>Armando V</given-names></name>
</contrib>
<aff id="aff1-0954411912463869">Department of Mechanical, Nuclear and Production Engineering, University of Pisa, Pisa, Italy</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0954411912463869">Alessandro Paoli, Department of Mechanical, Nuclear and Production Engineering, University of Pisa, Largo Lucio Lazzarino, n.1, 56126 Pisa, Italy. Email: <email>a.paoli@ing.unipi.it</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2013</year>
</pub-date>
<volume>227</volume>
<issue>2</issue>
<fpage>89</fpage>
<lpage>104</lpage>
<history>
<date date-type="received">
<day>3</day>
<month>7</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>12</day>
<month>9</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© IMechE 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Institution of Mechanical Engineers</copyright-holder>
</permissions>
<abstract>
<p>Recent developments in digital imaging techniques have allowed a wide spread of three-dimensional methodologies based on capturing anatomical tissues by different approaches, such as cone-beam computed tomography, three-dimensional photography and surface scanning. In oral rehabilitation, an objective method to predict surgical and orthodontic outcomes should be based on anatomical data belonging to soft facial tissue, facial skeleton and dentition (maxillofacial triad). However, none of the available imaging techniques can accurately capture the complete triad. This article presents a multi-modal framework, which allows image fusion of different digital techniques to create a three-dimensional virtual maxillofacial model, which integrates photorealistic face, facial skeleton and dentition. The methodology is based on combining structured light surface scanning and cone-beam computed tomography data processing. The fusion procedure provides multi-modal representations by aligning different tissues on the basis of common anatomical constraints.</p>
</abstract>
<kwd-group>
<kwd>Computer assisted</kwd>
<kwd>multi-modal image fusion</kwd>
<kwd>three-dimensional medical imaging</kwd>
<kwd>maxillofacial modelling</kwd>
<kwd>optical scanning</kwd>
<kwd>cone-beam computed tomography scanning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0954411912463869" sec-type="intro">
<title>Introduction</title>
<p>Recent advances in three-dimensional (3D) imaging techniques and computer-based methodologies have provided powerful tools for diagnostic and clinical assessments within many aspects of oral rehabilitation.<sup><xref ref-type="bibr" rid="bibr1-0954411912463869">1</xref></sup> For example, patients with dysgnathic deformity need careful assessment of the interdependencies between facial soft tissues, underlying facial skeleton and dentition (<italic>maxillofacial triad</italic>) to re-establish a subjective harmonious oral function. Technological progresses<sup><xref ref-type="bibr" rid="bibr2-0954411912463869">2</xref><xref ref-type="bibr" rid="bibr3-0954411912463869"/><xref ref-type="bibr" rid="bibr4-0954411912463869"/>–<xref ref-type="bibr" rid="bibr5-0954411912463869">5</xref></sup> have led to the development of 3D imaging techniques, such as computed tomography (CT), magnetic resonance imaging (MRI), 3D stereophotogrammetry and surface optical scanning, which can assist clinicians through preoperative virtual simulations and quantitative diagnostic analyses taking into account both functional and aesthetical aspects. However, none of the existing imaging technologies is able to simultaneously capture the complete maxillofacial triad with optimal resolution and accuracy.<sup><xref ref-type="bibr" rid="bibr6-0954411912463869">6</xref></sup> This problem can be solved by a <italic>multi-modal fusion</italic> process based on integration of different imaging techniques.</p>
<p>This article aims at introducing a multi-modal framework to create accurate and complete <italic>maxillofacial triad</italic> models by fusing a structured light scanner and a cone-beam computed tomography (CBCT) process. In particular, a configurable stereo vision system, based on projecting structured light patterns, has been developed to capture accurate models of both dentition and facial skin. The underlying facial skeleton is reconstructed by processing a stack of two-dimensional (2D) images obtained by CBCT. The dentition model captured by the stereo vision system is also used as anatomical <italic>ground truth</italic> (objective reference model) to optimise the reconstruction of the same dental tissue from CBCT data. The dental CBCT model represents the reference to fuse facial skeleton (CBCT data) and dentition (optical scanner data) within a bi-modal reconstruction. The bi-modal representation is further augmented by including the soft facial tissue on the basis of a photogrammetric procedure integrated within the optical scanning process.</p>
<p>The methodology combines well-known imaging technologies for modelling individual maxillofacial tissues. The novelty consists of a reliable integration of different imaging processes within a multi-modal framework, which is guided and controlled by accurate reference models. In particular, complete maxillofacial triads are modelled by spatially referring individual anatomical tissues on the basis of constraints, which are accurately measured by a configurable stereo vision system. The multi-modal framework represents a valid support for various treatments of oral rehabilitation (from orthodontic planning to preoperatively surgical predictions).</p>
<p>In the following paragraphs, the 3D reconstruction methodologies are individually described. Moreover, the multi-modal imaging fusions are presented detailing the procedures from bi-modal representations to <italic>maxillofacial triads</italic>.</p>
</sec>
<sec id="section2-0954411912463869">
<title>Motivation and background</title>
<p>3D representations of facial soft tissue, facial skeleton and dentition have been of interest for a long time. Nowadays, imaging and fusion techniques play a fundamental role in creating multi-modal representations to be used for several treatments of oral rehabilitation. For example, patients with bone deformities need careful assessment of interdependencies between facial soft tissue surface, underlying maxillofacial skeleton and dento-alveolar position. Surgeons have to take into account both functional and aesthetical aspects of the osteotomies, since soft tissue modifications usually accompany skeletal alterations.<sup><xref ref-type="bibr" rid="bibr1-0954411912463869">1</xref></sup> In this context, a 3D virtual model including both geometrical and chromatic information could be a useful tool for accurate orthodontic diagnosis and careful preoperative osteotomy planning. Moreover, full assessment of relationships between bone structure, dentition and mouth soft tissues (gingiva) represents the basis for dental implant placement.</p>
<p>In the last few years, the field of oral and maxillofacial surgery has seen a growing interest in 3D imaging technologies.<sup><xref ref-type="bibr" rid="bibr2-0954411912463869">2</xref></sup></p>
<p>Multi-slice computed tomography (MSCT), CBCT and MRI provide digital imaging and communications in medicine (DICOM) data, which can be used to reconstruct 3D skeletal structures and digital dental models. In particular, the introduction of craniofacial CBCT has gained access to the creation of high quality 3D models through in-office scanning devices reducing ionising radiation with respect to traditional CT systems.</p>
<p>Tomographic scanning could be used to reconstruct both external (i.e. facial soft tissues and dentitions) and hard internal (i.e. skull, maxilla and mandible) tissues. However, CBCT data do not provide dentition structures with accuracy as required in some surgery applications (e.g. implant guided surgery). The presence of streak artefacts owing to metal restorations and/or orthodontic fixed appliances may significantly affect the accuracy of overall maxillofacial reconstructions. Moreover, chromatic information of facial tissues cannot be retrieved from CBCT data, and the head posture during the tomographic scanning can affect the facial skin morphology. Gravity effects, chin rest points and different resting positions of jawbones occurring when patients are in horizontal or upright scanning positions alter the reconstruction of soft tissues.</p>
<p>In recent years, technical literature has documented the use of stereophotogrammetric imaging systems for 3D morphological facial analyses. 3D photography allows skin surfaces and photorealistic textures of human faces to be simultaneously captured.<sup><xref ref-type="bibr" rid="bibr3-0954411912463869">3</xref>,<xref ref-type="bibr" rid="bibr4-0954411912463869">4</xref></sup></p>
<p>3D optical surface scanners<sup><xref ref-type="bibr" rid="bibr5-0954411912463869">5</xref></sup> represent a further technology to effectively overcome CBCT shortcomings, since accurate reconstructions of anatomical structures can be easily provided, even with textured information. Accurate replicas of patient’s teeth can be created by capturing dental impressions or plaster models through 3D optical technologies based on either laser or structured light projection. However, optical scanners allow 3D accurate reconstructions of visible surfaces, whereas skeleton internal anatomies cannot be digitised.</p>
<p>The functional analysis of the 3D medical imaging technologies points out that a single reconstruction method is not able to acquire all the maxillofacial information with the necessary accuracy. Therefore, different imaging techniques have to be integrated by means of <italic>multi-modal fusion</italic> processes.</p>
<p>Within orthodontic and orthognathic surgery, technical literature<sup><xref ref-type="bibr" rid="bibr6-0954411912463869">6</xref></sup> has been mainly focused on modelling pairwise data sets: <italic>facial skeleton–dentition, facial soft tissue–facial skeleton</italic> and <italic>facial soft tissue–dentition</italic>.</p>
<p><italic>Facial skeleton–dentition</italic> models can be obtained by integrating digital patient’s teeth captured by an optical scanner within bone models reconstructed by CBCT devices. This approach, which establishes an augmentation with improved visualisation of dentition, is carried out using point-based matching processes.<sup><xref ref-type="bibr" rid="bibr7-0954411912463869">7</xref><xref ref-type="bibr" rid="bibr8-0954411912463869"/><xref ref-type="bibr" rid="bibr9-0954411912463869"/><xref ref-type="bibr" rid="bibr10-0954411912463869"/>–<xref ref-type="bibr" rid="bibr11-0954411912463869">11</xref></sup></p>
<p>Textured facial data captured by stereophotogrammetry can be integrated with skin surfaces obtained from CBCT<sup><xref ref-type="bibr" rid="bibr12-0954411912463869">12</xref><xref ref-type="bibr" rid="bibr13-0954411912463869"/>–<xref ref-type="bibr" rid="bibr14-0954411912463869">14</xref></sup> and with dentition models obtained by optically scanning plaster casts<sup><xref ref-type="bibr" rid="bibr15-0954411912463869">15</xref>,<xref ref-type="bibr" rid="bibr16-0954411912463869">16</xref></sup> to obtain the following bi-modal representations: <italic>facial soft tissue–facial skeleton</italic> and <italic>facial soft tissue–dentition</italic>, respectively.</p>
<p>Although these methodologies represent effective steps towards multi-modal reconstructions, they are limited to fuse pairwise data sets, whereas a proposal to create a full <italic>maxillofacial model</italic> including soft tissues, dentition and bone structures in the correct anatomical position is still missing. Moreover, the quantitative analysis of accuracies provided by individual and multi-modal reconstructions still remains a matter of research.</p>
<p>The aim of the present article is the development of a multi-modal framework to create maxillofacial models, which include photorealistic descriptions of faces, facial skeletons and dentitions. The methodology is based on integrating structured light scanning and CBCT data processing (<xref ref-type="fig" rid="fig1-0954411912463869">Figure 1</xref>). Individual tissues are acquired by means of the most accurate imaging technology for each specific anatomical tissue. The fusion procedure provides multi-modal representations by aligning different tissues on the basis of spatial constraints (common anatomical areas).</p>
<fig id="fig1-0954411912463869" position="float">
<label>Figure 1.</label>
<caption>
<p>Workflow of 3D multi-modal composition to create maxillofacial models.</p>
<p>CBCT: cone-beam computed tomography.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig1.tif"/>
</fig>
</sec>
<sec id="section3-0954411912463869">
<title>3D image acquisition</title>
<sec id="section4-0954411912463869">
<title>Optical scanning</title>
<p>In this article, an optical acquisition system has been developed to reconstruct visible maxillofacial tissues (dentition and face). The technology is based on an active stereo vision approach using a binary coded lighting (fringe projection) to recover 3D views (point clouds) of target surfaces.</p>
<p>The optical set-up is based on a configurable layout composed of a colour DLP<sup>®</sup> projector (OPTOMA EX330e, resolution XGA 1024 × 768 pixels) and a 8-bit monochrome charge-coupled device (CCD) digital camera (The Imaging Source<sup>®</sup> DMK 41BF02, resolution 1280 × 960 pixels) equipped with a lens having focal length of 16 mm (PENTAX, C31634KP 2/3″ C-mount). The imaging devices can be assembled on two different stereo rigs set up for scanning dental models and human faces, respectively. Camera and projector are used as active devices of a stereo triangulation process. A calibration procedure is required to calculate the intrinsic and extrinsic parameters of the optical devices, with respect to an absolute reference system. The camera parameters are obtained by correlating the coordinates of known markers located on a calibrating plate with the corresponding coordinates on the camera image plane. The projector is modelled like an inverse camera, exploiting its capability to generate both coded vertical and horizontal fringes.<sup><xref ref-type="bibr" rid="bibr17-0954411912463869">17</xref></sup></p>
<p>In this study, a vertical binary encoded light stripe approach is used for 3D shape recovery. In particular, a sequence of vertical light planes is projected onto the target model (<xref ref-type="fig" rid="fig2-0954411912463869">Figure 2(a)</xref>). The planes are defined as crossing areas between black and white parallel fringes, whose periods are progressively halved along the temporal sequence. Each pixel in the camera images is characterised by a light intensity that can be either bright or dark depending on its location in the respective plane image. A binary code (0 and 1 with <italic>n</italic> bit) is assigned to each pixel, where <italic>n</italic> is the number of the projected stripe patterns, and the values 0 and 1 are associated with the intensity levels, that is, 0 = black and 1 = white. This encoding procedure provides <inline-formula id="inline-formula1-0954411912463869"><mml:math display="inline" id="math1-0954411912463869"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> encoded lines (<xref ref-type="fig" rid="fig2-0954411912463869">Figure 2(b)</xref>). The 3D coordinates of the observed scene point are computed by intersecting the optical ray with the plane considering that the geometry of the hardware set-up, the camera ray direction and the plane equation of the corresponding stripe are known. The methodology provides <italic>n<sub>p</sub></italic> = <italic>l<sub>h</sub></italic> × <italic>l<sub>v</sub></italic> encoded points, where <italic>l<sub>h</sub></italic> is the horizontal resolution of the projector and <italic>l<sub>v</sub></italic> is the vertical resolution of the camera.</p>
<fig id="fig2-0954411912463869" position="float">
<label>Figure 2.</label>
<caption>
<p>Optical scheme of the scanning process: (a) fringe projection and (b) binary coding.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig2.tif"/>
</fig>
<sec id="section5-0954411912463869">
<title>3D measurement of dental models</title>
<p>In the field of oral and maxillofacial treatments, digital dental models can be obtained by either plaster model acquisition or intra-oral scanning. However, intra-oral 3D optical scanners do not represent a clinical standard methodology for oral rehabilitation, in particular when full dental arches have to be captured. Only few devices are currently available on the market, while others are at a clinical testing stage. For this reason, digital reconstructions of plaster dental models still represent the most accurate replicas of patient dentitions,<sup><xref ref-type="bibr" rid="bibr18-0954411912463869">18</xref></sup> though the manufacturing process can be subjected to inherent inaccuracies due to impression and casting procedures.<sup><xref ref-type="bibr" rid="bibr19-0954411912463869">19</xref></sup></p>
<p>In this article, the optical scanner has been configured with the aim at digitising dental samples, such as dental casts and surgical guides. Dental models are characterised by continuously changing geometries with sharp edges (i.e. margin lines) and undercut surfaces. An optical measurement process is typically based on the combination of different partial views in order to capture complete shapes. The multi-view data are collected by moving the acquisition system and/or the target object and aligned with reference to a common coordinate system.</p>
<p>In this article, the 3D optical scanner has been integrated with a turntable having two motorised axes, which allows the automatic reconstruction of roughly axial-symmetric shapes. The vision system (<xref ref-type="fig" rid="fig3-0954411912463869">Figure 3</xref>) has been configured for a working distance of 300 mm and a working volume of 100 mm × 80 mm × 80 mm (width × height × depth). The turntable is equipped with a vertical axis (rotating axis) and a horizontal axis (tilting axis) driven by stepper motors having a resolution of 400 steps per round. The combination of two distinct controlled axes allows a better reproduction detail since different viewing directions minimise undercut areas.</p>
<fig id="fig3-0954411912463869" position="float">
<label>Figure 3.</label>
<caption>
<p>Scheme of the 3D optical dental scanner configured to capture dental models.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig3.tif"/>
</fig>
<p>Acquired point clouds are then aligned on the basis of a calibration procedure relating the turntable position with respect to an absolute reference system. This process consists of determining the transformation matrices associated with the turntable displacements with respect to the scanner reference system. The method is based on the knowledge of intrinsic and extrinsic parameters of the camera and exploits the same calibration target used for the vision system calibration. In particular, the procedure is based on solving the relation</p>
<p>
<disp-formula id="disp-formula1-0954411912463869">
<label>(1)</label>
<mml:math display="block" id="math2-0954411912463869">
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">m</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">P</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mo>·</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">w</mml:mi>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0954411912463869" xlink:href="10.1177_0954411912463869-eq1.tif"/>
</disp-formula>
</p>
<p>where <italic>k</italic> indicates the generic position of the calibration board, <bold><italic>m</italic></bold><sub><italic>k</italic></sub> is the 2D coordinate vector of markers on the camera sensor plane, <bold><italic>w</italic></bold><sub><italic>k</italic></sub> is the 3D coordinate vector of the same markers with reference to an absolute datum system (O<sub>CB</sub>, X<sub>CB</sub>, Y<sub>CB</sub>, Z<sub>CB</sub>, integral to the calibration board), and <bold><italic>P</italic></bold><sub><italic>k</italic></sub> is the perspective transformation matrix containing the intrinsic and extrinsic parameters of the camera. The method consists of the acquisition of a number of images with the calibration sample, integral with the rotary plate in different positions (<xref ref-type="fig" rid="fig4-0954411912463869">Figure 4</xref>). For each image, an iterative process solves the correlation <xref ref-type="disp-formula" rid="disp-formula1-0954411912463869">equation (1)</xref>, providing the rotation matrix and the translation vector (R<sub>C-CB</sub> and T<sub>C-CB</sub>) of the camera reference frame (O<sub>C</sub>, X<sub>C</sub>, Y<sub>C</sub> and Z<sub>C</sub>) with respect to the absolute reference frame (O<sub>CB</sub>, X<sub>CB</sub>, Y<sub>CB</sub> and Z<sub>CB</sub>). The calibration specimen is rotated around the controlled axes of the turntable by a number of predetermined values to obtain estimations of the movement parameters of the rotating (R<sub>rot</sub> and T<sub>rot</sub>) and tilting axes (R<sub>tilt</sub> and T<sub>tilt</sub>) with respect to the camera reference frame.</p>
<fig id="fig4-0954411912463869" position="float">
<label>Figure 4.</label>
<caption>
<p>Geometric scheme of calibration process of the rotating and tilting axes.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig4.tif"/>
</fig>
<p>The calibration of the rotating and tilt axes allows an automatic pre-alignment of point clouds captured in the dentition scanning process. A global alignment optimisation is then performed by minimising gaps in overlapping areas of adjacent point clouds through Iterative Closest Point (ICP) algorithms.<sup><xref ref-type="bibr" rid="bibr20-0954411912463869">20</xref></sup> Post-processing algorithms are performed in order to obtain manifold representations of the scanned target objects (<italic>StL</italic> representations). In particular, curvature-based re-sampling procedures allow removal of redundant information in low curvature regions.<sup><xref ref-type="bibr" rid="bibr21-0954411912463869">21</xref></sup></p>
<p>A test campaign has been carried out to assess the accuracy of the developed optical scanner. Three nominal samples have been designed using primitive surfaces (spherical, cylindrical and conical surfaces) in order to reproduce shape features (oblique surfaces, steep walls and sharp edges), which are typically present in dental models (<xref ref-type="fig" rid="fig5-0954411912463869">Figure 5</xref>). Moreover, each test sample has been differentiated by the angle of the conical surface representing the undercut (α = 15°, 30° and 45°). The nine samples have been made of polyaryletheretherketone (PEEK), an organic polymer providing good hardness and excellent optical properties. Each sample has been measured using a calibrated coordinate measurement machine (CMM), and the measurements of 24 different points have been compared with data obtained by the optical scanner. <xref ref-type="fig" rid="fig6-0954411912463869">Figure 6(a)</xref> shows the collected deviations for all the nine samples along with the mean values (continuous red lines), 95% confidence intervals for the mean values (red coloured area delimited by dashed black lines) and standard deviation values (blue coloured area delimited by continuous black lines). The point clouds (∼20,000 sample points) acquired by the optical scanner have been aligned to the respective nominal computer-aided design (CAD) models by best fitting techniques, and their deviations have been calculated. <xref ref-type="fig" rid="fig6-0954411912463869">Figure 6(b)</xref> shows the distributions of the deviations for all the test samples associated with the relative mean and standard deviation values. The experimental validations have proved that the accuracy of the optical scanner (mean = 0.01 mm and standard deviation = 0.02 mm) is approximately the same order of magnitude as the CMM. Moreover, the optical scanning results have demonstrated a low variability for the conformations A and B. On the contrary, higher spreads have occurred for the third conformation due to the higher undercut angles creating a sharp margin line, which is too smooth with respect to the nominal edge.</p>
<fig id="fig5-0954411912463869" position="float">
<label>Figure 5.</label>
<caption>
<p>Test samples used to verify the optical scanner accuracy in capturing dental models.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig5.tif"/>
</fig>
<fig id="fig6-0954411912463869" position="float">
<label>Figure 6.</label>
<caption>
<p>(a) CMM and (b) optical scanner measurements for the nine samples compared to the respective CAD models.</p>
<p>CMM: coordinate measurement machine; CAD: computer-aided design; OPT: optical.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig6.tif"/>
</fig>
<p>The integration between optical devices and two-axis mechanical tracker is able to automatically capture and reconstruct the full-field data of whole dental casts obtained from patients’ impressions. <xref ref-type="fig" rid="fig7-0954411912463869">Figure 7</xref> shows an example of a plaster model and its relative digital reconstruction.</p>
<fig id="fig7-0954411912463869" position="float">
<label>Figure 7.</label>
<caption>
<p>(a) Dental plaster cast and (b) digital reconstruction obtained by the optical scanner.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig7.tif"/>
</fig>
</sec>
<sec id="section6-0954411912463869">
<title>3D measurement of human faces</title>
<p>The structured lighting technology has also been adapted to acquire 3D textured facial data through a reconfiguration of the optical layout and the development of an RGB imaging reconstruction to capture chromatic information.</p>
<p>The imaging devices have been settled for a working distance of 900 mm and a scanning volume of 300 mm × 200 mm × 200 mm with a lateral resolution of about 0.3 mm. The scanning methodology has been further developed to allow the simultaneous acquisition of geometrical and chromatic data using the same imaging devices, that is, monochrome CCD camera and colour DLP projector. The colour scanning process is based on projecting sequentially both black and white fringe patterns, used for the geometrical reconstruction as previously described, and three blank images providing the primary colours: red, green and blue, respectively (<xref ref-type="fig" rid="fig8-0954411912463869">Figure 8</xref>). Moreover, the background is also acquired and subtracted from the three primary coloured images in order to reduce environmental lighting effects. The three primary channels are then composed into a unique RGB image. In particular, the grey levels acquired by the monochrome camera at each blank projection are directly used to create a virtual RGB image (<xref ref-type="fig" rid="fig9-0954411912463869">Figure 9</xref>). A consistent chromatic reconstruction is then obtained using a chart of colour patches,<sup><xref ref-type="bibr" rid="bibr22-0954411912463869">22</xref></sup> which provide the references of a stretching process.</p>
<fig id="fig8-0954411912463869" position="float">
<label>Figure 8.</label>
<caption>
<p>(a) Scheme of the optical facial scanner set-up and (b) fringe pattern projection during the 3D acquisition of a human face.</p>
<p>3D: three-dimensional.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig8.tif"/>
</fig>
<fig id="fig9-0954411912463869" position="float">
<label>Figure 9.</label>
<caption>
<p>Acquisition of blank images obtained by projecting the three primary colours, (a) red, (b) green, (c) blue and (d) corresponding reconstructed RGB image.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig9.tif"/>
</fig>
<p>The chromatic information is automatically mapped on the 3D model by assigning an RGB value to each measured 3D point. The acquisition process is very fast (less than 2 s), allowing the acquisition of non-static human subjects. Moreover, the colour mapping procedure does not need any external registration technique.</p>
<p><xref ref-type="fig" rid="fig10-0954411912463869">Figure 10</xref> shows the geometrical and chromatic reconstructions obtained by optically scanning male (<xref ref-type="fig" rid="fig10-0954411912463869">Figure 10(a)</xref> and <xref ref-type="fig" rid="fig10-0954411912463869">(b)</xref>) and female (<xref ref-type="fig" rid="fig10-0954411912463869">Figure 10(c)</xref> and <xref ref-type="fig" rid="fig10-0954411912463869">(d)</xref>) faces, respectively. The 3D acquisitions of human faces are taken in natural head position with open eyes, avoiding soft tissue stretching and representing natural face orientation for each treatment planning.</p>
<fig id="fig10-0954411912463869" position="float">
<label>Figure 10.</label>
<caption>
<p>3D reconstructions of (a) male and (c) female human faces along with (b) and (d) chromatic textures of (a) and (c), respectively.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig10.tif"/>
</fig>
</sec>
</sec>
<sec id="section7-0954411912463869">
<title>CBCT scanning</title>
<p>In the last few years, the introduction of CBCT technology has increased the feasibility of 3D-based pre-surgical planning for oral and maxillofacial surgeries. The cone-beam technique uses rotational scanning of an x-ray source and reciprocating x-ray detector around the patient’s head to produce multiple single projection images. CBCT provides images of diagnostic quality with reasonable lower radiation doses, shorter acquisition time and reduced costs with respect to MSCT.<sup><xref ref-type="bibr" rid="bibr23-0954411912463869">23</xref></sup></p>
<p>The CBCT images are stored in DICOM format and processed to generate cross-sectional visualisations (<xref ref-type="fig" rid="fig11-0954411912463869">Figure 11(a)</xref>) and volumetric representations of anatomical tissues (<xref ref-type="fig" rid="fig11-0954411912463869">Figure 11(b)</xref>). However, the accuracy of 3D models reconstructed from CBCT has not yet been thoroughly evaluated.<sup><xref ref-type="bibr" rid="bibr24-0954411912463869">24</xref></sup> Acquisition parameters and reconstruction settings influence the quality of the acquired images<sup><xref ref-type="bibr" rid="bibr25-0954411912463869">25</xref></sup> and the accuracy of the 3D reconstruction process. In particular, a volumetric representation is typically the result of a user-entered threshold value based on visually segmenting different tissues. Robustness and efficiency of the segmentation process are affected by many factors: image contrast, image noise and knowledge about anatomies.<sup><xref ref-type="bibr" rid="bibr26-0954411912463869">26</xref></sup></p>
<fig id="fig11-0954411912463869" position="float">
<label>Figure 11.</label>
<caption>
<p>(a) CBCT data in the axial, sagittal and coronal planes and (b) 3D reconstruction of the anatomical jawbones and dentition models.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig11.tif"/>
</fig>
<p>Many segmentation techniques have been developed with the aim at automating or facilitating the perception of anatomical structures and other regions of interest. Usually, standard procedures provide semi-automated segmentation methodologies that require the operator to interact with grey-level distributions by choosing threshold values or by manually tracing anatomical contours.<sup><xref ref-type="bibr" rid="bibr27-0954411912463869">27</xref></sup> However, visual perceptions could affect the final model accuracy, since grey intensity levels at crossing zones between bright and dark pixels do not typically present abrupt variations (<xref ref-type="fig" rid="fig12-0954411912463869">Figure 12</xref>). In these cases, user-driven segmentations could provide different volumetric reconstructions relying on subjective visual responses (<xref ref-type="fig" rid="fig13-0954411912463869">Figure 13</xref>).</p>
<fig id="fig12-0954411912463869" position="float">
<label>Figure 12.</label>
<caption>
<p>Jawbone CBCT axial plane slice associated with a row grey intensity level.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig12.tif"/>
</fig>
<fig id="fig13-0954411912463869" position="float">
<label>Figure 13.</label>
<caption>
<p>(a to c) Segmented axial images and (d to f) corresponding model reconstructions using three different threshold values defined by visual perception.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig13.tif"/>
</fig>
<p>In this article, CBCT data, obtained by the Planmeca<sup>®</sup> ProMax 3D imaging unit, are used to reconstruct skeleton and dentition models on the basis of two different approaches. DICOM images are processed by means of 3D Slicer, freely available open-source software.<sup><xref ref-type="bibr" rid="bibr28-0954411912463869">28</xref></sup></p>
<p>Facial skeletons are reconstructed by a traditional procedure based on user-entering threshold values and clustering volumetric regions of interest. The operator’s visual perception distinguishes between tissues with different densities, for example, soft and hard tissues. Skeleton models are reconstructed by a threshold filter, which assigns a binary value, either transparent or visible, to voxel elements on the basis of their grey-level values. The operator defines the critical value, which splits voxels into visible and transparent. Final results consist of 3D representations of skeleton tissues composed of all visible voxels.</p>
<p>In this article, the CBCT scanning is also used to reconstruct dentition anatomies in occlusion conditions. In this case, DICOM images are segmented using dentition models obtained through the optical scanning procedure, as <italic>ground truth</italic> of the CBCT reconstruction process. In particular, 3D CBCT dentition models are aligned to the <italic>ground truth</italic> using common points and refining the alignment by best fitting techniques. An optimal threshold value is computed in order to minimise gaps between digital models obtained by the different scanning technologies.</p>
<p>Final CBCT dentition anatomies are only used as references to fuse dentition models obtained by optically scanning plaster samples, and facial skeletons reconstructed from CBCT data. As detailed in the following paragraph, the overall procedure contextually provides the optimisation of the dentition CBCT reconstruction and the fusion of dentitions obtained by the optical scanner within facial skeleton structures.</p>
</sec>
</sec>
<sec id="section8-0954411912463869">
<title>Maxillofacial reconstruction by multi-modal image fusion</title>
<sec id="section9-0954411912463869">
<title>Dentition–facial skeleton reconstruction</title>
<p>The fusion between bone structures and dentition is operatively obtained on best fitting dental models reconstructed by optically scanning the plaster samples (<italic>ground truth</italic>) and equivalent CBCT data. As previously introduced, CBCT teeth are segmented by evaluating an <italic>optimal threshold value</italic> (τ<italic><sub>opt</sub></italic>) in order to minimise 3D discrepancies, which occur in aligning multi-modal dentition models. However, the result of the best fitting alignment for a <italic>threshold value</italic> (τ<italic><sub>i</sub></italic>) is influenced by the volumetric nature of CBCT data when compared to surface data provided by the optical scanner. In this article, the mating surfaces of CBCT models are iteratively selected by a progressive reduction of their <italic>distance value</italic> (δ<italic><sub>i</sub></italic>) from the <italic>ground truth</italic> surfaces. This avoids disturbances occurring in the best fitting alignment due to volumetric islands introduced by CBCT reconstructions. The methodology allows for removal of artefacts generated in the reconstruction of CBCT dentition models due to the presence of metallic restorations. When metallic dental fillings or orthodontic devices are present, the quality of tomographic scans is greatly reduced, providing poor reconstructions of dentition shapes in the surroundings of restorations. The <italic>ground truth</italic> models obtained by optically scanning plaster models are used to remove the corrupted information.</p>
<p><xref ref-type="fig" rid="fig14-0954411912463869">Figure 14(a)</xref> shows an example of complete dentition model, which has been obtained by segmenting CBCT images with an initial user-entered threshold value (τ<italic><sub>i</sub></italic>), and the corresponding superior dental arch as obtained by optically scanning the plaster model (<italic>ground truth</italic>) and aligned by best fitting algorithms setting an initial <italic>distance value δ</italic><sub>1</sub> = 3 mm. The relative full-field discrepancies are reported in <xref ref-type="fig" rid="fig14-0954411912463869">Figure 14(b)</xref>. Moreover, <xref ref-type="fig" rid="fig14-0954411912463869">Figure 14(c)</xref> and <xref ref-type="fig" rid="fig14-0954411912463869">(d)</xref>, and <xref ref-type="fig" rid="fig14-0954411912463869">Figure 14(e)</xref> and <xref ref-type="fig" rid="fig14-0954411912463869">14(f)</xref> show the results of iterative alignment refinements performed by selecting different mating surfaces through the reduction of the <italic>distance value</italic> from δ<sub>2</sub> = 1 mm to δ<sub>3</sub> = 0.8 mm, respectively. <xref ref-type="fig" rid="fig15-0954411912463869">Figure 15</xref> reports the mean discrepancy values µ<italic><sub>d</sub></italic> (<xref ref-type="fig" rid="fig15-0954411912463869">Figure 15(a)</xref>) and the standard deviation values σ<italic><sub>d</sub></italic> (<xref ref-type="fig" rid="fig15-0954411912463869">Figure 15(b)</xref>) obtained using different threshold values in the reconstruction of CBCT dentition models. The plots show the misalignment values obtained when CBCT mating surfaces with δ<sub>1</sub> = 3 mm (dotted red line), δ<sub>2</sub> = 1 mm (dashed blue line) and δ<sub>3</sub> = 0.8 mm (continuous black line) are used for best fitting alignment. The minimum mean discrepancy value is used to determine the optimal threshold value (τ<italic><sub>opt</sub></italic>).</p>
<fig id="fig14-0954411912463869" position="float">
<label>Figure 14.</label>
<caption>
<p>(a) Alignment of the superior dental arch onto the CBCT model, refinements using mating surfaces within (c) 1 mm and (e) 0.8 mm. Full-field deviations between the respective models are shown in (b), (d) and (f).</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig14.tif"/>
</fig>
<fig id="fig15-0954411912463869" position="float">
<label>Figure 15.</label>
<caption>
<p>(a) Mean discrepancy values and (b) standard deviation values obtained by comparing the <italic>ground truth</italic> model with CBCT dentition models of the superior arch (<xref ref-type="fig" rid="fig14-0954411912463869">Figure 14</xref>) obtained using different threshold values and three different <italic>distance values</italic>.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig15.tif"/>
</fig>
<p>The proposed methodology avoids subjective visual perceptions by guiding the operator in selecting optimal threshold values using the <italic>ground truth</italic> as surface target of the CBCT segmentation process.</p>
<p>3D dentition models derived from CBCT scanning are of utmost importance to provide the accurate occlusion dispositions of jawbones, avoiding inaccuracies of the face-bow standard transfer methodologies. The final structure consists of a bi-modal representation of facial skeleton (CBCT data) and accurate dentitions, obtained by optically scanning plaster samples, in the correct anatomical occlusion (<xref ref-type="fig" rid="fig16-0954411912463869">Figure 16</xref>).</p>
<fig id="fig16-0954411912463869" position="float">
<label>Figure 16.</label>
<caption>
<p>3D bi-modal representation of the facial skeleton augmented with the dentition anatomy in correct occlusion condition.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig16.tif"/>
</fig>
</sec>
<sec id="section10-0954411912463869">
<title>Maxillofacial triad reconstruction</title>
<p>Maxillofacial triads are obtained by further augmenting 3D <italic>dentition–facial skeleton</italic> representations through the fusion of skin models captured by optically scanning the patients’ faces in natural configurations (<xref ref-type="fig" rid="fig17-0954411912463869">Figure 17(a)</xref>). The procedure is based on aligning facial tissues to bi-modal representations. The alignment process uses the vestibular surfaces of externally visible teeth, which are acquired by further scanning patients wearing cheek retractors in occlusion conditions (<xref ref-type="fig" rid="fig17-0954411912463869">Figure 17(b)</xref>). The result of a face scanning process consists of 3D representations in natural (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(a)</xref> and <xref ref-type="fig" rid="fig18-0954411912463869">(b)</xref>) and open-lip (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(c)</xref> and <xref ref-type="fig" rid="fig18-0954411912463869">(d)</xref>) configurations.</p>
<fig id="fig17-0954411912463869" position="float">
<label>Figure 17.</label>
<caption>
<p>Patient’s face in (a) natural configuration and (b) wearing cheek retractors.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig17.tif"/>
</fig>
<fig id="fig18-0954411912463869" position="float">
<label>Figure 18.</label>
<caption>
<p>3D models of a patient’s face in (a) natural and (c) open-lip configurations along with (b) and (d) chromatic reconstructions of (a) and (c), respectively.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig18.tif"/>
</fig>
<p>The model in open-lip configuration is aligned to the bi-modal representation using the anterior teeth as references of a best fitting procedure. <xref ref-type="fig" rid="fig19-0954411912463869">Figure 19</xref> shows the discrepancies occurring by best fitting the vestibular surfaces of anterior dentition (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(c)</xref>) to the corresponding bi-modal representation.</p>
<fig id="fig19-0954411912463869" position="float">
<label>Figure 19.</label>
<caption>
<p>Discrepancies occurring by best fitting the vestibular surfaces of externally visible teeth of <xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(c)</xref> to the corresponding bi-modal representation.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig19.tif"/>
</fig>
<p>However, skin surfaces acquired with the cheek retractors are not appropriate for a correct evaluation of the face morphologies, since soft tissues are not relaxed. Therefore, 3D face models captured with patients in natural conditions have to be aligned to virtual faces acquired when cheek retractors are worn. The alignment is based on establishing the most invariant face areas when patients undergo mouth openings. In particular, 36 un-coded targets are used to monitor facial displacements (<xref ref-type="fig" rid="fig17-0954411912463869">Figure 17</xref>). The markers are distributed on facial skins in accordance with the following schemes:<sup><xref ref-type="bibr" rid="bibr29-0954411912463869">29</xref></sup></p>
<list id="list1-0954411912463869" list-type="bullet">
<list-item><p><italic>Front: tr</italic> trichion, <italic>eu</italic> euryon, <italic>ft</italic> frontotemporal, <italic>fz</italic> frontozygomaticus, <italic>g</italic> glabella;</p></list-item>
<list-item><p><italic>Nose: n</italic> nasion, <italic>prn</italic> pronasal, <italic>sn</italic> subnasal</p></list-item>
<list-item><p><italic>Chin: pg</italic> pogonion, <italic>gn</italic> gnathion, <italic>sl</italic> sublabial;</p></list-item>
<list-item><p><italic>Ear: sba</italic> subaurale;</p></list-item>
<list-item><p><italic>Lateral surface: chk</italic> cheeks, <italic>go</italic> gonion, <italic>t</italic> tragion, <italic>zy</italic> zygion.</p></list-item>
</list>
<p>Moreover, some more targets are placed in order to extensively cover the whole patient face:</p>
<list id="list2-0954411912463869" list-type="bullet">
<list-item><p><italic>Front</italic>: fr<sub>R1</sub>, fr<sub>R2</sub>, fr<sub>L1</sub>, fr<sub>L2</sub>;</p></list-item>
<list-item><p><italic>Nose</italic>: n<sub>F</sub>;</p></list-item>
<list-item><p><italic>Chin</italic>: me<sub>R</sub>, me<sub>L</sub>;</p></list-item>
<list-item><p><italic>Neck</italic>: ne<sub>F</sub>, ne<sub>R1</sub>, ne<sub>R2</sub>, ne<sub>L1</sub>, ne<sub>L2</sub>.</p></list-item>
</list>
<p>The markers placed on the target face are measured by the vision system used to acquire 3D facial data. The 2D coordinates of the marker centres are extracted from the camera image plane on the basis of automatic intensity-based analyses.<sup><xref ref-type="bibr" rid="bibr30-0954411912463869">30</xref></sup> The 3D coordinates are then computed by intersecting the optical ray with the projected light plane corresponding to the marker centre. This correspondence is straightforward since the camera image plane is punctually coded with the codification representing the coordinate values of the projected vertical fringes. The sub-pixel accuracy of the methodology is obtained by computing the projector light plane corresponding to the detected marker, by a linear interpolation of the horizontal codification at the centroid position.</p>
<p>The different anatomical face morphologies (with and without the cheek retractor) are aligned by automatically matching correspondent 3D landmarks. The midpoint of the forehead (<italic>trichion</italic>) is supposed to be the most invariable region under face shape changes caused by the check retractor. For this reason, the matching process is efficiently reduced to a search of the most unchanging landmarks by computing their linear distances from the <italic>tr</italic> target. The search is carried out by varying the tolerance ε of the differences between landmarks starting from a small value (ε = 0) to a maximum threshold (ε = 1 mm) until at least six invariant corresponding targets have been identified. A registration between the two skin surface data sets is then performed by means of best fitting techniques using only areas located around the changeless detected landmarks. <xref ref-type="fig" rid="fig20-0954411912463869">Figure 20</xref> shows the 3D comparison between the models of a patient’s face in natural (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(a)</xref>) and open-lip (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(b)</xref>) configurations. The comparison shows that the higher discrepancies occur at the mouth areas while the forehead, the nasofrontal suture, the most lateral points of the zygomatic arches and the ear lobes are quite invariant under mouth displacements. However, the invariant face regions are typically related to individual features. The adopted methodology is able to automatically determine individual patient’s invariant areas in order to adapt the references of the alignment process to the specific anatomical behaviour.</p>
<fig id="fig20-0954411912463869" position="float">
<label>Figure 20.</label>
<caption>
<p>3D comparison between models of a patient’s face in natural (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(a)</xref>) and open-lip (<xref ref-type="fig" rid="fig18-0954411912463869">Figure 18(c)</xref>) configurations.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig20.tif"/>
</fig>
<p>The final result (<xref ref-type="fig" rid="fig21-0954411912463869">Figure 21</xref>) is composed of the 3D data set of facial soft tissues with full dentitions placed in the correct anatomical position. The integration between hard and soft tissues is straightforward since no further alignment processes are required.</p>
<fig id="fig21-0954411912463869" position="float">
<label>Figure 21.</label>
<caption>
<p>3D maxillofacial reconstructions of (a) female and (b) male human patients.</p>
</caption>
<graphic xlink:href="10.1177_0954411912463869-fig21.tif"/>
</fig>
</sec>
</sec>
<sec id="section11-0954411912463869" sec-type="conclusions">
<title>Conclusion</title>
<p>The three maxillofacial tissues (facial soft tissue, facial skeleton and dentition) play a crucial role in several specialisations of oral rehabilitation. Recently, technological developments have led to different 3D imaging methodologies, which can be used to predict surgical and orthodontic outcomes. This can be only achieved by multi-modal fusion of different imaging processes, since none of the available technologies can capture the complete maxillofacial triad with optimal quality.</p>
<p>In this article, maxillofacial triads composed of textured facial soft tissue, facial skeleton and dentition are reconstructed by an innovative multi-modal fusion framework based on integrating CBCT and optical scanning. The fusion process allows the definition of maxillofacial triads using the proper imaging technologies for each anatomical tissue. In particular, CBCT scanning (low radiations) is used for capturing internal anatomies (skeleton) and dentitions to be used as reference of the fusion process. The optical scanning is used to reconstruct accurate models of dentitions and 3D face representations mapped with textured information.</p>
<p>The integration of different imaging techniques is based on procedures leading to a more objective assessment in the reconstruction of the final anatomical triad without requiring any knowledge in terms of both technical and clinical parameters.</p>
<p>The comparison between CBCT dentition data and optically captured dentition models guides and optimises the segmentation process of DICOM images, contextually cleaning up metal artefacts and tissues not belonging to the target structure. Moreover, the imaging fusion process takes into account all the correct placements between different anatomical tissues. The framework provides accurate dispositions of jawbones, correct clinical representations of the relationships between maxilla and mandible, and more natural postures of patients’ faces.</p>
<p>The virtual <italic>maxillofacial triad</italic> represents a valid support for both clinicians and surgeons in preoperative prediction and planning activities within oral rehabilitation. <xref ref-type="table" rid="table1-0954411912463869">Table 1</xref> summarises the relationships between virtual models and anatomical tissue, along with the relative clinical applications that could benefit of each combined model. The proposed framework provides complete and reliable 3D references to be used in maintaining oral functions and appearances by the restoration of natural teeth and/or the replacement of missing teeth and contiguous oral and maxillofacial tissues with artificial prostheses.</p>
<table-wrap id="table1-0954411912463869" position="float">
<label>Table 1.</label>
<caption>
<p>Correlation between virtual models, anatomical tissues and relative clinical applications.</p>
</caption>
<graphic alternate-form-of="table1-0954411912463869" xlink:href="10.1177_0954411912463869-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Virtual models</th>
<th align="left">Anatomical tissues</th>
<th align="left">Clinical applications</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dentition</td>
<td>Teeth and gingiva</td>
<td><italic>Prosthetic dentistry</italic> and <italic>orthodontics</italic></td>
</tr>
<tr>
<td>Dentition–facial skeleton</td>
<td>Teeth, gingiva and jawbones</td>
<td><italic>Guided implant surgery</italic></td>
</tr>
<tr>
<td>Dentition–facial soft tissue</td>
<td>Teeth, gingiva and facial tissue</td>
<td><italic>Advanced orthodontics</italic></td>
</tr>
<tr>
<td>Triad</td>
<td>Teeth, gingiva, jawbones and facial tissue</td>
<td><italic>Prostheses, orthodontics, guided implant surgery</italic> and <italic>orthognathic surgery</italic></td>
</tr>
</tbody>
</table>
</table-wrap>
<p>In this study, the accuracy of the overall system has been assessed by pairwise validations. Indeed, the particular morphology of the overall anatomical structure allows an experimental analysis of the process only limited to external individual tissues or some pairwise modelling. However, the proposed methodology intrinsically provides accurate placements between different anatomical tissues through pairwise fusion processes, since the procedure is guided and controlled by ground truth references. The overall model could be partially validated within clinical downstream applications, such as dental implant placement<sup><xref ref-type="bibr" rid="bibr31-0954411912463869">31</xref></sup> or orthognathic surgery test cases. However, the results of clinical analyses would assess both the 3D reconstruction process and the specific clinical practice, whereas individual measurements of the geometrical accuracy would be still missing.</p>
<p>The proposed methodology still includes some semi-automated steps, which requires a skilled operator to participate in setting up the vision devices and in pairwise referring external and internal tissues. The next challenge could be focused on fully automatising these activities in order to make 3D virtual imaging implementable in daily practice, even by clinicians who still have a conservative attitude and a predilection towards traditional methods.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This study was supported by Tuscany Region of Italy within the SMILE project (POR CREO FESR 2007-2013 lines 1.1 e 1.6 – Line A, 2010).</p>
</fn>
<fn fn-type="conflict">
<label>Conflict of interest statement</label>
<p>The authors declare that there is no conflict of interest.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0954411912463869">
<label>1.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Swennen</surname><given-names>GR</given-names></name>
<name><surname>Mollemans</surname><given-names>W</given-names></name>
<name><surname>Schutyser</surname><given-names>F</given-names></name>
</person-group>. <article-title>Three-dimensional treatment planning of orthognathic surgery in the era of virtual imaging</article-title>. <source>J Oral Maxillofac Surg</source> <year>2009</year>; <volume>67</volume>: <fpage>2080</fpage>–<lpage>2092</lpage>.</citation>
</ref>
<ref id="bibr2-0954411912463869">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kau</surname><given-names>CH</given-names></name>
<name><surname>Richmond</surname><given-names>S</given-names></name>
<name><surname>Incrapera</surname><given-names>A</given-names></name><etal/>
</person-group>. <article-title>Three-dimensional surface acquisition systems for the study of facial morphology and their application to maxillofacial surgery</article-title>. <source>Int J Med Robot</source> <year>2007</year>; <volume>3</volume>(<issue>2</issue>): <fpage>97</fpage>–<lpage>110</lpage>.</citation>
</ref>
<ref id="bibr3-0954411912463869">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ayoub</surname><given-names>A</given-names></name>
<name><surname>Garrahy</surname><given-names>A</given-names></name>
<name><surname>Hood</surname><given-names>C</given-names></name><etal/>
</person-group>. <article-title>Validation of a vision-based, three-dimensional facial imaging system</article-title>. <source>Cleft Palate Craniofac J</source> <year>2003</year>; <volume>40</volume>(<issue>5</issue>): <fpage>523</fpage>–<lpage>529</lpage>.</citation>
</ref>
<ref id="bibr4-0954411912463869">
<label>4.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aldridge</surname><given-names>K</given-names></name>
<name><surname>Boyadjiev</surname><given-names>SA</given-names></name>
<name><surname>Capone</surname><given-names>GT</given-names></name><etal/>
</person-group>. <article-title>Precision and error of three-dimensional phenotypic measures acquired from 3dMD photogrammetric images</article-title>. <source>Am J Med Genet A</source> <year>2005</year>; <volume>138</volume>(<issue>3</issue>): <fpage>247</fpage>–<lpage>253</lpage>.</citation>
</ref>
<ref id="bibr5-0954411912463869">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kau</surname><given-names>CH</given-names></name>
<name><surname>Richmond</surname><given-names>S</given-names></name>
<name><surname>Zhurov</surname><given-names>AI</given-names></name><etal/>
</person-group>. <article-title>Reliability of measuring facial morphology with a 3-dimensional laser scanning system</article-title>. <source>Am J Orthod Dentofacial Orthop</source> <year>2005</year>; <volume>128</volume>(<issue>4</issue>): <fpage>424</fpage>–<lpage>430</lpage>.</citation>
</ref>
<ref id="bibr6-0954411912463869">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Plooij</surname><given-names>JM</given-names></name>
<name><surname>Maal</surname><given-names>TJ</given-names></name>
<name><surname>Haers</surname><given-names>P</given-names></name><etal/>
</person-group>. <article-title>Digital three-dimensional image fusion processes for planning and evaluating orthodontics and orthognathic surgery. A systematic review</article-title>. <source>Int J Oral Maxillofac Surg</source> <year>2011</year>; <volume>40</volume>(<issue>4</issue>): <fpage>341</fpage>–<lpage>352</lpage>.</citation>
</ref>
<ref id="bibr7-0954411912463869">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gateno</surname><given-names>J</given-names></name>
</person-group>. <article-title>A new technique for the creation of a computerized composite skull model</article-title>. <source>J Oral Maxillofac Surg</source> <year>2003</year>; <volume>61</volume>(<issue>2</issue>): <fpage>222</fpage>–<lpage>227</lpage>.</citation>
</ref>
<ref id="bibr8-0954411912463869">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Uechi</surname><given-names>J</given-names></name>
<name><surname>Okayama</surname><given-names>M</given-names></name>
<name><surname>Shibata</surname><given-names>T</given-names></name><etal/>
</person-group>. <article-title>A novel method for the 3-dimensional simulation of orthognathic surgery by using a multimodal image-fusion technique</article-title>. <source>Am J Orthod Dentofacial Orthop</source> <year>2006</year>; <volume>130</volume>(<issue>6</issue>): <fpage>786</fpage>–<lpage>798</lpage>.</citation>
</ref>
<ref id="bibr9-0954411912463869">
<label>9.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Swennen</surname><given-names>GR</given-names></name>
<name><surname>Barth</surname><given-names>EL</given-names></name>
<name><surname>Eulzer</surname><given-names>C</given-names></name><etal/>
</person-group>. <article-title>The use of a new 3D splint and double CT scan procedure to obtain an accurate anatomic virtual augmented model of the skull</article-title>. <source>Int J Oral Maxillofac Surg</source> <year>2007</year>; <volume>36</volume>(<issue>2</issue>): <fpage>146</fpage>–<lpage>152</lpage>.</citation>
</ref>
<ref id="bibr10-0954411912463869">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schutyser</surname><given-names>F</given-names></name>
<name><surname>Swennen</surname><given-names>G</given-names></name>
<name><surname>Suetens</surname><given-names>P</given-names></name>
</person-group>. <article-title>Robust visualization of the dental occlusion by a double scan procedure</article-title>. <source>Med Image Comput Comput Assist Interv</source> <year>2005</year>; <volume>8</volume>(<issue>1</issue>): <fpage>168</fpage>–<lpage>374</lpage>.</citation>
</ref>
<ref id="bibr11-0954411912463869">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nkenke</surname><given-names>E</given-names></name>
<name><surname>Zachow</surname><given-names>S</given-names></name>
<name><surname>Benz</surname><given-names>M</given-names></name><etal/>
</person-group>. <article-title>Fusion of computed tomography data and optical 3D images of the dentition for streak artefact correction in the simulation of orthognathic surgery</article-title>. <source>Dentomaxillofac Radiol</source> <year>2004</year>; <volume>33</volume>(<issue>4</issue>): <fpage>226</fpage>–<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr12-0954411912463869">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Maal</surname><given-names>TJ</given-names></name>
<name><surname>Plooij</surname><given-names>JM</given-names></name>
<name><surname>Rangel</surname><given-names>FA</given-names></name><etal/>
</person-group>. <article-title>The accuracy of matching three-dimensional photographs with skin surfaces derived from cone-beam computed tomography</article-title>. <source>Int J Oral Maxillofac Surg</source> <year>2008</year>; <volume>37</volume>(<issue>7</issue>): <fpage>641</fpage>–<lpage>646</lpage>.</citation>
</ref>
<ref id="bibr13-0954411912463869">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Khambay</surname><given-names>B</given-names></name>
<name><surname>Nebel</surname><given-names>JC</given-names></name>
<name><surname>Bowman</surname><given-names>J</given-names></name><etal/>
</person-group>. <article-title>3D stereophotogrammetric image superimposition onto 3D CT scan images: the future of orthognathic surgery. A pilot study</article-title>. <source>Int J Adult Orthodon Orthognath Surg</source> <year>2002</year>; <volume>17</volume>(<issue>4</issue>): <fpage>331</fpage>–<lpage>341</lpage>.</citation>
</ref>
<ref id="bibr14-0954411912463869">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ayoub</surname><given-names>AF</given-names></name>
<name><surname>Xiao</surname><given-names>Y</given-names></name>
<name><surname>Khambay</surname><given-names>B</given-names></name><etal/>
</person-group>. <article-title>Towards building a photo-realistic virtual human face for craniomaxillofacial diagnosis and treatment planning</article-title>. <source>Int J Oral Maxillofac Surg</source> <year>2007</year>; <volume>36</volume>(<issue>5</issue>): <fpage>423</fpage>–<lpage>428</lpage>.</citation>
</ref>
<ref id="bibr15-0954411912463869">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rangel</surname><given-names>FA</given-names></name>
<name><surname>Maal</surname><given-names>TJ</given-names></name>
<name><surname>Bergé</surname><given-names>SJ</given-names></name><etal/>
</person-group>. <article-title>Integration of digital dental casts in 3-dimensional facial photographs</article-title>. <source>Am J Orthod Dentofacial Orthop</source> <year>2008</year>; <volume>134</volume>(<issue>6</issue>): <fpage>820</fpage>–<lpage>826</lpage>.</citation>
</ref>
<ref id="bibr16-0954411912463869">
<label>16.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosati</surname><given-names>R</given-names></name>
<name><surname>De Menezes</surname><given-names>M</given-names></name>
<name><surname>Rossetti</surname><given-names>A</given-names></name><etal/>
</person-group>. <article-title>Digital dental cast placement in 3-dimensional, full-face reconstruction: a technical evaluation</article-title>. <source>Am J Orthod Dentofacial Orthop</source> <year>2010</year>; <volume>138</volume>(<issue>1</issue>): <fpage>84</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr17-0954411912463869">
<label>17.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barone</surname><given-names>S</given-names></name>
<name><surname>Paoli</surname><given-names>A</given-names></name>
<name><surname>Razionale</surname><given-names>AV</given-names></name>
</person-group>. <article-title>Assessment of chronic wounds by three-dimensional optical imaging based on integrating geometrical, chromatic, and thermal data</article-title>. <source>Proc IMechE, Part H: J Engineering in Medicine</source> <year>2011</year>; <volume>225</volume>(<issue>2</issue>): <fpage>181</fpage>–<lpage>193</lpage>.</citation>
</ref>
<ref id="bibr18-0954411912463869">
<label>18.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Keating</surname><given-names>AP</given-names></name>
<name><surname>Knox</surname><given-names>J</given-names></name>
<name><surname>Bibb</surname><given-names>R</given-names></name><etal/>
</person-group>. <article-title>A comparison of plaster, digital and reconstructed study model accuracy</article-title>. <source>J Orthod</source> <year>2008</year>; <volume>35</volume>: <fpage>191</fpage>–<lpage>201</lpage>.</citation>
</ref>
<ref id="bibr19-0954411912463869">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Popat</surname><given-names>H</given-names></name>
<name><surname>Richmond</surname><given-names>S</given-names></name>
<name><surname>Drage</surname><given-names>NA</given-names></name>
</person-group>. <article-title>New developments in: three-dimensional planning for orthognathic surgery</article-title>. <source>J Orthod</source> <year>2010</year>; <volume>37</volume>(<issue>1</issue>): <fpage>62</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr20-0954411912463869">
<label>20.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Rusinkiewicz</surname><given-names>S</given-names></name>
<name><surname>Levoy</surname><given-names>M</given-names></name>
</person-group>. <article-title>Efficient variants of the ICP algorithm</article-title>. In: <conf-name>Proceedings of the 3rd international conference 3D digital imaging and modeling</conf-name>, <conf-loc>Quebec City, Canada</conf-loc>, <conf-date>28 May - 1 June 2001</conf-date>, pp. <fpage>145</fpage>-<lpage>152</lpage>. <publisher-name>IEEE Computer Society</publisher-name>, <year>2001</year>.</citation>
</ref>
<ref id="bibr21-0954411912463869">
<label>21.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Carassale</surname><given-names>L</given-names></name>
<name><surname>Eljaarani</surname><given-names>M</given-names></name>
<name><surname>Paoli</surname><given-names>A</given-names></name><etal/>
</person-group>. <article-title>Uniform and non-uniform simplification of 3D point cloud data (PCD) sets obtained by reverse engineering systems</article-title>. In: <conf-name>Proceedings of the XVII INGEGRAF – XV ADM</conf-name>, <conf-loc>Seville, Spain</conf-loc>, <conf-date>1–3 June</conf-date> <year>2005</year>. <publisher-name>INGEGRAF</publisher-name>.</citation>
</ref>
<ref id="bibr22-0954411912463869">
<label>22.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCamy</surname><given-names>CS</given-names></name>
<name><surname>Marcus</surname><given-names>H</given-names></name>
<name><surname>Davidson</surname><given-names>JG</given-names></name>
</person-group>. <article-title>A color-rendition chart</article-title>. <source>J Appl Photogr Eng</source> <year>1976</year>; <volume>2</volume>(<issue>3</issue>): <fpage>95</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr23-0954411912463869">
<label>23.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>De Vos</surname><given-names>W</given-names></name>
<name><surname>Casselman</surname><given-names>J</given-names></name>
<name><surname>Swennen</surname><given-names>GRJ</given-names></name>
</person-group>. <article-title>Cone-beam computerized tomography (CBCT) imaging of the oral and maxillofacial region: a systematic review of the literature</article-title>. <source>Int J Oral Maxillofac Surg</source> <year>2009</year>; <volume>38</volume>: <fpage>609</fpage>–<lpage>625</lpage>.</citation>
</ref>
<ref id="bibr24-0954411912463869">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liang</surname><given-names>X</given-names></name>
<name><surname>Lambrichts</surname><given-names>I</given-names></name>
<name><surname>Sun</surname><given-names>Y</given-names></name><etal/>
</person-group>. <article-title>A comparative evaluation of cone beam computed tomography (CBCT) and multi-slice CT (MSCT). Part II: on 3D model accuracy</article-title>. <source>Eur J Radiol</source> <year>2010</year>; <volume>75</volume>(<issue>2</issue>): <fpage>270</fpage>–<lpage>274</lpage>.</citation>
</ref>
<ref id="bibr25-0954411912463869">
<label>25.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Loubele</surname><given-names>M</given-names></name>
<name><surname>Jacobs</surname><given-names>R</given-names></name>
<name><surname>Maes</surname><given-names>F</given-names></name><etal/>
</person-group>. <article-title>Image quality vs radiation dose of four cone beam computed tomography scanners</article-title>. <source>Dentomaxillofac Radiol</source> <year>2008</year>; <volume>37</volume>(<issue>6</issue>): <fpage>309</fpage>–<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr26-0954411912463869">
<label>26.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Loubele</surname><given-names>M</given-names></name>
<name><surname>Maes</surname><given-names>F</given-names></name>
<name><surname>Schutyser</surname><given-names>F</given-names></name><etal/>
</person-group>. <article-title>Assessment of bone segmentation quality of cone-beam CT versus multislice spiral CT: a pilot study</article-title>. <source>Oral Surg Oral Med Oral Pathol Oral Radiol Endod</source> <year>2006</year>; <volume>102</volume>(<issue>2</issue>): <fpage>225</fpage>–<lpage>234</lpage>.</citation>
</ref>
<ref id="bibr27-0954411912463869">
<label>27.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ma</surname><given-names>Z</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
<name><surname>Jorge</surname><given-names>RN</given-names></name><etal/>
</person-group>. <article-title>A review of algorithms for medical image segmentation and their applications to the female pelvic cavity</article-title>. <source>Comput Methods Biomech Biomed Engin</source> <year>2010</year>; <volume>13</volume>(<issue>2</issue>): <fpage>235</fpage>–<lpage>246</lpage>.</citation>
</ref>
<ref id="bibr28-0954411912463869">
<label>28.</label>
<citation citation-type="web">
<article-title>3D Slicer (version 3.6)</article-title>, <ext-link ext-link-type="uri" xlink:href="http://www.slicer.org">www.slicer.org</ext-link> (<access-date>accessed 2 August 2012</access-date>).</citation>
</ref>
<ref id="bibr29-0954411912463869">
<label>29.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Farkas</surname><given-names>L</given-names></name>
</person-group>. <source>Anthropometry of the head and face</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Raven Press</publisher-name>, <year>1994</year>.</citation>
</ref>
<ref id="bibr30-0954411912463869">
<label>30.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barone</surname><given-names>S</given-names></name>
<name><surname>Paoli</surname><given-names>A</given-names></name>
<name><surname>Razionale</surname><given-names>AV</given-names></name>
</person-group>. <article-title>Three-dimensional point cloud alignment detecting fiducial markers by structured light stereo imaging</article-title>. <source>Mach Vision Appl</source> <year>2012</year>; <volume>23</volume>(<issue>2</issue>): <fpage>217</fpage>–<lpage>229</lpage>.</citation>
</ref>
<ref id="bibr31-0954411912463869">
<label>31.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Paoli</surname><given-names>A</given-names></name>
<name><surname>Razionale</surname><given-names>AV</given-names></name>
</person-group>. <article-title>A CAD-based methodology for dental implant surgery</article-title>. In: <conf-name>Proceedings of the 18th international conference on virtual systems and multimedia (VSMM 2012), Virtual Systems in the Information Society</conf-name>, <conf-loc>Milan, Italy</conf-loc>, <conf-date>2–5 September</conf-date> <year>2012</year>, pp.<fpage>445</fpage>–<lpage>451</lpage>. <publisher-name>IEEEXplore digital library</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>