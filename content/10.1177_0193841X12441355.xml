<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ERX</journal-id>
<journal-id journal-id-type="hwp">sperx</journal-id>
<journal-id journal-id-type="nlm-ta">Eval Rev</journal-id>
<journal-title>Evaluation Review</journal-title>
<issn pub-type="ppub">0193-841X</issn>
<issn pub-type="epub">1552-3926</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0193841X12441355</article-id>
<article-id pub-id-type="publisher-id">10.1177_0193841X12441355</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Class Attendance and Students’ Evaluations of Teaching</article-title>
<subtitle>Do No-Shows Bias Course Ratings and Rankings?</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Wolbring</surname>
<given-names>Tobias</given-names>
</name>
<xref ref-type="aff" rid="aff1-0193841X12441355">1</xref>
<xref ref-type="corresp" rid="corresp1-0193841X12441355"/>
</contrib>
<bio>
<p>
<bold>Tobias Wolbring</bold> is a doctoral student in Sociology at the Ludwig-Maximilians-University Munich, Germany. His research interests include students’ evaluations of teaching, causal inference (especially experiments and panel data), and economic sociology.</p>
</bio>
</contrib-group>
<aff id="aff1-0193841X12441355">
<label>1</label>Institute of Sociology, Ludwig-Maximilians-University Munich, Munich, Germany</aff>
<author-notes>
<corresp id="corresp1-0193841X12441355">Tobias Wolbring, Institute of Sociology, Ludwig-Maximilians-University Munich, Konradstr, 6, Munich 80801, Germany Email: <email>tobias.wolbring@soziologie.uni-muenchen.de</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2012</year>
</pub-date>
<volume>36</volume>
<issue>1</issue>
<fpage>72</fpage>
<lpage>96</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>
<italic>Background:</italic> Many university departments use students’ evaluations of teaching (SET) to compare and rank courses. However, absenteeism from class is often nonrandom and, therefore, SET for different courses might not be comparable. <italic>Objective:</italic> The present study aims to answer two questions. Are SET positively biased due to absenteeism? Do procedures, which adjust for absenteeism, change course rankings? <italic>Research Design:</italic> The author discusses the problem from a missing data perspective and present empirical results from regression models to determine which factors are simultaneously associated with students’ class attendance and course ratings. In order to determine the extent of these biases, the author then corrects average ratings for students’ absenteeism and inspect changes in course rankings resulting from this adjustment. <italic>Subjects:</italic> The author analyzes SET data on the individual level. One or more course ratings are available for each student. <italic>Measures:</italic> Individual course ratings and absenteeism served as the key outcomes. <italic>Results:</italic> Absenteeism decreases with rising teaching quality. Furthermore, both factors are systematically related to student and course attributes. Weighting students’ ratings by actual absenteeism leads to mostly small changes in ranks, which follow a power law. Only a few, average courses are disproportionally influenced by the adjustment. Weighting by predicted absenteeism leads to very small changes in ranks. Again, average courses are more strongly affected than courses of very high or low in quality. <italic>Conclusions:</italic> No-shows bias course ratings and rankings. SET are more appropriate to identify high- and low-quality courses than to determine the exact ranks of average courses.</p>
</abstract>
<kwd-group>
<kwd>absenteeism</kwd>
<kwd>course rankings</kwd>
<kwd>missing data</kwd>
<kwd>sample selection bias</kwd>
<kwd>students’ evaluations of teaching</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0193841X12441355">
<title>Introduction</title>
<p>Students’ evaluations of teaching (SET) are a widely used instrument to assure and foster teaching quality at universities around the globe. More specifically, many departments do not only report SET results to the faculty but also use average course ratings to compare and rank courses. Meanwhile, even decisions about merit pay, tenure, payment-related budgeting, and teaching awards (not only in the United States but also in Asia, Australia, and Europe) are based on these measures of teaching quality (<xref ref-type="bibr" rid="bibr24-0193841X12441355">Hénard 2010</xref>; <xref ref-type="bibr" rid="bibr50-0193841X12441355">Wilkesmann and Schmid 2011</xref>). Thus, SET are a central component of a New Public Management in higher education (<xref ref-type="bibr" rid="bibr13-0193841X12441355">de Boer, Endres, and Schimank 2007</xref>; <xref ref-type="bibr" rid="bibr31-0193841X12441355">Lane and Kivisto 2008</xref>; <xref ref-type="bibr" rid="bibr47-0193841X12441355">Sporn 2011</xref>), whereby the wide use of SET is implicitly based on at least three empirical assumptions:<list list-type="simple">
<list-item>
<p>
<italic>Assumption 1:</italic> SET are valid measures (of students’ perception)<sup>
<xref ref-type="fn" rid="fn1-0193841X12441355">1</xref>
</sup> of teaching quality.</p>
</list-item>
<list-item>
<p>
<italic>Assumption 2</italic>: SET are fair measures (of students’ perception) of teaching quality.</p>
</list-item>
<list-item>
<p>
<italic>Assumption 3</italic>: The quality of different courses (as perceived by the students) can be compared based on SET.</p>
</list-item>
</list>In this article, we focus on the effects of students’ attendance on SET and test all three assumptions:<sup>
<xref ref-type="fn" rid="fn2-0193841X12441355">2</xref>
</sup> Assumption 1 would be challenged, if SET were systematically biased by the absence of less interested and dissatisfied students—a so-called sample selection bias (<xref ref-type="bibr" rid="bibr55-0193841X12441355">Becker and Walstad 1990</xref>; <xref ref-type="bibr" rid="bibr23-0193841X12441355">Heckman 1979</xref>) or problem of nonignorable missing data (<xref ref-type="bibr" rid="bibr32-0193841X12441355">Little and Rubin 1987</xref>; <xref ref-type="bibr" rid="bibr46-0193841X12441355">Rubin 1976</xref>). The fundamental consequence of such a nonrandom data loss is that the measure does not solely measure what it is intended to measure, namely teaching quality.</p>
<p>Furthermore, if factors, which teachers can hardly control (e.g., students’ employment, their leisure activities, number of courses taken, weekday and time of the course, weather), influence absenteeism and (mediated by this) SET, then the fairness of the procedure (Assumption 2) is also questionable. In this case, the mean rating of a course could be worse (than an SET of a course similar in quality), simply because the evaluation takes place during a sunny Friday morning, when especially interested or satisfied students are absent.<sup>
<xref ref-type="fn" rid="fn3-0193841X12441355">3</xref>
</sup>
</p>
<p>Finally, if absenteeism rates strongly vary between courses and are correlated with teaching quality, measurement biases could not only lead to imprecise course <italic>ratings</italic> but also to incorrect course <italic>rankings</italic>. In that case, Assumption 3 would be wrong and, therefore, one should not compare SET of different courses—at least as long as SET are not adjusted for differential absenteeism and dropout.<sup>
<xref ref-type="fn" rid="fn4-0193841X12441355">4</xref>
</sup>
</p>
<p>We further develop our argument in four steps: First, we discuss the problem from a missing data perspective and motivate our empirical analyses. Having explained our research strategy and the SET data used, we present empirical results from regression models to determine which factors are simultaneously associated with students’ class attendance and SET. In order to determine the extent of these biases, we then correct average ratings for actual or predicted student absenteeism and inspect changes in course rankings resulting from this adjustment. We will close with some general conclusions from these results for SET and give specific recommendations for the use of course rankings based on SET.</p>
</sec>
<sec id="section2-0193841X12441355">
<title>Students’ Absenteeism As a Case of Missing Data</title>
<p>The fact that some students are absent when the SET takes place can be regarded as a problem of missing data. One does not know how those students would have rated were they present. In their seminal book, <xref ref-type="bibr" rid="bibr32-0193841X12441355">Little and Rubin (1987</xref>; see also <xref ref-type="bibr" rid="bibr46-0193841X12441355">Rubin 1976</xref>) distinguish three missing data mechanisms: missing completely at random (MCAR), missing at random (MAR), and not missing at random (NMAR). NMAR refers to a situation, where the missing data mechanism is systematically related to variables of interest <bold>
<italic>Y</italic>
</bold>, even after controlling for other variables <bold>
<italic>X</italic>
</bold>. In contrast to that, data are MAR, if the probability of missing values is related to other variables <bold>
<italic>X</italic>
</bold>, but not directly to the outcome <italic>Y</italic>. In other words, <italic>Y</italic> is conditionally independent from the process of data loss. Finally, MCAR refers to the case of unconditional independence. In this case, missing values in the data set can be regarded as the result of a simple random process. Obviously, this is the most desirable type of missingness. However, in practice, the MCAR assumption almost never holds, whereas cases of MAR and NMAR are far more common. The same is true for students’ ratings of teaching quality.</p>
<p>In the case of SET, the MAR assumption would hold, if after controlling for all factors, which simultaneously affect course attendance and SET ratings, both variables were unrelated. Clearly, the plausibility of the MAR assumption and the success of any adjustment critically depend on the covariate selection. Therefore, ideally one would take into account all relevant information about both those students, who completed the SET, and those who did not. However, we have no information on absent students in our data. Therefore, we have to rely on the bold assumption that we have identified all (or at least the most important) variables, which simultaneously influence attendance and SET ratings.</p>
<p>The tenability of this MAR assumption is at least worthy of discussion, since, even after partialling out the effects of all selected covariates, one might still suspect a nonignorable nonresponse leading to biased estimates. First, one can never be sure to have identified all relevant variables. Second, course attendance, performance, and SET ratings seem to be directly related (<xref ref-type="bibr" rid="bibr4-0193841X12441355">Babad, Icekson, and Yelinek 2008</xref>; <xref ref-type="bibr" rid="bibr6-0193841X12441355">Berger and Schleußner 2003</xref>). And third, students dropping class or withdrawing from studies are probably not comparable to those, who miss a significant part of the course, but finish it. Especially, it appears quite plausible that dropouts would evaluate the quality of a course worse than infrequent visitors do. We are not aware of any study which explores this specific hypothesis. However, research shows that dissatisfied and low performing students have a higher propensity to drop class (<xref ref-type="bibr" rid="bibr8-0193841X12441355">Bosshardt 2004</xref>; <xref ref-type="bibr" rid="bibr16-0193841X12441355">Dobkin, Gill, and Marion 2007</xref>; <xref ref-type="bibr" rid="bibr43-0193841X12441355">Reed 1981</xref>) and withdraw from studies (<xref ref-type="bibr" rid="bibr48-0193841X12441355">Thomas, Adams, and Birchenough 1996</xref>; <xref ref-type="bibr" rid="bibr49-0193841X12441355">Tinto 1993</xref>; <xref ref-type="bibr" rid="bibr53-0193841X12441355">Yorke 1999</xref>).</p>
<p>As becomes clear from this discussion, one cannot formally test whether the data are MAR. However, one can perform calculations and analyses that provide some insight. For example, one can check whether the data are MCAR by determining whether missingness is related to variables that likely predict outcomes as well. Prior research suggests that these variables might include course and instructor characteristics such as course size, mandatory attendance rules, difficulty of course contents, weekday and time of the course, and physical attractiveness of the instructor (e.g., <xref ref-type="bibr" rid="bibr3-0193841X12441355">Arulampalam, Naylor, and Smith 2008</xref>; <xref ref-type="bibr" rid="bibr5-0193841X12441355">Becker and Powers 2001</xref>; <xref ref-type="bibr" rid="bibr8-0193841X12441355">Bosshardt 2004</xref>; <xref ref-type="bibr" rid="bibr15-0193841X12441355">Devadoss and Foltz 1996</xref>; <xref ref-type="bibr" rid="bibr22-0193841X12441355">Hamermesh and Parker 2005</xref>; <xref ref-type="bibr" rid="bibr51-0193841X12441355">Wolbring 2010</xref>). Moreover, students’ individual dispositions, prior interest in the course content, general study motivation, grades, courseload, and workload appear to be important predictors of attendance and course ratings (<xref ref-type="bibr" rid="bibr5-0193841X12441355">Becker and Powers 2001</xref>; <xref ref-type="bibr" rid="bibr6-0193841X12441355">Berger and Schleußner 2003</xref>; <xref ref-type="bibr" rid="bibr15-0193841X12441355">Devadoss and Foltz 1996</xref>; <xref ref-type="bibr" rid="bibr18-0193841X12441355">Esser 1997</xref>; <xref ref-type="bibr" rid="bibr28-0193841X12441355">Kirby and McElroy 2003</xref>; <xref ref-type="bibr" rid="bibr43-0193841X12441355">Reed 1981</xref>; Romer 1993; <xref ref-type="bibr" rid="bibr51-0193841X12441355">Wolbring 2010</xref>). However, all studies cited only report determinants of either class attendance or SET ratings, but not of both of them.</p>
<p>Therefore, in order to explore whether the attributes mentioned above are simultaneously related to attendance and course ratings, we estimated regression models with these variables as regressors and with class attendance and SET ratings as dependent variables. If the data are MAR, then the results should be corrected for bias. Since our results suggest such undesirable influences, we adjust ratings by weighting the data by actual and predicted class attendance.<sup>
<xref ref-type="fn" rid="fn5-0193841X12441355">5</xref>
</sup> However, before presenting our empirical findings, we describe data and statistical methods used.</p>
</sec>
<sec id="section3-0193841X12441355">
<title>Data and Methods</title>
<p>In this section, we give a description of the SET data used, motivate the choice of regression models employed to determine influential factors on class attendance and SET rating, and explain the weighting approach to adjust for bias.</p>
<sec id="section4-0193841X12441355">
<title>Data and Operationalizations</title>
<p>The following analyses are based on SET at the Faculty of Social Sciences of the University of Munich. In total, approximately 18,000 observations for over 680 courses with at least 10 participants are available for the years 2008–2010 (covering four terms). Besides specific items about a variety of dimensions of teaching quality and instructor behavior, the Munich SET questionnaire contains a global rating question about overall course quality (“All in all, how do you rate the overall quality of this course?” <italic>very good</italic> [1.0] – <italic>insufficient</italic> [5.0]). Moreover, for each course, the number of classes missed is also assessed in the SET form (“Up to now, how many classes of this course did you miss?”).</p>
<p>Furthermore, the data set contains the following variables (for an overview of their distribution see Table A1 in <xref ref-type="app" rid="app1-0193841X12441355">Appendix A</xref>):<list list-type="bullet">
<list-item>
<p>
<italic>PERFORMANCE RECORD</italic>: “Do you need a performance record?” <italic>yes</italic> (1); <italic>no</italic> (0).</p>
</list-item>
<list-item>
<p>
<italic>COURSE SIZE</italic>: Number of students who completed a SET form in the course.</p>
</list-item>
<list-item>
<p>
<italic>DEPARTMENT</italic>: Communication sciences, political sciences, or sociology.</p>
</list-item>
<list-item>
<p>
<italic>COURSE DAY and TIME</italic>: Weekday and starting time of the course.</p>
</list-item>
<list-item>
<p>
<italic>SUMMER TERM:</italic> Equals 1 if the course is held during a summer term (on average about 12 classes). Otherwise winter term (on average about 14 classes).</p>
</list-item>
<list-item>
<p>
<italic>COURSE PACE</italic>: “I could not follow the pace of the course.” <italic>totally agree</italic> (1)–<italic>totally disagree</italic> (5).</p>
</list-item>
<list-item>
<p>
<italic>COURSE DIFFICULTY: </italic>“The course was too difficult” <italic>totally agree</italic> (1)–<italic>totally disagree</italic> (5).</p>
</list-item>
<list-item>
<p>
<italic>PRIOR INTEREST</italic>: “I chose the course, because I was interested in its content” <italic>totally agree</italic> (1)–<italic>totally disagree</italic> (5).</p>
</list-item>
<list-item>
<p>
<italic>INSTRUCTOR KNOWN</italic>: “I chose the course, because I already knew the instructor” <italic>totally agree</italic> (1)–<italic>totally disagree</italic> (5).</p>
</list-item>
<list-item>
<p>
<italic>INSTRUCTOR’S PHYSICAL ATTRACTIVENESS: </italic>Only available for a subset of lecturers. 11 male and 9 female students from the University of Bern and 31 male and 34 female students from the University of Bern, who didn’t know the instructors, rated instructors’ portrait photos (taken from the internet) on an 11-point-attractiveness-scale (0 [<italic>very unattractive</italic>]–10 [<italic>very attractive</italic>]). For analyses we use each instructor’s average rating as a measure for her physical attractiveness.<sup>
<xref ref-type="fn" rid="fn6-0193841X12441355">6</xref>
</sup>
</p>
</list-item>
<list-item>
<p>
<italic>PREPARATION FOR THE COURSE</italic>: “On average, how many minutes per week did you prepare for the course?”</p>
</list-item>
<list-item>
<p>
<italic>COURSELOAD</italic>: “How many hours per week do you take for credit in this semester?”</p>
</list-item>
<list-item>
<p>
<italic>WORKLOAD</italic>: “How many hours per week do you work for payment in this semester?”</p>
</list-item>
<list-item>
<p>
<italic>SEMESTER:</italic> Student’s subject-related semester of study.</p>
</list-item>
</list>Based on prior findings on determinants of SET ratings and attendance, we included these variables as regressors in our models.</p>
</sec>
<sec id="section5-0193841X12441355">
<title>Regression Models</title>
<p>Perceived course quality and absenteeism are the dependent variables in our regression models. In a first step, we estimated simple linear regressions.<sup>
<xref ref-type="fn" rid="fn7-0193841X12441355">7</xref>
</sup> To take into account the fact that students usually complete more than one SET questionnaire, we clustered standard errors around students.<sup>
<xref ref-type="fn" rid="fn8-0193841X12441355">8</xref>
</sup> We can do this, since—compared to regular SET data for other universities and besides the rich information on student and course attributes—our data set has another major advantage: the Munich SET questionnaire contains a self-generating panel identifier (e.g., <xref ref-type="bibr" rid="bibr26-0193841X12441355">Kearney et al. 1984</xref>; <xref ref-type="bibr" rid="bibr54-0193841X12441355">Yurek, Vasey, and Havens 2008</xref>).<sup>
<xref ref-type="fn" rid="fn9-0193841X12441355">9</xref>
</sup>
</p>
<p>Moreover, the availability of a panel identifier allows us to control for unobserved interindividual heterogeneity, which often biases results from cross-sectional analyses. In the case of SET, individual differences in general abilities, socioeconomic background, and intrinsic motivation could influence class attendance and ratings. For that reason and in addition to simple linear regression models, we estimated models with individual fixed effects for each subject (<xref ref-type="bibr" rid="bibr1-0193841X12441355">Allison 2009</xref>; <xref ref-type="bibr" rid="bibr2-0193841X12441355">Angrist and Pischke 2009</xref>; <xref ref-type="bibr" rid="bibr52-0193841X12441355">Wooldridge 2002</xref>) to test for the robustness of our results.<sup>
<xref ref-type="fn" rid="fn10-0193841X12441355">10</xref>
</sup>
</p>
<p>Having identified factors, which simultaneously influence both class attendance and SET ratings, by this means, we then correct for bias due to influential covariates. We do this by weighting observations by actual and predicted absenteeism in the following way.</p>
</sec>
<sec id="section6-0193841X12441355">
<title>Weighting Approach</title>
<p>Assume that the number of previous classes of a course a student, who completed the SET questionnaire for this course, has missed reveals information about other students, who are absent during the SET of this course. If this assumption holds, based on the number of classes <italic>c<sub>j</sub>
</italic> of a course <italic>j </italic>previous to the SET and the number of classes <italic>m<sub>ij</sub>
</italic> a student <italic>i</italic> missed, we can calculate individual probabilities <italic>p<sub>ij</sub>
</italic> to be present during the SET of this course:<disp-formula id="disp-formula1-0193841X12441355">
<mml:math id="mml-disp1-0193841X12441355">
<mml:msub>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi>m</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula1-0193841X12441355" xlink:href="10.1177_0193841X12441355-eq1.tif"/>
</disp-formula>Thereby, a natural starting point is to use the actual number of classes missed (as self-disclosed in the questionnaire) as a proxy for <italic>m<sub>ij</sub>
</italic>. However, one might be worried that this measure has a significant random component (e.g., illness, problems with public transportation) and/or is biased (e.g., due to social desirability and fear of negative consequences). Therefore, besides a weighting approach using the self-assessed frequency of absenteeism, we also weight by the systematic part of absenteeism, namely, the predicted values we derived from the simple linear regression model in <xref ref-type="table" rid="table1-0193841X12441355">Table 1</xref>. Furthermore, we always set <italic>c<sub>j</sub>
</italic> = 11 for the winter term and <italic>c<sub>j</sub>
</italic> = 9 for the summer term, because the summer term is usually 2 weeks shorter than the winter term.</p>
<table-wrap id="table1-0193841X12441355" position="float">
<label>Table 1.</label>
<caption>
<p>Regression Results (Dependent Variable: Frequency of Absenteeism)</p>
</caption>
<graphic alternate-form-of="table1-0193841X12441355" xlink:href="10.1177_0193841X12441355-table1.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th colspan="2">Simple linear regression<hr/></th>
<th colspan="2">Fixed-effects regression 1<hr/></th>
<th colspan="2">Fixed-effects regression 2<hr/></th>
</tr>
<tr>
<th>Variable</th>
<th>Coef.</th>
<th>
<italic>SE</italic>
</th>
<th>Coef.</th>
<th>
<italic>SE</italic>
</th>
<th>Coef.</th>
<th>
<italic>SE</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Performance record (1 = required)</td>
<td>−0.204***</td>
<td>(0.041)</td>
<td>−0.342***</td>
<td>(0.056)</td>
<td>−0.379***</td>
<td>(0.069)</td>
</tr>
<tr>
<td>Course size</td>
<td>0.002***</td>
<td>(0.0001)</td>
<td>0.002***</td>
<td>(0.0002)</td>
<td>0.002***</td>
<td>(0.0002)</td>
</tr>
<tr>
<td colspan="7">Course day (ref = Monday)</td>
</tr>
<tr>
<td> Tuesday</td>
<td>−0.036</td>
<td>(0.027)</td>
<td>−0.122***</td>
<td>(0.029)</td>
<td>−0.165***</td>
<td>(0.049)</td>
</tr>
<tr>
<td> Wednesday</td>
<td>0.059*</td>
<td>(0.029)</td>
<td>0.038</td>
<td>(0.032)</td>
<td>−0.02</td>
<td>(0.047)</td>
</tr>
<tr>
<td> Thursday</td>
<td>−0.001</td>
<td>(0.030)</td>
<td>−0.033</td>
<td>(0.033)</td>
<td>−0.037</td>
<td>(0.051)</td>
</tr>
<tr>
<td> Friday</td>
<td>0.127*</td>
<td>(0.057)</td>
<td>0.138*</td>
<td>(0.063)</td>
<td>0.260*</td>
<td>(0.102)</td>
</tr>
<tr>
<td colspan="7">Course time (ref = 8/9 a.m.)</td>
</tr>
<tr>
<td> 10 a.m.</td>
<td>−0.157***</td>
<td>(0.037)</td>
<td>−0.181***</td>
<td>(0.037)</td>
<td>−0.174***</td>
<td>(0.050)</td>
</tr>
<tr>
<td> 12/1 p.m.</td>
<td>−0.135***</td>
<td>(0.040)</td>
<td>−0.188***</td>
<td>(0.041)</td>
<td>−0.114<sup>+</sup>
</td>
<td>(0.059)</td>
</tr>
<tr>
<td> 2/3 p.m.</td>
<td>−0.246***</td>
<td>(0.040)</td>
<td>−0.303***</td>
<td>(0.043)</td>
<td>−0.310***</td>
<td>(0.062)</td>
</tr>
<tr>
<td> 4 p.m.</td>
<td>−0.124**</td>
<td>(0.042)</td>
<td>−0.168***</td>
<td>(0.043)</td>
<td>−0.203**</td>
<td>(0.066)</td>
</tr>
<tr>
<td> 6/7/8 p.m.</td>
<td>−0.198***</td>
<td>(0.051)</td>
<td>−0.259***</td>
<td>(0.054)</td>
<td>−0.407***</td>
<td>(0.079)</td>
</tr>
<tr>
<td>Course pace</td>
<td>−0.019</td>
<td>(0.012)</td>
<td>−0.020</td>
<td>(0.014)</td>
<td>−0.012</td>
<td>(0.020)</td>
</tr>
<tr>
<td>Course difficulty</td>
<td>−0.010</td>
<td>(0.014)</td>
<td>−0.033*</td>
<td>(0.016)</td>
<td>−0.008</td>
<td>(0.023)</td>
</tr>
<tr>
<td>Prior interest</td>
<td>0.057***</td>
<td>(0.010)</td>
<td>0.057***</td>
<td>(0.011)</td>
<td>0.085***</td>
<td>(0.016)</td>
</tr>
<tr>
<td>Instructor known</td>
<td>0.013</td>
<td>(0.008)</td>
<td>0.006</td>
<td>(0.011)</td>
<td>0.033*</td>
<td>(0.015)</td>
</tr>
<tr>
<td>Preparation for the course</td>
<td>−0.002***</td>
<td>(0.0002)</td>
<td>−0.002***</td>
<td>(0.0002)</td>
<td>−0.003***</td>
<td>(0.0004)</td>
</tr>
<tr>
<td>Courseload</td>
<td>−0.006*</td>
<td>(0.002)</td>
<td>−0.007</td>
<td>(0.004)</td>
<td>−0.008</td>
<td>(0.005)</td>
</tr>
<tr>
<td>Workload</td>
<td>0.015***</td>
<td>(0.001)</td>
<td>0.006<sup>+</sup>
</td>
<td>(0.003)</td>
<td>0.005</td>
<td>(0.004)</td>
</tr>
<tr>
<td>Semesters</td>
<td>0.050***</td>
<td>(0.005)</td>
<td>0.155***</td>
<td>(0.016)</td>
<td>0.181***</td>
<td>(0.019)</td>
</tr>
<tr>
<td>Course quality</td>
<td>0.104***</td>
<td>(0.019)</td>
<td>0.123***</td>
<td>(0.021)</td>
<td>0.132***</td>
<td>(0.028)</td>
</tr>
<tr>
<td>Instructors’ attractiveness</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>−0.040*</td>
<td>(0.017)</td>
</tr>
<tr>
<td>Constant</td>
<td>0.869***</td>
<td>(0.106)</td>
<td>0.943***</td>
<td>(0.155)</td>
<td>1.008***</td>
<td>(0.215)</td>
</tr>
<tr>
<td>
<italic>R</italic>
<sup>2</sup>
</td>
<td align="center" colspan="2">.096</td>
<td align="center" colspan="2">.107</td>
<td align="center" colspan="2">.116</td>
</tr>
<tr>
<td>Adjusted <italic>R</italic>
<sup>2</sup>
</td>
<td align="center" colspan="2">.094</td>
<td align="center" colspan="2">.105</td>
<td align="center" colspan="2">.114</td>
</tr>
<tr>
<td>Observations</td>
<td align="center" colspan="2">14,104</td>
<td align="center" colspan="2">14,028</td>
<td align="center" colspan="2">9,967</td>
</tr>
<tr>
<td>Individuals</td>
<td align="center" colspan="2">—</td>
<td align="center" colspan="2">6,724</td>
<td align="center" colspan="2">5,331</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0193841X12441355">
<p>
<italic>Note.</italic> Regression models with dependent variable “frequency of absenteeism from classes”. Nonstandardized coefficients (for negative binomial model: incidence-rate ratios), standard errors in parentheses.</p>
</fn>
<fn id="table-fn2-0193841X12441355">
<p>
<sup>+</sup>
<italic>p</italic> &lt;.1. *<italic>p </italic>&lt; .05. **<italic>p </italic>&lt; .01. ***<italic>p </italic>&lt; .001. Controlled for department (communication sciences, political sciences, and sociology), summer term. Negative binomial and simple linear regression model with robust standard errors clustered around students. Fixed-effects models with robust standard errors.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>We then weight individual SET quality ratings by <italic>p<sub>ij</sub>
</italic>. More specifically, we use the inverse probability of being present 1/<italic>p<sub>ij</sub>
</italic> to weight up students, who miss class more often. This form of weighting reflects the fact that students with a lower <italic>p<sub>ij</sub> </italic>are underrepresented in our SET data. Thus, in order to receive a less biased measure of teaching quality more weight has to be given to absent students.<sup>
<xref ref-type="fn" rid="fn11-0193841X12441355">11</xref>
</sup>
</p>
<p>As common in many departments, the next step is to rank courses (with at least 10 observations) separately for each term using average course ratings (unadjusted and weighted by 1/<italic>p<sub>ij</sub>
</italic>). Finally, we compute absolute mean deviations between the ranked orderings, which are based on these two measures.</p>
</sec>
</sec>
<sec id="section7-0193841X12441355">
<title>Results</title>
<p>Having explained our empirical strategy, we now first present findings on determinants of students’ absenteeism and course ratings. By determining whether class attendance is related to variables that likely predict course ratings as well one can check whether the data are MCAR. Since our findings suggest that our SET data are probably MAR, but definitely not MCAR, we then adjust course rankings for absenteeism and explore changes in ranks resulting from this bias correction.</p>
<sec id="section8-0193841X12441355">
<title>Determinants of Students’ Absenteeism</title>
<p>First, we estimated simple linear regression models for students’ absenteeism. As can be seen in <xref ref-type="table" rid="table1-0193841X12441355">Table 1</xref>, most effects are in accordance with theoretical expectations: Most importantly, course quality is significantly correlated with absenteeism from class. If a student rates a course with the German grade 1.0 (+; <italic>very good</italic>) instead of the German grade 5.0 (−; <italic>insufficient</italic>), he misses .4 less classes, on average. Given that the average student misses 1.1 classes, this effect is surely not irrelevant in practice. If we do not control for other covariates, which also influence the SET ratings, we get a highly significant correlation between quality and attendance of .7. Using similar global rating questions (such as “I learned more than in other classes” or “I could explain the central concepts of the course to others”) instead we even find slightly stronger effect.</p>
<p>Moreover, needing a performance record significantly reduces absenteeism. The effect of social control is similar in size: if course size rises, it becomes more difficult for instructors to keep track of individual absenteeism. In result, an increase of course size by 100 students is associated with an increase in average absenteeism by 0.2. Further analyses (not reported) show that course size is only a predictor of absenteeism if students need a performance record—a finding which further strengthens the interpretation of the negative class size effect as the result of decreasing social control.</p>
<p>Furthermore, weekday and starting time of the course significantly affect class attendance. Classes on Monday, Wednesday, and Friday, as well as early in the morning (8/9 a.m.) are attended less regularly. However, in contrast to our theoretical expectations and previous findings, course pace and course difficulty have no significant effect.<sup>
<xref ref-type="fn" rid="fn12-0193841X12441355">12</xref>
</sup> However, if we test for their effects on absenteeism without including further controls in the model, both are significantly related to course attendance. According to these results, absenteeism is higher, if the course pace is too fast and courses are too difficult.</p>
<p>As well in accordance with theoretical expectations and previous findings, students, who were more interested in the content of the course, who knew the instructor when choosing the course, who better prepared for the course, and who spent less hours working for payment, attended class more frequently. Furthermore, dropout increases with higher semester and lower number of courses attended. However, this last result could only reflect the fact that students self-select into courses and that more interested and motivated students elect more courses.</p>
<p>For that reason, we next estimated a model with individual fixed effects to control for unobserved heterogeneity and test for the robustness of our results.<sup>
<xref ref-type="fn" rid="fn13-0193841X12441355">13</xref>
</sup> All our main results remain remarkably stable; most correlations between independent variables (e.g., course quality, performance record, and course time) and students’ absenteeism even become closer in the fixed-effects context.</p>
<p>In a last step, we analyzed a subsample of our data, for which measures of instructors’ physical attractiveness are available. Interestingly, students obviously value physical attractiveness, because they more regularly attend classes of more physically attractive instructors. Thus, to complement recent studies, which show that more attractive instructors are significantly rated better in SET (<xref ref-type="bibr" rid="bibr22-0193841X12441355">Hamermesh and Parker 2005</xref>; <xref ref-type="bibr" rid="bibr51-0193841X12441355">Wolbring 2010</xref>), students seem to have a preference for more physically attractive instructors and derive utility from attending their classes and interacting with them.</p>
<p>To sum up our results, course quality is clearly associated with absenteeism. Moreover, we found that various individual and structural factors, which are not under the control of the instructor, affect class attendance. In a next step, we ask whether absenteeism is simultaneously determined with course ratings. If this is the case, the Munich SET data are not MCAR and should be corrected for bias.</p>
</sec>
<sec id="section9-0193841X12441355">
<title>Determinants of Course Ratings</title>
<p>Simple linear regression models and fixed-effects models in <xref ref-type="table" rid="table2-0193841X12441355">Table 2</xref> actually show that some of the structural and individual factors, which influence attendance, are also significantly related to students’ ratings of course quality: Needing a performance record for the course not only increases the frequency of attendance but is also associated with slightly worse ratings. However, the effect is only significant in the fixed-effects model and rather small. In contrast to that, course size and student’s semester of study go hand in hand with more absenteeism and better ratings. Finally, some factors have both positive effects on class attendance and course ratings. This is true for students’ prior interest in course contents, the amount of time they spend to prepare for class, and physical attractiveness of the instructor. Finally, looking at standardized coefficients (not reported), one can see that course size, semester of study, and weekly preparation for the course are most closely correlated with SET.</p>
<table-wrap id="table2-0193841X12441355" position="float">
<label>Table 2.</label>
<caption>
<p>Regression Results (Dependent Variable: Course Quality)</p>
</caption>
<graphic alternate-form-of="table2-0193841X12441355" xlink:href="10.1177_0193841X12441355-table2.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th colspan="2">Simple linear regression<hr/></th>
<th colspan="2">Fixed-effects regressions 1<hr/></th>
<th colspan="2">Fixed-effects regressions 2<hr/></th>
</tr>
<tr>
<th>Variable</th>
<th>Coef.</th>
<th>
<italic>SE</italic>
</th>
<th>Coef.</th>
<th>
<italic>SE</italic>
</th>
<th>Coef.</th>
<th>
<italic>SE</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Performance record (1 = required)</td>
<td>0.026</td>
<td>(0.016)</td>
<td>0.078**</td>
<td>(0.027)</td>
<td>0.080*</td>
<td>(0.036)</td>
</tr>
<tr>
<td>Course size</td>
<td>−0.001***</td>
<td>(0.0001)</td>
<td>−0.001***</td>
<td>(0.0001)</td>
<td>−0.001***</td>
<td>(0.0001)</td>
</tr>
<tr>
<td colspan="7">Course day (ref = Monday)</td>
</tr>
<tr>
<td> Tuesday</td>
<td>−0.074***</td>
<td>(0.015)</td>
<td>−0.103***</td>
<td>(0.019)</td>
<td>−0.086***</td>
<td>(0.026)</td>
</tr>
<tr>
<td> Wednesday</td>
<td>0.015</td>
<td>(0.015)</td>
<td>−0.001</td>
<td>(0.018)</td>
<td>−0.04</td>
<td>(0.025)</td>
</tr>
<tr>
<td> Thursday</td>
<td>−0.027<sup>+</sup>
</td>
<td>(0.015)</td>
<td>−0.045*</td>
<td>(0.019)</td>
<td>−0.083**</td>
<td>(0.026)</td>
</tr>
<tr>
<td> Friday</td>
<td>−0.060*</td>
<td>(0.030)</td>
<td>−0.097*</td>
<td>(0.039)</td>
<td>−0.107*</td>
<td>(0.053)</td>
</tr>
<tr>
<td colspan="7">Course time (ref = 8/9 a.m.)</td>
</tr>
<tr>
<td> 10 a.m.</td>
<td>0.019</td>
<td>(0.018)</td>
<td>−0.029</td>
<td>(0.022)</td>
<td>−0.064*</td>
<td>(0.026)</td>
</tr>
<tr>
<td> 12/1 p.m.</td>
<td>0.039*</td>
<td>(0.020)</td>
<td>0.008</td>
<td>(0.025)</td>
<td>0.019</td>
<td>(0.031)</td>
</tr>
<tr>
<td> 2/3 p.m.</td>
<td>0.099***</td>
<td>(0.020)</td>
<td>0.070**</td>
<td>(0.025)</td>
<td>0.001</td>
<td>(0.032)</td>
</tr>
<tr>
<td> 4 p.m.</td>
<td>0.106***</td>
<td>(0.022)</td>
<td>0.102***</td>
<td>(0.027)</td>
<td>0.097**</td>
<td>(0.034)</td>
</tr>
<tr>
<td> 6/7/8 p.m.</td>
<td>0.202***</td>
<td>(0.030)</td>
<td>0.244***</td>
<td>(0.038)</td>
<td>0.228***</td>
<td>(0.041)</td>
</tr>
<tr>
<td>Course pace</td>
<td>−0.066***</td>
<td>(0.006)</td>
<td>−0.070***</td>
<td>(0.009)</td>
<td>−0.076***</td>
<td>(0.010)</td>
</tr>
<tr>
<td>Course difficulty</td>
<td>−0.086***</td>
<td>(0.008)</td>
<td>−0.091***</td>
<td>(0.011)</td>
<td>−0.082***</td>
<td>(0.012)</td>
</tr>
<tr>
<td>Prior interest</td>
<td>0.128***</td>
<td>(0.005)</td>
<td>0.145***</td>
<td>(0.007)</td>
<td>0.148***</td>
<td>(0.008)</td>
</tr>
<tr>
<td>Instructor known</td>
<td>0.137***</td>
<td>(0.004)</td>
<td>0.165***</td>
<td>(0.007)</td>
<td>0.170***</td>
<td>(0.007)</td>
</tr>
<tr>
<td>Preparation for the course</td>
<td>−0.001***</td>
<td>(0.0001)</td>
<td>−0.001***</td>
<td>(0.0001)</td>
<td>−0.001***</td>
<td>(0.0002)</td>
</tr>
<tr>
<td>Courseload</td>
<td>0.002</td>
<td>(0.001)</td>
<td>0.002</td>
<td>(0.002)</td>
<td>0.002</td>
<td>(0.003)</td>
</tr>
<tr>
<td>Workload</td>
<td>−0.0002</td>
<td>(0.001)</td>
<td>−0.0004</td>
<td>(0.002)</td>
<td>0</td>
<td>(0.002)</td>
</tr>
<tr>
<td>Semester</td>
<td>−0.0003</td>
<td>(0.002)</td>
<td>−0.051***</td>
<td>(0.008)</td>
<td>−0.054***</td>
<td>(0.010)</td>
</tr>
<tr>
<td>Instructors’ attractiveness</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>−0.032***</td>
<td>(0.009)</td>
</tr>
<tr>
<td>Constant</td>
<td>1.893***</td>
<td>(0.051)</td>
<td>2.016***</td>
<td>(0.083)</td>
<td>2.200***</td>
<td>(0.107)</td>
</tr>
<tr>
<td>
<italic>R</italic>
<sup>2</sup>
</td>
<td align="center" colspan="2">.262</td>
<td align="center" colspan="2">.283</td>
<td align="center" colspan="2">.304</td>
</tr>
<tr>
<td>Adjusted <italic>R</italic>
<sup>2</sup>
</td>
<td align="center" colspan="2">.261</td>
<td align="center" colspan="2">.282</td>
<td align="center" colspan="2">.302</td>
</tr>
<tr>
<td>Observations</td>
<td align="center" colspan="2">14,159</td>
<td align="center" colspan="2">14,159</td>
<td align="center" colspan="2">10,013</td>
</tr>
<tr>
<td>Individuals</td>
<td align="center" colspan="2">—</td>
<td align="center" colspan="2">6,771</td>
<td align="center" colspan="2">5,351</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0193841X12441355">
<p>
<italic>Note:</italic> Regression models with dependent variable “course quality” ranging from 1.0 (<italic>very good</italic>) to 5.0 (<italic>insufficient</italic>). Nonstandardized coefficients, standard errors in parentheses.</p>
</fn>
<fn id="table-fn4-0193841X12441355">
<p>
<sup>+</sup>
<italic>p</italic> &lt;.1. *<italic>p </italic>&lt; .05. **<italic>p </italic>&lt; .01; ***<italic>p </italic>&lt; .001. Controlled for department (communication sciences, political sciences, sociology), summer term.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Thus, our analyses show that the SET data are not MCAR. Because of this, one has to question the validity and fairness of SET as a measure of teaching quality (Assumptions 1 and 2). As well, it suggests itself to use information about students’ class attendance to at least correct SET ratings for known influences. If data were MAR, this correction would even remove all bias induced by missing students. However, before drawing such a practical conclusion for SET, we have to prove first that the bias induced by absenteeism on SET is reasonably strong, that is, that a correction would really make a difference for the ranking of courses. Furthermore, it is not clear how those different biases add up, since some variables have a positive (negative) influence on attendance and a negative (positive) influence on the ratings, whereas others have a positive effect on both outcomes.</p>
</sec>
<sec id="section10-0193841X12441355">
<title>Adjusting Course Rankings for Absenteeism</title>
<p>As described in the data and methods section, we weight observations by actual and predicted absenteeism, rank all courses with at least 10 participants on the basis of unadjusted and adjusted mean course ratings, and compare resulting rankings.</p>
<p>Mean and median differences in ranks are presented in <xref ref-type="table" rid="table3-0193841X12441355">Table 3</xref>. The absolute average deviation of the adjusted ranking (based on actual and not predicted absenteeism) from a ranking generated with the commonly used procedure is rather small and ranges from 4.0 to 7.1 ranks. This is equal to an average change in ranks between 3.7% and 6.5% relative to the maximum of possible rank changes. The position of one quarter of all courses only changes by a maximum of 1–3 ranks, the position of 75% of all courses changes by a maximum of 5–8 ranks. Furthermore, the median is always below the mean, which (in addition to the high standard deviation) indicates that the distribution in ranks is positively skewed. In other words, there are a few courses, which are assigned to significantly different ranks with the two procedures: 25% (5%) of all courses are faced with differences of at least 5–8 (13–22) ranks. For some courses, even more extreme variation can be observed (up to 22–59 differences in ranks).</p>
<table-wrap id="table3-0193841X12441355" position="float">
<label>Table 3.</label>
<caption>
<p>Absolute Differences in Ranks Using Unadjusted and Adjusted Mean Ratings</p>
</caption>
<graphic alternate-form-of="table3-0193841X12441355" xlink:href="10.1177_0193841X12441355-table3.tif"/>
<table>
<thead>
<tr>
<th>Term</th>
<th>Absenteeism </th>
<th>
<italic>N</italic>
</th>
<th>
<italic>M</italic>
</th>
<th>
<italic>SD</italic>
</th>
<th>min</th>
<th>5%</th>
<th>25%</th>
<th>Median</th>
<th>75%</th>
<th>95%</th>
<th>max</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="2">Winter 08/09</td>
<td>Actual</td>
<td>128</td>
<td>4.03</td>
<td>3.99</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>5</td>
<td>13</td>
<td>22</td>
</tr>
<tr>
<td>Predicted</td>
<td>123</td>
<td>.44</td>
<td>.76</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>4</td>
</tr>
<tr>
<td rowspan="2">Summer 09</td>
<td>Actual</td>
<td>146</td>
<td>7.14</td>
<td>6.69</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>5</td>
<td>8</td>
<td>22</td>
<td>51</td>
</tr>
<tr>
<td>Predicted</td>
<td>139</td>
<td>.56</td>
<td>.79</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>4</td>
</tr>
<tr>
<td rowspan="2">Winter 09/10</td>
<td>Actual</td>
<td>179</td>
<td>4.98</td>
<td>6.00</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>3</td>
<td>6</td>
<td>20</td>
<td>38</td>
</tr>
<tr>
<td>Predicted</td>
<td>166</td>
<td>.78</td>
<td>.90</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>4</td>
</tr>
<tr>
<td rowspan="2">Summer 10</td>
<td>Actual</td>
<td>181</td>
<td>6.19</td>
<td>8.43</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>8</td>
<td>18</td>
<td>59</td>
</tr>
<tr>
<td>Predicted</td>
<td>172</td>
<td>.68</td>
<td>.94</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>7</td>
</tr>
<tr>
<td rowspan="2">Total (per term)</td>
<td>Actual</td>
<td>634</td>
<td>5.63</td>
<td>6.71</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>4</td>
<td>7</td>
<td>18</td>
<td>59</td>
</tr>
<tr>
<td>Predicted</td>
<td>600</td>
<td>.64</td>
<td>.87</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>7</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0193841X12441355">
<p>
<italic>Note.</italic> Differences in ranks between league tables based on unadjusted mean ratings and with mean ratings adjusted for actual and predicted absenteeism. Predicted absenteeism based on simple linear regression in <xref ref-type="table" rid="table1-0193841X12441355">Table 1</xref>. Columns min to max refer to relative frequency of changes in ranks. For example, looking at column “75%” and the row “total” one can see that for 75% of all courses the position changed by a maximum of 7 ranks if we weigh by actual absenteeism.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>
<xref ref-type="fig" rid="fig1-0193841X12441355">Figure 1</xref> further illustrates this aspect. The distribution of differences in ranks obviously deviates from a normal distribution, since it has a longer tail and is positively skewed. Additional analyses show that the distribution follows a power law function (e.g., <xref ref-type="bibr" rid="bibr37-0193841X12441355">Mitzenmacher 2003</xref>; <xref ref-type="bibr" rid="bibr38-0193841X12441355">Newman 2005</xref>). An equation of the form <inline-formula id="inline-formula1-0193841X12441355">
<mml:math id="mml-inline1-0193841X12441355">
<mml:mo form="prefix" movablelimits="false">log</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mover accent="true">
<mml:mi>C</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">−</mml:mo>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo form="prefix" movablelimits="false">log</mml:mo>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula> with <inline-formula id="inline-formula2-0193841X12441355">
<mml:math id="mml-inline2-0193841X12441355">
<mml:mover accent="true">
<mml:mi>C</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1.94</mml:mn>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula3-0193841X12441355">
<mml:math id="mml-inline3-0193841X12441355">
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1.80</mml:mn>
</mml:math>
</inline-formula> adequately describes the relationship between differences in ranks <italic>X</italic> and the relative frequency of differences in ranks <italic>Y</italic> <inline-formula id="inline-formula4-0193841X12441355">
<mml:math id="mml-inline4-0193841X12441355">
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>R</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>.91</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>.<sup>
<xref ref-type="fn" rid="fn14-0193841X12441355">14</xref>
</sup> This implies an extremely unequal distribution of rank differences and, therefore, that the rank of a small number of courses is disproportionally influenced by the used ranking procedure.</p>
<fig id="fig1-0193841X12441355" position="float">
<label>Figure 1.</label>
<caption>
<p>Distribution of differences in ranks.</p>
</caption>
<graphic xlink:href="10.1177_0193841X12441355-fig1.tif"/>
</fig>
<p>One might ask what course type is disproportionally affected by a change in the ranking mechanism. Our answer is courses with average teaching quality. We find that the positions of courses with a mean grade between 1.5 and 2.0 (2.0 and 2.5) on average change by 7.2 (4.6) ranks, whereas the positions of courses at the upper (lower) tail of the distribution only vary by 2.3 (1.8) ranks. Because ratings at the center of the distribution are closer to each other than more extreme ratings, weighting has stronger effects on the rank of average courses. Thus, the usual ranking procedure is more reliable for the identification of very good and very poor courses than for average courses.</p>
<p>In general, we find similar patterns if we weight by predicted frequencies of attendance: average courses are affected more strongly than courses with a mean rating at the tails of the distribution. However, with a maximum difference of 7 ranks and an average difference of 0.4–0.8 ranks, the size of the changes becomes extremely small (again see <xref ref-type="table" rid="table3-0193841X12441355">Table 3</xref>).</p>
<p>The main reason for this is the much smaller variation of predicted values of absenteeism compared to the actual frequency of absenteeism. Technically speaking, the second weighting approach only used the—according to our models—systematic component of absenteeism. Since the explanatory value of those models is rather low (<italic>R</italic>
<sup>2</sup> » .1), much unexplained variance remains in the data. This residual variation is presumably at least partly systematic. So, we propose that the different weighting approaches are based on the assumption of two rather extreme constellations, namely that absenteeism is either completely or only to a very low degree systematic. We think the truth lies in between both extremes, since attendance behavior has a significant random component but is presumably also more systematic than our explanatory model suggests. Therefore, we argue that both weighting schemes are informative as measures of uncertainty in making comparisons based on incomplete data.</p>
</sec>
</sec>
<sec id="section11-0193841X12441355">
<title>Conclusions</title>
<p>In this article, we investigated whether SET are biased by students being absent and whether procedures which adjust for varying frequency of attendance between courses produce different rankings than the widely used procedure which is based on students’ raw mean ratings.</p>
<p>To begin with, we discussed the problem from a missing data perspective. Based on SET data for the Faculty of Social Sciences at the University of Munich, we then tested whether class attendance and quality ratings are determined by the same factors. This is the case for the need of a performance record, course size, course time, prior interest, preparation for the course, semester of study, and physical attractiveness of the instructor. Furthermore, attendance is also directly related to the quality of teaching.</p>
<p>Thus, it suggests itself that data are not MCAR and SET are biased. Therefore, Assumption 1 (SET are valid measures of teaching quality) does not hold. As well, Assumption 2 (SET are fair measures of teaching quality) is questionable, since some of these factors are not fully under the instructor’s control. So, for example, more interested students rate courses better and also attend them more frequently. Similarly, courses with more participants are rated worse and are attended less regularly.</p>
<p>However, as long as course rankings do not change significantly if we adjust for absenteeism, validity, and fairness issues concerning students’ ratings are not problematic from a pragmatic point of view. Therefore, we then switched from the micro to the macro level and asked whether course rankings based on a global measure of teaching quality change if we adjust for actual and predicted absenteeism (instead of using the raw mean). In other words, we tested Assumption 3, which posits that the quality of different courses can be compared based on SET. Weighting by actual frequency of absenteeism, we found that, on average, changes in ranks are low but follow a power law. The rank of a small number of mostly average courses is disproportionally influenced by the choice of the ranking procedure. This finding leads us to the conclusion that SET are appropriate to identify high- and low-quality courses, but not to determine the exact ranks of average courses. Using only the systematic part of absenteeism, which is associated with other covariates, we find similar patterns. However, resulting changes in ranks are so small, that weighting does not seem to be necessary at all. We posit that the truth lies in between those two rather extreme estimates.</p>
<p>However, we acknowledge that our data have weaknesses and, therefore, are not optimal for our endeavor. First, we had to rely on self-assessed information on students’ absenteeism. This gives a lower bound of true absenteeism, since (although anonymity is fully guaranteed) some students fear negative consequences if admitting higher frequency of absenteeism. Furthermore, it is not always the case that past attendance predicts current attendance in the expected way. For example, if students need a performance record and course attendance is compulsory, past absenteeism can even positively influence the probability of current attendance. However, based on the assumption that class attendance is mainly the result of a cost–benefit analysis, we would expect that past attendance reveals information on the utility, which students derive from the course and other alternatives. Therefore, we think that in this case, past behavior is predictive for current attendance.</p>
<p>Second, in our empirical models, we could not control for all factors, which might be relevant for students’ attendance and ratings. For example, we could not map peer group effects, although they are relevant for both class attendance decisions and students’ well-being in class. Given a residual variance of about 90%, it seems to be natural to think about further omitted variables.</p>
<p>Finally, and most importantly, our weighting approach is worth discussing. On one hand, one could argue that students who miss more classes should be given less and not more weight, since they are less equipped to evaluate the quality of teaching. The decision depends on whether the effect of perceived quality on attendance or of attendance on perceived quality is stronger. Although we have no proof for this, we assumed the former being stronger. On the other hand, even if one accepts giving absent students more weight the approach per se is probably problematic, because we had to draw inferences on students absent during the SET. More specifically, since no information on those students was available, we assumed that ratings by students present during the SET can be informative about the rating behavior of absent students. In other words, we assumed that students are MAR. However, one could argue that nonresponse is nonignorable, since students, who drop class or withdraw from studies, are also among those persons, who did not participate at the SET. Obviously, the decision of drooping out of university may not at all be driven by concerns about teaching quality of a specific course. However, if this is the case, these no-shows are unproblematic for ratings and ranking. In contrast to that, cancelling a course should be influenced more strongly by quality concerns. This nonignorable nonresponse is more problematic for ratings and rankings. However, we expect that changes in ranks would become more extreme if we controlled for this type of missingness. Thus, it suggests itself that our results give a lower bound of actual bias if part of the data is NMAR.</p>
<p>A more direct approach would have been to evaluate early and late in the course. As <xref ref-type="bibr" rid="bibr29-0193841X12441355">Kohlan (1973)</xref> showed SET “stabilize very early in the course”. Similarly, <xref ref-type="bibr" rid="bibr12-0193841X12441355">Costin (1968)</xref> reports medium to strong correlations between midsemester and end of course ratings. Thus, on one hand, given a design with two measurements in time one can compare the ratings of students, who completed both questionnaires, with those who only completed the first questionnaire. Based on such data, more reliable results on the exact size of the bias induced by absenteeism can be produced, since these estimates would rest on less bold assumptions than our analysis does. On the other hand, one can also utilize this additional information on absent students for the first measurement in time and can try to answer the counterfactual question how the evaluation of those students who are absent during the second SET would have looked (if they were present). Thus, it goes without saying that we plan further research with such a design with two measurements in time.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0193841X12441355">
<title>Appendix A</title>
<table-wrap id="table4-0193841X12441355" position="float">
<label>Table A1.</label>
<caption>
<p>Descriptive Statistics</p>
</caption>
<graphic alternate-form-of="table4-0193841X12441355" xlink:href="10.1177_0193841X12441355-table4.tif"/>
<table>
<thead>
<tr>
<th>Variable</th>
<th>
<italic>M</italic>
</th>
<th>
<italic>SD</italic>
</th>
<th>Min</th>
<th>Max</th>
<th>
<italic>N</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Performance record (1 = required)</td>
<td>0.91</td>
<td>0.29</td>
<td>0</td>
<td>1</td>
<td>18,756</td>
</tr>
<tr>
<td>Course size</td>
<td>72.22</td>
<td>95.20</td>
<td>1</td>
<td>426</td>
<td>19,186</td>
</tr>
<tr>
<td colspan="6">Department</td>
</tr>
<tr>
<td> Communication sciences</td>
<td>0.31</td>
<td>0.46</td>
<td>0</td>
<td>1</td>
<td>19,111</td>
</tr>
<tr>
<td> Political sciences</td>
<td>0.32</td>
<td>0.47</td>
<td>0</td>
<td>1</td>
<td>19,111</td>
</tr>
<tr>
<td> Sociology</td>
<td>0.36</td>
<td>0.48</td>
<td>0</td>
<td>1</td>
<td>19,111</td>
</tr>
<tr>
<td colspan="6">Course day</td>
</tr>
<tr>
<td> Monday</td>
<td>0.25</td>
<td>0.43</td>
<td>0</td>
<td>1</td>
<td>17,863</td>
</tr>
<tr>
<td> Tuesday</td>
<td>0.26</td>
<td>0.44</td>
<td>0</td>
<td>1</td>
<td>17,863</td>
</tr>
<tr>
<td> Wednesday</td>
<td>0.25</td>
<td>0.43</td>
<td>0</td>
<td>1</td>
<td>17,863</td>
</tr>
<tr>
<td> Thursday</td>
<td>0.21</td>
<td>0.41</td>
<td>0</td>
<td>1</td>
<td>17,863</td>
</tr>
<tr>
<td> Friday</td>
<td>0.03</td>
<td>0.17</td>
<td>0</td>
<td>1</td>
<td>17,863</td>
</tr>
<tr>
<td colspan="6">Course time</td>
</tr>
<tr>
<td> 8/9 a.m.</td>
<td>0.11</td>
<td>0.31</td>
<td>0</td>
<td>1</td>
<td>17,891</td>
</tr>
<tr>
<td> 10 a.m.</td>
<td>0.35</td>
<td>0.48</td>
<td>0</td>
<td>1</td>
<td>17,891</td>
</tr>
<tr>
<td> 12/1 p.m.</td>
<td>0.18</td>
<td>0.38</td>
<td>0</td>
<td>1</td>
<td>17,891</td>
</tr>
<tr>
<td> 2/3 p.m.</td>
<td>0.16</td>
<td>0.37</td>
<td>0</td>
<td>1</td>
<td>17,891</td>
</tr>
<tr>
<td> 4 p.m.</td>
<td>0.14</td>
<td>0.35</td>
<td>0</td>
<td>1</td>
<td>17,891</td>
</tr>
<tr>
<td> 6/7/8 p.m.</td>
<td>0.07</td>
<td>0.25</td>
<td>0</td>
<td>1</td>
<td>17,891</td>
</tr>
<tr>
<td>Summer term</td>
<td>0.48</td>
<td>0.50</td>
<td>0</td>
<td>1</td>
<td>19,137</td>
</tr>
<tr>
<td>Course speed</td>
<td>3.91</td>
<td>1.05</td>
<td>1</td>
<td>5</td>
<td>19,021</td>
</tr>
<tr>
<td>Course difficulty</td>
<td>4.13</td>
<td>0.93</td>
<td>1</td>
<td>5</td>
<td>19,009</td>
</tr>
<tr>
<td>Prior interest</td>
<td>2.32</td>
<td>1.24</td>
<td>1</td>
<td>5</td>
<td>17,783</td>
</tr>
<tr>
<td>Instructor known</td>
<td>3.21</td>
<td>1.41</td>
<td>1</td>
<td>5</td>
<td>17,303</td>
</tr>
<tr>
<td>Instructors’ attractiveness</td>
<td>4.52</td>
<td>1.05</td>
<td>2</td>
<td>7.45</td>
<td>13,374</td>
</tr>
<tr>
<td>Preparation for the course</td>
<td>62.43</td>
<td>66.78</td>
<td>0</td>
<td>998</td>
<td>17,977</td>
</tr>
<tr>
<td>Courseload</td>
<td>16.58</td>
<td>5.79</td>
<td>0</td>
<td>55</td>
<td>17,886</td>
</tr>
<tr>
<td>Workload</td>
<td>8.46</td>
<td>8.45</td>
<td>0</td>
<td>60</td>
<td>18,005</td>
</tr>
<tr>
<td>Semester</td>
<td>3.77</td>
<td>2.60</td>
<td>1</td>
<td>18</td>
<td>17,919</td>
</tr>
<tr>
<td>Course quality</td>
<td>1.98</td>
<td>0.69</td>
<td>1</td>
<td>5</td>
<td>18,095</td>
</tr>
<tr>
<td>Absenteeism</td>
<td>1.14</td>
<td>1.22</td>
<td>0</td>
<td>10</td>
<td>18,215</td>
</tr>
</tbody>
</table>
</table-wrap>
</app>
</app-group>
<ack>
<title>Acknowledgments</title>
<p>The author is grateful to Marc Keuschnigg for sharing his vast knowledge about power laws with us and also for providing STATA do-files to determine the exact functional form in our data. The author also appreciates the help he received from Christiane Bozoyan, Roger Berger, and the participants of their courses on “deviant behavior” at the University of Bern and on “methods of social research” in Leipzig, who rated the physical attractiveness of the instructors for us. Furthermore, the author would like to thank Patrick Riordan and Martina Kroher for their language editing support and for useful comments, Edgar Treischl for excellent research assistance, and Professor Helmut Küchenhoff for a helpful discussion on the usefulness of different weighting approaches. Last but not least, the author also received helpful suggestions from two anonymous reviewers and important support from Professor Michael Foster, who encouraged the author to frame students’ absenteeism as a case of missing data and to organize the article in a straightforward way.</p>
</ack>
<fn-group>
<fn fn-type="conflict" id="fn15-0193841X12441355">
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn16-0193841X12441355">
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0193841X12441355">
<label>1.</label>
<p>Considering SET as measures of teaching quality in students’ perception appears to be more appropriate, since this definition highlights that objective teaching quality and its subjective perception need not be identical. Furthermore, this formulation emphasizes the interplay between students, instructor, and environmental conditions in the learning process (<xref ref-type="bibr" rid="bibr7-0193841X12441355">Biggs 1985</xref>; <xref ref-type="bibr" rid="bibr41-0193841X12441355">Ramsden 1979</xref>, <xref ref-type="bibr" rid="bibr42-0193841X12441355">1991</xref>; <xref ref-type="bibr" rid="bibr44-0193841X12441355">Rindermann and Schofield 2001</xref>).</p>
</fn>
<fn fn-type="other" id="fn2-0193841X12441355">
<label>2.</label>
<p>Thereby, the range of these assumptions is, of course, much wider than the test we suggest. This might be one reason why by now a vast amount of research on SET and, especially, on their validity exists (e.g., <xref ref-type="bibr" rid="bibr30-0193841X12441355">Kulik 2001</xref>; <xref ref-type="bibr" rid="bibr34-0193841X12441355">Marsh 1987</xref>; <xref ref-type="bibr" rid="bibr36-0193841X12441355">Merritt 2008</xref>). We cannot deal with all the details of this research branch. Nonetheless, if one is able to show, that a single factor (such as students’ class attendance) biases SET, this is already sufficient to call the common practice of ranking into question.</p>
</fn>
<fn fn-type="other" id="fn3-0193841X12441355">
<label>3.</label>
<p>This would also imply problems with the reliability of the measurement, because in this case SET then differ markedly at two different points in time.</p>
</fn>
<fn fn-type="other" id="fn4-0193841X12441355">
<label>4.</label>
<p>As one of the reviewers pointed out, there are further arguments against respective comparisons (see also Footnote 2). For example, it is a matter of fact that each of the student ratings refers to an individual context of teaching and learning and is performed by different groups of students.</p>
</fn>
<fn fn-type="other" id="fn5-0193841X12441355">
<label>5.</label>
<p>We are aware of the fact that other ranking procedures than a simple weighting have been suggested in the literature. <xref ref-type="bibr" rid="bibr20-0193841X12441355">Goldstein and Spiegelhalter (1996)</xref> argue for random effects models to take “account of model-based uncertainty in making comparisons” (for a discussion of this and alternative statistical methodologies, see <xref ref-type="bibr" rid="bibr14-0193841X12441355">Deely and Smith 1998</xref>; <xref ref-type="bibr" rid="bibr17-0193841X12441355">Draper and Gittoes 2004</xref>). In order to partial out biases, <xref ref-type="bibr" rid="bibr35-0193841X12441355">McPherson and Jewell (2007)</xref> propose to adjust SET for factors that are beyond the control of the instructor (e.g., instructor race) or can be gamed by them (e.g., grades).</p>
</fn>
<fn fn-type="other" id="fn6-0193841X12441355">
<label>6.</label>
<p>Rating portrait photos by a group of raters is a common way to measure physical attractiveness and is called the “truth of consensus method” (e.g., <xref ref-type="bibr" rid="bibr25-0193841X12441355">Henss 1992</xref>; <xref ref-type="bibr" rid="bibr39-0193841X12441355">Patzer 1985</xref>, <xref ref-type="bibr" rid="bibr40-0193841X12441355">2007</xref>). Further analyses show that raters highly agree in their ratings (Cronbach’s α = .95). We conclude from this fact that our measurements are reliable. However, one has to acknowledge that the attractiveness of a face is only one aspect of the broader theoretical construct “physical attractiveness.” This also includes further dimensions such as height, weight, body composition, and gesture. Because only photos of the face are available, we concentrate on this dimension of attractiveness, which seems to be the most important dimension of overall physical attractiveness (e.g., <xref ref-type="bibr" rid="bibr21-0193841X12441355">Hamermesh 2011</xref>).</p>
</fn>
<fn fn-type="other" id="fn7-0193841X12441355">
<label>7.</label>
<p>Since the number of classes missed is a typical case of count data with overdispersion (<xref ref-type="bibr" rid="bibr9-0193841X12441355">Cameron and Trivedi 1998</xref>; <xref ref-type="bibr" rid="bibr33-0193841X12441355">Long 1997</xref>), we ran negative binomial and zero-inflated negative binomial models as sensitivity analyses. The results are very similar and predicted values from both count data models are highly correlated with those from the simple linear regression model (<italic>r</italic> = .977 and <italic>r </italic>= .942). Because of this and since the use of a nonlinear link function does raise additional estimation issues (involving distributional assumptions) that are generally underappreciated, we only report findings from ordinary regressions. Results from analyses using nonlinear regression models are available on request from the author.</p>
</fn>
<fn fn-type="other" id="fn8-0193841X12441355">
<label>8.</label>
<p>Following the suggestion of one of the reviewers, we also estimated a mixed model with random effects on course and individual level to take into account the fact that students are also nested into classes. Our findings remain the same if we control for both forms of clustering, although standard errors are higher than in simple linear regression models. However, standard errors are even more conservative in the fixed-effects models we report.</p>
</fn>
<fn fn-type="other" id="fn9-0193841X12441355">
<label>9.</label>
<p>By asking students in the SET for a series of time constant, easily retrievable characteristics (gender, year of birth, degree of studies, the first two digits of their mother’s birthday, the first two initials of their parents’ first name, and the number of older brothers and sisters), we can link SET to individual students and are able to observe their rating and attendance behavior for different courses over time.</p>
</fn>
<fn fn-type="other" id="fn10-0193841X12441355">
<label>10.</label>
<p>By adding a subject-specific intercept α<italic>
<sub>i</sub>
</italic> for each individual <italic>i,</italic> the fixed-effects approach allows to take into account the unobserved heterogeneity ascribable to the presence of repeated observations on the same student (repeated over time <italic>t</italic> and repeated over more courses <italic>j</italic>). Formally, fixed-effects models can be written as <inline-formula id="inline-formula5-0193841X12441355">
<mml:math id="mml-inline5-0193841X12441355">
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">ϵ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>, where <bold>β</bold> is a vector of parameters, <bold>
<italic>X</italic>
</bold> is a matrix of covariates and ∊<sub>ijt</sub> are independent and normally distributed errors. Since fixed-effects models relate changes in <bold>
<italic>X</italic>
</bold> for individual <italic>i</italic> to changes in <italic>y</italic> for the very same individual, but not differences in <bold>
<italic>X</italic>
</bold> to differences in <italic>y</italic> between individuals, interindividual differences are averaged out and do not bias fixed-effects estimates. Thus, the main motivation for estimating fixed-effects models is usually not to determine the between-unit variability in the outcome exactly, but to work with the within-unit variability only to produce more reliable estimates.</p>
</fn>
<fn fn-type="other" id="fn11-0193841X12441355">
<label>11.</label>
<p>On the other hand, one could argue that students who miss more classes are less equipped to evaluate the quality of teaching. Moreover, a lecturer could be not very good in the perception of those students since they missed previous classes and as a result lack basic knowledge to continue to attend the course. From this perspective students who miss more classes should be given less weight, not more. However, the decision to weigh absent students up or down depends on whether the effect of perceived quality on attendance or of attendance on perceived quality is stronger. We do not deny that the latter could be present, but we think the former dominates the latter and, thus, decided to give absent students more weight.</p>
</fn>
<fn fn-type="other" id="fn12-0193841X12441355">
<label>12.</label>
<p>However, it is possible that students drop out of too difficult courses. Unfortunately, we cannot control for this process with our data.</p>
</fn>
<fn fn-type="other" id="fn13-0193841X12441355">
<label>13.</label>
<p>It is worth mentioning that the average number of observations per individual is rather small. In the fixed-effects context, this could lead to inconsistent estimates (<xref ref-type="bibr" rid="bibr10-0193841X12441355">Cameron and Trivedi 2005</xref>). For that reason, we reestimated all fixed-effects models for a subsample of person, for which 10 or more observations were available. Our main results are qualitatively very similar to those in <xref ref-type="table" rid="table1-0193841X12441355">Tables 1</xref> and <xref ref-type="table" rid="table2-0193841X12441355">2</xref>.</p>
</fn>
<fn fn-type="other" id="fn14-0193841X12441355">
<label>14.</label>
<p>To determine the exact functional form in our data, we estimated simple linear regression models. We used a procedure suggested by <xref ref-type="bibr" rid="bibr11-0193841X12441355">Clauset, Shalizi, and Newman (2009)</xref> to determine the cutoff point, which lies around a difference in ranks of 5. We also followed their example when testing whether a maximum likelihood approach yields better estimates (for a similar, but more comprehensive application of power law analyses in the field of books, see <xref ref-type="bibr" rid="bibr27-0193841X12441355">Keuschnigg 2012</xref>).</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Allison</surname>
<given-names>P. D.</given-names>
</name>
</person-group> <year>2009</year>. <source>Fixed Effects Regression Models</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr2-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Angrist</surname>
<given-names>J. D.</given-names>
</name>
<name>
<surname>Pischke</surname>
<given-names>J.-S.</given-names>
</name>
</person-group> <year>2009</year>. <source>Mostly Harmless Econometrics. An Empiricist’s Companion</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-0193841X12441355">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Arulampalam</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Naylor</surname>
<given-names>R. A.</given-names>
</name>
<name>
<surname>Smith</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Am I Missing Something? The Effects of Absence from Class on Student Performance.”</article-title> <comment>IZA Discussion Paper No. 3749. Accessed June 27, 2011</comment>, <ext-link ext-link-type="uri" xlink:href="https://www.econstor.eu/dspace/bitstream/10419/35597/1/581797353.pdf">https://www.econstor.eu/dspace/bitstream/10419/35597/1/581797353.pdf</ext-link>
</citation>
</ref>
<ref id="bibr4-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Babad</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Icekson</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Yelinek</surname>
<given-names>Y.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Antecedents and Correlates of Course Cancellation in a University ‘Drop and Add’ Period.”</article-title> <source>Research in Higher Education</source> <volume>49</volume>:<fpage>293</fpage>–<lpage>319</lpage>.</citation>
</ref>
<ref id="bibr5-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Becker</surname>
<given-names>W. E.</given-names>
</name>
<name>
<surname>Powers</surname>
<given-names>J. R.</given-names>
</name>
</person-group> <year>2001</year>. <article-title>“Student Performance, Attrition, and Class Size Given Missing Student Data.”</article-title> <source>Economics of Education Review</source> <volume>20</volume>:<fpage>377</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr55-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Becker</surname>
<given-names>W. E.</given-names>
</name>
<name>
<surname>Walstad</surname>
<given-names>W. B.</given-names>
</name>
</person-group>. <year>1990</year>. <article-title>“Data loss from Pretest to Posttest as a Sample Selection Problem.”</article-title> <source>Review of Economics and Statistics</source> <volume>72</volume>:<fpage>184</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr6-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Berger</surname>
<given-names>U.</given-names>
</name>
<name>
<surname>Schleußner</surname>
<given-names>C.</given-names>
</name>
</person-group> <year>2003</year>. <article-title>“Are Ratings of Lectures Confounded with Students' Frequency of Participation?”</article-title> <source>German Journal of Educational Psychology</source> <volume>17</volume>:<fpage>125</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr7-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Biggs</surname>
<given-names>J. B.</given-names>
</name>
</person-group> <year>1985</year>. <article-title>“The Role of Metalearning in Study Processes.”</article-title> <source>British Journal of Educational Psychology</source> <volume>55</volume>:<fpage>185</fpage>–<lpage>212</lpage>.</citation>
</ref>
<ref id="bibr8-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bosshardt</surname>
<given-names>W.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>“Student Drops and Failure in Principles Courses.”</article-title> <source>Journal of Economic Education</source> <volume>35</volume>:<fpage>111</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr9-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cameron</surname>
<given-names>A. C.</given-names>
</name>
<name>
<surname>Trivedi</surname>
<given-names>P. K.</given-names>
</name>
</person-group> <year>1998</year>. <source>Regression Analysis of Count Data</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cameron</surname>
<given-names>A. C.</given-names>
</name>
<name>
<surname>Trivedi</surname>
<given-names>P. K.</given-names>
</name>
</person-group> <year>2005</year>. <source>Microeconometrics. Methods and Applications</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr11-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Clauset</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Shalizi</surname>
<given-names>C. R.</given-names>
</name>
<name>
<surname>Newman</surname>
<given-names>M. E. J.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“Power-law Distributions in Empirical Data.”</article-title> <source>SIAM Review</source> <volume>51</volume>:<fpage>661</fpage>–<lpage>703</lpage>.</citation>
</ref>
<ref id="bibr12-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Costin</surname>
<given-names>F.</given-names>
</name>
</person-group> <year>1968</year>. <article-title>“A Graduate Course in the Teaching of Psychology: Description and Evaluation.”</article-title> <source>Journal of Teacher Education</source> <volume>19</volume>:<fpage>425</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr13-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>de Boer</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Endres</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Schimank</surname>
<given-names>U.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>“On the Way towards New Public Management? The Governance of University Systems in England, the Netherlands, Austria, and Germany.”</article-title> In <source>New Forms of Governance in Research Organizations</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Jansen</surname>
<given-names>D.</given-names>
</name>
</person-group>, <fpage>137</fpage>–<lpage>54</lpage>. <publisher-loc>Dordrecht, The Netherlands</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr14-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Deely</surname>
<given-names>J. J.</given-names>
</name>
<name>
<surname>Smith</surname>
<given-names>A. F. M.</given-names>
</name>
</person-group> <year>1998</year>. <article-title>“Quantitative Refinements for Comparisons of Institutional Performance.”</article-title> <source>Journal of the Royal Statistical Society</source> <volume>161</volume>:<fpage>5</fpage>–<lpage>12</lpage>.</citation>
</ref>
<ref id="bibr15-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Devadoss</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Foltz</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>1996</year>. <article-title>“Evaluation of Factors Influencing Student Class Attendance and Performance.”</article-title> <source>American Journal of Agricultural Economics</source> <volume>78</volume>:<fpage>499</fpage>–<lpage>507</lpage>.</citation>
</ref>
<ref id="bibr16-0193841X12441355">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Dobkin</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Gil</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Marion</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>“Causes and Consequences of Skipping Class in College.”</article-title> <comment>Working Paper, UC Santa Cruz. Accessed January 4, 2012</comment>, <ext-link ext-link-type="uri" xlink:href="http://people.ucsc.edu/∼cdobkin/Papers/Class_Attendance.pdf">http://people.ucsc.edu/∼cdobkin/Papers/Class_Attendance.pdf</ext-link>.</citation>
</ref>
<ref id="bibr17-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Draper</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Gittoes</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>“Statistical Analysis of Performance Indicators in UK Higher Education.”</article-title> <source>Journal of the Royal Statistical Society</source> <volume>167</volume>:<fpage>449</fpage>–<lpage>74</lpage>.</citation>
</ref>
<ref id="bibr18-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Esser</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>1997</year>. <article-title>“Zweifel an der Evaluation der Lehre.”</article-title> <source>Wirtschaftswissenschaftliches Studium: Zeitschrift für Ausbildung und Hochschulkontakt</source> <volume>26</volume>:<fpage>45</fpage>–<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr20-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Goldstein</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Spiegelhalter</surname>
<given-names>D. J.</given-names>
</name>
</person-group> <year>1996</year>. <article-title>“League Tables and Their Limitations: Statistical Issues in Comparisons of institutional Performance.”</article-title> <source>Journal of the Royal Statistical Society</source> <volume>159</volume>:<fpage>385</fpage>–<lpage>443</lpage>.</citation>
</ref>
<ref id="bibr21-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hamermesh</surname>
<given-names>D. S.</given-names>
</name>
</person-group> <year>2011</year>. <source>Beauty Pays. Why Attractive People Are More Successful</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hamermesh</surname>
<given-names>D. S.</given-names>
</name>
<name>
<surname>Parker</surname>
<given-names>A. M.</given-names>
</name>
</person-group> <year>2005</year>. <article-title>“Beauty in the Classroom. Instructors’ Pulchritude and Putative Pedagogical Productivity.”</article-title> <source>Economics of Education Review</source> <volume>24</volume>:<fpage>369</fpage>–<lpage>76</lpage>.</citation>
</ref>
<ref id="bibr23-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heckman</surname>
<given-names>J. J.</given-names>
</name>
</person-group> <year>1979</year>. <article-title>“Sample Selection Bias as a Specification Error.”</article-title> <source>Econometrica</source> <volume>47</volume>:<fpage>153</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr24-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hénard</surname>
<given-names>F.</given-names>
</name>
</person-group> <year>2010</year>. <source>Learning Our Lesson. Review of Quality Teaching in Higher Education</source>. <publisher-loc>Paris, France</publisher-loc>: <publisher-name>Organization for Economic Co-operation and Development</publisher-name>.</citation>
</ref>
<ref id="bibr25-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Henss</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>1992</year>. <source>Spieglein, Spieglein an der Wand.…Geschlecht, Alter und physische Attraktivität</source>. <publisher-loc>Weinheim</publisher-loc>: <publisher-name>Psychologie Verlags Union</publisher-name>.</citation>
</ref>
<ref id="bibr26-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kearney</surname>
<given-names>K. A.</given-names>
</name>
<name>
<surname>Hopkins</surname>
<given-names>R. H.</given-names>
</name>
<name>
<surname>Mauss</surname>
<given-names>A. L.</given-names>
</name>
<name>
<surname>Weisheit</surname>
<given-names>R. A.</given-names>
</name>
</person-group> <year>1984</year>. <article-title>“Self-Generated Identification Codes for Anonymous Collection of Longitudinal Questionnaire Data.”</article-title> <source>Public Opinion Quarterly</source> <volume>48</volume>:<fpage>370</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr27-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Keuschnigg</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2012</year>. <source>Das Bestseller-Phänomen. Die Entstehung von Nachfragekonzentration im Buchmarkt</source>. <publisher-loc>Wiesbaden</publisher-loc>: <publisher-name>VS Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr28-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kirby</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>McElroy</surname>
<given-names>B.</given-names>
</name>
</person-group> <year>2003</year>. <article-title>“The Effect of Attendance on Grade for First Year Economics Students in University College Cork.”</article-title> <source>Economic and Social Review</source> <volume>34</volume>:<fpage>311</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr29-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kohlan</surname>
<given-names>R. G.</given-names>
</name>
</person-group> <year>1973</year>. <article-title>“A Comparison of Faculty Evaluations Early and Late in the Course.”</article-title> <source>Journal of Higher Education</source> <volume>44</volume>:<fpage>587</fpage>–<lpage>95</lpage>.</citation>
</ref>
<ref id="bibr30-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kulik</surname>
<given-names>J. A.</given-names>
</name>
</person-group> <year>2001</year>. <article-title>“Student Ratings: Validity, Utility, and Controversy.”</article-title> <source>New Directions for Institutional Research</source> <volume>109</volume>:<fpage>9</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr31-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lane</surname>
<given-names>J. E.</given-names>
</name>
<name>
<surname>Kivisto</surname>
<given-names>J. A.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Interests, Information, and Incentives in Higher Education: Principal-Agent Theory and Its Potential Applications to the Study of Higher Education Governance.”</article-title> In <source>Higher Education: Handbook of Theory and Research</source>. <volume>Vol. XXIII</volume>, edited by <person-group person-group-type="editor">
<name>
<surname>Smart</surname>
<given-names>C. J.</given-names>
</name>
</person-group>, <fpage>141</fpage>–<lpage>79</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr32-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Little</surname>
<given-names>R. J.</given-names>
</name>
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> <year>1987</year>. <source>Statistical Analysis with Missing Data</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr33-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Long</surname>
<given-names>J. S.</given-names>
</name>
</person-group> <year>1997</year>. <source>Regression Models for Categorical and Limited Dependent Variables</source>. <publisher-loc>Thousand Oaks</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr34-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Marsh</surname>
<given-names>H.</given-names>
</name>
</person-group> <year>1987</year>. <article-title>“Students’ Evaluations of University Teaching: Research Findings, Methodological Issues, and Directions for Future Research.”</article-title> <source>International Journal of Educational Research</source> <volume>11</volume>:<fpage>253</fpage>–<lpage>388</lpage>.</citation>
</ref>
<ref id="bibr35-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>McPherson</surname>
<given-names>M. A.</given-names>
</name>
<name>
<surname>Jewell</surname>
<given-names>R. T.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>“Leveling the Playing Field: Should Student Evaluation Scores be Adjusted?”</article-title> <source>Social Science Quarterly</source> <volume>88</volume>:<fpage>868</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr36-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Merritt</surname>
<given-names>D. J.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Bias, the Brain, and Student Evaluations of Teaching.”</article-title> <source>St. John’s Law Review</source> <volume>82</volume>:<fpage>235</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr37-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mitzenmacher</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2003</year>. <article-title>“A Brief History of Generative Models for Power Law and Lognormal Distributions.”</article-title> <source>Internet Mathematics</source> <volume>1</volume>:<fpage>226</fpage>–<lpage>51</lpage>.</citation>
</ref>
<ref id="bibr38-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Newman</surname>
<given-names>M. E. J.</given-names>
</name>
</person-group> <year>2005</year>. <article-title>“Power Laws, Pareto Distributions and Zipf's Law.”</article-title> <source>Contemporary Physic</source> <volume>46</volume>:<fpage>323</fpage>–<lpage>51</lpage>.</citation>
</ref>
<ref id="bibr39-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Patzer</surname>
<given-names>G. L.</given-names>
</name>
</person-group> <year>1985</year>. <source>The Physical Attractiveness Phenomena</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Plenum Press</publisher-name>.</citation>
</ref>
<ref id="bibr40-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Patzer</surname>
<given-names>G. L.</given-names>
</name>
</person-group> <year>2007</year>. <source>Why Physically Attractive People are More Successful. The Scientific Explanation, Social Consequences, and Ethical Problems</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Edwin Mellen Press</publisher-name>.</citation>
</ref>
<ref id="bibr41-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ramsden</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>1979</year>. <article-title>“Student Learning and Perceptions of the Academic Environment.”</article-title> <source>Higher Education</source> <volume>8</volume>:<fpage>411</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr42-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ramsden</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>1991</year>. <article-title>“A Performance Indicatory of Teaching Quality in Higher Education: The Course Experience Questionnaire.”</article-title> <source>Studies in Higher Education</source> <volume>16</volume>:<fpage>129</fpage>–<lpage>50</lpage>.</citation>
</ref>
<ref id="bibr43-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Reed</surname>
<given-names>J. G.</given-names>
</name>
</person-group> <year>1981</year>. <article-title>“Dropping a College Course: Factors Influencing Students’ Withdrawal Decisions.”</article-title> <source>Journal of Educational Psychology</source> <volume>73</volume>:<fpage>376</fpage>–<lpage>85</lpage>.</citation>
</ref>
<ref id="bibr44-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rindermann</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Schofield</surname>
<given-names>N.</given-names>
</name>
</person-group> <year>2001</year>. <article-title>“Generalizability of Multidimensional Student Ratings of University Instruction across Courses and Teachers.”</article-title> <source>Research in Higher Education</source> <volume>42</volume>:<fpage>377</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr45-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Romer</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>1993</year>. <article-title>“Do Students Go to Class? Should They?”</article-title> <source>Journal of Economic Perspectives</source> <volume>7</volume>:<fpage>167</fpage>–<lpage>74</lpage>.</citation>
</ref>
<ref id="bibr46-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>1976</year>. <article-title>“Inference with Missing Data.”</article-title> <source>Biometrika</source> <volume>63</volume>:<fpage>581</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr47-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sporn</surname>
<given-names>B.</given-names>
</name>
</person-group> <year>2011</year>. <article-title>“Governance and Administration: Organizational and Structural Trends.”</article-title> In <source>International Handbook of Higher Education</source>. <volume>Vol. 1</volume>, edited by <person-group person-group-type="editor">
<name>
<surname>Forest</surname>
<given-names>J. F.</given-names>
</name>
<name>
<surname>Altbach</surname>
<given-names>P. G.</given-names>
</name>
</person-group>, <fpage>141</fpage>–<lpage>57</lpage>. <publisher-loc>Dordrecht, The Netherlands</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr48-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Thomas</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Adams</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Birchenough</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>1996</year>. <article-title>“Student Withdrawal from Higher Education.”</article-title> <source>Educational Management Administration &amp; Leadership</source> <volume>24</volume>:<fpage>207</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr49-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Tinto</surname>
<given-names>V.</given-names>
</name>
</person-group> <year>1993</year>. <source>Leaving College: Rethinking the Causes and Cures of Student Attrition</source>. <publisher-loc>Chicago</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr50-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wilkesmann</surname>
<given-names>U.</given-names>
</name>
<name>
<surname>Schmid</surname>
<given-names>C. J.</given-names>
</name>
</person-group> <year>2011</year>. <article-title>“The Impacts of New Governance on Teaching at German Universities. Findings from a National Survey in Germany.”</article-title> <source>Higher Education</source>, <comment>doi:10.1007/s10734-011-9423-1</comment>
</citation>
</ref>
<ref id="bibr51-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wolbring</surname>
<given-names>T</given-names>
</name>
</person-group>. <year>2010</year>. <article-title>“Physical Attractiveness, Gender and the Evaluation of Teaching. A Replication Study of Hamermesh’s and Parker’s (2005) and Klein’s and Rosar’s (2006) Findings Analyzing Individual Data.”</article-title> <source>Zeitschrift für Evaluation</source> <volume>9</volume>:<fpage>29</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr52-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wooldridge</surname>
<given-names>J. M.</given-names>
</name>
</person-group> <year>2002</year>. <source>Econometric Analysis of Cross Section and Panel Data</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr53-0193841X12441355">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Yorke</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>1999</year>. <source>Leaving Early: Undergraduate Non-completion in Higher Education</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Falmer Press</publisher-name>.</citation>
</ref>
<ref id="bibr54-0193841X12441355">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yurek</surname>
<given-names>L. A.</given-names>
</name>
<name>
<surname>Vasey</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Havens</surname>
<given-names>D. S.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“The Use of Self-Generated Identification Codes in Longitudinal Research.”</article-title> <source>Evaluation Review</source> <volume>32</volume>:<fpage>1</fpage>–<lpage>18</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>