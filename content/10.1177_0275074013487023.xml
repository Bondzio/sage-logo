<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ARP</journal-id>
<journal-id journal-id-type="hwp">sparp</journal-id>
<journal-title>The American Review of Public Administration</journal-title>
<issn pub-type="ppub">0275-0740</issn>
<issn pub-type="epub">1552-3357</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0275074013487023</article-id>
<article-id pub-id-type="publisher-id">10.1177_0275074013487023</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Invited Essay</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Advancing the Empirical Study of Performance Management</article-title>
<subtitle>What We Learned From the Program Assessment Rating Tool</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Moynihan</surname><given-names>Donald P.</given-names></name>
<xref ref-type="aff" rid="aff1-0275074013487023">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0275074013487023"><label>1</label>La Follette School of Public Affairs, University of Wisconsin-Madison, USA</aff>
<author-notes>
<corresp id="corresp1-0275074013487023">Donald P. Moynihan, La Follette School of Public Affairs, University of Wisconsin-Madison, 122 5Observatory Drive, Madison, 53711, USA. Email: <email>dmoynihan@lafollette.wisc.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2013</year>
</pub-date>
<volume>43</volume>
<issue>5</issue>
<fpage>499</fpage>
<lpage>517</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Interest in performance management has never been higher. But what does actual research on this topic tell us about the effects of performance management, reform efforts, and governance more generally? Historically, the answer often seemed to be that such reforms did not work very well. This article focuses on a recent chapter in the history of performance management at the U.S. federal government, the Program Assessment Rating Tool (PART). PART was created by the George W. Bush administration, and ended by the Obama White House. PART, like many management initiatives, came and went. What distinguishes it, however, is the quality and breadth of the research it prompted—research that has increased our knowledge of performance management and reform implementation as well as a whole host of fundamental governance phenomena such as political ideology, administrative burden, performance information use, leadership commitment, and goal ambiguity.</p>
</abstract>
<kwd-group>
<kwd>performance management</kwd>
<kwd>administrative reform</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0275074013487023" sec-type="intro">
<title>Introduction</title>
<p>In the last decade, the study of performance management has progressed dramatically. In part, this is because of the ongoing popularity of the topic for practitioners. But it is also a function of more rigorous use of research methods to address a wide variety of questions. For example, framing performance information use as a behavioral question of significant importance has encouraged a variety of researchers to model its antecedents and consequences (<xref ref-type="bibr" rid="bibr31-0275074013487023">Moynihan &amp; Pandey, 2010</xref>). We are starting to see the use of experimental designs to persuasively model the response to performance data (e.g., <xref ref-type="bibr" rid="bibr21-0275074013487023">James, 2011</xref>). The use of mixed methods and careful modeling have unearthed how performance regimes operate in a contracted-out environment (e.g., <xref ref-type="bibr" rid="bibr19-0275074013487023">Heinrich, 2010</xref>; <xref ref-type="bibr" rid="bibr43-0275074013487023">Soss, Fording, &amp; Schram, 2011</xref>).</p>
<p>In a variety of ways we can therefore make the case that there has been a dramatic improvement in our knowledge of the workings of performance management reforms. One area that is less tractable to some of the improved application of research methods are whole-of-government performance reforms. We usually lack a randomized control or variation in the rates of adoption that might provide inferences about the effects of such reforms. There are too many potential measures of performance to consider, and attribution problems are too severe—we cannot exclude the possibility that some change in a desired performance goal were not the result of external factors. We might have success stories on some dimension—say money saved—but we also have trade-off problems. Public organizations pursue multiple goals, and while we might point to an increase in performance in one area, we are likely to be unaware of whether it came at the cost of a reduction in performance in another (possibly unmeasured) area.</p>
<p>What to do given the difficulties of studying performance management reforms and similar government-wide reforms? Scholars have still looked for ways to provide insights, and such insights have come. To develop these insights, researchers have historically relied on some variation on the “soak and poke” method associated with Richard Fenno: the researcher mixes observation and interviews of public managers to generate insights about the implementation of the reform. I will refer to this as the “traditional approach,” which can be found in the work of giants in the early study of performance systems, such as Aaron Wildavksy and Allen Schick. It also appears in more recent empirical work (e.g., <xref ref-type="bibr" rid="bibr11-0275074013487023">Frederickson &amp; Frederickson, 2006</xref>; <xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>, <xref ref-type="bibr" rid="bibr36-0275074013487023">Radin, 2006</xref>).</p>
<p>This traditional approach has offered us some very real and profound insights. In an earlier era, Wildavksy pointed to the cognitive limitations and political disinterest that made the systematic use of performance data unlikely. More recently, <xref ref-type="bibr" rid="bibr36-0275074013487023">Radin (2006)</xref> has argued persuasively that the institutional design of the U.S. government is at odds with basic performance management assumptions, and that performance management works less well for some tasks than others. There is a general sense that these processes are burdensome, rarely replacing existing requirements, and complied with begrudgingly. The tone of this work is frequently critical, and a traditional trope is to compare the hopes or explicit goals of reformers with how things work in practice. This has often been useful, casting a skeptical eye on reforms that frequently have uncritical or naive boosters. But these assessments often appear to leave little room for optimism for performance management techniques.</p>
<p>The traditional approach to performance management is frequently mixed with general theorizing about the relationship between these reforms and the existing social processes and behavior in government. It is not always apparent whether the more general theories are a function of the qualitative data, or whether the data is more illustrative. Indeed, in some cases the theoretical argument is explicitly normative.</p>
<p>One very real limitation of the traditional approach is that it is often only as good as the person doing it. It depends on their ability to gain trust, what they make of the information they observe and hear, and how persuasively they tell that story. Or to put it another way, we are not all Wildavsky. Of course, the quality of more recent work that relies primarily upon quantitative techniques also depends on the researcher, but the terms for testing causal claims and statistical problems can be assessed more transparently, and others can take the same data and evaluate it.</p>
<p>This article narrates the insights scholars have drawn from studying the Program Assessment Rating Tool (PART), a now-defunct government-wide performance initiative of the George W. Bush administration. One pattern that characterized PART is a greater presence of research that relied on quantitative techniques, and a behavioral approach. PART might have had negligible effects on actual governing (more on that in the paper) but it has undoubtedly facilitated the empirical study of performance management, providing an array of studies using different techniques, asking different research questions. The resulting studies provide some of the most compelling tests on whether a government-wide reform achieved its goal. There may have been a parallel level of interest in reforms like the National Performance Review and the Government Performance and Results Act (GPRA) of 1993, but with some notable exceptions (e.g., <xref ref-type="bibr" rid="bibr46-0275074013487023">Thompson, 1999</xref>) this interest did not develop reasonable estimates as to the effect of the reform. Studies of PART also offer insights into basic questions of governance and management: the role of political ideology in administrative reform, administrative burden, goal ambiguity, political appointees, and the role of leadership. In what follows I do not include all studies of PART, but tend to favor those in peer-reviewed journals, and which were clearly empirical, regardless of whether they were qualitative or quantitative.</p>
<p>It is important to note that the purpose of this article is not to anoint one methodological technique or theoretical tradition at the expense of another. Indeed, I am in no position to do so even if I were so inclined. My own studies of PART have ranged from the traditional soak-and-poke approach to developing and testing formal models, and I have mixed normative and behavioral theorizing. In the narrative that follows, I weave in work from these contrasting approaches. The central point for the study of performance management, and administrative reforms more generally, is the need to utilize a variety of approaches. We know more about the workings of PART, and PART has helped us to understand other basic questions, precisely because it has been tackled by a variety of approaches that have collectively complemented one another. The key difference relative to earlier reforms is the balancing of the traditional approaches with methodological techniques that sought to test causal theory.</p>
</sec>
<sec id="section2-0275074013487023">
<title>What Was PART?</title>
<p>Here I offer a thumbnail sketch of the essential features of PART. Those interested in a more extensive account of the development and history of PART should turn to <xref ref-type="bibr" rid="bibr8-0275074013487023">Dull (2006)</xref>, or <xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan (2008)</xref>. PART was an outgrowth of the <xref ref-type="bibr" rid="bibr47-0275074013487023">2001</xref> President’s Management Agenda, a blueprint prepared by the U.S. Office of Management and Budget (OMB) to represent President Bush’s management goals. Included in this agenda was the goal of integrating performance data and budgeting. PART was a product of this goal.</p>
<p>PART itself was a survey instrument, developed by OMB staff with outside advice. The instrument asked 25 to 30 questions divided into four categories: program purpose and design, strategic planning, program management, and program results. Based on the responses to those questions, programs were given a numerical score that aligned with a categorical scale of performance ranging from effective, moderately effective, adequate, or ineffective. In cases where evaluators felt they could not make a judgment, programs were assigned a “results not demonstrated” judgment, which was generally believed to be a negative assessment on a par with an ineffective grade.</p>
<p>The tool was implemented by OMB budget examiners, but with extensive consultation with agency staff. Ultimately, the evaluation reflected the judgment of the examiner, but the input of the agency was substantial. If the agency was unhappy with a program score, it could appeal to senior appointees at OMB, or seek a reevaluation at a later period.</p>
<p>Over a 5-year time period, the OMB assessed just over 1,000 federal programs, representing 98% of the federal budget. PART was hailed as a successful innovation, winning the prestigious Innovations in American Government Award. However, PART ended with the Bush administration. The Obama administration characterized the tool as ineffective at generating true performance information use. Overwhelmed with the economic downturn and dealing with a massive stimulus package, it deployed OMB resources for other purposes (<xref ref-type="bibr" rid="bibr22-0275074013487023">Joyce, 2011</xref>).</p>
</sec>
<sec id="section3-0275074013487023">
<title>Did PART Increase Performance Information Use?</title>
<p>To assess whether PART worked, we must define what PART’s goals were. To some degree, this is a matter of speculation, but one clear goal was to increase performance information use. The Bush administration criticized GPRA on these grounds, saying “After eight years of experience [since passage of GPRA], progress toward the use of performance information for program management has been discouraging . . . Performance measures are insufficiently used to monitor and reward staff, or to hold program managers accountable” (<xref ref-type="bibr" rid="bibr47-0275074013487023">OMB 2001</xref>, p. 27). Did PART do any better than GPRA in this regard? PART certainly placed more demands on agencies than before (as explained below), but did it increase use? At an aggregate level, the answer to both questions appears to be no.</p>
<sec id="section4-0275074013487023">
<title>Managerial Use</title>
<p><xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan and Lavertu (2012)</xref> seek to estimate the effects of PART using 2007 Government Accountability Office (GAO) survey data. Since PART was implemented across government, there is no group of control and treatment groups to compare, and we do not have cross-time data that allows pre–post comparisons of exposure to PART. In an attempt to solve this problem, Moynihan and Lavertu use self-reported involvement in PART as a treatment to assess its impact, with the assumption that this involvement should increase use. Comparisons of rates of performance information use among those involved with PART and those who were not can be therefore used to infer if PART increased use. If PART is unable to increase performance information use among those exposed to it (about one third of federal managers surveyed), there seems little hope it will increase use among those who are unaware of it. While there is a possible selection effect in play (those who were selected to be involved in performance management might be different from others), it seems to run in the direction of finding a positive result between involvement and use.</p>
<p>Moynihan and Lavertu divide the dependent variables representing performance information use into two categories. <italic>Passive use</italic> represents the use of data to comply with existing performance management requirements, and is represented by survey items tracking the use of data for refining measures and setting goals. <italic>Purposeful use</italic> implies the use of data for decision making and performance improvement, and is represented by items tracking use of data for setting program priorities, changing processes, allocating resources, taking corrective action to solve program problems, setting employee job expectations, and rewarding employees.</p>
<p>Controlling for agency fixed effects and a variety of additional individual and organizational variables, the authors find that involvement in PART is not significantly associated with purposeful performance information use. The one exception is that it is positively associated with the use of data for changing processes, though the size of the effect is not large and it is significant only at marginal levels. In contrast, PART involvement is strongly associated with passive uses of data to refine measures and goals. The authors compare the findings on PART with 2000 survey data tracking the same items with respect to GPRA. The results look almost identical. Involvement in GPRA is associated with passive use of performance data, but not with purposeful forms of use. In fact, GPRA performs slightly better statistically than PART, associated with using data to change processes at the <italic>p</italic> &lt; .05 for a two-tailed test, and with using data to set program priorities at the .10 level.</p>
<p>The findings are at odds with the goals of PART, but are consistent with claims that critics of PART have made. Overall, the results suggest that despite differences, PART and GPRA generated similar responses among federal managers. They were perceived primarily as a compliance exercise rather than an opportunity to generate purposeful performance information use (though in the section of political ideology that follows, I describe one major exception to this finding). As a formal mechanism of control PART, like GPRA, emphasized creating routines of data collection and dissemination, and gave relatively little attention to routines of performance information use. From this perspective, it is unsurprising that federal managers responded by devoting attention to measurement, and not use.</p>
<p><xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan and Lavertu (2012)</xref> point to other factors are associated with performance information use. Three are highlighted here, on the basis of relatively strong theoretical and empirical support from prior work on performance information use, as well as findings in the context of PART.</p>
<sec id="section5-0275074013487023">
<title>Goal Clarity</title>
<p>A variety of studies on performance information use have emphasized the positive benefits of goal clarity to performance information use (e.g., <xref ref-type="bibr" rid="bibr33-0275074013487023">Moynihan, Wright, &amp; Pandey, 2012</xref>). This is consistent with basic claim of Locke and Latham’s goal-setting theory that more specific goals are more motivational. <xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan and Lavertu (2012)</xref> add an additional twist to the goal-clarity point, showing that the managerial perception that it was easy to determine how to use performance information to improve the program was significantly associated with use. The connection between data and action is partly a function of the complexity of the task, but likely also partly a function of those undertaking it. It is likely that greater consideration of causality in discussions of performance may clarify the connection between measures and actions.</p>
</sec>
<sec id="section6-0275074013487023">
<title>Learning Forums</title>
<p>Federal managers who reported having basic discussions with their supervisors and peers about performance information also were more likely to report using performance data for purposeful means. This may seem an obvious point. But discussing data and using data is not the same thing. A common design flaw of performance management reforms, including PART, is the failure to give attention to creating routines of use. Discussion of performance data appears to be a strong social process that help use to occur.</p>
</sec>
<sec id="section7-0275074013487023">
<title>Leadership Commitment by Leaders</title>
<p><xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan and Lavertu (2012)</xref> find that perceived leadership commitment to results is positively associated with performance information use in the context of PART, echoing prior results in the context of GPRA (<xref ref-type="bibr" rid="bibr9-0275074013487023">Dull, 2009</xref>) and elsewhere (e.g., <xref ref-type="bibr" rid="bibr1-0275074013487023">Askim, Johnsen, &amp; Christophersen, 2008</xref>; <xref ref-type="bibr" rid="bibr29-0275074013487023">Moynihan &amp; Ingraham, 2004</xref>). These findings align with some qualitative work that had pointed to leadership commitment as important to PART. For example, in his qualitative study of PART implementation <xref ref-type="bibr" rid="bibr14-0275074013487023">Gilmour (2006)</xref> noted that perceived commitment to PART by Secretary of State Colin Powell facilitated lower level commitment.</p>
</sec>
</sec>
<sec id="section8-0275074013487023">
<title>Budgeting Use</title>
<p>A particular goal of PART was to facilitate the use of performance data for budgeting. The <xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan and Lavertu (2012)</xref> assessment of the impact of PART on managers did not find a relationship between PART involvement and use of performance data for budget execution. <xref ref-type="bibr" rid="bibr15-0275074013487023">Gilmour and Lewis (2006)</xref> regress PART scores on changes the President’s proposed budget, and find a modest but significant positive correlation. This fits with qualitative accounts of OMB staff taking PART seriously, using it as at least one relevant piece of information in budget decisions (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>; <xref ref-type="bibr" rid="bibr35-0275074013487023">Posner &amp; Fantone, 2007</xref>; <xref ref-type="bibr" rid="bibr49-0275074013487023">White, 2012</xref>). It also makes a good deal of sense that OMB officials might be at least somewhat likely to pay attention to the results of the tool they developed.</p>
<p>Actual budget appropriations are determined not by the President, but by Congress. Here, qualitative and quantitative work generally coalesce to suggest that PART did not have an effect on appropriations. Qualitative research found that congressional actors paid little attention to PART (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>; <xref ref-type="bibr" rid="bibr39-0275074013487023">Redburn &amp; Newcomer, 2008</xref>), and PART scores did not systematically influence budget decisions. Content analyses of Congressional budget deliberations suggested that PART was not widely used, and appeared to lose influence over time (<xref ref-type="bibr" rid="bibr12-0275074013487023">Frisco &amp; Stalebrink, 2008</xref>) and that Congress had plenty of other types of performance information to draw on if it was so inclined (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>). One reason for this resistance is that congressional staffers often doubted the judgments that less experienced OMB budget examiners drew from PART (<xref ref-type="bibr" rid="bibr49-0275074013487023">White, 2012</xref>). <xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich (2012)</xref> offers the most careful attempt to link PART to congressional decisions. Examining 95 Health and Human Service programs, she finds no connection between PART scores and budget changes.</p>
<p>A basic measure of Congressional resistance is that efforts to put PART in statute won little support, partly because of Democratic fears it was a partisan tool, but also because of an unwillingness to delegate institutional prerogatives from the legislature to the White House (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>). <xref ref-type="bibr" rid="bibr44-0275074013487023">Stalebrink and Frisco (2011)</xref> developed a quantitative model of legislative support for PART. To measure their dependent variable, they coded public comments made by legislative actors about PART. They found that partisanship did not explain legislative statements of support for PART. Legislators with a business background were more apt to support PART, while those with greater experience or who had received a great deal of campaign contributions from special interests were more resistant to it.</p>
</sec>
</sec>
<sec id="section9-0275074013487023">
<title>The Costs of PART</title>
<p>If PART did not obviously increase performance information use among managers, or result in performance budgeting, there is good evidence that it generated significant costs in implementation. Reforms do not implement themselves, and implementation costs should be considered as a factor in assessing the worth of these reforms. In the case of PART two particular sets of actors—OMB staff and agency officials—bore the brunt of these costs.</p>
<p>The death of PART went unmourned by OMB staff. They had added PART to their existing budgetary responsibilities with few additional resources. OMB staff complained about the burdens of PART (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>; <xref ref-type="bibr" rid="bibr39-0275074013487023">Redburn &amp; Newcomer, 2008</xref>). One GAO report argued that PART was spreading budget examiners attention too thin, a point reinforced by White’s interviews of OMB staff (2012). The focus on PART also created opportunity costs, argued <xref ref-type="bibr" rid="bibr49-0275074013487023">White (2012)</xref>, reducing the ability of OMB to think more analytically about allocative efficiency in judging spending.</p>
<p>Survey assessments of agency staff also found the process burdensome. The GAO survey found that 31% of agency officials reported they had been involved in PART in some way (<xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan &amp; Lavertu, 2012</xref>). Another survey asked “How much time and effort did your agency put into the Program Assessment Rating Tool (PART) process?” Answers ranged from “Not much at all” (1) to “Tremendous amount” (5), with an average response of 3.92, well above the midpoint. Qualitative studies have also emphasized the burdens created by PART on agencies (<xref ref-type="bibr" rid="bibr11-0275074013487023">Frederickson &amp; Frederickson, 2006</xref>; <xref ref-type="bibr" rid="bibr14-0275074013487023">Gilmour, 2006</xref>). <xref ref-type="bibr" rid="bibr39-0275074013487023">Redburn and Newcomer (2008</xref>, p. 3) noted: “Some agency officials are skeptical, or even cynical, about the benefits reaped by program managers and executives from program assessment and evaluation, especially compared to the heavy costs entailed in both and when the resulting data are not used to inform decisions.” Some descriptive statistics reported by Gallo and Lewis on the perceived value of PART reiterate this point. They find that more managers believed that PART rarely (22.7%) or never (14.2%) reflected real differences in program performance than believed that that it almost always (2.6%) or generally (14.9%) did. An additional 26.6% believed that PART sometimes reflected real differences, and 19% did not know.</p>
</sec>
<sec id="section10-0275074013487023">
<title>Preach to the Choir and Punish the Heretics? Political Ideology and PART</title>
<p>PART represents an opportunity to examine how political ideology may matter to the implementation of management reforms. A research literature on political control of the bureaucracy has emphasized two main tactics: centralization of policy making authority into the White House and politicization of agencies primarily via the use of political appointees (<xref ref-type="bibr" rid="bibr27-0275074013487023">Lewis, 2008</xref>; <xref ref-type="bibr" rid="bibr41-0275074013487023">Rudalevige, 2002</xref>). Both parties have used these tools, and seem to use them more aggressively when there is ideological divergence between the President and an agency. These tools are therefore overtly ideological, and given the perceived liberalism of large parts of the federal bureaucracy, tend to be most overt in the case of conservative Presidents (e.g., <xref ref-type="bibr" rid="bibr16-0275074013487023">Golden, 2000</xref>; <xref ref-type="bibr" rid="bibr32-0275074013487023">Moynihan &amp; Roberts, 2010</xref>). However, there is relatively little attention to how nominally nonpartisan “good-government” initiatives are implemented in ways that suggest a partisan bias in implementation on the part of the principal, or response on the part of the agent (for an exception, see <xref ref-type="bibr" rid="bibr10-0275074013487023">Durant’s [2008]</xref> account of the implementation of the National Performance Review in the conservative Department of Defense).</p>
<p>The study of PART unearthed a series of insights into the role of political ideology in reform implementation. A series of papers show that under a relatively conservative President, programs in liberal agencies received systematically lower effectiveness scores, were more at risk of budget losses because of these scores, and experienced a greater administrative burden in implementing the reforms. The practical benefits of PART, in terms of greater use of performance data, appear to be reserved for more conservative agencies.</p>
<p>PART was presented as a good-government initiative, deliberately constructed to avoid the criticism that it was a partisan tool. The basic design of the tool incorporated peer review from outside performance management experts and the National Academy of Public Administration, and was revised to drop questions that might be seen as overtly political. Mitch Daniels, Director of OMB when PART was created, urged staff to create a nonpartisan tool (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>). The assessments were carried out by OMB career staff rather than appointees. Compared to the traditional mechanisms of political control that presidents have used, PART seemed markedly different, argued Matthew <xref ref-type="bibr" rid="bibr8-0275074013487023">Dull (2006)</xref>, who offers a narrative history of its creation. Dull offered a compelling argument for why the Bush administration invested in making PART a politically neutral tool, asking “Why would this administration, otherwise so strategic in its approach to administration, invest great time and energy building a neutral and transparent instrument like PART?” (<xref ref-type="bibr" rid="bibr8-0275074013487023">2006</xref>, p. 189). The answer is that reforms like PART “seek to orient and revise policy administration by gathering and organizing intelligence and by aligning agency activities with administration priorities. Modern presidents face a dilemma in that policy competence, and the credible information about policy process and outcomes it provides, requires investments of resources and discretion, and with them the acceptance of political risk” (p. 192). There was a political logic to invest in a politically neutral tool, Dull concludes, because the tool could only be beneficial in enabling the administration to pursue its policy goals if it was seen as credible.</p>
<p>My own early assessment of PART tended to align with that of Dull’s. Certainly in interviewing members of OMB, they took pains to emphasize that PART was not a partisan tool. Overt partisanship would likely have reduced the willingness of OMB career staff to invest the very great time and effort involved in implementing PART. OMB staff tended to argue that the PART score was not politically influenced, although they noted that the budget decisions that accompanied PART were always a political decision, implying the link between PART scores and budgets would not be equally applied. Some agency staff and Democrats tended to be less sanguine about PART, suggesting that since liberal programs tended to deal with complex social problems, they would have a harder time demonstrating outcomes. Democratic legislators viewed PART “as a White House tool to cloak ideologically based attacks on traditionally liberal programs under the neutrality of management” (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>, p. 134).</p>
<p>It is fair to suggest that while there was some qualitative evidence both for and against the notion that political ideology mattered to PART, there was little evidence that it was an overt strategy. But the weight of evidence that emerges at this point suggests that PART was partisan, if not in thought than in deed. This evidence comes in a variety of forms, but it implies a basic willingness on the part of the reader to accept that certain types of tasks, programs, and agencies can be placed approximately on the liberal–conservative political spectrum. Such a claim has been made, with little contention, within political science (<xref ref-type="bibr" rid="bibr4-0275074013487023">Clinton, Bertelli, Grosse, &amp; Lewis, 2012</xref>; <xref ref-type="bibr" rid="bibr5-0275074013487023">Clinton &amp; Lewis, 2008</xref>). But systematic use of both the concept and measures of agency ideology is novel within public administration, perhaps reflective of a traditional intellectual preference for keeping matters of partisan politics out of administration. It is worth noting that the bulk of the studies on the ideology of PART come from scholars with a political science disciplinary training.</p>
<p>The potential influence of ideology, or other discretionary factors, is made feasible because PART was not a precise tool applied in exactly the same way by all budget examiners. Despite the very real effort of the OMB to make PART a consistent tool, including training and a guidebook on how to implement PART (<xref ref-type="bibr" rid="bibr48-0275074013487023">OMB, 2007</xref>), qualitative research has pointed out the ambiguity inherent in many of the questions asked in PART, and in defining what constituted an acceptable answer (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>; <xref ref-type="bibr" rid="bibr35-0275074013487023">Posner &amp; Fantone, 2007</xref>). The possibility of an ideological effect is also enhanced because PART reallocated greater power to OMB, which is part of the White House. Prior to the Bush administration, OMB played a secondary role in shaping the performance goals of agencies. PART gave OMB a process by which it could communicate to agencies what their preferred goals should be. Indeed, a content analysis of management recommendations made by OMB to agencies during the PART process found that the majority of these recommendations focused on agency goals and measurement, and not management issues (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>). Even though most staff there are career officials, part of their job is to represent the goals of the president. Presidential preferences may, consciously or unconsciously, affect the judgment of budget examiners in ambiguous situations that allow for discretionary judgment. And the judgment process was not completely separated from political staff at OMB, since unhappy agency staff could appeal their judgments up to political appointees at the OMB. This happened rarely, but the mere threat of it may have compelled budget examiners to marginally favor programs that aligned with appointee ideology rather than risk having their judgment overturned. Finally, political leaders in agencies could affect how PART was implemented. They could make it more or less a priority, affecting how resources were allocated to completing PART, and therefore affecting scores. They could also use PART as a mechanism to closely evaluate programs they may not have trusted could perform well (more on this process below).</p>
<p>How did ideology reveal itself? First, a variety of evidence has established that more liberal agencies received systematically lower scores on PART than more conservative ones. Relying on agency-level preference estimates created by <xref ref-type="bibr" rid="bibr5-0275074013487023">Clinton and Lewis (2008)</xref> to categorize programs, <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo and Lewis (2012)</xref> find that programs housed in liberal agencies score systematically lower than moderate agencies, which in turn score lower than programs in conservative agencies. This remains true even when program type and other controls are included. In a narrower context that controls for task, <xref ref-type="bibr" rid="bibr45-0275074013487023">Thomas and Fumia (2011)</xref> examine the PART scores for environmental programs. They include a dummy variable for those housed in Environmental Protection Agency (EPA) programs, since this agency is considered a liberal agency (<xref ref-type="bibr" rid="bibr5-0275074013487023">Clinton &amp; Lewis 2008</xref>) and find that environmental programs housed in the EPA receive lower scores relative to environmental program elsewhere in the federal government. Finally, <xref ref-type="bibr" rid="bibr17-0275074013487023">Greitens and Joaquin (2010)</xref>, who find that programs with redistributive purposes receive lower scores than others.</p>
<p>There is also evidence that ideology mattered to how PART influenced budgets. As noted above, there is only strong evidence that PART mattered to budget allocations in the President’s proposed budget. Here, <xref ref-type="bibr" rid="bibr15-0275074013487023">Gilmour and Lewis (2006)</xref> find that this relationship is explained by programs created under unified Democratic control. Put more simply, liberal programs were exposed to the risks of performance budgeting, while conservative programs were not. They also found that large programs were largely impervious to PART scores for budgeting purposes.</p>
<p>Given these patterns, we might assume that ideological differences might extend to agency behavior in response to PART. There is evidence to support this assumption. <xref ref-type="bibr" rid="bibr25-0275074013487023">Lavertu, Lewis, and Moynihan (2012)</xref> examine the level of effort reported by managers in responding to PART. They find that respondents in liberal agencies report a greater level of effort than those in conservative agencies, using equivalent data from different sources. For example, 67% of managers in what <xref ref-type="bibr" rid="bibr5-0275074013487023">Clinton and Lewis (2008)</xref> classify as liberal agencies say that to a “moderate,” “great,” or “very great” extent PART “imposed a significant burden on management resources,” compared to 56% of respondents in conservative agencies.</p>
<p>Other basic descriptive statistics support the notion that PART was more burdensome in liberal agencies. A greater percentage of employees report being involved in PART in liberal agencies, and liberal agencies had significantly higher number of programs PARTed. This might be simply because liberal agencies take on smaller programs, but here qualitative work was instructive, suggesting that one mechanism by which ideological differences might have generated greater effort is via the definition of what constituted a program for purposes of PART. Decisions about what a program was were not set in stone, but determined by the OMB in consultation with the political appointees who led agencies (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>). This created an opportunity for agency leadership who wanted to closely monitor agency activities to use PART to do so by defining programs very narrowly. A case in point is that the liberal Department of Education had more PART programs than the conservative Department of Defense, despite having only one tenth of the budget (<xref ref-type="bibr" rid="bibr22-0275074013487023">Joyce, 2011</xref>). Some PART programs in Education were as small as US$1 million annual budget (<xref ref-type="bibr" rid="bibr14-0275074013487023">Gilmour, 2006</xref>). Education also scored very poorly in the PART assessments. The explanation as to why helps to illustrate how political processes might work. “According to Robert Shea, the OMB manager of the PART initiative, Education’s low ratings do not reflect a lack of interest in performance management. Rather, the leaders at the Education Department believe the department is burdened with many ill-conceived, poorly designed programs, and see the PART process as a means of shining a light on those deficiencies” (<xref ref-type="bibr" rid="bibr14-0275074013487023">Gilmour, 2006</xref>, p. 16). The differences between managers in liberal and conservative agencies in terms of their level of effort with PART hold even when controls are included, including individual partisan beliefs, and the number of PART reviews conducted in an agency.</p>
<p>If effort is one type of agency response that PART created, another is whether managers actually use the data. Here, again, there is evidence that political ideology matters. <xref ref-type="bibr" rid="bibr26-0275074013487023">Lavertu and Moynihan (2012)</xref> find that managers in conservative agencies who are involved in PART report higher level of performance information use relative to peers not involved in PART. By contrast, managers in liberal agencies involved in PART reported no different use of performance information than managers not involved in PART. In short, while PART appeared to increase performance information use among managers in conservative agencies, it had no such effects in liberal agencies. To better discern if this was primarily a function of liberal agencies having different characteristics that made performance management more difficult, the authors compared the responses of those involved and not involved in PART on a series of items that dealt with perceived difficulty in measuring performance, conflict between stakeholders, and difficulty discerning causality. They found that managers in liberal agencies who were involved in PART were likely to regard these items as being significant impediments to performance management compared both to managers in liberal agencies not involved in PART, and all types of managers in other agencies. In other words, managers in liberal and nonliberal agencies tend to rate hindrances to performance management in similar ways, except for managers in liberal agencies exposed to PART. This finding provides more support for the notion that the PART process itself was experienced as more onerous for managers in liberal agencies.</p>
<p>Cumulatively, the findings on PART provide compelling evidence that both the implementation and response to administrative reforms, even ones framed as politically neutral, will be shaped by political ideology. The most positive assessment we can make is that agencies who share the ideological preference of the executive will be more receptive to reforms that he proposes—after all, we see managers in conservative agencies report an increase in performance information use because of PART, not a reduction in performance information use as in liberal agencies. Put another way, reforms are more likely to succeed if the political executive is preaching to the ideological choir and more likely to falter among ideological heretics. But the more negative possibility that arises from PART is that reforms are used as a mechanism to investigate and burden the heretics. Managers in liberal agencies exerted greater effort, faced more PART assessments, received lower scores, and found their budgets threatened by PART in a way that peers in conservative agencies did not.</p>
</sec>
<sec id="section11-0275074013487023">
<title>Task Difficulty and Working the Ref: How Did Different Programs Fare Under PART?</title>
<p>A basic claim in the study of performance management is that some programs are inherently unsuited to performance management techniques. This argument is often derived from <xref ref-type="bibr" rid="bibr51-0275074013487023">James Q. Wilson’s (1989)</xref> observation that some programs have outputs and outcomes that are more or less easy to observe (<xref ref-type="bibr" rid="bibr18-0275074013487023">Gueorguieva et al., 2009</xref>; <xref ref-type="bibr" rid="bibr36-0275074013487023">Radin, 2006</xref>). Further, programs with multiple goals, and hard-to-measure goals will be less able to justify themselves if performance measures become the coin of the realm. <xref ref-type="bibr" rid="bibr18-0275074013487023">Gueorguieva et al. (2009)</xref> illustrate this point by comparing the PART assessments of seven programs, noting that PART makes no distinction between programs where performance is easier or harder to measure.</p>
<p>The design of PART attempted to be flexible enough to deal with different program typologies, and different versions of PART were developed for direct federal, regulatory programs, research and development (R&amp;D) programs, block/formula grants, credit programs, competitive grant programs, capital asset and service acquisition programs. The separation of these program types could be seen as a practical hypothesis that a government-wide performance management tool could be tweaked to meet the broad differences between programs, treating each fairly, and allowing comparison across type of programs. It is worth noting that the different questionnaires were modeled on the direct federal questionnaire, with some additional questions for the other program types, and so the different forms of PART were much more similar than dissimilar.</p>
<p>The rival hypothesis, best articulated by <xref ref-type="bibr" rid="bibr36-0275074013487023">Radin (2006)</xref> is that such tools are inevitably one-size-fits-all, and will be unable to reflect the nuance of different program types. For example, the basic intent of block grants is to allow states to have some measure of discretion in the goals they pursue, even as PART is apt to punish programs that cannot report a single set of goals. R&amp;D programs seek to generate innovation by funding disparate sets of high-risk projects that may take years to generate positive impacts (if they do so at all), while a mechanism such as PART frowns upon failure and demands tangible outcomes in the short-term.</p>
<p>The study of PART helped to provide clearer evidence on how different types of programs fared under a performance management regime. It was relatively easy to compare PART scores across the typologies mentioned above, to see if some programs did systematically better or worse, and this comparison is best captured by <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo and Lewis (2012)</xref>. The findings are mixed. On one hand, most types of programs do not score significantly differently from other types of programs, suggesting that by and large, PART did not penalize most programs because of their distinct characteristics.</p>
<p>But some types of programs had systematically different scores than others. As predicted by Radin, block grant programs did relatively worse compared to other programs (<xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo &amp; Lewis, 2012</xref>). But contrary to expectations, R&amp;D programs scored relatively higher. <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo and Lewis (2012)</xref> find this effect across different PART programs, while <xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich (2012)</xref> finds it within Health and Human Services programs. What accounts for this surprising finding? The causal mechanism is not clear, but we can speculate based on some circumstantial evidence that suggests what we might call the “working the ref” hypothesis. Working the referee is a tactic that players, coaches and fans use in sports. By complaining loudly about the unfairness of a particular decision, the player may hope to generate sympathetic treatment for later decisions. In the case of performance regimes, this implies a community of practitioners and stakeholders arguing about the unfairness of methods of evaluation to their particular program or type of program.</p>
<p>With PART, the R&amp;D community articulated their concerns about the unfairness focus that PART placed on outcomes, and how it did not hold for their type of programs (<xref ref-type="bibr" rid="bibr14-0275074013487023">Gilmour, 2006</xref>). As early as 2002, the National Academies hosted a daylong workshop where members of R&amp;D agencies expressed concern to OMB officials about the idea of evaluating their programs. The National Academies Committee on Science, Engineering &amp; Public Policy (COSEPUP) was able to draw upon arguments it had developed in critiquing GPRA (<xref ref-type="bibr" rid="bibr6-0275074013487023">COSEPUP, 2001</xref>) about the need to for OMB to consider broader criteria for science, including relevance and quality that could be best determined by peer review. OMB largely accepted these arguments, and sought to adjust PART accordingly. Indeed, OMB’s guidance on PART told budget examiners to apply a different standard to such programs: “agencies should define appropriate output and outcome measures for all R&amp;D programs, but agencies should not expect fundamental basic research to be able to identify outcomes and measure performance in the same way that applied research or development are able to. Highlighting the results of basic research is important, but it should not come at the expense of risk-taking and innovation” (<xref ref-type="bibr" rid="bibr48-0275074013487023">OMB, 2007</xref>, p. 76). Despite this, the R&amp;D community remained critical. A report delivered late in the Bush administration continued to reiterate similar arguments, saying that outcome-based measures are “neither achievable or valid” for R&amp;D programs and “have grown out of inappropriate OMB requirements for outcome-based efficiency metrics” (<xref ref-type="bibr" rid="bibr7-0275074013487023">COSEPUP, 2008</xref>, p. 59), and instead suggesting that performance of programs was best reviewed by peers, not by budget examiners. In case studies of PART implementation, <xref ref-type="bibr" rid="bibr11-0275074013487023">Frederickson and Frederickson (2006)</xref> report that R&amp;D agencies had some success in convincing OMB budget examiners to relax their definition of performance.</p>
<p>The “working the ref” hypothesis fits within the broader notion of performance as an interactive dialogue I have written about elsewhere (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan, 2008</xref>), portraying basic notions of performance as something that is negotiated between actors in the policy process. Even so, the relative success of the R&amp;D community is striking, and not emulated by other communities. Any group could lobby for better scores, but why was this group so successful? Another speculative (though testable) claim is that it may have had to do with the high status of this community, that is, that the success of working the ref is contingent on who is doing it. Some groups are better able than others to press their claims because of their positive image (<xref ref-type="bibr" rid="bibr42-0275074013487023">Schneider &amp; Ingram, 1993</xref>). The R&amp;D community is generally characterized by accomplished scientists who can argue that peer review offers a functional form of performance assessment superior to tools such as PART. In reviewing the success of the National Institutes of Health (NIH) under GPRA and PART, Frederickson and Frederickson note “it is difficult to underestimate the importance of the status or prestige of NIH third parties” (<xref ref-type="bibr" rid="bibr11-0275074013487023">2006</xref>, p. 112). It is possible that such a group was better able to press its claims than others.</p>
<p>There is other circumstantial evidence for the working the ref hypothesis in other areas. For example if an agency was unhappy with the score allocated to a program, they could request a second review at a later point in time, asking the ref to revisit the prior decision, theoretically on the basis of improved evidence. <xref ref-type="bibr" rid="bibr14-0275074013487023">Gilmour (2006)</xref> undertook a qualitative study of a selection of programs that were reviewed a second time, and scored higher. What did agencies do to improve their scores? Gilmour found they did not fundamentally change their programs or improve actual performance. Instead, they became more skilled at completing the PART assessment, at understanding what the OMB wanted, and satisfying those desires. Agencies simply got better at presenting their claims via PART. More generally, PART scores improved consistently over the course of the Bush administration (<xref ref-type="bibr" rid="bibr22-0275074013487023">Joyce, 2011</xref>, p. 360), perhaps a function this greater skill of agencies in completing the assessment, though perhaps also a function of the desire by the White House to show that performance was improving.</p>
</sec>
<sec id="section12-0275074013487023">
<title>PART As a Dependent Variable: Factors Associated With Program Performance</title>
<p>In this section I examine studies that have used PART as an indicator of program performance. The appeal of using PART for such a purpose is understandable. Studying public sector performance is inherently difficult because of data limitations. Indeed, the dominance of research on schools in this area owes much to the fact that there are widely agreed upon measures of educational performance (test scores) in way that is not mirrored by other public functions. In general, there are also no definitive measures of performance across functions that allow us to judge the relative effectiveness of programs or organizations pursuing different tasks and researchers often rely on self-reports by agency employees. PART, by developing a comparable single set of performance grades for very different types of programs, provided researchers with a rare opportunity to test theories of effectiveness using a third party and ostensibly neutral assessment of performance.</p>
<p>Given some of the biases associated with PART scores discussed above, the claim that PART accurately captures performance should not be accepted uncritically. At the same time, even if the scores do include some degree of bias, this does not mean they are uncorrelated with some underlying concept of performance. Studies can seek to control for biases by including controls for the observed sources of biases (e.g., measures of political ideology and program type, in <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo &amp; Lewis, 2012</xref>), or by studying PART within a functional area (e.g., <xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich, 2012</xref>). In the longer run, it would be desirable to correlate PART scores to other measures of organizational performance. Its also worth noting that a good deal of published research has used measures similar to PART to summarize performance, most notably the simple 5-point measure of U.K. local government performance, the Comprehensive Performance Assessment, even as <xref ref-type="bibr" rid="bibr2-0275074013487023">Bertelli and John (2010)</xref> find evidence of partisan bias in these assessments similar to those unearthed for PART.</p>
<p>It is also possible to use data within PART, rather than the scores themselves, to construct measures of performance. For example, <xref ref-type="bibr" rid="bibr23-0275074013487023">Jung (2012a)</xref> uses proportion of targets actually achieved (reported in the Program Performance Measure section of PART), and aggregates these to develop a measure of agency (rather than program) performance. Jung uses the measure to demonstrate a curvilinear relationship between organizational size and performance—both very large and very small organizations had lower levels of target achievement. Jung’s alternate measure of performance appears to reduce the potential for bias observed in the PART scores. However, OMB evaluators and agency staff play a role in selecting what target measures are included in PART (<xref ref-type="bibr" rid="bibr28-0275074013487023">Moynihan 2008</xref>), introducing a potential for bias that has not been examined in the same way as it has for PART scores (e.g., <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo &amp; Lewis, 2012</xref>).</p>
<sec id="section13-0275074013487023">
<title>Goal Ambiguity</title>
<p>Goal ambiguity has been associated with lower organizational performance (<xref ref-type="bibr" rid="bibr3-0275074013487023">Chun &amp; Rainey, 2005</xref>). PART data has been used to expand our knowledge of how the relationship between the two variables works by providing new measures of both goal ambiguity and performance.</p>
<p><xref ref-type="bibr" rid="bibr24-0275074013487023">Jung (2012b)</xref> used PART data to construct measures of different types of goal ambiguity, which presumably could be replicated from similar types of performance systems. Target-specification ambiguity, defined as “lack of clarity in deciding on the quantity and/or quality of work toward the achievement of a program’s performance goals” (<xref ref-type="bibr" rid="bibr24-0275074013487023">Jung 2012b</xref>, p. 681), was measured as the proportion of explicit goals in PART not accompanied with specific targets. Time-specification goal ambiguity (also referred to as timeline ambiguity, <xref ref-type="bibr" rid="bibr23-0275074013487023">Jung, 2012a</xref>) is “the lack of clarity in deciding on the distinction between annual and long-term goals in each program” (<xref ref-type="bibr" rid="bibr24-0275074013487023">Jung, 2012b</xref>, p. 684), and is measured as the proportion of PART goals that are not clearly labeled as annual or long-term. Finally, evaluative goal ambiguity the “interpretive leeway that a statement of organizational goals allows in evaluating the progress toward the achievement of the mission” (<xref ref-type="bibr" rid="bibr3-0275074013487023">Chun &amp; Rainey 2005</xref>, p. 533)—is measured as the ratio of outcomes measures to output measures for PART.</p>
<p>Target-specification ambiguity is negatively related to PART scores based on a wide sample of PART programs (<xref ref-type="bibr" rid="bibr38-0275074013487023">Rainey &amp; Jung, 2009</xref>) and a study of environmental programs (<xref ref-type="bibr" rid="bibr45-0275074013487023">Thomas &amp; Fumia, 2011</xref>). <xref ref-type="bibr" rid="bibr23-0275074013487023">Jung (2012a)</xref> finds that target-specification ambiguity and time-specification ambiguity are negatively associated with agency performance using the proportion-of-targets-achieved indicator of performance. <xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich (2012)</xref> offers some overlapping findings. Looking at the quality of evidence of Health and Human Service programs, she finds that the use of long-term measures, baseline measures or targets and independent evaluations, are generally associated with higher PART scores. She also notes that while program assessments show a preference for presenting qualitative data, programs that relied upon quantitative data tended to enjoy higher PART scores.</p>
<p><xref ref-type="bibr" rid="bibr23-0275074013487023">Jung (2012a)</xref> also finds that evaluative goal ambiguity is associated with lower proportion of PART targets achieved. <xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich’s (2012)</xref> more limited sample of Health and Human Service programs does not reveal a significant correlation between evaluative goal ambiguity and PART scores, but does find that this type of ambiguity is associated with lower funding by Congressional appropriators, a relatively rare instance of a systematic association between performance data and legislative decisions. Meanwhile, <xref ref-type="bibr" rid="bibr45-0275074013487023">Thomas and Fumia (2011)</xref> find that a related type of goal ambiguity, accuracy in labeling measures as outcomes, is associated with higher PART scores.</p>
<p><xref ref-type="bibr" rid="bibr4-0275074013487023">Clinton et al. (2012)</xref> use PART to develop a measure of policy certainty that is conceptually similar to goal ambiguity: the higher proportion of programs with valid PART performance measures, the higher is policy certainty. They find that this measure is negatively related to agency autonomy (as measured by length of agency-relevant public law). When Congress has more valid performance measures at its disposal, it appears to delegate less to agencies.</p>
</sec>
<sec id="section14-0275074013487023">
<title>Political Appointees</title>
<p>PART has also shed light on ways that political leadership mattered to performance. Using early PART scores as measures of performance <xref ref-type="bibr" rid="bibr27-0275074013487023">Lewis (2008)</xref> finds that programs run by political appointees generally scored lower than career managers. The plausible interpretation, offered by Lewis, is that career managers were more skilled, and better able to generate performance. It may also be the case that career managers cared more about protecting their program and were willing to contribute effort to scoring more highly on the PART assessment. <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo and Lewis (2012)</xref> retest the role of political appointees on PART performance using all PART assessments, though limiting their analysis only to programs where survey data suggests managers believe that PART scores were meaningful in discerning real performance differences.</p>
<p>With this better validated measure of performance, and controlling for agency type and ideology, Gallo and Lewis again find that political appointees score more poorly on PART relative to career managers. Furthermore, they find that political appointees who were selected on the basis of campaign experience score even worse than other appointees. The results offer perhaps the most persuasive evidence of the performance costs associated with the use of political appointees. In both studies, length of term leading the bureau is associated with higher PART scores, pointing to the particular advantage of leadership stability for performance.</p>
</sec>
</sec>
<sec id="section15-0275074013487023" sec-type="discussion">
<title>Discussion: What Have We Learned From PART?</title>
<p><xref ref-type="table" rid="table1-0275074013487023">Table 1</xref> summarizes some of the key findings from the study of PART, organized by a series of dependent variables. Rather than simply restate these findings, let us consider what research questions the study PART raises. If PART never took place, would the trajectory of future public management research be much different?</p>
<table-wrap id="table1-0275074013487023" position="float">
<label>Table 1.</label>
<caption>
<p>Selected Summary of Findings From Quantitative Research on PART.</p>
</caption>
<graphic alternate-form-of="table1-0275074013487023" xlink:href="10.1177_0275074013487023-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Concept (measure)</th>
<th align="center">Key predictors</th>
<th align="center">Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="4" valign="top">Performance (PART scores)</td>
<td>Agency political ideology</td>
<td>Programs in conservative agencies received higher PART scores than those in liberal agencies (<xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo &amp; Lewis, 2012</xref>; <xref ref-type="bibr" rid="bibr45-0275074013487023">Thomas &amp; Fumia, 2011</xref>)</td>
</tr>
<tr>
<td>Political appointees</td>
<td>Political appointees, especially campaign staff, lower performance (<xref ref-type="bibr" rid="bibr27-0275074013487023">Lewis, 2008</xref>; <xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo &amp; Lewis, 2012</xref>)</td>
</tr>
<tr>
<td>Program type</td>
<td>R&amp;D programs received systematically higher scores; block grants and redistributive programs received lower scores (<xref ref-type="bibr" rid="bibr13-0275074013487023">Gallo &amp; Lewis 2012</xref>; <xref ref-type="bibr" rid="bibr17-0275074013487023">Greitens &amp; Joaquin, 2010</xref>)</td>
</tr>
<tr>
<td>Goal ambiguity</td>
<td>Target-specification goal ambiguity associated with lower performance (<xref ref-type="bibr" rid="bibr38-0275074013487023">Rainey &amp; Jung, 2009</xref>; <xref ref-type="bibr" rid="bibr45-0275074013487023">Thomas &amp; Fumia, 2011</xref>); lower PART scores if programs failed to provide quantitative evidence, long-term or baseline measures, or evaluations (<xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich, 2012</xref>)</td>
</tr>
<tr>
<td rowspan="2" valign="top">Performance (proportion of PART targets achieved)</td>
<td>Goal ambiguity</td>
<td>Target-specification, timeline and evaluation goal ambiguity (<xref ref-type="bibr" rid="bibr23-0275074013487023">Jung, 2012a</xref>) associated with lower performance</td>
</tr>
<tr>
<td>Organizational size</td>
<td>Curvilinear effect; small and large organizations perform less well (<xref ref-type="bibr" rid="bibr23-0275074013487023">Jung, 2012a</xref>)</td>
</tr>
<tr>
<td>Reform implementation (performance information use by managers)</td>
<td>Involvement with PART * agency political ideology</td>
<td>Involvement with PART does not increase purposeful performance information use on aggregate, but does increase passive use (<xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan &amp; Lavertu, 2012</xref>) and purposeful performance information use for managers in conservative agencies (<xref ref-type="bibr" rid="bibr26-0275074013487023">Lavertu &amp; Moynihan, 2012</xref>)</td>
</tr>
<tr>
<td rowspan="2" valign="top">Performance budgeting (President’s budget proposal)</td>
<td>PART program scores</td>
<td>Modest but significant correlation between PART scores and program budget changes (<xref ref-type="bibr" rid="bibr15-0275074013487023">Gilmour &amp; Lewis, 2006</xref>)</td>
</tr>
<tr>
<td>Agency political ideology</td>
<td>Programs created under Democratic control more subject to risk of budget losses due to PART (<xref ref-type="bibr" rid="bibr15-0275074013487023">Gilmour &amp; Lewis, 2006</xref>); large programs protected from budget risks because of PART</td>
</tr>
<tr>
<td>Performance budgeting (legislative budget)</td>
<td>PART program scores</td>
<td>No connection between PART scores and changes in appropriations for Health and Human Service programs (<xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich, 2012</xref>)</td>
</tr>
<tr>
<td>Performance budgeting (legislative budget)</td>
<td>Goal ambiguity</td>
<td>Evaluation goal ambiguity reduces appropriations for Health and Human Service programs (<xref ref-type="bibr" rid="bibr20-0275074013487023">Heinrich, 2012</xref>)</td>
</tr>
<tr>
<td>Performance budgeting (managerial budget execution)</td>
<td>Involvement with PART * agency political ideology</td>
<td>Involvement with PART does not increase performance information use for managerial resource allocation on aggregate, but does increase use for those in ideologically moderate and conservative agencies (<xref ref-type="bibr" rid="bibr30-0275074013487023">Moynihan &amp; Lavertu, 2012</xref>; <xref ref-type="bibr" rid="bibr26-0275074013487023">Lavertu &amp; Moynihan, 2012</xref>)</td>
</tr>
<tr>
<td rowspan="2" valign="top">Administrative burden (time and effort devoted to completing PART)</td>
<td>Agency political ideology</td>
<td>Respondents in liberal agencies report higher level of burden in completing PART than those in conservative agencies (<xref ref-type="bibr" rid="bibr25-0275074013487023">Lavertu, Lewis &amp; Moynihan, 2012</xref>)</td>
</tr>
<tr>
<td>Program type</td>
<td>Less burdensome to complete PART for R&amp;D programs; regulatory programs more burdensome (<xref ref-type="bibr" rid="bibr25-0275074013487023">Lavertu, Lewis, &amp; Moynihan, 2012</xref>)</td>
</tr>
<tr>
<td>Agency autonomy (length of statues)</td>
<td>Policy certainty</td>
<td>Higher policy certainty (proportion of PART programs with valid performance measures) results in lower discretion (<xref ref-type="bibr" rid="bibr4-0275074013487023">Clinton et al., 2012</xref>)</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Perhaps the most importance substantive lesson from the study of PART is the need to explicitly model political variables in studying administrative outcomes. More persuasively than research on any comparable reform or presidential administration, studies relying on PART pointed to the effect of political appointees on performance, and the role of political ideology in shaping how performance is defined, how a reform is implemented, and how it is received. These studies show that political appointees are associated with lower performance outcomes, and that agency political ideology matters a good deal. Programs in liberal agencies received systematically lower PART scores, and were more subject to budget risk because of those scores. Managers working in liberal agencies were more likely to regard PART as burdensome, and less likely to be spurred to use performance data as a result. The prominence of these political variables can be at least partly attributed to marked presence of political scientists working on PART, more fluent in political concepts, and more willing to assume that political ideology matters even to good-government reforms. The findings challenge those of us who come from a traditionally public administration background to take politics seriously enough to understand how it shapes the workings of administrative life.</p>
<p>In some respects the contribution of PART is methodological, offering new techniques to address existing questions. This is true of questions of performance, which allowed for tests of established variables such as size and goal ambiguity. For goal ambiguity, studies using PART data not only connected it to lower performance, but also to greater autonomy and lower resource allocation. The ability to pursue these questions and the examples of how to do so has an effect that goes beyond methodology, shifting the winds that direct new research in one area or another, and inviting similar studies for other well-established variables, such as employee motivation.</p>
<p>The study of PART is also likely to have an impact in studying how performance management reforms fare. <xref ref-type="table" rid="table1-0275074013487023">Table 1</xref> summarizes a relatively weak case for the notion that PART achieved its goals of fostering performance budgeting or performance information use. While there is a relationship between PART scores and the President’s proposed budget, there is no evidence of such an effect on legislative decisions or budget execution by managers. In these studies, PART research offered performance information use—either self-reported or inferred from decision outcomes—as a benchmark for understanding the impact of performance management reforms. This variable was already the subject of growing attention (<xref ref-type="bibr" rid="bibr31-0275074013487023">Moynihan &amp; Pandey, 2010</xref>), but studies involving PART looked for means to isolate the effects of a particular reform on this form of behavior. Though not always easy to achieve, the study of PART evokes a logic of quasi-experimental design as a standard for studying performance management, a significant difference from the traditional approach.</p>
<p>The study of PART provides a sense of the possibility of balancing qualitative and quantitative work in performance management. <xref ref-type="table" rid="table1-0275074013487023">Table 1</xref> is incomplete because it focuses on quantitative work. This is partly because of the difficulty of summarizing the more complex concepts that feature in qualitative work. But in a wide variety of areas, we see overlap between qualitative and quantitative assessments of PART, for example, on the burdens imposed by PART on agency staff, or on the importance of leadership commitment. Quantitative analysis has relied upon qualitatively based insights on the workings of PART to develop reasonable hypotheses, establish the most plausible direction of causality with cross-sectional data, and explain results, and to avoid the problem of armchair theorizing. Qualitative work has also provided a better sense of the mechanics of PART and the sometimes untidy process of social construction that gave rise to the contents of PART scores, reminding us of the adage popularized by the former head of the Bank of England, Sir <xref ref-type="bibr" rid="bibr37-0275074013487023">Josiah Stamp (1929</xref>, pp. 258-259): “The government are very keen on amassing statistics. They collect them, add them, raise them to the <italic>n</italic>th power, take the cube root and prepare wonderful diagrams. But you must never forget that every one of these figures comes in the first instance from the <italic>chowky dar</italic> (village watchman in India), who just puts down what he damn pleases.” Qualitative work gave us a glimpse and understanding of <italic>how</italic> PART emerged, who the village watchmen were and why they acted. But qualitative work did not always offer a consistent set of claims, and in some cases, quantitative research resolved issues raised by qualitative work, such as how well different program types fared under PART. Quantitative findings also sometimes go beyond mere tests of hypotheses generated from qualitative work. The body of work on the role of political ideology does more than resolve a debate on this topic, providing a well-developed theoretical basis for understanding the effects of ideology on reform more generally.</p>
<p>At the same time, there are areas where quantitative work offers little. These are primarily to do with normative arguments about the purpose of reforms. A good example is a set of works that have argued that performance regimes serve to displace attention to democratic values—such as equity (<xref ref-type="bibr" rid="bibr36-0275074013487023">Radin, 2006</xref>), transparency (<xref ref-type="bibr" rid="bibr34-0275074013487023">Piotrowski &amp; Rosenbloom, 2002</xref>), constitutional values (<xref ref-type="bibr" rid="bibr40-0275074013487023">Rosenbloom, 2007</xref>), and citizenship (<xref ref-type="bibr" rid="bibr50-0275074013487023">Wichowsky &amp; Moynihan, 2008</xref>)—or other important tasks, such as policy making (<xref ref-type="bibr" rid="bibr49-0275074013487023">White, 2012</xref>). Empirical work can help to illustrate this point, or test the degree of goal displacement. But the key argument here is a normative one about how management reforms should reflect democratic values. Such arguments deserve a domain in public administration research, though should not be our sole focus.</p>
<p>The point is not that one approach is better than the other. Rather, the article notes prior approaches to assessing the impact of reforms such as PART have relied almost exclusively on a combination of qualitative work and normative theorizing, and that balancing such with the greater generalizability of large-N work allows for more persuasive tests of causal claims. Such work will be strongest if it can apply a mixed methods approach. Failing that, a basic willingness to draw insights from multiple methodological approaches helps to avoid a blind spot of any one approach.</p>
</sec>
<sec id="section16-0275074013487023" sec-type="conclusions">
<title>Conclusion</title>
<p>As we conclude, one might ponder why PART was so well-studied relative to similar reforms. There are a number of plausible reasons. First, general improvements in methodological training meant that there were simply more well-trained people able to study the topic. A second reason is the transparency of the tool itself. To the everlasting credit of the Bush administration the application of PART was made unusually transparent. The questions asked, the answers given, the judgments based to those answers were all recorded and made publicly available on the internet. PART provided desirable measures to study with its ineffective–effective scale and accompanying budget recommendations, and academics could also code the contents of the PART assessments for additional measures. A third factor was the development of data that could be related to PART. The GAO collected invaluable survey data that it shared with academics. Academics developed supplementary data, including surveys that asked directly about PART, and categorizations of agency ideology, and public statements about PART.</p>
<p>A final point raised by the study of PART has to do with the relationship between academia and the world of practice. There is a trade-off between practitioner needs and the ability of academics to provide timely insights on reform. Practitioners want insights on the new reform they are currently implementing. But the first wave of research on PART did not appear until 2006 to 2008, and comprehensive analyses are just now emerging. Academics had little to report directly on PART until PART was fully in place and nearing its conclusion. One may blame this partly on the relaxed schedules of academic production, but it also takes time to develop meaningful data on a phenomena. The process of evaluating the effects of a reform is inherently retrospective. This may disappoint practitioners who have moved on to something else, and creates pressures on scholars to equate relevancy with studying contemporary reforms. But the scholarly community provides a greater service to practice by using its skills to evaluate reforms thoroughly. Commentary on the new idea will be most insightful only if it is informed by a deep understanding of the past, which, as the Book of Ecclesiastes notes, has a tendency to repeat itself: “What has been will be again, what has been done will be done again; there is nothing new under the sun.” Our ability to identify underlying variables in reform and governance and how they mattered in the past will aid us best if we are to influence the future.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<bio>
<title>Author Biography</title>
<p><bold>Donald P. Moynihan</bold> is Professor of Public Affairs a the La Follette School. His research areas include performance management, motivation, and organizational reform. He is a member of the National Academy of Public Administration.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Askim</surname><given-names>J.</given-names></name>
<name><surname>Johnsen</surname><given-names>A.</given-names></name>
<name><surname>Christophersen</surname><given-names>K. A.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Factors behind organizational learning from benchmarking: Experiences from Norwegian municipal benchmarking networks</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>18</volume>, <fpage>297</fpage>-<lpage>320</lpage>.</citation>
</ref>
<ref id="bibr2-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bertelli</surname><given-names>A. M.</given-names></name>
<name><surname>John</surname><given-names>P.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Government checking government: How performance measures expand distributive politics</article-title>. <source>Journal of Politics</source>, <volume>72</volume>, <fpage>545</fpage>-<lpage>558</lpage>.</citation>
</ref>
<ref id="bibr3-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chun</surname><given-names>Y. H.</given-names></name>
<name><surname>Rainey</surname><given-names>H. G.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Goal ambiguity and organizational performance in U.S. federal agencies</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>15</volume>, <fpage>529</fpage>-<lpage>557</lpage>.</citation>
</ref>
<ref id="bibr4-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clinton</surname><given-names>J. D.</given-names></name>
<name><surname>Bertelli</surname><given-names>A.</given-names></name>
<name><surname>Grosse</surname><given-names>C.</given-names></name>
<name><surname>Lewis</surname><given-names>D. E.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Separated powers in the United States: The ideology of agencies, presidents and congress</article-title>. <source>American Journal of Political Science</source>, <volume>56</volume>, <fpage>341</fpage>-<lpage>354</lpage>.</citation>
</ref>
<ref id="bibr5-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clinton</surname><given-names>J. D.</given-names></name>
<name><surname>Lewis</surname><given-names>D. E.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Expert opinion, agency characteristics, and agency preferences</article-title>. <source>Political Analysis</source>, <volume>16</volume>, <fpage>3</fpage>-<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr6-0275074013487023">
<citation citation-type="web">
<collab>Committee on Science, Engineering, and Public Policy (COSEPUP</collab>, <year>2001</year>). <source>Implementing the government performance and results act for research</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://books.nap.edu/catalog.php?record_id=10106#toc">http://books.nap.edu/catalog.php?record_id=10106#toc</ext-link></citation>
</ref>
<ref id="bibr7-0275074013487023">
<citation citation-type="web">
<collab>Committee on Science, Engineering, and Public Policy (COSEPUP</collab>, <year>2008</year>). <source>Evaluating research efficiency in the U.S. environmental protection agency</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://books.nap.edu/catalog.php?record_id=12150#toc">http://books.nap.edu/catalog.php?record_id=12150#toc</ext-link></citation>
</ref>
<ref id="bibr8-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dull</surname><given-names>M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Why PART? The institutional politics of presidential budget reform</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>16</volume>, <fpage>187</fpage>-<lpage>215</lpage>.</citation>
</ref>
<ref id="bibr9-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dull</surname><given-names>M.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Results-model reform leadership: Questions of credible commitment</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>19</volume>, <fpage>255</fpage>-<lpage>284</lpage>.</citation>
</ref>
<ref id="bibr10-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Durant</surname><given-names>R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Sharpening a knife cleverly: Organizational change, policy paradox, and the “Weaponizing” of administrative reforms</article-title>. <source>Public Administration Review</source>, <volume>68</volume>, <fpage>282</fpage>-<lpage>294</lpage>.</citation>
</ref>
<ref id="bibr11-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Frederickson</surname><given-names>D. G.</given-names></name>
<name><surname>Frederickson</surname><given-names>H. G.</given-names></name>
</person-group> (<year>2006</year>). <source>Measuring the performance of the hollow state</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Georgetown University Press</publisher-name>.</citation>
</ref>
<ref id="bibr12-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Frisco</surname><given-names>V.</given-names></name>
<name><surname>Stalebrink</surname><given-names>O. J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Congressional use of the program assessment rating tool</article-title>. <source>Public Budgeting and Finance</source>, <volume>28</volume>, <fpage>1</fpage>-<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr13-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gallo</surname><given-names>N.</given-names></name>
<name><surname>Lewis</surname><given-names>D. E.</given-names></name>
</person-group> (<year>2012</year>). <article-title>The consequences of presidential patronage for federal agency performance</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>22</volume>, <fpage>195</fpage>-<lpage>217</lpage>.</citation>
</ref>
<ref id="bibr14-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gilmour</surname><given-names>J. B.</given-names></name>
</person-group> (<year>2006</year>). <source>Implementing OMB’s Program Assessment Rating Tool (PART): Meeting the challenges of integrating budget and performance</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IBM Center for the Business of Government</publisher-name>.</citation>
</ref>
<ref id="bibr15-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilmour</surname><given-names>J. B.</given-names></name>
<name><surname>Lewis</surname><given-names>D. E.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Assessing performance budgeting at OMB: The influence of politics, performance, and program size</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>16</volume>,<fpage>169</fpage>-<lpage>186</lpage>.</citation>
</ref>
<ref id="bibr16-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Golden</surname><given-names>M.</given-names></name>
</person-group> (<year>2000</year>). <source>What motivates bureaucrats?</source> <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Columbia University Press</publisher-name>.</citation>
</ref>
<ref id="bibr17-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Greitens</surname><given-names>T. J.</given-names></name>
<name><surname>Joaquin</surname><given-names>M. E.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Policy typology and performance measurement: Results from the Program Assessment Rating Tool (PART)</article-title>. <source>Public Performance &amp; Management Review</source>, <volume>33</volume>, <fpage>555</fpage>-<lpage>570</lpage></citation>
</ref>
<ref id="bibr18-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gueorguieva</surname><given-names>V.</given-names></name>
<name><surname>Accius</surname><given-names>J.</given-names></name>
<name><surname>Apaza</surname><given-names>C.</given-names></name>
<name><surname>Bennett</surname><given-names>L.</given-names></name>
<name><surname>Brownley</surname><given-names>C.</given-names></name>
<name><surname>Cronin</surname><given-names>S.</given-names></name>
<name><surname>Preechyanud</surname><given-names>P.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The Program Assessment Rating Tool and the government performance and results act: Evaluating conflicts and disconnections</article-title>. <source>American Review of Public Administration</source>, <volume>39</volume>, <fpage>225</fpage>-<lpage>245</lpage>.</citation>
</ref>
<ref id="bibr19-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heinrich</surname><given-names>C. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Third-party governance under no child left behind: Accountability and performance management challenges</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>20</volume>, <fpage>i59</fpage>-<lpage>i80</lpage>.</citation>
</ref>
<ref id="bibr20-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heinrich</surname><given-names>C. J.</given-names></name>
</person-group> (<year>2012</year>). <article-title>How credible is the evidence, and does it matter? An analysis of the program assessment rating tool</article-title>. <source>Public Administration Review</source>, <volume>72</volume>, <fpage>123</fpage>-<lpage>134</lpage>.</citation>
</ref>
<ref id="bibr21-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>James</surname><given-names>O.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Performance measures and democracy: Information effects on citizens in field and laboratory experiments</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>21</volume>, <fpage>399</fpage>-<lpage>418</lpage>.</citation>
</ref>
<ref id="bibr22-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Joyce</surname><given-names>P. G.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The Obama administration and PBB: Building on the legacy of federal performance-informed budgeting</article-title>. <source>Public Administration Review</source>, <volume>71</volume>, <fpage>356</fpage>-<lpage>367</lpage>.</citation>
</ref>
<ref id="bibr23-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jung</surname><given-names>C. S.</given-names></name>
</person-group> (<year>2012a</year>). <article-title>Navigating a rough terrain of public management: Examining the relationship between organizational size and effectiveness</article-title>. <source>Journal of Public Administration Research and Theory</source>. Advance online publication. doi:<pub-id pub-id-type="doi">10.1093/jopart/mus040</pub-id></citation>
</ref>
<ref id="bibr24-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jung</surname><given-names>C. S.</given-names></name>
</person-group> (<year>2012b</year>). <article-title>Developing and validating new concepts and measures of program goal ambiguity in the U.S. federal government</article-title>. <source>Administration &amp; Society</source>, <volume>44</volume>, <fpage>675</fpage>-<lpage>701</lpage>.</citation>
</ref>
<ref id="bibr25-0275074013487023">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lavertu</surname><given-names>S.</given-names></name>
<name><surname>Lewis</surname><given-names>D. E.</given-names></name>
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
</person-group> (<year>2012</year>). <source>Administrative reform, ideology, and bureaucratic effort: Performance management in the Bush era</source>. <conf-name>Paper presented at Association of Public Policy Analysis and Management annual meeting</conf-name>, <conf-date>November 8-11</conf-date>, <conf-loc>Baltimore, Maryland</conf-loc>.</citation>
</ref>
<ref id="bibr26-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lavertu</surname><given-names>S.</given-names></name>
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Agency political ideology and reform implementation: Performance management in the Bush administration</article-title>. <source>Journal of Public Administration Research and Theory</source>. Advance online publication. doi:<pub-id pub-id-type="doi">10.1093/jopart/mus026</pub-id></citation>
</ref>
<ref id="bibr27-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lewis</surname><given-names>D. E.</given-names></name>
</person-group> (<year>2008</year>). <source>The politics of presidential appointments</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr28-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
</person-group> (<year>2008</year>). <source>The dynamics of performance management: Constructing information and reform</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Georgetown University Press</publisher-name>.</citation>
</ref>
<ref id="bibr29-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
<name><surname>Ingraham</surname><given-names>P. W.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Integrative leadership in the public sector: A model of performance information use</article-title>. <source>Administration &amp; Society</source>, <volume>36</volume>, <fpage>427</fpage>-<lpage>453</lpage>.</citation>
</ref>
<ref id="bibr30-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
<name><surname>Lavertu</surname><given-names>S.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Does involvement in performance reforms encourage performance information use? Evaluating GPRA and PART</article-title>. <source>Public Administration Review</source>, <volume>7</volume>, <fpage>592</fpage>-<lpage>602</lpage>.</citation>
</ref>
<ref id="bibr31-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
<name><surname>Pandey</surname><given-names>S. K.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The big question for performance management: Why do managers use performance information?</article-title> <source>Journal of Public Administration Research and Theory</source>, <volume>20</volume>, <fpage>849</fpage>-<lpage>866</lpage>.</citation>
</ref>
<ref id="bibr32-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
<name><surname>Roberts</surname><given-names>A. S.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The triumph of loyalty over competence: The Bush administration and the exhaustion of the politicized presidency</article-title>. <source>Public Administration Review</source>, <volume>70</volume>, <fpage>572</fpage>-<lpage>581</lpage>.</citation>
</ref>
<ref id="bibr33-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
<name><surname>Wright</surname><given-names>B. E.</given-names></name>
<name><surname>Pandey</surname><given-names>S.K.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Setting the table: How transformational leadership fosters performance information use</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>22</volume>, <fpage>143</fpage>-<lpage>164</lpage>.</citation>
</ref>
<ref id="bibr34-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Piotrowski</surname><given-names>S. J.</given-names></name>
<name><surname>Rosenbloom</surname><given-names>D.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Nonmission-based values in results oriented public management</article-title>. <source>Public Administration Review</source>, <volume>62</volume>, <fpage>643</fpage>-<lpage>657</lpage>.</citation>
</ref>
<ref id="bibr35-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Posner</surname><given-names>P. L.</given-names></name>
<name><surname>Fantone</surname><given-names>D. L.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Assessing federal program performance: Observations on the U.S. office of management and budget’s program assessment rating tool and its use in the budget process</article-title>. <source>Public Performance &amp; Management Review</source>, <volume>30</volume>, <fpage>351</fpage>-<lpage>368</lpage>.</citation>
</ref>
<ref id="bibr36-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Radin</surname><given-names>B.</given-names></name>
</person-group> (<year>2006</year>). <source>Challenging the performance movement: Accountability, complexity and democratic values</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Georgetown University Press</publisher-name>.</citation>
</ref>
<ref id="bibr37-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stamp</surname><given-names>J.</given-names></name>
</person-group> (<year>1929</year>). <source>Some economic factors in modern life</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>P. S. King &amp; Son</publisher-name></citation>
</ref>
<ref id="bibr38-0275074013487023">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Rainey</surname><given-names>H.</given-names></name>
<name><surname>Jung</surname><given-names>C. S.</given-names></name>
</person-group> (<year>2009</year>, <month>October</month>). <source>Program types, goal ambiguity, and performance in U.S. federal programs</source>. <conf-name>Paper presented at the 2009 Public Management Research Conference</conf-name>, <conf-loc>Columbus, Ohio</conf-loc>.</citation>
</ref>
<ref id="bibr39-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Redburn</surname><given-names>F. S.</given-names></name>
<name><surname>Newcomer</surname><given-names>K.</given-names></name>
</person-group> (<year>2008</year>). <source>Achieving real improvement in program performance and policy outcomes: The next frontier</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academy of Public Administration</publisher-name>.</citation>
</ref>
<ref id="bibr40-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosenbloom</surname><given-names>D. H.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Reinventing administrative prescriptions: The case for democratic-constitutional impact statements and scorecards</article-title>. <source>Public Administration Review</source>, <volume>67</volume>, <fpage>28</fpage>-<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr41-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rudalevige</surname><given-names>A.</given-names></name>
</person-group> (<year>2002</year>). <source>Managing the president’s program: Presidential leadership and presidential policy formulation</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr42-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schneider</surname><given-names>A.</given-names></name>
<name><surname>Ingram</surname><given-names>H.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Social construction of target populations: Implications for politics and policy</article-title>. <source>American Political Science Review</source>, <volume>87</volume>, <fpage>334</fpage>-<lpage>347</lpage>.</citation>
</ref>
<ref id="bibr43-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Soss</surname><given-names>J.</given-names></name>
<name><surname>Fording</surname><given-names>R.</given-names></name>
<name><surname>Schram</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The organization of discipline: From performance management to perversity and punishment</article-title>. <source>Journal of Public Administration Research and Theory</source>, <volume>21</volume>, <fpage>i203</fpage>-<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr44-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stalebrink</surname><given-names>O. J.</given-names></name>
<name><surname>Frisco</surname><given-names>V.</given-names></name>
</person-group> (<year>2011</year>). <article-title>PART in retrospect: An examination of legislator’s attitudes toward PART</article-title>. <source>Public Budgeting and Finance</source>, <volume>31</volume>, <fpage>1</fpage>-<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr45-0275074013487023">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Thomas</surname><given-names>C.</given-names></name>
<name><surname>Fumia</surname><given-names>D.</given-names></name>
</person-group> (<year>2011</year>, <month>June</month>). <source>The effect of program size and goal ambiguity on performance: An analysis of PART assessments for 165 environmental programs</source>. <conf-name>Paper presented at the National Public Management Research Conference</conf-name>, <conf-loc>Syracuse University, NY</conf-loc>.</citation>
</ref>
<ref id="bibr46-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Devising administrative reform that works</article-title>. <source>Public Administration Review</source>, <volume>59</volume>, <fpage>283</fpage>-<lpage>293</lpage>.</citation>
</ref>
<ref id="bibr47-0275074013487023">
<citation citation-type="book">
<collab>U.S. Office of Management and Budget (US OMB</collab>, <year>2001</year>). <source>The president’s management agenda</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Government Printing Office</publisher-name>.</citation>
</ref>
<ref id="bibr48-0275074013487023">
<citation citation-type="web">
<collab>U.S. Office of Management and Budget (OMB</collab>, <year>2007</year>). <source>Program Assessment Rating Tool guidance 2007-02</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://stinet.dtic.mil/cgi-bin/GetTRDoc?AD=ADA471562&amp;Location=U2&amp;doc=GetTRDoc.pdf">http://stinet.dtic.mil/cgi-bin/GetTRDoc?AD=ADA471562&amp;Location=U2&amp;doc=GetTRDoc.pdf</ext-link></citation>
</ref>
<ref id="bibr49-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>White</surname><given-names>J.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Playing the wrong PART: The program assessment rating tool and the functions of the president’s budget</article-title>. <source>Public Administration Review</source>, <volume>72</volume>, <fpage>112</fpage>-<lpage>121</lpage>.</citation>
</ref>

<ref id="bibr50-0275074013487023">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wichowsky</surname><given-names>A.</given-names></name>
<name><surname>Moynihan</surname><given-names>D. P.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Measuring how administration shapes citizenship: A policy feedback perspective on performance management</article-title>. <source>Public Administration Review</source>, <volume>68</volume>, <fpage>908</fpage>-<lpage>920</lpage>.</citation>
</ref>
<ref id="bibr51-0275074013487023">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>J. Q.</given-names></name>
</person-group> (<year>1989</year>). <source>Bureaucracy: What government agencies do and why they do it</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>