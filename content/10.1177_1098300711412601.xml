<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PBI</journal-id>
<journal-id journal-id-type="hwp">sppbi</journal-id>
<journal-title>Journal of Positive Behavior Interventions</journal-title>
<issn pub-type="ppub">1098-3007</issn>
<issn pub-type="epub">1538-4772</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1098300711412601</article-id>
<article-id pub-id-type="publisher-id">10.1177_1098300711412601</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Illinois Statewide Positive Behavioral Interventions and Supports</article-title>
<subtitle>Evolution and Impact on Student Outcomes Across Years</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Simonsen</surname><given-names>Brandi</given-names></name>
<xref ref-type="aff" rid="aff1-1098300711412601">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Eber</surname><given-names>Lucille</given-names></name>
<xref ref-type="aff" rid="aff2-1098300711412601">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Black</surname><given-names>Anne C.</given-names></name>
<xref ref-type="aff" rid="aff3-1098300711412601">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Sugai</surname><given-names>George</given-names></name>
<xref ref-type="aff" rid="aff1-1098300711412601">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Lewandowski</surname><given-names>Holly</given-names></name>
<xref ref-type="aff" rid="aff2-1098300711412601">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Sims</surname><given-names>Barbara</given-names></name>
<xref ref-type="aff" rid="aff4-1098300711412601">4</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Myers</surname><given-names>Diane</given-names></name>
<xref ref-type="aff" rid="aff5-1098300711412601">5</xref>
</contrib>
</contrib-group>
<aff id="aff1-1098300711412601"><label>1</label>University of Connecticut, Storrs, CT, USA</aff>
<aff id="aff2-1098300711412601"><label>2</label>Illinois PBIS Network</aff>
<aff id="aff3-1098300711412601"><label>3</label>Yale University, New Haven, CT, USA</aff>
<aff id="aff4-1098300711412601"><label>4</label>Illinois State Board of Education, Springfield, IL, USA</aff>
<aff id="aff5-1098300711412601"><label>5</label>Assumption College, Worcester, MA, USA</aff>
<author-notes>
<corresp id="corresp1-1098300711412601">Brandi Simonsen, University of Connecticut, Neag School of Education, 249 Glenbrook Road, Unit 2064, Storrs, CT 06269-2064, USA Email: <email>brandi.simonsen@uconn.edu</email></corresp>
<fn fn-type="other" id="bio1-1098300711412601">
<p>Brandi Simonsen, PhD, is an associate professor of Special Education at the Neag School of Education at the University of Connecticut. Her current interests include schoolwide positive behavior support in alternative settings, classwide positive behavior support, and secondary/tertiary supports for students with more intensive needs.</p>
</fn>
<fn fn-type="other" id="bio2-1098300711412601">
<p>Lucille Eber, EdD, is the Statewide Director of the Illinois PBIS Network. Her current interests include scaling up schoolwide positive behavior support, developing state-wide data and evaluation systems to support implementation, and integrating wraparound process throughout the SWPBS framework</p>
</fn>
<fn fn-type="other" id="bio3-1098300711412601">
<p>Anne C. Black, PhD, is an associate research scientist in the Department of Psychiatry at Yale University. Her recent work has focused on risk taking and impulsivity, and on methods for modeling incomplete data.</p>
</fn>
<fn fn-type="other" id="bio4-1098300711412601">
<p>George Sugai, PhD, is the Carole J. Neag Endowed Professor in the Neag School of Education at the University of Connecticut. His interests include schoolwide positive behavior supports, function-based behavior supports, systems implementation improvement, and educating students with behavior disorders.</p>
</fn>
<fn fn-type="other" id="bio5-1098300711412601">
<p>Holly Lewandowski, MA, is a program evaluation consultant and former evaluation coordinator for the Illinois PBIS Network. Her current interests include using utilization-focused evaluation and developmental evaluation to evaluate programs for nonprofits, universities, and state-run agencies.</p>
</fn>
<fn fn-type="other" id="bio6-1098300711412601">
<p>Barbara Sims, MA, is an associate director with the National Implementation Research Network in the Frank Porter Graham Child Development Institute at the University of North Carolina at Chapel Hill. She is currently concentrating on the application of implementation research, especially in building the capacity of state education systems to implement and scale up effective education innovations</p>
</fn>
<fn fn-type="other" id="bio7-1098300711412601">
<p>Diane Myers, PhD, is an assistant professor of Special Education at Assumption College. Her interests include positive behavior support, teacher education and professional development, and classroom management.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>14</volume>
<issue>1</issue>
<fpage>5</fpage>
<lpage>16</lpage>
<permissions>
<copyright-statement>© 2012 Hammill Institute on Disabilities</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Hammill Institute on Disabilities</copyright-holder>
</permissions>
<abstract>
<p>More than 1,000 Illinois schools are implementing schoolwide positive behavior support (SWPBS) to enhance outcomes for students and staff. Consequently, Illinois established layered support structures to facilitate scaling up SWPBS. This paper describes the development of this infrastructure and presents the results of HLM analyses exploring the effects of implementing SWPBS, with and without fidelity across time, on student behavior and academic outcomes (office discipline referrals, suspensions, and state-wide test scores in reading and math) for a sample of 428 Illinois schools implementing SWPBS. Results indicate that (a) most schools implemented with fidelity and maintained or improved student performance across time and (b) implementation fidelity was associated with improved social outcomes and academic outcomes in math. Study limitations and implications are discussed.</p>
</abstract>
<kwd-group>
<kwd>schoolwide positive behavior support</kwd>
<kwd>scaling up</kwd>
<kwd>state-level implementation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Schoolwide positive behavior support (SWPBS) is a systems-level, positive, and preventive approach that results in desired change in student and staff behavior (<xref ref-type="bibr" rid="bibr3-1098300711412601">Bradshaw, Koth, Bevans, Ialongo, &amp; Leaf, 2008</xref>; <xref ref-type="bibr" rid="bibr4-1098300711412601">Bradshaw, Mitchell, &amp; Leaf, 2010</xref>; <xref ref-type="bibr" rid="bibr5-1098300711412601">Bradshaw, Reinke, Brown, Bevans, &amp; Leaf, 2008</xref>; <xref ref-type="bibr" rid="bibr8-1098300711412601">Horner et al., 2009</xref>). Schools that implement SWPBS develop a continuum of prevention and intervention strategies, which are typically organized in three tiers (e.g., <xref ref-type="bibr" rid="bibr26-1098300711412601">Walker et al., 1996</xref>): universal or primary (Tier 1), targeted-group or secondary (Tier 2), and intensive or tertiary (Tier 3). Descriptions of the three tiers have been published in numerous articles (e.g., <xref ref-type="bibr" rid="bibr7-1098300711412601">Horner &amp; Sugai, 2005</xref>; <xref ref-type="bibr" rid="bibr20-1098300711412601">Sugai &amp; Horner, 2002</xref>; <xref ref-type="bibr" rid="bibr26-1098300711412601">Walker et al., 1996</xref>).</p>
<p>SWPBS relies on district- and state-level support structures to facilitate implementation of SWPBS with fidelity across an increasing number of schools (<xref ref-type="bibr" rid="bibr15-1098300711412601">McIntosh, Horner, &amp; Sugai, 2009</xref>; <xref ref-type="bibr" rid="bibr21-1098300711412601">Sugai et al., 2010</xref>; <xref ref-type="bibr" rid="bibr22-1098300711412601">Sugai, Horner, &amp; McIntosh, 2008</xref>). Implementation fidelity, or the extent to which components of an intervention are implemented as intended (<xref ref-type="bibr" rid="bibr13-1098300711412601">Lane, Bocian, MacMillon, &amp; Gresham, 2004</xref>), is critical to achieve desired outcomes. Without fidelity, intervention effectiveness is difficult to judge. In this paper, we (a) describe common district- and state-level features intended to promote implementation fidelity across schools, (b) provide an example of these features in Illinois, (c) discuss gaps in the literature on SWPBS implementation fidelity, and (d) present the methods and results of a study that aims to document the importance of implementation fidelity as SWPBS is taken to scale.</p>
<sec id="section1-1098300711412601">
<title>Common Features of Scaling-Up SWPBS</title>
<p>As of 2010, more than 13,000 schools were implementing SWPBS with support of the Office of Special Education Program’s National Technical Assistance Center on Positive Behavior Interventions and Supports (PBIS Center; <ext-link ext-link-type="uri" xlink:href="http://www.pbis.org">www.pbis.org</ext-link>). Therefore, issues of scaling up (i.e., increasing the number of schools, districts, and states that are implementing SWPBS with fidelity) are important and timely. In 2004, the PBIS Center developed the Schoolwide Positive Behavior Support Implementers’ Blueprint and Self-Assessment (subsequently referred to as “SWPBS Blueprint”). The SWPBS Blueprint, which was updated in 2010 (<xref ref-type="bibr" rid="bibr21-1098300711412601">Sugai et al., 2010</xref>), guides districts and states in supporting schools as they scale up their implementation.</p>
<p>As of 2010, more than 13,000 schools were implementing SWPBS with support of the Office of Special Education Program’s National Technical Assistance Center on Positive Behavior Interventions and Supports (PBIS Center; <ext-link ext-link-type="uri" xlink:href="http://www.pbis.org">www.pbis.org</ext-link>). Therefore, issues of scaling up (i.e., increasing the number of schools, districts, and states that are implementing SWPBS with fidelity) are important and timely. In 2004, the PBIS Center developed the Schoolwide Positive Behavior Support Implementers’ Blueprint and Self-Assessment (subsequently referred to as “SWPBS Blueprint”). The SWPBS Blueprint, which was updated in 2010 (<xref ref-type="bibr" rid="bibr21-1098300711412601">Sugai et al., 2010</xref>), guides districts and states in supporting schools as they scale up their implementation.</p>
<p>At the district and state levels, the PBIS Center recommends forming a leadership team to coordinate four primary functions: training, coaching, evaluation, and developing behavioral expertise (<xref ref-type="bibr" rid="bibr21-1098300711412601">Sugai et al., 2010</xref>). Initially, the leadership team’s primary focus is to create local school/district exemplars. Then, to make sustained implementation possible, the leadership team focuses on securing and maintaining visibility, political support, stable funding, and policy changes that support implementation (see <xref ref-type="bibr" rid="bibr21-1098300711412601">Sugai et al., 2010</xref>).</p>
<p>Many states have used this approach to develop district- and state-level structures. As of 2008, 31 states had active state-level leadership teams (<xref ref-type="bibr" rid="bibr19-1098300711412601">Spaulding, Horner, May, &amp; Vincent, 2008</xref>). In particular, Maryland, Iowa, and New Hampshire (a) used the SWPBS Blueprint and scaling-up logic to improve behavior supports and student behavior outcomes and (b) published their results in peer-reviewed journals. Participating schools in Maryland (<xref ref-type="bibr" rid="bibr2-1098300711412601">Barrett, Bradshaw, &amp; Lewis-Palmer, 2008</xref>), Iowa (<xref ref-type="bibr" rid="bibr14-1098300711412601">Mass-Galloway, Panyan, Smith, &amp; Wessendorf, 2008</xref>), and New Hampshire (<xref ref-type="bibr" rid="bibr16-1098300711412601">Muscott, Mann, &amp; LeBrun, 2008</xref>) largely implemented SWPBS with fidelity and achieved desired student outcomes (e.g., decreased office discipline referrals, decreased suspensions, increased scores on statewide assessments).</p>
<p>Like these other states, Illinois followed the 2004 SWPBS Blueprint to build state-level support structures. However, the Illinois implementation is unique in that the PBIS initiative was established more than 10 years ago (before the SWPBS blueprint was widely available), and additional layers of support (school, district, region, and state) were established to facilitate implementation across the state. In addition, a larger number of schools were involved in implementation: as of 2008, 804 Illinois schools were implementing SWPBS, whereas other states reported between 0 and 691 schools (<xref ref-type="bibr" rid="bibr19-1098300711412601">Spaulding et al., 2008</xref>)</p>
</sec>
<sec id="section2-1098300711412601">
<title>Focus on Illinois PBIS</title>
<p>Illinois has formally supported students’ social behavior at the state level for almost 20 years. In 1990, the state established the Emotional and Behavioral Disabilities (EBD) Network. In April 1998, this network expanded its focus from students with EBD to all students by initiating SWPBS training for 23 schools. In 2004, with 520 schools trained and implementing SWPBS, the Network officially changed its name to the Illinois PBIS Network. As of 2009, the Illinois PBIS network was actively involved in training, coaching, and evaluating more than 1,000 schools. The Illinois PBIS network took the following steps to scale up and promote fidelity of SWPBS implementation across their state.</p>
<sec id="section3-1098300711412601">
<title>Infrastructure of Illinois PBIS</title>
<p>Like most states, the Illinois PBIS network provides schools with multiple layers of support. At the school level, a school-based SWPBS team is established; it is composed of a representative group of stakeholders (faculty, staff, parents, and students) and facilitated by a school-based internal coach. Across schools, districtwide teams and external coaches provide additional support to the internal coaches and school-based teams. External coaches typically have more experience and training than internal coaches, and they provide on- and off-site technical assistance. Coaches are funded primarily by school districts and in some cases by intermediate districts, such as Special Education Cooperatives. School-based SWPBS teams, internal coaches, districtwide teams, and external coaches progress through a clear sequence of training activities. These activities focus on the three tiers of prevention and intervention and are delivered across 3 to 5 years (see “Sample Plan for PBIS Implementation” under the “Training” link on <ext-link ext-link-type="uri" xlink:href="http://www.pbisillinois.org">www.pbisillinois.org</ext-link>).</p>
<p>At the regional level, PBIS Technical Assistance Coordinators provide direct technical assistance and training to school-based teams, internal coaches, districtwide teams, and external coaches and are supervised by PBIS Technical Assistance Directors (see <xref ref-type="bibr" rid="bibr10-1098300711412601">Illinois PBIS Network, 2009</xref>, for full description of the Illinois PBIS infrastructure). At the state level, a statewide PBIS director oversees the regional efforts and coordinates training, coaching, and evaluation activities across regions within the state, with the assistance of her administrative team. To facilitate evaluation activities, the statewide PBIS director accesses the National PBIS Center’s database (<ext-link ext-link-type="uri" xlink:href="http://www.pbseval.org">www.pbseval.org</ext-link>), which is used by coaches and school teams to enter and maintain office discipline referral, self-assessment, and other fidelity data. These data are integrated with a statewide database that stores additional student and school-level data. The combined information is used to develop and disseminate statewide annual evaluation reports as well as brief quarterly reports and newsletters. The statewide PBIS Network leadership participates in and receives direct assistance from the national PBIS Center.</p>
</sec>
<sec id="section4-1098300711412601">
<title>Capacity Building</title>
<p>Across the various infrastructure layers, the programmatic focus is on capacity building (i.e., developing expertise within local and existing personnel). The statewide PBIS director works with regional PBIS leaders to build fluency with training content among all network staff across the three tiers, including the wraparound process. Specifically, Technical Assistance Directors develop training capacity among regional coordinators, who then co-train with external coaches to build their training capacity, thereby increasing the number of PBIS trainers. External coaches work with school-based internal coaches to build their fluency with providing technical assistance, which increases the number of individuals with the required skills and experience to become external coaches. Over the past ten years, the Illinois PBIS network has used this model to increase the number of schools and internal and external coaches. Given the exponential growth in the number of schools and internal coaches and given that many of those schools have been implementing for multiple years, the Illinois PBIS network presents a unique opportunity to examine the impact of fidelity of SWPBS implementation on student outcomes.</p>
</sec>
</sec>
<sec id="section5-1098300711412601">
<title>Gaps in the Literature on SWPBS Implementation Fidelity</title>
<p>In Illinois and other states, systems (e.g., coaching, training, and evaluation structures) were put in place to promote and assess the fidelity of SWPBS implementation across schools. Implementation fidelity is critical when evaluating intervention effectiveness. Despite the importance of implementation fidelity, relatively few studies report fidelity data (Lane, Kalberg, Bruhn, Mahoney, &amp; Driscoll, 2008). Researchers conducting large-scale studies on SWPBS have begun to address this gap in the literature by collecting and reporting fidelity data (e.g., <xref ref-type="bibr" rid="bibr4-1098300711412601">Bradshaw et al., 2010</xref>; <xref ref-type="bibr" rid="bibr3-1098300711412601">Bradshaw, Koth, et al., 2008</xref>; <xref ref-type="bibr" rid="bibr5-1098300711412601">Bradshaw, Reinke, et al., 2008</xref>; <xref ref-type="bibr" rid="bibr8-1098300711412601">Horner et al., 2009</xref>). However, even fewer studies have directly examined the impact of implementation fidelity on student outcomes. After performing a search of the PsychInfo and ERIC databases for the descriptors of “school wide positive behavior support” and “fidelity,” it appeared that no published peer-reviewed studies have systematically examined the effects of implementing SWPBS with (and without) fidelity over time.</p>
<p>This paper aims to address this gap in the literature. We present a longitudinal analysis of data from Illinois schools that implemented SWPBS with varying levels of fidelity across 7 years (from 2000–2001 through 2007–2008 school years). Specifically, this study was conducted to address the following research question: What is the relationship between SWPBS implementation fidelity and school-level student behavior and academic outcomes (as measured by office discipline referrals, out of school suspensions, total suspensions, and the percentage of students who met or exceeded benchmarks on statewide reading and math tests) across time? In addition, we explored the proportion of schools implementing with fidelity across time.</p>
</sec>
<sec id="section6-1098300711412601" sec-type="methods">
<title>Method</title>
<sec id="section7-1098300711412601">
<title>Sample</title>
<p>The sample consisted of the subset Illinois schools that implemented SWPBS from 2000 to 2008 and entered data into the state-wide data base. Altogether, the sample consisted of 428 schools nested within 125 districts; not all schools had data for all years, and for many schools, data were only available for 1 or 2 years. This sample included 274 elementary (K–6), 46 K–8, 91 middle (6–9), and 17 high (9–12) schools.</p>
<p>The number of schools with available data increased over the study period. Subsets of districts and schools with available <italic>Schoolwide Evaluation Tool</italic> (SET; <xref ref-type="bibr" rid="bibr23-1098300711412601">Sugai, Lewis-Palmer, Todd, &amp; Horner, 2001</xref>) data differed for each targeted outcome. For the suspension analyses, which studied days out of school (OSS) and total number of suspensions (TS), 242 schools nested within 81 districts had corresponding SET data for 6 years (2001/2002–2007/2008). For office discipline referrals (ODRs), data for the same 6 years were available from 400 schools nested within 118 districts. Finally, Illinois State Achievement Test data for schools with SET data were available over 7 years (2000/2001–2007/2008) from 324 schools within 101 districts. <xref ref-type="table" rid="table1-1098300711412601">Table 1</xref> summarizes descriptive data for sample schools across study years (counts, means, and standardized mean-difference effect sizes).</p>
<table-wrap id="table1-1098300711412601" position="float">
<label>Table 1.</label>
<caption>
<p>Mean Outcome Scores and Standardized Group Mean Difference Effect Sizes for Each Study Variable by Set Status and Year (2000–2008)</p>
</caption>
<graphic alternate-form-of="table1-1098300711412601" xlink:href="10.1177_1098300711412601-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">2000–2001</th>
<th align="center">2001–2002</th>
<th align="center">2002–2003</th>
<th align="center">2003–2004</th>
<th align="center">2004–2005</th>
<th align="center">2005–2006</th>
<th align="center">2006–2007</th>
<th align="center">2007–2008</th>
<th align="center">Overall</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="10">ODRs per 100 students</td>
</tr>
<tr>
<td> SET = N</td>
<td/>
<td>1.06</td>
<td>1.08</td>
<td>0.75</td>
<td>0.79</td>
<td>0.80</td>
<td>0.91</td>
<td>1.03</td>
<td>0.89</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td/>
<td>9</td>
<td>21</td>
<td>21</td>
<td>42</td>
<td>37</td>
<td>37</td>
<td>28</td>
<td/>
</tr>
<tr>
<td> SET = Y</td>
<td/>
<td>0.88</td>
<td>0.54</td>
<td>0.67</td>
<td>0.53</td>
<td>0.71</td>
<td>0.70</td>
<td>0.48</td>
<td>0.60</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td/>
<td>5</td>
<td>24</td>
<td>36</td>
<td>32</td>
<td>54</td>
<td>83</td>
<td>104</td>
<td/>
</tr>
<tr>
<td> Effect size</td>
<td/>
<td>0.14</td>
<td>0.50</td>
<td>0.12</td>
<td>0.39</td>
<td>0.11</td>
<td>0.22</td>
<td>0.51</td>
<td>0.32</td>
</tr>
<tr>
<td colspan="10">Total suspensions (No. of suspension events)</td>
</tr>
<tr>
<td> SET = N</td>
<td/>
<td>64.22</td>
<td>114.10</td>
<td>86.38</td>
<td>170.84</td>
<td>135.04</td>
<td>77.63</td>
<td>221.50</td>
<td>132.26</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td/>
<td>9</td>
<td>21</td>
<td>21</td>
<td>25</td>
<td>24</td>
<td>19</td>
<td>22</td>
<td/>
</tr>
<tr>
<td> SET = Y</td>
<td/>
<td>90.80</td>
<td>77.67</td>
<td>68.44</td>
<td>51.00</td>
<td>47.03</td>
<td>68.02</td>
<td>54.16</td>
<td>61.31</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td/>
<td>5</td>
<td>24</td>
<td>36</td>
<td>18</td>
<td>36</td>
<td>58</td>
<td>68</td>
<td/>
</tr>
<tr>
<td> Effect size</td>
<td/>
<td>-0.41</td>
<td>0.23</td>
<td>0.12</td>
<td>0.39</td>
<td>0.33</td>
<td>0.07</td>
<td>0.54</td>
<td>0.31</td>
</tr>
<tr>
<td colspan="10">Out-of-school suspensions (total no. of days suspended out of school)</td>
</tr>
<tr>
<td> SET = N</td>
<td/>
<td>191.38</td>
<td>298.75</td>
<td>224.42</td>
<td>495.48</td>
<td>408.95</td>
<td>202.06</td>
<td>665.95</td>
<td>373.15</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td/>
<td>8</td>
<td>20</td>
<td>19</td>
<td>21</td>
<td>20</td>
<td>18</td>
<td>19</td>
<td/>
</tr>
<tr>
<td> SET = Y</td>
<td/>
<td>161.4</td>
<td>197.14</td>
<td>194.20</td>
<td>123.07</td>
<td>112.72</td>
<td>154.65</td>
<td>108.31</td>
<td>142.96</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td/>
<td>5</td>
<td>22</td>
<td>30</td>
<td>14</td>
<td>32</td>
<td>55</td>
<td>64</td>
<td/>
</tr>
<tr>
<td> Effect size</td>
<td/>
<td>0.14</td>
<td>0.22</td>
<td>0.09</td>
<td>0.46</td>
<td>0.39</td>
<td>0.13</td>
<td>0.66</td>
<td>0.37</td>
</tr>
<tr>
<td colspan="10">ISAT Math (% students MOE grade-level mastery criteria)</td>
</tr>
<tr>
<td> SET = N</td>
<td>71.33</td>
<td>61.07</td>
<td>63.61</td>
<td>75.07</td>
<td>64.82</td>
<td>78.26</td>
<td>76.85</td>
<td>77.58</td>
<td>72.89</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td>6</td>
<td>27</td>
<td>20</td>
<td>33</td>
<td>71</td>
<td>74</td>
<td>85</td>
<td>60</td>
<td/>
</tr>
<tr>
<td> SET = Y</td>
<td>58.00</td>
<td>67.91</td>
<td>67.53</td>
<td>74.56</td>
<td>76.45</td>
<td>83.00</td>
<td>83.94</td>
<td>81.11</td>
<td>80.63</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td>2</td>
<td>6</td>
<td>18</td>
<td>33</td>
<td>66</td>
<td>96</td>
<td>159</td>
<td>162</td>
<td/>
</tr>
<tr>
<td> Effect size</td>
<td>-1.82</td>
<td>0.38</td>
<td>0.21</td>
<td>-0.04</td>
<td>0.59</td>
<td>.36</td>
<td>0.41</td>
<td>0.21</td>
<td>0.43</td>
</tr>
<tr>
<td colspan="10">ISAT Reading (% students MOE grade-level mastery criteria)</td>
</tr>
<tr>
<td>SET = N</td>
<td>66.00</td>
<td>56.80</td>
<td>58.49</td>
<td>70.45</td>
<td>64.82</td>
<td>68.47</td>
<td>67.51</td>
<td>69.49</td>
<td>66.05</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td>6</td>
<td>27</td>
<td>20</td>
<td>33</td>
<td>71</td>
<td>74</td>
<td>85</td>
<td>60</td>
<td/>
</tr>
<tr>
<td> SET = Y</td>
<td>53.25</td>
<td>60.59</td>
<td>54.71</td>
<td>67.11</td>
<td>67.85</td>
<td>71.33</td>
<td>71.64</td>
<td>72.15</td>
<td>70.25</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td>2</td>
<td>6</td>
<td>18</td>
<td>33</td>
<td>66</td>
<td>96</td>
<td>159</td>
<td>162</td>
<td/>
</tr>
<tr>
<td> Effect size</td>
<td>-1.40</td>
<td>0.25</td>
<td>-0.27</td>
<td>-0.28</td>
<td>0.35</td>
<td>0.20</td>
<td>0.25</td>
<td>0.17</td>
<td>0.27</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1098300711412601">
<p><italic>Note</italic>. Because variables were not normally distributed, means and mean differences should be interpreted with caution; group differences may be underrepresented. ISAT = <italic>Illinois State Achievement Test</italic>; SET = <italic>Schoolwide Evaluation Tool</italic>; MOE = meeting or exceeding.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section8-1098300711412601">
<title>Study Variables</title>
<p>Data were retrieved from existing databases maintained by the Illinois State Board of Education (ISBE) and the Illinois PBIS network, in collaboration with the national PBIS Center (<ext-link ext-link-type="uri" xlink:href="http://www.pbseval.org">www.pbseval.org</ext-link>). In addition, general information about which schools were implementing SWPBS (number of schools implementing, name of schools, etc.) was maintained by the Illinois PBIS network on a locally managed data system. The SET (<xref ref-type="bibr" rid="bibr23-1098300711412601">Sugai et al., 2001</xref>) was used to document fidelity of SWPBS implementation (independent variable), and the following measures were used as indicators of student social behavior and academic outcomes (dependent variables): office discipline referrals, OSS, TS, and <italic>Illinois State Achievement Test</italic> (ISAT) scores in reading and math.</p>
<sec id="section9-1098300711412601">
<title>Schoolwide Evaluation Tool (SET; <xref ref-type="bibr" rid="bibr23-1098300711412601">Sugai et al., 2001</xref>)</title>
<p>The SET is a reliable and valid measure of the first tier of SWPBS implementation. The SET comprises seven subscales: behavior expectations defined, behavioral expectations taught, reward system, violation system, monitoring and evaluation, management, and district support. Indices of internal consistency (α = .96), test–retest reliability (average of 97.3% agreement), and interobserver agreement (average of 99.0% agreement) were high; indices of construct validity (the SET correlated with the Effective Behavior Support: Self-Assessment Survey, <italic>r</italic> = 0.75, <italic>p</italic> ≤ .01) were acceptable; and the SET was demonstrated to be sensitive to change over time (statistically significant differences were observed for schools across time; <xref ref-type="bibr" rid="bibr9-1098300711412601">Horner et al., 2004</xref>). Although the SET is the standard metric for evaluating fidelity of Tier 1 implementation for research (<xref ref-type="bibr" rid="bibr1-1098300711412601">Algozzine et al., 2010</xref>), new analyses suggest that reliability and validity indices of the SET may vary by school level (<xref ref-type="bibr" rid="bibr25-1098300711412601">Vincent, Spaulding, &amp; Tobin, 2010</xref>).</p>
<p>The SET was completed in schools participating in the Illinois PBIS network by trained outside evaluators (i.e., regional Technical Assistance Coordinators, external coaches, or retired administrators who were not directly involved with the school). Evaluators participated in a 1-day SET training and shadowed another trained evaluator before conducting SETs independently. SETs were completed for each school after initial training in PBIS and then once a year thereafter, typically in the spring. Overall and subscale SET scores were entered into the SWPBS evaluation site (<ext-link ext-link-type="uri" xlink:href="http://pbseval.org">pbseval.org</ext-link>) for each school. As with any applied large-scale evaluation, there were factors that interfered with SET completion (e.g., administrative changes, scheduling conflicts); therefore, some schools do not have consistent SET scores. Previous research demonstrated that schools that meet 80% of fidelity criteria on the overall scale (<xref ref-type="bibr" rid="bibr9-1098300711412601">Horner et al., 2004</xref>) and 80% of fidelity criteria on the subscale related to teaching expectations have the most positive student outcomes (<xref ref-type="bibr" rid="bibr6-1098300711412601">Doolittle, 2006</xref>). Therefore, the “80/80” criterion was used to sort schools into two groups for each year: those that did (met or exceeded 80/80) and those that did not (i.e., lower than 80/80) implement with fidelity.</p>
</sec>
<sec id="section10-1098300711412601">
<title>Office Discipline Referral (ODR)</title>
<p>ODR data were entered into the schoolwide information system (<ext-link ext-link-type="uri" xlink:href="http://www.swis.org">www.swis.org</ext-link>) by each school and were accessed by researchers through an interface with the <ext-link ext-link-type="uri" xlink:href="http://www.pbseval.org">www.pbseval.org</ext-link> site. ODR data were stripped of identifiers and reported by school. ODR data have been demonstrated to be reliable and valid when used for within-school comparisons across time (<xref ref-type="bibr" rid="bibr11-1098300711412601">Irvin et al., 2006</xref>; <xref ref-type="bibr" rid="bibr12-1098300711412601">Irvin, Tobin, Sprague, Sugai, &amp; Vincent, 2004</xref>). ODR values represent the number of ODRs per 100 students. The distribution of ODR scores was positively skewed (skewness/SE ratio ranged by year from 5.28 to 31.05), with low frequencies of events occurring for most schools. To more closely meet the assumptions of the analytical model for normally distributed dependent variables, the square roots of ODR scores were used (<xref ref-type="bibr" rid="bibr24-1098300711412601">Tabachnick &amp; Fidell, 2001</xref>).</p>
</sec>
<sec id="section11-1098300711412601">
<title>Total Number of Suspensions and Out-of-School Suspension Days (TS and OSS)</title>
<p>TS and OSS data were reported by each school. School-level data were entered into the <ext-link ext-link-type="uri" xlink:href="http://www.pbseval.org">www.pbseval.org</ext-link> database. TS reflects the number of suspension events whereas OSS reflects the number of days suspended. Both variables represent count data, and both TS and OS were positively skewed (skewness/SE ratios ranged by year from 5.56 to 17.55, and 4.66 to 14.93, respectively), with low frequencies of events occurring for most schools. HLM software (version 6.06; <xref ref-type="bibr" rid="bibr17-1098300711412601">Raudenbush, Bryk, &amp; Congdon, 2004</xref>) allows specifying count data (Poisson distribution); thus data were not transformed.<sup><xref ref-type="fn" rid="fn1-1098300711412601">1</xref></sup></p>
</sec>
<sec id="section12-1098300711412601">
<title>Illinois State Achievement Test (ISAT)</title>
<p>The IL State Board of Education maintained ISAT scores, and we used school-level aggregate data as the intervention was administered at the school level. In particular, we examined the percentage of students meeting or exceeding (MOE) grade-level mastery criteria within each school. ISAT scores for reading and math are posted for Grades 3, 5, and 8 as academic benchmark years. For schools with multiple grades of ISAT (e.g., K–8 grade schools that have data for ISAT in Grades 3, 5, and 8), the mean percentage MOE across grades was used. High school data represent the percentage of students MOE Grade 11 mastery criteria. Reading and math percentage MOE scores were negatively skewed (skewness/SE ratio ranged by year from −3.38 to −8.21, and −4.72 to −15.37, respectively), with higher percentages occurring most frequently. To normalize the distribution to meet model assumptions, these percentage scores were squared.</p>
</sec>
</sec>
<sec id="section13-1098300711412601">
<title>Procedures for Data Analysis</title>
<p>With fidelity of SWPBS implementation as a primary variable of interest, rates of fidelity were analyzed as the proportion of schools meeting 80/80 criteria on the SET across years of the study. Because subsets of schools and districts differed according to outcome variables, and schools had different identifiers in each data set, rates of implementation were calculated separately by outcome category. Proportions of implementation fidelity were calculated separately for ODR, suspension (OSS and TS), and academic (reading and math) variables. Yearly proportions were then averaged across outcomes (accounting for different numbers of schools by outcome) to provide a single proportion of implementation for each year.<sup><xref ref-type="fn" rid="fn2-1098300711412601">2</xref></sup></p>
<p>We modeled each outcome variable over time using hierarchical linear modeling (HLM) and nonlinear modeling. These analytical techniques allowed for the estimation of models, accounting for the nonindependence of repeated measures within schools and schools within districts. HLM software (Version 6.06; Raudenbush, Bryk, &amp; Congdon, 1994–2008) was used to estimate three-level hierarchical models, representing observation years (Level 1 scores) nested within schools (Level 2 scores), and schools nested within districts (Level 3 scores). First, an empty model (no predictors) was specified for each variable to determine the intraclass correlation coefficients (ICCs), or the proportions of variance in scores explained by schools and districts. (All ICCs were greater than 0, indicating that data were not independent.) Then, each analytical model included year (centered at the first observation year, such that the intercept for each model represented Year 1 scores) and SET as a time-varying covariate (a variable whose value could differ at each time point for a given school). Because of the coding of variables, the Level 1 intercept estimate represented the estimated score in the first year for a school below the SET threshold (not implementing SWPBS with sufficient fidelity). Given constraints of limited data, intercepts were only estimated at Levels 2 (school level) and 3 (district level), and no school- or district-level predictors were used. We estimated the variance around each of the Level 2 and 3 intercept estimates (see models in <xref ref-type="app" rid="app1-1098300711412601">appendix</xref>). Power was not sufficient to estimate other random effects (e.g., variances around the estimates for effects of Year and SET); other variance components were fixed at zero. For transformed ODR and ISAT variables, the distribution was specified as normal in the model. Distributions of OSS and TS were specified as Poisson with over-dispersion (i.e., count data with variances larger than their respective means). Full maximum likelihood estimation (the default estimation procedure in HLM 6.06 with three-level models) was used to estimate all models.</p>
</sec>
</sec>
<sec id="section14-1098300711412601" sec-type="results">
<title>Results</title>
<p>Model results were favorable overall, revealing maintenance or improvement in outcomes over time for all schools in the fidelity of SWPBS implementation, and demonstrating in most cases an association between SWPBS implementation fidelity and significantly better outcomes for those schools across years (see <xref ref-type="fig" rid="fig1-1098300711412601">Figure 1</xref>).</p>
<fig id="fig1-1098300711412601" position="float">
<label>Figure 1.</label>
<caption>
<p>Effects of fidelity and time for each study variable</p>
<p><italic>Note</italic>. Solid line represents schools not meeting 80/80 fidelity criteria, and broken line represents schools meeting 80/80 criteria.</p>
</caption>
<graphic xlink:href="10.1177_1098300711412601-fig1.tif"/></fig>
<p>Solid line represents schools not meeting 80/80 fidelity criteria, and broken line represents schools meeting 80/80 criteria.</p>
<sec id="section15-1098300711412601">
<title>Fidelity</title>
<p>Percentages of schools meeting or exceeding SET criteria (averaged across outcome variables) increased over the course of the study from 36% of schools in 2000–2001 to 78% of schools in 2007–2008. Fidelity differed by school type. Elementary (K–6) schools, the most highly represented school type in the sample, implemented with the highest rate of fidelity at 81% by 2007–2008. That is, by the end of the study, 8 of every 10 elementary schools in the sample met 80/80 criteria on the SET. High schools (Grades 9–12) had the lowest rates of implementation at 31% in 2007–2008. However the number of high schools was remarkably low; fewer than 10 high schools were represented in any of the data sets in any given year. Notably, 73% of all middle schools (Grades 6–9) implemented with fidelity by the final year of the study.</p>
</sec>
<sec id="section16-1098300711412601">
<title>Office Discipline Referrals</title>
<p>The proportion of variance in ODR scores explained by schools at Level 2 was .23 and by districts at Level 3 was .56; that is, approximately 23% and 56% of the total variance in ODR data was accounted for in school and district differences, respectively.</p>
<p>Because the square root of scores was used, interpretation of the intercept in this model was not meaningful. However, model results indicated that ODR decreased significantly over time (see <xref ref-type="fig" rid="fig1-1098300711412601">Figure 1[a]</xref>); the effect of years was statistically significant and negative (γ<sub>200</sub> = −0.04, <italic>p</italic> = .001; <xref ref-type="table" rid="table2-1098300711412601">Table 2</xref>). In addition, we noted a statistical trend that ODR levels across years were lower for schools that implemented SWPBS with fidelity (γ<sub>100</sub> = −0.06, <italic>p</italic> = .086).</p>
<table-wrap id="table2-1098300711412601" position="float">
<label>Table 2.</label>
<caption>
<p>Model Estimates for all Dependent Variables</p>
</caption>
<graphic alternate-form-of="table2-1098300711412601" xlink:href="10.1177_1098300711412601-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">ODR<sup><xref ref-type="table-fn" rid="table-fn3-1098300711412601">a</xref></sup></th>
<th align="center" colspan="2">OSS<sup><xref ref-type="table-fn" rid="table-fn4-1098300711412601">b</xref></sup></th>
<th align="center" colspan="2">TS<sup><xref ref-type="table-fn" rid="table-fn5-1098300711412601">c</xref></sup></th>
<th align="center" colspan="2">ISAT Reading<sup><xref ref-type="table-fn" rid="table-fn6-1098300711412601">d</xref></sup></th>
<th align="center" colspan="2">ISAT Math<sup><xref ref-type="table-fn" rid="table-fn7-1098300711412601">e</xref></sup></th>
</tr>
<tr>
<th align="left">Effect</th>
<th align="center"><italic>df</italic></th>
<th align="center">Estimate (<italic>SE</italic>)</th>
<th align="center"><italic>df</italic></th>
<th align="center">Estimate (<italic>SE</italic>)</th>
<th align="center"><italic>df</italic></th>
<th align="center">Estimate (<italic>SE</italic>)</th>
<th align="center"><italic>df</italic></th>
<th align="center">Estimate (<italic>SE</italic>)</th>
<th align="center"><italic>df</italic></th>
<th align="center">Estimate (<italic>SE</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Intercept γ<sub>000</sub></td>
<td>117</td>
<td>0.974 (0.05) <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>80</td>
<td>4.23 (0.17) <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>80</td>
<td>3.33 (0.17) <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>100</td>
<td>3568.48 (175.46) <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>100</td>
<td>4081.87 (191.85) <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
</tr>
<tr>
<td>SET γ<sub>100</sub></td>
<td>305</td>
<td>-0.06 (0.04)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">*</xref></td>
<td>344</td>
<td>-0.19 (0.06)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>383</td>
<td>-0.15 (0.06)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">**</xref></td>
<td>887</td>
<td>61.85 (75.24)</td>
<td>887</td>
<td>244.65 (92.33)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
</tr>
<tr>
<td>School yearγ<sub>200</sub></td>
<td>305</td>
<td>-0.04 (0.01)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>344</td>
<td>0.01 (0.02)</td>
<td>383</td>
<td>0.02 (0.02)</td>
<td>887</td>
<td>281.64 (20.99)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>887</td>
<td>402.58 (25.84)<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
</tr>
<tr>
<td>Level 1 variance σ2</td>
<td/>
<td>0.037</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td>633421.85</td>
<td/>
<td>990632.92</td>
</tr>
<tr>
<td>Level 2 variance τπ</td>
<td>189</td>
<td>0.064<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>111</td>
<td>2.03<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>118</td>
<td>1.77<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>212</td>
<td>1138284.27 <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>212</td>
<td>1284177.60<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
</tr>
<tr>
<td>Level 3 variance τβ</td>
<td>82</td>
<td>0.031<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>51</td>
<td>0.28<xref ref-type="table-fn" rid="table-fn8-1098300711412601">*</xref></td>
<td>54</td>
<td>0.40<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>99</td>
<td>1237007.20 <xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
<td>99</td>
<td>1140951.62<xref ref-type="table-fn" rid="table-fn8-1098300711412601">***</xref></td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1098300711412601">
<p><italic>Note</italic>. ODR = office discipline referral; OSS = out-of-school suspension; TS = total number of suspensions; ISAT = <italic>Illinois State Achievement Test</italic>; SET = <italic>Schoolwide Evaluation Tool</italic>.</p>
</fn>
<fn id="table-fn3-1098300711412601">
<label>a.</label>
<p>Number of schools entered in the model = 400; districts = 118.</p>
</fn>
<fn id="table-fn4-1098300711412601">
<label>b.</label>
<p>Number of schools entered in the model = 242; districts = 81.</p>
</fn>
<fn id="table-fn5-1098300711412601">
<label>c.</label>
<p>Number of schools entered in the model = 242; districts = 81.</p>
</fn>
<fn id="table-fn6-1098300711412601">
<label>d.</label>
<p>Number of schools entered in the model = 324; districts = 101.</p>
</fn>
<fn id="table-fn7-1098300711412601">
<label>e.</label>
<p>Number of schools entered in the model = 324; districts = 101.</p>
</fn>
<fn id="table-fn8-1098300711412601">
<label>*</label>
<p><italic>p</italic> &lt; .10. **<italic>p</italic> &lt; .05. ***<italic>p</italic> &lt; .01.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section17-1098300711412601">
<title>Suspension Data</title>
<p>The proportion of variance accounted for by school and district grouping was less than 1% for both OSS and TS. Frequencies of suspensions were distributed differently by year, with greater variability in the number of suspensions for some years than others. As a result, most of the variability in scores was accounted for by school year, rather than by school or district.</p>
<sec id="section18-1098300711412601">
<title>Out-of-School Suspensions (OSS)</title>
<p>The average rate of OSS did not change significantly over time (γ<sub>200</sub> = 0.01, <italic>p</italic> = .771), despite fluctuation in distribution of frequencies by year. However, schools implementing SWPBS with fidelity had significantly lower rates of OSS (γ<sub>100</sub> = −0.19, <italic>p</italic> = .002) than other schools in the sample (see <xref ref-type="fig" rid="fig1-1098300711412601">Figure 1[b]</xref>). The number of OSS days estimated by the statistical model for schools below SET fidelity criteria in 2001–2002 was 68, and for schools implementing with fidelity, was 57. This represents a difference in event rate of 17% (<xref ref-type="table" rid="table2-1098300711412601">Table 2</xref>).</p>
</sec>
<sec id="section19-1098300711412601">
<title>Total suspensions</title>
<p>The results of the TS model were similar to those for OSS. The rate of yearly TS did not change significantly over time (γ<sub>200</sub> = 0.02, <italic>p</italic> = .330), but schools implementing SWPBS with fidelity had significantly lower rates of suspensions (γ<sub>100</sub> = −0.15, <italic>p</italic> = .007) than schools not implementing with fidelity (see <xref ref-type="fig" rid="fig1-1098300711412601">Figure 1[c]</xref>). The estimated number of suspension events for schools below SET criteria in 2001–2002 was 27, and for schools meeting SET criteria it was 24, a 12% difference (<xref ref-type="table" rid="table2-1098300711412601">Table 2</xref>).</p>
</sec>
</sec>
<sec id="section20-1098300711412601">
<title>ISAT</title>
<p>The proportions of variance in reading scores accounted for by schools and districts were .33 and .41, respectively. That is, school differences explained 33% of the variability in reading scores, whereas district differences explained 41% of score variability. Proportions differed slightly for math, with 30% and 34% of the variance in math scores explained by the school and district, respectively.</p>
<sec id="section21-1098300711412601">
<title>Reading</title>
<p>For all schools in the sample, the average percentage of students MOE grade-level mastery criteria for ISAT Reading tests increased significantly over the course of the study (γ<sub>200</sub> = 281.64, <italic>p</italic> &lt; .001). There was no statistically significant difference on this outcome between schools that met SET fidelity criteria and those that did not (γ<sub>100</sub> = 61.85, <italic>p</italic> = .411; see <xref ref-type="table" rid="table2-1098300711412601">Table 2</xref> and <xref ref-type="fig" rid="fig1-1098300711412601">Figure 1[d]</xref>)).</p>
</sec>
<sec id="section22-1098300711412601">
<title>Math</title>
<p>Across all schools in the sample, the average percentage of students in Grades 3, 5, and 8 who MOE grade-level mastery criteria on the ISAT Math test increased significantly over time (γ<sub>200</sub>= 402.58, <italic>p</italic> &lt; .001). However, consistent with the behavioral outcome variables, schools that implemented SWPBS with fidelity had significantly higher percentages of students overall who mastered the Math test (γ<sub>100</sub> = 244.65, <italic>p</italic> = .009; see <xref ref-type="fig" rid="fig1-1098300711412601">Figure 1[e]</xref>; also see <xref ref-type="table" rid="table2-1098300711412601">Table 2</xref> and observed differences in percentages by year in <xref ref-type="table" rid="table1-1098300711412601">Table 1</xref>).</p>
</sec>
</sec>
</sec>
<sec id="section23-1098300711412601" sec-type="discussion">
<title>Discussion</title>
<p>The large scale of SWPBS implementation in Illinois presented a unique opportunity to explore the effects of implementing SWPBS with and without fidelity. In this article, we used HLM to examine the effects of implementing SWPBS with and without fidelity across time for 428 Illinois schools that implemented SWPBS and reported data. In this section, we discuss study results, limitations, and implications.</p>
<sec id="section24-1098300711412601">
<title>Interpretation of Study Results</title>
<p>All schools in the Illinois study sample were implementing SWPBS, and the percentage of schools implementing with fidelity increased throughout the study (from 36% to 78%). Schools demonstrated a statistically significant improvement on all social behavior and academic outcome measures. Across measures, statistically significant improvements were associated with (a) time (ISAT Reading), (b) implementation fidelity (OSS and TS), or (c) both time and fidelity (ODRs and ISAT Math). Implementing SWPBS with fidelity was related to better rates of all social behavior outcomes and higher average percentages of students MOE mastery criteria for math, but was not related to the average percentage of students MOE mastery levels in reading.</p>
<p>SWPBS primarily supports programming for improvement in social behavior (i.e., prompting, teaching, reinforcement); therefore, it was not surprising to find that schools that implemented SWPBS with fidelity also experienced lower rates of ODRs, OSS, and TS. Similar results have been reported in randomized controlled trials (<xref ref-type="bibr" rid="bibr4-1098300711412601">Bradshaw et al., 2010</xref>; <xref ref-type="bibr" rid="bibr3-1098300711412601">Bradshaw, Koth, et al., 2008</xref>; <xref ref-type="bibr" rid="bibr5-1098300711412601">Bradshaw, Reinke, et al., 2008</xref>; <xref ref-type="bibr" rid="bibr8-1098300711412601">Horner et al., 2009</xref>) and other descriptive studies of state implementation (e.g., <xref ref-type="bibr" rid="bibr2-1098300711412601">Barrett et al., 2008</xref>; <xref ref-type="bibr" rid="bibr14-1098300711412601">Mass-Galloway et al., 2008</xref>; <xref ref-type="bibr" rid="bibr16-1098300711412601">Muscott et al., 2008</xref>). In addition, regardless of fidelity, schools experienced decreases in ODRs over time, but time alone did not lead to overall decreases in OSS or TS. One explanation may be that student behaviors that resulted in an ODR may be sensitive to change and responsive to SWPBS implementation, regardless of fidelity. In contrast, student behaviors that resulted in suspension remained intractable with lower SWPBS fidelity and only appeared to decrease with higher levels of fidelity.</p>
<p>Schools that implemented SWPBS with fidelity also had a larger portion of students who MOE benchmarks on the ISAT test in math than schools that did not implement with fidelity. As student behavior improved, teachers may have been more able to reallocate their resources (time, attention, planning) from managing problem behavior to teaching academic content. For example, <xref ref-type="bibr" rid="bibr18-1098300711412601">Scott and Barrett (2004)</xref> performed a cost–benefit analysis to explore the amount of instructional time saved by teachers at an elementary school as a result of implementing SWPBS and decreasing ODRs. They assumed that (a) each ODR corresponded to approximately 20 min of lost instructional time for a student and (b) each student experienced a 6-hr (360-min) school day. They found, on average, 79.5 days of instructional time were saved per year as a result of implementing SWPBS.</p>
<p>In contrast, schools that implemented SWPBS, regardless of fidelity, increased the proportion of students who MOE benchmarks on the ISAT test in reading over time. In other words, fidelity of implementation did not affect ISAT scores on reading in a statistically significant manner. This is consistent with earlier research showing improvements in math but not reading. <xref ref-type="bibr" rid="bibr16-1098300711412601">Muscott et al. (2008)</xref> found improvements in math (i.e., the percentage of students achieving proficiency [basic or above]) for 73% of schools implementing with fidelity; however, they only found improvements in reading for 41% of schools implementing with fidelity. In contrast, <xref ref-type="bibr" rid="bibr8-1098300711412601">Horner and colleagues (2009)</xref> reported a tentative finding that SWPBS implementation was related to an increase in the proportion of third-graders who met or exceeded the state standard in reading. Specifically, they noted statistically significant improvement (conditional effects) of (a) treatment schools over time and (b) treatment schools over control schools at one time point. However, the overall (interaction) effects of treatment and time were not statistically significant, and they suggest readers should interpret conditional effects “with caution” (p. 140). Further research is needed to understand the relationship between the fidelity of SWPBS implementation and students’ academic outcomes.</p>
</sec>
<sec id="section25-1098300711412601">
<title>Limitations</title>
<p>The results from this study should be interpreted in light of the following limitations. First, the number of schools varied across outcome measures, which may have resulted in less statistical power to detect statistically significant effects for some outcome measures (e.g., OSS and TS). As a result, we acknowledged in this study all effects that were significant at α = .10 and below. In addition, smaller sample sizes limited our ability to model random effects (e.g., slopes for year and SET). The appropriateness of assuming the same effect of year and SET fidelity on outcome measures for every school is unclear, and future studies should assess whether and how these effects may vary across schools. Specifically, it is possible that schools changed at different rates over time, and benefited differently from fidelity to SWPBS. Models with sufficient power to estimate school-specific effects should be tested. Furthermore, maximum likelihood estimation is a large-sample technique. With relatively small and unbalanced numbers of observations at Levels 1 and 2, standard errors for fixed effects estimates may have been underestimated (Raudenbush &amp; Bryk, 2002), potentially inflating the Type I error rate.</p>
<p>Second, although the sample sizes utilized in these analyses enabled statements about general patterns, statements about how individual schools responded to SWPBS implementation should be made with caution. For example, we reported the mean percent of students MOE grade-level mastery criteria on the ISAT across grades for schools with multiple grades participating in the ISAT. This procedure may have obscured grade-level differences, and findings should not be generalized to all schools or all grade levels. In addition, the number of implementing high schools meeting inclusion criteria was relatively low, and broad statements about the relationship between SWPBS implementation and student outcomes in high schools are therefore more difficult to make. The general direction of results suggests that SWPBS is a viable means for improving disciplinary climate and enhancing academic outcomes.</p>
<p>Third, because levels of implementation and specific features of the SWPBS approach were contextualized to Illinois policy, resources, training curricula, needs, etc., generalizations of the findings from the Illinois experience to other state implementation efforts should be made with careful consideration of similarities and differences across schools, districts, and states.</p>
<p>Fourth, only 428 of approximately 1,000 schools met criteria for inclusion in this analysis. Thus, interpretations of the results from this study should not necessarily be extended to all IL PBIS schools. That is, outcomes and interpretations may have been different if data from excluded schools had been included, and it is unclear whether and how schools without data differ from the schools included in these analyses. However, the patterns represented by this sample of 428 schools suggest the importance of implementation fidelity for academic and social behavior outcomes, especially in elementary and middle schools.</p>
</sec>
<sec id="section26-1098300711412601">
<title>Implications</title>
<p>The results from this study suggest the importance of implementing SWPBS with fidelity. Specifically, implementing SWPBS with fidelity was associated with increases in ISAT scores in math and decreases in ODRs, OSS, and TS. Therefore, our results have a number of important implications for research, practice, and policy.</p>
<sec id="section27-1098300711412601">
<title>Implications for research</title>
<p>First, our findings extend the literature base on the importance of collecting and reporting data on the fidelity of SWPBS implementation, as implementing with lower levels of fidelity is frequently related to differential outcomes over time. Therefore, researchers should ensure that fidelity data are included in their research plans and publication reports.</p>
<p>Second, this article provides a springboard for additional research on the effects of implementing SWPBS with fidelity on academic outcomes. In this study, fidelity of SWPBS implementation was related to larger proportions of students who met or exceeded state benchmarks in math, but not in reading. However, as discussed, research in this area is still emerging, and deserves further investigation. Future research should take curricular and instructional variables into consideration when evaluating the impact of implementing SWPBS with fidelity. Similarly, future research efforts may collect academic data that are more closely aligned with the daily, weekly, and monthly curriculum. For example, at the elementary level, curriculum-based assessment or measurement (CBA or CBM, respectively) information on literacy and numeracy performance progress could be collected to determine if there is a stronger relationship between SWPBS fidelity and these academic outcomes than annual state test scores.</p>
<p>Third, in this study, typical school-level disciplinary data were collected (i.e., ODR, OSS, TS), which often required an administrator’s response or action for data to be recorded (ODR) or generated (OSS and TS). In other words, an administrator decides whether to enter an ODR into the database and issue a suspension; therefore, these metrics may be underestimates of the actual levels of problem behavior in a school. To provide a greater depth of understanding of the specific effects of SWPBS implementation, future research should collect and examine information related to more immediate behavioral and social climate variables (e.g., academic engagement, opportunities to respond, scheduled/allocated academic time, disruptive behavior).</p>
<p>Fourth, to make generalizable statements about the usefulness of the Illinois implementation design and outcomes, future research should examine similar longitudinal efforts in other states and ensure sufficiently large and balanced samples at all levels of the hierarchical model. These more ideal data conditions would provide a platform for replication of the current analyses and would allow for the estimation of more complex models, including random effects and school- and district-level predictors of outcomes. In addition, more definitive statements about causal directions and relationships will require researchers to implement different research designs (e.g., randomized controlled trials that include/model potential mediator and moderator variables) to enable more direct statements about causal influences.</p>
<p>Fifth, the Illinois PBIS network used the elements (e.g., leadership team, coordination, training, coaching, evaluation) of the SWPBS Implementation Blueprint to guide its statewide efforts. The inference in this study is that these systemic elements are important, related to implementation fidelity, and equally influential. As these inferences have not been systematically studied, future studies may examine the state level organizational factors that contribute to effects at the student and school levels. In addition, the Illinois PBIS network adapted application of these supports to fit the regional, district, and school characteristics of the Illinois school system; therefore, adaptations to these organizational factors may also be considered in future studies.</p>
</sec>
<sec id="section28-1098300711412601">
<title>Implications for practice and policy</title>
<p>Results from this study offer important considerations for implementers and policy makers at the local, state, and national levels who are working to scale up SWPBS implementation with fidelity. Given the improved outcomes associated with accurate and consistent implementation, implementers should attend to factors that affect implementation fidelity and policy makers should establish guidelines, contingencies, and rewards for high levels of implementation fidelity. For example, in Illinois, a comprehensive and dedicated investment in data collection and evaluation enables formative and immediate programmatic enhancements, visible demonstrations of accomplishments, and means for acknowledging successful SWPBS school and district implementers. Results from the Illinois implementation are evidence of improved student outcomes when implementation is accurate, consistent, and sustained.</p>
</sec>
</sec>
</sec>
<sec id="section29-1098300711412601" sec-type="conclusions">
<title>Conclusion</title>
<p>The Illinois SWPBS implementation presented an exciting and informative opportunity for a longitudinal state-level evaluation. In general, the results of HLM analyses document that implementing SWPBS with fidelity is associated with better student social behavior (office discipline referrals, suspensions) and academic (statewide test scores in math) outcomes for Illinois schools. Although preliminary, the results from this research suggest that other system-level implementers of SWPBS should invest in structures and capacities that maximize adoption of evidence-based practices and promote implementation fidelity.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-1098300711412601">
<title>Appendix</title>
<sec id="section30-1098300711412601">
<title>Example Three-Level Model</title>
<graphic position="anchor" xlink:href="10.1177_1098300711412601-img1.tif"/>
</sec>
</app>
</app-group>
<fn-group>
<fn fn-type="other">
<p><bold>Action Editor:</bold> V. Mark Durand</p>
</fn>
<fn fn-type="conflict">
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The development of this article was supported in part by Grant H029D40055 from the Office of Special Education Programs, U.S. Department of Education for OSEP Center on Positive Behavioral Interventions and Supports (<ext-link ext-link-type="uri" xlink:href="http://www.pbis.org">www.pbis.org</ext-link>). Opinions expressed herein are the author’s and do not necessarily reflect the position of the U.S. Department of Education, and such endorsements should not be inferred.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1098300711412601">
<label>1.</label>
<p>Because ODR data were analyzed as number of events per 100 students (and scores represented proportion, not count/integer data), the Poisson distribution did not apply to this variable. Instead, we transformed ODR scores to approximate a normal distribution. ISAT Math and Reading percent scores were also transformed for this reason.</p>
</fn>
<fn fn-type="other" id="fn2-1098300711412601">
<label>2.</label>
<p>To illustrate the calculation of average proportion of schools meeting or exceeding SET fidelity thresholds, consider data from the 2007–2008 school year. The ODR database had 86 K-6 schools with 82% meeting fidelity criteria; the ISAT database had 55 K-6 schools with 80% meeting fidelity criteria; and the Suspension database had 114 K-6 schools with 81% meeting fidelity criteria. The average percentage of K-6 schools meeting fidelity criteria was calculated as [(86*82%)+(55*80%)+ (114*81%)]/255 schools total = 81%.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1098300711412601">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Algozzine</surname><given-names>B.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Barrett</surname><given-names>S.</given-names></name>
<name><surname>Dickey</surname><given-names>S. R.</given-names></name>
<name><surname>Eber</surname><given-names>L.</given-names></name>
<name><surname>. . . Tobin</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Evaluation blueprint for school-wide positive behavior support</article-title>. <source>Eugene, OR: National Technical Assistance Center on Positive Behavior Interventions and Support</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.pbis.org">www.pbis.org</ext-link></comment></citation>
</ref>
<ref id="bibr2-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barrett</surname><given-names>S. B.</given-names></name>
<name><surname>Bradshaw</surname><given-names>C. P.</given-names></name>
<name><surname>Lewis-Palmer</surname><given-names>T.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Maryland statewide PBIS initiative; Systems, evaluation, and next steps</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>10</volume>, <fpage>105</fpage>–<lpage>114</lpage>.</citation>
</ref>
<ref id="bibr3-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradshaw</surname><given-names>C.</given-names></name>
<name><surname>Koth</surname><given-names>C.</given-names></name>
<name><surname>Bevans</surname><given-names>K.</given-names></name>
<name><surname>Ialongo</surname><given-names>N.</given-names></name>
<name><surname>Leaf</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <article-title>The impact of school-wide positive behavioral interventions and supports (PBIS) on the organizational health of elementary schools</article-title>. <source>School Psychology Quarterly</source>, <volume>23</volume>, <fpage>462</fpage>–<lpage>473</lpage>.</citation>
</ref>
<ref id="bibr4-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradshaw</surname><given-names>C.</given-names></name>
<name><surname>Mitchell</surname><given-names>M.</given-names></name>
<name><surname>Leaf</surname><given-names>P.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Examining the effects of school-wide positive behavioral interventions and supports on student outcomes: Results from a randomized controlled effectiveness trial in elementary schools</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>12</volume>, <fpage>133</fpage>–<lpage>148</lpage>.</citation>
</ref>
<ref id="bibr5-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradshaw</surname><given-names>C.</given-names></name>
<name><surname>Reinke</surname><given-names>W.</given-names></name>
<name><surname>Brown</surname><given-names>L.</given-names></name>
<name><surname>Bevans</surname><given-names>K.</given-names></name>
<name><surname>Leaf</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Implementation of school-wide positive behavioral interventions and supports (PBIS) in elementary schools: Observations from a randomized trial</article-title>. <source>Education and Treatment of Children</source>, <volume>31</volume>, <fpage>1</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr6-1098300711412601">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Doolittle</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Sustainability of positive supports in schools</article-title>. <comment>Unpublished dissertation</comment>, <publisher-name>University of Oregon</publisher-name>, <publisher-loc>Eugene</publisher-loc>.</citation>
</ref>
<ref id="bibr7-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
</person-group> (<year>2005</year>). <article-title>School-wide positive behavior support: An alternative approach to discipline in schools</article-title>. In <person-group person-group-type="editor">
<name><surname>Bambara</surname><given-names>L.</given-names></name>
<name><surname>Kern</surname><given-names>L.</given-names></name>
</person-group> (Eds.), <source>Positive behavior support</source> (pp. <fpage>359</fpage>–<lpage>390</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford</publisher-name>.</citation>
</ref>
<ref id="bibr8-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Smolkowski</surname><given-names>K.</given-names></name>
<name><surname>Eber</surname><given-names>L.</given-names></name>
<name><surname>Nakasato</surname><given-names>J.</given-names></name>
<name><surname>Todd</surname><given-names>A.</given-names></name>
<name><surname>Esperanza</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A randomized, wait-list controlled effectiveness trial assessing school-wide positive behavior support in elementary schools</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>11</volume>, <fpage>133</fpage>–<lpage>144</lpage>.</citation>
</ref>
<ref id="bibr9-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Todd</surname><given-names>A. W.</given-names></name>
<name><surname>Lewis-Palmer</surname><given-names>T.</given-names></name>
<name><surname>Irvin</surname><given-names>L. K.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Boland</surname><given-names>J. B.</given-names></name>
</person-group> (<year>2004</year>). <article-title>The School-Wide Evaluation Tool (SET): A research instrument for assessing school-wide positive behavior support</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>6</volume>, <fpage>3</fpage>–<lpage>12</lpage>.</citation>
</ref>
<ref id="bibr10-1098300711412601">
<citation citation-type="web">
<collab>Illinois PBIS Network</collab>. (<year>2009</year>). <article-title>Chapter 2: PBIS implementation in Illinois</article-title>. In <source>Illinois Positive Behavioral Interventions and Supports (ILPBIS) Network: 2008–2009 Progress Report</source> (pp. <fpage>5</fpage>–<lpage>16</lpage>). <collab>Illinois PBIS Network</collab>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.pbisillinois.org/Online_Library">http://www.pbisillinois.org/Online_Library</ext-link></comment></citation>
</ref>
<ref id="bibr11-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Irvin</surname><given-names>L. K.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Ingram</surname><given-names>K.</given-names></name>
<name><surname>Todd</surname><given-names>A. W.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Sampson</surname><given-names>N. K.</given-names></name>
<name><surname>Boland</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Using office discipline referral data for decision making about student behavior in elementary and middle school: An empirical evaluation of validity</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>8</volume>, <fpage>10</fpage>–<lpage>23</lpage>.</citation>
</ref>
<ref id="bibr12-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Irvin</surname><given-names>L. K.</given-names></name>
<name><surname>Tobin</surname><given-names>T. J.</given-names></name>
<name><surname>Sprague</surname><given-names>J. R.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Vincent</surname><given-names>C. G.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Validity of office discipline referral measures as indices of school-wide behavioral status and effects of school-wide behavioral interventions</article-title>. <source>Journal of Positive Behavioral Interventions</source>, <volume>6</volume>, <fpage>131</fpage>–<lpage>147</lpage>.</citation>
</ref>
<ref id="bibr13-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lane</surname><given-names>K. L.</given-names></name>
<name><surname>Bocian</surname><given-names>K. M.</given-names></name>
<name><surname>MacMillan</surname><given-names>D. L.</given-names></name>
<name><surname>Gresham</surname><given-names>F. M.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Treatment integrity: An essential-but often forgotten-component of school-based interventions</article-title>. <source>Preventing School Failure</source>, <volume>48</volume>, <fpage>36</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr14-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mass-Galloway</surname><given-names>R. L.</given-names></name>
<name><surname>Panyan</surname><given-names>M. V.</given-names></name>
<name><surname>Smith</surname><given-names>C. R.</given-names></name>
<name><surname>Wessendorf</surname><given-names>S.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Systems change within school-wide positive behavior supports; Iowa’s work in progress</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>10</volume>, <fpage>129</fpage>–<lpage>135</lpage>.</citation>
</ref>
<ref id="bibr15-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McIntosh</surname><given-names>K.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Sustainability of systems-level evidence-based practices in schools: Current knowledge and future directions</article-title>. In <person-group person-group-type="editor">
<name><surname>Sailor</surname><given-names>W.</given-names></name>
<name><surname>Dunlap</surname><given-names>G.</given-names></name>
<name><surname>Horner</surname><given-names>R.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
</person-group> (Eds), <source>Handbook of positive behavior support</source> (<comment>Chap. 14</comment>, pp. <fpage>327</fpage>–<lpage>352</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr16-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Muscott</surname><given-names>H. S.</given-names></name>
<name><surname>Mann</surname><given-names>E. L.</given-names></name>
<name><surname>LeBrun</surname><given-names>M. R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Positive Behavioral Interventions and Supports in New Hampshire; Effects of large-scale implementation of school wide positive behavior support on student discipline and academic achievement</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>10</volume>, <fpage>190</fpage>–<lpage>205</lpage>.</citation>
</ref>
<ref id="bibr17-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Raudenbush</surname><given-names>S. W.</given-names></name>
<name><surname>Bryk</surname><given-names>A. S.</given-names></name>
<name><surname>Congdon</surname><given-names>R.</given-names></name>
</person-group> (<year>2004</year>). <source>Heirarchical Linear and Nonlinear Modeling (HLM) for Windows</source> <comment>(Version 6.06) [Computer Software]</comment>. <publisher-loc>Lincolnwood, IL</publisher-loc>: <publisher-name>Scientific Software International</publisher-name>.</citation>
</ref>
<ref id="bibr18-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scott</surname><given-names>T. M.</given-names></name>
<name><surname>Barrett</surname><given-names>S. B.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Using staff and student time engaged in disciplinary procedures to evaluate the impact of school-wide PBS</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>6</volume>, <fpage>21</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr19-1098300711412601">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Spaulding</surname><given-names>S. A.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>May</surname><given-names>S. L.</given-names></name>
<name><surname>Vincent</surname><given-names>C. G.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Evaluation brief: Implementation of school-wide PBS across the United States</article-title>. <source>OSEP Technical Assistance Center on Positive Behavioral Interventions and Supports</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://pbis.org/evaluation/evaluation_briefs/default.aspx">http://pbis.org/evaluation/evaluation_briefs/default.aspx</ext-link></comment></citation>
</ref>
<ref id="bibr20-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The evolution of discipline practices: School-wide positive behavior supports</article-title>. <source>Child and Family Behavior Therapy</source>, <volume>24</volume>, <fpage>23</fpage>–<lpage>50</lpage>.</citation>
</ref>
<ref id="bibr21-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Algozzine</surname><given-names>R.</given-names></name>
<name><surname>Barrett</surname><given-names>S.</given-names></name>
<name><surname>Lewis</surname><given-names>T.</given-names></name>
<name><surname>Anderson</surname><given-names>C.</given-names></name>
<name><surname>. . . Simonsen</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <source>School-wide positive behavior support: Implementers’ blueprint and self-assessment</source>. <publisher-loc>Eugene</publisher-loc>: <publisher-name>University of Oregon</publisher-name>.</citation>
</ref>
<ref id="bibr22-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>McIntosh</surname><given-names>K.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Best practices in developing a broad-scale system of support for school-wide positive behavior support</article-title>. In <person-group person-group-type="editor">
<name><surname>Thomas</surname><given-names>A.</given-names></name>
<name><surname>Grimes</surname><given-names>J. P.</given-names></name>
</person-group> (Eds.), <source>Best practices in school psychology V</source> (<volume>Vol. 3</volume>, pp. <fpage>765</fpage>–<lpage>780</lpage>). <publisher-loc>Bethesda, MD</publisher-loc>: <publisher-name>National Association of School Psychologists</publisher-name>.</citation>
</ref>
<ref id="bibr23-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Lewis-Palmer</surname><given-names>T.</given-names></name>
<name><surname>Todd</surname><given-names>A.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
</person-group> (<year>2001</year>). <source>Schoolwide evaluation tool</source>. <publisher-loc>Eugene</publisher-loc>: <publisher-name>University of Oregon</publisher-name>.</citation>
</ref>
<ref id="bibr24-1098300711412601">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tabachnick</surname><given-names>B. G.</given-names></name>
<name><surname>Fidell</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2001</year>). <source>Using multivariate statistics</source> (<edition>4th ed.</edition>). <publisher-loc>Needham Heights, MA</publisher-loc>: <publisher-name>Allyn &amp; Bacon</publisher-name>.</citation>
</ref>
<ref id="bibr25-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vincent</surname><given-names>C.</given-names></name>
<name><surname>Spaulding</surname><given-names>S.</given-names></name>
<name><surname>Tobin</surname><given-names>T. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A reexamination of the psychometric properties of the school-wide evaluation tool (SET)</article-title>. <source>Journal of Positive Behavior Interventions</source>, <volume>12</volume>, <fpage>161</fpage>–<lpage>179</lpage>. doi:10.1177/1098300709332345<pub-id pub-id-type="doi">10.1177/1098300709332345</pub-id></citation>
</ref>
<ref id="bibr26-1098300711412601">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walker</surname><given-names>H. M.</given-names></name>
<name><surname>Horner</surname><given-names>R. H.</given-names></name>
<name><surname>Sugai</surname><given-names>G.</given-names></name>
<name><surname>Bullis</surname><given-names>M.</given-names></name>
<name><surname>Sprague</surname><given-names>J. R.</given-names></name>
<name><surname>Bricker</surname><given-names>D.</given-names></name>
<name><surname>Kaufman</surname><given-names>M. J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Integrated approaches to preventing antisocial behavior patterns among school-age children and youth</article-title>. <source>Journal of Emotional and Behavioral Disorders</source>, <volume>4</volume>, <fpage>194</fpage>–<lpage>209</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>