<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PPS</journal-id>
<journal-id journal-id-type="hwp">sppps</journal-id>
<journal-id journal-id-type="nlm-ta">Perspect Psychol Sci</journal-id>
<journal-title>Perspectives on Psychological Science</journal-title>
<issn pub-type="ppub">1745-6916</issn>
<issn pub-type="epub">1745-6924</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1745691611432124</article-id>
<article-id pub-id-type="publisher-id">10.1177_1745691611432124</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Special Section: Sizes of Our Science</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Introduction to the Special Section</article-title>
<subtitle>Data, Data, Everywhere . . . Especially in My File Drawer</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Spellman</surname><given-names>Barbara A.</given-names></name>
</contrib>
<aff id="aff1-1745691611432124">Department of Psychology, University of Virginia, Charlottesville</aff>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>7</volume>
<issue>1</issue>
<fpage>58</fpage>
<lpage>59</lpage>
<permissions>
<copyright-statement>© Association for Psychological Science 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Association for Psychological Science</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<p>
<disp-quote>
<p>You are invited to post online comments on this and the other articles in the special section. Go to <ext-link ext-link-type="uri" xlink:href="http://pps.sagepub.com/content/7/1.toc">pps.sagepub.com/content/7/1.toc</ext-link>. Click for the text of the article you want to comment on. On the right side bar, you will see a link to “Submit a Comment.” Please join the discussion.</p>
</disp-quote>
</p>
<p>I don’t know about you, but most of my data are not published in good journals, or even in bad journals; most of my data are sitting in my file drawer.<sup><xref ref-type="fn" rid="fn1-1745691611432124">1</xref></sup> And most of <italic>those</italic> data have never even been sent to a journal. Some data are from novel studies that just “didn’t work.” Some are from studies my coauthors and I now call “pilot studies”—studies we did before the ones that “worked” and were published. Some are from actual or conceptual replications of other people’s research—a few of those worked and many of those did not. The successful replications are unpublishable; journals reject such research saying “But we already knew that.” Of course, the failures to replicate are also unpublishable; we all learned that our first week in graduate school.<sup><xref ref-type="fn" rid="fn2-1745691611432124">2</xref></sup> I’m told that the justification for that practice is that “there are a lot of reasons why a good published study will fail to replicate.”</p>
<p>These days, however, many of us are concerned with the flip side of that statement: There are lots of reasons why a bad result (i.e., one that incorrectly rejects the null hypothesis) <italic>will</italic> get published. I’m not talking about deliberately miscoding or inventing data as has been recently alleged against a couple of highly visible psychologists. And I’m not simply talking about the “random” set of Type I errors that are likely to occur (see <xref ref-type="bibr" rid="bibr4-1745691611432124">Rosenthal, 1979</xref>). Rather, I’m talking about well-intentioned scientists making well-intentioned (although biased) decisions that lead to incorrect results.</p>
<p>A selection of cleverly titled articles over the last few years have made the argument well, pointing to problems in how research is run, analyzed, reported, evaluated, reviewed, and selected for publication.<sup><xref ref-type="fn" rid="fn3-1745691611432124">3</xref></sup> The first of these, published in <italic>PLoS Medicine</italic> and therefore not specific to psychology research, was <xref ref-type="bibr" rid="bibr3-1745691611432124">Ioannidis’s (2005)</xref> article “Why Most Published Research Findings Are False.” <italic>Perspectives on Psychological Science</italic> (<italic>PPS</italic>) later published a controversial paper by <xref ref-type="bibr" rid="bibr6-1745691611432124">Vul, Harris, Winkielman, and Pashler (2009)</xref> titled “Puzzlingly High Correlations in fMRI Studies of Emotion, Personality, and Social Cognition,” which had originally been titled “Voodoo Correlations in Social Neuroscience.” And 2011 was a busy year for publications about problems in our science, not only in the news but also in our journals. Generalizing from the Vul et al. paper, in early 2011, <italic>PPS</italic> published <xref ref-type="bibr" rid="bibr2-1745691611432124">Fiedler’s (2011)</xref> “Voodoo Correlations Are Everywhere—Not Only in Neuroscience.” “The (Mis)reporting of Statistical Results in Psychology Journals” by <xref ref-type="bibr" rid="bibr1-1745691611432124">Bakker and Wicherts (2011)</xref> appeared in <italic>Behavioral Research Methods</italic>. Most recently, <italic>Psychological Science</italic> has published <xref ref-type="bibr" rid="bibr5-1745691611432124">Simmons, Nelson, and Simonsohn’s (2011)</xref> paper “False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant.” So, yes, because it’s now time to worry about what we do actually publish, it’s also time to revisit our thoughts about what we choose not to publish.</p>
<p>So, what can be done and what is being done? There are now more journals, typically online, that make the review process quicker and more open. In addition, various method-related websites have sprung up where people can, for example, post nonrefereed research or “register” experiments before they are run. In Fall 2011, I created <ext-link ext-link-type="uri" xlink:href="http://www.psychologyreplications.org">www.psychologyreplications.org</ext-link>—a website where you can post information about your attempted replications of published studies, regardless of whether they succeeded or failed.<sup><xref ref-type="fn" rid="fn4-1745691611432124">4</xref></sup> At the same time, Hal Pashler and colleagues created <ext-link ext-link-type="uri" xlink:href="http://www.psychfiledrawer.org">www.psychfiledrawer.org</ext-link>, a website that allows exactly the same thing. When we discovered our “replication” in early November while both sites were still in development (I sent my link to Hal as part of beta testing), we were astonished. The sites were very similar in tone and content. As I write this introduction, we have plans to combine the sites. By the time you read this introduction, you should be able to use our final product. Note that in addition to posting attempted replications you will be able to post comments and questions. Posted replications must be signed and must have met ethical guidelines for research. Browsing may be done anonymously.</p>
<p>Meanwhile, <italic>PPS</italic> gets many submissions about scientific methodology. Because it is not a “methods journal” per se, most are politely rejected. But because methodology is something we have in common across the field, sometimes we have published single papers or sets of papers on method-related issues.</p>
<p>This issue contains several articles reacting to these recent events and publications. Some address the problems; some address potential solutions. In “Short, Sweet, and Problematic? The Rise of the Short Report in Psychological Science,” Ledgerwood and Sherman discuss the pluses and minuses of the trend toward shorter and faster publications. One of the minuses, of course, is the problem of false positives, which is taken up in more detail by Bertamini and Munafo in “Bite-Size Science and Its Undesired Side Effects.” Hegarty and Walton give us reason to worry about Journal Impact Factors as proxies for scientific merit in “The Consequences of Predicting Scientific Impact in Psychology Using Journal Impact Factors.”</p>
<p>The final paper in this issue is Chan and Arvey’s “Meta-Analysis and the Development of Knowledge.” It describes the many ways that meta-analyses can be useful (with lots of examples and not a lot of math). I am a fan of meta-analyses and look forward to <italic>PPS</italic> getting more meta-analysis manuscripts that include more unpublished research.<sup><xref ref-type="fn" rid="fn5-1745691611432124">5</xref></sup> I encourage people who post to the replication website to collaborate on such endeavors.</p>
<p>We all know that science proceeds not only by the accretion of new facts but also by the weeding out of what was once falsely believed. I hope this new website will provide a place to discuss what is robust and what is not, to discover and report limiting conditions on our findings, and to provide more complete input to the meta-analyses that we so badly need, and, therefore, help us improve our theories. Scientists should not feel attacked when other scientists report failures to replicate our work; it’s not an accusation that we did something wrong. Rather, we should see failures to replicate—and successful replications—first as compliments, because people thought our work was worth paying attention to and spending time on, and second as providing more pieces to the puzzle that is the field of psychology.</p>
</body>
<back>
<ack>
<p>I would like to thank Tony Greenwald, Greg Mitchell, Brian Nosek, Hal Pashler, and Jeff Sherman for never-dull discussions of what can and should be done.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<p>The author declared that she had no conflicts of interest with respect to her authorship or the publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1745691611432124">
<label>1.</label>
<p>Okay, my more recent data are scattered across computer files.</p>
</fn>
<fn fn-type="other" id="fn2-1745691611432124">
<label>2.</label>
<p>Very occasionally, a major psychology journal will publish a systematic set of studies that fail to replicate some phenomenon.</p>
</fn>
<fn fn-type="other" id="fn3-1745691611432124">
<label>3.</label>
<p>Of course, this selection is not exhaustive. For example, <italic>PPS</italic> published an entire special issue on ways of improving the practice of psychological science in January 2009.</p>
</fn>
<fn fn-type="other" id="fn4-1745691611432124">
<label>4.</label>
<p>Here’s the disclaimer: This site has no affiliation with <italic>PPS</italic> or the Association for Psychological Science.</p>
</fn>
<fn fn-type="other" id="fn5-1745691611432124">
<label>5.</label>
<p>Of course, such unpublished research would need to be evaluated as to quality by authors of the meta-analyses.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1745691611432124">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bakker</surname><given-names>M.</given-names></name>
<name><surname>Wicherts</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The (mis)reporting of statistical results in psychology journals</article-title>. <source>Behavior Research Methods</source>, <volume>43</volume>, <fpage>666</fpage>–<lpage>678</lpage>. doi:10.3758/s13428-011-0089-5<pub-id pub-id-type="doi">10.3758/s13428-011-0089-5</pub-id></citation>
</ref>
<ref id="bibr2-1745691611432124">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fiedler</surname><given-names>K.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Voodoo correlations are everywhere—Not only in neuroscience</article-title>. <source>Perspectives on Psychological Science</source>, <volume>6</volume>, <fpage>163</fpage>–<lpage>171</lpage>. doi:10.1177/1745691611400237<pub-id pub-id-type="doi">10.1177/1745691611400237</pub-id></citation>
</ref>
<ref id="bibr3-1745691611432124">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Why most published research findings are false</article-title>. <source>PLoS Medicine</source>, <volume>2</volume>, <fpage>e124</fpage>. doi:10.1371/journal.pmed.0020124<pub-id pub-id-type="doi">10.1371/journal.pmed.0020124</pub-id></citation>
</ref>
<ref id="bibr4-1745691611432124">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosenthal</surname><given-names>R.</given-names></name>
</person-group> (<year>1979</year>). <article-title>The file drawer problem and tolerance for null results</article-title>. <source>Psychological Bulletin</source>, <volume>86</volume>, <fpage>638</fpage>–<lpage>641</lpage>. doi:10.1037/0033-2909.86.3.638<pub-id pub-id-type="doi">10.1037/0033-2909.86.3.638</pub-id></citation>
</ref>
<ref id="bibr5-1745691611432124">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simmons</surname><given-names>J. P.</given-names></name>
<name><surname>Nelson</surname><given-names>L. D.</given-names></name>
<name><surname>Simonsohn</surname><given-names>U.</given-names></name>
</person-group> (<year>2011</year>). <article-title>False- positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title>. <source>Psychological Science</source>, <volume>22</volume>, <fpage>1359</fpage>–<lpage>1366</lpage>. doi:10.1177/0956797611417632<pub-id pub-id-type="doi">10.1177/0956797611417632</pub-id></citation>
</ref>
<ref id="bibr6-1745691611432124">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vul</surname><given-names>E.</given-names></name>
<name><surname>Harris</surname><given-names>C.</given-names></name>
<name><surname>Winkielman</surname><given-names>P.</given-names></name>
<name><surname>Pashler</surname><given-names>H.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Puzzlingly high correlations in fMRI studies of emotion, personality, and social cognition</article-title>. <source>Perspectives on Psychological Science</source>, <volume>4</volume>, <fpage>274</fpage>–<lpage>290</lpage>. doi:10.1111/j.1745-6924.2009.01125.x<pub-id pub-id-type="doi">10.1111/j.1745-6924.2009.01125.x</pub-id></citation>
</ref>
</ref-list>
</back>
</article>