<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BST</journal-id>
<journal-id journal-id-type="hwp">spbst</journal-id>
<journal-title>Bulletin of Science, Technology &amp; Society</journal-title>
<issn pub-type="ppub">0270-4676</issn>
<issn pub-type="epub">1552-4183</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0270467612459924</article-id>
<article-id pub-id-type="publisher-id">10.1177_0270467612459924</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>“Obligatory Technologies”</article-title>
<subtitle>Explaining Why People Feel Compelled to Use Certain Technologies</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Chandler</surname><given-names>Jennifer A.</given-names></name>
<xref ref-type="aff" rid="aff1-0270467612459924">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0270467612459924"><label>1</label>University of Ottawa, Ottawa, Ontario, Canada</aff>
<author-notes>
<corresp id="corresp1-0270467612459924">Jennifer A. Chandler, Faculty of Law, University of Ottawa, 57 Louis Pasteur St., Ottawa, Ontario, Canada K1N 6N5 Email: <email>chandler@uottawa.ca</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2012</year>
</pub-date>
<volume>32</volume>
<issue>4</issue>
<issue-title>Special Issue: The Intellectual Gift of Jacques Ellul, Part II</issue-title>
<fpage>255</fpage>
<lpage>264</lpage>
<permissions>
<copyright-statement>© 2012 SAGE Publications</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The ideas of technological determinism and the autonomy of technology are long-standing and widespread. This article explores why the use of certain technologies is perceived to be obligatory, thus fueling the fatalism of technological determinism and undermining our sense of freedom vis-à-vis the use of technologies. Three main mechanisms that might explain “obligatory technologies” (technologies that must be adopted) are explored. First, competition between individuals or groups drives the adoption of technologies that enhance or extend human capacities. Second, individuals and groups may become dependent on technologies. Third, technologies induce changes in social norms and values that may come to be enforced through various social mechanisms, including the law. The widespread ideology of the beneficence and inevitability of technological progress in our culture helps this process along.</p>
</abstract>
<kwd-group>
<kwd>technological determinism</kwd>
<kwd>autonomy of technology</kwd>
<kwd>ideology of technology</kwd>
<kwd>philosophy of technology</kwd>
<kwd>law and regulation of technology</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0270467612459924" sec-type="intro">
<title>Introduction</title>
<p>The objective of this article is to explore the enduring popularity of the ideas of technological determinism and the autonomy of technology. These long-standing and ubiquitous ideas point to a fundamental cultural disquiet about how human societies develop and use their technologies. The specific question addressed here is why the use of certain technologies is perceived to be obligatory, thus fueling the fatalism of technological determinism and undermining our sense of freedom vis-à-vis the use of technologies.</p>
<p>This article explores three main mechanisms that might explain “obligatory technologies” (technologies that must be adopted). First, competition between individuals or groups drives the adoption of technologies that enhance or extend human capacities. Second, individuals and groups may become dependent on technologies, either through the satisfaction of an important unmet need or because we adapt to the use of the technology. The costs of abandoning the technology may be so high in some cases that the continued use of the technology does become essentially compulsory. Third, technologies induce changes in social norms and values. The “normalization” of the use of a technology both flows from and encourages the uptake of the technology, in a self-reinforcing pattern that may make the nonuse of the technology appear aberrant. The law reflects these social norms in interesting ways, sometimes vividly demonstrating how the technology and its use become an essentially invisible part of the normal environment. In addition, by extending human capacities, technologies bring a greater range of actions within our control. Once a technology that enables us to take a certain action exists, it becomes coherent to talk of a moral obligation to take that action (using the technology, of course). In this way, the use of a technology may be converted into a moral obligation—a process of the “moralization” of technology use—which may also culminate in a legal obligation. The widespread ideology of the beneficence and inevitability of technological progress in our culture helps this process along. It is at this third stage of social norms and values that the law plays its role in making the use of certain technologies nonoptional. It does so not just by implicitly and explicitly reinforcing norms of behavior but also by imposing disadvantages on those who refuse to use technologies that have been declared reasonable and normal.</p>
</sec>
<sec id="section2-0270467612459924">
<title>The Theoretical Context: Technological Determinism Versus Social Constructivism</title>
<p>The relationship between technology<sup><xref ref-type="fn" rid="fn1-0270467612459924">1</xref></sup> and social factors<sup><xref ref-type="fn" rid="fn2-0270467612459924">2</xref></sup> is a long-standing question among those who study the history, philosophy, and sociology of technology. A central theme has been the confrontation between technological determinism and social constructivism in describing this relationship. Technological determinism holds that “technology causes or determines the rest of society and culture” (<xref ref-type="bibr" rid="bibr13-0270467612459924">Dusek, 2006</xref>, p. 84; see also <xref ref-type="bibr" rid="bibr22-0270467612459924">Heilbroner, 1967</xref>, <xref ref-type="bibr" rid="bibr23-0270467612459924">1994</xref>), or that “technological changes force social adaptations” (<xref ref-type="bibr" rid="bibr41-0270467612459924">Sismondo, 2007</xref>, p. 96). The ideas known as “the autonomy of technology” (<xref ref-type="bibr" rid="bibr13-0270467612459924">Dusek, 2006</xref>, p. 84; <xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>, p. 15), “technology out of control,” “technological momentum,” or the “technological imperative” capture and amplify the idea, inherent in technological determinism, that we have little choice or control in the matter of the development and eventual uptake of technologies.</p>
<p>This perception that technology is out of our control is commonly reflected in the views of policy makers, the public, and some scholars (despite the fact that such views are deeply unfashionable within the sociological study of technology) (<xref ref-type="bibr" rid="bibr46-0270467612459924">Wyatt 2007</xref>, p. 165, 167; <xref ref-type="bibr" rid="bibr20-0270467612459924">Hassan, 2010</xref>, p. 357, 364). It is true that some of the most famous dystopian and determinist critiques of technology were perhaps too easy to dismiss because of overblown rhetoric that appeared to give technology a “willful, active, self-determining quality of its own.”<sup><xref ref-type="fn" rid="fn3-0270467612459924">3</xref></sup> In addition, technological determinism in its “hard” form—which sees no possible escape from technologically determined outcomes—has also been rejected as self-defeating and as an abdication of our responsibility for the technologies we make and use (<xref ref-type="bibr" rid="bibr5-0270467612459924">Bijker, 1995</xref>; <xref ref-type="bibr" rid="bibr46-0270467612459924">Wyatt, 2007</xref>). However, not all of the so-called determinists were actually hard technological determinists. Instead, some argued that it might be difficult, but that people were capable of reasserting control over their technologies (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>).</p>
<p>The response of social constructivists to technological determinism was to embark on close case studies of specific technical artifacts in order to lay bare the social influences at work in their development, thus refuting the claim that social factors do not affect technological development (<xref ref-type="bibr" rid="bibr5-0270467612459924">Bijker, 1995</xref>, <xref ref-type="bibr" rid="bibr7-0270467612459924">2009</xref>; <xref ref-type="bibr" rid="bibr32-0270467612459924">Misa, 1988</xref>; <xref ref-type="bibr" rid="bibr46-0270467612459924">Wyatt, 2007</xref>). Social constructivism takes the position that science and technology are fundamentally social activities, producing knowledge and artifacts shaped according to social influences (<xref ref-type="bibr" rid="bibr41-0270467612459924">Sismondo, 2007</xref>). These studies suggested that the process of technological design was characterized by “interpretative flexibility” (or a period of competing interpretations among different social groups of what a technological artifact should do and how it should be designed), followed by “closure mechanisms” and “stabilization” (or social processes by which the flexibility disappears as a dominant interpretation and design emerge; <xref ref-type="bibr" rid="bibr34-0270467612459924">Oudshoorn &amp; Pinch, 2007</xref>). The appearance of inevitability of a particular technological design might thus flow from the failure to remember the earlier phase of flexibility once the dominant interpretation and design emerge (<xref ref-type="bibr" rid="bibr15-0270467612459924">Feenberg, 1999</xref>).</p>
<p>Many scholars now reject the claim that technological change causes or determines social change, but they equally reject strict social determinism in explaining technological change (<xref ref-type="bibr" rid="bibr44-0270467612459924">Volti, 2001</xref>). Instead, they emphasize the mutual influence of technology and society, using terms such as <italic>co-construction, mutual shaping</italic> (<xref ref-type="bibr" rid="bibr29-0270467612459924">Lock, 2007</xref>, p. 876; <xref ref-type="bibr" rid="bibr34-0270467612459924">Oudshoorn &amp; Pinch, 2007</xref>, p. 544), <italic>inextricable feedback</italic> (<xref ref-type="bibr" rid="bibr13-0270467612459924">Dusek, 2006</xref>, p. 85), or <italic>dialectical relationship</italic> (<xref ref-type="bibr" rid="bibr46-0270467612459924">Wyatt, 2007</xref>, p. 176) to describe the simultaneous shaping of technology and society, one by the other. Indeed, some reject the separation of the two, arguing that they are two sides of the same coin and that we should study the “sociotechnical ensemble” rather than separate social and technical factors (<xref ref-type="bibr" rid="bibr6-0270467612459924">Bijker, 1997</xref>, p. 274).</p>
<p>Despite this, technological determinism survives as a familiar and long-standing theme in our culture. Historical literature touching on this theme includes <italic>Frankenstein</italic> and <italic>The Sorcerer’s Apprentice</italic>, and recent science fiction is replete with stories on similar themes. These stories are a dramatic and extreme expression of the ubiquitous sense that our lives are deeply influenced by technological developments in ways that are not really matters of individual or even collective choice (<xref ref-type="bibr" rid="bibr31-0270467612459924">Marx &amp; Smith, 1994</xref>).</p>
<p>The purpose of this article it to describe a set of mechanisms that explain this persistent sense that our control over technological development and our choices with respect to technology use are sometimes limited. In other words, why does the use of some technologies come to seem obligatory?</p>
</sec>
<sec id="section3-0270467612459924">
<title>Why Does the Use of Technology Become or Seem to Become Obligatory?</title>
<p>At the outset, it is necessary to distinguish two matters. First, one set of mechanisms explains why technologies seem to develop autonomously, without the deliberate choices of human beings. A second set, on which I am focusing in this article, explains why we feel obliged to use them. Although the first set of mechanisms does not directly answer the question of why technology use comes to feel obligatory, they are relevant to the general perception that we lack control not just of decisions to use but of the path of technological development. I address this first set briefly before turning to the main focus of this article, which is a set of mechanisms that might explain the perception that technology use is obligatory.</p>
<sec id="section4-0270467612459924">
<title>Explaining Why Technological Development Seems to Proceed Independent of Deliberate Human Control</title>
<p>A review of the literature on technological determinism and autonomous technology reveals several explanations for the perception that we lack control of technological development. One explanation is that whether there appears to be effective deliberate human control of technological change depends upon whether one uses a “micro”-level perspective that focuses on specific technological artifacts versus a “macro”-level perspective that instead observes the evolution of large and complex technological systems. For example, <xref ref-type="bibr" rid="bibr32-0270467612459924">Misa (1988)</xref> suggests that technological determinism looks more plausible when one looks at high-level social changes using a “macro” perspective. Thus, one notes the changes in urbanization and the economy that seem to have been brought about by the Industrial Revolution’s railroads and machinery (<xref ref-type="bibr" rid="bibr44-0270467612459924">Volti, 2001</xref>). If one looks instead at the individual technological artifacts, the social influences on the development of the technology come to the fore—or, as <xref ref-type="bibr" rid="bibr32-0270467612459924">Misa (1988)</xref> puts it, the “micro studies dissolve the Machine” (p. 319).</p>
<p>Similarly, the stage of development of the technology being examined might also affect the appearance of control or lack thereof (<xref ref-type="bibr" rid="bibr44-0270467612459924">Volti, 2001</xref>). At earlier stages in the development of a technology, social factors have a strong impact, while later on, once a technology is well established, it becomes more difficult to deviate from the patterns of life built around the technology because of social adaptation and infrastructural investment. Hughes writes that as technological systems grow larger and more complex, they acquire “technological momentum” and “tend to be more shaping of society and less shaped by it” (<xref ref-type="bibr" rid="bibr25-0270467612459924">Hughes, 1994</xref>, p. 112). This is because of the increasingly large investment in “acquired skill and knowledge, special-purpose machines and processes, enormous physical structures . . . organizational bureaucracy” and the network of interdependencies with other systems (<xref ref-type="bibr" rid="bibr25-0270467612459924">Hughes, 1994</xref>, p. 108). This produces a system with great inertia as a result of the “host of institutions and persons dependent politically, economically and ideologically on the system” (<xref ref-type="bibr" rid="bibr25-0270467612459924">Hughes, 1994</xref>, p. 113), and also produces the appearance of a lack of human choice or control that characterizes the technological imperative (<xref ref-type="bibr" rid="bibr32-0270467612459924">Misa, 1988</xref>). Before this inertia sets in, there is greater flexibility and social shaping is easier. As a result, he says, “social constructivists have a key to understanding the behavior of young systems; technical determinists come into their own with the mature ones” (<xref ref-type="bibr" rid="bibr25-0270467612459924">Hughes, 1994</xref>, p. 108). Social constructivists, too, have noted the “obduracy” of technological systems, explaining it as a result of the build-up of a set of social practices and infrastructure around a technology to produce a technological frame that makes it difficult to envisage or to pursue alternatives (<xref ref-type="bibr" rid="bibr26-0270467612459924">Jasanoff, Markle, Peterson, &amp; Pinch, 1995</xref>; <xref ref-type="bibr" rid="bibr41-0270467612459924">Sismondo, 2007</xref>).</p>
<p>A third observation is that technological development is often complex and that this undermines the effective control we have over that development. Novel technologies often generate unanticipated consequences, some of which are unwelcome. This give the impression to those reviewing the development process retroactively that the control was imperfect because of the inability to foresee and address harmful consequences. In addition, technological changes often result from the accretion of many small contributions from various actors or groups, operating under a multitude of different economic, social, educational, and environmental constraints. Put another way, “the entire process of change . . . is a vast series of partial adaptations adding up to results that no one ‘chose’ or ‘controlled’” (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>, p. 85). This uncoordinated process is far from deliberate conscious control—or, as Winner puts it “effective, guiding human will that determines the final result” (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>, p. 56). Others have proposed that the idea of autonomous technology is a natural psychological reaction in the face of the complexity of modern technology, the origins and workings of which are mysterious to most of us (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>; <xref ref-type="bibr" rid="bibr46-0270467612459924">Wyatt, 2007</xref>).</p>
<p>A fourth idea regarding the lack of human control of technological development is that a belief in technological determinism is deliberately propagated in order to serve the interests of those who are in favor of certain technologies. <xref ref-type="bibr" rid="bibr46-0270467612459924">Wyatt (2007)</xref> suggests that a belief in technological determinism would mute resistance and criticism of technological projects. This works partly because technological determinism suggests inevitability (such that resistance seems useless and those resisting look foolish) and also by tying the impugned action to the general cultural belief in inevitable and beneficial technological progress.</p>
<p>Fifth, Winner’s idea of “reverse adaptation” may also explain the apparent autonomy of technological development. He argues that the goals we meet using technological means are not freely or independently chosen. Instead, they are modified to suit the available technological means, producing reverse adapted objectives (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>). Winner offers the example of techniques of standardized computer-scored mass testing in the educational context that were intended to improve pedagogy but which subtly shifted pedagogical objectives toward those skills suited to this form of testing and away from skills (such as writing) that are not suited to it (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>). Even if there are limits to the malleability of our objectives, this mechanism might explain the prominence and inevitability of at least some technologies, which are virtually guaranteed to succeed by our redefining success as whatever it is they do.</p>
<p>Finally, a lack of control may emerge from what has been called the “shifting baseline syndrome” in the environmental context (<xref ref-type="bibr" rid="bibr35-0270467612459924">Pauly, 1995</xref>). The idea is that successive generations redefine what is natural as a function of their own starting points so that we fail to notice or care about shifts over time. Where technologies induce subtle changes over time, the failure to see them also undermines the claim that we have choice or control.</p>
</sec>
<sec id="section5-0270467612459924">
<title>Explaining Why the Use of Technology Becomes or Seems to Become Obligatory</title>
<p>I turn now to the different but related question of why we come to feel obliged to use certain technologies. Here I have in mind situations in which a person or community knowingly adopts a technology because it seems obligatory rather than situations of involuntary or unknowing exposure to the effects of the use of a technology by others (such as pollution). I discuss the following three mechanisms, which I think best explain obligatory technology: (1) competition, (2) dependency, and (3) a shift in norms and values (particularly the normalization and moralization of the use of the technology), which is sometimes enforced by the law.</p>
</sec>
</sec>
<sec id="section6-0270467612459924">
<title>Mechanism 1: Competition</title>
<p>All technologies that “work” enhance human capabilities in some way (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>). This is true even of technologies that, on their surface, appear to reduce human freedoms—such as locks or antilibidinal hormone treatment (“chemical castration”) sometimes used in the treatment of sex offenders. Locks enhance the capabilities of some humans to control others, and antilibidinal drugs can be interpreted as a mechanism to enhance self-control. In other words, a means to limit one’s own freedom in anticipation of a loss of self-control may be freedom-enhancing, as in the story of Odysseus who voluntarily had himself bound to the ship’s mast in anticipation of his loss of control upon hearing the Sirens’ song.</p>
<p>Of itself, the fact that a technology offers a way to extend human capabilities does not make the use of that new technological capability obligatory. One could wish others well with their enhanced capabilities while refusing them for ourselves. However, competition between individuals or groups may nonetheless prompt the uptake of technologies, in order not to be disadvantaged or left behind.</p>
<p>At the individual level, people may use technologies in order to obtain competitive advantage in the workplace, in academics, or in the social or political context. They may not necessarily view this as a form of obligatory technology, as they may be happy to seize these means for “getting ahead.” In the medical context, writers express concern about the use of cognition-enhancing drugs by healthy people in order to maintain or improve a competitive position. For example, there is evidence that some students misuse unprescribed stimulants in order to maintain alertness and concentration for studying (Sahakian &amp; Morein-Zamir, 2010). Others are concerned that people will face pressure to take the cognition-enhancing drugs in other competitive environments such as the workplace or the military (<xref ref-type="bibr" rid="bibr17-0270467612459924">Forlini &amp; Racine, 2009</xref>).</p>
<p>Competition at the level of groups (societies, nations, or communities) may also prompt the uptake of technologies.<sup><xref ref-type="fn" rid="fn4-0270467612459924">4</xref></sup> The phenomenon of the “arms race” is a competition <italic>par excellence</italic> that drives the pursuit and uptake of technology.</p>
</sec>
<sec id="section7-0270467612459924">
<title>Mechanism 2: Dependency and Need</title>
<p>The notion of technological dependency is a common one in the social study of technology (<xref ref-type="bibr" rid="bibr19-0270467612459924">Gerrie, 2008</xref>). Authors define this notion in different ways. Some see technological dependency as a mindset—namely, the tendency to look for “technological fixes” for problems, as well as the tendency to convert situations into problems that suit our technological means. This latter tendency is summed up in the aphorism that “to a person with a hammer, everything looks like a nail.” Conrad argues that this tendency exists in medicine, where the availability of new treatments, promoted by commercial and consumer interests, increasingly drives the creation of new categories of medical problems (<xref ref-type="bibr" rid="bibr11-0270467612459924">Conrad, 2005</xref>). The preference for technological fixes involves not just a faith in the superiority of the technological fix but also a narrowness of imagination that prevents us from seeing alternative interpretations of a situation.</p>
<p>However, there is more to technological dependency than this. We may also come to <italic>need</italic> the technology in several ways. First, a technology may offer a means of satisfying an existential need that cannot otherwise be met. Medicine provides multiple examples of this. Dialysis or a transplant is needed by patients with kidney failure in order to ensure survival. Patients may, of course, refuse these technologies, but at the cost of their lives. <xref ref-type="bibr" rid="bibr45-0270467612459924">Winner (1977)</xref> suggests that the invention of transplant technologies created the need for hearts:
<disp-quote>
<p>A technological innovation will often create scarcity where none existed before. . . . Before the invention of techniques of heart transplanting, there was no scarcity of hearts; one per person was universally supplied. (p. 101)</p>
</disp-quote></p>
<p>This is not quite accurate, as people with heart failure did need a new or a healed heart before we had the technological means to supply it. However, it is true that once a technological means to meet a critical need developed, the need for that technology will be so compelling as to be “obligatory.”</p>
<p>Second, and more commonly, a technology induces adaptations that may make it exceedingly hard to discontinue the use of the technology. An ancient example is provided by the story of King Thamus and Theuth that is recounted by Socrates in Plato’s <italic>Phaedrus</italic> (<xref ref-type="bibr" rid="bibr36-0270467612459924">Plato, 360 BCE</xref>). In a short section in the middle of the dialogue, Socrates recounts the story of how King Thamus reacted to the invention of writing by Theuth. Theuth thought that the invention would give people better memories and more knowledge. King Thamus, on the other hand, warned that far from improving memory, writing would weaken the human faculty of memory since people would no longer practice it. Another example of technologically induced dependency is the biological adaptation to an addictive drug. Dependency via adaptation may take place at the level of whole societies as well. The growth in the world’s population is supported by the increased productive capacity made possible by a range of agricultural technologies. To abandon these would most likely involve terrible costs.</p>
<p>Social adaptation may also make technologies seem obligatory. As technologies are taken up, they can shift social behaviors and expectations, making it difficult to participate fully in society if one does not follow along. In some places, the car has contributed to urban layouts that make it difficult to live without one, and has also produced social expectations that equate full “normal” adult status with owning a car (<xref ref-type="bibr" rid="bibr43-0270467612459924">Vanderbilt, 2010</xref>). In another example, it is now expected within our wired society that we will be available to communicate with others through certain communications networks (e.g., e-mail, mobile phone). If not, we risk being excluded from many social or economic activities. Similarly, it is expected that we will have access to a certain store of information now available most conveniently online. If we refuse to use the Internet, we will similarly find it difficult to participate fully in a community that engages in a lot of social, political, or economic activity online (<xref ref-type="bibr" rid="bibr20-0270467612459924">Hassan, 2010</xref>). Furthermore, we may be hindered in our off-line interactions that presuppose our use of the Internet—as with students unable to complete assignments set by their teachers.</p>
<p>Another example is drawn from the discussion above regarding large-scale technological systems. These tend to involve massive investments in equipment, education, and infrastructure that can be very difficult to dismantle (<xref ref-type="bibr" rid="bibr25-0270467612459924">Hughes, 1994</xref>). The individual decision to live “off the grid” can have considerable financial and social costs. <xref ref-type="bibr" rid="bibr45-0270467612459924">Winner (1977)</xref> sees in this an explanation for the apparent autonomy of technology:
<disp-quote>
<p>Megatechnical systems . . . are anything but responsive and flexible. Their conditions of size, complexity, and mutual interdependence give them a rigidity and inertia difficult to overcome. Rather than respond to commands generated by political or social processes, such systems produce demands society must fulfill or face unfortunate consequences. (p. 251)</p>
</disp-quote></p>
<p>In both of these examples (the technological satisfaction of unmet existential needs, or major biological, environmental, or social adaptations to technologies that make them hard to abandon), the use of the technology seems obligatory. Of course, they are not strictly obligatory because they could be abandoned or modified at a cost. Where that cost is exceedingly high, however, they will be effectively obligatory.</p>
</sec>
<sec id="section8-0270467612459924">
<title>Mechanism 3: Technological Ideology, Values, Norms, and the Law</title>
<p>A third mechanism that explains obligatory technologies operates at the level of culture. I have in mind three aspects of the cultural approach to technology that contribute to making technology obligatory. First, as has been observed many times, the ideology of technological progress helps to mute criticism and to smooth the incorporation of technologies into the culture. Second, the emergence of a new technology extends human capacities. Since moral responsibility is generally reserved for actions within our capacity, it is possible to “moralize” about that technology. By this I mean that we can now make moral judgments about the use or (more importantly for this discussion) the nonuse of that technology. This idea is encapsulated by <xref ref-type="bibr" rid="bibr12-0270467612459924">Dennett’s (2004)</xref> observation that
<disp-quote>
<p>the more we know, the more we can do; the more we can do, the more obligations we face. We may yearn for the good old days when ignorance was a better excuse than it is today, but we cannot turn back the clock. (p. 301)</p>
</disp-quote></p>
<p>Third, as a new technology is widely adopted, it becomes “normalized,” creating an “inversion of the normal” (<xref ref-type="bibr" rid="bibr33-0270467612459924">Morgan, 1991</xref>) whereby the use of the technology becomes normal and nonuse becomes aberrant even if not morally blameworthy. This normalization may also entail social and legal consequences. I will now address each of these three topics in greater detail.</p>
<p>The ideology of technological progress is a long-standing feature of our culture. The belief, since the Enlightenment, that advances in science and technology would deliver steady improvement in human welfare produces a very welcoming ideological environment for the creation and adoption of new technologies (<xref ref-type="bibr" rid="bibr28-0270467612459924">Marx and Smith, 1994</xref>). A corollary of this is that a culture is less likely to focus on what is lost in technologically driven change and is apt to view objections or resistance to the change as wrongheaded (Winner, 1997). Winner outlines a range of other ideas that might give technologies such a central role in human existence. Beyond the ideology of technological progress, these include a supposed religious imperative or entitlement to dominate nature, a dominant mindset that defines and responds to problems technologically or a narrowly instrumental outlook that sees everything as a means to be used for one end or another (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>). This ideological context likely makes it more difficult for people to choose not to use a technology—indirectly contributing to the sense that the use of a technology is obligatory.</p>
<p>Technologies usually offer extended or novel capabilities to human beings. While it makes little sense to ask whether a person <italic>ought</italic> to do something that is not possible, the question can be sensibly asked once a technology makes an action possible. Where a societal consensus exists that a particular technology ought to be used, a person may come under pressure to do so, producing the sense that the use of the technology is obligatory. Social and sometimes legal sanctions for failing to do so may ensue. Of course, not all technologies will attract moral judgment, but some may become obligatory in this way.</p>
<p>The moral judgment of the nonuse of technology may be enforced through social disapproval or sometimes even through legal consequences. One area in which there is a pronounced tendency to apply moral judgment around technology use and nonuse is in pregnancy. Women who use antidepressants during pregnancy are judged unfavorably by some (despite the risks to the mother and fetus posed by uncontrolled depression and despite the relatively low risks associated with some antidepressants;(<xref ref-type="bibr" rid="bibr18-0270467612459924">Gawley, Einarson, &amp; Bowen, 2011</xref>). At the same time, women are also sometimes judged unfavorably when they refuse other prenatal treatments such as Caesarean section (<xref ref-type="bibr" rid="bibr40-0270467612459924">Scott, 2000</xref>) or antiretroviral drugs (<xref ref-type="bibr" rid="bibr1-0270467612459924">Ayers, 2002</xref>), or when they refuse a hospital birth in favor of a home birth.<sup><xref ref-type="fn" rid="fn5-0270467612459924">5</xref></sup> Bioethicists now debate whether parents who have the ability to avoid giving birth to a child with a severe disability have a moral obligation to do so, using one of the range of novel or emerging technologies of preconception, preimplantation, or prenatal diagnosis and selection.<sup><xref ref-type="fn" rid="fn6-0270467612459924">6</xref></sup> Evidently, in the absence of these technologies, no such question was debated but once the technologies became available, moral questions about their non-use emerged.</p>
<p>Once a child is born, a parental refusal of the standard medical treatment for a child may not only give rise to moral disapproval of that parent but also to state intervention in the form of child protection proceedings. Cochlear implantation for children has given rise to a vigorous debate centering on the morality of parental decisions. Some argue that it is unethical, even abusive, not to provide the implantation where it is available, while others argue that it is unethical and abusive to impose the implants on children (<xref ref-type="bibr" rid="bibr2-0270467612459924">Balkany, Hodges, &amp; Goodman, 1996</xref>; <xref ref-type="bibr" rid="bibr8-0270467612459924">Byrd, Shuman, Kileny, &amp; Kileny, 2011</xref>; <xref ref-type="bibr" rid="bibr39-0270467612459924">Savulescu, 2009b</xref>).<sup><xref ref-type="fn" rid="fn7-0270467612459924">7</xref></sup> Similar debates surround childhood vaccination (e.g., <xref ref-type="bibr" rid="bibr16-0270467612459924">Finn &amp; Savulescu, 2011</xref>). The consensus moral position on some of these debates is unsettled, so the pressure to adopt these particular treatments may not (yet) be strong. In other cases, strong moral judgment is backed up by legal enforcement, as with the removal of children from parental custody where parents refuse blood transfusions for them on religious grounds (e.g., <italic>B(R) v. Children’s Aid Society of Metropolitan Toronto</italic>, <xref ref-type="bibr" rid="bibr47-0270467612459924">1995</xref>). This tendency to “moralize” about the use of some technologies provides one explanation for the phenomenon of “obligatory technologies.”</p>
<p>The moral judgment of the non-use of technologies is enforced via legal consequences in other ways as well. I propose two additional examples, also focusing on the reasonableness of refusing to use medical technologies. The first is the doctrine of mitigation in tort law. This requires a plaintiff who seeks compensation for negligent injuries inflicted by the defendant to take reasonable steps to ameliorate their own injuries. If a patient refuses to do so, the injuries are viewed as “avoidable losses” that are not compensable. In the leading Canadian case, <italic>Janiak v. Ippolito</italic> (<xref ref-type="bibr" rid="bibr54-0270467612459924">1985</xref>), the Supreme Court held that a patient who refused the medically recommended spinal surgery because he was frightened by the small risks of paralysis and death posed by the surgery could not recover damages for the disability that he would have been likely to avoid by accepting the surgery. Canadian courts have applied the doctrine of mitigation to a broad range of medical treatments and the standard approach is to require plaintiffs to take only reasonable steps. However, what is reasonable is judged by the court and will reflect the consensus in the medical profession as well as in the community more generally. In this way, those who do not conform to this consensus will nonetheless find themselves bound to abide by it or to suffer financial consequences. For example, refusals based on religious belief are generally treated as failures to mitigate (<xref ref-type="bibr" rid="bibr27-0270467612459924">Knapp, 1992</xref>; <xref ref-type="bibr" rid="bibr52-0270467612459924"><italic>Hobbs v. Robertson</italic>, 2001</xref>).</p>
<p>The second example is drawn from the case law dealing with legal responsibility for injuries inflicted by legally incapable persons. In Canadian tort law, people who become suddenly and unforeseeably incapacitated through mental illness, seizures, heart attack, or unconsciousness will not usually be labeled negligent and held legally responsible for injuries they cause to others (<xref ref-type="bibr" rid="bibr50-0270467612459924"><italic>Fiala v. Cechmanek</italic>, 2001</xref>). However, where a person knows or ought to know that they are at risk of becoming incapacitated, they may be held liable for engaging in risky activities such as driving (<xref ref-type="bibr" rid="bibr48-0270467612459924"><italic>Calgary (City) v. Thomas</italic>, 1995</xref>; <xref ref-type="bibr" rid="bibr49-0270467612459924"><italic>Dobbs v. Mayer Estate</italic>, 1985</xref>; <xref ref-type="bibr" rid="bibr51-0270467612459924"><italic>Gordon v. Wallace</italic>, 1973</xref>; <xref ref-type="bibr" rid="bibr59-0270467612459924"><italic>Telfer v. Wright</italic>, 1978</xref>). It may not be enough, however, for people simply to avoid activities like driving. Although such cases are rare, mentally ill people who may pose risks of injury to others even while not engaging in risky activities like driving may be required to take prescribed medication on pain of being held negligent should they cause injury while incapacitated because of mental illness. Note that in the absence of this pharmacological means of maintaining capacity, incapable mentally ill people would not have been held liable in Canadian law. However, as the following case examples illustrate, once capacity-restoring technologies are available, some courts will view their non-use as negligent.</p>
<p>For example, in <xref ref-type="bibr" rid="bibr55-0270467612459924"><italic>McLean v. Seisel</italic> (2002)</xref>, a woman who, while competent and while being aware of the risk that she may become violent during psychotic episodes, decided not to take her antipsychotic drugs was held contributorily negligent for injuries later inflicted on her by the police while they attempted to apprehend her. The judgment demonstrates how the law may create a form of legal responsibility to use the available technological means to maintain self-control. The trial judge sympathized with the “plaintiff’s plight of being plagued with a condition thought to be due to a chemical imbalance,” but noted that it responded to drug therapy (para. 65). He ruled that she knew or ought to have known that “non-compliance with her drug program” would lead to psychotic episodes and police intervention, and that during these episodes she posed a risk of harm to others, the police and herself (para. 67). The judge concluded that “to the extent that she increases this risk of harm, she is the author of her own misfortune and she must accept responsibility for consciously allowing her latent disease to become overt” (para. 68). On appeal, the plaintiff argued that her failure to take her medication was a symptom of her illness and was an involuntary act. The Court of Appeal rejected this argument, stating that she was aware that (1) she had a medical disorder, (2) the failure to take her medication would lead to psychotic episodes, and (3) this posed a risk of harm to herself and others, and that she took the decision to discontinue her medication when she was “medicated and lucid” (<xref ref-type="bibr" rid="bibr55-0270467612459924"><italic>McLean v. Seisel</italic>, 2004</xref>).</p>
<p>In <xref ref-type="bibr" rid="bibr58-0270467612459924"><italic>Swift v. Fitchburg Mutual Insurance Co</italic> (1998)</xref>, a man with a history of psychological problems was prescribed antidepressants. He violently attacked the plaintiffs in a state of uncontrollable rage when his car became stuck in snow in their driveway. At the time, he had stopped taking the prescribed drugs. He was found not guilty by reason of mental illness in the criminal trial, but he was found negligent in the ensuing civil lawsuit. The plaintiffs argued that he knew or ought to have known that he “had a propensity to become irate and uncontrollable if he failed to take his medication as prescribed.” The judge agreed, and found him negligent in doing so.</p>
<p>In <xref ref-type="bibr" rid="bibr57-0270467612459924"><italic>Stuyvesant Associates v. Doe</italic> (1987)</xref>, a landlord brought an action for possession of a rental property against the tenant who had damaged it during a psychotic state. The statutory condition for eviction was that the damage should have been caused willfully or through gross negligence. The defendant had been diagnosed with schizophrenia and had been treated through injections of medication. The psychiatric testimony was that if the defendant missed an injection, he would become psychotic and incapable within 7 to 10 days. The psychiatrist testified that, while mentally well, the defendant knew the significance and likely consequences of missing the injections. He also testified that while well, a person might rationalize that the injections were not needed and might then miss an injection. No evidence was given for why the defendant missed the injection in this case. The court concluded that the defendant had been negligent in failing to get his scheduled injections, and because of this “he allowed himself to become psychotic, with the resulting damage done by his own hands” (p. 450). Even if he did not intend to tempt fate by missing the injection and did not intend the resulting damage, the court said: “[It] is obvious that he was the person who allowed the condition to result, with the consequent damage. This court finds that his having allowed the condition was the reasonably foreseeable consequence of his acts, and was grossly negligent” (p. 450).</p>
<p>Another way in which technology use may come to seem obligatory is through the process of “normalization.” In essence, as more people adopt a particular technology, it comes to seem normal and reasonable, and the refusal of the technology becomes abnormal and unreasonable—a process that Morgan describes as the “inversion of the normal” in the context of cosmetic surgery (<xref ref-type="bibr" rid="bibr33-0270467612459924">Morgan, 1991</xref>). An interesting example is drawn from the Canadian case, <xref ref-type="bibr" rid="bibr53-0270467612459924"><italic>Hoffman v. Monsanto</italic> (2005/2007)</xref>. In that case, a group of organic farmers sued the maker of genetically modified canola because its pollen had drifted onto their canola crops, making it impossible for them to sell their crops as certified organic canola. The defendant argued that the pollen from its genetically modified canola was not harmful and had in fact been approved by the government. It took the position that the organic farmers had brought harm upon themselves because they made the decision to grow organic canola that would be rejected by organic certifiers (<xref ref-type="bibr" rid="bibr9-0270467612459924">Chandler, 2007</xref>; <xref ref-type="bibr" rid="bibr53-0270467612459924"><italic>Hoffman v. Monsanto</italic>, 2005</xref>, <xref ref-type="bibr" rid="bibr53-0270467612459924">2007</xref>). This reasoning hides the implicit redefinition of the normal environment as containing genetically modified canola pollen, and harm as flowing from attempts to live in a manner inconsistent with the new “normal” environment. Undoubtedly, the normal environment in Canada and the United States now does contain genetically modified canola, not just because most farmers now grow genetically modified canola but also because it is likely to be cross-pollinating with other wild plants (<xref ref-type="bibr" rid="bibr4-0270467612459924">Biello, 2010</xref>).</p>
<p>The normalization of the use of technologies can also be self-reinforcing. In the context of cognition-enhancing drugs, Sahakian and Morein-Zamir note that college students overestimate the prevalence of the nonmedical use of prescription stimulants. They suggest that this may give rise to “misperceived norms which in turn may promote such behavior” (<xref ref-type="bibr" rid="bibr37-0270467612459924">Sahakian &amp; Morein-Zamir, 2011</xref>, citing <xref ref-type="bibr" rid="bibr30-0270467612459924">McCabe et al., 2005</xref>).</p>
<p>Social norms about what is reasonable and normal as far as medical treatment is concerned are likely to affect patient consent to treatment. The law may reflect these norms in interesting ways as well. In Canada, patients who suffer harm from treatment may sue physicians in negligence for failure to disclose the material risks of treatment. In order to succeed in their claim for damages, they must show that they would have refused the treatment had there been proper disclosure of the risks. The Supreme Court of Canada has indicated that the way to determine what the plaintiff would have done if properly warned of the risks is to ask not what <italic>that</italic> plaintiff would have done, but what a hypothetical reasonable person in the position of the patient would have done (<xref ref-type="bibr" rid="bibr56-0270467612459924"><italic>Reibl v. Hughes</italic>, 1980</xref>). The purpose of setting aside what plaintiffs say they would have done is, according to the court, that plaintiff will invariably say they would have rejected the treatment. It is true that courts will consider some features of the plaintiff in asking about a reasonable person <italic>in the position of the plaintiff</italic>, but the fact remains that the inquiry may give effect to social norms related to medical treatment in a way that works against a patient who might genuinely have decided differently.</p>
</sec>
<sec id="section9-0270467612459924" sec-type="conclusions">
<title>Conclusion</title>
<p>The issue of human control of the development and use of technologies is a fascinating question. The argument never really was that technologies themselves have some sort of autonomous agency, but instead that humans have imperfect control over the process of technological development and the patterns of use of technologies. This poor control flows from limited powers of foresight and understanding, familiar problems of political governance and coordination, and from a fundamental ideological embrace of technological progress. Technological progress has without doubt brought a multitude of benefits, and likely will bring many more. However, it is also clear that we struggle to manage the costs of that progress and that these can include not just physical harm but also psychological discomfort (as manifested in the recurring malaise about our powerlessness vis-à-vis the development and uptake of technologies).</p>
<p>The problem of inadequate human control over technological development and use is obviously a big one, requiring attention from many people representing multiple disciplinary perspectives. Winner’s diagnosis of our problem is that we are “technological somnambulists” (<xref ref-type="bibr" rid="bibr45-0270467612459924">Winner, 1977</xref>, p. 324). In essence, we are largely unaware of the dynamics that drive the uptake of technologies, and only intermittently aware of the often far-reaching changes in our cultures that the technologies bring about. His prescription is for increased attention and sensitivity to these dynamics so that we are better placed to make informed decisions.</p>
<p>This article has sought to answer this prescription by exploring three mechanisms that might explain “obligatory technologies”: competition, dependency, and ideologies, norms, and values. The final category is particularly interesting from the legal perspective because of how the law reflects and reinforces social norms and also imposes disadvantages on those whose nonuse of technologies is viewed as abnormal or morally wrong. In some cases this may be quite obvious and direct, but I hope I have demonstrated that the effects can also be quite subtle.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other">
<label>Author’s Note</label>
<p>This article has been shortened and refocused for publication in the <italic>Bulletin of Science, Technology &amp; Society</italic>, with the permission of the original publisher. The original publication, which explored these themes in the context of the autonomy of patients in medical decision making, is available at Jennifer A. Chandler. (2011). Obligatory technologies and the autonomy of patients in biomedical ethics. <italic>Griffith Law Review, 20</italic>(4), 905-930.</p>
</fn>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p></fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0270467612459924">
<label>1.</label>
<p>“Technology” is usually understood as the tools, techniques, and organizational structures devised and used by humans to achieve their objectives.</p>
</fn>
<fn fn-type="other" id="fn2-0270467612459924">
<label>2.</label>
<p>The phrase <italic>social factors</italic> is used here to refer to patterns of relationships between people, as well as to culture, norms, and values.</p>
</fn>
<fn fn-type="other" id="fn3-0270467612459924">
<label>3.</label>
<p>Winner (1997, p. 280) offers a selection of such statements drawn from <xref ref-type="bibr" rid="bibr14-0270467612459924">Ellul (1964)</xref>: “Technique has become a reality in itself, self-sufficient, with its special laws and its own determinations” (p. 134).</p>
</fn>
<fn fn-type="other" id="fn4-0270467612459924">
<label>4.</label>
<p><xref ref-type="bibr" rid="bibr45-0270467612459924">Winner (1977</xref>, p. 13), quoting <xref ref-type="bibr" rid="bibr24-0270467612459924">Heisenberg (1958</xref>, p. 189):
<disp-quote>
<p>The enormous success of this combination of natural and technical science . . . led to a strong preponderance of those nations or states or communities in which this kind of activity flourished, and as a natural consequence this activity had to be taken up even by those nations which by tradition would not have been inclined toward natural and technical sciences. The modern means of communication and of traffic finally completed this process of expansion of technical civilization.</p>
</disp-quote></p>
</fn>
<fn fn-type="other" id="fn5-0270467612459924">
<label>5.</label>
<p><xref ref-type="bibr" rid="bibr10-0270467612459924">Chervenak, McCullough, and Arabin (2011)</xref> observe that “the immutable truth is that planned home birth imposes unnecessary increased risk of neonatal mortality and morbidity and perinatal mortality. The pregnant woman is ethically obligated to prevent these clinical risks by accepting hospital-based delivery” (p. 1186).</p>
</fn>
<fn fn-type="other" id="fn6-0270467612459924">
<label>6.</label>
<p>See the diverging views in <xref ref-type="bibr" rid="bibr21-0270467612459924">Hayry (2010)</xref>, <xref ref-type="bibr" rid="bibr38-0270467612459924">Savulescu (2009a)</xref>, and <xref ref-type="bibr" rid="bibr3-0270467612459924">Bennett (2009)</xref>.</p>
</fn>
<fn fn-type="other" id="fn7-0270467612459924">
<label>7.</label>
<p>For an insightful examination of the topic that addresses the technological dimension—for example, exploring the ethical arguments around public funding for research into “cures” for deafness—see <xref ref-type="bibr" rid="bibr42-0270467612459924">Sparrow (2005)</xref>.</p></fn>
</fn-group>
</notes>
<bio>
<title>Bio</title>
<p><bold>Jennifer A. Chandler</bold>, BSc. (University of Western Ontario), LLB (Queen’s University), LLM (Harvard) is an Associate Professor in the Faculty of Law, University of Ottawa. Her research and teaching are focused on the ethico-legal aspects of biomedical science and technology, particularly neuroscience as well as organ donation and transplantation.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ayers</surname><given-names>L.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Is mama a criminal: An analysis of potential criminal liability of HIV-infected pregnant women in the context of mandated drug therapy</article-title>. <source>Drake Law Review</source>, <volume>50</volume>, <fpage>293</fpage>-<lpage>314</lpage>.</citation>
</ref>
<ref id="bibr2-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Balkany</surname><given-names>T. J.</given-names></name>
<name><surname>Hodges</surname><given-names>A. V.</given-names></name>
<name><surname>Goodman</surname><given-names>K. W.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Ethics of cochlear implantation in young children</article-title>. <source>Otolaryngology: Head and Neck Surgery</source>, <volume>114</volume>, <fpage>748</fpage>-<lpage>755</lpage>.</citation>
</ref>
<ref id="bibr3-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The fallacy of the principle of procreative beneficence</article-title>. <source>Bioethics</source>, <volume>23</volume>, <fpage>265</fpage>-<lpage>273</lpage>.</citation>
</ref>
<ref id="bibr4-0270467612459924">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Biello</surname><given-names>D.</given-names></name>
</person-group> (<year>2010</year>, <month>August</month> <day>6</day>). <source>Genetically modified crop on the loose and evolving in U.S. Midwest</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.scientificamerican.com/article.cfm?id=genetically-modified-crop">http://www.scientificamerican.com/article.cfm?id=genetically-modified-crop</ext-link></citation>
</ref>
<ref id="bibr5-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bijker</surname><given-names>W. E.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Sociohistorical technology studies</article-title>. In <person-group person-group-type="editor">
<name><surname>Jasanoff</surname><given-names>S.</given-names></name>
<name><surname>Markle</surname><given-names>G. E.</given-names></name>
<name><surname>Petersen</surname><given-names>J. C.</given-names></name>
<name><surname>Pinch</surname><given-names>T.</given-names></name>
</person-group> (Eds.), <source>Handbook of science and technology studies</source> (Rev ed., pp. <fpage>229</fpage>-<lpage>256</lpage>). <publisher-loc>London, England</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr6-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bijker</surname><given-names>W. E.</given-names></name>
</person-group> (<year>1997</year>). <source>Of bicycles, bakelites and bulbs: Toward a theory of sociotechnical change</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr7-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bijker</surname><given-names>W. E.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Social construction of technology</article-title>. In <person-group person-group-type="editor">
<name><surname>Olsen</surname><given-names>J. K. B.</given-names></name>
<name><surname>Pedersen</surname><given-names>S. A.</given-names></name>
<name><surname>Hendricks</surname><given-names>V. F.</given-names></name>
</person-group> (Eds.), <source>A companion to the philosophy of technology</source> (pp. <fpage>88</fpage>-<lpage>94</lpage>). <publisher-loc>Chichester, England</publisher-loc>: <publisher-name>Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr8-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Byrd</surname><given-names>S.</given-names></name>
<name><surname>Shuman</surname><given-names>A. G.</given-names></name>
<name><surname>Kileny</surname><given-names>S.</given-names></name>
<name><surname>Kileny</surname><given-names>P. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The right not to hear: The ethics of parental refusal of hearing rehabilitation</article-title>. <source>Laryngoscope</source>, <volume>121</volume>, <fpage>1800</fpage>-<lpage>1804</lpage>.</citation>
</ref>
<ref id="bibr9-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chandler</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The autonomy of technology: Do courts control technology or do they just legitimize its social acceptance?</article-title> <source>Bulletin of Science, Technology &amp; Society</source>, <volume>27</volume>, <fpage>339</fpage>-<lpage>348</lpage>.</citation>
</ref>
<ref id="bibr10-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chervenak</surname><given-names>F. A.</given-names></name>
<name><surname>McCullough</surname><given-names>L. B.</given-names></name>
<name><surname>Arabin</surname><given-names>B.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Obstetric ethics: An essential dimension of planned home birth</article-title>. <source>Obstetrics and Gynecology</source>, <volume>117</volume>, <fpage>1183</fpage>-<lpage>1187</lpage>.</citation>
</ref>
<ref id="bibr11-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Conrad</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The shifting engines of medicalization</article-title>. <source>Journal of Health and Social Behavior</source>, <volume>46</volume>(<issue>1</issue>), <fpage>3</fpage>-<lpage>14</lpage>.</citation>
</ref>
<ref id="bibr12-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dennett</surname><given-names>D. C.</given-names></name>
</person-group> (<year>2004</year>). <source>Freedom evolves</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Penguin</publisher-name>.</citation>
</ref>
<ref id="bibr13-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dusek</surname><given-names>V.</given-names></name>
</person-group> (<year>2006</year>). <source>Philosophy of technology: An introduction</source>. <publisher-loc>Oxford, England</publisher-loc>: <publisher-name>Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr14-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ellul</surname><given-names>J.</given-names></name>
</person-group> (<year>1964</year>). <source>The technological society</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Knopf Doubleday</publisher-name>.</citation>
</ref>
<ref id="bibr15-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Feenberg</surname><given-names>A.</given-names></name>
</person-group> (<year>1999</year>). <source>Questioning technology</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr16-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Finn</surname><given-names>A.</given-names></name>
<name><surname>Savulescu</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Is immunisation child protection?</article-title> <source>Lancet</source>, <volume>378</volume>, <fpage>465</fpage>-<lpage>468</lpage>.</citation>
</ref>
<ref id="bibr17-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Forlini</surname><given-names>C.</given-names></name>
<name><surname>Racine</surname><given-names>E.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Autonomy and coercion in academic “cognitive enhancement” using methylphenidate: Perspectives of key stakeholders</article-title>. <source>Neuroethics</source>, <volume>2</volume>, <fpage>163</fpage>-<lpage>177</lpage>.</citation>
</ref>
<ref id="bibr18-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gawley</surname><given-names>L.</given-names></name>
<name><surname>Einarson</surname><given-names>A.</given-names></name>
<name><surname>Bowen</surname><given-names>A.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Stigma and attitudes towards antenatal depression and antidepressant use during pregnancy in healthcare students</article-title>. <source>Advances in Health Science Education: Theory and Practice</source>, <volume>16</volume>, <fpage>669</fpage>-<lpage>679</lpage>.</citation>
</ref>
<ref id="bibr19-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gerrie</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Three species of technological dependency</article-title>. <source>Techne</source>, <volume>12</volume>, <fpage>184</fpage>-<lpage>194</lpage>.</citation>
</ref>
<ref id="bibr20-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hassan</surname><given-names>R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Social acceleration and the network effect: A defence of social “science fiction” and network determinism</article-title>. <source>British Journal of Sociology</source>, <volume>61</volume>, <fpage>356</fpage>-<lpage>374</lpage>.</citation>
</ref>
<ref id="bibr21-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hayry</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <source>Rationality and the genetic challenge: Making people better?</source> <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heilbroner</surname><given-names>R. L.</given-names></name>
</person-group> (<year>1967</year>). <article-title>Do machines make history?</article-title> <source>Technology and Culture</source>, <volume>8</volume>, <fpage>335</fpage>-<lpage>345</lpage>.</citation>
</ref>
<ref id="bibr23-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Heilbroner</surname><given-names>R. L.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Technological determinism revisited</article-title>. In <person-group person-group-type="editor">
<name><surname>Smith</surname><given-names>M. R.</given-names></name>
<name><surname>Marx</surname><given-names>L.</given-names></name>
</person-group> (Eds.), <source>Does technology drive history? The dilemma of technological determinism</source> (pp. <fpage>67</fpage>-<lpage>78</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr24-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Heisenberg</surname><given-names>W.</given-names></name>
</person-group> (<year>1958</year>). <source>Physics and philosophy</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Harper &amp; Row</publisher-name>.</citation>
</ref>
<ref id="bibr25-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hughes</surname><given-names>T. P.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Technological momentum</article-title>. In <person-group person-group-type="editor">
<name><surname>Smith</surname><given-names>M. R.</given-names></name>
<name><surname>Marx</surname><given-names>L.</given-names></name>
</person-group> (Eds.), <source>Does technology drive history? The dilemma of technological determinism</source> (pp. <fpage>101</fpage>-<lpage>113</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr26-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Jasanoff</surname><given-names>S.</given-names></name>
<name><surname>Markle</surname><given-names>G. E.</given-names></name>
<name><surname>Peterson</surname><given-names>J. C.</given-names></name>
<name><surname>Pinch</surname><given-names>T.</given-names></name>
</person-group> (Eds.). (<year>1995</year>). <source>Handbook of science and technology studies</source> (Rev. ed.). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr27-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Knapp</surname><given-names>G.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Annotation: Refusal of medical treatment on religious grounds as affecting right to recover for personal injury or death</article-title>. <source>ALR</source>, <volume>3</volume>, <fpage>721</fpage>.</citation>
</ref>
<ref id="bibr28-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Marx</surname><given-names>Leo</given-names></name>
<name><surname>Smith</surname><given-names>Merritt Roe</given-names></name>
</person-group> (<year>1994</year>) ‘<article-title>Introduction</article-title>’ in <person-group person-group-type="editor">
<name><surname>Smith</surname><given-names>Merritt Roe</given-names></name>
<name><surname>Marx</surname><given-names>Leo</given-names></name>
</person-group> (eds) <source>Does Technology Drive History? The Dilemma of Technological Determinism</source>, <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr29-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lock</surname><given-names>M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Biomedical technologies, cultural horizons and contested boundaries</article-title>. In <person-group person-group-type="editor">
<name><surname>Hackett</surname><given-names>E. J.</given-names></name>
<name><surname>Amsterdamska</surname><given-names>O.</given-names></name>
<name><surname>Lynch</surname><given-names>M.</given-names></name>
<name><surname>Wajcman</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <source>Handbook of science and technology studies</source> (<edition>3rd ed.</edition>, pp. <fpage>875</fpage>-<lpage>900</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr30-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCabe</surname><given-names>S. E.</given-names></name>
<name><surname>Schulenberg</surname><given-names>J. E.</given-names></name>
<name><surname>Johnston</surname><given-names>L.</given-names></name>
<name><surname>O’Malley</surname><given-names>P. M.</given-names></name>
<name><surname>Bachman</surname><given-names>J.</given-names></name>
<name><surname>Kloska</surname><given-names>D. D.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Selection and socialization effects of fraternities and sororities on U.S. college student substance use: A multi-cohort national longitudinal study</article-title>. <source>Addiction</source>, <volume>100</volume>, <fpage>512</fpage>-<lpage>524</lpage>.</citation>
</ref>
<ref id="bibr31-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Marx</surname><given-names>L.</given-names></name>
<name><surname>Smith</surname><given-names>M. R.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Introduction</article-title>. In <person-group person-group-type="editor">
<name><surname>Smith</surname><given-names>M. R.</given-names></name>
<name><surname>Marx</surname><given-names>L.</given-names></name>
</person-group> (Eds.), <source>Does technology drive history? The dilemma of technological determinism</source> (pp. <fpage>ix</fpage>-<lpage>xv</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr32-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Misa</surname><given-names>T. J.</given-names></name>
</person-group> (<year>1988</year>). <article-title>How machines make history and how historians (and others) help them to do so</article-title>. <source>Science Technology &amp; Human Values</source>, <volume>13</volume>, <fpage>308</fpage>-<lpage>331</lpage>.</citation>
</ref>
<ref id="bibr33-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Morgan</surname><given-names>K. P.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Women and the knife: Cosmetic surgery and the colonization of women’s bodies</article-title>. <source>Hypatia</source>, <volume>6</volume>, <fpage>25</fpage>-<lpage>33</lpage>.</citation>
</ref>
<ref id="bibr34-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Oudshoorn</surname><given-names>N.</given-names></name>
<name><surname>Pinch</surname><given-names>T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>User–technology relationships</article-title>. In <person-group person-group-type="editor">
<name><surname>Hackett</surname><given-names>E. J.</given-names></name>
<name><surname>Amsterdamska</surname><given-names>O.</given-names></name>
<name><surname>Lynch</surname><given-names>M.</given-names></name>
<name><surname>Wajcman</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <source>Handbook of science and technology studies</source> (<edition>3rd ed.</edition>, pp. <fpage>541</fpage>-<lpage>566</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr35-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pauly</surname><given-names>D.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Anecdotes and the shifting baseline syndrome of fisheries</article-title>. <source>Trends in Ecology and Evolution</source>, <volume>10</volume>, <fpage>430</fpage>.</citation>
</ref>
<ref id="bibr36-0270467612459924">
<citation citation-type="web">
<collab>Plato</collab>. (360 BCE). <source>Phaedrus</source> (<person-group person-group-type="translator">
<name><surname>Jowett</surname><given-names>B.</given-names></name>
</person-group>, Trans.). <source>Internet Classics Archive</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://classics.mit.edu/Plato/phaedrus.html">http://classics.mit.edu/Plato/phaedrus.html</ext-link></citation>
</ref>
<ref id="bibr37-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sahakian</surname><given-names>B.</given-names></name>
<name><surname>Morein-Zamir</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Neuroethical issues in cognitive enhancement</article-title>. <source>Journal of Psychopharmacology</source>, <volume>25</volume>, <fpage>197</fpage>-<lpage>204</lpage>.</citation>
</ref>
<ref id="bibr38-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Savulescu</surname><given-names>J.</given-names></name>
</person-group> (<year>2009a</year>). <article-title>The moral obligation to create children with the best chance of the best life</article-title>. <source>Bioethics</source>, <volume>23</volume>, <fpage>274</fpage>-<lpage>290</lpage>.</citation>
</ref>
<ref id="bibr39-0270467612459924">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Savulescu</surname><given-names>J.</given-names></name>
</person-group> (<year>2009b</year>, <month>July</month> <day>13</day>). <article-title>Refusing cochlear implants: Is it child neglect?’</article-title> <source>Practical Ethics Blog</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.practicalethicsnews.com/practicalethics/2009/07/refusing-cochlear-implants-is-it-child-neglect.html">www.practicalethicsnews.com/practicalethics/2009/07/refusing-cochlear-implants-is-it-child-neglect.html</ext-link></citation>
</ref>
<ref id="bibr40-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scott</surname><given-names>R.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The pregnant woman and the Good Samaritan: Can a woman have a duty to undergo a caesarean section?</article-title> <source>Oxford Journal of Legal Studies</source>, <volume>20</volume>, <fpage>407</fpage>-<lpage>436</lpage>.</citation>
</ref>
<ref id="bibr41-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sismondo</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Science and technology studies and an engaged program</article-title>. In <person-group person-group-type="editor">
<name><surname>Hackett</surname><given-names>E. J.</given-names></name>
<name><surname>Amsterdamska</surname><given-names>O.</given-names></name>
<name><surname>Lynch</surname><given-names>M.</given-names></name>
<name><surname>Wajcman</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <source>Handbook of science and technology studies</source> (<edition>3rd ed.</edition>, pp. <fpage>13</fpage>-<lpage>32</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr42-0270467612459924">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sparrow</surname><given-names>R.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Defending deaf culture: The case of cochlear implants</article-title>. <source>Journal of Political Philosophy</source>, <volume>13</volume>, <fpage>135</fpage>-<lpage>152</lpage>.</citation>
</ref>
<ref id="bibr43-0270467612459924">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Vanderbilt</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <source>Dude, where’s your car? How not having a car became Hollywood shorthand for loser</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.slate.com/id/2262214/?from=rss">www.slate.com/id/2262214/?from=rss</ext-link></citation>
</ref>
<ref id="bibr44-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volti</surname><given-names>R.</given-names></name>
</person-group> (<year>2001</year>). <source>Society and technological change</source> (<edition>4th ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Worth</publisher-name>.</citation>
</ref>
<ref id="bibr45-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Winner</surname><given-names>L.</given-names></name>
</person-group> (<year>1977</year>). <source>Autonomous technology: Technics-out-of-control as a theme in political thought</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr46-0270467612459924">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wyatt</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Technological determinism is dead: Long live technological determinism</article-title>. In <person-group person-group-type="editor">
<name><surname>Hackett</surname><given-names>E. J.</given-names></name>
<name><surname>Amsterdamska</surname><given-names>O.</given-names></name>
<name><surname>Lynch</surname><given-names>M.</given-names></name>
<name><surname>Wajcman</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <source>Handbook of science and technology studies</source> (<edition>3rd ed.</edition>, pp. <fpage>165</fpage>-<lpage>189</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
</ref-list>
<ref-list>
<title>Cases</title>
<ref id="bibr47-0270467612459924">
<citation citation-type="other">B(R) v. Children’s Aid Society of Metropolitan Toronto [<year>1995</year>] 1 SCR 315.</citation>
</ref>
<ref id="bibr48-0270467612459924">
<citation citation-type="other">Calgary (City) v. Thomas (<year>1995</year>) 173 AR 51 (Prov Ct).</citation>
</ref>
<ref id="bibr49-0270467612459924">
<citation citation-type="other">Dobbs v. Mayer Estate (<year>1985</year>) 32 CCLT 191 (Ont Dist Ct).</citation>
</ref>
<ref id="bibr50-0270467612459924">
<citation citation-type="other">Fiala v. Cechmankek (<year>2001</year>) 201 DLR (4th) 680 (Alta CA).</citation>
</ref>
<ref id="bibr51-0270467612459924">
<citation citation-type="other">Gordon v. Wallace (<year>1973</year>) 42 DLR (3d) 342 (Ont HC).</citation>
</ref>
<ref id="bibr52-0270467612459924">
<citation citation-type="other">Hobbs v. Robertson [<year>2006</year>] BCJ No 266 (BCCA).</citation>
</ref>
<ref id="bibr53-0270467612459924">
<citation citation-type="other">Hoffman v. Monsanto [<year>2005</year>] 264 Sask R 1 (Sask QB), aff’d [2007] 293 Sask R 89 (Sask CA).</citation>
</ref>
<ref id="bibr54-0270467612459924">
<citation citation-type="other">Janiak v. Ippolito [<year>1985</year>] SCJ No 5.</citation>
</ref>
<ref id="bibr55-0270467612459924">
<citation citation-type="other">McLean v. Seisel [<year>2002</year>] OJ No 2195 (Ont SCJ), [2004] OJ No 185 (Ont CA).</citation>
</ref>
<ref id="bibr56-0270467612459924">
<citation citation-type="other">Reibl v. Hughes [<year>1980</year>] 2 SCR 880.</citation>
</ref>
<ref id="bibr57-0270467612459924">
<citation citation-type="other">Stuyvesant Associates v. Doe, 534 A2d 448 (Sup Ct New Jersey, <year>1987</year>).</citation>
</ref>
<ref id="bibr58-0270467612459924">
<citation citation-type="other">Swift v. Fitchburg Mutual Insurance Co, 700 NE2d 288 (App Ct Mass, <year>1998</year>).</citation>
</ref>
<ref id="bibr59-0270467612459924">
<citation citation-type="other">Telfer v. Wright (<year>1978</year>) 23 OR (2d) 117 (Ont CA).</citation>
</ref>
</ref-list>
</back>
</article>