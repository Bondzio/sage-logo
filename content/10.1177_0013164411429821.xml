<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPM</journal-id>
<journal-id journal-id-type="hwp">spepm</journal-id>
<journal-title>Educational and Psychological Measurement</journal-title>
<issn pub-type="ppub">0013-1644</issn>
<issn pub-type="epub">1552-3888</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0013164411429821</article-id>
<article-id pub-id-type="publisher-id">10.1177_0013164411429821</article-id>
<title-group>
<article-title>Impact of Outliers Arising From Unintended and Unknowingly Included Subpopulations on the Decisions About the Number of Factors in Exploratory Factor Analysis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Liu</surname><given-names>Yan</given-names></name>
<xref ref-type="aff" rid="aff1-0013164411429821">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Zumbo</surname><given-names>Bruno D.</given-names></name>
<xref ref-type="aff" rid="aff1-0013164411429821">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0013164411429821"><label>1</label>University of British Columbia, Vancouver, British Columbia, Canada</aff>
<author-notes>
<corresp id="corresp1-0013164411429821">Bruno D. Zumbo, The University of British Columbia, Scarfe Building, 2125 Main Mall, Department of ECPS, Vancouver, British Columbia, Canada V6T 1Z4 Email: <email>bruno.zumbo@ubc.ca</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>6</month>
<year>2012</year>
</pub-date>
<volume>72</volume>
<issue>3</issue>
<fpage>388</fpage>
<lpage>414</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>There is a lack of research on the effects of outliers on the decisions about the number of factors to retain in an exploratory factor analysis, especially for outliers arising from unintended and unknowingly included subpopulations. The purpose of the present research was to investigate how outliers from an unintended and unknowingly included subpopulation affected the decisions about the number of factors to retain using four commonly used methods separately. The results showed that all the decision methods could provide biased results and the number of factors could be inflated, deflated, or remain the same depending on the decision methods used and outlier conditions. The findings also revealed that symmetric outliers did not affect the three principal component analysis–based methods but affected chi-square (ML) sequential tests. Finally, sample size did not play a role in the effect of outliers.</p>
</abstract>
<kwd-group>
<kwd>exploratory factor analysis</kwd>
<kwd>number of factors</kwd>
<kwd>outliers</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Exploratory factor analysis (EFA) is a widely used statistical technique in the psychosocial, behavioral, and health sciences. However, the matter of the impact of outliers on the decisions about the number of factors to retain is largely undocumented in the psychometric and methodological literature. Recently, <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu, Zumbo, and Wu (in press)</xref> demonstrated the impact of outliers on the decision about the number of factors. Their study focused on outliers that are errors in the data—that is, <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo’s (2007)</xref> first category of outlier sources. Liu and colleagues found that this type of outliers inflated, deflated, or had no effect on the number of factors retained, depending on the extent of outlier contamination and which decision method (e.g., parallel analysis, Kaiser–Guttman’s eigenvalues-greater-than-one, minimum average partial, or sequential chi-square tests) was used.</p>
<p>The purpose of the present article is to continue this line of research and investigate <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo’s (2007)</xref> second and third categories of outliers using a probabilistic mixture of distributions. With this purpose in mind, we first discuss the connection between the various sources of outliers and the models used for simulating them in psychometric studies. Next, two studies are reported. The first study demonstrates the impact of these types of outliers on the decision about the number of factors to retain. The second study is a follow-up to the first study, including a focused simulation study of a small correlation matrix and a report on the skewness and kurtosis of variables that were simulated using the same simulation design as in Study 1. The second study provides insight into how the outliers altered the properties of the correlation matrix. Readers interested in a review of the literature as well as a discussion of the need to study outliers in terms of deciding on the number of factors to retain should see <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>.</p>
<sec id="section1-0013164411429821">
<title>Various Sources of Outliers and the Models Used in Simulation Studies</title>
<p>As <xref ref-type="bibr" rid="bibr34-0013164411429821">Zumbo and Zimmerman (1993)</xref> state, computer simulation (including Monte Carlo simulation) is an empirical method of experimental mathematics that is loosely defined as the mimicking of the rules of a model (in our case, a psychological or psychometric phenomenon) via random processes. The key concept in this definition is the correspondence of the psychometric or psychological process to how it is being mimicked in the simulation. For example, in the case of the study of outliers, it is important that the simulation method matches the source of outliers being considered. Below, we briefly review a taxonomy of sources of outliers and then address the simulation methods that can be used to mimic these outliers.</p>
</sec>
<sec id="section2-0013164411429821">
<title>Sources of Outlier Contamination</title>
<p>In terms of psychometric analysis, <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo (2007)</xref> described three categories of possible sources of outliers in item responses—that is, a univariate distribution of item responses. As noted above, the first category usually refers to “errors” in the data, instantiations of which include errors that occur during data collection, data recording, or data entry. The outliers generated from such sources are obviously illegitimate observations and should, when found, be corrected. This first category of outliers arise from mistakes and are hence specific to a particular data set, so that they are a property of a sample but not of a population. For example, typically it does not make sense to talk about the number of typographical data entry errors in a population; however, it does make sense to talk about the number of such typos in a sample. Because of this characteristic, this type of outliers distinguishes itself from the other two categories of outliers in terms of the outlier generation models used in methodological and simulation studies—that is, deterministic or slippage simulation models.</p>
<p>The second category of outliers refers to the unpredictable measurement-related errors from participants, including guessing and inattentiveness during item responding, which may be caused by fatigue or participants’ lack of interest in participation. Another example of this category includes item misresponding, which happens when, for example, participants misunderstand the instructions or the descriptors on the response scale (e.g., <xref ref-type="bibr" rid="bibr3-0013164411429821">Barnette, 1999</xref>). Unlike the first category, which are clearly errors and sample specific, depending on the particular psychological processes in item responding, the second category of outliers may be considered either (sample specific) errors or characteristics and propensities of respondents and hence a population characteristic. For example, misunderstanding the item response instructions may be due to something that reflects momentary inattention or an inherent inattentiveness by the respondent. The former is a sample specific error (and hence akin to an error of the kind in the first category), whereas the latter is, by definition, a characteristic of respondents and hence may reflect a subgroup of inattentive respondents in the population of possible item respondents.</p>
<p><xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo’s (2007)</xref> third category of outliers occurs when researchers unknowingly recruit some individuals who are not members of the target population, resulting in a subpopulation for whom the measure operates differently than for the target population. Liu and Zumbo described an example of this in the context of self-concept research conducted with a student population wherein some study participants are from Asian countries for which self-concept may be a different construct. There are many examples of this sort of problem as evidenced by the growing number of articles on construct comparability and test adaptation (e.g., <xref ref-type="bibr" rid="bibr14-0013164411429821">Hambleton, Merenda, &amp; Spielberger, 2005</xref>).</p>
<p>Outliers from the third category as well as the second category (when they are a characteristic of respondents) reflect an unintended and unknowingly included (henceforth referred to as “unintended”) subgroup in one’s target population, which are usually simulated via probability models. Although they represent different psychological phenomena, these outliers behave the same mathematically and hence can be simulated by the same outlier generation models.</p>
</sec>
<sec id="section3-0013164411429821">
<title>Models Used in Simulation Studies</title>
<p>In the statistical literature, one sees reference to three common models for simulating outliers: deterministic, slippage, and mixture models. Deterministic and slippage models are typically used for the first category and for sample-specific errors in the second category, whereas mixture models are typically used for the second category of outliers that are a characteristic of respondents (and, hence, a population characteristic) and for the third category of outliers. Whether it is the second and third categories, the mixture model is used to mimic unintended subpopulations. It should be noted, however, that the slippage model can, in particular instances, also be used to model unintended subpopulations except that the number of outliers, in this case, would be fixed from replication to replication.</p>
<sec id="section4-0013164411429821">
<title>Deterministic model</title>
<p>The first category of outliers, errors in the data, has been simulated using a deterministic model (<xref ref-type="bibr" rid="bibr5-0013164411429821">Barnett &amp; Lewis, 1994</xref>). Because this type of outliers is sample specific, the number of outliers is fixed for a sample and rejection of the null hypothesis of no outliers is deterministically correct, as these outliers are obviously different from the majority of observations (<xref ref-type="bibr" rid="bibr5-0013164411429821">Barnett &amp; Lewis, 1994</xref>). One way to simulate outliers using a deterministic model is simply to alter the original data, by either multiplying or adding a constant to raw scores. Examples of this type abound in the literature and include EFA studies by <xref ref-type="bibr" rid="bibr32-0013164411429821">Yuan, Marshall, and Bentler (2002)</xref> and Study 1 of <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>. In both examples, outliers were created by multiplying raw scores of one or more variables by a constant (2, 3, 4, or 5) for a certain proportion of subjects in a sample.</p>
</sec>
<sec id="section5-0013164411429821">
<title>Slippage model</title>
<p>Another common strategy of simulating outliers as errors in the data (i.e., the first category of outliers) is the slippage model. Like the deterministic model, the number of outliers in a sample is fixed from replication to replication in a simulation study; however, with the slippage model, these outliers arise from some probability distribution.</p>
<p>The slippage model has been widely discussed and used in the literature (e.g., <xref ref-type="bibr" rid="bibr1-0013164411429821">Anscombe, 1960</xref>; <xref ref-type="bibr" rid="bibr4-0013164411429821">Barnett &amp; Lewis, 1978</xref>; <xref ref-type="bibr" rid="bibr10-0013164411429821">Dixon, 1950</xref>; <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al., in press</xref>). In its general form, the null model (without outliers) is</p>
<p>
<disp-formula id="disp-formula1-0013164411429821">
<mml:math display="block" id="math1-0013164411429821">
<mml:mrow>
<mml:mi>H</mml:mi>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>F</mml:mi>
<mml:mspace width="1.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mspace width="0.5em"/>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0013164411429821" xlink:href="10.1177_0013164411429821-eq1.tif"/>
</disp-formula>
</p>
<p>The alternative model is</p>
<p>
<disp-formula id="disp-formula2-0013164411429821">
<mml:math display="block" id="math2-0013164411429821">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>H</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>F</mml:mi>
<mml:mspace width="1.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mspace width="1.5em"/>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>p</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>G</mml:mi>
<mml:mspace width="1.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mspace width="1.5em"/>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0013164411429821" xlink:href="10.1177_0013164411429821-eq2.tif"/>
</disp-formula>
</p>
<p>where <italic>I + P = n; F</italic> denotes an target distribution (sometimes called parent distribution); <italic>G</italic> denotes a contamination distribution with a different mean and/or variance; <italic>n</italic> denotes the total number of observations in a sample; <italic>I</italic> is the number of observations from a target distribution; and <italic>P</italic> is the number of observations from a contamination distribution. In the null model, all observations are assumed to come from the same population distribution. In the alternative model, a small number of observations are assumed to come from a contamination distribution, and the total number of observations in a sample is the sum of observations from a target distribution and from a contamination distribution (<xref ref-type="bibr" rid="bibr2-0013164411429821">Balakrishnan &amp; Childs, 2001</xref>).</p>
</sec>
<sec id="section6-0013164411429821">
<title>Mixture of distributions</title>
<p>One can think of this model intuitively as mixing two different population distributions together. A psychological example may help make this concrete: people from Denmark typically rate their life satisfaction as much higher than people from Hungary (<xref ref-type="bibr" rid="bibr24-0013164411429821">Organization for Economic Co-operation and Development, 2005</xref>). If we targeted people in Denmark for an investigation, but unknowingly also recruited a small group of people who just immigrated to Denmark from Hungary, the observations recruited are from a mixture of two populations and responses from Hungarian people might appear as outliers. To mimic this kind of outliers, one would use a <italic>mixture of distributions</italic>,<sup><xref ref-type="fn" rid="fn1-0013164411429821">1</xref></sup> which has been widely used in the research literature and also is used in the present research.</p>
<p>A mixture of two distributions is a general model, comprising two weighted probability distributions with positive weights that sum up to one (<xref ref-type="bibr" rid="bibr7-0013164411429821">Blischke, 1978</xref>). As the weights represent a probability distribution, the mixture is also a probability distribution. The two distributions thus mixed, depending on the parameter values for the mixing, represent different populations. These components of a mixture of distributions can be normal distributions or nonnormal distributions (e.g., Poisson, negative binomial distributions). In the statistical and psychometric research literatures, a mixture of two normal distributions has been frequently used for simulating outliers. One of the most well known and widely used mathematical models is the mixture contamination model—also referred to as the mixed normal distribution, which was introduced by <xref ref-type="bibr" rid="bibr27-0013164411429821">Tukey (1962)</xref> and later extended by <xref ref-type="bibr" rid="bibr18-0013164411429821">Huber (1964)</xref>, <xref ref-type="bibr" rid="bibr23-0013164411429821">Mosteller and Tukey (1968)</xref>, and <xref ref-type="bibr" rid="bibr5-0013164411429821">Barnett and Lewis (1994)</xref>. This mixture contamination model is the one used herein. It is generated by including two normal distributions, a target distribution with mean µ and standard deviation σ, <italic>N</italic>(µ, σ), denoted by <italic>F</italic>, and a contamination distribution with some values of mean and/or standard deviation different from <italic>F</italic>, denoted by <italic>G</italic>.</p>
<p>Given a sample of <italic>n</italic> independent observations, <italic>X<sub>i</sub></italic> (<italic>i</italic> = 1, 2, . . . , <italic>n</italic>), the majority of the data points follow the target distribution <italic>F</italic> and the proportion of the sample is denoted by 1 − <italic>p</italic>, whereas a small fraction, <italic>p</italic>, follows the contamination distribution <italic>G</italic>. The mixed contamination model is a mixture of <italic>F</italic> and <italic>G</italic>. The null model is</p>
<p>
<disp-formula id="disp-formula3-0013164411429821">
<mml:math display="block" id="math3-0013164411429821">
<mml:mrow>
<mml:mi>H</mml:mi>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>F</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0013164411429821" xlink:href="10.1177_0013164411429821-eq3.tif"/>
</disp-formula>
</p>
<p>The alternative model is</p>
<p>
<disp-formula id="disp-formula4-0013164411429821">
<mml:math display="block" id="math4-0013164411429821">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>H</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>*</mml:mo>
<mml:mi>F</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo>*</mml:mo>
<mml:mi>G</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mspace width="1.5em"/>
<mml:mn>0</mml:mn>
<mml:mo>&lt;</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo>&lt;</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>/</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0013164411429821" xlink:href="10.1177_0013164411429821-eq4.tif"/>
</disp-formula>
</p>
<p>where the amount of contamination/outliers <italic>p</italic> must be less than one half, and often substantially less, which indicates the probability that an observation arises from a contamination distribution <italic>G</italic>. If the amount of outliers is as large as near half, any outlier treatment methods, such as robust methods, are not legitimate to apply to these outliers in practice and the outliers should be modeled as another population. It is important to note that, in a simulation study with, for example, 100 replications, the proportion of the sample from the <italic>G</italic> distribution is itself a random variable whose average over the 100 replications (i.e., the expected value) is the proportion <italic>p</italic>—that is, the proportion of outliers varies from sample to sample, however, on average it will be <italic>p</italic>. In the results section, the varying proportion of outliers from sample to sample was shown in the description of our simulation method (<xref ref-type="table" rid="table1-0013164411429821">Table 1</xref>).</p>
<table-wrap id="table1-0013164411429821" position="float">
<label>Table 1.</label>
<caption>
<p>Documenting Simulations Using Mixture of Distributions: Proportion of Outliers in Each Sample Across 100 Replications</p>
</caption>
<graphic alternate-form-of="table1-0013164411429821" xlink:href="10.1177_0013164411429821-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Pc</th>
<th align="center"><italic>n</italic></th>
<th align="center">Mean</th>
<th align="center"><italic>SD</italic></th>
<th align="center">Minimum</th>
<th align="center">1st Quartile</th>
<th align="center">Median</th>
<th align="center">3rd Quartile</th>
<th align="center">Maximum</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.010</td>
<td>1,000</td>
<td>0.010</td>
<td>0.003</td>
<td>0.003</td>
<td>0.008</td>
<td>0.010</td>
<td>0.012</td>
<td>0.018</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.010</td>
<td>0.004</td>
<td>0.000</td>
<td>0.008</td>
<td>0.010</td>
<td>0.012</td>
<td>0.022</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>0.010</td>
<td>0.007</td>
<td>0.000</td>
<td>0.004</td>
<td>0.008</td>
<td>0.012</td>
<td>0.028</td>
</tr>
<tr>
<td>0.080</td>
<td>1,000</td>
<td>0.080</td>
<td>0.010</td>
<td>0.060</td>
<td>0.073</td>
<td>0.080</td>
<td>0.088</td>
<td>0.106</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.080</td>
<td>0.011</td>
<td>0.054</td>
<td>0.072</td>
<td>0.082</td>
<td>0.088</td>
<td>0.106</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>0.080</td>
<td>0.019</td>
<td>0.040</td>
<td>0.068</td>
<td>0.076</td>
<td>0.088</td>
<td>0.128</td>
</tr>
<tr>
<td>0.150</td>
<td>1,000</td>
<td>0.150</td>
<td>0.010</td>
<td>0.121</td>
<td>0.143</td>
<td>0.150</td>
<td>0.156</td>
<td>0.178</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>0.150</td>
<td>0.015</td>
<td>0.108</td>
<td>0.140</td>
<td>0.149</td>
<td>0.162</td>
<td>0.184</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>0.150</td>
<td>0.023</td>
<td>0.104</td>
<td>0.132</td>
<td>0.150</td>
<td>0.168</td>
<td>0.200</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0013164411429821">
<p><italic>Note</italic>. Pc = proportion of contamination in the population; <italic>n</italic> = sample size; <italic>SD</italic> = standard deviation.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Slippage models and the mixture contamination model share some similarities, but have some fundamental differences. <xref ref-type="bibr" rid="bibr5-0013164411429821">Barnett and Lewis (1994)</xref> pointed out that the number of outliers is fixed in a slippage model and outliers are regarded as fixed contamination, whereas the number of outliers is a random variable in a mixture contamination model and hence outliers are regarded as random contamination. It should be noted that it is not appropriate to use a mixture of distributions model to simulate outliers from <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo’s (2007)</xref> first category, but is more appropriate to simulate outliers from their second and third categories. As the first category of outliers is obvious (typographical) errors and sample specific, the randomness of mixture of distributions models does not fit into the fixed property of outliers from the first category. However, slippage models can be used for this kind of outliers because the number of outliers is fixed in each sample.</p>
<p>There are two contamination conditions: symmetric and asymmetric contamination. The contamination is symmetric if the population is a mixture of <italic>N</italic>(µ, σ) and <italic>N</italic>(µ, <italic>b</italic>σ), where <italic>b</italic> is a positive constant greater than one and hence can generate a contamination distribution with a larger standard deviation (<italic>SD</italic>) than the parent distribution, which is called <italic>SD</italic> shift in this article. It is worth noting that if <italic>b</italic> is less than one, the condition of inliers should be considered instead of outliers, which is not of interest of the present study. The contamination is asymmetric when the population is a mixture of <italic>N</italic>(µ, σ) and <italic>N</italic>(µ + <italic>a</italic>σ) or <italic>N</italic>(µ, σ) and <italic>N</italic>(µ + <italic>a, b</italic>σ), where <italic>a</italic> is a constant and <italic>a</italic> ≠ 0. The mean and <italic>SD</italic> of <italic>F</italic> are usually defined as 0 and 1, respectively, that is, <italic>N</italic>(0, 1), so adding or subtracting any value to zero will result in the mean shift of a contamination distribution from the center of the population distribution and hence lead to the asymmetric contamination. Therefore, a variety of contamination conditions can be generated by increasing the three outlier factors, that is, the proportion of contamination, mean shift, and <italic>SD</italic> shift of the contamination distribution.</p>
<p>An example of outliers in a mixed contamination model is given in <xref ref-type="fig" rid="fig1-0013164411429821">Figure 1</xref>. <xref ref-type="fig" rid="fig1-0013164411429821">Figure 1A</xref> is a normal distribution, <italic>N</italic>(µ = 0, σ = 1). <xref ref-type="fig" rid="fig1-0013164411429821">Figure 1B</xref> presents a case of symmetric outliers with 15% of outliers, consisting of a parent distribution <italic>N</italic>(µ = 0, σ = 1) and a contamination distribution <italic>N</italic>(µ =0, σ = 3). Outliers are shown as long and heavy tails at each side of the distribution and result in a highly leptokurtic (peaked) distribution. <xref ref-type="fig" rid="fig1-0013164411429821">Figure 1C</xref> demonstrates a case of asymmetric outliers with 15% of outliers, consisting of a parent distribution <italic>N</italic>(µ = 0, σ = 1) and a contamination distribution <italic>N</italic>(µ = 3, σ = 1). Outliers are shown as a heavy tail on one side of the distribution. <xref ref-type="fig" rid="fig1-0013164411429821">Figure 1D</xref> shows another case of asymmetric outliers with a parent distribution <italic>N</italic>(µ = 0, σ = 1) and a contamination distribution <italic>N</italic>(µ = 3, σ = 3). Outliers make the distribution have a heavy tail on one side as well as a high peak.</p>
<fig id="fig1-0013164411429821" position="float">
<label>Figure 1.</label>
<caption>
<p>An example of symmetric and asymmetric outliers (proportion of contamination = 0.15)</p>
</caption>
<graphic xlink:href="10.1177_0013164411429821-fig1.tif"/>
</fig>
<p>Building on the findings of <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, the purpose of the present research was to investigate how outliers, arising from an unintended and unknowingly recruited subpopulation (Liu and Zumbo’s second and third categories of outliers), affected the decisions about the number of factors to retain using four commonly used methods, and the most commonly used variants thereof, that is, parallel analysis (PA, using the PCA model and the 95th percentile of the 100 random data sets), Kaiser–Guttman’s (K-G) eigenvalues-greater-than-one, minimum average partial (MAP, see <xref ref-type="bibr" rid="bibr28-0013164411429821">Velicer, 1976</xref>, for a detailed description of the procedure used herein), or sequential chi-square tests based on maximum likelihood estimation (<inline-formula id="inline-formula1-0013164411429821">
<mml:math display="inline" id="math5-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>). The results of a Monte Carlo simulation study were reported first, in which the outlier conditions were manipulated using five factors (i.e., mean shift, <italic>SD</italic> shift, proportions of contamination of subjects, number of variables with outliers, and sample size). A follow-up study was also presented to provide insight into potential causes of our findings.</p>
</sec>
</sec>
<sec id="section7-0013164411429821">
<title>Study 1: Investigating the Effects of Outliers Generated Using the Mixture Contamination Model</title>
<sec id="section8-0013164411429821">
<title>Method</title>
<sec id="section9-0013164411429821">
<title>Study design</title>
<p>A Monte Carlo simulation study was used to investigate the effects of outliers on decisions about the number of factors by the four decision methods. This study systematically varied five factors with 100 replications for each outlier condition (i.e., simulation condition). These five factors are as follows:</p>
<list id="list1-0013164411429821" list-type="order">
<list-item><p>Mean shift of a contamination distribution (0, 1.5, 3)</p></list-item>
<list-item><p><italic>SD</italic> shift of a contamination distribution (1, 1.5, 3)</p></list-item>
<list-item><p>Proportion of contamination (i.e., proportion of the subjects from the contamination distribution; .01, .08, .15)</p></list-item>
<list-item><p>Sample size (250, 500, 1,000)</p></list-item>
<list-item><p>Number of variables with outliers (1, 6, 12, 24)</p></list-item>
</list>
<p>The study design is therefore a 3 × 3 × 3 × 3 × 4 completely crossed factorial design with 324 conditions, which also includes the no-outlier conditions (i.e., the comparison condition) that has mean shift of zero and <italic>SD</italic> shift of one.</p>
<p>To ensure a systematic investigation of outlier effects, the selection of the magnitude of three factors (mean shift, <italic>SD</italic> shift, and proportion of contamination), which are the parameters of a typical mixture contamination model, were guided by previous studies, <xref ref-type="bibr" rid="bibr6-0013164411429821">Blair and Higgins (1980)</xref>, <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo (2007)</xref>, <xref ref-type="bibr" rid="bibr23-0013164411429821">Mosteller and Tukey (1968)</xref>, and <xref ref-type="bibr" rid="bibr33-0013164411429821">Zumbo and Jennings (2002)</xref>. Following these studies, the present study adopted similar values of model parameters with some modifications to fit the purpose of the present study. The number of variables with outliers was also included in the present study as it was demonstrated to be an influential factor in determining the number of factors in Liu et al.’s (in press) study. In addition, sample size was found in the literature to affect the performance of the K-G rule as well as chi-square tests (e.g., <xref ref-type="bibr" rid="bibr13-0013164411429821">Gorsuch, 1983</xref>; <xref ref-type="bibr" rid="bibr17-0013164411429821">Hubbard &amp; Allen, 1987</xref>; <xref ref-type="bibr" rid="bibr35-0013164411429821">Zwick &amp; Velicer, 1986</xref>). Hence, we included samples size as a factor in the present study.</p>
</sec>
<sec id="section10-0013164411429821">
<title>Data generation</title>
<p>In line with the earlier work by <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo (2007)</xref>, <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, and the psychometric context of our study, the outliers are induced in the item responses, that is, the marginal distributions. Twenty-four continuous variables were simulated and therefore our findings apply equally to analyses of subscale scores or visual analogue item response data (<xref ref-type="bibr" rid="bibr21-0013164411429821">Liu &amp; Zumbo, 2007</xref>).</p>
<p>For the mixture contamination model in <xref ref-type="disp-formula" rid="disp-formula1-0013164411429821">Equation (1)</xref>, both the target and contamination data were generated based on the population correlation matrix from <xref ref-type="bibr" rid="bibr16-0013164411429821">Holzinger and Swineford’s (1939)</xref> classic data set. The original data set consists of 24 psychological ability test scores from 301 junior high school students with a four-factor solution recommended by many researchers (e.g., <xref ref-type="bibr" rid="bibr13-0013164411429821">Gorsuch, 1983</xref>; <xref ref-type="bibr" rid="bibr15-0013164411429821">Harman, 1976</xref>; <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al., in press</xref>). As in Liu et al.’s studies, a four-factor solution based on maximum likelihood EFA was obtained using Holzinger and Swineford’s data. To give the reader a sense of the factorial solution that generated the implied correlation matrix, using maximum likelihood EFA along with PROMAX rotation, the average interfactor correlation was .46 and ranged from .40 to .55. In addition, the structure coefficients (i.e., the factor loadings) demonstrate some complexity (i.e., not precisely simple structure); however, every factor had at least eight loadings greater than .40, and the interpretation of the factors is in line with <xref ref-type="bibr" rid="bibr13-0013164411429821">Gorsuch (1983)</xref>. The resulting reproduced correlation matrix (i.e., the implied correlation matrix with “1s” on the diagonal rather than the reproduced communalities) was used as the population correlation matrix in the simulation to generate multivariate normal data sets with specified marginal means and <italic>SD</italic>s, depending on the experimental condition, that correspond to the target or contamination distribution in <xref ref-type="disp-formula" rid="disp-formula1-0013164411429821">Equation (1)</xref>. Multivariate normal data were generated in software R 2.12.1, using a method akin to the <xref ref-type="bibr" rid="bibr20-0013164411429821">Kaiser and Dickman (1962)</xref> method wherein we used Cholesky decomposition rather than principal components analysis in the computation. Generating data from a model with a known (prespecified) number of factors allowed us to compare the number of factors obtained from different outlier conditions to a common criterion in the population: four factors.</p>
</sec>
<sec id="section11-0013164411429821">
<title>Outcome variable</title>
<p>In each of the 324 experimental conditions, and for each of the 100 replications, the number of factors to retain for the EFA was determined, separately, by the K-G rule, PA, MAP, and sequential <inline-formula id="inline-formula2-0013164411429821">
<mml:math display="inline" id="math6-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests. The number of factors retained is the dependent variable for each of these four methods, respectively, in this simulation study. It should be noted that, as in Liu et al.’s (in press) Study 2, for each outlier design condition, an average of the number of factors over 100 replications was obtained and hence the number of factors reported might not be a whole number.</p>
</sec>
<sec id="section12-0013164411429821">
<title>Analysis of the simulation results</title>
<p>Following the data analysis strategy used in <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo (2007)</xref> and <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, five-way ANOVAs (3 × 3 × 3 × 3 × 4) were conducted with the number of factors retained as the dependent variable separately for each of the four decision methods, that is, the K-G rule, PA, MAP, and <inline-formula id="inline-formula3-0013164411429821">
<mml:math display="inline" id="math7-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> sequential test. Given the large sample size (32,400—i.e., 324 cells in the design with 100 replications per cell), we used eta-square (η<sup>2</sup>) to orthogonally partition the explained variance obtained from the fixed-effect ANOVA models instead of looking at the statistical significance. An experiment with a sample size of 100 per cell (with an overall sample size of 32,400) results in a statistical power for main effects and interactions approaching one; hence, statistical significance was not useful in interpreting the results because even trivial effects would be statistically significant with that much power. Instead, the proportion of explained variance was used to aid our interpretation of the simulation results, which is like <italic>R</italic><sup>2</sup> in regression analysis. In line with <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, we used <xref ref-type="bibr" rid="bibr11-0013164411429821">Ferguson’s (2009)</xref> minimum effect size of η<sup>2</sup> of .04 as the criterion to judge the importance of the main effects and interactions. In addition, if interactions appeared in the model, only higher order interactions were interpreted because main effects and lower order interactions are not interpretable in the presence of higher order interactions.</p>
<p>The sequential <inline-formula id="inline-formula4-0013164411429821">
<mml:math display="inline" id="math8-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test can result in no decision about the number of factors to retain because of nonconvergence. Therefore, the nonconvergence problem can result in unbalanced data for the ANOVA, which can, in turn, distort the orthogonal partition of variance in the outcome variable. Please see our discussion of our findings in <xref ref-type="table" rid="table6-0013164411429821">Table 6</xref>, below, for the details about the small amount of unbalance in the sample sizes, and where it was found to be present in the design. We therefore adopted the Type III sum-of-squares method in SPSS, an often-used method for handling unbalanced data with no missing cells (<xref ref-type="bibr" rid="bibr26-0013164411429821">SPSS Inc., 2009</xref>), for the data analysis of the simulation results.</p>
</sec>
</sec>
<sec id="section13-0013164411429821">
<title>Results</title>
<sec id="section14-0013164411429821">
<title>Proportion of outliers in a given sample</title>
<p>As noted earlier, when using the mixture contamination model to simulate outliers, the proportion of outliers in a sample can vary across replications—that is, from sample to sample. To our knowledge, the central tendency and variability in sample-to-sample proportions of outliers has not been documented in simulation studies. To better understand these statistics, we recorded the proportion of outliers across 100 replications for a single variable.</p>
<p><xref ref-type="table" rid="table1-0013164411429821">Table 1</xref> lists the central tendency (mean, median) and variability (<italic>SD</italic>, quartiles, minimum and maximum values) for the proportion of outliers for the various conditions in the current simulation study across the 100 replications. Starting from the far left in <xref ref-type="table" rid="table1-0013164411429821">Table 1</xref>, one can find the population value of the proportion of contamination, the sample size, and then the seven descriptive statistics computed across the 100 replications. One can see that, as expected, the mean is equal to the population value of contamination in every case. However, also as expected, there is variability in the proportion of contamination across the samples, which depends on the sample size and the population proportion of contamination.</p>
</sec>
<sec id="section15-0013164411429821">
<title>Results of the simulation study</title>
<p><xref ref-type="table" rid="table2-0013164411429821">Tables 2</xref> to <xref ref-type="table" rid="table5-0013164411429821">5</xref> present the results for the four decision methods (K-G, MAP, PA, and sequential <inline-formula id="inline-formula5-0013164411429821">
<mml:math display="inline" id="math9-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests), respectively. <xref ref-type="fig" rid="fig2-0013164411429821">Figures 2</xref> to <xref ref-type="fig" rid="fig5-0013164411429821">5</xref> show the corresponding highest order interactions for these four methods identified as important factors using η<sup>2</sup>. For the K-G, MAP, and PA methods, the highest order interaction meeting our criterion was the same: <italic>mean shift</italic> by <italic>the number of variables having outliers</italic> by <italic>the proportion of contamination</italic>. Hence, we only interpreted this three-way interaction for the K-G, MAP, and PA methods and not any of the lower order interactions and main effects.</p>
<fig id="fig2-0013164411429821" position="float">
<label>Figure 2.</label>
<caption>
<p>Graphs for three-way interactions of variables with outliers versus proportion of contamination by three levels of mean shift on the number of factors extracted by the K-G rule</p>
</caption>
<graphic xlink:href="10.1177_0013164411429821-fig2.tif"/>
</fig>
<fig id="fig3-0013164411429821" position="float">
<label>Figure 3.</label>
<caption>
<p>Graphs for three-way interactions of variables with outliers versus proportion of contamination by three levels of mean shift on the number of factors extracted by MAP approach</p>
</caption>
<graphic xlink:href="10.1177_0013164411429821-fig3.tif"/>
</fig>
<fig id="fig4-0013164411429821" position="float">
<label>Figure 4.</label>
<caption>
<p>Three-way interactions of variables with outliers versus proportion of contamination by three levels of mean shift on the number of factors extracted by PA approach</p>
</caption>
<graphic xlink:href="10.1177_0013164411429821-fig4.tif"/>
</fig>
<fig id="fig5-0013164411429821" position="float">
<label>Figure 5.</label>
<caption>
<p>Three-way interactions of variables with outliers versus proportion of contamination by three levels of standard deviation shift on the number of factors decided by the sequential <inline-formula id="inline-formula6-0013164411429821">
<mml:math display="inline" id="math10-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test</p>
</caption>
<graphic xlink:href="10.1177_0013164411429821-fig5.tif"/>
</fig>
<p><xref ref-type="table" rid="table2-0013164411429821">Table 2</xref> presents the results of the variance decomposition for the K-G rule, and <xref ref-type="fig" rid="fig2-0013164411429821">Figure 2</xref> shows the corresponding plot of the three-way interaction. With a mean shift of zero (i.e., symmetric outliers), the number of factors was not affected by outliers, which was also the case for the MAP and PA methods. With mean shift of 1.5 and 3 (i.e., asymmetric outliers), the change in the number of factors depended on the number of variables having outliers and the proportion of contamination. When mean shift was 1.5, the number of factors was not affected when one variable and all variables (24) had outliers, but was inflated (from 4 up to 5 factors) when 6 and 12 variables had outliers. With a mean shift of 3, the number of factors was not affected when only one variable had outliers, was inflated (from 4 up to 5 factors) when 6 and 12 variables had outliers, but deflated when all 24 variables had outliers (from 4 to an average of 2.7 factors). There was more deflation with an increase in the proportion of contamination.</p>
<table-wrap id="table2-0013164411429821" position="float">
<label>Table 2.</label>
<caption>
<p>Variable Ordering for a Five-Way ANOVA on the Number of Factors Extracted by the K-G Rule</p>
</caption>
<graphic alternate-form-of="table2-0013164411429821" xlink:href="10.1177_0013164411429821-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">Sum Squares</th>
<th align="center">Eta-Square</th>
<th align="center">Percentage of <italic>R</italic><sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr>
<td><bold>vars</bold> * <bold>mean</bold></td>
<td><bold>1929.155</bold></td>
<td><bold>0.197</bold></td>
<td><bold>25.953</bold></td>
</tr>
<tr>
<td><bold>Vars</bold></td>
<td><bold>1742.855</bold></td>
<td><bold>0.178</bold></td>
<td><bold>23.447</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold> * <bold>mean</bold></td>
<td><bold>930.368</bold></td>
<td><bold>0.095</bold></td>
<td><bold>12.516</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold></td>
<td><bold>887.323</bold></td>
<td><bold>0.090</bold></td>
<td><bold>11.937</bold></td>
</tr>
<tr>
<td>pc</td>
<td>242.723</td>
<td>0.025</td>
<td>3.265</td>
</tr>
<tr>
<td>pc * mean</td>
<td>238.286</td>
<td>0.024</td>
<td>3.206</td>
</tr>
<tr>
<td>vars * <italic>SD</italic></td>
<td>233.350</td>
<td>0.024</td>
<td>3.139</td>
</tr>
<tr>
<td><italic>N</italic></td>
<td>232.309</td>
<td>0.024</td>
<td>3.125</td>
</tr>
<tr>
<td><italic>SD</italic></td>
<td>169.119</td>
<td>0.017</td>
<td>2.275</td>
</tr>
<tr>
<td>Mean</td>
<td>165.230</td>
<td>0.017</td>
<td>2.223</td>
</tr>
<tr>
<td>pc * vars * mean * <italic>SD</italic></td>
<td>91.428</td>
<td>0.009</td>
<td>1.230</td>
</tr>
<tr>
<td>pc * vars * <italic>SD</italic></td>
<td>81.851</td>
<td>0.008</td>
<td>1.101</td>
</tr>
<tr>
<td>vars * mean * <italic>SD</italic></td>
<td>65.865</td>
<td>0.007</td>
<td>0.886</td>
</tr>
<tr>
<td><italic>n</italic> * <italic>SD</italic></td>
<td>56.401</td>
<td>0.006</td>
<td>0.759</td>
</tr>
<tr>
<td><italic>n</italic> * vars * <italic>SD</italic></td>
<td>44.155</td>
<td>0.005</td>
<td>0.594</td>
</tr>
<tr>
<td>pc * <italic>SD</italic></td>
<td>37.587</td>
<td>0.004</td>
<td>0.506</td>
</tr>
<tr>
<td>pc * mean * <italic>SD</italic></td>
<td>37.478</td>
<td>0.004</td>
<td>0.504</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean</td>
<td>37.212</td>
<td>0.004</td>
<td>0.501</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean * <italic>SD</italic></td>
<td>30.391</td>
<td>0.003</td>
<td>0.409</td>
</tr>
<tr>
<td><italic>n</italic> * mean</td>
<td>26.433</td>
<td>0.003</td>
<td>0.356</td>
</tr>
<tr>
<td><italic>n</italic> * mean * <italic>SD</italic></td>
<td>25.753</td>
<td>0.003</td>
<td>0.346</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean</td>
<td>24.026</td>
<td>0.002</td>
<td>0.323</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean</td>
<td>23.618</td>
<td>0.002</td>
<td>0.318</td>
</tr>
<tr>
<td>mean * <italic>SD</italic></td>
<td>19.424</td>
<td>0.002</td>
<td>0.261</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars</td>
<td>15.457</td>
<td>0.002</td>
<td>0.208</td>
</tr>
<tr>
<td><italic>n</italic> * vars</td>
<td>14.537</td>
<td>0.001</td>
<td>0.196</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean * <italic>SD</italic></td>
<td>11.692</td>
<td>0.001</td>
<td>0.157</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean * <italic>SD</italic></td>
<td>10.674</td>
<td>0.001</td>
<td>0.144</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * <italic>SD</italic></td>
<td>3.998</td>
<td>0.000</td>
<td>0.054</td>
</tr>
<tr>
<td><italic>n</italic> * pc</td>
<td>2.270</td>
<td>0.000</td>
<td>0.031</td>
</tr>
<tr>
<td><italic>n</italic> * pc * <italic>SD</italic></td>
<td>2.220</td>
<td>0.000</td>
<td>0.030</td>
</tr>
<tr>
<td>Error</td>
<td>2373.010</td>
<td/>
<td/>
</tr>
<tr>
<td>Total</td>
<td>581401.000</td>
<td/>
<td/>
</tr>
<tr>
<td>Corrected total</td>
<td>9806.198</td>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0013164411429821">
<p><italic>Note. R</italic><sup>2</sup> = 0.758. ANOVA = analysis of variance; K-G = Kaiser–Guttman rule; mean = mean shift of the contamination distribution; <italic>SD</italic> = standard deviation shift of the contamination distribution; pc = proportion of contamination in the population; <italic>n</italic> = sample size; vars = number of variables having outliers. The important main effects and/or interactions, as described in the Methods section, are listed in boldface.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p><xref ref-type="table" rid="table3-0013164411429821">Table 3</xref> presents the results of the variance decomposition for the MAP method, with the corresponding plots in <xref ref-type="fig" rid="fig3-0013164411429821">Figure 3</xref>. <xref ref-type="fig" rid="fig3-0013164411429821">Figure 3</xref> showed that the number of factors was not affected when the mean shift was 0 and 1.5, but inflated from 4 to 5 when the mean shift increased to 3 for the cases of 6 and 12 variables having outliers. The magnitude of the inflation increased with the increase of the proportion of contamination. It is worth noting that the number of factors retained was not affected when all variables had outliers in the MAP method, which was different from the K-G and PA methods.</p>
<table-wrap id="table3-0013164411429821" position="float">
<label>Table 3.</label>
<caption>
<p>Variable Ordering for a Five-Way ANOVA on the Number of Factors Extracted by the MAP Approach</p>
</caption>
<graphic alternate-form-of="table3-0013164411429821" xlink:href="10.1177_0013164411429821-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">Sum Squares</th>
<th align="center">Eta-Square</th>
<th align="center">Percentage of <italic>R</italic><sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr>
<td><bold>vars</bold> * <bold>mean</bold></td>
<td><bold>564.060</bold></td>
<td><bold>0.140</bold></td>
<td><bold>21.940</bold></td>
</tr>
<tr>
<td><bold>mean</bold></td>
<td><bold>543.740</bold></td>
<td><bold>0.135</bold></td>
<td><bold>21.149</bold></td>
</tr>
<tr>
<td><bold>vars</bold></td>
<td><bold>414.457</bold></td>
<td><bold>0.103</bold></td>
<td><bold>16.121</bold></td>
</tr>
<tr>
<td>
<bold>pc</bold> * <bold>vars</bold> * <bold>mean</bold></td>
<td><bold>292.322</bold></td>
<td><bold>0.072</bold></td>
<td><bold>11.370</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>mean</bold></td>
<td><bold>273.508</bold></td>
<td><bold>0.068</bold></td>
<td><bold>10.638</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold></td>
<td><bold>204.590</bold></td>
<td><bold>0.051</bold></td>
<td><bold>7.958</bold></td>
</tr>
<tr>
<td><bold>pc</bold></td>
<td><bold>166.922</bold></td>
<td><bold>0.041</bold></td>
<td><bold>6.493</bold></td>
</tr>
<tr>
<td><italic>n</italic></td>
<td>28.671</td>
<td>0.007</td>
<td>1.115</td>
</tr>
<tr>
<td><italic>SD</italic></td>
<td>14.232</td>
<td>0.004</td>
<td>0.554</td>
</tr>
<tr>
<td>pc * vars * mean * <italic>SD</italic></td>
<td>6.649</td>
<td>0.002</td>
<td>0.259</td>
</tr>
<tr>
<td>vars * <italic>SD</italic></td>
<td>5.894</td>
<td>0.001</td>
<td>0.229</td>
</tr>
<tr>
<td>pc * <italic>SD</italic></td>
<td>5.838</td>
<td>0.001</td>
<td>0.227</td>
</tr>
<tr>
<td>vars * mean * <italic>SD</italic></td>
<td>4.605</td>
<td>0.001</td>
<td>0.179</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean</td>
<td>4.435</td>
<td>0.001</td>
<td>0.173</td>
</tr>
<tr>
<td><italic>n</italic> * mean</td>
<td>4.411</td>
<td>0.001</td>
<td>0.172</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean</td>
<td>4.298</td>
<td>0.001</td>
<td>0.167</td>
</tr>
<tr>
<td>pc * mean * <italic>SD</italic></td>
<td>4.121</td>
<td>0.001</td>
<td>0.160</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean</td>
<td>4.038</td>
<td>0.001</td>
<td>0.157</td>
</tr>
<tr>
<td><italic>n</italic> * vars * <italic>SD</italic></td>
<td>3.618</td>
<td>0.001</td>
<td>0.141</td>
</tr>
<tr>
<td>pc * vars * <italic>SD</italic></td>
<td>3.613</td>
<td>0.001</td>
<td>0.141</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * <italic>SD</italic></td>
<td>2.343</td>
<td>0.001</td>
<td>0.091</td>
</tr>
<tr>
<td><italic>n</italic> * <italic>SD</italic></td>
<td>2.169</td>
<td>0.001</td>
<td>0.084</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean * <italic>SD</italic></td>
<td>2.156</td>
<td>0.001</td>
<td>0.084</td>
</tr>
<tr>
<td>mean * <italic>SD</italic></td>
<td>2.028</td>
<td>0.001</td>
<td>0.079</td>
</tr>
<tr>
<td><italic>n</italic> * vars</td>
<td>1.838</td>
<td>0.000</td>
<td>0.071</td>
</tr>
<tr>
<td><italic>n</italic> * pc</td>
<td>1.513</td>
<td>0.000</td>
<td>0.059</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean * <italic>SD</italic></td>
<td>1.390</td>
<td>0.000</td>
<td>0.054</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars</td>
<td>1.061</td>
<td>0.000</td>
<td>0.041</td>
</tr>
<tr>
<td><italic>n</italic> * pc * <italic>SD</italic></td>
<td>1.025</td>
<td>0.000</td>
<td>0.040</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean * <italic>SD</italic></td>
<td>1.020</td>
<td>0.000</td>
<td>0.040</td>
</tr>
<tr>
<td><italic>n</italic> * mean * <italic>SD</italic></td>
<td>0.234</td>
<td>0.000</td>
<td>0.009</td>
</tr>
<tr>
<td>Error</td>
<td>1471.610</td>
<td/>
<td/>
</tr>
<tr>
<td>Total</td>
<td>542513.000</td>
<td/>
<td/>
</tr>
<tr>
<td>Corrected total</td>
<td>4042.407</td>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0013164411429821">
<p><italic>Note. R</italic><sup>2</sup> = 0.636. ANOVA = analysis of variance; MAP = minimum average partial; mean = mean shift of the contamination distribution; <italic>SD</italic> = standard deviation shift of contamination distribution; pc = proportion of contamination in the population; <italic>n</italic> = sample size; vars = number of variables having outliers. The important main effects and/or interactions, as described in the Methods section, are listed in boldface.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p><xref ref-type="table" rid="table4-0013164411429821">Table 4</xref> presents the results of the variance decomposition for the PA method, and <xref ref-type="fig" rid="fig4-0013164411429821">Figure 4</xref> is the corresponding interaction plot. Similar to the performance of the K-G and MAP methods, the PA method was robust to symmetric outliers. In general, the PA method was accurate in retaining the number of factors in the presence of asymmetric outliers; however, it became dysfunctional when all variables had outliers: (a) the number of factors was deflated slightly when the mean shift was 1.5 and deflated dramatically when the mean shift increased to 3 and (b) the magnitude of deflation increased when the proportion of contamination increased.</p>
<table-wrap id="table4-0013164411429821" position="float">
<label>Table 4.</label>
<caption>
<p>Variable Ordering for a Five-Way ANOVA on the Number of Factors Extracted by the PA Approach</p>
</caption>
<graphic alternate-form-of="table4-0013164411429821" xlink:href="10.1177_0013164411429821-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">Sum Squares</th>
<th align="center">Eta-Square</th>
<th align="center">Percentage of <italic>R</italic><sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr>
<td><bold>vars</bold> * <bold>mean</bold></td>
<td><bold>2280.285</bold></td>
<td><bold>0.196</bold></td>
<td><bold>23.802</bold></td>
</tr>
<tr>
<td><bold>Vars</bold></td>
<td><bold>1985.020</bold></td>
<td><bold>0.171</bold></td>
<td><bold>20.720</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold> * <bold>mean</bold></td>
<td><bold>1069.485</bold></td>
<td><bold>0.092</bold></td>
<td><bold>11.163</bold></td>
</tr>
<tr>
<td><bold>Mean</bold></td>
<td><bold>1006.276</bold></td>
<td><bold>0.087</bold></td>
<td><bold>10.504</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold></td>
<td><bold>940.891</bold></td>
<td><bold>0.081</bold></td>
<td><bold>9.821</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>mean</bold></td>
<td><bold>498.573</bold></td>
<td><bold>0.043</bold></td>
<td><bold>5.204</bold></td>
</tr>
<tr>
<td>pc</td>
<td>410.573</td>
<td>0.035</td>
<td>4.286</td>
</tr>
<tr>
<td><italic>N</italic></td>
<td>234.027</td>
<td>0.020</td>
<td>2.443</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean</td>
<td>120.726</td>
<td>0.010</td>
<td>1.260</td>
</tr>
<tr>
<td><italic>n</italic> * vars</td>
<td>107.233</td>
<td>0.009</td>
<td>1.119</td>
</tr>
<tr>
<td>vars * mean * <italic>SD</italic></td>
<td>104.751</td>
<td>0.009</td>
<td>1.093</td>
</tr>
<tr>
<td>vars * <italic>SD</italic></td>
<td>97.287</td>
<td>0.008</td>
<td>1.015</td>
</tr>
<tr>
<td>mean * <italic>SD</italic></td>
<td>94.225</td>
<td>0.008</td>
<td>0.984</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean</td>
<td>84.549</td>
<td>0.007</td>
<td>0.883</td>
</tr>
<tr>
<td><italic>SD</italic></td>
<td>80.244</td>
<td>0.007</td>
<td>0.838</td>
</tr>
<tr>
<td><italic>n</italic> * mean</td>
<td>75.325</td>
<td>0.006</td>
<td>0.786</td>
</tr>
<tr>
<td>pc * vars * mean * <italic>SD</italic></td>
<td>64.773</td>
<td>0.006</td>
<td>0.676</td>
</tr>
<tr>
<td>pc * vars * <italic>SD</italic></td>
<td>60.835</td>
<td>0.005</td>
<td>0.635</td>
</tr>
<tr>
<td>pc * mean * <italic>SD</italic></td>
<td>50.661</td>
<td>0.004</td>
<td>0.529</td>
</tr>
<tr>
<td>pc * <italic>SD</italic></td>
<td>48.762</td>
<td>0.004</td>
<td>0.509</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars</td>
<td>42.428</td>
<td>0.004</td>
<td>0.443</td>
</tr>
<tr>
<td><italic>n</italic> * pc</td>
<td>41.678</td>
<td>0.004</td>
<td>0.435</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean</td>
<td>27.678</td>
<td>0.002</td>
<td>0.289</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean * <italic>SD</italic></td>
<td>15.749</td>
<td>0.001</td>
<td>0.164</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean * <italic>SD</italic></td>
<td>10.429</td>
<td>0.001</td>
<td>0.109</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean * <italic>SD</italic></td>
<td>9.840</td>
<td>0.001</td>
<td>0.103</td>
</tr>
<tr>
<td><italic>n</italic> * mean * <italic>SD</italic></td>
<td>8.414</td>
<td>0.001</td>
<td>0.088</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * <italic>SD</italic></td>
<td>7.395</td>
<td>0.001</td>
<td>0.077</td>
</tr>
<tr>
<td><italic>n</italic> * vars * <italic>SD</italic></td>
<td>1.617</td>
<td>0.000</td>
<td>0.017</td>
</tr>
<tr>
<td><italic>n</italic> * pc * <italic>SD</italic></td>
<td>0.393</td>
<td>0.000</td>
<td>0.004</td>
</tr>
<tr>
<td><italic>n</italic> * <italic>SD</italic></td>
<td>0.291</td>
<td>0.000</td>
<td>0.003</td>
</tr>
<tr>
<td>Error</td>
<td>2039.620</td>
<td/>
<td/>
</tr>
<tr>
<td>Total</td>
<td>485484.000</td>
<td/>
<td/>
</tr>
<tr>
<td>Corrected total</td>
<td>11620.035</td>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0013164411429821">
<p><italic>Note. R</italic><sup>2</sup> =0.824. ANOVA = analysis of variance; PA = parallel analysis; mean = mean shift of the contamination distribution; <italic>SD</italic> = standard deviation shift of the contamination distribution; pc = proportion of contamination in the population; <italic>n</italic> = sample size; vars = number of variables having outliers. The important main effects and/or interactions, as described in the Methods section, are listed in boldface.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Unlike the three PCA-based methods, for the sequential <inline-formula id="inline-formula7-0013164411429821">
<mml:math display="inline" id="math11-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test, the highest order interaction identified as important using η<sup>2</sup> was found to be: <italic>SD shift</italic> by <italic>the number of variables having outliers</italic> by <italic>the proportion of contamination</italic>. <xref ref-type="table" rid="table5-0013164411429821">Table 5</xref> presents the results of the variance decomposition for the sequential <inline-formula id="inline-formula8-0013164411429821">
<mml:math display="inline" id="math12-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test, and <xref ref-type="fig" rid="fig5-0013164411429821">Figure 5</xref> shows the corresponding interaction plot. The <italic>SD</italic> shift played an important role in the interaction, which indicated that the symmetric outliers affected the performance of the sequential <inline-formula id="inline-formula9-0013164411429821">
<mml:math display="inline" id="math13-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test. When the <italic>SD</italic> was one (no shift) or 1.5 (mild increase on variations for the contamination distribution), the number of factors retained was either not affected or inflated by a small magnitude. However, the number of factors retained was inflated dramatically when the <italic>SD</italic> shift increased to 3, and especially when all variables had outliers, the number of factors retained increased from 4 (baseline) to almost 12.</p>
<table-wrap id="table5-0013164411429821" position="float">
<label>Table 5.</label>
<caption>
<p>Variable Ordering for a Five-Way ANOVA on the Number of Factors Decided by the Chi-Square (ML) Test</p>
</caption>
<graphic alternate-form-of="table5-0013164411429821" xlink:href="10.1177_0013164411429821-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">Sum Squares</th>
<th align="center">Eta-Square</th>
<th align="center">Percentage of <italic>R</italic><sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr>
<td><bold>vars</bold> * <bold><italic>SD</italic></bold></td>
<td><bold>27625.757</bold></td>
<td><bold>0.306</bold></td>
<td><bold>32.393</bold></td>
</tr>
<tr>
<td><bold><italic>SD</italic></bold></td>
<td><bold>19436.831</bold></td>
<td><bold>0.216</bold></td>
<td><bold>22.791</bold></td>
</tr>
<tr>
<td><bold>Vars</bold></td>
<td><bold>13616.464</bold></td>
<td><bold>0.151</bold></td>
<td><bold>15.966</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold> * <bold><italic>SD</italic></bold></td>
<td><bold>7747.121</bold></td>
<td><bold>0.086</bold></td>
<td><bold>9.084</bold></td>
</tr>
<tr>
<td><bold>pc</bold></td>
<td><bold>5190.159</bold></td>
<td><bold>0.058</bold></td>
<td><bold>6.086</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold><italic>SD</italic></bold></td>
<td><bold>4856.412</bold></td>
<td><bold>0.054</bold></td>
<td><bold>5.694</bold></td>
</tr>
<tr>
<td><bold>pc</bold> * <bold>vars</bold></td>
<td><bold>4018.700</bold></td>
<td><bold>0.045</bold></td>
<td><bold>4.712</bold></td>
</tr>
<tr>
<td>Mean</td>
<td>765.987</td>
<td>0.008</td>
<td>0.898</td>
</tr>
<tr>
<td>vars * mean</td>
<td>642.238</td>
<td>0.007</td>
<td>0.753</td>
</tr>
<tr>
<td><italic>N</italic></td>
<td>214.615</td>
<td>0.002</td>
<td>0.252</td>
</tr>
<tr>
<td><italic>n</italic> * vars * <italic>SD</italic></td>
<td>134.941</td>
<td>0.001</td>
<td>0.158</td>
</tr>
<tr>
<td><italic>n</italic> * <italic>SD</italic></td>
<td>131.215</td>
<td>0.001</td>
<td>0.154</td>
</tr>
<tr>
<td>pc * vars * mean</td>
<td>119.643</td>
<td>0.001</td>
<td>0.140</td>
</tr>
<tr>
<td>pc * mean</td>
<td>117.121</td>
<td>0.001</td>
<td>0.137</td>
</tr>
<tr>
<td>mean * <italic>SD</italic></td>
<td>100.804</td>
<td>0.001</td>
<td>0.118</td>
</tr>
<tr>
<td><italic>n</italic> * vars</td>
<td>99.760</td>
<td>0.001</td>
<td>0.117</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * <italic>SD</italic></td>
<td>88.972</td>
<td>0.001</td>
<td>0.104</td>
</tr>
<tr>
<td>vars * mean * <italic>SD</italic></td>
<td>74.092</td>
<td>0.001</td>
<td>0.087</td>
</tr>
<tr>
<td>pc * mean * <italic>SD</italic></td>
<td>62.435</td>
<td>0.001</td>
<td>0.073</td>
</tr>
<tr>
<td>pc * vars * mean * <italic>SD</italic></td>
<td>48.162</td>
<td>0.001</td>
<td>0.056</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean</td>
<td>31.810</td>
<td>0.000</td>
<td>0.037</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean</td>
<td>29.125</td>
<td>0.000</td>
<td>0.034</td>
</tr>
<tr>
<td><italic>n</italic> * pc * <italic>SD</italic></td>
<td>26.532</td>
<td>0.000</td>
<td>0.031</td>
</tr>
<tr>
<td><italic>n</italic> * pc</td>
<td>24.936</td>
<td>0.000</td>
<td>0.029</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars</td>
<td>22.889</td>
<td>0.000</td>
<td>0.027</td>
</tr>
<tr>
<td><italic>n</italic> * pc * vars * mean * <italic>SD</italic></td>
<td>18.122</td>
<td>0.000</td>
<td>0.021</td>
</tr>
<tr>
<td><italic>n</italic> * mean</td>
<td>10.558</td>
<td>0.000</td>
<td>0.012</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean * <italic>SD</italic></td>
<td>8.307</td>
<td>0.000</td>
<td>0.010</td>
</tr>
<tr>
<td><italic>n</italic> * mean * <italic>SD</italic></td>
<td>8.049</td>
<td>0.000</td>
<td>0.009</td>
</tr>
<tr>
<td><italic>n</italic> * vars * mean</td>
<td>7.478</td>
<td>0.000</td>
<td>0.009</td>
</tr>
<tr>
<td><italic>n</italic> * pc * mean * <italic>SD</italic></td>
<td>5.091</td>
<td>0.000</td>
<td>0.006</td>
</tr>
<tr>
<td>Error</td>
<td>8922.025</td>
<td/>
<td/>
</tr>
<tr>
<td>Total</td>
<td>855330.000</td>
<td/>
<td/>
</tr>
<tr>
<td>Corrected total</td>
<td>90140.908</td>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0013164411429821">
<p><italic>Note. R</italic><sup>2</sup> = .946. ANOVA = analysis of variance; mean = mean shift of the contamination distribution; <italic>SD</italic> = standard deviation shift of the contamination distribution; pc = proportion of contamination in the population; <italic>n</italic> = sample size; vars = number of variables having outliers. The important main effects and/or interactions, as described in the Methods section, are listed in boldface.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>It should be noted that nonconvergence was found for the sequential <inline-formula id="inline-formula10-0013164411429821">
<mml:math display="inline" id="math14-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests, ranging from 1% to 19% of the replications in a cell of the experimental design (in most cases it was zero), and less than one half of a percentage point overall. As shown in <xref ref-type="table" rid="table6-0013164411429821">Table 6</xref>, the nonconvergence occurred for experimental conditions wherein the <italic>SD</italic> shift was 3, which we saw in <xref ref-type="fig" rid="fig1-0013164411429821">Figure 1</xref> involved high kurtosis for the variable with outliers. Within the conditions involving an <italic>SD</italic> shift of 3, nonconvergence happened when the proportion of contamination was either .08 or .15 and either 12 or 24 variables had outliers and was more likely to happen when all 24 variables had outliers. Sample size also seemed to interact in this finding, wherein the nonconvergence occurred predominantly with sample sizes of 1,000. Like the findings of <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, in inspecting the statistical output from the simulation, the nonconvergence problem resulted from a combination of a Heywood case and failure to find local minimum of the empirical likelihood solution.</p>
<table-wrap id="table6-0013164411429821" position="float">
<label>Table 6.</label>
<caption>
<p>Percentage of Nonconvergent Replications With the Sequential Chi-Square (ML) Tests</p>
</caption>
<graphic alternate-form-of="table6-0013164411429821" xlink:href="10.1177_0013164411429821-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="3"><bold><italic>SD</italic> Shift of 3</bold></th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="3"><bold>Mean Shift</bold></th>
</tr>
<tr>
<th align="left"><bold>Pc</bold></th>
<th align="center"><bold>Vars</bold></th>
<th align="center"><bold>.0</bold></th>
<th align="center"><bold>1.5</bold></th>
<th align="center"><bold>3.0</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td><bold>.08</bold></td>
<td><bold>12</bold></td>
<td/>
<td/>
<td>1 (<italic>n</italic> = 250)</td>
</tr>
<tr>
<td/>
<td><bold>24</bold></td>
<td>3 (<italic>n</italic> = 500)</td>
<td>4 (<italic>n</italic> = 500)</td>
<td>3 (<italic>n</italic> = 500)</td>
</tr>
<tr>
<td/>
<td/>
<td>8 (<italic>n</italic> = 1,000)</td>
<td>15 (<italic>n</italic> = 1,000)</td>
<td>18 (<italic>n</italic> = 1,000)</td>
</tr>
<tr>
<td><bold>.15</bold></td>
<td><bold>24</bold></td>
<td/>
<td>1 (<italic>n</italic> = 250)</td>
<td>1 (<italic>n</italic> = 250)</td>
</tr>
<tr>
<td/>
<td/>
<td>3 (<italic>n</italic> = 500)</td>
<td>4 (<italic>n</italic> = 500)</td>
<td>10 (<italic>n</italic> = 500)</td>
</tr>
<tr>
<td/>
<td/>
<td>19 (<italic>n</italic> = 1,000)</td>
<td>17 (<italic>n</italic> = 1,000)</td>
<td>16 (<italic>n</italic> = 1,000)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-0013164411429821">
<p><italic>Note. SD</italic> = standard deviation; pc = proportion of contamination in the population; vars = number of variables having outliers.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="section16-0013164411429821">
<title>Study 2: Demonstrations of Effects of Outliers on Correlation Matrix and Kurtosis and Skewness of Item Responses</title>
<p>The purpose of Study 2 was to facilitate our understanding about why these decision methods performed differently in the presence of outliers. As <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref> pointed out, correlation matrices are the engine for the PCA-based methods and hence are the input data for them. Furthermore, skewness and kurtosis are related to the performance of the <inline-formula id="inline-formula11-0013164411429821">
<mml:math display="inline" id="math15-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test in factor analysis (<xref ref-type="bibr" rid="bibr8-0013164411429821">Boomsma, 1983</xref>; <xref ref-type="bibr" rid="bibr9-0013164411429821">Browne, 1984</xref>). We, therefore, include two demonstrations in Study 2: a small, focused simulation to show how outliers distort the correlation matrix and eigenvalues as well as a demonstration of the change in kurtosis and skewness in the presence of outliers.</p>
<sec id="section17-0013164411429821">
<title>Demonstration 1</title>
<p>Researchers usually ignored the effects of outliers on factor analysis partly because they believed that a few outliers should not substantially change the correlation matrix and, as such, a factor analysis should not be affected by outliers. The present small-scale simulation aimed to demonstrate how outliers may distort properties of a correlation matrix. Following Liu et al.’s (in press) study, we also used the original correlation matrix of the first four variables from <xref ref-type="bibr" rid="bibr16-0013164411429821">Holzinger and Swineford’s (1939)</xref> classic data as the population correlation matrix for simulating multivariate normal data sets. For demonstration purposes, we only included extreme outlier conditions (mean shift = 3 and/or <italic>SD</italic> shift = 3) with either two or all four variables having outliers as well as a no-outlier condition. Across all outlier conditions, the proportion of contamination was 0.15. In Study 1, we did not find sample size effects; therefore, in this demonstration we ruled out this factor and used data sets with 100,000 observations so as to have population analogues.</p>
<p>To examine the change in the correlation matrix under outlier conditions, we used the matrix’s condition number to document if it is ill-conditioned and the magnitude of ill-condition—with larger condition number indicating more ill-conditioned. The advantage of using the condition number is that, when the correlation matrix is close to being singular, we can still obtain a solution, which disguises the problem of being ill-conditioned, but the condition number can reflect if the matrix is ill-conditioned and if the properties of the matrix are distorted. The condition number is a product term, <inline-formula id="inline-formula12-0013164411429821">
<mml:math display="inline" id="math16-0013164411429821">
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>‖</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo>‖</mml:mo>
</mml:mrow>
<mml:mo>×</mml:mo>
<mml:mrow>
<mml:mo>‖</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mo>‖</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> , where <italic>A</italic> denotes a correlation matrix, <inline-formula id="inline-formula13-0013164411429821">
<mml:math display="inline" id="math17-0013164411429821">
<mml:mrow>
<mml:mrow>
<mml:mo>‖</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo>‖</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> denotes matrix norm, <italic>A</italic><sup>−1</sup> denotes the inverse of a matrix, and <inline-formula id="inline-formula14-0013164411429821">
<mml:math display="inline" id="math18-0013164411429821">
<mml:mrow>
<mml:mrow>
<mml:mo>‖</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mo>‖</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> denotes the matrix norm for the inverse of a matrix (<xref ref-type="bibr" rid="bibr29-0013164411429821">Watkins, 2010</xref>). Given that a correlation matrix is a special case of a square matrix that is symmetric about the major diagonal that contains ones, <inline-formula id="inline-formula15-0013164411429821">
<mml:math display="inline" id="math19-0013164411429821">
<mml:mrow>
<mml:mrow>
<mml:mo>‖</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo>‖</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> is the largest eigenvalue of a correlation matrix, and <inline-formula id="inline-formula16-0013164411429821">
<mml:math display="inline" id="math20-0013164411429821">
<mml:mrow>
<mml:mrow>
<mml:mo>‖</mml:mo>
<mml:mrow>
<mml:msup>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mo>‖</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> is the largest eigenvalue of the inverse of a correlation matrix (<xref ref-type="bibr" rid="bibr12-0013164411429821">Golub &amp; Van Loan, 1993</xref>).</p>
<p><xref ref-type="table" rid="table7-0013164411429821">Table 7</xref> presents the results of the simulation with four rows and seven columns. The first column indicates the outlier conditions (i.e., mean shift and <italic>SD</italic> shift), the second column shows the resulting correlation matrix with only two variables having outliers, the third and fourth columns are the corresponding condition number and eigenvalues, the fifth column shows the resulting correlation matrix with all four variables having outliers, and the sixth and seventh columns are the corresponding condition number and eigenvalues.</p>
<table-wrap id="table7-0013164411429821" position="float">
<label>Table 7.</label>
<caption>
<p>Demonstration of Changes in Correlation Coefficients, Condition Number, and Eigenvalues Using a Four-Variable Data Set in the Presence of Outliers (15%) Compared to the No-Outlier Condition</p>
</caption>
<graphic alternate-form-of="table7-0013164411429821" xlink:href="10.1177_0013164411429821-table7.tif"/>
<table-wrap-foot>
<fn id="table-fn7-0013164411429821">
<p><italic>Note. M</italic> = mean; <italic>SD</italic> = standard deviation. Dashed lines are used to indicate which variables had outliers.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The top row presents the results for the correlation matrix in the no-outlier condition. The second row shows the results for symmetric outlier condition, with no mean shift and a <italic>SD</italic> shift of 3. The effects of outliers were not found for either the case of two variables having outliers or that of all variables having outliers. Some of the correlation coefficients were deflated to a small degree when two variables had outliers, and the condition number as well as the magnitude of eigenvalues was not affected by symmetric outliers.</p>
<p>However, there were dramatic changes for the asymmetric outlier condition with mean shift only (mean shift = 3, <italic>SD</italic> shift = 1). Echoed in the findings of <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, we also found that when two variables had outliers, the correlation coefficient for those two variables was inflated, whereas the remaining correlations in the matrix were either deflated when involving combinations of variables with and without outliers or were unchanged when only involving variables without outliers. The complex pattern created an extra factor and resulted in an increase of the condition number from 3.415 (baseline) to 6.481. When all the variables had outliers, the correlation coefficients were all inflated resulting in the creation of a more dominant (or salient) factor and a large increase in the condition number from 3.415 to 11.363.</p>
<p>For the asymmetric outlier condition with both mean shift and <italic>SD</italic> shift (mean shift = 3, <italic>SD</italic> shift = 3), the effects of outliers were reduced to some degree. Compared with the mean shift only condition (mean shift = 3, <italic>SD</italic> shift = 1), the magnitude of inflation in correlation coefficients became smaller; the condition number dropped to some extent, from 6.481 and 11.363 to 4.465 and 7.093; the second eigenvalue for two variables having outliers was not greater than one anymore (i.e., dropped from 1.009 to 0.955); and the magnitude of the largest eigenvalue for all variables having outliers decreased from 3.047 to 2.666.</p>
<p>The interesting findings here were that symmetric outliers did not affect the correlation matrix whereas the asymmetric outliers, especially in the mean shift only condition, distorted the correlation matrix, which either created an extra factor or led to the appearance of a dominant factor that could reduce the number of factors if there were more than one factor. This helps us understand why mean shift and the number of variables having outliers played important roles for PCA-based methods whereas <italic>SD</italic> shift did not. Although they are all PCA-based, K-G, MAP, and PA methods adopt different procedures and hence one should not be surprised to find some variation among these methods when determining the number of factors, which was shown in our Study 1.</p>
</sec>
<sec id="section18-0013164411429821">
<title>Demonstration 2</title>
<p>Our findings from Study 1 revealed that, for the sequential <inline-formula id="inline-formula17-0013164411429821">
<mml:math display="inline" id="math21-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> test, the number of factors was inflated with an increase in the magnitude of <italic>SD</italic> shift, the proportion of contamination, and the number of variables having outliers. Unlike the PCA-based methods, <italic>SD</italic> shift played an important role, but mean shift did not. In this demonstration, we followed the simulation design in Study 1, but did not manipulate the number of variables having outliers. The purpose was to demonstrate the univariate skewness and kurtosis for a single variable in each outlier condition. Like Demonstration 1, we did not manipulate sample size and hence reported the population analogues—that is, we reported the values of kurtosis and skewness for a data set with 100,000 observations.</p>
<p><xref ref-type="table" rid="table8-0013164411429821">Table 8</xref> comprises two parts: the upper part reports kurtosis and the lower part reports skewness.<sup><xref ref-type="fn" rid="fn2-0013164411429821">2</xref></sup> The kurtosis was inflated when the <italic>SD</italic> shifted from 1 to 1.5, and greatly inflated when <italic>SD</italic> shift became 3. Mean shift affected kurtosis to some degree for the proportion of contamination of .01 and .08, but not much for a proportion of contamination of .15. It should be noted that the kurtosis was inflated to 8.62 (mean shift = 3, <italic>SD</italic> shift = 3) for the proportion of contamination of .08, but was 5.96 for the proportion of contamination of .15. This suggests that a higher level of proportion of contamination (.15) led to less inflation in kurtosis than a lower level (.08). As shown mathematically by <xref ref-type="bibr" rid="bibr25-0013164411429821">Pena and Prieto (2001)</xref>, symmetric outliers increase the kurtosis and a small proportion of asymmetric outliers also increase kurtosis, but a large proportion of asymmetric outliers can make kurtosis smaller.</p>
<table-wrap id="table8-0013164411429821" position="float">
<label>Table 8.</label>
<caption>
<p>Demonstration of Effects of Outliers on Kurtosis and Skewness</p>
</caption>
<graphic alternate-form-of="table8-0013164411429821" xlink:href="10.1177_0013164411429821-table8.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="9">Kurtosis</th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="9">Mean</th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="3">0.0</th>
<th align="center" colspan="3">1.5</th>
<th align="center" colspan="3">3.0</th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="3"><italic>SD</italic></th>
<th align="center" colspan="3"><italic>SD</italic></th>
<th align="center" colspan="3"><italic>SD</italic></th>
</tr>
<tr>
<th colspan="2"/>
<th align="center">1.0</th>
<th align="center">1.5</th>
<th align="center">3.0</th>
<th align="center">1.0</th>
<th align="center">1.5</th>
<th align="center">3.0</th>
<th align="center">1.0</th>
<th align="center">1.5</th>
<th align="center">3.0</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pc</td>
<td>0.01</td>
<td>−0.02</td>
<td>0.01</td>
<td>1.31</td>
<td>0.01</td>
<td>0.18</td>
<td>2.06</td>
<td>0.61</td>
<td>1.13</td>
<td>4.51</td>
</tr>
<tr>
<td/>
<td>0.08</td>
<td>0.01</td>
<td>0.37</td>
<td>5.89</td>
<td>0.17</td>
<td>1.05</td>
<td>6.86</td>
<td>1.22</td>
<td>2.57</td>
<td>8.62</td>
</tr>
<tr>
<td/>
<td>0.15</td>
<td>0.00</td>
<td>0.48</td>
<td>5.27</td>
<td>0.11</td>
<td>1.09</td>
<td>5.68</td>
<td>0.56</td>
<td>1.72</td>
<td>5.96</td>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="9">Skewness</th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="9">Mean</th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="3">0.0</th>
<th align="center" colspan="3">1.5</th>
<th align="center" colspan="3">3.0</th>
</tr>
<tr>
<th/>
<th/>
<th align="center" colspan="3"><italic>SD</italic></th>
<th align="center" colspan="3"><italic>SD</italic></th>
<th align="center" colspan="3"><italic>SD</italic></th>
</tr>
<tr>
<th colspan="2"/>
<th align="center">1.0</th>
<th align="center">1.5</th>
<th align="center">3.0</th>
<th align="center">1.0</th>
<th align="center">1.5</th>
<th align="center">3.0</th>
<th align="center">1.0</th>
<th align="center">1.5</th>
<th align="center">3.0</th>
</tr>
<tr>
<td>Pc</td>
<td>0.01</td>
<td>0.02</td>
<td>0.02</td>
<td>0.01</td>
<td>0.05</td>
<td>0.10</td>
<td>0.33</td>
<td>0.25</td>
<td>0.34</td>
<td>0.77</td>
</tr>
<tr>
<td/>
<td>0.08</td>
<td>0.00</td>
<td>−0.01</td>
<td>−0.08</td>
<td>0.17</td>
<td>0.44</td>
<td>1.13</td>
<td>0.78</td>
<td>1.07</td>
<td>1.98</td>
</tr>
<tr>
<td/>
<td>0.15</td>
<td>0.00</td>
<td>−0.01</td>
<td>−0.03</td>
<td>0.22</td>
<td>0.58</td>
<td>1.24</td>
<td>0.77</td>
<td>1.09</td>
<td>1.90</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn8-0013164411429821">
<p><italic>Note</italic>. Mean = mean shift; <italic>SD</italic> = standard deviation shift; Pc = proportion of contamination.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The lower part of <xref ref-type="table" rid="table8-0013164411429821">Table 8</xref> shows that, as expected, skewness was inflated when the mean shifted to 1.5 and 3 and <italic>SD</italic> shifted to 1.5 and 3. The largest increase of skewness is 1.98 for the mean shift of 3 and <italic>SD</italic> shift of 3 with .08 proportion of contamination. However, the inflation of skewness was not as large as the inflation of kurtosis. Hence, the inflation in kurtosis likely drove the inflation of Type I error rate of chi-square (ML) sequential tests in our simulation, in which <italic>SD</italic> shift was an influential factor. This might reflect why <italic>SD</italic> shift played an important role in explaining the inflation of number of factors in sequential <inline-formula id="inline-formula18-0013164411429821">
<mml:math display="inline" id="math22-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests.</p>
</sec>
</sec>
<sec id="section19-0013164411429821">
<title>General Discussion</title>
<p>The common practices to deal with outliers in data analysis are either to (a) remove or correct them if they are errors or (b) use a robust estimator if one is uncertain about the source of the outliers or if one is uncertain that outliers are present (e.g., outliers in high-dimensional data are very difficult to detect). However, it should be noted that not all outliers are typographical or data entry (or recording) errors. If outliers arise from unintentionally and unknowingly included subpopulations other than the target population, the outliers are not errors of the first kind described in <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo (2007)</xref> but rather, in that sense, legitimate observations that arise from a subpopulation different than the target population in a study. The example we provided earlier of the study of life satisfaction in Denmark demonstrates the subtle issues of unintentionally and unknowingly invoking an assumption of measurement universality with heterogeneous populations involved in a multicultural and globalized assessment environment (<xref ref-type="bibr" rid="bibr14-0013164411429821">Hambleton et al., 2005</xref>).</p>
<p>The purpose of the present research was to investigate the effects of outliers, arising from an unintentionally and unknowingly recruited subpopulation, on decisions about the number of factors to retain in an EFA using four decision methods separately. Four important findings are summarized as follows. First, the effects of outliers did not depend on the sample size. This is an important finding because many practitioners believe that having a larger sample size makes them immune to the effects of outliers, which has been shown herein (and elsewhere) to not be the case. Second, the performance of the three PCA-based methods (K-G, MAP, and PA) was not affected by symmetric contamination, but that of sequential <inline-formula id="inline-formula19-0013164411429821">
<mml:math display="inline" id="math23-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests was affected with inflation of the number of factors retained. Third, for the asymmetric contamination, the number of factors retained was inflated for the MAP method, deflated for the PA method, and either inflated or deflated for the K-G rule, depending on the number of variables having outliers, the proportion of contamination, and the level of mean shift, whereas mean shift did not affect sequential <inline-formula id="inline-formula20-0013164411429821">
<mml:math display="inline" id="math24-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests. Finally, the MAP and PA methods are, in general, more resistant to outliers than the K-G rule and sequential <inline-formula id="inline-formula21-0013164411429821">
<mml:math display="inline" id="math25-0013164411429821">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> tests. However, it should be noted that both MAP and PA are still affected by outliers under certain conditions, so they are not fully resistant to outliers.</p>
<p>The present study, along with the earlier study by <xref ref-type="bibr" rid="bibr22-0013164411429821">Liu et al. (in press)</xref>, provide a broad picture of the effects of outliers on the decisions about the number of factors to retain in an EFA study. When reading extant literature, or conducting an EFA study, readers can be assured that outliers in the item response distributions are likely to have a significant impact on the conclusions, either inflating or deflating the number of factors retained depending on the decision methods used, outlier sources (<xref ref-type="bibr" rid="bibr21-0013164411429821">Liu &amp; Zumbo, 2007</xref>), and manifestation of outliers (e.g., asymmetric or symmetric outliers) in the sample. The take-home message in this line of research, however, is still the same: researchers are strongly encouraged to check for outliers and use robust methods in their day-to-day research practice (<xref ref-type="bibr" rid="bibr19-0013164411429821">Huber, 1981</xref>; <xref ref-type="bibr" rid="bibr30-0013164411429821">Wilcox, 2010</xref>, <xref ref-type="bibr" rid="bibr31-0013164411429821">in press)</xref> and that not doing so may lead to misleading empirical conclusions.</p>
<p>The present research has high fidelity with real data situations, which provides useful information for applied researchers. However, using real data for simulation also brings some limitations, such as we only mimic one real data situation, so we did not vary the number of variables and number of factors and manipulate different levels of factor loadings and factor correlations. We would encourage future research to investigate these variables when examining the effects of outliers on the decision about the number of factors.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author(s) disclosed receipt of the following support for the research, authorship, and/or publication of this article: Bruno Zumbo wishes to acknowledge support from the Social Sciences and Humanities Research Council of Canada (SSHRC) and the Canadian Institutes of Health Research (CIHR) during the preparation of this work.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0013164411429821">
<label>1.</label>
<p>Although we do not discuss them in detail here, “mixture of statistical models” can also be used in this context. It involves situations in which the observed data are a mixture of two statistical models that are different (e.g., one is a one-dimensional and the other a two-dimensional factor analysis model). These sorts of structured populations may be characterized as multigroup factor analysis in the psychometric literature.</p>
</fn>
<fn fn-type="other" id="fn2-0013164411429821">
<label>2.</label>
<p>Although, due to space limitations, we do not report it here, our interpretation of the effects of the outlier factors on the kurtosis and skewness are supported by results of ANOVAs of the kurtosis and skewness data in <xref ref-type="table" rid="table4-0013164411429821">Table 4</xref>.8 with an unreplicated design. Please see <xref ref-type="bibr" rid="bibr21-0013164411429821">Liu and Zumbo (2007)</xref> for a description of the ANOVA model and the partitioning of the eta-squared with unreplicated simulation designs.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Anscombe</surname><given-names>F. J.</given-names></name>
</person-group> (<year>1960</year>). <article-title>Rejection of outliers</article-title>. <source>Technometrics</source>, <volume>2</volume>, <fpage>123</fpage>-<lpage>147</lpage>.</citation>
</ref>
<ref id="bibr2-0013164411429821">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Balakrishnan</surname><given-names>N.</given-names></name>
<name><surname>Childs</surname><given-names>A.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Outlier</article-title>. In <person-group person-group-type="editor">
<name><surname>Hazewinkel</surname><given-names>M.</given-names></name>
</person-group> (Ed.), <source>Encyclopaedia of mathematics</source> (<comment>online version</comment>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://eom.springer.de/">http://eom.springer.de/</ext-link></comment></citation>
</ref>
<ref id="bibr3-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barnett</surname><given-names>V.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Nonattending respondent effects on internal consistency of self-administered surveys: A Monte Carlo simulation study</article-title>. <source>Educational and Psychological Measurement</source>, <volume>59</volume>, <fpage>38</fpage>-<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr4-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Barnett</surname><given-names>V.</given-names></name>
<name><surname>Lewis</surname><given-names>T.</given-names></name>
</person-group> (<year>1978</year>). <source>Outliers in statistical data</source> (<edition>1st ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr5-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Barnett</surname><given-names>V.</given-names></name>
<name><surname>Lewis</surname><given-names>T.</given-names></name>
</person-group> (<year>1994</year>). <source>Outliers in statistical data</source> (<edition>3rd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr6-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Blair</surname><given-names>R. C.</given-names></name>
<name><surname>Higgins</surname><given-names>J. J.</given-names></name>
</person-group> (<year>1980</year>). <article-title>The power of t and Wilcoxon statistics: A comparison</article-title>. <source>Evaluation Review</source>, <volume>4</volume>, <fpage>645</fpage>-<lpage>656</lpage>.</citation>
</ref>
<ref id="bibr7-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Blischke</surname><given-names>W. S.</given-names></name>
</person-group> (<year>1978</year>). <article-title>Mixtures of distributions</article-title>. In <person-group person-group-type="editor">
<name><surname>Kruskal</surname><given-names>W. H.</given-names></name>
<name><surname>Tanur</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>International encyclopedia of statistics</source> (Vol. <volume>1</volume>, pp. <fpage>174</fpage>-<lpage>180</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Free Press</publisher-name>.</citation>
</ref>
<ref id="bibr8-0013164411429821">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Boomsma</surname><given-names>A.</given-names></name>
</person-group> (<year>1983</year>). <source>On the robustness of LISREL (maximum likelihood estimation) against small sample size and nonnormality</source>. <publisher-loc>Amsterdam, Netherlands</publisher-loc>: <publisher-name>Sociometric Research Foundation</publisher-name>. (<comment>Unpublished doctoral dissertation, University of Groningen, Netherlands</comment>)</citation>
</ref>
<ref id="bibr9-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Browne</surname><given-names>M. W.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Asymptotically distribution-free methods for the analysis of covariance structures</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>37</volume>, <fpage>62</fpage>-<lpage>83</lpage>.</citation>
</ref>
<ref id="bibr10-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dixon</surname><given-names>W. J.</given-names></name>
</person-group> (<year>1950</year>). <article-title>Analysis of extreme values</article-title>. <source>Annals of Mathematical Statistics</source>, <volume>21</volume>, <fpage>488</fpage>-<lpage>506</lpage>.</citation>
</ref>
<ref id="bibr11-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ferguson</surname><given-names>C. J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>An effect size primer: A guide for clinicians and researchers</article-title>. <source>Professional Psychology: Research and Practice</source>, <volume>40</volume>, <fpage>532</fpage>-<lpage>538</lpage>.</citation>
</ref>
<ref id="bibr12-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Golub</surname><given-names>G. H.</given-names></name>
<name><surname>Van Loan</surname><given-names>C. F.</given-names></name>
</person-group> (<year>1993</year>). <source>Matrix computation</source>. <publisher-loc>Baltimore, MD</publisher-loc>: <publisher-name>Johns Hopkins University Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gorsuch</surname><given-names>R. L.</given-names></name>
</person-group> (<year>1983</year>). <source>Factor analysis</source> (<edition>2nd ed.</edition>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr14-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hambleton</surname><given-names>R. K.</given-names></name>
<name><surname>Merenda</surname><given-names>P. F.</given-names></name>
<name><surname>Spielberger</surname><given-names>C. D.</given-names></name>
</person-group> (<year>2005</year>). <source>Adapting educational and psychological tests for cross-cultural assessment</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr15-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Harman</surname><given-names>H. H.</given-names></name>
</person-group> (<year>1976</year>). <source>Modern factor analysis</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr16-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Holzinger</surname><given-names>K. J.</given-names></name>
<name><surname>Swineford</surname><given-names>F.</given-names></name>
</person-group> (<year>1939</year>). <source>A study in factor analysis: The stability of a bi-factor solution</source> (<comment>Supplementary Educational Monographs, No. 48</comment>). <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago</publisher-name>.</citation>
</ref>
<ref id="bibr17-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hubbard</surname><given-names>R.</given-names></name>
<name><surname>Allen</surname><given-names>S. J.</given-names></name>
</person-group> (<year>1987</year>). <article-title>An empirical comparison of alternative methods for principal components extraction</article-title>. <source>Journal of Business Research</source>, <volume>15</volume>, <fpage>173</fpage>-<lpage>190</lpage>.</citation>
</ref>
<ref id="bibr18-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Huber</surname><given-names>P. J.</given-names></name>
</person-group> (<year>1964</year>). <article-title>Robust estimation of a location parameter</article-title>. <source>Annals of Mathematical Statistics</source>, <volume>35</volume>, <fpage>73</fpage>-<lpage>101</lpage>.</citation>
</ref>
<ref id="bibr19-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Huber</surname><given-names>P. J.</given-names></name>
</person-group> (<year>1981</year>). <source>Robust statistics</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr20-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaiser</surname><given-names>H. F.</given-names></name>
<name><surname>Dickman</surname><given-names>K.</given-names></name>
</person-group> (<year>1962</year>). <article-title>Sample and population score matrices and sample correlation matrices from an arbitrary population correlation matrix</article-title>. <source>Psychometrika</source>, <volume>27</volume>, <fpage>179</fpage>-<lpage>182</lpage>.</citation>
</ref>
<ref id="bibr21-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The impact of outliers on Cronbach’s coefficient alpha estimate of reliability: Visual analogue scales</article-title>. <source>Educational and Psychological Measurement</source>, <volume>67</volume>, <fpage>620</fpage>-<lpage>634</lpage>.</citation>
</ref>
<ref id="bibr22-0013164411429821">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
<name><surname>Wu</surname><given-names>A. D.</given-names></name>
</person-group> (<year>in press</year>). <article-title>A demonstration of the impact of outliers on the decisions about the number of factors in exploratory factor analysis</article-title>. <source>Educational and Psychological Measurement</source>.</citation>
</ref>
<ref id="bibr23-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mosteller</surname><given-names>F.</given-names></name>
<name><surname>Tukey</surname><given-names>J. W.</given-names></name>
</person-group> (<year>1968</year>). <article-title>Data analysis, including statistics</article-title>. In <person-group person-group-type="editor">
<name><surname>Lindzey</surname><given-names>G.</given-names></name>
<name><surname>Aronson</surname><given-names>E.</given-names></name>
</person-group> (Eds.), <source>Handbook of social psychology</source> (<edition>2nd ed.</edition>, Vol. <volume>2</volume>, pp. <fpage>80</fpage>-<lpage>203</lpage>). <publisher-loc>Reading, MA</publisher-loc>: <publisher-name>Addison-Wesley</publisher-name>.</citation>
</ref>
<ref id="bibr24-0013164411429821">
<citation citation-type="web">
<collab>Organization for Economic Co-operation and Development</collab>. (<year>2005</year>). <source>Society at a glance: OECD social indicators—2005 Edition</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.oecd.org/dataoecd/34/13/34542721.xls">http://www.oecd.org/dataoecd/34/13/34542721.xls</ext-link></comment></citation>
</ref>
<ref id="bibr25-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pena</surname><given-names>D.</given-names></name>
<name><surname>Prieto</surname><given-names>F. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Multivariate outlier detection and robust covariance matrix estimation</article-title>. <source>Technometrics</source>, <volume>43</volume>, <fpage>286</fpage>-<lpage>310</lpage>.</citation>
</ref>
<ref id="bibr26-0013164411429821">
<citation citation-type="book">
<collab>SPSS Inc</collab>. (<year>2009</year>). <source>PASW STATISTICS 17.0 command syntax reference</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr27-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tukey</surname><given-names>J. W.</given-names></name>
</person-group> (<year>1962</year>). <article-title>The future of data analysis</article-title>. <source>Annals of Mathematical Statistics</source>, <volume>3</volume>, <fpage>1</fpage>-<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr28-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Velicer</surname><given-names>W.</given-names></name>
</person-group> (<year>1976</year>). <article-title>Determining the number of components from the matrix of partial correlations</article-title>. <source>Psychometrika</source>, <volume>41</volume>, <fpage>321</fpage>-<lpage>327</lpage>.</citation>
</ref>
<ref id="bibr29-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Watkins</surname><given-names>D. S.</given-names></name>
</person-group> (<year>2010</year>). <source>Fundamentals of matrix computations</source> (<edition>3rd ed.</edition>). <publisher-loc>Pullman, MA</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr30-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wilcox</surname><given-names>R. R.</given-names></name>
</person-group> (<year>2010</year>). <source>Fundamentals of modern statistical methods: Substantially improving power and accuracy</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr31-0013164411429821">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wilcox</surname><given-names>R. R.</given-names></name>
</person-group> (<year>in press</year>). <source>Modern statistics for the social and behavioral sciences: A practical introduction</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Chapman &amp; Hall/CRC Press</publisher-name>.</citation>
</ref>
<ref id="bibr32-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yuan</surname><given-names>K. H.</given-names></name>
<name><surname>Marshall</surname><given-names>L. L.</given-names></name>
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
</person-group> (<year>2002</year>). <article-title>A unified approach to exploratory factor analysis with missing data, nonnormal data, and in the presence of outliers</article-title>. <source>Psychometrika</source>, <volume>67</volume>, <fpage>95</fpage>-<lpage>122</lpage>.</citation>
</ref>
<ref id="bibr33-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
<name><surname>Jennings</surname><given-names>M.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The robustness of validity and efficiency of the related samples t-test in the presence of outliers</article-title>. <source>Psicologica</source>, <volume>23</volume>, <fpage>415</fpage>-<lpage>450</lpage>.</citation>
</ref>
<ref id="bibr34-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
<name><surname>Zimmerman</surname><given-names>D. W.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Is the selection of statistical methods governed by level of measurement?</article-title> <source>Canadian Psychology</source>, <volume>34</volume>, <fpage>390</fpage>-<lpage>400</lpage>.</citation>
</ref>
<ref id="bibr35-0013164411429821">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zwick</surname><given-names>W. R.</given-names></name>
<name><surname>Velicer</surname><given-names>W. F.</given-names></name>
</person-group> (<year>1986</year>). <article-title>Comparison of 5 rules for determining the number of components to retain</article-title>. <source>Psychological Bulletin</source>, <volume>99</volume>, <fpage>432</fpage>-<lpage>442</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>