<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSS</journal-id>
<journal-id journal-id-type="hwp">sppss</journal-id>
<journal-id journal-id-type="nlm-ta">Psychol Sci</journal-id>
<journal-title>Psychological Science</journal-title>
<issn pub-type="ppub">0956-7976</issn>
<issn pub-type="epub">1467-9280</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0956797612438732</article-id>
<article-id pub-id-type="publisher-id">10.1177_0956797612438732</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Role of Socioeconomic Status in SAT-Grade Relationships and in College Admissions Decisions</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Sackett</surname><given-names>Paul R.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Kuncel</surname><given-names>Nathan R.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Beatty</surname><given-names>Adam S.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Rigdon</surname><given-names>Jana L.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Shen</surname><given-names>Winny</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Kiger</surname><given-names>Thomas B.</given-names></name>
</contrib>
<aff id="aff1-0956797612438732">University of Minnesota</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0956797612438732">Paul R. Sackett, University of Minnesota, Elliott Hall, 75 E. River Rd., Minneapolis, MN 55455 E-mail: <email>psackett@umn.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2012</year>
</pub-date>
<volume>23</volume>
<issue>9</issue>
<fpage>1000</fpage>
<lpage>1007</lpage>
<history>
<date date-type="received">
<day>31</day>
<month>5</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>3</day>
<month>1</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>This article examines the role of socioeconomic status (SES) in the relationships among college admissions-test scores, secondary school grades, and subsequent academic performance. Scores on the SAT (a test widely used in the admissions process in the United States), secondary school grades, college grades, and SES measures from 143,606 students at 110 colleges and universities were examined, and results of these analyses were compared with results obtained using a 41-school data set including scores from the prior version of the SAT and using University of California data from prior research on the role of SES. In all the data sets, the SAT showed incremental validity over secondary school grades in predicting subsequent academic performance, and this incremental relationship was not substantially affected by controlling for SES. The SES of enrolled students was very similar to that of specific schools’ applicant pools, which suggests that the barrier to college for low-SES students in the United States is a lower rate of entering the college admissions process, rather than exclusion on the part of colleges.</p>
</abstract>
<kwd-group>
<kwd>educational measurement</kwd>
<kwd>individual differences</kwd>
<kwd>socioeconomic status</kwd>
<kwd>test validity</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Access to a college or university education is a scarce resource. The college admissions systems of different countries fall into three main categories. First, some systems use a test focusing on a common set of topics for all test takers. The use of the SAT (with Critical Reading, Mathematics, and Writing subtests) and ACT (with English, Reading, Mathematics, and Science subtests) in the United States illustrates this model, as do testing systems in countries such as Israel, Pakistan, Russia, Turkey, and South Korea. Second, some countries have test-based systems that focus on achievement in specific topics, with students choosing the topics on which to focus. The British A-levels and the French baccalauréat exemplify this approach. Finally, other systems do not use tests, but rely primarily on performance in secondary school (e.g., Australian Tertiary Admissions Record system).</p>
<p>The U.S.-based tests are administered worldwide, as many international students wish to pursue postsecondary education in the United States. Thus, there is broad interest in tests of the type used in the United States. Admissions tests are commonly used in conjunction with a variety of other sources of information, with secondary school performance the most prominent. In the U.S. educational system, secondary school is termed <italic>high school</italic> and typically involves 4 years of study between the ages of 14 and 18. The relative emphasis on test scores, high school performance, and other factors varies by college or university.</p>
<p>Concern about access to postsecondary education for differing segments of the population is widespread. Given societal goals of broad access to educational opportunities, understanding the roles played by family socioeconomic status (SES) and standardized tests in the admissions process is of interest both as a scientific issue and as an issue of social policy. Whereas college admissions tests have extensive research support as predictors of subsequent academic performance (e.g., <xref ref-type="bibr" rid="bibr8-0956797612438732">Hezlett et al., 2001</xref>; <xref ref-type="bibr" rid="bibr11-0956797612438732">Noble &amp; Sawyer, 2002</xref>; <xref ref-type="bibr" rid="bibr13-0956797612438732">Sackett, Kuncel, Arneson, Cooper, &amp; Waters, 2009</xref>), the role of SES in college admissions remains the focus of considerable attention. Indeed, prominent critics of the SAT have asserted that University of California data show that the incremental power of the SAT in predicting college performance, over and above the predictive power of high school grade point average (GPA), is “decisively diminished” (<xref ref-type="bibr" rid="bibr1-0956797612438732">Atkinson, 2009</xref>) or “significantly reduced” (<xref ref-type="bibr" rid="bibr2-0956797612438732">Atkinson &amp; Geiser, 2009</xref>, p. 673) once SES is taken into consideration; prompted by such concern, the University of California system has questioned its continued use of the SAT.</p>
<p>Here, we examine two critical questions about the role of SES in the college admissions process. The first is whether the incremental validity of the SAT in predicting subsequent academic performance above and beyond the level of predictive accuracy obtained using high school GPA is substantially reduced once SES is controlled. We present results using the current SAT in a data set of 110 colleges and universities and then compare these results with findings from two historical data sets, one including scores on the prior version of the SAT and the other comprising University of California data.</p>
<p>Other studies have examined related issues. <xref ref-type="bibr" rid="bibr12-0956797612438732">Rothstein (2004)</xref> reported that the contribution of SAT scores to the prediction of academic performance was reduced when a broad set of demographic variables, including race and demographic characteristics of the high school a student attended, were controlled. However, Rothstein did not include measures of SES at the individual student level. <xref ref-type="bibr" rid="bibr4-0956797612438732">Bowen, Chingos, and McPherson (2009)</xref> reported that the small relationship between SAT scores and college graduation is reduced further when SES is controlled. <xref ref-type="bibr" rid="bibr7-0956797612438732">Geiser and Studley (2002)</xref> simultaneously added scores on another test (the SAT II), as well as SES, to models using SAT scores and high school GPA to predict performance, so it is not possible to determine whether the observed effects of adding these predictors were due to SAT II scores or to SES. Our study differs from these in focusing on the possible role of the SES of the individual student in influencing the contribution of SAT scores to the prediction of subsequent college grades.</p>
<p>The second question concerns the effect of admissions systems on the SES distribution of college enrollees. There are multiple mechanisms that might limit college access for low-SES students. First, students with lower SES are less likely to enter into the college admissions process (e.g., <xref ref-type="bibr" rid="bibr5-0956797612438732">Cabrera &amp; La Nasa, 2000</xref>; <xref ref-type="bibr" rid="bibr9-0956797612438732">Hossler, Schmit, &amp; Vesper, 1999</xref>; <xref ref-type="bibr" rid="bibr15-0956797612438732">Walpole, 2003</xref>). Second, colleges may have an implicit or explicit bias against low-SES students, and thus use SES as part of the admissions process. Third, factors commonly considered in the admissions process, such as admissions-test scores, are correlated with SES, and heavy reliance on these factors may result in limiting access for low-SES students. <xref ref-type="bibr" rid="bibr13-0956797612438732">Sackett et al. (2009)</xref> reported a correlation of .42 between SAT scores and SES among the population of SAT takers; exclusive reliance on SAT scores in admissions would limit access for low-SES students.</p>
<p>To shed light on the role of SES in the admissions process, we compared the variability of SES in the applicant pool for each school with the SES variability in the group of enrolled students. The extent to which SES variability was reduced in the enrolled group relative to the applicant group was our index of the degree to which the admissions process restricts access on the basis of SES.</p>
<sec id="section1-0956797612438732" sec-type="methods">
<title>Method</title>
<sec id="section2-0956797612438732">
<title>2006 revised-SAT data set</title>
<p>In collaboration with 110 U.S. colleges and universities, the College Board collected information on revised-SAT scores, high school GPA, SES, and freshman college grades from the students entering each institution in 2006. The schools were selected, on the basis of a sampling plan, to be geographically diverse, to include large and small schools, to include public and private institutions, and to cover a broad range of school selectivity. The 110 schools included 63 private and 47 public institutions. Freshman class size averaged 1,305.5 (<italic>SD</italic> = 1,286.5) and ranged from 106 to 6,462. The mean high school GPA (the traditional scale from 0 to 4, with extra credit for Advanced Placement and honors courses) among entering students across the 110 schools was 3.56 (<italic>SD</italic> = 0.24), and the mean school-specific high school GPA ranged from 2.86 to 4.05. The mean SAT total score (i.e., Critical Reading + Math + Writing) across schools was 1676.5 (<italic>SD</italic> = 181.8), and the mean school-specific SAT score ranged from 1281.2 to 2157.3 (scores can range from 600 to 2400). Our primary analyses are based on data from those students for whom the data set included an SES measure, in addition to SAT scores and high school and college GPAs; this subset consisted of 143,606 cases. These primary analyses relied on students’ self-reported high school GPAs. We also conducted a secondary set of analyses based on high school GPAs provided by the colleges and universities. School-reported GPAs were available from 49 of the 110 colleges and universities, with the number of students totaling 60,361.</p>
<sec id="section3-0956797612438732">
<title>Test scores</title>
<p>Critical Reading (CR), Math (M), and Writing (W) scores on the revised SAT were obtained from College Board records. We combined these scores into a unit-weighted composite: CR + M + W.</p>
</sec>
<sec id="section4-0956797612438732">
<title>SES</title>
<p>Three SES variables were obtained from questionnaires completed by students at the time they took the SAT: father’s education, mother’s education, and family income. The natural log of family income was used. In the entire national population of SAT takers, the correlation between the two parent’s education variables was .60; father’s and mother’s education correlated .42 and .39, respectively, with family income. Following other research on this topic (e.g., <xref ref-type="bibr" rid="bibr13-0956797612438732">Sackett et al., 2009</xref>), we created an equally weighted composite of these three variables.</p>
</sec>
<sec id="section5-0956797612438732">
<title>Freshman GPA</title>
<p>Freshman (i.e., 1st-year) GPA was provided by the colleges and universities.</p>
</sec>
<sec id="section6-0956797612438732">
<title>Self-reported high school GPA</title>
<p>Self-reported high school GPA was obtained from the students’ SAT questionnaires.</p>
</sec>
<sec id="section7-0956797612438732">
<title>College-reported high school GPA</title>
<p>A subset of individual colleges and universities provided students’ high school GPAs from their own records. Self- and school-reported high school GPA can differ for multiple reasons. For example, students may forget or misreport their GPAs. Also, postsecondary schools may recompute enrollees’ high school GPAs, using students’ transcripts and including only grades for a specified set of classes (e.g., core academic subjects). In our data, self-reported and school-reported high school GPA correlated .75; a meta-analysis of self- and school-reported high school GPA by <xref ref-type="bibr" rid="bibr10-0956797612438732">Kuncel, Crede, and Thomas (2005)</xref> reported a mean <italic>r</italic> of .82.</p>
</sec>
</sec>
<sec id="section8-0956797612438732">
<title>1995–1997 SAT data set</title>
<p>As already mentioned, we compared results obtained using the 2006 data set with those obtained using an earlier data set in which the SAT scores were from the version of the test in use prior to the 2005 revision. The earlier data set, including 136,725 students from cohorts entering 41 schools in 1995 through 1997, is structurally similar to the 2006 data set in terms of the variables included. In the 1995–1997 data set, the SAT total score was a combination of Verbal (renamed Critical Reading in the 2005 revision) and Math scores, as the Writing test was added in the 2005 revision. Details about the data set (e.g., means, standard deviations, and intercorrelations) can be found in <xref ref-type="bibr" rid="bibr13-0956797612438732">Sackett et al. (2009)</xref>.</p>
</sec>
<sec id="section9-0956797612438732">
<title>Analyses</title>
<p>For the 2006 data set, we sought to obtain data on the applicant population in order to correct correlations among SAT scores, high school GPA, freshman GPA, and SES for range restriction. Restricted variance in enrolled students, due to the use of the SAT and high school GPA in admissions decisions, results in a lower test-grade correlation than would be found if the relationship were examined in applicant samples (<xref ref-type="bibr" rid="bibr14-0956797612438732">Sackett &amp; Yang, 2000</xref>).</p>
<p>The additional data needed to correct for multivariate range restriction are the unrestricted means, standard deviations, and correlations among the variables. We used two separate sources of information for this purpose. First, we obtained means, standard deviations, and correlations for SAT scores, self-reported high school GPA, and SES among the entire population of individuals who took the SAT and completed a questionnaire reporting SES in 2006 (more than 1.25 million students). Second, we estimated the means, standard deviations, and correlations for these same variables in the applicant pool for each specific college or university. To do this, we needed a reasonable proxy for each school-specific applicant pool. When students take the SAT, they indicate the schools to which they wish their scores be sent; we used the set of students who asked that their scores be sent to a given school as our estimate of the applicant pool for that school (a strategy also used by <xref ref-type="bibr" rid="bibr13-0956797612438732">Sackett et al., 2009</xref>).</p>
<p>Correcting for range restriction using each college’s applicant pool estimated how well SAT score and high school GPA predicted freshman GPA across that college’s applicant pool. Correcting for range restriction using the entire population of SAT takers estimated how well SAT score and high school GPA predicted freshman GPA in the population of test takers. We present both types of correction for comparison purposes.</p>
<p>To examine the SAT composite as a predictor of freshman GPA when used in conjunction with high school GPA and SES in the 2006 data set, we looked at a series of regression models. In Model 1, SAT score was the only predictor, and in Model 2, high school GPA was the only predictor. Model 3 included both SAT score and high school GPA, and Model 4 added SES. These models were examined separately for each of the 110 schools, and sample-size-weighted mean standardized regression coefficients and squared multiple correlations were computed. These four models were also examined in the subset of 49 schools for which school-reported high school GPA was available and in the 1995–1997 data set with scores from the previous version of the SAT.</p>
<p>To investigate the degree to which the admissions process restricts access for low-SES students, we examined SAT, high school GPA, and SES means and variances among applicants and enrolled students separately at each school. If a school preferentially selected students with higher SES, the SES variance would be substantially reduced in the enrolled group.</p>
</sec>
</sec>
<sec id="section10-0956797612438732" sec-type="results">
<title>Results</title>
<p><xref ref-type="table" rid="table1-0956797612438732">Table 1</xref> presents sample-size-weighted mean correlations between study variables across the schools in the 2006 and 1995–1997 data sets. <xref ref-type="table" rid="table2-0956797612438732">Table 2</xref> presents results for the regression models for the 2006 revised-SAT data set; <xref ref-type="fig" rid="fig1-0956797612438732">Figure 1</xref> presents the results graphically. We first discuss observed relationships, prior to correction for restriction of range. In Model 1, SAT score alone had a mean regression weight of 0.35. In Model 2, high school GPA alone had a mean regression weight of 0.37. When SAT and high school GPA were both included, in Model 3, the resulting regression weights were 0.30 for high school GPA and 0.27 for SAT score. The squared multiple correlation of .21 for Model 3 was higher than was found using either SAT score alone (.13) or high school GPA alone (.14).</p>
<table-wrap id="table1-0956797612438732" position="float">
<label>Table 1.</label>
<caption><p>Sample-Size-Weighted Correlations From the 2006 and 1995–1997 Data Sets</p></caption>
<graphic alternate-form-of="table1-0956797612438732" xlink:href="10.1177_0956797612438732-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Variable</th>
<th align="center">SAT score</th>
<th align="center">Self-reported high school GPA</th>
<th align="center">SES composite</th>
<th align="center">Freshman GPA</th>
</tr>
</thead>
<tbody>
<tr>
<td>SAT score</td>
<td>—</td>
<td>.31</td>
<td>.22</td>
<td>.35</td>
</tr>
<tr>
<td>Self-reported high school GPA</td>
<td>.27</td>
<td>—</td>
<td>−.01</td>
<td>.40</td>
</tr>
<tr>
<td>SES composite</td>
<td>.25</td>
<td>.00</td>
<td>—</td>
<td>.12</td>
</tr>
<tr>
<td>Freshman GPA</td>
<td>.35</td>
<td>.37</td>
<td>.13</td>
<td>—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0956797612438732">
<p>Note: Correlations above the diagonal are from the 1995–1997 data set (<italic>K</italic> = 41, <italic>N</italic> = 136,725), and correlations below the diagonal are from the 2006 data set (<italic>K</italic> = 110, <italic>N</italic> = 143,606). SAT score was the total score from the Verbal and Math subtests for the 1995–1997 data set and from the Critical Reading, Math, and Writing subtests for the 2006 data set. GPA = grade point average; SES (socioeconomic status) composite = unit-weighted composite of father’s education, mother’s education, and log parental income.</p></fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table2-0956797612438732" position="float">
<label>Table 2.</label>
<caption><p>SAT Score, Self-Reported High School Grade Point Average (GPA), and Socioeconomic Status (SES) as Predictors of Freshman GPA: 2006 Data</p></caption>
<graphic alternate-form-of="table2-0956797612438732" xlink:href="10.1177_0956797612438732-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="3">β<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center"><italic>R</italic><sup>2</sup></th>
<th align="center">SAT</th>
<th align="center">High school GPA</th>
<th align="center">SES</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="5">Observed data</td>
</tr>
<tr>
<td> Model 1: SAT alone</td>
<td>.127</td>
<td>0.349</td>
<td/>
<td/>
</tr>
<tr>
<td> Model 2: high school GPA alone</td>
<td>.139</td>
<td/>
<td>0.366</td>
<td/>
</tr>
<tr>
<td> Model 3: SAT + high school GPA</td>
<td>.211</td>
<td>0.265</td>
<td>0.300</td>
<td/>
</tr>
<tr>
<td> Model 4: SAT + high school GPA + SES</td>
<td>.216</td>
<td>0.246</td>
<td>0.302</td>
<td>0.068</td>
</tr>
<tr>
<td colspan="5">School-applicant-pool corrected data</td>
</tr>
<tr>
<td> Model 1: SAT alone</td>
<td>.218</td>
<td>0.460</td>
<td/>
<td/>
</tr>
<tr>
<td> Model 2: high school GPA alone</td>
<td>.223</td>
<td/>
<td>0.468</td>
<td/>
</tr>
<tr>
<td> Model 3: SAT + high school GPA</td>
<td>.312</td>
<td>0.316</td>
<td>0.334</td>
<td/>
</tr>
<tr>
<td> Model 4: SAT + high school GPA + SES</td>
<td>.318</td>
<td>0.286</td>
<td>0.339</td>
<td>0.072</td>
</tr>
<tr>
<td colspan="5">National-population corrected data</td>
</tr>
<tr>
<td> Model 1: SAT alone</td>
<td>.300</td>
<td>0.534</td>
<td/>
<td/>
</tr>
<tr>
<td> Model 2: high school GPA alone</td>
<td>.306</td>
<td/>
<td>0.550</td>
<td/>
</tr>
<tr>
<td> Model 3: SAT + high school GPA</td>
<td>.400</td>
<td>0.347</td>
<td>0.370</td>
<td/>
</tr>
<tr>
<td> Model 4: SAT + high school GPA + SES</td>
<td>.405</td>
<td>0.315</td>
<td>0.374</td>
<td>0.066</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0956797612438732">
<p>Note: The values in the table are means across 110 schools (<italic>N</italic> = 143,606).</p></fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig1-0956797612438732" position="float">
<label>Fig. 1.</label>
<caption><p>SAT score, high school grade point average (GPA), and socioeconomic status (SES) as predictors of freshman GPA in the 2006 data set. Results are shown for Model 1, in which SAT score was the only predictor; Model 2, in which high school GPA was the only predictor; Model 3, which included both SAT score and high school GPA; and Model 4, which added SES. The lower graph presents standardized regression coefficients, and the upper graph presents the <italic>R</italic><sup>2</sup> values for all four models. Both observed results and results corrected for school-specific range restriction are shown.</p></caption>
<graphic xlink:href="10.1177_0956797612438732-fig1.tif"/>
</fig>
<p>These findings are consistent with prior literature in three respects. First, secondary school performance is generally found to be a slightly better predictor of academic performance than are admissions-test scores (<xref ref-type="bibr" rid="bibr16-0956797612438732">Zwick, 2002</xref>). Second, when SAT score and high school GPA are used in conjunction, the regression coefficient for each is smaller than when each is used alone, a result reflecting the shared variance between the two. Third, using the two predictors together produces a meaningful increment in predictive power over using either individually.</p>
<p>Finally, Model 4 included SAT score, high school GPA, and SES simultaneously. The addition of SES to the model reduced the SAT coefficient only slightly: from 0.27 to 0.25. In other words, SAT score retained the vast majority of its predictive power when SES was added to the model. In addition, adding SES increased the overall predictive power of the model by about 1% of the variance. This is consistent with the comparatively weak relationship between SES and freshman grades (<italic>r</italic> = .13 in the present data). Thus, SAT score and high school GPA together remained useful predictors of academic performance when SES was controlled.</p>
<p>The observed values represent relationships in the samples of enrolled students, whereas the question of interest concerns the relationships in the school-specific applicant pools and the national SAT-taking population. On average, the standard deviation for SAT score among enrolled students at a given school was 18% smaller than the standard deviation among applicants to that school, a reduction reflecting the selection process used by the school, as well as any SAT-related self-selection in accepting admission offers. <xref ref-type="table" rid="table2-0956797612438732">Table 2</xref> includes regression coefficients and squared multiple correlations corrected for range restriction at both the school-specific applicant-pool and national applicant-pool levels; <xref ref-type="fig" rid="fig1-0956797612438732">Figure 1</xref> shows the school-specific corrected values only (in the interest of ease of presentation). Although the regression coefficients and squared multiple correlations were, as expected, higher after correction for range restriction, the pattern of results paralleled that for the observed data.</p>
<p>The same four models were examined in the 49-school subset for which school-reported high school GPA was available. As school-reported high school GPA was available only for admitted students, correction for restriction of range was not possible. These results are presented in <xref ref-type="table" rid="table3-0956797612438732">Table 3</xref>. Several key findings obtained using self-reported high school GPA continued to hold: Using high school GPA and SAT score in conjunction produced a higher squared multiple correlation than using either one alone, and adding SES had minimal effects on the regression coefficients for SAT score and high school GPA. Note, though, that the regression weights for high school GPA were higher using school reports than self-reports, and that the predictive advantage of high school GPA over SAT score was greater using the school-reported data.</p>
<table-wrap id="table3-0956797612438732" position="float">
<label>Table 3.</label>
<caption><p>SAT Score, School-Reported High School Grade Point Average (GPA), and Socioeconomic Status (SES) as Predictors of Freshman GPA: 2006 Data</p></caption>
<graphic alternate-form-of="table3-0956797612438732" xlink:href="10.1177_0956797612438732-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="3">β<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center"><italic>R</italic><sup>2</sup></th>
<th align="center">SAT</th>
<th align="center">High school GPA</th>
<th align="center">SES</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model 1: SAT alone</td>
<td>.129</td>
<td>0.352</td>
<td/>
<td/>
</tr>
<tr>
<td>Model 2: high school GPA alone</td>
<td>.220</td>
<td/>
<td>0.465</td>
<td/>
</tr>
<tr>
<td>Model 3: SAT + high school GPA</td>
<td>.275</td>
<td>0.230</td>
<td>0.399</td>
<td/>
</tr>
<tr>
<td>Model 4: SAT + high school GPA + SES</td>
<td>.280</td>
<td>0.211</td>
<td>0.405</td>
<td>0.070</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0956797612438732">
<p>Note: The values in the table are means across 49 schools (<italic>N</italic> = 60,361).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>These four models were also examined in the 1995–1997 data set with scores from the previous version of the SAT. The results (see <xref ref-type="table" rid="table4-0956797612438732">Table 4</xref>), based on observed data without correction for range restriction, closely parallel those obtained with the revised SAT. Thus, neither the 2006 data nor the 1995–1997 data offer evidence that controlling for SES will substantially reduce the incremental predictive validity of SAT score above and beyond high school GPA.</p>
<table-wrap id="table4-0956797612438732" position="float">
<label>Table 4.</label>
<caption><p>SAT Score, Self-Reported High School Grade Point Average (GPA), and Socioeconomic Status (SES) as Predictors of Freshman GPA: 1995–1997 Data</p></caption>
<graphic alternate-form-of="table4-0956797612438732" xlink:href="10.1177_0956797612438732-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="3">β<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center"><italic>R</italic><sup>2</sup></th>
<th align="center">SAT</th>
<th align="center">High school GPA</th>
<th align="center">SES</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model 1: SAT alone</td>
<td>.132</td>
<td>0.355</td>
<td/>
<td/>
</tr>
<tr>
<td>Model 2: high school GPA alone</td>
<td>.164</td>
<td/>
<td>0.401</td>
<td/>
</tr>
<tr>
<td>Model 3: SAT + high school GPA</td>
<td>.229</td>
<td>0.255</td>
<td>0.325</td>
<td/>
</tr>
<tr>
<td>Model 4: SAT + high school GPA + SES</td>
<td>.235</td>
<td>0.236</td>
<td>0.332</td>
<td>0.076</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0956797612438732">
<p>Note: The values in the table are means across 41 schools (<italic>N</italic> = 136,725).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>We now turn to the University of California data set, which includes about 78,000 entering students at eight of the University of California campuses between 1996 and 1999. We drew from supporting materials (<xref ref-type="bibr" rid="bibr6-0956797612438732">Geiser &amp; Studley, 2001</xref>) from a study of these data to create close analogues to the four models we examined for the previous data sets. The approach taken by <xref ref-type="bibr" rid="bibr6-0956797612438732">Geiser and Studley (2001</xref>, <xref ref-type="bibr" rid="bibr7-0956797612438732">2002)</xref> in their analyses of the University of California data differs from our approach with the College Board data in two respects. First, <xref ref-type="bibr" rid="bibr7-0956797612438732">Geiser and Studley (2002)</xref> aggregated data across the eight University of California campuses, whereas we analyzed each school’s data separately and then averaged the results. Second, Geiser and Studley included parental income and parental education as two separate variables, whereas we used a composite of parental income, mother’s education, and father’s education in the College Board data (though keeping the three separate did not discernibly affect our findings). In our analyses of the College Board data, adding SES to the model involved adding this composite; in Geiser and Studley’s analyses of the University of California data, adding SES involved adding the two SES indicators. The high school GPA measure in the University of California data was school reported and used a weighting formula that gave extra points for honors courses; thus, it was more comparable to the school-reported than to the self-reported high school GPA measure we used in analyzing the 2006 College Board data.</p>
<p><xref ref-type="table" rid="table5-0956797612438732">Table 5</xref> includes a summary of results for the University of California data (Models 1–4 plus two additional models). Findings closely followed those for the 2006 and 1995–1997 data. For comparison here, we focus on the 2006 data using school-reported high school GPA. In Model 1, SAT I (the traditional SAT) score alone had a coefficient of 0.37 (vs. 0.35 in the 2006 data set). Including both SAT score and high school GPA reduced the coefficients for both, with the SAT coefficient taking a value of 0.25 (vs. 0.23 in the 2006 data set). Adding SES to the model reduced the SAT coefficient to 0.22 (vs. 0.21 in the 2006 data set). Thus, in both the University of California data and the 2006 data, SAT score retained the vast majority of its predictive power above and beyond high school GPA even after SES was added to the model.</p>
<table-wrap id="table5-0956797612438732" position="float">
<label>Table 5.</label>
<caption><p>SAT I Score, SAT II Score, High School Grade Point Average (GPA), and Socioeconomic Status as Predictors of Freshman GPA: University of California data</p></caption>
<graphic alternate-form-of="table5-0956797612438732" xlink:href="10.1177_0956797612438732-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="5">β<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center"><italic>R</italic><sup>2</sup></th>
<th align="center">SAT I</th>
<th align="center">High school GPA</th>
<th align="center">Parental education</th>
<th align="center">Log income</th>
<th align="center">SAT II</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model 1: SAT I alone</td>
<td>.133</td>
<td>0.365</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Model 2: high school GPA alone</td>
<td>.154</td>
<td/>
<td>0.393</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Model 3: SAT I + high school GPA</td>
<td>.208</td>
<td>0.251</td>
<td>0.296</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Model 4: SAT I + high school GPA + parental education + log income</td>
<td>.212</td>
<td>0.216</td>
<td>0.304</td>
<td>0.031</td>
<td>0.031</td>
<td/>
</tr>
<tr>
<td>Model 5: SAT I + high school GPA + parental education + log income + SAT II</td>
<td>.228</td>
<td>0.022</td>
<td>0.28</td>
<td>0.061</td>
<td>0.034</td>
<td>0.238</td>
</tr>
<tr>
<td>Model 6: SAT I + high school GPA + SAT II</td>
<td>.222</td>
<td>0.068</td>
<td>0.273</td>
<td/>
<td/>
<td>0.227</td>
</tr>
</tbody>
</table>
</table-wrap>
<p><xref ref-type="bibr" rid="bibr1-0956797612438732">Atkinson (2009)</xref> and <xref ref-type="bibr" rid="bibr2-0956797612438732">Atkinson and Geiser (2009)</xref> relied on <xref ref-type="bibr" rid="bibr6-0956797612438732">Geiser and Studley’s (2001)</xref> work in asserting that adding SES substantially reduces the SAT coefficient. However, it is important to consider that Geiser and Studley did not add SES by itself to the model including SAT and high school GPA; rather, they also added composite score on the SAT II (scores on three achievement scales: writing, mathematics, and a third subject of the student’s choosing). Thus, they focused on what we include in <xref ref-type="table" rid="table5-0956797612438732">Table 5</xref> as Model 5. In this model, the SAT I coefficient did indeed drop to near zero (i.e., 0.02). But it would be incorrect to infer from these results that it was the addition of SES that caused the SAT I coefficient to drop. As Model 4 shows, adding SES alone did not reduce the SAT I coefficient. For added clarity, we also include in <xref ref-type="table" rid="table5-0956797612438732">Table 5</xref> the results for a Model 6, which ignored SES completely and added SAT II score to a model including SAT I score and high school GPA. This model showed that adding SAT II score reduced the SAT I coefficient from 0.25 to 0.07. So it was the addition of SAT II score, not SES, that drove the reduction in the SAT I coefficient in Geiser and Studley’s study.</p>
<p>Turning to the effects of the admissions process on the distribution of SES in enrolled students, we compared the SES of applicants and enrolled students. In the 2006 data on 110 schools, the mean SES among enrolled students was only 0.126 standard deviations higher than the mean SES in the school-specific applicant pools. Similarly, the standard deviation of SES among enrolled students was, on average, only 3% smaller than the standard deviation among applicants. Both of these findings are contrary to what would be found if proxies for SES were the sole or primary determinant of admissions, or if schools had a per se preference for high-SES students. If either were the case, mean SES among enrollees would be much higher than the mean in the applicant pool, and the standard deviation for enrollees would be much smaller than the standard deviation in the applicant pool. It is useful to contrast this analysis with similar analyses for SAT scores and high school grades. Although the standard deviation of SES among enrolled students averaged only 3% less than the standard deviation in the applicant pool, the enrolled students’ standard deviations for SAT score and high school grades averaged 20% and 18% less than the standard deviations in the applicant pool. Note that there was variability from school to school in the difference in mean SES between applicants and enrolled students, with some schools showing greater differences than others. These differences tended to be larger in more selective schools: There was a correlation of –.39 between the percentage of applicants admitted and the difference in mean SES between applicants and enrolled students.</p>
</sec>
<sec id="section11-0956797612438732" sec-type="discussion">
<title>Discussion</title>
<p>The finding that SAT scores provide incremental validity in predicting freshman grades, beyond the predictive validity contributed by high school grades, and that this is true even when controlling for SES supports the usefulness of the SAT for predicting first-year academic performance. Although it will take time for relationships between the revised SAT and longer-term academic performance to be observed, it is useful to note that, contrary to the popular assertion that tests like the SAT predict nothing but freshman grades, extensive research documents the relationship between test scores and academic performance throughout the curriculum (<xref ref-type="bibr" rid="bibr3-0956797612438732">Berry &amp; Sackett, 2009</xref>; <xref ref-type="bibr" rid="bibr8-0956797612438732">Hezlett et al., 2001</xref>).</p>
<p>Although it is not the case that test validity is an artifact of SES, SES is linked to the development of abilities that are predictive of academic performance. In the 2006 national population of test takers, the correlation between SES and composite SAT score was .46. Therefore, 21.2% of variance in SAT scores is shared with SES, as measured here as a composite of mother’s education, father’s education, and parental income. Thus, SAT scores are by no means isomorphic with SES, although the source of the SES-SAT relationship is likely due to some combination of educational opportunity, school quality, peer effects, and other social factors.</p>
<p>The finding that SES variability was only 3% smaller among enrolled students than in the applicant pool has important consequences that challenge the popular notion that U.S. college selection systems actively screen out low-SES students. An admissions policy that relied heavily or exclusively on the SAT would indeed screen out low-SES students at a higher rate than high-SES students. However, the data from the 110 schools suggest that in the typical U.S. school, SES does not play a primary exclusionary role in the admissions process. Thus, once students are in the applicant pool for a given school, the school typically does not substantially restrict entry on the basis of SES. Although low-SES students are less likely to enroll in college, this appears to be a function of differences in the rates at which high- and low-SES students choose to enter the college application process, rather than of exclusion on the part of colleges.</p>
<p>The present study focused on one widely used U.S-based admissions test. Although our study did include a broad range of colleges, it was nonetheless limited to U.S. colleges. Each of the major findings merits investigation in other settings. The strength of the relationship between admissions-test scores and SES, for example, could vary from country to country as a function of the degree to which the quality of available education is linked to SES. Similarly, the finding that SES affects the decision to enter the application process to a greater degree than it affects admissions decisions by colleges may not hold in all countries. Thus, we present these findings as providing a basis for research comparing the role of SES in other settings.</p>
<p>In sum, large multi-institution data sets show that (a) the SAT retains the vast majority of its weight in predicting subsequent college grades when high school GPA and SES are controlled, (b) the bivariate relationship between SAT score and freshman GPA is not substantially reduced when SES is controlled, and (c) implicitly, given these two findings, it is not the case that the SAT is nothing more than a proxy for SES. An additional important finding is that the SES distribution of enrolled students at a college closely resembles the distribution of applicants to that college, which indicates that the barrier to college for low-SES students in the United States is far more a matter of factors that affect the decision to enter the college application process than of exclusionary admissions decisions on the part of colleges.</p>
</sec>
</body>
<back>
<ack>
<p>This research used data provided by the College Board (copyright 2006–2007, The College Board, <ext-link ext-link-type="uri" xlink:href="http://www.collegeboard.com">http://www.collegeboard.com</ext-link>).</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>Paul R. Sackett serves as a research adviser to the College Board, and this research was supported by a grant from the College Board to Paul R. Sackett and Nathan R. Kuncel. Beyond this, the authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p></fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0956797612438732">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Atkinson</surname><given-names>R. C.</given-names></name>
</person-group> (<year>2009</year>, <month>April</month>). <article-title>The new SAT: A test at war with itself</article-title>. <conf-name>Paper presented at the annual meeting of the American Educational Research Association</conf-name>, <conf-loc>San Diego, CA</conf-loc>.</citation>
</ref>
<ref id="bibr2-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Atkinson</surname><given-names>R. C.</given-names></name>
<name><surname>Geiser</surname><given-names>S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Reflections on a century of college admissions tests</article-title>. <source>Educational Researcher</source>, <volume>38</volume>, <fpage>665</fpage>–<lpage>676</lpage>.</citation>
</ref>
<ref id="bibr3-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Berry</surname><given-names>C. M.</given-names></name>
<name><surname>Sackett</surname><given-names>P. R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Individual differences in course choice result in underestimation of the validity of college admissions systems</article-title>. <source>Psychological Science</source>, <volume>20</volume>, <fpage>822</fpage>–<lpage>830</lpage>.</citation>
</ref>
<ref id="bibr4-0956797612438732">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bowen</surname><given-names>W.</given-names></name>
<name><surname>Chingos</surname><given-names>M.</given-names></name>
<name><surname>McPherson</surname><given-names>M.</given-names></name>
</person-group> (<year>2009</year>). <source>Crossing the finish line: Completing college at America’s public universities</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr5-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cabrera</surname><given-names>A. F.</given-names></name>
<name><surname>La Nasa</surname><given-names>S. M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Understanding the college choice process</article-title>. <source>New Directions for Institutional Research</source>, <volume>107</volume>, <fpage>5</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr6-0956797612438732">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Geiser</surname><given-names>S.</given-names></name>
<name><surname>Studley</surname><given-names>R.</given-names></name>
</person-group> (<year>2001</year>). <source>Supporting documents for UC and the SAT: Predictive validity and differential impact of the SAT I and SAT II at the University of California</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ucop.edu/sas/research/researchandplanning/supporting.htm">http://www.ucop.edu/sas/research/researchandplanning/supporting.htm</ext-link></comment></citation>
</ref>
<ref id="bibr7-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Geiser</surname><given-names>S.</given-names></name>
<name><surname>Studley</surname><given-names>R.</given-names></name>
</person-group> (<year>2002</year>). <article-title>UC and the SAT: Predictive validity and differential impact of the SAT I and SAT II at the University of California</article-title>. <source>Educational Assessment</source>, <volume>8</volume>, <fpage>1</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr8-0956797612438732">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Hezlett</surname><given-names>S. A.</given-names></name>
<name><surname>Kuncel</surname><given-names>N. R.</given-names></name>
<name><surname>Vey</surname><given-names>M. A.</given-names></name>
<name><surname>Ahart</surname><given-names>A. M.</given-names></name>
<name><surname>Ones</surname><given-names>D. S.</given-names></name>
<name><surname>Campbell</surname><given-names>J. P.</given-names></name>
<name><surname>Camara</surname><given-names>W.</given-names></name>
</person-group> (<year>2001</year>, <month>April</month>). <source>The effectiveness of the SAT in predicting success early and late in college: A comprehensive meta-analysis</source>. <conf-name>Paper presented at the annual meeting of the National Council on Measurement in Education</conf-name>, <conf-loc>Seattle, WA</conf-loc>.</citation>
</ref>
<ref id="bibr9-0956797612438732">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hossler</surname><given-names>D.</given-names></name>
<name><surname>Schmit</surname><given-names>J.</given-names></name>
<name><surname>Vesper</surname><given-names>N.</given-names></name>
</person-group> (<year>1999</year>). <source>Going to college: How social, economic, and educational factors influence the decisions students make</source>. <publisher-loc>Baltimore, MD</publisher-loc>: <publisher-name>Johns Hopkins University Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kuncel</surname><given-names>N. R.</given-names></name>
<name><surname>Crede</surname><given-names>M.</given-names></name>
<name><surname>Thomas</surname><given-names>L. T.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The validity of self-reported grade point averages, class ranks, and test scores: A meta-analysis and review of the literature</article-title>. <source>Review of Educational Research</source>, <volume>75</volume>, <fpage>63</fpage>–<lpage>82</lpage>.</citation>
</ref>
<ref id="bibr11-0956797612438732">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Noble</surname><given-names>J.</given-names></name>
<name><surname>Sawyer</surname><given-names>R.</given-names></name>
</person-group> (<year>2002</year>). <source>Predicting different levels of academic success in college using high school GPA and ACT composite score</source> (<comment>ACT Research Report Series No. 2002-4</comment>). <publisher-loc>Iowa City, IA</publisher-loc>: <publisher-name>ACT</publisher-name>.</citation>
</ref>
<ref id="bibr12-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rothstein</surname><given-names>J.</given-names></name>
</person-group> (<year>2004</year>). <article-title>College performance predictions and the SAT</article-title>. <source>Journal of Econometrics</source>, <volume>121</volume>, <fpage>297</fpage>–<lpage>317</lpage>.</citation>
</ref>
<ref id="bibr13-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sackett</surname><given-names>P. R.</given-names></name>
<name><surname>Kuncel</surname><given-names>N. R.</given-names></name>
<name><surname>Arneson</surname><given-names>J. J.</given-names></name>
<name><surname>Cooper</surname><given-names>S. R.</given-names></name>
<name><surname>Waters</surname><given-names>S. D.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Does socioeconomic status explain the relationship between admissions tests and post-secondary academic performance?</article-title> <source>Psychological Bulletin</source>, <volume>135</volume>, <fpage>1</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr14-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sackett</surname><given-names>P. R.</given-names></name>
<name><surname>Yang</surname><given-names>H.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Correcting for range restriction: An expanded typology</article-title>. <source>Journal of Applied Psychology</source>, <volume>85</volume>, <fpage>112</fpage>–<lpage>118</lpage>.</citation>
</ref>
<ref id="bibr15-0956797612438732">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walpole</surname><given-names>M.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Socioeconomic status and college: How SES affects college experiences and outcomes</article-title>. <source>The Review of Higher Education</source>, <volume>27</volume>, <fpage>45</fpage>–<lpage>73</lpage>.</citation>
</ref>
<ref id="bibr16-0956797612438732">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Zwick</surname><given-names>R.</given-names></name>
</person-group> (<year>2002</year>). <source>Fair game? The use of standardized admissions tests in higher education</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>RoutledgeFalmer</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>