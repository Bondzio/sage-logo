<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JEB</journal-id>
<journal-id journal-id-type="hwp">spjeb</journal-id>
<journal-title>Journal of Educational and Behavioral Statistics</journal-title>
<issn pub-type="ppub">1076-9986</issn>
<issn pub-type="epub">1935-1054</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.3102/1076998611435413</article-id>
<article-id pub-id-type="publisher-id">10.3102_1076998611435413</article-id>
<title-group>
<article-title>Contrasting OLS and Quantile Regression Approaches to Student “Growth” Percentiles</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Castellano</surname>
<given-names>Katherine Elizabeth</given-names>
</name>
<aff id="aff1-1076998611435413">University of Iowa</aff>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ho</surname>
<given-names>Andrew Dean</given-names>
</name>
<aff id="aff2-1076998611435413">Harvard Graduate School of Education</aff>
</contrib>
<bio>
<title>Authors</title>
<p>KATHERINE ELIZABETH CASTELLANO is a postdoctoral fellow at the University of California, Berkeley, CA; e-mail: <email>kcastel@berkeley.edu</email>. She was at the University of Iowa when she co-wrote this article. Her research interests involve the application of statistical models to educational policy issues, such as the use of the growth models in accountability systems.</p>
<p>ANDREW DEAN HO is an assistant professor at the Harvard Graduate School of Education, Gutman Library, Cambridge, MA; e-mail: <email>Andrew_Ho@gse.harvard.edu</email>. His research interests are in developing and applying statistical and psychometric methods to improve high-stakes educational accountability metrics.</p>
</bio>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2013</year>
</pub-date>
<volume>38</volume>
<issue>2</issue>
<fpage>190</fpage>
<lpage>215</lpage>
<history>
<date date-type="received">
<day>14</day>
<month>7</month>
<year>2011</year>
</date>
<date date-type="rev-recd">
<day>19</day>
<month>10</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>1</day>
<month>12</month>
<year>2011</year>
</date>
</history>
<permissions>
<copyright-statement>© 2012 AERA</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">American Educational Research Association</copyright-holder>
</permissions>
<abstract>
<p>Regression methods can locate student test scores in a conditional distribution, given past scores. This article contrasts and clarifies two approaches to describing these locations in terms of readily interpretable percentile ranks or “conditional status percentile ranks.” The first is Betebenner’s quantile regression approach that results in “Student Growth Percentiles.” The second is an ordinary least squares (OLS) regression approach that involves expressing OLS regression residuals as percentile ranks. The study describes the empirical and conceptual similarity of the two metrics in simulated and real-data scenarios. The metrics contrast in their scale-transformation invariance and sample size requirements but are comparable in their dependence on the number of prior years used as conditioning variables. These results support guidelines for selecting the model that best fits the data and have implications for the interpretations of these percentiles ranks as “growth” measures.</p>
</abstract>
<kwd-group>
<kwd>student growth percentiles</kwd>
<kwd>growth</kwd>
<kwd>conditional status</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Federal funding priorities and state-level initiatives have led to a dramatic increase in the number and sophistication of longitudinal data systems that track individual student test scores over time (<xref ref-type="bibr" rid="bibr17-1076998611435413">Data Quality Campaign, 2010</xref>; <xref ref-type="bibr" rid="bibr35-1076998611435413">United States Department of Education, 2009</xref>). These data systems support the modeling of students’ current scores as functions of their previous scores. In large-scale educational accountability systems, these types of models can support three different types of inferences. The first type of inference attributes variance in student outcomes to teachers, schools, and other predictive variables in an approach sometimes called value-added modeling (e.g., <xref ref-type="bibr" rid="bibr29-1076998611435413">McCaffrey, Lockwood, Koretz, Louis, &amp; Hamilton, 2004</xref>). The second type of inference makes predictions about future student status, given past scores in an approach sometimes called a prediction or projection model (e.g., <xref ref-type="bibr" rid="bibr23-1076998611435413">Hoffer et al., 2011</xref>; <xref ref-type="bibr" rid="bibr37-1076998611435413">Wright, Sanders, &amp; Rivers, 2006</xref>). The third type of inference expresses current student status in terms of its location in a conditional distribution, given past scores (e.g., <xref ref-type="bibr" rid="bibr4-1076998611435413">Betebenner, 2008</xref>).</p>
<p>This article focuses on the third type of inference. It contrasts two different regression-based metrics that support conditional status interpretations. The first is <xref ref-type="bibr" rid="bibr4-1076998611435413">Betebenner’s (2008</xref>, <xref ref-type="bibr" rid="bibr5-1076998611435413">2009</xref>) Student Growth Percentile (SGP) that uses quantile regression (<xref ref-type="bibr" rid="bibr24-1076998611435413">Koenker, 2005</xref>) to express conditional status in terms of conditional quantiles. Twelve states have adopted or are adopting this metric for reporting, and 13 other states are considering adoption (<xref ref-type="bibr" rid="bibr6-1076998611435413">Betebenner, 2010a</xref>). A second, somewhat ad hoc approach expresses the residuals from an ordinary least squares (OLS) regression of current status on past scores as percentile ranks. This metric is described accurately as the “percentile rank of a residual” (PRR). PRRs are a re-expression of “residual change” or “residual gain scores” that have been a topic of considerable research in their own right (<xref ref-type="bibr" rid="bibr16-1076998611435413">Cronbach &amp; Furby, 1970</xref>; <xref ref-type="bibr" rid="bibr26-1076998611435413">Manning &amp; DuBois, 1962</xref>; <xref ref-type="bibr" rid="bibr33-1076998611435413">Rogosa, Brandt, &amp; Zimowski, 1982</xref>; <xref ref-type="bibr" rid="bibr36-1076998611435413">Williams, Maresh, &amp; Peebles, 1972</xref>).</p>
<p>The following section introduces SGPs and PRRs and reviews the relevant literature. The subsequent sections compare the two metrics and evaluate them in terms of recovering benchmark percentiles and variability under scale transformations. In the concluding section, we review the findings in terms of guidelines for large-scale reporting.</p>
<sec id="section1-1076998611435413">
<title>Conditional Status Percentile Ranks</title>
<p>SGPs and PRRs are “Conditional Status Percentile Ranks” (CSPRs) that describe a student’s current status conditional on the student’s past scores as a percentile rank. SGPs estimate conditional percentile ranks explicitly, whereas PRRs “re-express” residuals as percentile ranks in the distribution of residuals. Two of the three words in the SGP acronym are potentially misleading. First, SGPs are not percentiles that would be reported on a score scale but percentile ranks that take on values from 1 to 99. Second, SGPs do not describe “growth” as much as conditional status, as the developer of the metric has noted (<xref ref-type="bibr" rid="bibr9-1076998611435413">Betebenner, 2011b</xref>). We return to a discussion of SGPs and PRRs with respect to growth in the final section, but the distinction is a multipredictor extension of the well-known differences between gain scores and residual difference scores described by <xref ref-type="bibr" rid="bibr16-1076998611435413">Cronbach and Furby (1970</xref>), <xref ref-type="bibr" rid="bibr32-1076998611435413">Rogosa (1995</xref>), <xref ref-type="bibr" rid="bibr38-1076998611435413">Zumbo (1999</xref>), and many others. Whether or not CSPRs support growth inferences, we evaluate them first on their merits as what they are most literally.</p>
<p>The regression framework supporting CSPRs is agnostic to the substantive meaning of the outcome and predictors. In practice, SGPs use the “current” grade as the outcome and the available prior grade scores as predictors or conditioning variables. We initially restrict our attention to this application and use terms like “outcome” and “predictor” interchangeably with “current grade” and “prior grade,” respectively. We discuss the practical consequences arising from the flexibility of these methods to variable selection in the conclusion.</p>
<sec id="section2-1076998611435413">
<title>Student Growth Percentiles</title>
<p>SGPs use a quantile regression model to estimate expected quantiles, given previous test scores. As OLS regression estimates the mean of <italic>Y</italic> given <bold>
<italic>X</italic>
</bold>, quantile regression estimates quantiles of <italic>Y</italic> given <bold>
<italic>X</italic>
</bold>. In practice, SGPs define <italic>Y</italic> as the current grade-level test score and <bold>
<italic>X</italic>
</bold> as the set of past grade-level test scores. The operational derivation of SGPs involves estimating 100 quantile regression lines, surfaces, or hypersurfaces (for 1, 2, or &gt;2 prior years of data, respectively) from .005 to .995 in increments of .01. This is documented in <xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner’s (2010b)</xref> “SGP” computing package for estimating SGPs in the statistical software program R (<xref ref-type="bibr" rid="bibr31-1076998611435413">R Development Core Team, 2009</xref>).</p>
<p>We use Q<sub>τ</sub>(<italic>Y</italic>|<italic>
<bold>X</bold>
</italic>) to denote the τth conditional quantile for the current achievement score, <italic>Y</italic>, given a vector of prior year achievement scores of length <italic>J</italic>, <italic>
<bold>X</bold> = X<sub>1</sub>,X<sub>2</sub>,…,X<sub>J</sub>
</italic>. In the computation of SGPs, <xref ref-type="bibr" rid="bibr5-1076998611435413">Betebenner (2009</xref>) uses B-spline parameterizations instead of linear parameterizations to accommodate nonlinearity and heteroscedasticity in the test score data. B-splines require the specification of the polynomial degree and the number and locations of knots. The B-spline approach is well reviewed by introductory texts such as <xref ref-type="bibr" rid="bibr18-1076998611435413">de Boor (2001</xref>) and <xref ref-type="bibr" rid="bibr34-1076998611435413">Schumaker (2007</xref>). Here, we review the spline specifications most common for operational SGP estimation (<xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner, 2010b</xref>).</p>
<p>
<xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner’s (2010b)</xref> default “SGP” code in R specifies cubic (third degree) B-splines and four interior knots for each prior year, corresponding to the .2, .4, .6, and .8 quantiles of each of the prior grade level’s test scores. Alternatively, the most recent version of the “SGP” package (<xref ref-type="bibr" rid="bibr10-1076998611435413">Betebenner, 2011c</xref>) allows states to save the .2, .4, .6, and .8 quantiles of a large multicohort data set as “reference” knots for use in all subsequent derivations of SGPs. The latter approach favors knot stability over time but may change fit characteristics, especially if distributions shift substantially over time. A full exploration of the sensitivity of SGPs to spline parameterization is beyond the scope of this study, although preliminary work suggests that as few or fewer knots and degrees used in default SGP estimation can suffice in simulations (<xref ref-type="bibr" rid="bibr30-1076998611435413">Moses, 2010</xref>). The default “SGP” code (<xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner, 2010b</xref>) also sets the two exterior knots for each prior year as the maximum and minimum score extended outward by 10% of the range of the test scores. With these specifications, the τth conditional quantile can be expressed as a linear combination of seven cubic B-spline basis functions per prior year:<disp-formula id="disp-formula1-1076998611435413">
<label>1</label>
<mml:math id="mml-disp1-1076998611435413">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">Q</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi mathvariant="italic">τ</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">X</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">α</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">+</mml:mo>
<mml:munderover>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>J</mml:mi>
</mml:munderover>
<mml:munderover>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mn>7</mml:mn>
</mml:munderover>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">β</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">ϕ</mml:mi>
<mml:mrow>
<mml:mi>h</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula1-1076998611435413" xlink:href="10.3102_1076998611435413-eq1.tif"/>
</disp-formula>
</p>
<p>where ϕ<sub>
<italic>hj</italic>
</sub>(<italic>X<sub>j</sub>
</italic>) denotes the <italic>h</italic>th cubic B-spline basis function for prior year <italic>j</italic> as a function of <italic>X<sub>j</sub>
</italic>. The 7∗<italic>J</italic>β<sub>
<italic>hj</italic>
</sub> coefficients are the B-spline control points to be estimated, and α is the intercept. The notation in <xref ref-type="disp-formula" rid="disp-formula1-1076998611435413">Equation 1</xref> differs slightly from <xref ref-type="bibr" rid="bibr24-1076998611435413">Koenker (2005</xref>) and <xref ref-type="bibr" rid="bibr5-1076998611435413">Betebenner (2009</xref>) to emphasize upcoming contrasts. We refer the reader to <xref ref-type="bibr" rid="bibr24-1076998611435413">Koenker (2005</xref>) for a more detailed discussion of quantile regression in general and to <xref ref-type="bibr" rid="bibr5-1076998611435413">Betebenner (2009</xref>) for quantile regression-based SGPs in particular.</p>
<p>The SGP for student <italic>i</italic> is operationally defined as the midpoint between the ranks of the fitted conditional quantiles that border the student’s observed current score, <italic>y = y<sub>i</sub>
</italic> (<xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner, 2010b</xref>):<disp-formula id="disp-formula2-1076998611435413">
<label>2</label>
<mml:math id="mml-disp2-1076998611435413">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">G</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo form="prefix" movablelimits="true">max</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">τ</mml:mi>
<mml:mo stretchy="false">;</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="normal">Q</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mi mathvariant="italic">τ</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mo form="prefix" movablelimits="true">min</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">τ</mml:mi>
<mml:mo stretchy="false">;</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="normal">Q</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mi mathvariant="italic">τ</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">×</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>100</mml:mn>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula2-1076998611435413" xlink:href="10.3102_1076998611435413-eq2.tif"/>
</disp-formula>
</p>
<p>where <bold>
<italic>x</italic>
</bold>
<italic>
<sub>i</sub>
</italic> is student <italic>i</italic>’s vector of prior observed scores. For instance, a student with an observed current score that lies between her fitted value for the τ = .495 and τ = .505 regression surfaces receives an SGP of 50.</p>
<p>A final adjustment prior to operational SGP assignment is the uncrossing of conditional quantile surfaces. Crossed surfaces are a known complication of nonparametric quantile regression, where the theoretical monotonicity of conditional quantiles over τ does not hold (<xref ref-type="bibr" rid="bibr19-1076998611435413">Dette &amp; Volgushev, 2008</xref>; <xref ref-type="bibr" rid="bibr24-1076998611435413">Koenker, 2005</xref>). The default “SGP” code (<xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner, 2010b</xref>) uncrosses conditional quantiles by rank ordering them by <inline-formula id="inline-formula8-1076998611435413">
<mml:math id="mml-inline8-1076998611435413">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Q</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi mathvariant="italic">τ</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> and reassociating the 100 τ levels consecutively to this rank order. This has no effect when <inline-formula id="inline-formula10-1076998611435413">
<mml:math id="mml-inline10-1076998611435413">
<mml:msub>
<mml:mover accent="true">
<mml:mi>Q</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi mathvariant="italic">τ</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> is monotonic over τ but “switches” quantile associations to ensure monotonicity when quantile surfaces cross. The adjustment for crossing is illustrated in <xref ref-type="fig" rid="fig1-1076998611435413">Figure 1</xref> using an empirical data set of bivariate (<italic>J</italic> = 1) test scores. The figure uses conditional boxplots to show the empirical distributions of current year scores, given each score point in the previous year. <xref ref-type="fig" rid="fig1-1076998611435413">Figure 1</xref> overlays quantile regression splines for the 5th, 50th, and 95th conditional percentiles with solid curves and shows the adjustment for uncrossing with dashed curves. Although the differences seem notable at the extremes, uncrossing has an impact on few students in practice (<xref ref-type="bibr" rid="bibr14-1076998611435413">Colorado Department of Education, 2009a</xref>).</p>
<fig id="fig1-1076998611435413" position="float">
<label>Figure 1.</label>
<caption>
<p>Illustration of the contrast among the 5th, 50th, and 95th quantile regression splines before and after adjustments for crossing and the ordinary least squares (OLS) percentile Ranks of Residuals (PRRs) lines for the 5th, 50th, and 95th quantiles using bivariate empirical data displayed with conditional boxplots of current status on initial status.</p>
</caption>
<graphic alternate-form-of="fig1-1076998611435413" xlink:href="10.3102_1076998611435413-fig1.tif"/>
</fig>
<p>SGPs are described as having several advantageous properties: They do not require a vertical scale, are robust to outliers, and are invariant to monotonic transformations of the test scale (e.g., <xref ref-type="bibr" rid="bibr8-1076998611435413">Betebenner, 2011a</xref>). We characterize these as propositions worthy of clarification and empirical investigation. SGPs do not require a vertical scale to support inferences about conditional status but may require a vertical scale to support growth inferences. Median (least absolute value) regression is more robust to outliers than OLS regression (<xref ref-type="bibr" rid="bibr24-1076998611435413">Koenker, 2005</xref>), but SGPs also require estimation of extreme conditional quantiles, and these may be affected by outliers. Moreover, the B-spline parameterizations of the quantile regression lines fit the data without parametric assumptions, which can increase the fit to the sample, including outliers, at the expense of the fit to the population. Similarly, although quantile regression should be more invariant under transformations than linear regression, it only has the property of being strictly invariant under transformations of the outcome variable and not the predictor variables (<xref ref-type="bibr" rid="bibr24-1076998611435413">Koenker, 2005</xref>).</p>
<p>A small but growing literature has investigated these properties of SGPs. <xref ref-type="bibr" rid="bibr11-1076998611435413">Briggs and Betebenner (2009</xref>) investigated the scale invariance of SGPs at the aggregate level. They found that median SGPs were nearly perfectly correlated under transformations of the score scale that resulted in linear and nonlinear growth over time. However, the authors did not supplement these correlations with difference statistics that are arguably more relevant than correlations, nor did they describe differences at the individual level.</p>
<p>Other explorations investigate bias and variance in terms of “true” percentile ranks under various sample sizes and covariate inclusion decisions. <xref ref-type="bibr" rid="bibr22-1076998611435413">Grady, Lewis, and Gao (2010</xref>) investigated SGP recovery of benchmark CSPRs across sample sizes ranging from 250 to 10,000. They defined benchmark CSPRs as empirical CSPRs—the percentile rank of a student’s current status within conditional distributions of students with the exact same previous scores—obtained with the largest sample size. They evaluated SGP recovery of these benchmarks for sample sizes subsetted from the large empirical data set. This method of empirically defining a student’s benchmark percentile is problematic for three reasons. First, there is no a priori justification for the status of a full sample as a population. Inability to recover the benchmark percentiles from subsamples may be explained as a natural consequence of a different reference group or as a particular characteristic of the empirical sample. Second, empirical CSPRs are derived using empirical conditional distributions and thus require large samples for stable estimates. <xref ref-type="bibr" rid="bibr22-1076998611435413">Grady et al. (2010</xref>) thus used only a single prior year of data so as to obtain conditional distributions with reasonable <italic>n</italic> counts. Third, the small numbers of score points in empirical conditional distributions will limit empirical CSPRs to certain values in each conditional distribution. This will lead to discrepancies from SGPs reported on a 99-point integer scale. In an upcoming section, we propose an alternative method for defining benchmark CSPRs that uses population generating distributions with known conditional distributions, allowing multiple prior years of data.</p>
<p>We add to the literature on SGPs by investigating their recovery of benchmark CSPRs under formal distributional assumptions, their invariance to scale transformations, and their variance over varying the number of prior years of test score data included. The findings are elucidated by a useful contrast to a CSPR derived from the familiar OLS framework or a PRR.</p>
</sec>
<sec id="section3-1076998611435413">
<title>Percentile Ranks of Residuals</title>
<p>PRRs require estimation of a single line, plane, or hyperplane representing the conditional mean. This contrasts with the estimation of 100 manifolds in the SGP approach. PRRs involve first regressing the current grade-level score for a particular subject area (<italic>Y</italic>) on the past <italic>J </italic>grade-level assessment scores in that subject (<italic>X = X<sub>1</sub>, X<sub>2</sub>, … X<sub>J</sub>
</italic>) using the familiar multiple regression equation:<disp-formula id="disp-formula3-1076998611435413">
<label>3</label>
<mml:math id="mml-disp3-1076998611435413">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">μ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:munderover>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>J</mml:mi>
</mml:munderover>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-1076998611435413" xlink:href="10.3102_1076998611435413-eq3.tif"/>
</disp-formula>
</p>
<p>in which α is the intercept and β<italic>j</italic> denotes the <italic>j</italic>th regression coefficient. The target of inference, μ<sub>
<italic>Y</italic>|<italic>
<bold>X</bold>
</italic>
</sub>, contrasts with the targets of quantile regression, Q<sub>τ</sub>(<italic>Y</italic>|<italic>
<bold>X</bold>
</italic>), and the model is noticeably simpler. The estimated conditional mean score, given past achievement, is denoted <inline-formula id="inline-formula16-1076998611435413">
<mml:math id="mml-inline16-1076998611435413">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> and is estimated with sample intercept and slope statistics, <inline-formula id="inline-formula17-1076998611435413">
<mml:math id="mml-inline17-1076998611435413">
<mml:mover accent="true">
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula18-1076998611435413">
<mml:math id="mml-inline18-1076998611435413">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>’s, respectively. The residuals, or simple differences between observed and expected current achievement scores, <inline-formula id="inline-formula19-1076998611435413">
<mml:math id="mml-inline19-1076998611435413">
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>, are computed for each student, rank ordered, and expressed as a percentile rank as follows:<disp-formula id="disp-formula4-1076998611435413">
<label>4</label>
<mml:math id="mml-disp4-1076998611435413">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi mathvariant="normal">#</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mtext mathvariant="normal"> </mml:mtext>
<mml:mi mathvariant="normal">r</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
<mml:mi mathvariant="normal">s</mml:mi>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">d</mml:mi>
<mml:mi mathvariant="normal">u</mml:mi>
<mml:mi mathvariant="normal">a</mml:mi>
<mml:mi mathvariant="normal">l</mml:mi>
<mml:mi mathvariant="normal">s</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">≤</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula4-1076998611435413" xlink:href="10.3102_1076998611435413-eq4.tif"/>
</disp-formula>
</p>
<p>where PRR<italic>
<sub>i</sub>
</italic> represents the <italic>i</italic>th student’s PRR, <italic>e<sub>i</sub>
</italic> represents the <italic>i</italic>th residual, <italic>F</italic>() denotes the empirical cumulative distribution function of the residuals, <italic>i</italic> = 1, 2,…, <italic>n</italic>, and <italic>n</italic> represents the sample size.</p>
<p>Researchers have used percentile ranks of residuals to support conditional status interpretations in a range of fields, from educational accountability (<xref ref-type="bibr" rid="bibr21-1076998611435413">Fetler, 1991</xref>) to childhood obesity (<xref ref-type="bibr" rid="bibr20-1076998611435413">Ellis, Abrams, &amp; Wong, 1999</xref>). One refinement to the metric uses studentized residuals, a reasonable approach that inflates higher leverage residuals in accordance with their expected standard deviation. The inflation factor is negligible for large testing data sets and does not change the conclusions presented here, so, for clarity of description, we report results for percentile ranks of raw residuals. A second refinement applies inverse normal transformations to studentized residuals, assuming that studentized residuals have a standard normal distribution. We find this assumption unnecessary.</p>
<p>A third refinement calculates residuals and expresses them as percentile ranks within a conditional distribution of <bold>
<italic>X</italic>
</bold>. At its extreme, that is, looking at distributions of students who have the exact same prior scores, all students within each conditional distribution will have the same <inline-formula id="inline-formula20-1076998611435413">
<mml:math id="mml-inline20-1076998611435413">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>, so this approach does not differ from computing empirical CSPRs. The sizes of these empirical conditional distributions are far too small to support stable percentile estimates, particularly as the number of prior years increases. This approach sets a nonparametric extreme with no assumptions, one that SGPs moderate with nonparametric B-splines, and PRRs contrast further with parametric OLS regression.</p>
<p>
<xref ref-type="fig" rid="fig1-1076998611435413">Figure 1</xref>, which shows the adjustment for crossing quantile regression splines, also illustrates the contrast between the quantile regression–based SGPs and OLS regression–based PRRs with the same empirical data set. PRRs can be displayed conveniently on the same plot by computing the OLS residuals, finding their percentiles, and then adding these percentiles to the OLS regression line. The thin, solid gray lines in <xref ref-type="fig" rid="fig1-1076998611435413">Figure 1</xref> correspond to the PRRs of 5, 50, and 95. These conditional percentiles are most similar with the corresponding SGPs at the center of the bivariate distribution, where there is a higher concentration of data and the conditional distributions are roughly symmetric. At either extreme of the Time 1 score distribution, the differences between the two approaches are more apparent.</p>
<p>Despite the differences in the derivations of SGPs and PRRs, PRRs share some of the properties of SGPs. Like SGPs, vertical scales are not necessary for the use of PRRs for conditional status interpretations. However, OLS regression has known sensitivity to nonlinear scale transformations that can alter linear relationships and diminish model fit. The transformation sensitivity of PRRs has not been established and serves as a useful benchmark to the sensitivity of SGPs. In the following sections, this article establishes the comparability of SGPs and PRRs, investigates their recovery of benchmark CSPRs under distributional assumptions, assesses their transformation dependence, and determines the extent that they are affected by the number of prior years included in the models.</p>
</sec>
</sec>
<sec id="section4-1076998611435413">
<title>Comparability of SGPs and PRRs</title>
<p>We begin by describing the empirical comparability of SGPs and PRRs in simulated and real-data scenarios. The empirical data sets consist of two statewide data files with matched, longitudinal student achievement data. The states contrast usefully in size and scaling procedures. Their identities are not relevant to the findings and are referred to as “State A” and “State B.” The State A data set contains longitudinally matched reading and mathematics scores for a single cohort of about 25,000 students from vertically scaled tests from Grade 3 (2004–2005) to Grade 6 (2007–2008). The State B data set contains longitudinally matched reading and mathematics scores for a single cohort of about 75,000 students from Grade 3 (2002–2003) to Grade 6 (2005–2006) within-grade scaled tests.</p>
<p>To evaluate whether the comparability of SGPs and PRRs depends on the number of prior years included, we selectively withhold data to create <italic>J = </italic>1, 2, and 3 prior-year data sets. In each case, we hold Grade 6 constant as the “current year” and condition on the immediately prior 1, 2, and 3 years, respectively. The data sets are limited to students with complete records for all 4 years of interest (i.e., Grade 3 to Grade 6). Trajectories with missing data are not likely to substantially bias these particular findings and are beyond the scope of this article.</p>
<p>The simulated data sets in this comparability analysis are generated from multivariate normal (MVN) distributions. Multivariate normality is a convenient choice for modeling joint distributions of consecutive grade-level test scores, as test scales are often chosen so that each grade-level score distribution is roughly normal (<xref ref-type="bibr" rid="bibr25-1076998611435413">Kolen &amp; Brennan, 2004</xref>). A subsequent analysis generates explicitly nonnormal distributions to evaluate properties of the SGPs and PRRs when OLS assumptions do not hold, but we begin with familiar generating distributions. We construct the simulated data sets by first generating 1,000 data sets of size <italic>n </italic>= 10,000 with 4 years of test score data (i.e., <italic>J </italic>= 3) from an MVN distribution, nominally representing data from Grade 3 to Grade 6. These MVN distributions are parameterized by the mean vector, variance vector, and correlation matrix supplied in <xref ref-type="table" rid="table1-1076998611435413">Table 1</xref>. These parameters reflect a constant variance pattern and roughly mimic the summary statistics of the State B distribution as shown in <xref ref-type="table" rid="table1-1076998611435413">Table 1</xref>.</p>
<table-wrap id="table1-1076998611435413" position="float">
<label>Table 1</label>
<caption>
<p>Correlations, Variances, and Means for the Empirical and Simulated Data</p>
</caption>
<graphic alternate-form-of="table1-1076998611435413" xlink:href="10.3102_1076998611435413-table1.tif"/>
<table>
<thead>
<tr>
<th>Grade</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>Variance</th>
<th>
<italic>M</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="7">1—State A<sup>a</sup>
</td>
</tr>
<tr>
<td> 3</td>
<td>
</td>
<td>.76</td>
<td>.74</td>
<td>.73</td>
<td>541</td>
<td>187</td>
</tr>
<tr>
<td> 4</td>
<td>.79</td>
<td>
</td>
<td>.77</td>
<td>.77</td>
<td>728</td>
<td>207</td>
</tr>
<tr>
<td> 5</td>
<td>.78</td>
<td>.83</td>
<td>
</td>
<td>.79</td>
<td>838</td>
<td>223</td>
</tr>
<tr>
<td> 6</td>
<td>.76</td>
<td>.81</td>
<td>.84</td>
<td>
</td>
<td>1034</td>
<td>230</td>
</tr>
<tr>
<td> Variance</td>
<td align="center">339</td>
<td align="center">492</td>
<td align="center">668</td>
<td align="center">842</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td> <italic>M</italic>
</td>
<td align="center">184</td>
<td align="center">205</td>
<td align="center">222</td>
<td align="center">235</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="7">2—State B<sup>a</sup>
</td>
</tr>
<tr>
<td> 3</td>
<td>
</td>
<td>.78</td>
<td>.76</td>
<td>.75</td>
<td>71</td>
<td>249</td>
</tr>
<tr>
<td> 4</td>
<td>.82</td>
<td>
</td>
<td>.79</td>
<td>.78</td>
<td>67</td>
<td>253</td>
</tr>
<tr>
<td> 5</td>
<td>.80</td>
<td>.84</td>
<td>
</td>
<td>.80</td>
<td>55</td>
<td>258</td>
</tr>
<tr>
<td> 6</td>
<td>.77</td>
<td>.81</td>
<td>.84</td>
<td>
</td>
<td>59</td>
<td>260</td>
</tr>
<tr>
<td> Variance</td>
<td align="center">36</td>
<td align="center">52</td>
<td align="center">86</td>
<td align="center">90</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td> <italic>M</italic>
</td>
<td align="center">254</td>
<td align="center">260</td>
<td align="center">263</td>
<td align="center">356</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="7">3—Simulated Multivariate Normal Data</td>
</tr>
<tr>
<td> 3</td>
<td>1.00</td>
<td>0.78</td>
<td>0.76</td>
<td>0.74</td>
<td>65</td>
<td>250</td>
</tr>
<tr>
<td> 4</td>
<td>
</td>
<td>1.00</td>
<td>0.78</td>
<td>0.76</td>
<td>65</td>
<td>255</td>
</tr>
<tr>
<td> 5</td>
<td>
</td>
<td>
</td>
<td>1.00</td>
<td>0.78</td>
<td>65</td>
<td>260</td>
</tr>
<tr>
<td> 6</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>1.00</td>
<td>65</td>
<td>265</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1076998611435413">
<p>
<sup>a</sup>The statistics for the reading data sets are above the diagonal and those for the mathematics data sets are below the diagonal.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>We investigate SGP and PRR comparability over varying sample sizes (<italic>n </italic>= 250, 1,000, 5,000, and 10,000) and numbers of prior years (<italic>J</italic> = 1, 2, and 3). We chose the sample size levels to span a range from small schools or districts to a small state. For the 1,000 MVN data sets, we randomly subset row-wise to create data sets with the three smaller sample sizes (<italic>n</italic> = 250, 1,000, and 5,000) and subset column-wise to create data sets with fewer prior years (<italic>J</italic> = 1 and 2). This subsetting was done for convenience, and conclusions do not differ when regenerating random data sets each time. In total, there are 1,000 Replications × 3 Prior Year Levels × 4 Sample Sizes to yield 12,000 simulated data sets.</p>
<p>For each empirical and simulated data set, we estimate every student’s SGP and PRR value using the statistical computing package R (<xref ref-type="bibr" rid="bibr31-1076998611435413">R Development Core Team, 2009</xref>). We compute the SGPs with <xref ref-type="bibr" rid="bibr7-1076998611435413">Betebenner’s (2010b)</xref> R function “studentGrowthPercentiles” in his “SGP” package. Using the default arguments would produce SGPs corresponding to integer values from 1 to 99. To reduce the influence of rounding and to obtain finer grain comparisons with PRRs, we alter the code to estimate 1,000 conditional quantiles instead of 100, from .0005 to .9995 in increments of .001. This results in SGPs rounded to one decimal place from 0 to 100. For comparability, PRRs are also rounded to one decimal place and are easily computed with OLS regression functions in R.</p>
<p>
<xref ref-type="table" rid="table2-1076998611435413">Table 2</xref> summarizes the comparability of SGPs and PRRs for the 12 empirical data sets (2 States × 2 Subjects × 3 Prior Year Levels). It includes Pearson correlations, root mean square differences (RMSDs), and percentages of absolute differences within <italic>k</italic> units, <italic>k</italic> = 1, 5, and 10, denoted, (%Diff)<italic>
<sub>k</sub>
</italic>. The latter two statistics are defined as follows:<table-wrap id="table2-1076998611435413" position="float">
<label>Table 2</label>
<caption>
<p>Statistics Summarizing the Comparability of Student Growth Percentiles and Percentile Ranks of Residuals for Data From Two States and Two Subjects</p>
</caption>
<graphic alternate-form-of="table2-1076998611435413" xlink:href="10.3102_1076998611435413-table2.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th colspan="3">Percentage of Differences Within <italic>k</italic> Units</th>
</tr>
<tr>
<th>
</th>
<th>Prior Years</th>
<th>Correlation</th>
<th>RMSD</th>
<th>
<italic>k </italic>= 1</th>
<th>
<italic>k </italic>= 5</th>
<th>
<italic>k </italic>= 10</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="3">State A Reading</td>
<td>1</td>
<td>.9912</td>
<td>3.84</td>
<td>22.45</td>
<td>84.18</td>
<td>98.73</td>
</tr>
<tr>
<td>2</td>
<td>.9950</td>
<td>2.89</td>
<td>30.72</td>
<td>92.50</td>
<td>99.51</td>
</tr>
<tr>
<td>3</td>
<td>.9945</td>
<td>3.02</td>
<td>32.01</td>
<td>91.70</td>
<td>99.44</td>
</tr>
<tr>
<td rowspan="3">State A Math</td>
<td>1</td>
<td>.9972</td>
<td>2.15</td>
<td>48.51</td>
<td>98.67</td>
<td>99.77</td>
</tr>
<tr>
<td>2</td>
<td>.9967</td>
<td>2.34</td>
<td>45.48</td>
<td>98.06</td>
<td>99.64</td>
</tr>
<tr>
<td>3</td>
<td>.9965</td>
<td>2.40</td>
<td>44.77</td>
<td>97.46</td>
<td>99.49</td>
</tr>
<tr>
<td rowspan="3">State B Reading</td>
<td>1</td>
<td>.9919</td>
<td>3.77</td>
<td>25.50</td>
<td>93.22</td>
<td>98.00</td>
</tr>
<tr>
<td>2</td>
<td>.9940</td>
<td>3.16</td>
<td>35.00</td>
<td>92.43</td>
<td>98.39</td>
</tr>
<tr>
<td>3</td>
<td>.9947</td>
<td>2.98</td>
<td>35.51</td>
<td>92.38</td>
<td>98.71</td>
</tr>
<tr>
<td rowspan="3">State B Math</td>
<td>1</td>
<td>.9871</td>
<td>4.67</td>
<td>29.33</td>
<td>78.37</td>
<td>97.51</td>
</tr>
<tr>
<td>2</td>
<td>.9877</td>
<td>4.52</td>
<td>33.19</td>
<td>82.15</td>
<td>97.54</td>
</tr>
<tr>
<td>3</td>
<td>.9873</td>
<td>4.60</td>
<td>33.22</td>
<td>81.53</td>
<td>97.46</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1076998611435413">
<p>
<italic>Note</italic>. RMSD = root mean squared difference.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<disp-formula id="disp-formula5-1076998611435413">
<label>5</label>
<mml:math id="mml-disp5-1076998611435413">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">R</mml:mi>
<mml:mi mathvariant="normal">M</mml:mi>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">D</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">G</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">,</mml:mo>
<mml:mtext> </mml:mtext>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msubsup>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">G</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
</mml:msqrt>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula5-1076998611435413" xlink:href="10.3102_1076998611435413-eq5.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula6-1076998611435413">
<label>6</label>
<mml:math id="mml-disp6-1076998611435413">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:msub>
<mml:mfenced close="|" open="|">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">D</mml:mi>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mtext> </mml:mtext>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mfenced close="" open="{">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mfenced close="|" open="|">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">S</mml:mi>
<mml:mi mathvariant="normal">G</mml:mi>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">≤</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">o</mml:mi>
<mml:mi mathvariant="normal">t</mml:mi>
<mml:mi mathvariant="normal">h</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
<mml:mi mathvariant="normal">w</mml:mi>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">s</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">%</mml:mi>
<mml:mi mathvariant="normal">D</mml:mi>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mtext> </mml:mtext>
<mml:mo stretchy="false">=</mml:mo>
<mml:mtext> </mml:mtext>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mo stretchy="false">∑</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msubsup>
<mml:msub>
<mml:mfenced close="|" open="|">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">D</mml:mi>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>100.</mml:mn>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula6-1076998611435413" xlink:href="10.3102_1076998611435413-eq6.tif"/>
</disp-formula>
</p>
<p>Here, SGP<italic>
<sub>i</sub> </italic>and PRR<italic>
<sub>i</sub>
</italic> denote the CSPRs for student <italic>i</italic>, <italic>i</italic> = 1, 2, …, <italic>n</italic>. <xref ref-type="table" rid="table2-1076998611435413">Table 2</xref> shows that SGPs and PRRs have correlations near .99 and differ on average between 2 and 5 units on the percentile rank scale. There is no consistent pattern in the effect of the number of prior years, and the State B Math data show the greatest contrast between the metrics.</p>
<p>
<xref ref-type="fig" rid="fig2-1076998611435413">Figure 2</xref> supplements the summary statistics by identifying the types of students that have disparate SGPs and PRRs. <xref ref-type="fig" rid="fig2-1076998611435413">Figure 2</xref> displays the bivariate scatterplot of Grade 5 and Grade 6 scores for the State B Reading data with plotting symbols coded by the magnitude of the absolute differences between students’ SGPs and PRRs derived using<italic> J</italic> = 1 prior year of data. The OLS regression line representing the conditional mean is overlaid. <xref ref-type="fig" rid="fig2-1076998611435413">Figure 2</xref> reveals that the metrics differ most for students near the conditional mean and for students who have extreme predictor values. Students near the conditional mean are in a high-density region of the conditional distribution, thus small differences on the score metric correspond to large differences on the percentile rank metric. Students with extreme predictor values have small sample sizes guiding the spline functions in those regions, leading to instability in SPGs with respect to PRRs. If the population relationship were heteroscedastic or nonlinear, the extreme predictor values would similarly show the greatest discrepancies, as the quantile regression lines would capture the features of the conditional distributions better than the PRRs that are bound by OLS regression assumptions.</p>
<fig id="fig2-1076998611435413" position="float">
<label>Figure 2.</label>
<caption>
<p>Bivariate scatterplot of students’ observed scores using the (<italic>J</italic> = 1) State B Reading data with plotting symbols coded by the magnitude of the absolute differences between Student Growth Percentiles and Percentile Ranks of Residuals, abbreviated “Diff” in the legend.</p>
</caption>
<graphic alternate-form-of="fig2-1076998611435413" xlink:href="10.3102_1076998611435413-fig2.tif"/>
</fig>
<p>The simulated data allow comparability of SGPs and PRRs in a controlled setting. <xref ref-type="fig" rid="fig3-1076998611435413">Figure 3</xref> illustrates the effects of sample size and the number of prior years of data on the comparability of SGPs and PRRs. The criterion is the square root of the averaged mean squared differences over the 1,000 replications of the generated MVN data, which we will refer to as a RMSD for simplicity. As previously mentioned, these simulated data are generated from a covariance structure that mimics the constant variance pattern in State B. To ensure that our results were generalizable to other variance patterns, we ran the analysis with generated MVN data parameterized by an increasing variance structure that mimicked State A’s statistics and a mirror image, decreasing variance structure. The results were nearly indistinguishable from those seen in <xref ref-type="fig" rid="fig3-1076998611435413">Figure 3</xref> and are thus not shown here.</p>
<fig id="fig3-1076998611435413" position="float">
<label>Figure 3.</label>
<caption>
<p>Root mean squared differences (RMSDs) between Student Growth Percentiles and Percentile Ranks of Residuals for the simulated multivariate normal data over varying sample sizes and <italic>J</italic> = 1, 2, and 3 prior years.</p>
</caption>
<graphic alternate-form-of="fig3-1076998611435413" xlink:href="10.3102_1076998611435413-fig3.tif"/>
</fig>
<p>
<xref ref-type="fig" rid="fig3-1076998611435413">Figure 3</xref> shows that the effect of sample size on the comparability of the SGPs and PRRs is fairly consistent across all the prior-year conditions. In all cases, as the sample size increases, SGP and PRR comparability increases. For instance, for <italic>J</italic> = 3 prior years, the RMSD between SGPs and PRRs decreases from approximately 7 for <italic>n</italic> = 250 to about 1 for <italic>n</italic> = 10,000. For large data sets, the choice of the quantile regression–based SGPs or OLS regression–based PRRs is not as important as it is for smaller data sets for which students are more likely to receive more disparate values.</p>
<p>In contrast, the comparability of SGPs and PRRs decreases as the number of prior years increases. In a typical regression context, this may seem counterintuitive: Increasing the number of predictor variables increases the variance explained and improves prediction of sample outcomes. This intuition fails when interpreting results for CSPR recovery. There is no single, target CSPR for a student in the way that there is a single observed <italic>Y</italic> targeted for prediction by <inline-formula id="inline-formula22-1076998611435413">
<mml:math id="mml-inline22-1076998611435413">
<mml:mover accent="true">
<mml:mi>Y</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>. By definition, the target CSPR is conditional on the predictors (i.e., scores from prior years) included in the regression equations. A student has as many target CSPRs as there are combinations of valid conditioning variables. Thus, increasing the number of predictor variables does not improve the accuracy of CSPR recovery; it redefines the true CSPR with each additional prior year included. <xref ref-type="fig" rid="fig3-1076998611435413">Figure 3</xref> thus shows that SGPs and PRRs grow less similar as the number of conditioning variables increases. The more conditioning variables included, the less that an alternative approach to conditioning is likely to result in the same conditional status percentile. We discuss this further in subsequent sections.</p>
</sec>
<sec id="section5-1076998611435413">
<title>Recovery of Benchmark CSPRs</title>
<p>To determine the bias and variability of SGPs and PRRs, we next compare them against theoretical benchmarks using two population-generating distributions with known conditional distributions: the MVN and multivariate skew normal (MVSN) distributions. These known conditional distributions can in turn define known “benchmark” CSPRs for any student’s observed score vector. We include an explicitly nonnormal distribution, the skew-normal distribution, to explore the relative performance of metrics when OLS assumptions are violated.</p>
</sec>
<sec id="section6-1076998611435413">
<title>Benchmark CSPRs Under Multivariate Normality</title>
<p>Simulated MVN data allow for direct calculation of CSPRs. To emphasize that these CSPRs are derived under multivariate normality assumptions, we refer to them as “Normal-CSPRs” or “N-CSPRs” for shorthand. Assuming the vector of<italic> J </italic>+ 1 grade-level test scores are distributed MVN with known parameters<inline-formula id="inline-formula23-1076998611435413">
<mml:math id="mml-inline23-1076998611435413">
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mi>Y</mml:mi>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">~</mml:mo>
<mml:msub>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mi>J</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="bold">μ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mi>Y</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mo mathvariant="bold">μ</mml:mo>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">,</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mi>
</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula>, the conditional distribution of <italic>Y</italic>|<bold>
<italic>X</italic>
</bold> is univariate normal with the following mean and variance:</p>
<p>
<disp-formula id="disp-formula7-1076998611435413">
<label>7</label>
<mml:math id="mml-disp7-1076998611435413">
<mml:mtable>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:msub>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mi>Y</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi mathvariant="bold">x</mml:mi>
<mml:mo mathvariant="bold" stretchy="false">−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="bold">μ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo mathvariant="bold" stretchy="false">)</mml:mo>
<mml:mo mathvariant="bold" stretchy="false">,</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi mathvariant="bold">X</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:msup>
<mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">Σ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:msup>
<mml:mi>
</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula7-1076998611435413" xlink:href="10.3102_1076998611435413-eq7.tif"/>
</disp-formula>
</p>
<p>With the population conditional distribution of Y|<bold>X</bold> known, the location of each student’s observed current score within the distribution, given their observed past scores, is also known. Because the distribution of Y|<bold>X</bold> is normal, we can use the inverse standard normal cumulative distribution function, Φ<sup>−1</sup>, to compute student <italic>i</italic>’s N-CSPR:</p>
<p>
<disp-formula id="disp-formula8-1076998611435413">
<label>8</label>
<mml:math id="mml-disp8-1076998611435413">
<mml:mtable columnalign="left">
<mml:mtr>
<mml:mtd>
<mml:mtext>N</mml:mtext>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mtext>CSPR</mml:mtext>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo> </mml:mo>
<mml:mo>≤</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo> </mml:mo>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mtext>P</mml:mtext>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo> </mml:mo>
<mml:mo>≤</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>|</mml:mo>
<mml:mo> </mml:mo>
<mml:msub>
<mml:mi>μ</mml:mi>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mtext>σ</mml:mtext>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mtext>Φ</mml:mtext>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mo> </mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>μ</mml:mi>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mtext>σ</mml:mtext>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mtext> </mml:mtext>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mo>,</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula8-1076998611435413" xlink:href="10.3102_1076998611435413-eq8.tif"/>
</disp-formula>
</p>
<p>where P denotes a probability statement. Ideally, SGPs and PRRs would recover these benchmark CSPRs through their estimation procedures.</p>
<p>
<xref ref-type="table" rid="table3-1076998611435413">Table 3</xref> summarizes the extent that SGPs and PRRs recover N-CSPRs. No empirical data results are reported because N-CSPRs can only be computed for simulated data generated from an MVN distribution for which the mean vector and variance–covariance matrix are known. The biases, RMSDs, and percentages of differences within <italic>k</italic> units, <italic>k</italic> = 1, 5, and 10, given in <xref ref-type="table" rid="table3-1076998611435413">Table 3</xref> are averaged over the 1,000 replications for each specified sample size and number of prior years. As in the previous comparability study, we also conducted this analysis using MVN data parameterized by covariance structures that reflected increasing and decreasing variance patterns. These analyses again yielded results very similar to those reported for the constant-variance MVN data, suggesting that degree of SGPs and PRRs recovery of N-CSPRs is robust to common variance structures seen in test score data.</p>
<table-wrap id="table3-1076998611435413" position="float">
<label>Table 3</label>
<caption>
<p>Student Growth Percentile (SGP) and Percentile Rank of a Residual (PRR) Recovery of Benchmark Normal–Conditional Status Percentile Ranks (N-CSPRs) across Varying Prior Years and Sample Sizes for Simulated Multivariate Normal Data</p>
</caption>
<graphic alternate-form-of="table3-1076998611435413" xlink:href="10.3102_1076998611435413-table3.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th> </th>
<th>
</th>
<th>
</th>
<th>
</th>
<th colspan="3">Percentage of Differences Within <italic>k</italic> Units</th>
</tr>
<tr>
<th>Metric</th>
<th>
<italic>n</italic>
</th>
<th>Prior Years</th>
<th>Mean Bias</th>
<th>RMSD</th>
<th>
<italic>k =</italic>1</th>
<th>
<italic>k</italic> = 5</th>
<th>
<italic>k</italic> = 10</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="8">1—Recovering N-CSPRs: Varying Prior Years (<italic>n</italic> Fixed)</td>
</tr>
<tr>
<td> SGP</td>
<td>10,000</td>
<td>1</td>
<td>.0023</td>
<td>1.1725</td>
<td>72.91</td>
<td>99.64</td>
<td>99.93</td>
</tr>
<tr>
<td> SGP</td>
<td>10,000</td>
<td>2</td>
<td>.0041</td>
<td>1.5971</td>
<td>60.43</td>
<td>99.11</td>
<td>99.85</td>
</tr>
<tr>
<td> SGP</td>
<td>10,000</td>
<td>3</td>
<td>.0056</td>
<td>1.9355</td>
<td>52.54</td>
<td>98.37</td>
<td>99.76</td>
</tr>
<tr>
<td> PRR</td>
<td>10,000</td>
<td>1</td>
<td>.0072</td>
<td>0.5138</td>
<td>94.14</td>
<td>100.00</td>
<td>100.00</td>
</tr>
<tr>
<td> PRR</td>
<td>10,000</td>
<td>2</td>
<td>.0089</td>
<td>0.5919</td>
<td>90.84</td>
<td>100.00</td>
<td>100.00</td>
</tr>
<tr>
<td> PRR</td>
<td>10,000</td>
<td>3</td>
<td>.0104</td>
<td>0.6614</td>
<td>87.73</td>
<td>100.00</td>
<td>100.00</td>
</tr>
<tr>
<td colspan="8">2—Recovering N-CSPRs: Varying Sample Size (Prior Years Fixed)</td>
</tr>
<tr>
<td> SGP</td>
<td>250</td>
<td>1</td>
<td>.0204</td>
<td>7.8334</td>
<td>15.37</td>
<td>61.44</td>
<td>87.52</td>
</tr>
<tr>
<td> SGP</td>
<td>1,000</td>
<td>1</td>
<td>.0084</td>
<td>3.7791</td>
<td>30.82</td>
<td>88.81</td>
<td>98.57</td>
</tr>
<tr>
<td> SGP</td>
<td>5,000</td>
<td>1</td>
<td>−.0102</td>
<td>1.6525</td>
<td>59.05</td>
<td>99.08</td>
<td>99.84</td>
</tr>
<tr>
<td> SGP</td>
<td>10,000</td>
<td>1</td>
<td>.0023</td>
<td>1.1725</td>
<td>72.91</td>
<td>99.64</td>
<td>99.93</td>
</tr>
<tr>
<td> PRR</td>
<td>250</td>
<td>1</td>
<td>.2098</td>
<td>3.2436</td>
<td>30.30</td>
<td>88.24</td>
<td>99.19</td>
</tr>
<tr>
<td> PRR</td>
<td>1,000</td>
<td>1</td>
<td>.0585</td>
<td>1.6148</td>
<td>53.51</td>
<td>99.13</td>
<td>99.99</td>
</tr>
<tr>
<td> PRR</td>
<td>5,000</td>
<td>1</td>
<td>−.0004</td>
<td>0.7222</td>
<td>84.90</td>
<td>100.00</td>
<td>100.00</td>
</tr>
<tr>
<td> PRR</td>
<td>10,000</td>
<td>1</td>
<td>.0072</td>
<td>0.5138</td>
<td>94.14</td>
<td>100.00</td>
<td>100.00</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1076998611435413">
<p>
<italic>Note</italic>. RMSD = root mean squared difference. Bias is the average difference between the estimated growth percentiles and the benchmark N-CSPR values (e.g., SGP − N-CSPR).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>
<xref ref-type="table" rid="table3-1076998611435413">Table 3</xref> reports SGP and PRR recovery of N-CSPRs over two factors of interest: number of prior years and sample size. The RMSDs indicate that N-CSPR recovery worsens from 1 prior year to 3 prior years for both metrics, increasing from 1 to 2 for SGPs and from .5 to .7 for PRRs. These results are consistent with the finding that SGPs and PRRs become less comparable to each other as the number of prior years increases. The benchmark N-CSPRs change as the conditioning variables change, and an increase in the number of conditioning variables makes it increasingly difficult for both regression-based CSPRs to recover the benchmark N-CSPRs. However, the RMSDs for PRRs, which are less than 1 for all the prior year levels, are small relative to the percentile rank scale of 0–100, indicating that if <italic>n</italic> is large (i.e., <italic>n ≥ </italic>10,000) the recovery of N-CSPRs by PRRs is good when as many as 3 prior years are included. The SGPs also have small RMSDs, but their recovery of N-CSPRs is more affected by the addition of prior years than the PRRs.</p>
<p>For all prior year levels, PRRs recover N-CSPRs within 5 units for 100% of students; the same is not true of SGPs, which differ by more than 10 units for a small percentage of students. Through closer examination of individual cases, we found that these students correspond to those with extreme predictor scores. For instance, in one of the replications, a student who happened to earn the minimum Grade 5 and Grade 6 score in his cohort earned an SGP (<italic>J = </italic>1) of 7.5 and an N-CSPR (<italic>J </italic>= 1) of about 95.74—a difference of about 85 units. These are rare occurrences, but they reflect the tendency of B-splines to follow sample data at the expense of parameter recovery.</p>
<p>
<xref ref-type="table" rid="table3-1076998611435413">Table 3</xref> also shows that as the sample size increases, the SGPs and PRRs better recover the N-CSPRs. For SGPs at <italic>n</italic> = 250, the RMSD is about 8 and only about 15% of students have SGPs and N-CSPRs within 1 unit of each other, whereas at <italic>n = </italic>10,000, the RMSD decreases to 1 and the percentage of students with SGPs and N-CSPRs within 1 unit of each other increases to 73%. PRR recovery of N-CSPRs also improves with increasing sample size, but PRRs perform better over all sample size levels. In particular, we find that the RMSD between PRRs and N-CSPRs is about 1.6 for <italic>n</italic> = 1,000, whereas SGPs do not obtain a comparable RMSD until an <italic>n </italic>of 5,000. PRRs thus require smaller sample sizes for robust estimates as gauged by their recovery of expected N-CSPRs under multivariate normality. This is unsurprising, given that SGPs require estimation of many more parameters than PRRs and will thus need larger sample sizes to obtain stable results. As expected, there is no evidence from <xref ref-type="table" rid="table3-1076998611435413">Table 3</xref> that SGPs or PRRs are biased estimates of N-CSPRs under varying sample sizes or prior years. The OLS regression model will fit the MVN data by design, and the linearity and homoscedasticity should result in well-behaved quantile regression lines on average, as well.</p>
<p>Although neither SGPs nor PRRs are biased estimates of N-CSPRs, SGPs have higher variance in their approximation of N-CSPRs across both the sample size and the prior year levels. The estimation of SGP quantile manifolds requires estimation of relatively large numbers of parameters that lead to relatively high variability under sampling, and there is no payoff when the population data are linear and homoscedastic. To investigate realistic test score distributions that do not necessarily meet OLS regression assumptions, we extend this analysis to a series of MVSN scenarios.</p>
</sec>
<sec id="section7-1076998611435413">
<title>Benchmark CSPRs Under Multivariate Skew-Normal Distributions</title>
<p>The MVSN distribution allows us to approximate real-world data that are likely to exhibit departures from multivariate normality, particularly in the skewness of the grade-level test score distributions. We consider expected CSPRs for MVSN data to determine the approximate degree of skewness at which SGPs outperform PRRs in their recovery of benchmark CSPRs.</p>
<p>When the joint distribution for a set of test score data is MVSN, the conditional distribution of the current year, given the past years is approximately skew normal with derivable location, scale, and shape parameters (<xref ref-type="bibr" rid="bibr3-1076998611435413">Azzalini &amp; Capitanio, 1999</xref>). <xref ref-type="bibr" rid="bibr12-1076998611435413">Capitanio, Azzalini, and Stanghellini (2003</xref>) discuss an extension to the skew-normal distribution with an additional shape parameter that results in the conditional distribution being exactly, instead of approximately, skew normal. However, we use the simpler parameterization because in preliminary simulation studies, we found that the conditional distributions were sufficiently captured by this parameterization.</p>
<p>Skew-Normal CSPRs (SN-CSPRs) are a natural analog of N-CSPRs. Assuming the vector of<italic> J </italic>+ 1 grade-level test scores,<inline-formula id="inline-formula25-1076998611435413">
<mml:math id="mml-inline25-1076998611435413">
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mi>Y</mml:mi>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula>, is MVSN with known location (ξ), scale (Ω), and shape (α) parameters, <inline-formula id="inline-formula27-1076998611435413">
<mml:math id="mml-inline27-1076998611435413">
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mi>Y</mml:mi>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>S</mml:mi>
<mml:msub>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mi>J</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mo mathvariant="bold">ξ</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ξ</mml:mi>
<mml:mi>Y</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mo mathvariant="bold">ξ</mml:mo>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">,</mml:mo>
<mml:mo>Ω</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">ω</mml:mi>
<mml:mi>Y</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mo>Ω</mml:mo>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mo>′</mml:mo>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mo>Ω</mml:mo>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mo>Ω</mml:mo>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">,</mml:mo>
<mml:mo mathvariant="bold">α</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mi>Y</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mo mathvariant="bold">α</mml:mo>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfenced>
</mml:math>
</inline-formula>, a closed-form expression for the moment-generating function for the conditional distribution of <italic>Y</italic>|<bold>
<italic>X</italic>
</bold> can be derived (<xref ref-type="bibr" rid="bibr3-1076998611435413">Azzalini &amp; Capitanio, 1999</xref>). From the moment-generating function, we can compute the moments up to the third order and then solve for the parameters for a skew-normal density that has the same moments. In other words, the approximate skew-normal density preserves exact moments up to the third order for the exact conditional distribution of <italic>Y</italic>|<italic>
<bold>X</bold>
</italic> (<xref ref-type="bibr" rid="bibr3-1076998611435413">Azzalini &amp; Capitanio, 1999</xref>). We use the R function “msn.conditional” in <xref ref-type="bibr" rid="bibr2-1076998611435413">Azzalini’s (2010)</xref> R package “sn” to perform these computations. Using the parameters of the approximate skew-normal conditional distribution, we use the inverse skew-normal cumulative distribution function, <italic>G</italic>
<sup>−1</sup>(), to determine student <italic>i</italic>’s SN-CSPR as follows:<disp-formula id="disp-formula9-1076998611435413">
<label>9</label>
<mml:math id="mml-disp9-1076998611435413">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mi>S</mml:mi>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mtext>-</mml:mtext>
</mml:mrow>
<mml:mi>C</mml:mi>
<mml:mi>S</mml:mi>
<mml:mi>P</mml:mi>
<mml:msub>
<mml:mi>R</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">≤</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>100</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">≤</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">ξ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">ω</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">α</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>100</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
</mml:mtd>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mi>G</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">ξ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">ω</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">α</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>100.</mml:mn>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula9-1076998611435413" xlink:href="10.3102_1076998611435413-eq9.tif"/>
</disp-formula>
</p>
<p>In assessing the recovery of SGPs and PRRs of SN-CSPRs, we generate 1,000 replications of MVSN data. For these generated MVSN data sets, we fix the sample size and prior years factors at the largest levels, <italic>n</italic> =10,000 and <italic>J </italic>= 3 prior years, to mimic state-level operational data sets. We hold the location parameter constant as the zero vector (i.e., ξ = 0) and use the correlation matrix, given for the simulated MVN data in <xref ref-type="table" rid="table1-1076998611435413">Table 1</xref> for the scale matrix (<bold>Ω</bold>). To construct test score distributions for nominal Grade 3 to Grade 6 with approximately equal skewness levels, we use constant shape vectors, <bold>α</bold>, of length <italic>J </italic>+ 1. We vary the skewness of each of the four grade-level distributions by setting five different alpha vectors: <bold>α</bold> = [.<bold>3</bold>], [.<bold>45</bold>], [.<bold>50</bold>], [.<bold>65</bold>], and [<bold>1</bold>]. These result in average expected skewness levels of approximately 0.1, 0.2, 0.25, 0.3, and 0.4, respectively. For each α vector, the resulting expected skewness of each of the four distributions is nearly equal, with minor deviations arising due to the features of the scale matrix. For instance, when α = <bold>.3</bold>, the expected skewness indices for the nominal Grade 3 to Grade 6 data are 0.1054, 0.1109, 0.1109, and 0.1054, respectively, resulting in an average skewness of about 0.108. Precise control over the skewness of all distributions is not possible without adjusting the scale matrix, but it is also not necessary. Real test score distributions will never be exactly skew normal, thus these kinds of approximations will suffice for our purposes.</p>
<p>
<xref ref-type="fig" rid="fig4-1076998611435413">Figure 4</xref> illustrates the recovery of SN-CSPRs by PRRs and SGPs across varying skewness levels. We plot RMSDs against the average expected skewness of the 4 years of test score data for each <bold>α</bold> vector. A skewness of 0 corresponds to MVN data and the corresponding results were reported in <xref ref-type="table" rid="table3-1076998611435413">Table 3</xref>. The RMSDs between SN-CSPRs and PRRs are shown with the solid smoothed line, while those for SGPs are given by the dashed smoothed line. As expected, <xref ref-type="fig" rid="fig4-1076998611435413">Figure 4</xref> shows that for lower levels of skewness, PRRs outperform SGPs in their recovery of benchmark CSPRs. SGPs, however, begin to outperform PRRs from a skewness of approximately 0.25, which we label as the “pivot point” in <xref ref-type="fig" rid="fig4-1076998611435413">Figure 4</xref>. This finding suggests that SGPs are better suited for nonnormal, skewed data, whereas for symmetric and only slightly skewed data, the simpler PRRs may be a suitable alternative.</p>
<fig id="fig4-1076998611435413" position="float">
<label>Figure 4.</label>
<caption>
<p>Root mean squared differences (RMSDs) between skew normal–conditional status percentile ranks (SN-CSPRs) and two conditional status percentile rank metrics—student growth percentiles (SGPs) and percentile ranks of residuals (PRRs)—by degree of skewness. The labeled pivot point indicates the skewness at which SGPs begin to outperform PRRs in their recovery of SN-CSPRs.</p>
</caption>
<graphic alternate-form-of="fig4-1076998611435413" xlink:href="10.3102_1076998611435413-fig4.tif"/>
</fig>
<p>Overall, neither SGPs nor PRRs show bias in recovery across skewness levels. However, PRRs show slight bias conditional on the outcome variable, that is, scores in the current grade. In particular, PRRs for students with extreme and central Grade 6 scores are systematically slightly overestimated and underestimated, respectively. At higher levels of multivariate skewness, the variance associated with SGPs becomes worth the model’s ability to capture the heteroscedasticity in the data.</p>
<p>The State A and State B empirical distributions have skewnesses ranging from ±0.02 to ±0.30, where the Math distributions are typically more skewed than the Reading distributions. As other examples, the technical manual for Indiana state tests reports skewnesses ranging from ±0.01 to ±0.20 across four core subject tests from 2008 to 2010 (<xref ref-type="bibr" rid="bibr1-1076998611435413">ACT &amp; Indiana State Board of Education, 2010</xref>). These ranges suggest that blind application of PRRs and SGPs to typical test score data will more often favor PRRs using RMSD as a criterion. However, our identified pivot point is an illustration derived from particular distributional assumptions. As we discuss in the conclusion, this finding does not support the use of a particular CSPR but instead reframes the decision in terms of choosing a model that best fits the data.</p>
</sec>
<sec id="section8-1076998611435413">
<title>Scale Transformation Invariance</title>
<p>After establishing the comparability of SGPs and PRRs and their ability to recover benchmark CSPRs, we analyze their invariance under monotonic test scale transformations. To test the scale transformation invariance property of SGPs and PRRs, we apply piecewise scale transformations to the sets of empirical and simulated MVN data that stretch or shrink parts of the scale, altering the skewness and kurtosis of the test score distributions. Some test developers also use piecewise transformations to obtain desired distributional characteristics of their scale below/above key cut points, such as Proficiency. For instance, in the 1990s, for the Massachusetts state tests, two linear equations were used in the raw-to-scale-score conversions to transform raw scores below the proficiency cut score differently from those above it (<xref ref-type="bibr" rid="bibr28-1076998611435413">Massachusetts Department of Elementary and Secondary Education, 1999</xref>).</p>
<p>We choose four skewness/kurtosis scale transformations that we refer to as the positive skewness, negative skewness, positive kurtosis, and negative kurtosis transformations. This analysis contrasts with the previous skew-normal study in that these scale transformations are applied to empirical data on an original established score scale and cannot be generated from a known population distribution. We apply the transformations independently to each year of data in the full <italic>J </italic>= 1 prior-year empirical and simulated MVN data sets. First, the scores within each grade are converted to <italic>z</italic>-scores (<italic>z</italic>). Then, the piecewise functions in <xref ref-type="disp-formula" rid="disp-formula10-1076998611435413">Equations 10</xref> and <xref ref-type="disp-formula" rid="disp-formula11-1076998611435413">11</xref> are applied to obtain the positive/negative skewness transformations, <italic>S</italic>(<italic>z</italic>), and kurtosis transformations, <italic>K</italic>(z<italic>),</italic> respectively, where the constant <italic>k</italic> in the transformations can be varied to modulate the degree to which the skewness and kurtosis are altered:</p>
<p>
<disp-formula id="disp-formula10-1076998611435413">
<label>10</label>
<mml:math id="mml-disp10-1076998611435413">
<mml:mi>S</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>z</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="}" open="{">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mstyle displaystyle="true" scriptlevel="0">
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mrow>
<mml:mi>z</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
</mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">×</mml:mo>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mstyle>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>2.7</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mstyle displaystyle="true" scriptlevel="0">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">×</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mstyle>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">≤</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mstyle displaystyle="true" scriptlevel="0">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">×</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mstyle>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>0.8</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">≤</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfenced close=")" open="(">
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">×</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">+</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>2.3</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula10-1076998611435413" xlink:href="10.3102_1076998611435413-eq10.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula11-1076998611435413">
<label>11</label>
<mml:math id="mml-disp11-1076998611435413">
<mml:mi>K</mml:mi>
<mml:mfenced close=")" open="(">
<mml:mi>z</mml:mi>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mfenced close="}" open="{">
<mml:mrow>
<mml:mtable columnspacing="1em" rowspacing="4pt">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">×</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>[</mml:mo>
</mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>2.8</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>z</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
</mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">≤</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>z</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
</mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>0.7</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">≤</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">×</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>[</mml:mo>
</mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">;</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>2.2</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula11-1076998611435413" xlink:href="10.3102_1076998611435413-eq11.tif"/>
</disp-formula>
</p>
<p>To produce reasonable but noticeable changes in the skewness and kurtosis of the grade-level test score distributions, we use <italic>k</italic> of 1.2 for the positive skew and kurtosis levels and <italic>k</italic> = 1/1.2 for the negative skewness and kurtosis levels. These values of <italic>k</italic> result in skewness ≈±0.3 and kurtosis ≈+3 ± 0.7 for data that are originally normally distributed. We also include the more extreme exponential transformation to test the performance of the SGPs and PRRs under a drastic scale transformation.</p>
<p>We evaluate the scale transformation invariance of the SGPs and PRRs with two different indices—one that summarizes the effect of each scale transformation separately and another that summarizes the overall measure of SGP/PRR invariance across all the transformations. The first index is the RMSD between the SGPs/PRRs from the original data sets—the data before any transformations are applied—and the resulting SGPs/PRRs from each scale transformation. <xref ref-type="table" rid="table4-1076998611435413">Table 4</xref> provides these RMSDs for each of the relevant (<italic>J </italic>= 1) empirical and simulated data sets. For all scale transformations, the results across the data sets strongly suggest that SGPs are more scale invariant than PRRs. For example, across the data sets, students receive SGPs that differ by about 0.5 to 1 percentile rank units between the original, observed scores and the scores after applying the positive skewness transformation, whereas the corresponding PRRs differ by about 2 percentile rank units.</p>
<table-wrap id="table4-1076998611435413" position="float">
<label>Table 4</label>
<caption>
<p>Student Growth Percentile (SGP) and Percentile Rank of a Residual (PRR) Scale-Transformation Invariance for Simulated Multivariate Normal (MVN) and Empirical Data Sets</p>
</caption>
<graphic alternate-form-of="table4-1076998611435413" xlink:href="10.3102_1076998611435413-table4.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>
</th>
<th colspan="5">Individual Scale Transformation Measure: RMSDs Between the Original Data and Each Scale Transformation</th>
<th colspan="2">Overall Measure: CSPR Ranges</th>
</tr>
<tr>
<th>Metric</th>
<th>Data</th>
<th>Positive Skew</th>
<th>Negative Skew</th>
<th>Positive Kurtosis</th>
<th>Negative Kurtosis</th>
<th>Exp</th>
<th>
<italic>M</italic>
</th>
<th>
<italic>SD</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="5">SGP</td>
<td>Simulated MVN </td>
<td>0.49</td>
<td>0.48</td>
<td>0.81</td>
<td>0.74</td>
<td>0.92</td>
<td>0.96</td>
<td>1.13</td>
</tr>
<tr>
<td>State A Reading</td>
<td>0.70</td>
<td>0.69</td>
<td>0.95</td>
<td>0.92</td>
<td>0.91</td>
<td>1.29</td>
<td>1.04</td>
</tr>
<tr>
<td>State A Math</td>
<td>0.51</td>
<td>0.53</td>
<td>0.76</td>
<td>0.72</td>
<td>0.57</td>
<td>1.12</td>
<td>0.94</td>
</tr>
<tr>
<td>State B Reading</td>
<td>1.40</td>
<td>1.18</td>
<td>1.34</td>
<td>1.79</td>
<td>1.74</td>
<td>2.19</td>
<td>1.48</td>
</tr>
<tr>
<td>State B Math</td>
<td>1.10</td>
<td>1.20</td>
<td>1.20</td>
<td>1.31</td>
<td>1.25</td>
<td>1.90</td>
<td>1.42</td>
</tr>
<tr>
<td rowspan="5">PRR</td>
<td>Simulated MVN </td>
<td>1.91</td>
<td>1.85</td>
<td>2.60</td>
<td>2.57</td>
<td>10.71</td>
<td>4.35</td>
<td>3.37</td>
</tr>
<tr>
<td>State A Reading</td>
<td>1.95</td>
<td>1.92</td>
<td>2.47</td>
<td>2.52</td>
<td>10.22</td>
<td>4.39</td>
<td>2.99</td>
</tr>
<tr>
<td>State A Math</td>
<td>2.02</td>
<td>1.98</td>
<td>2.70</td>
<td>2.66</td>
<td>11.27</td>
<td>4.87</td>
<td>2.97</td>
</tr>
<tr>
<td>State B Reading</td>
<td>1.90</td>
<td>1.88</td>
<td>2.45</td>
<td>2.48</td>
<td>11.11</td>
<td>4.25</td>
<td>3.06</td>
</tr>
<tr>
<td>State B Math</td>
<td>2.10</td>
<td>1.92</td>
<td>2.54</td>
<td>2.58</td>
<td>12.52</td>
<td>4.53</td>
<td>2.87</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-1076998611435413">
<p>
<italic>Note. </italic>CSPR = conditional status percentile rank; Exp = exponential; MVN = multivariate normal; RMSDs = root mean squared differences.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>As expected, the SGPs are not perfectly scale invariant, although the RMSDs are not large. A minor concern remains, similar to the comparability and recovery studies, that SGPs for students with extreme statuses can be substantially affected by scale transformations; such students receive SGPs that can flip as drastically as from 1 to 99. Not surprisingly, PRRs are most affected by the extreme exponential transformation. The large RMSDs of 10 to13 accentuate the lack of PRR invariance under monotonic scale transformations that violate OLS regression assumptions. As we note later, this extreme result also points to an obvious remedy in a regression modeling framework: a natural logarithm transformation of variables followed by PRR calculation.</p>
<p>We also compute an overall scale invariance index by summarizing CSPR ranges under all transformations. Every student in the simulated and empirical data sets has an SGP/PRR for the original data as well as each of the transformed data sets. To obtain a student range, we take the difference between the maximum and minimum SGP/PRR for each student over the original data and the transformed data sets. We exclude the more unrealistic exponential transformation in calculating these ranges. We summarize these CSPR range statistics with their means and standard deviations, which are also given in <xref ref-type="table" rid="table4-1076998611435413">Table 4</xref>. Consistent with the RMSDs for the individual transformations, SGPs have lower means and less variable student ranges than PRRs. The mean student ranges for SGPs are between 1 and 2, meaning that, on average, students receive SGPs between 1 and 2 units apart across the original and four transformed data sets of interest. In contrast, PRRs have mean student ranges between 4 and 5 units. The relative sensitivity of PRRs to scale transformations suggests that SGPs would be preferable when there are serious concerns about the equal-interval properties of the test score scales.</p>
</sec>
<sec id="section9-1076998611435413">
<title>Sensitivity to Number of Prior Years of Test Score Data</title>
<p>Instead of comparing the CSPRs to each other, a benchmark value, or a value estimated from transformed data, this final analysis compares each CSPR metric to itself over varying numbers of prior years of test scores. The number of prior years of test scores included in the model will change the value of a student’s conditional status percentile rank, be it an SGP, PRR, or even an N-CSPR. It is useful to know how stable these metrics are across the number of conditioning variables.</p>
<p>In this study, we use the <italic>J</italic> = 1, 2, and 3 prior-year empirical and simulated data sets at their largest sample sizes: the actual <italic>n</italic>-count for the empirical data and 10,000 for the simulated data. We evaluate the sensitivity of the SGPs, PRRs, and N-CSPRs to the number of prior years included using RMSDs that compare the pertinent metric from each pair of <italic>J</italic> = 1, 2, 3 data sets (e.g., SGPs from <italic>J = </italic>1-prior-year data sets vs. <italic>J </italic>= 2-prior-year data sets). For the simulated MVN data, we include the N-CSPRs as a point of reference: The RMSDs among the various prior-year data sets for the N-CSPRs summarize the extent that CSPRs are expected to vary under prior year selection for MVN data.</p>
<p>
<xref ref-type="table" rid="table5-1076998611435413">Table 5</xref> shows that the variance of the CSPRs over varying prior years is consistent across all the metrics. For the simulated data, the SGPs and PRRs are just as dependent on the number of prior years as the benchmark N-CSPRs, a reminder that the inconsistency of CSPRs under the number of conditioning variables occurs even when CSPRs are “true.” The magnitudes of the RMSDs are also roughly consistent across all the data sets, with the empirical Math data sets having slightly lower values than the other data sets. We also found this result in a simulation study using MVN data parameterized with a correlation matrix that mimics the empirical Math data sets. This discrepancy is due to the fact that the Math data sets have higher between grade correlations than the Reading or simulated MVN data, as seen in <xref ref-type="table" rid="table1-1076998611435413">Table 1</xref>. As covariates become more collinear, adding covariates affects conditional distributions less, and a perfectly collinear covariate would be like adding nothing at all.</p>
<table-wrap id="table5-1076998611435413" position="float">
<label>Table 5</label>
<caption>
<p>Root Mean Squared Differences Comparing Each Conditional Status Percentile Rank Metric Across Varying Prior Years for the Simulated and Empirical Data</p>
</caption>
<graphic alternate-form-of="table5-1076998611435413" xlink:href="10.3102_1076998611435413-table5.tif"/>
<table>
<thead>
<tr>
<th>Data</th>
<th>Metric</th>
<th>1 Year Versus 2 Years</th>
<th>2 Years Versus 3 Years</th>
<th>1 Year Versus 3 Years</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="3">Simulated MVN Data </td>
<td>N-CSPR</td>
<td>11.90</td>
<td>6.83</td>
<td>13.55</td>
</tr>
<tr>
<td>SGP</td>
<td>11.95</td>
<td>6.96</td>
<td>13.63</td>
</tr>
<tr>
<td>PRR</td>
<td>11.90</td>
<td>6.85</td>
<td>13.55</td>
</tr>
<tr>
<td rowspan="2">State A Reading</td>
<td>SGP</td>
<td>12.43</td>
<td>7.02</td>
<td>14.05</td>
</tr>
<tr>
<td>PRR</td>
<td>12.55</td>
<td>6.90</td>
<td>14.16</td>
</tr>
<tr>
<td rowspan="2">State A Math</td>
<td>SGP</td>
<td>11.28</td>
<td>6.23</td>
<td>12.72</td>
</tr>
<tr>
<td>PRR</td>
<td>11.16</td>
<td>6.12</td>
<td>12.55</td>
</tr>
<tr>
<td rowspan="2">State B Reading</td>
<td>SGP</td>
<td>12.55</td>
<td>6.97</td>
<td>14.15</td>
</tr>
<tr>
<td>PRR</td>
<td>12.80</td>
<td>7.18</td>
<td>14.51</td>
</tr>
<tr>
<td rowspan="2">State B Math</td>
<td>SGP</td>
<td>10.20</td>
<td>5.50</td>
<td>11.48</td>
</tr>
<tr>
<td>PRR</td>
<td>10.24</td>
<td>5.32</td>
<td>11.41</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-1076998611435413">
<p>
<italic>Note</italic>. MVN = multivariate normal; N-CSPR = normal-conditional status percentile rank; PRR = percentile rank of a residual; SGP = student growth percentile.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The RMSDs in <xref ref-type="table" rid="table5-1076998611435413">Table 5</xref> reveal that CSPRs are highly dependent on the number of prior years included. On average, students receive CSPRs that differ by 12 percentile rank units when only the most immediate prior year of data is used (<italic>J</italic> = 1) versus the two most immediate prior years (<italic>J </italic>= 2). This finding is not surprising in the familiar conditional probability context. When we add or subtract the number of prior years included in these models, we alter the pool of students who are “similar,” or have the same past test score history, which, in turn, alters the location of a student’s current score in the distribution of his or her “similar” peers. However, this finding could have serious implications for the use of SGPs in an accountability context in which students are categorized by their SGP score. In such cases, student growth categorization (i.e., high/low/typical growth) could be highly dependent on the number of prior years available.</p>
<p>Across all the CSPRs, the effect on their stability after adding a second prior year to the model is larger than adding a third prior year: The RMSDs comparing 1-prior-year metrics versus 2-prior-year metrics are almost twice as large as those comparing the 2-prior-year to 3-prior-year metrics. For most test score covariance matrices, at some <italic>J</italic>, the difference between a student’s CSPR from a <italic>J</italic>-prior-year data set versus a <italic>J </italic>+ 1-prior-year data set will be negligible.</p>
<p>We can also identify which students are most affected by including an additional prior year in the model. For each student with Grade 6 scores, calculate a simple difference between a CSPR derived using 2 prior years (Grade 4 and Grade 5) and a CSPR derived using 1 prior year (Grade 5 alone). This is the difference in CSPRs had another year of data been included. The correlation between this difference and the actual Grade 4 score is around −.6 for all empirical and simulated CSPRs. The higher the early grade score, the less the student benefits from its inclusion. This is similar to a “trajectory model” on a vertical scale, where including lower earlier scores steepens the trajectory and increases the estimated gain. The difference between trajectory models, which require a vertical scale, and CSPRs is that increasing CSPRs by including more prior years requires lower earlier scores in a relative not absolute sense.</p>
</sec>
<sec id="section10-1076998611435413">
<title>Discussion</title>
<p>This article locates the widely used SGP metric in a more general and familiar framework of conditional status and investigates a contrasting CSPR metric, PRRs. The goal of the article is not to advocate for a particular metric but to contrast metric properties under different and realistic scenarios. The three primary findings can be summarized as follows: (1) The metrics are very similar in practice with the largest differences occurring for extreme scoring students; (2) PRRs are superior to SGPs in MVN scenarios; and (3) as MVN and equal-interval assumptions are threatened to a particular degree, SGPs become superior. The design of these studies allowed for sequential degradation of MVN and equal-interval assumptions to identify pivot points and conditions where SGPs would be preferable. In this conclusion, we offer three further reflections on the endeavor of describing conditional status, given past scores.</p>
<p>First, PRRs and SGPs do not exhaust the universe of possible CSPR metrics. The PRR metric is located toward the end of a parametric continuum with SGPs located toward the other, nonparametric, end. In cases where heteroscedasticity and nonlinearity are a clear concern, PRRs can be redefined as percentile ranks of residuals from regression models that use transformed variables or polynomials. When ceiling or floor effects threaten model fit at extreme scale points, PRR properties may improve after ad hoc monotone transformations that linearize multivariate relationships. Conversely, SGPs can be adapted to be less flexible than they are by using linear instead of B-spline parameterizations, or B-spline knots can be chosen with different specifications. Other CSPRs lie at further extremes of the parametric continuum, such as making strong MVN assumptions and calculating CSPRs, given the mean and covariance structure alone, or making no assumptions at all and reporting empirical CSPRs, given students with the exact same previous scores. The model that supports a particular CSPR metric should be chosen based on the features of the data. This article represents an overview of salient factors and the consequences of ignoring them in model selection.</p>
<p>Second, accurate interpretations of CSPRs require clear understanding of the covariates included in the model. A student may have a single true score, but no student has a single true CSPR, as it depends on the choice of conditioning variables. With large numbers of covariates or covariates that add no or redundant predictive utility, it is possible that a student’s CSPR will change little when an additional covariate is included. However, when in practice, a CSPR may be reported with 1 to many years of prior data functioning as covariates (<xref ref-type="bibr" rid="bibr15-1076998611435413">Colorado Department of Education, 2009b</xref>), each CSPR should be understood as defined only with respect to its particular set of covariates. Aggregating over students’ CSPRs to summarize the conditional status of a group introduces still other confounding factors (<xref ref-type="bibr" rid="bibr13-1076998611435413">Castellano, 2011</xref>), particularly when aggregating CSPRs with differing covariates, but this is beyond the scope of this article.</p>
<p>Third, we have described SGPs and PRRs as CSPRs. However, as the name suggests, in practice, SGPs are described as growth measures. We maintain that CSPRs afford a particular kind of growth interpretation, where growth is defined as status conditional on past scores. This may not match well with many intuitive conceptions of growth. In particular, SGPs and PRRs can be computed without regard to construct stability, vertical scales, or the meaning of the variables included as covariates. Even if the covariates were test scores on a defensible vertical scale, CSPRs are only setting expectations for performance based on these predictors. There is thus a disconnect between CSPRs and the growth metric itself, making it impossible to directly answer the question, how much did my child grow? Although it is unlikely, students could decline in their performance but still receive a high CSPR depending on how their performance ranks against their peers. As several different models with different interpretations currently fall under the umbrella term of “growth models,” a more nuanced discussion of “growth” is needed to develop clear terminology that distinguishes explicitly among them. Our recommendation matches what we have done in this article: Describe SGPs and their like as CSPRs, since this is what they literally are, and be explicit about the covariates being used for setting the expectations.</p>
<p>The push under current educational reforms for growth metrics to be used for high-stakes purposes, especially ones that afford normative growth interpretations, makes it imperative that SGPs are well understood. This study addresses important questions related to the increasingly popular SGP metric. This article also underscores the importance for policymakers, educational researchers, and educational data users to disentangle ambiguities about the term “growth” and to fully understand the statistics used to measure it.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="bibr1-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">ACT, &amp; The Illinois State Board of Education</collab>. (<year>2010</year>). <source>Prairie state achievement examination technical manual: 2010 testing cycle</source>. <comment>Retrieved from the Illinois State Board of Education website</comment>: <ext-link ext-link-type="uri" xlink:href="http://www.isbe.state.il.us/assessment/pdfs/psae/tech_manual10.pdf">http://www.isbe.state.il.us/assessment/pdfs/psae/tech_manual10.pdf</ext-link>
</citation>
</ref>
<ref id="bibr2-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Azzalini</surname>
<given-names>A</given-names>
</name>
</person-group>. (<year>2010</year>). <source>sn: The skew-normal and skew-t distributions</source> <comment>[R package version 0.4-16]</comment>.</citation>
</ref>
<ref id="bibr3-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Azzalini</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Capitanio</surname>
<given-names>A.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Statistical applications of the multivariate skew normal distribution</article-title>. <source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source>, <volume>61</volume>, <fpage>579</fpage>–<lpage>602</lpage>.</citation>
</ref>
<ref id="bibr4-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Toward a normative understanding of student growth</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Ryan</surname>
<given-names>K. E.</given-names>
</name>
<name>
<surname>Shepard</surname>
<given-names>L. A.</given-names>
</name>
</person-group> (Eds.), <source>The future of test-based educational accountability</source> (pp. <fpage>155</fpage>–<lpage>170</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Taylor &amp; Francis</publisher-name>.</citation>
</ref>
<ref id="bibr5-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W</given-names>
</name>
</person-group>. (<year>2009</year>). <article-title>Norm-and criterion-referenced student growth</article-title>. <source>Educational Measurement: Issues and Practice</source>, <volume>28</volume>, <fpage>42</fpage>–<lpage>51</lpage>. <comment>doi:10.1111/j.1745-3992.2009.00161.x</comment>
</citation>
</ref>
<ref id="bibr6-1076998611435413">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W</given-names>
</name>
</person-group>. (<year>2010a</year>). <source>New directions for student growth models</source>. <comment>Retrieved from the National Center for the Improvement of Educational Assessment website</comment>: <ext-link ext-link-type="uri" xlink:href="http://www.ksde.org/LinkClick.aspx?fileticket=UssiNoSZks8%3D&amp;tabid=4421&amp;mid=10564">http://www.ksde.org/LinkClick.aspx?fileticket=UssiNoSZks8%3D&amp;tabid=4421&amp;mid=10564</ext-link>
</citation>
</ref>
<ref id="bibr7-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W</given-names>
</name>
</person-group>. (<year>2010b</year>). <comment>SGP: Student growth percentile and percentile growth projection/trajectory functions [R package version 0.0–6]</comment>.</citation>
</ref>
<ref id="bibr8-1076998611435413">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W</given-names>
</name>
</person-group>. (<year>2011a</year>). <comment>A technical overview of the student growth percentile methodology: Student growth percentiles and percentile growth trajectories/projections. The National Center for the Improvement of Educational Assessment. Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.nj.gov/education/njsmart/performance/SGP_Technical_Overview.pdf">http://www.nj.gov/education/njsmart/performance/SGP_Technical_Overview.pdf</ext-link>
</citation>
</ref>
<ref id="bibr9-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W.</given-names>
</name>
</person-group> (<year>2011b, June 19</year>). <source>New directions in student growth: The Colorado growth model</source>. <comment>Presented at the National Conference on Student Assessment, Orlando, FL.</comment>
</citation>
</ref>
<ref id="bibr10-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Betebenner</surname>
<given-names>D. W</given-names>
</name>
</person-group>. (<year>2011c</year>). <comment>SGP: An R package for the calculation and visualization of student growth percentiles &amp; percentile growth trajectories [R package version 0.7–1.0]</comment>.</citation>
</ref>
<ref id="bibr11-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Briggs</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Betebenner</surname>
<given-names>D. W.</given-names>
</name>
</person-group> (<year>2009</year>, <article-title>April)</article-title>. <source>Is growth in student achievement scale dependent?</source> <comment>Paper presented at the invited symposium Measuring and Evaluating Changes in Student Achievement</comment>: <publisher-name>A Conversation About Technical and Conceptual Issues at the annual meeting of the National Council for Measurement in Education</publisher-name>, <publisher-loc>San Diego, CA</publisher-loc>.</citation>
</ref>
<ref id="bibr12-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Capitanio</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Azzalini</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Stanghellini</surname>
<given-names>E.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Graphical models for skew-normal variates</article-title>. <source>Scandinavian Journal of Statistics</source>, <volume>30</volume>, <fpage>129</fpage>–<lpage>144</lpage>.</citation>
</ref>
<ref id="bibr13-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Castellano</surname>
<given-names>K. E.</given-names>
</name>
</person-group> (<year>2011</year>). <source>Unpacking student growth percentiles: Statistical properties of regression-based approaches with implications for student and school classifications</source>. <comment>Available from ProQuest Dissertations and Theses database. (UMI No. 3461371).</comment>
</citation>
</ref>
<ref id="bibr14-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">Colorado Department of Education</collab>. (<year>2009a</year>). <source>Changes in Colorado growth model calculations in 2009</source>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.cde.state.co.us/research/Documents.htm">http://www.cde.state.co.us/research/Documents.htm</ext-link>
</citation>
</ref>
<ref id="bibr15-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">Colorado Department of Education</collab>. (<year>2009b</year>). <source>The Colorado growth model: Frequently asked questions</source>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.schoolview.org/documents/CGM_FAQ.pdf">http://www.schoolview.org/documents/CGM_FAQ.pdf</ext-link>
</citation>
</ref>
<ref id="bibr16-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cronbach</surname>
<given-names>L. J.</given-names>
</name>
<name>
<surname>Furby</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>1970</year>). <article-title>How we should measure “change”—Or should we?</article-title> <source>Psychological Bulletin</source>, <volume>74</volume>, <fpage>68</fpage>–<lpage>80</lpage>. <comment>doi:10.1037/h0029382</comment>
</citation>
</ref>
<ref id="bibr17-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">Data Quality Campaign</collab>. (<year>2010</year>). <source>DQC state analysis: Executive summary</source>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.dataqualitycampaign.org/stateanalysis/executive_summary/">http://www.dataqualitycampaign.org/stateanalysis/executive_summary/</ext-link>
</citation>
</ref>
<ref id="bibr18-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>de Boor</surname>
<given-names>C.</given-names>
</name>
</person-group> (<year>2001</year>). <source>A practical guide to splines</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr19-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dette</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Volgushev</surname>
<given-names>S</given-names>
</name>
</person-group>. (<year>2008</year>). <article-title>Non-crossing non-parametric estimates of quantile curves</article-title>. <source>Journal of the Royal Statistical Society B</source>, <volume>70</volume>, <fpage>609</fpage>–<lpage>627</lpage>. <comment>doi:10.1111/j.1467-9868.2008.00651.x</comment>
</citation>
</ref>
<ref id="bibr20-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ellis</surname>
<given-names>K. J.</given-names>
</name>
<name>
<surname>Abrams</surname>
<given-names>S. A.</given-names>
</name>
<name>
<surname>Wong</surname>
<given-names>W. W.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Monitoring childhood obesity: Assessment of the weight/height2 index</article-title>. <source>American Journal of Epidemiology</source>, <volume>150</volume>, <fpage>939</fpage>–<lpage>946</lpage>.</citation>
</ref>
<ref id="bibr21-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fetler</surname>
<given-names>M. E.</given-names>
</name>
</person-group> (<year>1991</year>). <article-title>A method for the construction of differentiated school norms</article-title>. <source>Applied Measurement in Education</source>, <volume>4</volume>, <fpage>53</fpage>–<lpage>66</lpage>.</citation>
</ref>
<ref id="bibr22-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Grady</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Lewis</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Gao</surname>
<given-names>F.</given-names>
</name>
</person-group> (<year>2010</year>, <article-title>May)</article-title>. <source>The effect of sample size on student growth percentiles</source>. <comment>Paper presented at the 2010 annual meeting of the National Council on Measurement in Education. Denver, CO</comment>.</citation>
</ref>
<ref id="bibr23-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hoffer</surname>
<given-names>T. B.</given-names>
</name>
<name>
<surname>Hedberg</surname>
<given-names>E. C.</given-names>
</name>
<name>
<surname>Brown</surname>
<given-names>K. L.</given-names>
</name>
<name>
<surname>Halverson</surname>
<given-names>M. L.</given-names>
</name>
<name>
<surname>Reid-Brossard</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Ho</surname>
<given-names>A. D.</given-names>
</name>
<name>
<surname>Furgol</surname>
<given-names>K. E.</given-names>
</name>
</person-group> (<year>2011</year>). <source>Final report on the evaluation of the growth model pilot project</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr24-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Koenker</surname>
<given-names>R.</given-names>
</name>
</person-group> (<year>2005</year>). <source>Quantile Regression</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr25-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kolen</surname>
<given-names>M. J.</given-names>
</name>
<name>
<surname>Brennan</surname>
<given-names>R. L.</given-names>
</name>
</person-group> (<year>2004</year>). <source>Test equating, scaling, and linking: Methods and practices</source> (<edition>2nd ed</edition>.). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer Science + Business Media</publisher-name>.</citation>
</ref>
<ref id="bibr26-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Manning</surname>
<given-names>W. H.</given-names>
</name>
<name>
<surname>DuBois</surname>
<given-names>P. H.</given-names>
</name>
</person-group> (<year>1962</year>). <article-title>Correlational methods in research on human learning</article-title>. <source>Perceptual and Motor Skills</source>, <volume>15</volume>, <fpage>287</fpage>–<lpage>321</lpage>.</citation>
</ref>
<ref id="bibr28-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">Massachusetts Department of Elementary and Secondary Education</collab>. (<year>1999</year>). <source>Massachusetts comprehensive assessment system: 1998 technical report</source>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.doe.mass.edu/mcas/tech/98techrpt.pdf">http://www.doe.mass.edu/mcas/tech/98techrpt.pdf</ext-link>
</citation>
</ref>
<ref id="bibr29-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>McCaffrey</surname>
<given-names>D. F.</given-names>
</name>
<name>
<surname>Lockwood</surname>
<given-names>J. R.</given-names>
</name>
<name>
<surname>Koretz</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Louis</surname>
<given-names>T. A.</given-names>
</name>
<name>
<surname>Hamilton</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Models for value-added modeling of teacher effects</article-title>. <source>Journal of Educational and Behavioral Statistics</source>, <volume>29</volume>, <fpage>67</fpage>–<lpage>101</lpage>.</citation>
</ref>
<ref id="bibr30-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Moses</surname>
<given-names>T</given-names>
</name>
</person-group>. (<year>2010</year>). <source>A comparison of quantile regression implementations for estimating student growth quantiles</source>. <comment>Unpublished manuscript</comment>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Educational Testing Service</publisher-name>.</citation>
</ref>
<ref id="bibr31-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">R Development Core Team</collab>. (<year>2009</year>). <source>R: A language and environment for statistical computing</source>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org">http://www.R-project.org</ext-link>
</citation>
</ref>
<ref id="bibr32-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rogosa</surname>
<given-names>D. R.</given-names>
</name>
</person-group> (<year>1995</year>). <article-title>Myth and methods: “Myths about longitudinal research” plus supplemental questions</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Gottmann</surname>
<given-names>J. M.</given-names>
</name>
</person-group> (Ed.), <source>The analysis of change</source> (pp. <fpage>3</fpage>–<lpage>66</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr33-1076998611435413">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rogosa</surname>
<given-names>D. R.</given-names>
</name>
<name>
<surname>Brandt</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Zimowski</surname>
<given-names>M</given-names>
</name>
</person-group>. (<year>1982</year>). <article-title>A growth curve approach to the measurement of change</article-title>. <source>Psychological Bulletin</source>, <volume>92</volume>, <fpage>726</fpage>–<lpage>748</lpage>. <comment>doi:10.1037/0033-2909.92.3.726</comment>
</citation>
</ref>
<ref id="bibr34-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Schumaker</surname>
<given-names>L. L.</given-names>
</name>
</person-group> (<year>2007</year>). <source>Spline functions: Basic theory</source> <edition>(3 rd ed.)</edition>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr35-1076998611435413">
<citation citation-type="web">
<collab collab-type="author">United States Department of Education</collab>. (<year>2009</year>). <source>Race to the top program: Executive summary</source>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www2.ed.gov/programs/racetothetop/executive-summary.pdf">http://www2.ed.gov/programs/racetothetop/executive-summary.pdf</ext-link>
</citation>
</ref>
<ref id="bibr36-1076998611435413">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Williams</surname>
<given-names>J. D.</given-names>
</name>
<name>
<surname>Maresh</surname>
<given-names>R. T.</given-names>
</name>
<name>
<surname>Peebles</surname>
<given-names>J. D</given-names>
</name>
</person-group>. (<year>1972, April</year>). <source>A comparison of raw gain scores, residual gain scores, and the analysis of covariance with two modes of teaching reading</source>. <comment>Paper presented at the annual meeting of the American Educational Research Association, Chicago, Illinois. Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://eric.ed.gov/">http://eric.ed.gov/</ext-link>
</citation>
</ref>
<ref id="bibr37-1076998611435413">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Wright</surname>
<given-names>S. P.</given-names>
</name>
<name>
<surname>Sanders</surname>
<given-names>W. L.</given-names>
</name>
<name>
<surname>Rivers</surname>
<given-names>J. C</given-names>
</name>
</person-group>. (<year>2006</year>). <source>Measurement of academic growth of individual students toward variable and meaningful academic standards</source>. <comment>Retrieved from SAS website</comment>: <ext-link ext-link-type="uri" xlink:href="http://www.sas.com/resources/asset/measurement-of-academic-growth.pdf">http://www.sas.com/resources/asset/measurement-of-academic-growth.pdf</ext-link>
</citation>
</ref>
<ref id="bibr38-1076998611435413">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Zumbo</surname>
<given-names>B. D.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>The simple difference score as an inherently poor measure of change: Some reality, much mythology</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Thompson</surname>
<given-names>B.</given-names>
</name>
</person-group> (Ed.). <source>Advances in social science methodology</source> (Vol. <volume>5</volume>, pp. <fpage>269</fpage>–<lpage>304</lpage>). <publisher-loc>Greenwich, CT</publisher-loc>: <publisher-name>JAI Press</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>