<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MMR</journal-id>
<journal-id journal-id-type="hwp">spmmr</journal-id>
<journal-title>Journal of Mixed Methods Research</journal-title>
<issn pub-type="ppub">1558-6898</issn>
<issn pub-type="epub">1558-6901</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1558689811417133</article-id>
<article-id pub-id-type="publisher-id">10.1177_1558689811417133</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Mixed Methods Sampling Methodology for a Multisite Case Study</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Sharp</surname><given-names>Julia L.</given-names></name>
<xref ref-type="aff" rid="aff1-1558689811417133">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Mobley</surname><given-names>Catherine</given-names></name>
<xref ref-type="aff" rid="aff1-1558689811417133">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hammond</surname><given-names>Cathy</given-names></name>
<xref ref-type="aff" rid="aff1-1558689811417133">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Withington</surname><given-names>Cairen</given-names></name>
<xref ref-type="aff" rid="aff1-1558689811417133">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Drew</surname><given-names>Sam</given-names></name>
<xref ref-type="aff" rid="aff1-1558689811417133">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Stringfield</surname><given-names>Sam</given-names></name>
<xref ref-type="aff" rid="aff2-1558689811417133">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Stipanovic</surname><given-names>Natalie</given-names></name>
<xref ref-type="aff" rid="aff2-1558689811417133">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-1558689811417133"><label>1</label>Clemson University, Clemson, SC, USA</aff>
<aff id="aff2-1558689811417133"><label>2</label>University of Louisville, Louisville, KY, USA</aff>
<author-notes>
<corresp id="corresp1-1558689811417133">Julia L. Sharp, Department of Applied Economics and Statistics, 237 Barre Hall, Clemson University, Clemson, SC 29634-0313, USA Email: <email>jsharp@clemson.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>6</volume>
<issue>1</issue>
<fpage>34</fpage>
<lpage>54</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The flexibility of mixed methods research strategies makes such approaches especially suitable for multisite case studies. Yet the utilization of mixed methods to select sites for these studies is rarely reported. The authors describe their pragmatic mixed methods approach to select a sample for their multisite mixed methods case study of a statewide education policy initiative in the United States. The authors designed a four-stage sequential mixed methods site selection strategy to select eight sites in order to capture the broader context of the research, as well as any contextual nuances that shape policy implementation. The authors anticipate that their experience would provide guidance to other mixed methods researchers seeking to maximize the rigor of their multisite case study sampling designs.</p>
</abstract>
<kwd-group>
<kwd>site selection</kwd>
<kwd>mixed methods sampling</kwd>
<kwd>mixed methods study</kwd>
<kwd>case study</kwd>
<kwd>purposive sampling</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Social scientists use mixed methods research in a variety of contexts, including educational research and policy analyses. Ultimately, the mixing decisions in these studies entail deciding on how and at what stages the mixing will occur (<xref ref-type="bibr" rid="bibr10-1558689811417133">Creswell &amp; Plano Clark, 2007</xref>). Much of the pertinent literature focuses on selecting qualitative and quantitative data collection strategies to explore the study’s research questions. More robust studies often involve mixing methods throughout the research process (<xref ref-type="bibr" rid="bibr49-1558689811417133">Tashakkori &amp; Teddlie, 1998</xref>, <xref ref-type="bibr" rid="bibr50-1558689811417133">2003a</xref>), including during the sample or site selection stage of research.</p>
<p><xref ref-type="bibr" rid="bibr9-1558689811417133">Collins, Onwuegbuzie, and Jiao (2007)</xref> described sample selection as one of the most important stages of mixed methods studies. Mixed methods sampling techniques may be useful when it is challenging to obtain a representative sample using only one method. Such sampling techniques are often appropriate for mixed methods studies that incorporate both goals of generalizability of research findings and in-depth understanding of the research context (<xref ref-type="bibr" rid="bibr21-1558689811417133">Kemper, Stringfield, &amp; Teddlie, 2003</xref>; <xref ref-type="bibr" rid="bibr28-1558689811417133">Onwuegbuzie &amp; Leech, 2007</xref>). Specifically, if a study cannot use random assignment or selection, then multistage, mixed methods sampling designs may be used to select participants or sites that are more likely representative of the population studied and that are best suited to answer the research questions.</p>
<p>Addressing sampling issues early in the research design helps ensure that the mixed methodology employed is maximized to the fullest extent possible (<xref ref-type="bibr" rid="bibr24-1558689811417133">Lieber, 2009</xref>). Yet few mixed methods studies provide enough details about sample or site selection so researchers can learn from the strategy employed (<xref ref-type="bibr" rid="bibr55-1558689811417133">Teddlie &amp; Tashakkori, 2009</xref>). <xref ref-type="bibr" rid="bibr9-1558689811417133">Collins et al.’s (2007)</xref> extensive literature review uncovered only four articles that specifically address sample selection. There is a similar lack of published information about how to best select sites for multisite case studies (<xref ref-type="bibr" rid="bibr28-1558689811417133">Onwuegbuzie &amp; Leech, 2007</xref>).</p>
<p>Our study aims to fill this gap in the literature. In our article, we describe the mixed methods multisite study of a statewide education policy initiative and the sampling strategy that we developed and used to select sites. We anticipate that our experience can provide guidance to other mixed methods researchers seeking to maximize the rigor of their own multisite case study sampling designs.</p>
<sec id="section1-1558689811417133">
<title>Background of Our Mixed Methods Multisite Case Study</title>
<p>There continues to be much concern regarding how best to prepare students for higher education and ultimately the demands of the modern workplace. This concern is evidenced in federal, state, and local legislation, initiatives, and programs. A major focus of the Obama administration’s education agenda is preparing students for college and/or for high-skill, high-wage jobs (<xref ref-type="bibr" rid="bibr60-1558689811417133">White House Web site, 2010</xref>). Across the United States, policymakers have developed innovative programs and curriculum reform efforts to improve school-to-work and school-to-college transitions.</p>
<p>In 2007, the National Research Center for Career and Technical Education funded three overlapping multiyear studies to investigate the development of Perkins IV–defined Programs of Study (POS) and the impact of POS on student outcomes (see <xref ref-type="table" rid="table1-1558689811417133">Table 1</xref> for acronym definitions). Our study, one of the three, is a longitudinal, 5-year examination of the early effects of a state-mandated school reform policy that requires a focus on career awareness and exploration at all school levels. This policy is based on South Carolina’s Education and Economic Development Act (EEDA) of 2005 that mandated the creation of locally relevant career pathways or programs of study in high schools. Among other requirements, these pathways or programs must align with postsecondary education, pertain to local economic realities and industry, and provide work-based learning opportunities for students. All South Carolina public schools are expected to have fully implemented EEDA by July 2011.</p>
<table-wrap id="table1-1558689811417133" position="float">
<label>Table 1.</label>
<caption>
<p>Definition of Acronyms</p>
</caption>
<graphic alternate-form-of="table1-1558689811417133" xlink:href="10.1177_1558689811417133-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Acronym</th>
<th align="center">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>EEDA</td>
<td>Education and Economic Development Act</td>
</tr>
<tr>
<td>IGP</td>
<td>Individual Graduation Plan</td>
</tr>
<tr>
<td>NRCCTE</td>
<td>National Research Center for Career and Technical Education</td>
</tr>
<tr>
<td>POS</td>
<td>Programs of Study</td>
</tr>
<tr>
<td>PSLOI</td>
<td>Preliminary Site Selection Level of Policy Implementation</td>
</tr>
<tr>
<td>SDE</td>
<td>South Carolina Department of Education</td>
</tr>
<tr>
<td>SLOI</td>
<td>Site Selection Level of Policy Implementation</td>
</tr>
<tr>
<td>WIA</td>
<td>Workforce Investment Area</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Our overarching study aims to assess the extent to which a statewide reform mandate such as EEDA facilitates the creation of POS and whether these POS affect students’ engagement, achievement, high school completion, and successful transition to postsecondary education and/or employment. We also explore whether or not the availability of school and community resources and future employment opportunities influence the development of POS and the outcomes of students enrolled in them. This study considers two main questions: (a) Can a statewide mandate like EEDA increase the number of and level of participation in school POS? and (b) How does the number of and level of participation in POS, in combination with various political, economic, and social characteristics, influence selected outcomes for South Carolina’s secondary students and the schools they attend?</p>
<p>Given that the state law applies to all high schools in South Carolina, random assignment of schools to experimental and control groups was not possible. Thus, our 5-year study employs a quasi-experimental design with a mixed methods, triangulated approach (<xref ref-type="bibr" rid="bibr50-1558689811417133">Tashakkori &amp; Teddlie, 2003a</xref>), following three student cohorts (the Classes of 2009, 2011, and 2014) from a sample of eight high schools from economically and culturally diverse regions of South Carolina. Each school’s Class of 2009 received very little to no exposure to the reforms, whereas the Class of 2011 is receiving exposure during high school and the Class of 2014 is receiving exposure from middle through high school. Using a mixed methods research design will help us achieve a broader understanding of the policy’s impacts on students, teachers, schools, and POS creation.</p>
<p>Our study most closely approximates the pragmatic parallel mixed methods research design in which both qualitative and quantitative data are collected and analyzed to address research questions. The mixing occurs either concurrently or after some time passes (<xref ref-type="bibr" rid="bibr25-1558689811417133">Mertens, 2010</xref>). The qualitative and quantitative approaches address various dimensions of the main research questions (<xref ref-type="bibr" rid="bibr55-1558689811417133">Teddlie &amp; Tashakkori, 2009</xref>). Quantitative data include student outcome data (e.g., grades and attendance) from the three student cohorts and responses from student questionnaires. Qualitative data include the results from content analyses of school course catalogs and career-related materials and perspectives culled from interviews and focus groups conducted with school administrators, counselors, and teachers from sample high schools, relevant career center staff, and administrators at partner two-year colleges. Both qualitative and quantitative data come from student Individual Graduation Plans (IGPs) from the state database, questionnaires of guidance personnel and high school principals, and Class of 2009 and Class of 2011 student transition and post-graduation information.</p>
</sec>
<sec id="section2-1558689811417133">
<title>Justification for Using Mixed Methods Research for Our Multisite Case Study</title>
<p>The choice to use a mixture of qualitative or quantitative methods is a reflection of an epistemological, or philosophical, stance to research, as much as it is a choice in actual data collection methodologies. Case studies can be postpositivistic, phenomenological, or both (<xref ref-type="bibr" rid="bibr1-1558689811417133">Amaratunga, Baldry, Sarshar, &amp; Newton, 2002</xref>). Our study was influenced by the research philosophy of pragmatism that served as a bridge between conflicting paradigms and across the paradigm–methodology–method continuum (<xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>). Indeed, the complex nature of the social world requires a more fluid understanding and application of the relationship between philosophical paradigms (assumptions about the social world and nature of knowledge), methodology (the logic of inquiry), and methods (techniques of data collection).</p>
<p>Various authors have argued for the need to move beyond incommensurability, whereby one set of philosophical assumptions necessarily dictates a specific methodological approach, which would then subsequently limit one’s choice of data collection methods (<xref ref-type="bibr" rid="bibr18-1558689811417133">Howe, 1988</xref>; <xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>). As described below, the flexibility inherent in a pragmatic approach to research is especially important in complex case studies.</p>
<p>Longitudinal multisite case studies like ours combine the study of specific sites with an exploration of the various contexts in which the policy might be implemented to provide a broader basis for generalization (<xref ref-type="bibr" rid="bibr37-1558689811417133">Simons, 1996</xref>). For our study, we faced the challenges of selecting sites that were representative of the study area (South Carolina) while also selecting sites that could tell us the most about the complexities of policy implementation. To meet these challenges, our research design and site selection process relied on the epistemological approach of pragmatism (<xref ref-type="bibr" rid="bibr4-1558689811417133">Biesta, 2010</xref>; <xref ref-type="bibr" rid="bibr17-1558689811417133">Greene &amp; Hall, 2010</xref>). This mixed methods research approach is primarily guided by a study’s research questions, is based on the needs of and contingencies present in a particular study, and ultimately reflects a value of both subjective and objective knowledge (<xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>; <xref ref-type="bibr" rid="bibr50-1558689811417133">Tashakkori &amp; Teddlie, 2003a</xref>). This pragmatic research philosophy results in more robust and interesting findings and thus is of greater value to policymakers and practitioners (<xref ref-type="bibr" rid="bibr34-1558689811417133">Sammons, 2010</xref>), although we recognize that pragmatism is not the only, or even most appropriate, philosophical foundation for all mixed methods research (<xref ref-type="bibr" rid="bibr4-1558689811417133">Biesta, 2010</xref>; <xref ref-type="bibr" rid="bibr17-1558689811417133">Greene &amp; Hall, 2010</xref>).</p>
<p>Several principles of pragmatism influenced our logic of inquiry, research design, and the methods used for our site selection process (<xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>):</p>
<list id="list1-1558689811417133" list-type="bullet">
<list-item><p>Pragmatism recognizes the importance of eclecticism and pluralism whereby “different, even conflicting theories and perspectives can be useful; observation, experience and experiments are all useful ways to gain an understanding of people and the world” (<xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>, p. 18).</p></list-item>
<list-item><p>Pragmatists prefer action over philosophizing.</p></list-item>
<list-item><p>Pragmatism endorses practical theory or praxis (theory that informs effective practice).</p></list-item>
<list-item><p>From a pragmatic perspective, “knowledge is viewed as being both constructed and based on the reality of the world we experience and live in” (<xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>, p. 18).</p></list-item>
</list>
<p>These principles of pragmatism subsequently influenced our logic of inquiry on four different levels described below.</p>
<p>First, as a study of policy implementation, our research seeks “actionable knowledge of direct practical value in the context being studied” (<xref ref-type="bibr" rid="bibr17-1558689811417133">Greene &amp; Hall, 2010</xref>, p. 138). The nature of our study made it important for us to consider how the data would help us learn about the impact of the legislation and school-based policies related to POS. As expressed by <xref ref-type="bibr" rid="bibr31-1558689811417133">Rorty (1999)</xref>, a more comprehensive assessment of policy implementation can be obtained using a pragmatic approach, not necessarily for the goal of providing a more “accurate account” but rather to improve the usefulness of the research. Thus, we had to be mindful of the consequences of our study, its utility for informing future policy initiatives (<xref ref-type="bibr" rid="bibr13-1558689811417133">Feilzer, 2010</xref>), and its value for a variety of stakeholders, including practitioners and policy makers (<xref ref-type="bibr" rid="bibr34-1558689811417133">Sammons, 2010</xref>).</p>
<p>In a similar vein, we felt it was important to capture the broader context of the research as well as the subtle contextual nuances that shaped policy implementation and how these varied across the study sites. This contextual search is a second quality of pragmatism that influenced our research. This notion is reinforced by research that demonstrates that some schools are more effective in achieving outcomes (such as implementing a complex policy like EEDA) than others (<xref ref-type="bibr" rid="bibr51-1558689811417133">Tashakkori &amp; Teddlie, 2003b</xref>). Thus, we recognized the need to account for school effects and other contextual variables when explaining outcomes.</p>
<p>Third, a pragmatic approach to sample selection shaped our conceptions of generalizability and how the findings can be applied when reporting study results. Careful selection of sites is no trivial matter and this choice is often governed by whether the researcher wants to generalize results to a larger population (in which case random sampling is often used) or desires to learn more about a specific setting or phenomenon (in which case purposive sampling strategies are often used; <xref ref-type="bibr" rid="bibr28-1558689811417133">Onwuegbuzie &amp; Leech, 2007</xref>). As <xref ref-type="bibr" rid="bibr49-1558689811417133">Tashakkori and Teddlie (1998)</xref> claimed, mixed methods researchers often switch between different types of generalizability–generalizing results to a theoretical population and generalizing results to another specific setting. The intermingling of quantitative and qualitative approaches and their underlying philosophies is a central feature of mixed methods studies and of multisite case studies where there is pressure to generalize research findings beyond a single case (<xref ref-type="bibr" rid="bibr37-1558689811417133">Simons, 1996</xref>). In light of these factors, our study used a purposive sampling strategy that integrated quantitative and qualitative approaches.</p>
<p>Finally, from a pragmatic perspective, mixed methods studies are strengthened when research teams are composed of individuals from a variety of disciplines (<xref ref-type="bibr" rid="bibr34-1558689811417133">Sammons, 2010</xref>). This reflects <xref ref-type="bibr" rid="bibr16-1558689811417133">Greene’s (2007)</xref> notion that mixed methods researchers should engage in a “mixed methods way of thinking,” whereby we not only mix methodologies but also “different ways of seeing, interpreting, and knowing” about the social world (p. xi). The development of our research design and site selection process was influenced by the make-up of the research team and a consideration of the relationships between the team members themselves and between the team members and the study design, a feature of mixed methods research (<xref ref-type="bibr" rid="bibr34-1558689811417133">Sammons, 2010</xref>; <xref ref-type="bibr" rid="bibr51-1558689811417133">Tashakkori &amp; Teddlie, 2003b</xref>). Our team includes a statistician, an economist, sociologists, and educational researchers, each contributing unique methodological training and skills to the project. According to <xref ref-type="bibr" rid="bibr55-1558689811417133">Teddlie and Tashakkori (2009)</xref>, this collaborative team approach is especially useful for mixed methods studies such as ours that use the parallel mixed methods design.</p>
<p>The philosophical approach of pragmatism and the four elements comprising our logic of inquiry shaped our choice of methods used to select study sites. In the next section, we review the literature on case studies and sample selection.</p>
</sec>
<sec id="section3-1558689811417133">
<title>Selecting Sample Sites for Mixed Methods Case Studies</title>
<p><xref ref-type="bibr" rid="bibr64-1558689811417133">Yin (2003)</xref> cited several reasons for engaging in case studies. Case studies are (a) relevant when the focus of a study is on “how” and “why,” (b) used when researchers cannot manipulate the behavior of those under study, (c) appropriate when researchers want to learn more about the contextual conditions that are especially relevant to the phenomenon under study, and (d) used when the boundaries between the subject of study and the context are not clear. All four of these reasons are applicable to our study.</p>
<p><xref ref-type="bibr" rid="bibr63-1558689811417133">Yin (1994)</xref> distinguished between a variety of case study approaches ranging from a single case study to multiple case studies such as the Type 4 design, which involves multiple sources of data, multiple cases, multiple methods, and multiple units of analysis. Longitudinal multisite case studies such as ours offer a combination of the study of a specific site with the need to understand the context and provide a wider basis for generalizing findings (<xref ref-type="bibr" rid="bibr37-1558689811417133">Simons, 1996</xref>). Such studies are particularly valuable as they allow for comparisons within cases and across time and contexts, thus offering a “rich harvest of lessons and insights” (<xref ref-type="bibr" rid="bibr66-1558689811417133">Zartman, 2005</xref>, p. 8).</p>
<p>Despite the recognition that a mixed methods design is appropriate for case studies, the literature offers little guidance on how to select study sites and how many sites to select. Researchers often resort to convenience sampling and choosing sites that allow easy access. As a result, site selection often lacks any theoretical justification and the resulting data are often not situated within a particular theoretical context (<xref ref-type="bibr" rid="bibr58-1558689811417133">Walford, 2001</xref>). Although we recognize the need for convenience sampling in some cases, our work highlights the importance of rigor when selecting sites for case studies, especially when researchers need to understand the influence of a policy on outcomes achieved within complex settings, such as educational institutions. Such complex studies often require that researchers use a combination of quantitative and qualitative sampling techniques (<xref ref-type="bibr" rid="bibr21-1558689811417133">Kemper et al., 2003</xref>).</p>
<p>Concerning sampling strategies, <xref ref-type="bibr" rid="bibr15-1558689811417133">Goetz and LeCompte (1984)</xref> called for <italic>criterion-based sampling</italic> to “establish the criteria, bases, or standards necessary for units to be included” in the research study (p. 77). This idea of criterion-based sampling is similar to <italic>purposeful or purposive sampling</italic> designs that are often used to select a sample to attain representativeness or comparability in a study (<xref ref-type="bibr" rid="bibr29-1558689811417133">Patton, 1980</xref>; <xref ref-type="bibr" rid="bibr56-1558689811417133">Teddlie &amp; Yu, 2007</xref>). However, both strategies offer more generalized guidelines than those used in our study. That is, we did not select what <xref ref-type="bibr" rid="bibr29-1558689811417133">Patton (1980)</xref> described as the most extreme or deviant, typical cases, critical cases, or politically sensitive cases. Other site selection criteria include choosing sites that have high experience levels of the phenomenon under study and choosing sites that increase the chance for negotiating access (<xref ref-type="bibr" rid="bibr30-1558689811417133">Pettigrew, 1990</xref>). Some of these factors played an indirect role in, but did not drive, our selection process.</p>
<p>No universal rule exists regarding the number of sites to select for multisite case studies (<xref ref-type="bibr" rid="bibr2-1558689811417133">Axinn &amp; Pearce, 2006</xref>). <xref ref-type="bibr" rid="bibr65-1558689811417133">Yin (2009)</xref> observed that the number of cases depends on both literal replication (the amount of certainty desired concerning the research findings) and theoretical replication (the extent to which external, contextual factors shape research findings and how many cases are needed to reflect this variety). Such decisions are directly related to the idea that case study research is not meant to be generalizable in the positivist, statistical sense of the word. Thus, the traditional concept of random sampling typically does not apply to multisite case studies (<xref ref-type="bibr" rid="bibr65-1558689811417133">Yin, 2009</xref>). Rather, a purposive sampling strategy generally is used to select the best sites possible, given the research goals and questions.</p>
<p>Our mixed methods sampling strategy represents a unique integration of quantitative and qualitative methods at the sampling (i.e., site selection) phase of our mixed methods study (<xref ref-type="bibr" rid="bibr27-1558689811417133">O’Cathain, Murphy, &amp; Nicholl, 2007</xref>). Within the context of our overarching parallel mixed methods study, we developed a four-stage nested mixed methods sampling strategy following the principles of a pragmatic sequential mixed methods approach. With this strategy, one type of data informs the collection of another type of data in a subsequent stage (<xref ref-type="bibr" rid="bibr25-1558689811417133">Mertens, 2010</xref>). The remainder of this article describes our mixed methods site selection strategy in more detail.</p>
</sec>
<sec id="section4-1558689811417133">
<title>Using Mixed Methods to Select Sites for Our Multisite Case Study</title>
<p>As is the case in most multisite case studies, we faced the challenges of deciding how to select study sites (i.e., high schools) and identifying relevant criteria for selecting those sites. Budgetary and time restraints limited the number of sites that could be studied, thus making it even more important to choose sites in a way that would allow us to learn as much as possible about state policy implementation and POS under differing school conditions.</p>
<p><xref ref-type="bibr" rid="bibr9-1558689811417133">Collins et al. (2007)</xref> listed major sampling schemes frequently employed in mixed methods research. A random selection of high schools may have led us to select schools all with similar policy implementation levels or with similar other characteristics that would best be varied in order to address the research questions. Instead, we used a multistage, mixed methods sampling design to select a sample that characterizes the population of interest so we could better analyze the impact of the policy on students and schools.</p>
<p>Similar to <xref ref-type="bibr" rid="bibr59-1558689811417133">Wells, Hirschberg, Lipton, and Oakes’s (1995)</xref> study of school detracking efforts and <xref ref-type="bibr" rid="bibr53-1558689811417133">Teddlie and Stringfield’s (1993)</xref> research on school effects, we were interested in selecting a sample of schools that exhibited variety on primary variables of interest. In particular, we wanted to assure variation on critical variables shown in past research to influence the implementation of school reforms together with other variables that were perceived from the outset to have potential influence on outcomes. Following <xref ref-type="bibr" rid="bibr2-1558689811417133">Axinn and Pearce (2006)</xref>, we sought to identify “all factors believed to produce initial characteristics or conditions in a nonrandom way. These measures can then be used in sophisticated statistical models to simulate random assignment of initial conditions” (p. 161). We used a dual approach to identify key variables—hypothesizing some early on and allowing others to emerge through data collection.</p>
<p>In our site selection plan, we aimed for variation across sites in actual level of policy implementation. Based on policy guidelines provided to schools,<sup><xref ref-type="fn" rid="fn1-1558689811417133">1</xref></sup> the study team identified the most salient initiatives for high schools and grouped them into the following six key facets around which to measure policy implementation: (a) identification of and assistance for students who are at high risk for dropping out of school; (b) integration of rigorous academic and career-focused curricula, organized into career clusters and majors; (c) increased counselor roles in education and career planning; (d) implementation of evidence-based high school reform; (e) facilitation of local business–education partnerships and resource dissemination; and (f) articulation between kindergarten through 12th grade and higher education.</p>
<p>Coupled with a desire for obtaining variety in levels of policy implementation, we aimed to include schools from a diversity of contexts that are important for understanding educational reform efforts such as EEDA. Thus, our sample included high schools that varied across several policy-relevant factors including industry-related variables, availability of community and economic resources, and level of implementation of the statewide policy. Defining these variables before data collection allowed us to discuss in advance how to operationalize the contextual variables relevant for our study. Focusing on these contextual variables during our site selection process enabled us to connect them to student and school outcomes, a consideration that has become increasingly important in school effectiveness research (<xref ref-type="bibr" rid="bibr54-1558689811417133">Teddlie, Stringfield, &amp; Reynolds, 2000</xref>; <xref ref-type="bibr" rid="bibr61-1558689811417133">Wimpelberg, Teddlie, &amp; Stringfield, 1989</xref>) and other kinds of educational studies (<xref ref-type="bibr" rid="bibr34-1558689811417133">Sammons, 2010</xref>).</p>
</sec>
<sec id="section5-1558689811417133">
<title>Our Mixed Methods Site Selection Strategy</title>
<p>In using a mixed methods approach for site selection, we considered several factors important for our study of EEDA implementation and the policy’s impact on POS and student outcomes. First, sample selection and study data collection were narrowed to high schools as the penultimate sites of EEDA efforts, even though EEDA is a kindergarten through college initiative with implications beyond that in terms of further education/training and community partnerships required for successful implementation. Second, the team chose to limit the sampling frame to those high schools considered to be “traditional” high schools that included only Grades 9 through 12.<sup><xref ref-type="fn" rid="fn2-1558689811417133">2</xref></sup> Among the high schools listed on the South Carolina Department of Education website (<xref ref-type="bibr" rid="bibr43-1558689811417133">SDE; 2010</xref>), there were more than 150 schools that we defined as traditional. In all practicality, the team was unable to include all these high schools in our sample. We chose to include eight high schools in our study sample so that we could conduct our study within time and budget constraints, yet effectively answer our research questions. Our final sample size of eight schools was within the number (4-12 sites) suggested by <xref ref-type="bibr" rid="bibr55-1558689811417133">Teddlie and Tashakkori (2009)</xref> for mixed methods multisite case studies.</p>
<p>As an alternative to selecting experimental and control schools and to provide a measure of control over various factors that might affect the study at sample schools, our sampling design followed the MaxMinCon strategy (<xref ref-type="bibr" rid="bibr22-1558689811417133">Kerlinger, 1986</xref>; <xref ref-type="bibr" rid="bibr49-1558689811417133">Tashakkori &amp; Teddlie, 1998</xref>). South Carolina is geographically divided into 12 Workforce Investment Area (WIA) regions (<xref ref-type="fig" rid="fig1-1558689811417133">Figure 1</xref>). The team sampled to Maximize differences among WIAs (e.g., communities offering differing economic opportunities) and schools within WIAs (on level of EEDA implementation based on the six key facets previously listed). Furthermore, the team chose to Minimize differences between schools within WIAs on student background characteristics and district support for the schools, and Control for as many extraneous variables as practical, so as to minimize error variability. Although anchored in a postpositivist tradition, the MaxMinCon methodology is also reflective of the pragmatic goals of generalizability, contextuality, and relevance (<xref ref-type="bibr" rid="bibr49-1558689811417133">Tashakkori &amp; Teddlie, 1998</xref>). This strategy led us to a four-stage sequential school selection process that we describe in more detail below. <xref ref-type="fig" rid="fig2-1558689811417133">Figure 2</xref> provides an illustration of the sampling strategy used for site selection.</p>
<fig id="fig1-1558689811417133" position="float">
<label>Figure 1.</label>
<caption>
<p>Workforce Investment Areas (WIAs) in South Carolina</p>
<p>Note: From South Carolina Employment Security Commission, “Spotlights: WIA Profiles.” Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.sces.org/lmi/spotlights/WIA/">http://www.sces.org/lmi/spotlights/WIA/</ext-link></p>
</caption>
<graphic xlink:href="10.1177_1558689811417133-fig1.tif"/>
</fig>
<fig id="fig2-1558689811417133" position="float">
<label>Figure 2.</label>
<caption>
<p>Sampling strategies and resulting number of schools selected at each stage of the sampling design</p>
<p>Note: Near the end of Stage 3, one cluster of schools declined to participate in the study. A substitute cluster of 12 schools was selected using the Stage 2 process. Stage 3 procedures were then applied to this new group to reach a revised grouping of 10 schools at the end of Stage 3.</p>
</caption>
<graphic xlink:href="10.1177_1558689811417133-fig2.tif"/>
</fig>
<sec id="section6-1558689811417133">
<title>Stage 1: Representing Regional and Industrial Diversity</title>
<p>All high schools could, in theory, offer a wide range of POS options. In practice, schools may have chosen to offer specific POS best matched to the careers most likely to be available to students in their region. Hence, in the first stage of sampling, we introduced controls for economic and industry conditions that might affect the availability and development of business partners for POS and work-based learning opportunities and career-specific education and employment opportunities. Local and regional economics would likely influence policy implementation since the reform model is career-focused and is intended to be linked and relevant to local labor markets and industries. We also wanted to control for a school’s local economic conditions so that we could compare policy implementation for schools facing similar labor market and economic conditions and contrast schools from different local conditions.</p>
<p>We used industry-related (private and government) information for 10 primary industries in each of the 12 WIAs in South Carolina (<xref ref-type="bibr" rid="bibr44-1558689811417133">South Carolina Employment Security Commission, 2008</xref>). As a part of EEDA, a Regional Education Center (REC) is being developed in each WIA to serve as a hub for the region’s training and education resources. The Regional Education Centers will help to facilitate business–education partnerships, coordinate workforce education programs, and promote community involvement. Thus, we considered the WIA as an economic entity focused on a somewhat distinctive industry mix.</p>
<p>Industry employment data, averaged within each WIA, were used in a quantitative Chi-square analysis to explore the association between WIAs and industry employment. We used this analysis to explore the statistical justification to select WIAs based on concentrations of workers in major state industries. Results indicated a significant association (using a significance level of .05) between the WIAs and industry employment, χ<sup>2</sup>(33, <italic>N</italic> = 1,116,799) = 108200.70, <italic>p</italic> &lt; .01. Three WIAs were identified in which employment for one of the top five South Carolina industries (trade, transportation, and utilities; government; manufacturing; leisure and hospitality; and professional and business services) was significantly greater than expected, and one WIA was identified where employment in two of the top five industries was significantly greater than expected. We selected these four WIAs so that we could make comparisons among, and within, WIAs. Fifty-nine high schools that met our school criteria were located in these four WIAs.</p>
<p>Although 59 high schools would have been a more manageable sample than the original sampling frame of more than 150 traditional 4-year high schools in South Carolina, it still would have been difficult for us to collect timely and appropriate data from such a large sample during the study period. The schools in the four WIAs also varied across other study-relevant factors, including local economic conditions, thus making it difficult to discern in our final analysis whether the impact of the legislation was due to policy or economic conditions. For this reason, a second quantitative sampling stage was used to select schools of varying local economic conditions across the WIAs and with similar economic conditions within the WIAs.</p>
</sec>
<sec id="section7-1558689811417133">
<title>Stage 2: Selecting School Clusters Based on Level of Available Economic Resources</title>
<p>During the second sequential stage of school selection, we used hierarchical cluster analysis to cluster schools within each of the four selected WIA regions based on the level of selected local economic measures (i.e., measures that were closer to the school level of analysis). Research indicates that community resource and poverty levels can influence a school’s ability to implement change (<xref ref-type="bibr" rid="bibr5-1558689811417133">Bryk, Sebring, Allensworth, Luppescu, &amp; Easton, 2009</xref>; <xref ref-type="bibr" rid="bibr52-1558689811417133">Teddlie &amp; Reynolds, 2000</xref>). The impact of economic resources on student and school outcomes and on successful implementation of school reforms is also well documented. <xref ref-type="bibr" rid="bibr3-1558689811417133">Balfanz and Legters (2004)</xref> found that urban, low-income high schools, or so-called dropout factories, produced the highest percentages of dropouts. Dropout rates are also higher in impoverished communities (<xref ref-type="bibr" rid="bibr33-1558689811417133">Rumberger, 2001</xref>), and some links have been found between dropout rates and employment rates. Schools with higher concentrations of lower income students tend to have higher dropout rates (<xref ref-type="bibr" rid="bibr32-1558689811417133">Rumberger, 1995</xref>).</p>
<p>We used the following local economic measures to cluster schools within the WIAs: per capita income by postal codes of all students enrolled in each school, a school poverty index based on the percentage of students eligible for Medicaid or qualified for free and/or reduced price lunch by school, the percentage of families in poverty with children below the age of 18 years by postal code, and the percentage civilian unemployment by postal code. Most of the 59 schools in our set of potential sites did not draw from specific postal codes, that is, the postal delivery zones did not align with attendance zones. Therefore, for each potential site, we acquired a data set of postal codes of all students enrolled for the most recent school year, then applied a weight to each postal code for each school according to the proportion of students from each postal code. These weights were then applied to the 2000 Census postal code data so that the data were representative of the student populations at the schools (<xref ref-type="bibr" rid="bibr57-1558689811417133">U.S. Bureau of the Census, 2000</xref>).</p>
<p>A hierarchical cluster analysis was performed within each WIA using SAS v. 9.2 (<xref ref-type="bibr" rid="bibr35-1558689811417133">SAS Institute Inc., 2008</xref>). In this analysis, each observation begins in its own cluster and the two closest clusters (based on the squared distance between the averages) are grouped together. This merging is continued until only one cluster remains. <xref ref-type="fig" rid="fig3-1558689811417133">Figure 3</xref> illustrates the clustering of the 59 schools on the four local economic measures. We clustered schools in each WIA into one of two clusters: either high or low-to-moderate (mid/low) poverty. Clusters selected from two WIAs (one with more urban areas and one with little or no urban areas) included high-poverty schools and clusters selected from the other two WIAs (one with more urban areas and one with little or no urban areas) included low-to-moderate poverty schools. Demographics for the four selected school clusters are shown in <xref ref-type="table" rid="table2-1558689811417133">Table 2</xref>. Thirty-three eligible high schools were contained in these four clusters. Two schools were removed from the sampling frame due to excessive missing data for the third stage,<sup><xref ref-type="fn" rid="fn3-1558689811417133">3</xref></sup> leaving 31 schools from which to select our final sample.</p>
<fig id="fig3-1558689811417133" position="float">
<label>Figure 3.</label>
<caption>
<p>Clustering of 59 schools using data representing local economic conditions</p>
</caption>
<graphic xlink:href="10.1177_1558689811417133-fig3.tif"/>
</fig>
<table-wrap id="table2-1558689811417133" position="float">
<label>Table 2.</label>
<caption>
<p>Demographic Characteristics of School Clusters</p>
</caption>
<graphic alternate-form-of="table2-1558689811417133" xlink:href="10.1177_1558689811417133-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">High-Poverty Clusters</th>
<th align="center" colspan="2">Low-to-Moderate Poverty Clusters</th>
</tr>
<tr>
<th align="left">Demographic Factor</th>
<th align="center">Rural WIA</th>
<th align="center">Urban WIA</th>
<th align="center">Rural WIA</th>
<th align="center">Urban WIA</th>
</tr>
</thead>
<tbody>
<tr>
<td>Average per capita income (1999)<sup><xref ref-type="table-fn" rid="table-fn4-1558689811417133">a</xref></sup></td>
<td>$15,521</td>
<td>$19,752</td>
<td>$19,128</td>
<td>$24,268</td>
</tr>
<tr>
<td>Range in per capita income (1999)<sup><xref ref-type="table-fn" rid="table-fn4-1558689811417133">a</xref></sup></td>
<td>$13,486-$18,156</td>
<td>$16,305-$23,034</td>
<td>$18,638-$19,758</td>
<td>$21,505-$29,223</td>
</tr>
<tr>
<td>Average school poverty index (2004-05, 2005-06, 2006-07)<sup><xref ref-type="table-fn" rid="table-fn5-1558689811417133">b</xref></sup></td>
<td>74%</td>
<td>54%</td>
<td>50%</td>
<td>35%</td>
</tr>
<tr>
<td>Range in school poverty index (2004-05, 2005-06, 2006-07)<sup><xref ref-type="table-fn" rid="table-fn5-1558689811417133">b</xref></sup></td>
<td>50%-92%</td>
<td>36%-83%</td>
<td>47%-57%</td>
<td>13%-51%</td>
</tr>
<tr>
<td>Range in percent unemployment (1999)<sup><xref ref-type="table-fn" rid="table-fn6-1558689811417133">c</xref></sup></td>
<td>5%-12%</td>
<td>3%-7%</td>
<td>4%-5%</td>
<td>2%-7%</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1558689811417133">
<p>Note: WIA = Workforce Investment Area.</p>
</fn>
<fn id="table-fn4-1558689811417133">
<label>a.</label>
<p>A local per capita income figure was derived for each school using weighted 5-digit postal code data (weighted by postal code residence data for students enrolled in each school) from the U.S. Census Bureau. <italic>2000 Census of Population and Housing</italic>, Summary File 3 (SF3), Sample Data, Table P82 Per Capita Income in 1999 (Dollars)—Universe: Total population. The list of postal codes used to get weighted averages of all census data for schools came from South Carolina Department of Education, Office of Data Management and Analysis (personal communication, September 25, 2008).</p>
</fn>
<fn id="table-fn5-1558689811417133">
<label>b.</label>
<p>This is school-level data published in the South Carolina Department of Education <italic>State of South Carolina Education Accountability Act report cards</italic> (<xref ref-type="bibr" rid="bibr39-1558689811417133">South Carolina Department of Education, 2005</xref>, <xref ref-type="bibr" rid="bibr40-1558689811417133">2006a</xref>, <xref ref-type="bibr" rid="bibr42-1558689811417133">2007</xref>), available online at the South Carolina Department of Education website. The poverty index is a measure of the percentage of students at each school eligible for Medicaid or qualified for free and/or reduced lunch.</p>
</fn>
<fn id="table-fn6-1558689811417133">
<label>c.</label>
<p>A local percentage of civilian unemployment figure was derived for each school using weighted 5-digit postal code data (weighted by postal code residence data for students enrolled in each school) from the U.S. Census Bureau. <italic>2000 Census of Population and Housing</italic>, SF3, Sample Data, Table P43 Sex by Employment Status for the Population 16 Years and Over—Universe: Population 16 years and over.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section8-1558689811417133">
<title>Stage 3: Ranking High Schools on EEDA Implementation Within Each Selected WIA Cluster</title>
<p>Researchers in multisite case studies have frequently selected schools based on varying levels of implementation or exposure to a particular policy or practice (e.g., <xref ref-type="bibr" rid="bibr6-1558689811417133">Burgess, Pole, Evans, &amp; Priestly, 1994</xref>). Several studies provided strong support for including prior level of implementation as a selection variable for our study (<xref ref-type="bibr" rid="bibr47-1558689811417133">Stallings &amp; Kaskowitz, 1974</xref>; <xref ref-type="bibr" rid="bibr48-1558689811417133">Stringfield, Millsap, &amp; Herman, 1997</xref>; <xref ref-type="bibr" rid="bibr11-1558689811417133">Datnow, Borman, Stringfield, Overman, &amp; Castellano, 2003</xref>). Selecting schools that exhibit a range of implementation levels helped us avoid a challenge that frequently arises in multisite studies: selecting only schools that are exemplary or selecting only schools that exhibit low levels of implementation (<xref ref-type="bibr" rid="bibr7-1558689811417133">Christ, 2007</xref>; <xref ref-type="bibr" rid="bibr62-1558689811417133">Wolf, Borko, Elliott, &amp; McIver, 2000</xref>). <xref ref-type="bibr" rid="bibr30-1558689811417133">Pettigrew (1990)</xref> recommended identifying “polar sites” for study, whereby researchers select cases that illustrate high and low performance on the indicator of interest.</p>
<p>In the third sequential stage of sample selection, the research team gave schools preliminary site selection level of policy implementation (PSLOI) scores based on available data from the 2007-2008 school year (the initial year of the study) on the six measures previously described. Because visiting all 31 schools was not practical, we used data from the SDE and school and district websites to assist in formulating the PSLOI scores. The PSLOI scores allowed us to consider relevant contextual factors during sample selection.</p>
<p>The research team collected both quantitative and qualitative data on school EEDA implementation to obtain the PSLOI for each school. Survey data were collected from a state-mandated questionnaire on guidance activities and an SDE high school reform needs questionnaire. We acquired additional SDE data on each school’s progress in policy implementation. Schools are required to inform staff, parents, and students about EEDA, and many choose to do so through school websites. An instrument was developed to analyze content of materials, text, and catalogs available on school and district websites about curriculum, course selection, registration, programs, guidance personnel, and materials for parents and students. The content analysis consisted of conceptual analysis of materials to identify the common and most consistent themes as they related to the research questions and the policy itself. We looked at how closely these materials met the state’s standard policy format and how much EEDA information schools provided on their websites.<sup><xref ref-type="fn" rid="fn4-1558689811417133">4</xref></sup> We used the constant comparative method of analysis (<xref ref-type="bibr" rid="bibr14-1558689811417133">Glaser &amp; Straus, 1967</xref>), comparing the various sources of data, simultaneously coding and analyzing the data as we progressed. The content analysis instrument was tested until 100% agreement among three reviewers was achieved. In total, three schools were used to test the instrument. The instrument was then used to content analyze each school’s website. We also contacted schools and districts to collect missing data so as not to bias PSLOI simply due to ineffective or poor school or district websites.</p>
<p>From the SDE data sources and the website analyses, we initially identified 63 possible data points that could be used to rank schools on our six identified key policy facets. After more in-depth review of each data point, some were found to duplicate content measured by other data points whereas others seemed unreliable (e.g., a survey question was unclear and responses varied widely). We chose 41 of the possible 63 data points to include in our scoring. A final coding scheme was devised for all the data used.<sup><xref ref-type="fn" rid="fn5-1558689811417133">5</xref></sup> Schools that had more advanced implementation of the state policy across the six identified facets received higher PSLOI scores, and schools that had less advanced implementation across the six facets received lower PSLOI scores.</p>
<p>Schools were then rank ordered within clusters on the PSLOI scores, with the goal of identifying one school with a high level and one school with a low level of implementation from each cluster. <xref ref-type="fig" rid="fig4-1558689811417133">Figure 4</xref> illustrates the range in PSLOI scores across the schools within WIAs. If two or more schools had similar PSLOI scores, we considered other factors such as school size, urbanicity of the school (as defined by the <xref ref-type="bibr" rid="bibr26-1558689811417133">National Center for Education Statistics, 2002</xref>), and minority enrollment to ensure that a diverse array of schools was chosen. Sixteen high schools (two with high PSLOI and two with low PSLOI scores in each of the four clusters) were invited to receive preliminary site data validation visits and to possibly participate in the study.</p>
<fig id="fig4-1558689811417133" position="float">
<label>Figure 4.</label>
<caption>
<p>Preliminary selection level of implementation (PSLOI) scores for the 43 high schools considered for inclusion in the sample</p>
<p>Note: The 16 original schools invited to participate are shown with solid black bars; WIA4 schools declined to participate as did several other schools (labeled with “D” in school names). Substitute schools invited to participate are shown with striped bars (and labeled with “S” in school names). Eight schools selected for study have stars above their bars. In all, 43 (31 across original 4 clusters plus 12 in new “replacement” WIA3 high poverty cluster) were given PSLOI scores and considered for inclusion in the study.</p>
<p>a. Schools are numbered in order of PSLOI by WIA cluster. Letters following the numbers in school names correspond to the following codes: F = one of the first 16 schools chosen; V = visited but not selected; D = declined to participate, did not conform to criteria, or never responded to invitation; S = substitute school; N = school from new WIA3 high poverty cluster invited to participate.</p>
</caption>
<graphic xlink:href="10.1177_1558689811417133-fig4.tif"/>
</fig>
<p>Of the initial 16 schools (schools marked by solid black lines in <xref ref-type="fig" rid="fig4-1558689811417133">Figure 4</xref>, with “F” in the school name to signify “first round” picks) contacted, nine agreed to receive visits, whereas the remaining schools either did not respond to repeated contacts or declined to participate (<xref ref-type="fig" rid="fig4-1558689811417133">Figure 4</xref>, “D” in the school name to signify “declined”). One of these nine schools, School 4FD (<xref ref-type="fig" rid="fig4-1558689811417133">Figure 4</xref>) was removed from the sampling frame when the structure of the high school was modified so that it no longer met our definition for inclusion in the study. In the WIA with the fewest schools accepting our invitation to participate in the study (WIA3), we invited two substitute high schools with PSLOI scores similar to those schools not participating to receive validation visits (<xref ref-type="fig" rid="fig4-1558689811417133">Figure 4</xref>, “S” in the school name to signify “substitutes”). One of the two substitute schools agreed to participate and was included in Stage 4.</p>
<p>Toward the end of Stage 3, schools in one WIA cluster declined to participate in our study (WIA4 in <xref ref-type="fig" rid="fig3-1558689811417133">Figure 3</xref>) due to their time, budgetary, and research circumstances. To compensate for losing WIA4, the high-poverty cluster from the remaining urban group from the Stage 2 sampling frame was added as a substitute cluster. We contacted three schools from the substitute cluster (WIA3, urban, high-poverty). One of these three schools agreed to participate and was also included in Stage 4. Thus, at the end of Stage 3, we had identified 10 schools to receive site visits in Stage 4.</p>
</sec>
<sec id="section9-1558689811417133">
<title>Stage 4: Validating Policy Implementation Level and Variation on Key School Characteristics</title>
<p>The fourth stage of the sampling scheme involved site visits to validate the qualitative and quantitative data collected in the prior stages. We visited the schools to verify that the PSLOI scores generally reflected the reality at the schools and to determine the qualifications of the school for inclusion in the final study sample. The 10 site visits were scheduled with the assistance of site administrators. The research team met with key school personnel including principals, assistant principals, guidance directors, guidance counselors, and teachers to verify the scores. Interviews with each individual or group were 30 minutes to 1 hour in length. We asked about EEDA implementation, the stage of development of the high school’s majors and career pathways, and the operational details of the IGP development process. We asked guidance directors and guidance personnel to describe their specific roles in policy implementation; the ways in which they work with students, teachers, and parents on career development; and the amount of time they devoted to these activities.</p>
<p>We conducted one to three focus groups with 9th and 10th grade teachers at each school. Each group included three to six teachers from different concentration areas, including math, English, social studies, science, career and technical education, honors, advanced placement (courses through which students have the opportunity to earn college credit), college preparation, and basic and special education courses. Focus groups lasted from 45 minutes to 1 hour each. Teachers were asked to discuss their perceptions of school implementation of the various components of EEDA, including career-focused activities and curricula, the progress made in implementation, and the impacts of the reform on their work generally and specifically on how they teach their courses (<xref ref-type="bibr" rid="bibr38-1558689811417133">Smink et al., 2010</xref>).</p>
<p>From the site visit interviews and observations, the team was able to substantiate the initial implementation selection scores and revise where necessary. The PSLOI scores were updated from verified information gathered during the validation site visits. The new scores (called site selection level of policy implementation scores; SLOI) were used for final sample selection and will also be revised for use at the end of the study to compare the change in level of policy implementation over time. In addition to SLOI scores, we considered other information for our final selection of study sites including school staff opinions on policy implementation, the school’s interest in participation in the study, and the school’s cooperation in providing materials.</p>
<p>The final eight high schools selected varied in terms of the level of EEDA implementation (high and low-to-moderate) and levels of poverty, urbanicity, and industry characteristics (as characterized by location within a particular WIA). As a result, in our subsequent analyses, we will be better able to make important comparisons between and among schools, based on the characteristics of the schools. We will also be able to obtain a wide variety of information to understand better how these and other factors influence state policy implementation and subsequently other outcomes of interest.</p>
</sec>
</sec>
<sec id="section10-1558689811417133">
<title>Discussion</title>
<p>Case studies are characterized by their multilevel, multidimensional characteristics. Such research studies naturally evolve over time, as do the contexts and sites themselves. Schools are complex and hierarchical in nature, with multiple interrelated levels, including students, classrooms, schools, and districts. A number of factors about our study and the settings we explored led us to a mixed methods approach not only for data collection and analysis to address our research questions but also to select our study sites so that we could investigate these questions. Multiple vantage points and data sources are necessary to better understand the complexity of these educational settings. Such complexities inevitably invite reflection on how we framed our research, designed the overall study, and developed our site selection strategy.</p>
<p>We assume that mixed methods have been used to select participants or cases for other mixed methods research studies, but few authors have described the specifics of their sampling strategies. Specifically, we used quantitative analyses to select four WIA regions (Stage 1) and to cluster schools from these regions by selected local economic measures to select high and low-to-moderate poverty schools (Stage 2). During the third and fourth stages of sampling, we not only used qualitative and quantitative data but also qualitative and quantitative methods to obtain scores to better rank and compare schools for site selection. This mixed methods sampling design was crucial to help us address the research questions for our study, a reflection of our pragmatic philosophical stance to the study design.</p>
<p>Our study was influenced by several factors common to policy implementation studies. For example, the primary goal of Stages 3 and 4 was to assess whether schools were meeting EEDA mandates as of the date we selected our sites. Since we aim to examine the implementation and impact of a mandated state policy on school and student outcomes, we realized that there would be both official reports of the implementation process, so that the school will appear to be following mandates, and firsthand data about the actual implementation process at schools. Such data may show that the policy is not being fully implemented or is not implemented as required. Policy implementation research must also account for the various individuals who need to implement the policy and the fact that implementation is filtered down through the hierarchy. At the school level, the policy must be interpreted by administrators, implemented by counselors and teachers, and requires student participation.</p>
<p>The mixing of quantitative and qualitative data sources during the sequential site selection process allowed us to corroborate the various sources of information and to accommodate multiple viewpoints on initial levels of policy implementation. Comparing questionnaire results with school archival data and following up with school staff were essential for checking the quality of various data sources used for site selection. This corroboration increased our confidence in the combined data to address our research questions, an important consideration in mixed methods research (<xref ref-type="bibr" rid="bibr10-1558689811417133">Creswell &amp; Plano Clark, 2007</xref>).</p>
<p>Pragmatism provided the essential framework for our research design and for site selection methodology. <xref ref-type="bibr" rid="bibr20-1558689811417133">Johnson, Onwuegbuzie, and Turner (2007)</xref> observed that mixed methods research “should be used when the nexus of contingencies in a situation, in relation to one’s research question(s), suggests that mixed methods research is likely to provide superior research findings and outcomes” (p. 129). The mixed methods sampling design was crucial to help us address the research questions for our study, a reflection of our pragmatic philosophical stance to the study design. In the context of our complex multisite case study, we were particularly influenced by the notions that (a) there are multiple routes to knowledge, (b) as policy researchers we should make “warranted assertions” rather than ultimate claims of truth, and (c) theories are important for predicting and explaining change, rather than being viewed as “true” or “false” (<xref ref-type="bibr" rid="bibr19-1558689811417133">Johnson &amp; Onwuegbuzie, 2004</xref>). That is, the complex and multilevel nature of our longitudinal case study required a philosophical stance that recognizes that research is situated and purposeful (<xref ref-type="bibr" rid="bibr36-1558689811417133">Scott &amp; Briggs, 2009</xref>).</p>
<p>As described earlier, four pragmatic principles influenced our logic of inquiry (methodology) and our data collection techniques (method)—utility, contextual relevance, generalization, and the use of interdisciplinary research teams. These principles were enacted throughout our four-stage site selection process. Because this process was ultimately guided by our desire to learn more about a complex policy initiative, it was important for us to consider how the data would help us learn about the impact of the legislation and school-based policies related to POS. Thus, by using a pragmatic framework, we recognized the need to obtain a more comprehensive picture of policy implementation (e.g., by quantifying the varying implementation levels in Stage 3) and to learn more about differences between sites in policy implementation. In studies of policy implementation, the researcher will not always be aware of all the contextual factors that influence policy implementation. By conducting interviews and focus groups with school staff during Stage 4, we were able to consider aspects of implementation that were not apparent from the review of official policy guidelines and data. We were also able to appraise contextual influences that challenged and/or altered policy implementation at school sites.</p>
<p>From a pragmatic perspective, the economic context is particularly relevant and was thus explicitly considered during the first and second sequential stages of sampling. By accounting for these differences in our sample selection process, we can engage in more thoughtful generalizability of research findings across regions with varying economic circumstances. As <xref ref-type="bibr" rid="bibr8-1558689811417133">Collins and O’Cathain (2009)</xref> explained, “the researcher’s choice of sampling design impacts the legitimation of the researcher’s inferences and the appropriate generalization of results” (p. 5).</p>
<p>In terms of generalizations of results, when random samples are not possible, researchers should select sites that vary across policy implementation levels and should control for major contextual variables. By combining quantitative and qualitative components in the sampling scheme, we achieved a balance of schools across the state on initial level of policy implementation, industry mix, local economic conditions, and incidentally on location (urbanicity) and school size. Our mixed methods sampling scheme will allow us to draw comparisons and contrasts across several dimensions that are important for addressing our research questions, including the level of policy implementation and the availability of various community resources. This mixing of sampling procedures will help us increase internal validity and trustworthiness and the generalizability/transferability of results (<xref ref-type="bibr" rid="bibr21-1558689811417133">Kemper et al., 2003</xref>). Our site selection strategy increases our ability to Maximize at least initial variance on issues of greatest policy interest, Minimize differences on student background characteristics, and Control for many extraneous variables (MaxMinCon).</p>
<p>EEDA focuses on developing students’ knowledge and abilities for high-skill, high-wage jobs and preparing them for the modern workforce. Since the policy is statewide, its effectiveness depends on ensuring benefits to students in all communities, regardless of levels of resources. This requires a better understanding of the influence of community-level poverty on educational outcomes. This is especially the case in South Carolina, where educational inequities could potentially influence EEDA implementation (<xref ref-type="bibr" rid="bibr23-1558689811417133">Kuczera, 2011</xref>). Thus, in the spirit of previous pragmatic approaches to school effectiveness and school improvement research (<xref ref-type="bibr" rid="bibr51-1558689811417133">Tashakkori &amp; Teddlie, 2003b</xref>), our site selection strategy accounted for varying levels of poverty (during Stage 2) so we could ultimately learn about the influence of community resources on study outcomes.</p>
<p>Our site selection process provides a strong foundation for our subsequent mixed methods data collection and analytical procedures that capitalize on the benefits of these approaches. The practical utility of pragmatism allowed us to incorporate both quantitative and qualitative methods into our sampling strategy with the goal of ensuring that our research is practical, contextual, responsive, and consequential (<xref ref-type="bibr" rid="bibr12-1558689811417133">Datta, 1997</xref>). As our study progresses, and at the conclusion of our study, the sharing of the practical consequences of our methodological and methods decisions should prove beneficial to the mixed methods community (<xref ref-type="bibr" rid="bibr36-1558689811417133">Scott &amp; Briggs, 2009</xref>). We anticipate that the site selection process described in this article will enable other researchers to think more purposefully about their selection of sites for mixed methods studies, whether these sites are schools or other organizations. Specifically, if random assignment or selection cannot be achieved or are inappropriate, multistage, mixed methods sampling designs such as ours may be used to select participants and/or sites. The rigor associated with such strategies can help researchers ultimately gain more valuable information about policy implementation across a range of settings.</p>
</sec>
</body>
<back>
<ack>
<p>We would like to thank Marty Duckenfield and Peg Chrestman for their careful review of the article. We would also like to thank the <italic>JMMR</italic> editors and four anonymous reviewers whose comments and suggestions have significantly strengthened this article.</p>
</ack>
<fn-group>
<fn fn-type="other">
<p>Julia Sharp and Catherine Mobley are the primary authors. Sam Drew and Cathy Hammond are co–principal investigators on the project. The research study team consists of all listed authors.</p>
</fn>
<fn fn-type="conflict">
<p>The author(s) declared the following potential conflicts of interest with respect to the research, authorship, and/or publication of this article:</p>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article:</p>
<p>The work reported herein is being completed through the National Dropout Prevention Center, Clemson University, and is supported under the National Research Center for Career and Technical Education, University of Louisville, PR/Award (No. VO51A070003) as administered by the Office of Vocational and Adult Education, U.S. Department of Education. However, the contents do not necessarily represent the positions or policies of the Office of Vocational and Adult Education or the U.S. Department of Education and you should not assume endorsement by the Federal Government.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1558689811417133">
<label>1.</label>
<p>South Carolina Technical College System series, <italic>How EEDA works for South Carolina</italic>, including: <italic>An educator’s guide to develop and implement the EEDA curriculum framework and Individual Graduation Plan</italic> (<xref ref-type="bibr" rid="bibr45-1558689811417133">2006a</xref>) and <italic>An educator’s orientation guide to the Education and Economic Development Act</italic> (<xref ref-type="bibr" rid="bibr46-1558689811417133">2006b</xref>); and South Carolina Department of Education, <italic>South Carolina Education and Economic Development Act guidelines</italic> (<xref ref-type="bibr" rid="bibr41-1558689811417133">2006b</xref>).</p>
</fn>
<fn fn-type="other" id="fn2-1558689811417133">
<label>2.</label>
<p>The following schools were excluded from our sampling frame: schools that are kindergarten through 12th grade, 6th grade to 12th grade schools, schools with grade levels other than 9th grade to 12th grade, vocational/career centers, magnet schools, charter or lab schools, and alternative schools.</p>
</fn>
<fn fn-type="other" id="fn3-1558689811417133">
<label>3.</label>
<p>Eighteen out of 33 schools had missing data, but we were able to contact all but two to obtain the data. The two schools that were excluded were unresponsive to our requests for data and neither school had submitted data on enrollment and types of at-risk programs nor had they completed a questionnaire that would give guidance counselor and career specialist information and more details on the at-risk efforts and whole school reform. One of the two schools with excessive missing data had also failed to submit a state-mandated guidance report that would give details on implementation and participation in policy activities. Also, this school’s course catalog could not be located online.</p>
</fn>
<fn fn-type="other" id="fn4-1558689811417133">
<label>4.</label>
<p>SDE provided standardized EEDA materials to all schools on a statewide website and through regional training sessions. EEDA guidelines stipulate that schools must use the standardized form for IGP development. Additionally, all schools were required to use the 16 federally defined career clusters for reporting to the state but were allowed to modify the clusters (the names and what types of subjects were included under each) for school use and to choose their own majors for each cluster. Most schools moved to the standard IGP format in their course registration materials in the first year of EEDA, but not all were using this format at the time we were selecting schools and reviewing catalogs online.</p>
</fn>
<fn fn-type="other" id="fn5-1558689811417133">
<label>5.</label>
<p>Most survey data were already scaled appropriately for our purposes (e.g., <italic>yes</italic> = 1, <italic>no</italic> = 0; or a range 0-5) with higher values indicating higher implementation; for data where a higher score would indicate lower implementation, the scale was reversed. Some raw data was in a form that would result in one question carrying more weight than another. For example, for the percentage of 9th graders with a complete IGP, the range was 2 to 100 with a median of 96. Giving this data point a value of 96 compared with another data point with values from 0 to 5 would give too much weight to the first data point. In such cases, responses were categorized into three groups with scores ranging between 0 and 2. See <xref ref-type="bibr" rid="bibr38-1558689811417133">Smink et al. (2010)</xref> for more details about this scoring process.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Amaratunga</surname><given-names>D.</given-names></name>
<name><surname>Baldry</surname><given-names>D.</given-names></name>
<name><surname>Sarshar</surname><given-names>M.</given-names></name>
<name><surname>Newton</surname><given-names>R.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Quantitative and qualitative research in the built environment: Application of “mixed” research approach</article-title>. <source>Work Study</source>, <volume>51</volume>(<issue>1</issue>), <fpage>17</fpage>-<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr2-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Axinn</surname><given-names>W. G.</given-names></name>
<name><surname>Pearce</surname><given-names>L. D.</given-names></name>
</person-group> (<year>2006</year>). <source>Mixed method data collection strategies</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Balfanz</surname><given-names>R.</given-names></name>
<name><surname>Legters</surname><given-names>N.</given-names></name>
</person-group> (<year>2004</year>). <source>Locating the dropout crisis. Which high schools produce the nation’s dropouts? Where are they located? Who attends them?</source> <publisher-loc>Baltimore, MD</publisher-loc>: <publisher-name>Johns Hopkins University Center for Social Organization of Schools</publisher-name>.</citation>
</ref>
<ref id="bibr4-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Biesta</surname><given-names>G.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Pragmatism and the philosophical foundations of mixed methods research</article-title>. In <person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Sage handbook of mixed methods in social and behavioral research</source> (pp. <fpage>95</fpage>-<lpage>117</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr5-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bryk</surname><given-names>A.</given-names></name>
<name><surname>Sebring</surname><given-names>P. B.</given-names></name>
<name><surname>Allensworth</surname><given-names>E.</given-names></name>
<name><surname>Luppescu</surname><given-names>S.</given-names></name>
<name><surname>Easton</surname><given-names>J. Q.</given-names></name>
</person-group> (<year>2009</year>). <source>Organizing schools for improvement: Lessons from Chicago</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr6-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Burgess</surname><given-names>R. G.</given-names></name>
<name><surname>Pole</surname><given-names>C. J.</given-names></name>
<name><surname>Evans</surname><given-names>K.</given-names></name>
<name><surname>Priestly</surname><given-names>C.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Four studies from one or one study from four? Multisite case study research</article-title>. In <person-group person-group-type="editor">
<name><surname>Bryman</surname><given-names>A.</given-names></name>
<name><surname>Burgess</surname><given-names>R. R.</given-names></name>
</person-group> (Eds.), <source>Analyzing qualitative data</source> (pp. <fpage>129</fpage>-<lpage>145</lpage>). <publisher-loc>London, England</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr7-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Christ</surname><given-names>T. W.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A recursive approach to mixed methods research in a longitudinal study of postsecondary education disability support services</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>1</volume>(<issue>3</issue>), <fpage>226</fpage>-<lpage>241</lpage>.</citation>
</ref>
<ref id="bibr8-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Collins</surname><given-names>K. M. T.</given-names></name>
<name><surname>O’Cathain</surname><given-names>A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Ten points about mixed methods research to be considered by the novice researcher</article-title>. <source>International Journal of Multiple Research Approaches</source>, <volume>3</volume>(<issue>1</issue>), <fpage>2</fpage>-<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr9-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Collins</surname><given-names>K. M. T.</given-names></name>
<name><surname>Onwuegbuzie</surname><given-names>A. J.</given-names></name>
<name><surname>Jiao</surname><given-names>Q. G.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A mixed-methods investigation of mixed-methods sampling designs in social and health science research</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>1</volume>(<issue>3</issue>), <fpage>267</fpage>-<lpage>294</lpage>.</citation>
</ref>
<ref id="bibr10-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Creswell</surname><given-names>J. W.</given-names></name>
<name><surname>Plano Clark</surname><given-names>V. L.</given-names></name>
</person-group> (<year>2007</year>). <source>Designing and conducting mixed methods research</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr11-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Datnow</surname><given-names>A.</given-names></name>
<name><surname>Borman</surname><given-names>G. D.</given-names></name>
<name><surname>Stringfield</surname><given-names>S.</given-names></name>
<name><surname>Overman</surname><given-names>L. T.</given-names></name>
<name><surname>Castellano</surname><given-names>M.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Comprehensive school reform in culturally and linguistically diverse contexts: Implementation and outcomes from a four-year study</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>25</volume>(<issue>2</issue>), <fpage>143</fpage>-<lpage>170</lpage>.</citation>
</ref>
<ref id="bibr12-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Datta</surname><given-names>L.</given-names></name>
</person-group> (<year>1997</year>). <article-title>A pragmatic basis for mixed-method designs</article-title>. In <person-group person-group-type="editor">
<name><surname>Greene</surname><given-names>J. C.</given-names></name>
<name><surname>Caracelli</surname><given-names>V. J.</given-names></name>
</person-group> (Eds.), <source>Advances in mixed-method evaluation: The challenges and benefits of integrating diverse paradigms</source> (<comment>New Directions for Evaluation, No. 74</comment>, pp. <fpage>34</fpage>-<lpage>36</lpage>). <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr13-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Feilzer</surname><given-names>M. F.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Doing mixed methods research pragmatically: Implications for the rediscovery of pragmatism as a research paradigm</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>41</volume>(<issue>1</issue>), <fpage>6</fpage>-<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr14-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Glaser</surname><given-names>B. G.</given-names></name>
<name><surname>Strauss</surname><given-names>A. L.</given-names></name>
</person-group> (<year>1967</year>). <source>The discovery of grounded theory: Strategies for qualitative research</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Aldine</publisher-name>.</citation>
</ref>
<ref id="bibr15-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Goetz</surname><given-names>J. P.</given-names></name>
<name><surname>LeCompte</surname><given-names>M. D.</given-names></name>
</person-group> (<year>1984</year>). <source>Ethnography and qualitative design in educational research</source>. <publisher-loc>Orlando, FL</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr16-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Greene</surname><given-names>J. C.</given-names></name>
</person-group> (<year>2007</year>). <source>Mixed methods in social inquiry</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr17-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Greene</surname><given-names>J. C.</given-names></name>
<name><surname>Hall</surname><given-names>J. N.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Dialectics and pragmatism: Being of consequence</article-title>. In <person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Sage handbook of mixed methods in social and behavioral research</source> (pp. <fpage>119</fpage>-<lpage>143</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr18-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Howe</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Against the quantitative-qualitative incompatibility thesis or dogmas die hard</article-title>. <source>Educational Researcher</source>, <volume>17</volume>(<issue>8</issue>), <fpage>10</fpage>-<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr19-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>R. B.</given-names></name>
<name><surname>Onwuegbuzie</surname><given-names>A. J.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Mixed methods research: A research paradigm whose time has come</article-title>. <source>Educational Researcher</source>, <volume>33</volume>(<issue>7</issue>), <fpage>14</fpage>-<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr20-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>R. B.</given-names></name>
<name><surname>Onwuegbuzie</surname><given-names>A. J.</given-names></name>
<name><surname>Turner</surname><given-names>L. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Toward a definition of mixed methods research</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>1</volume>(<issue>2</issue>), <fpage>112</fpage>-<lpage>133</lpage>.</citation>
</ref>
<ref id="bibr21-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kemper</surname><given-names>E.</given-names></name>
<name><surname>Stringfield</surname><given-names>S.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Mixed methods sampling strategies</article-title>. In <person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Handbook of mixed methods in social and behavioral research</source> (pp. <fpage>273</fpage>-<lpage>296</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr22-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kerlinger</surname><given-names>F.</given-names></name>
</person-group> (<year>1986</year>). <source>Foundations of behavioral research</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Holt, Rinehart &amp; Winston</publisher-name>.</citation>
</ref>
<ref id="bibr23-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kuczera</surname><given-names>M.</given-names></name>
</person-group> (<year>2011</year>). <source>Learning for jobs: OECD reviews of vocational and technical training: United States: South Carolina</source>. <publisher-loc>Paris, France</publisher-loc>: <publisher-name>Organization for Economic Cooperation and Development</publisher-name>.</citation>
</ref>
<ref id="bibr24-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lieber</surname><given-names>E.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Mixing qualitative and quantitative methods: Insights into design and analysis issues</article-title>. <source>Journal of Ethnographic &amp; Qualitative Research</source>, <volume>3</volume>, <fpage>218</fpage>-<lpage>227</lpage>.</citation>
</ref>
<ref id="bibr25-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mertens</surname><given-names>D. M.</given-names></name>
</person-group> (<year>2010</year>). <source>Research and evaluation in education and psychology: Integrating diversity with quantitative, qualitative, and mixed methods</source> (<edition>3rd ed.</edition>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr26-1558689811417133">
<citation citation-type="book">
<collab>National Center for Education Statistics</collab>. (<year>2002</year>). <source>School locale codes, 1987-2000</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr27-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>O’Cathain</surname><given-names>A.</given-names></name>
<name><surname>Murphy</surname><given-names>E.</given-names></name>
<name><surname>Nicholl</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Integration and publications as indicators of “yield” from mixed methods studies</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>1</volume>(<issue>2</issue>), <fpage>147</fpage>-<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr28-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Onwuegbuzie</surname><given-names>A. J.</given-names></name>
<name><surname>Leech</surname><given-names>N. L.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Sampling designs in qualitative research: Making the sampling process more public</article-title>. <source>The Qualitative Report</source>, <volume>12</volume>, <fpage>238</fpage>-<lpage>254</lpage>.</citation>
</ref>
<ref id="bibr29-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Patton</surname><given-names>M. Q.</given-names></name>
</person-group> (<year>1980</year>). <source>Qualitative evaluation methods</source>. <publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr30-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pettigrew</surname><given-names>A. M.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Longitudinal field research on change: Theory and practice</article-title>. <source>Organization Science</source>, <volume>1</volume>, <fpage>267</fpage>-<lpage>292</lpage>.</citation>
</ref>
<ref id="bibr31-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rorty</surname><given-names>R.</given-names></name>
</person-group> (<year>1999</year>). <source>Philosophy and social hope</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Penguin Books</publisher-name>.</citation>
</ref>
<ref id="bibr32-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rumberger</surname><given-names>R. W.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Dropping out of middle school: A multilevel analysis of students and schools</article-title>. <source>American Educational Research Journal</source>, <volume>32</volume>, <fpage>583</fpage>-<lpage>625</lpage>.</citation>
</ref>
<ref id="bibr33-1558689811417133">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Rumberger</surname><given-names>R. W.</given-names></name>
</person-group> (<year>2001</year>). <source>Who drops out of school and why</source>. <publisher-loc>Santa Barbara, CA</publisher-loc>: <publisher-name>University of California–Santa Barbara</publisher-name>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://education.ucsb.edu/rumberger/internet%20pages/Papers/Rumberger--NRC%20dropout%20paper%20version%2012%20with%20figures.doc">http://education.ucsb.edu/rumberger/internet%20pages/Papers/Rumberger--NRC%20dropout%20paper%20version%2012%20with%20figures.doc</ext-link></comment></citation>
</ref>
<ref id="bibr34-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sammons</surname><given-names>P.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The contribution of mixed methods to recent research on educational effectiveness</article-title>. In <person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Sage handbook of mixed methods in social and behavioral research</source> (pp. <fpage>697</fpage>-<lpage>723</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr35-1558689811417133">
<citation citation-type="book">
<collab>SAS Institute Inc</collab>. (<year>2008</year>). <source>SAS 9.2 software, help and documentation</source>. <publisher-loc>Cary, NC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr36-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scott</surname><given-names>P. J.</given-names></name>
<name><surname>Briggs</surname><given-names>J. S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A pragmatist argument for mixed methodology in medical informatics</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>3</volume>(<issue>3</issue>), <fpage>223</fpage>-<lpage>241</lpage>.</citation>
</ref>
<ref id="bibr37-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simons</surname><given-names>H.</given-names></name>
</person-group> (<year>1996</year>). <article-title>The paradox of case study research</article-title>. <source>Cambridge Journal of Education</source>, <volume>26</volume>, <fpage>225</fpage>-<lpage>240</lpage>.</citation>
</ref>
<ref id="bibr38-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Smink</surname><given-names>J.</given-names></name>
<name><surname>Drew</surname><given-names>S.</given-names></name>
<name><surname>Hammond</surname><given-names>C.</given-names></name>
<name><surname>Withington</surname><given-names>C.</given-names></name>
<name><surname>Mobley</surname><given-names>C.</given-names></name>
<name><surname>Sharp</surname><given-names>J.</given-names></name><etal/>
</person-group>. (<year>2010</year>). <source>A longitudinal study of the South Carolina Personal Pathways to Success initiative</source>. <publisher-loc>Louisville, KY</publisher-loc>: <publisher-name>National Research Center for Career and Technical Education</publisher-name>.</citation>
</ref>
<ref id="bibr39-1558689811417133">
<citation citation-type="gov">
<collab>South Carolina Department of Education</collab>. (<year>2005</year>). <source>2005 EAA report card Excel files: High schools</source> <comment>[Data File]</comment>. <access-date>Retrieved August 22, 2008</access-date>, <comment>from <ext-link ext-link-type="uri" xlink:href="http://www.ed.sc.gov/topics/researchandstats/schoolreportcard/2005/data">http://www.ed.sc.gov/topics/researchandstats/schoolreportcard/2005/data</ext-link></comment></citation>
</ref>
<ref id="bibr40-1558689811417133">
<citation citation-type="gov">
<collab>South Carolina Department of Education</collab>. (<year>2006a</year>). <source>2006 EAA report card Excel files: Poverty indices</source> <comment>[Data File]</comment>. <access-date>Retrieved August 22, 2008</access-date>, <comment>from <ext-link ext-link-type="uri" xlink:href="http://www.ed.sc.gov/topics/researchandstats/schoolreportcard/2006/data/">http://www.ed.sc.gov/topics/researchandstats/schoolreportcard/2006/data/</ext-link></comment></citation>
</ref>
<ref id="bibr41-1558689811417133">
<citation citation-type="book">
<collab>South Carolina Department of Education</collab> (<year>2006b</year>). <source>South Carolina Education and Economic Development Act guidelines</source>. <publisher-loc>Columbia, SC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr42-1558689811417133">
<citation citation-type="gov">
<collab>South Carolina Department of Education</collab>. (<year>2007</year>). <source>2007 State of South Carolina Education Accountability Act report cards - data files: Poverty index</source> [<comment>Data File</comment>]. <access-date>Retrieved August 22, 2008</access-date>, <comment>from <ext-link ext-link-type="uri" xlink:href="http://www.ed.sc.gov/topics/researchandstats/schoolreportcard/2007/data/">http://www.ed.sc.gov/topics/researchandstats/schoolreportcard/2007/data/</ext-link></comment></citation>
</ref>
<ref id="bibr43-1558689811417133">
<citation citation-type="gov">
<collab>South Carolina Department of Education</collab>. (<year>2010</year>). <source>South Carolina High Schools</source> [<comment>Data File</comment>]. <access-date>Retrieved February 19, 2010</access-date> <comment>from <ext-link ext-link-type="uri" xlink:href="http://ed.sc.gov/schools/allschools.cfm">http://ed.sc.gov/schools/allschools.cfm</ext-link></comment></citation>
</ref>
<ref id="bibr44-1558689811417133">
<citation citation-type="web">
<collab>South Carolina Employment Security Commission</collab>. (<year>2008</year>). <source>Spotlights: WIA profiles</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.sces.org/lmi/spotlights/WIA">http://www.sces.org/lmi/spotlights/WIA</ext-link></comment></citation>
</ref>
<ref id="bibr45-1558689811417133">
<citation citation-type="book">
<collab>South Carolina Technical College System</collab>. (<year>2006a</year>). <source>How EEDA works for South Carolina. An educator’s guide to develop and implement the EEDA curriculum framework and individual graduation plan</source>. <publisher-loc>Columbia, SC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr46-1558689811417133">
<citation citation-type="book">
<collab>South Carolina Technical College System</collab>. (<year>2006b</year>). <source>How EEDA works for South Carolina. An educator’s orientation guide to the Education and Economic Development Act</source>. <publisher-loc>Columbia, SC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr47-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stallings</surname><given-names>J. A.</given-names></name>
<name><surname>Kaskowitz</surname><given-names>D.</given-names></name>
</person-group> (<year>1974</year>). <source>Follow through classroom observation evaluation, 1972-73: A study of implementation</source>. <publisher-loc>Menlo Park, CA</publisher-loc>: <publisher-name>Stanford Research Institute, Stanford University</publisher-name>.</citation>
</ref>
<ref id="bibr48-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stringfield</surname><given-names>S.</given-names></name>
<name><surname>Millsap</surname><given-names>M.A.</given-names></name>
<name><surname>Herman</surname><given-names>R.</given-names></name>
</person-group> (<year>1997</year>). <source>Special strategies for educating disadvantaged children: Findings and implications of a longitudinal study</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr49-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.). (<year>1998</year>). <source>Mixed methodology: Applying qualitative and quantitative approaches</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr50-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.). (<year>2003a</year>). <source>Handbook of mixed methods in social and behavioral research</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr51-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (<year>2003b</year>). <article-title>The past and future of mixed methods research: From data triangulation to mixed model designs</article-title>. In <person-group person-group-type="editor">
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Handbook of mixed methods in social and behavioral research</source> (pp. <fpage>671</fpage>-<lpage>701</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr52-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Reynolds</surname><given-names>D.</given-names></name>
</person-group> (<year>2000</year>). <source>The international handbook on school effectiveness research</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Falmer</publisher-name>.</citation>
</ref>
<ref id="bibr53-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Stringfield</surname><given-names>S.</given-names></name>
</person-group> (<year>1993</year>). <source>Schools make a difference</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Teachers College Press</publisher-name>.</citation>
</ref>
<ref id="bibr54-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Stringfield</surname><given-names>S.</given-names></name>
<name><surname>Reynolds</surname><given-names>D.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Context issues within school effectiveness research</article-title>. In <person-group person-group-type="editor">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Reynolds</surname><given-names>D.</given-names></name>
</person-group> (Eds.), <source>The international handbook on school effectiveness research</source> (pp. <fpage>160</fpage>-<lpage>186</lpage>). <publisher-loc>London</publisher-loc>: <publisher-name>Falmer</publisher-name>.</citation>
</ref>
<ref id="bibr55-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Tashakkori</surname><given-names>A.</given-names></name>
</person-group> (<year>2009</year>). <source>Foundations of mixed methods research: Integrating quantitative and qualitative approaches in the social and behavioral sciences</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr56-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Yu</surname><given-names>F.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Mixed methods sampling: A typology with examples</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>1</volume>(<issue>1</issue>), <fpage>77</fpage>-<lpage>100</lpage>.</citation>
</ref>
<ref id="bibr57-1558689811417133">
<citation citation-type="gov">
<collab>U.S. Bureau of the Census</collab>. (<year>2000</year>). <source>2000 Census of Population and Housing: Summary tape file 3, <italic>Tables P43, P82</italic></source> <comment>[Data files]. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://factfinder.census.gov">http://factfinder.census.gov</ext-link></comment></citation>
</ref>
<ref id="bibr58-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walford</surname><given-names>G.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Site selection within comparative case study and ethnographic research</article-title>. <source>Compare</source>, <volume>31</volume>, <fpage>151</fpage>-<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr59-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wells</surname><given-names>A. S.</given-names></name>
<name><surname>Hirschberg</surname><given-names>D.</given-names></name>
<name><surname>Lipton</surname><given-names>M.</given-names></name>
<name><surname>Oakes</surname><given-names>J.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Bounding the case within its context: A constructivist approach to studying detracking reform</article-title>. <source>Educational Researcher</source>, <volume>24</volume>(<issue>5</issue>), <fpage>18</fpage>-<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr60-1558689811417133">
<citation citation-type="gov">
<collab>White House.gov</collab>. (<year>2010</year>). <source>Issues: Education</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.whitehouse.gov/issues/education">http://www.whitehouse.gov/issues/education</ext-link></comment></citation>
</ref>
<ref id="bibr61-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wimpelberg</surname><given-names>R.</given-names></name>
<name><surname>Teddlie</surname><given-names>C.</given-names></name>
<name><surname>Stringfield</surname><given-names>S.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Sensitivity to context: The past and future of effective schools research</article-title>. <source>Educational Administration Quarterly</source>, <volume>25</volume>, <fpage>82</fpage>-<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr62-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolf</surname><given-names>S.</given-names></name>
<name><surname>Borko</surname><given-names>H.</given-names></name>
<name><surname>Elliott</surname><given-names>R.</given-names></name>
<name><surname>McIver</surname><given-names>M. C.</given-names></name>
</person-group> (<year>2000</year>). <article-title>“That dog won’t hunt!” Exemplary school change efforts within the Kentucky reform</article-title>. <source>American Educational Research Journal</source>, <volume>37</volume>, <fpage>349</fpage>-<lpage>393</lpage>.</citation>
</ref>
<ref id="bibr63-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Yin</surname><given-names>R. K.</given-names></name>
</person-group> (<year>1994</year>). <source>Case study research: Design and methods</source> (<edition>2nd ed.</edition>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr64-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Yin</surname><given-names>R. K.</given-names></name>
</person-group> (<year>2003</year>). <source>Case study research: Design and methods</source> (<edition>3rd ed.</edition>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr65-1558689811417133">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Yin</surname><given-names>R. K.</given-names></name>
</person-group> (<year>2009</year>). <source>Case study research: Design and methods</source> (<edition>4th ed.</edition>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr66-1558689811417133">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zartman</surname><given-names>I. W.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Comparative case studies</article-title>. <source>International Negotiation</source>, <volume>10</volume>, <fpage>3</fpage>-<lpage>15</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>