<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AEI</journal-id>
<journal-id journal-id-type="hwp">spaei</journal-id>
<journal-title>Assessment for Effective Intervention</journal-title>
<issn pub-type="ppub">1534-5084</issn>
<issn pub-type="epub">1938-7458</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1534508413489724</article-id>
<article-id pub-id-type="publisher-id">10.1177_1534508413489724</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Curriculum-Based Measurement in Science Learning</article-title>
<subtitle>Vocabulary-Matching As an Indicator of Performance and Progress</subtitle>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Lembke</surname><given-names>Erica S.</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Espin</surname><given-names>Christine A.</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508413489724">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Busch</surname><given-names>Todd W.</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff2-1534508413489724">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Lembke</surname><given-names>Erica S.</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff3-1534508413489724">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hampton</surname><given-names>David D.</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff4-1534508413489724">4</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Seo</surname><given-names>Kyounghee</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff5-1534508413489724">5</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Zukowski</surname><given-names>Beth A.</given-names></name>
<degrees>MA</degrees>
<xref ref-type="aff" rid="aff6-1534508413489724">6</xref>
</contrib>
</contrib-group>
<aff id="aff1-1534508413489724"><label>1</label>Leiden University, Netherlands</aff>
<aff id="aff2-1534508413489724"><label>2</label>University of St. Thomas, St. Paul, MN, USA</aff>
<aff id="aff3-1534508413489724"><label>3</label>University of Missouri, Columbia, USA</aff>
<aff id="aff4-1534508413489724"><label>4</label>Bowling Green State University, OH, USA</aff>
<aff id="aff5-1534508413489724"><label>5</label>St. Cloud University, MN, USA</aff>
<aff id="aff6-1534508413489724"><label>6</label>Totino-Grace High School, Fridley, MN, USA</aff>
<author-notes>
<corresp id="corresp1-1534508413489724">Christine A. Espin, Department of Education and Child Studies, Leiden University, Pieter de la Court, Wassenaarseweg 52, 2333 AK Leiden, Netherlands. Email: <email>espinca@fsw.leidenuniv.nl</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2013</year>
</pub-date>
<volume>38</volume>
<issue>4</issue>
<issue-title>Special Series: Content Area Measurement Using Curriculum-Based Measurement</issue-title>
<fpage>203</fpage>
<lpage>213</lpage>
<permissions>
<copyright-statement>© Hammill Institute on Disabilities 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="other">Hammill Institute on Disabilities</copyright-holder>
</permissions>
<abstract>
<p>The technical adequacy of curriculum-based measures in the form of short and simple vocabulary-matching probes to predict students’ performance and progress in science at the secondary level was investigated. Participants were 198 seventh-grade students from 10 science classrooms. Curriculum-based measurements (CBM) were 5-min vocabulary-matching probes administered once weekly over a period of 14 weeks. Criterion measures were knowledge pre- and posttests, the science subtest of the <italic>Iowa Test of Basic Skills</italic> (ITBS), and course grades. Alternate-form reliability coefficients ranged from <italic>r</italic> = .64 to .84. Coefficients increased over time and by combining scores across probes. Correlations between scores on the vocabulary-matching and criterion measures ranged from <italic>r</italic> = .55 to .76. The estimated mean group growth rate on the vocabulary-matching measure was .63 correct matches per week, which was significantly different from zero. The measures produced significant interindividual differences in growth rates, and growth on the measures was related to performance on the ITBS, course grades, and pre–post gains on the knowledge test. Results provide initial support for the technical adequacy of vocabulary-matching as an indicator of performance and progress in science.</p>
</abstract>
<kwd-group>
<kwd>curriculum-based measurement</kwd>
<kwd>content-area assessment</kwd>
<kwd>middle school</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Science is one of the most challenging content areas for students with learning disabilities (LD). Instruction in science is often textbook driven, requiring large amounts of reading (<xref ref-type="bibr" rid="bibr2-1534508413489724">Bean, Zigmond, &amp; Hartman, 1994</xref>; <xref ref-type="bibr" rid="bibr23-1534508413489724">Mastropieri &amp; Scruggs, 1992</xref>, <xref ref-type="bibr" rid="bibr24-1534508413489724">1994</xref>; <xref ref-type="bibr" rid="bibr28-1534508413489724">Moin, Magiera, &amp; Zigmond, 2009</xref>). Science textbooks often are “inconsiderate” (<xref ref-type="bibr" rid="bibr1-1534508413489724">Armbruster &amp; Anderson, 1988</xref>), that is, they are poorly structured, conceptually dense, vocabulary laden, and introduce large numbers of ideas and terms in a short span of time (<xref ref-type="bibr" rid="bibr1-1534508413489724">Armbruster &amp; Anderson, 1988</xref>; <xref ref-type="bibr" rid="bibr20-1534508413489724">Groves, 1995</xref>; <xref ref-type="bibr" rid="bibr22-1534508413489724">Mason &amp; Hedin, 2011</xref>; <xref ref-type="bibr" rid="bibr31-1534508413489724">Scruggs &amp; Mastropieri, 2007</xref>). <xref ref-type="bibr" rid="bibr20-1534508413489724">Groves (1995)</xref> and <xref ref-type="bibr" rid="bibr40-1534508413489724">Yager (1983)</xref> report that more new vocabulary words are introduced in 1 year in science texts than in foreign language courses. <xref ref-type="bibr" rid="bibr17-1534508413489724">Fang (2006)</xref> describes science as having its own unique language with technical vocabulary, abstract nouns, complex sentences, and ordinary words used in nontypical ways.</p>
<sec id="section1-1534508413489724">
<title>Performance of Students With Disabilities in Science</title>
<p>Given the characteristics of science texts, and the heavy reading requirements in science classes, it is not surprising that students with disabilities struggle in science. Results of the most recent National Assessment of Educational Progress (NAEP) in science (<xref ref-type="bibr" rid="bibr29-1534508413489724">National Center for Education Statistics, 2012</xref>) reveal that the average scale score for eighth-grade students with disabilities is 124 compared with the national average of 151, and the percentage of students with disabilities who score at or below a basic level is 67% compared with the national average of 36%. The poor performance in science for students with disabilities is of concern given the fact that the development of skills in science and technology (science, technology, engineering, and mathematics [STEM]) is becoming increasingly important in our society (<xref ref-type="bibr" rid="bibr7-1534508413489724">Business-Higher Education Forum, 2005</xref>; <xref ref-type="bibr" rid="bibr9-1534508413489724">Carnevale, Smith, &amp; Melton, 2011</xref>; <xref ref-type="bibr" rid="bibr10-1534508413489724">Coble &amp; Allen, 2005</xref>; <xref ref-type="bibr" rid="bibr36-1534508413489724">U.S. Department of Education, 2006</xref>).</p>
<p>Despite the challenges they face, students with LD can improve in science if given appropriate instruction. Several effective interventions have been developed for students with LD in the areas of science (see, for example, <xref ref-type="bibr" rid="bibr33-1534508413489724">Therrien, Hughes, &amp; Hand, 2011</xref>). The availability of such effective interventions is important as more and more schools move toward a response to intervention (RTI) approach where students’ responses to evidence-based interventions are used to determine the need for specialized instruction (<xref ref-type="bibr" rid="bibr18-1534508413489724">D. Fuchs, Mock, Morgan, &amp; Young, 2003</xref>; <xref ref-type="bibr" rid="bibr38-1534508413489724">Vaughn &amp; Fuchs, 2003</xref>). Missing from the literature on effective science interventions, however, is a key component of RTI: progress monitoring.</p>
<p>One progress-monitoring system often used within RTI is curriculum-based measurement (CBM; <xref ref-type="bibr" rid="bibr11-1534508413489724">Deno, 1985</xref>). In CBM, brief samples of student performance are collected and graphed on a frequent (e.g., weekly) basis to produce a picture of student growth. The graphs are used to aid in decision making about the effectiveness of instructional programs for students. The measures used for CBM must be reliable, valid, simple to construct and score, efficient, easy to understand, inexpensive, and allow for repeated measurement over time (<xref ref-type="bibr" rid="bibr11-1534508413489724">Deno, 1985</xref>). Although a large body of research exists on the development of CBM measures at the elementary school level (see <xref ref-type="bibr" rid="bibr39-1534508413489724">Wayman, Wallace, Wiley, Tichá, &amp; Espin, 2007</xref>), relatively little attention has been devoted to the development of measures at the secondary school level or in the content areas.</p>
</sec>
<sec id="section2-1534508413489724">
<title>Progress Monitoring in Science for Secondary School Students</title>
<p>In the 1990s, <xref ref-type="bibr" rid="bibr8-1534508413489724">Carlisle and Andrews (1993)</xref> and <xref ref-type="bibr" rid="bibr34-1534508413489724">Tindal and Nolet (1995</xref>, <xref ref-type="bibr" rid="bibr35-1534508413489724">1996</xref>) worked on the development of measures to monitor the progress of students in the content areas. Although these measures proved valuable for assessing what students had learned following instruction, and for identifying areas of concern for intervention, they were limited in terms of their potential use as CBM progress measures. The measures were too long for frequent (weekly) repeated administration and were not simple to construct or score. In addition, the measures were not suitable for producing a graphic picture of growth over time of the kind typically seen in CBM progress monitoring.</p>
<p>Taking a somewhat different approach, Espin and colleagues examined the development of vital signs or critical indicators (<xref ref-type="bibr" rid="bibr11-1534508413489724">Deno, 1985</xref>) of content-area learning (see <xref ref-type="bibr" rid="bibr16-1534508413489724">Espin &amp; Tindal, 1998</xref>). Critical indicators were defined as brief measures designed to reflect general performance and progress over time in a broad curriculum area. Critical indicators met the requirements outlined by <xref ref-type="bibr" rid="bibr11-1534508413489724">Deno (1985)</xref> of efficiency, simplicity, ease of use, inexpensiveness, and appropriateness for repeated measurement over time. The initial research examined the validity of a reading aloud measure as a potential indicator of performance in biology (<xref ref-type="bibr" rid="bibr13-1534508413489724">Espin &amp; Deno, 1993</xref>), but results were not positive. In a subsequent study, <xref ref-type="bibr" rid="bibr14-1534508413489724">Espin and Foegen (1996)</xref> examined the relation between three potential CBM measures—reading aloud, maze selection, and vocabulary-matching—and three criterion variables—comprehension, acquisition, and retention of content information. Results of the research supported the validity of all three measures as indicators of performance on content learning tasks, with correlations between the three measures and the criterion variables ranging from <italic>r</italic> = .52 to .62. The strongest correlations were found for the vocabulary-matching measure (<italic>r</italic> = .62–.65), and in a regression analysis, vocabulary-matching accounted for the largest proportion of variance in the outcome measures.</p>
<p>The <xref ref-type="bibr" rid="bibr14-1534508413489724">Espin and Foegen (1996)</xref> study was unfortunately not conducted in an actual content-area classroom. In addition, the study did not address the reliability of the measures, and it focused only the technical adequacy of the measures as performance, not progress, measures. These limitations were addressed in a subsequent study in which the validity and reliability of vocabulary-matching as an indicator of both performance (<xref ref-type="bibr" rid="bibr12-1534508413489724">Espin, Busch, Shin, &amp; Kruschwitz, 2001</xref>) and progress (<xref ref-type="bibr" rid="bibr15-1534508413489724">Espin, Shin, &amp; Busch, 2005</xref>) in seventh-grade social studies classes were addressed. Two forms of vocabulary-matching measures were examined: student-read and administrator-read. In the student-read form, students were given 5 min to read terms and match to definitions. In the administrator-read form, the terms and definitions were read to the students at 15 sec intervals for a total of 5 min and students selected a term for each definition after it was read. Both types of vocabulary probes were administered once per week over a period of 5 months. Criterion measures in the study were a researcher-made knowledge test given at the beginning and end of the study, students’ social studies grades, and performance on the social studies subtest of a standardized achievement test.</p>
<p>Results revealed similar alternate-form reliability and criterion-related validity coefficients for the student- and administrator-read measures. Alternate-form reliability coefficients ranged from <italic>r</italic> = .58 to .81 with a mean of <italic>r</italic> = .70 for both versions. Correlations between the vocabulary-matching and criterion measures ranged from <italic>r</italic> = .56 to .84 for the knowledge and standardized achievement tests, and from <italic>r</italic> = .27 to .51 for course grades for both versions. Although the sample of students with LD was small (<italic>n</italic> = 5), scores for students with LD were lower on both types of probes than for students without LD. In sum, results provided support for both types of measures as indicators of <italic>performance</italic> in social studies.</p>
<p>In a subsequent analysis, the technical adequacy of the measures as <italic>progress</italic> measures was examined (<xref ref-type="bibr" rid="bibr15-1534508413489724">Espin et al., 2005</xref>). Hierarchical linear modeling (HLM; <xref ref-type="bibr" rid="bibr5-1534508413489724">Bryk &amp; Raudenbush, 1987</xref>, <xref ref-type="bibr" rid="bibr6-1534508413489724">1992</xref>) was used to examine the sensitivity of the measures to improvement over time and individual differences, and to examine the validity of the growth rates produced by the two measures. Results revealed that both the administrator- and student-read measures reflected group growth over time, with greater growth seen for the student- than for the administrator-read measure (estimated growth rates of .65 vs. .22 choices per week). However, only the student-read measure produced significant interindividual differences in growth. Growth on the student-read measure was found to be significantly related to course grades, scores on the standardized achievement test, and gain scores on the knowledge test.</p>
<p>Research on the development of critical indicators has been extended to the area of science at both the elementary and secondary school level. At the elementary school level, <xref ref-type="bibr" rid="bibr37-1534508413489724">Vannest, Parker, and Dyer (2011)</xref> examined the use of science key vocabulary short tests as progress measures for low-performing students in Grade 5. Key vocabulary terms were defined as specialized vocabulary words that were specific to the domain and were necessary to know to understand text in that domain (<xref ref-type="bibr" rid="bibr37-1534508413489724">Vannest et al., 2011</xref>). Terms were selected from several different instructional programs used in science in the state of Texas. Probes were created and administered via the computer. Each probe consisted of 20 items that were presented to students in blocks of five vocabulary items and six definitions (five correct answers and one distracter). Probe items were single “cloze” sentences in which the missing term was a key vocabulary term to be selected by the students. In a departure from typical CBM approaches, probes were untimed, and scores were reported as percentage correct. Between five and six weekly probes were administered over the course of the study. Results revealed significant group growth on the measures but only marginally supported the sensitivity of the measures as indicators of growth at the individual level. Correlations between residualized gain scores on the key vocabulary probes and a science assessment used in the state ranged from <italic>r</italic> = .25 to .83 with a median of .60. The measurement procedures used by Vannest and colleagues were not typical of CBM in the sense that the measures were untimed and scores were reported as percentage scores rather than number correct, but the method used to create the probes was systematic and thorough, and the probes were generated and administered electronically, features that should guide future research on progress monitoring in science.</p>
<p>At the secondary school level, <xref ref-type="bibr" rid="bibr4-1534508413489724">Borsuk (2010)</xref> examined the technical adequacy of administrator-read vocabulary-matching measures for students in Grades 6 and 7. Vocabulary-matching measures were developed from terms listed in the glossary of the science textbooks used in class. Terms and definitions were read to the students at 15-sec intervals for a total of 6 min. Students selected the correct term for each definition from six different options. Probes were administered weekly over a period of 24 weeks. Results supported the validity of the vocabulary probes as indicators of learning in science. HLM analysis revealed an estimated mean group growth rate of .26 correct choices per week, which was significantly different from 0, and the measure produced significant variability in growth rates across participants. In addition, disability status predicted growth, with students without LD growing significantly more than students with LD.</p>
<p>Although the results were positive, <xref ref-type="bibr" rid="bibr4-1534508413489724">Borsuk (2010)</xref> reflected on the practical significance of a growth rate of only .26 choices per week. Such low growth rates might prove difficult to use in making decisions about students’ responses to instructional interventions. The growth rate of .26 was in contrast to the growth rate of .65 items per week on the student-read measure found in the <xref ref-type="bibr" rid="bibr15-1534508413489724">Espin et al. (2005)</xref> study, but similar to the growth rate of .22 for the administrator-read probe in that study. <xref ref-type="bibr" rid="bibr4-1534508413489724">Borsuk (2010)</xref> suggested that the differences in growth rates between the two studies might be due to differences in the probe formats, that is, the matching of 20 terms and definitions in the <xref ref-type="bibr" rid="bibr15-1534508413489724">Espin et al. (2005)</xref> study versus selection of a correct term for a definition from six possible choices in the <xref ref-type="bibr" rid="bibr4-1534508413489724">Borsuk (2010)</xref> study. However, it is also possible that differences might be related to the fact that the probes were administrator-read rather than student-read. If reading is an important factor in science learning, then student-read probes should be more sensitive to growth than administrator-read probes (see <xref ref-type="bibr" rid="bibr15-1534508413489724">Espin et al., 2005</xref>, for discussion of this point).</p>
<p>In sum, the <xref ref-type="bibr" rid="bibr12-1534508413489724">Espin et al. (2001)</xref>, <xref ref-type="bibr" rid="bibr15-1534508413489724">Espin et al. (2005)</xref>, <xref ref-type="bibr" rid="bibr37-1534508413489724">Vannest et al. (2011)</xref>, and <xref ref-type="bibr" rid="bibr4-1534508413489724">Borsuk (2010)</xref> studies provide tentative support for the use of a vocabulary-based measure as a critical indicator of performance and progress in science. However, it is important to replicate and extend these findings for broader generalizability. It is especially important to further examine the technical adequacy of a student-read probe in the science content area for secondary school students.</p>
</sec>
<sec id="section3-1534508413489724">
<title>Current Study</title>
<p>In the current study, we examine the technical adequacy of a vocabulary-matching measure as a critical indicator of performance and progress in science learning. We examine the reliability, validity, and sensitivity to growth of a student-read vocabulary-matching measure in science for secondary school students. We address two research questions:</p>
<list id="list1-1534508413489724" list-type="simple">
<list-item><p><italic>Research Question 1</italic>: What are the alternate-form reliability and validity of vocabulary-matching measures as indicators of performance in science?</p></list-item>
<list-item><p><italic>Research Question 2</italic>: What are the reliability and validity of vocabulary-matching measures as indicators of progress (growth) in science?</p></list-item>
</list>
<p><xref ref-type="bibr" rid="bibr19-1534508413489724">L. S. Fuchs (2004)</xref> described three stages in the development of progress-monitoring measures. The current study addresses the first two stages: (a) technical features of the measures as static or performance measures and (b) technical features of the measures as growth or progress measures. At these stages of development, it is important to include students across a range of performance levels to determine whether the measures reveal interindividual differences in performance and growth. The third stage of research examines the instructional utility of the measures to determine whether use of the measures improves decision making for a particular population of students, for example, students with LD.</p>
</sec>
<sec id="section4-1534508413489724" sec-type="methods">
<title>Method</title>
<sec id="section5-1534508413489724">
<title>Participants</title>
<p>Participants were 198 seventh-grade students (85 male) from 10 science classrooms taught by two different teachers. Seventeen participants were students with LD and were receiving services in reading and written expression in a resource room setting. The mean age for participants was 13 (range = 12.7–13.5 years). Participants were from a suburban middle school located in a large metropolitan area in the Midwest. The school was located in a district with approximately 10,660 students in Grades K–12. Approximately 47% of students in the district received free or reduced-price lunches, and 48% were from minority populations, including 2% American Indian, 18% Asian, 10% Hispanic, and 18% African American. Approximately 35 different languages were spoken, including English, Hmong, Spanish, Cambodian, and Chinese. The mean standard score on the science subtest of the <italic>Iowa Test of Basic Skills</italic> (ITBS; <xref ref-type="bibr" rid="bibr21-1534508413489724">Hoover, Dunbar, &amp; Frisbie, 2001</xref>) for the students in the district was 242 (<italic>SD</italic> = 41; range = 141–359).</p>
</sec>
<sec id="section6-1534508413489724">
<title>Measures</title>
<p>The predictor variable in the study was a vocabulary-matching measure. Probes were developed by randomly selecting vocabulary terms and definitions from the classroom science textbook, teacher notes, labs, and teacher lectures. Eighty-one terms and definitions were selected from three different units: plants, protists and fungi, and genetics. Terms were selected that were in bold or italics or were highlighted in the teachers’ notes, labs, or lectures. Fourteen alternate-form probes were created, each with 20 terms and 22 definitions. Two additional definitions on each probe served as distracters. Definitions were based on the definition given in the text or in the teachers’ materials but were modified if necessary to consist of 15 or fewer words. A sample of items selected from a vocabulary probe is presented in <xref ref-type="table" rid="table1-1534508413489724">Table 1</xref>.</p>
<table-wrap id="table1-1534508413489724" position="float">
<label>Table 1.</label>
<caption>
<p>Sample Items From a Science Vocabulary-Matching Probe.</p>
</caption>
<graphic alternate-form-of="table1-1534508413489724" xlink:href="10.1177_1534508413489724-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<tbody>
<tr>
<td>5</td>
<td>Allele</td>
<td>1. The tube-like structures that transport food down to the rest of the plant.</td>
</tr>
<tr>
<td>3</td>
<td>DNA</td>
<td>2. A change in the genetic code that sometimes alters the outward appearance of the individual.</td>
</tr>
<tr>
<td>6</td>
<td>Euglena</td>
<td>3. Deoxyribonucleic acid, the genetic material all life is based on.</td>
</tr>
<tr>
<td>2</td>
<td>Mutation</td>
<td>4. Movement of a plant toward or away from a stimulus.</td>
</tr>
<tr>
<td>1</td>
<td>Phloem</td>
<td>5. A different form of the same gene.</td>
</tr>
<tr>
<td>4</td>
<td>Tropism</td>
<td>6. A plantlike protest that contains chloroplasts and moves by means of a flagellum.</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The criterion variables in the study included a research-created knowledge test, students’ grades in the science class, and student performance on the science subtest of the ITBS (<xref ref-type="bibr" rid="bibr21-1534508413489724">Hoover et al., 2001</xref>), a standardized achievement test. The knowledge test consisted of 45 multiple-choice questions addressing the three units covered during the course of the study (plants, protists and fungi, and genetics). The test included 15 questions from each unit. Test items for the knowledge test were designed to match the central concepts covered in the classroom lectures, classroom activities, and the textbook. Following development of an initial list of terms and concepts, the science teachers selected the items they felt were most central to the content they would be covering in their classes. As a final step, the teachers reviewed the knowledge test to confirm that the questions were worded appropriately and that the questions accurately reflected course content.</p>
<p>All questions were in a multiple-choice format with three distracters and one correct answer. The knowledge test was created to reflect student learning of the specific content covered during the progress-monitoring period; thus, the knowledge test was more representative of students’ learning of the material covered in class during the time of the study than either course grades or the standardized achievement test in science.</p>
<p>Two types of questions were included on the knowledge test: factual and applied. One third of the questions were factual, where students were required to make simple one-to-one relations between names, terms, and events, and two thirds were applied, where students were required to apply knowledge to correctly answer a question (see <xref ref-type="table" rid="table2-1534508413489724">Table 2</xref> for examples). The emphasis was put on applied questions to ensure that a relation between the vocabulary probes and the knowledge test would not solely be a function of the similarities between vocabulary-matching and factual questions. After test items were constructed, two independent evaluators read and classified each question as factual or applied. Item disagreements were discussed and revisions were made to questions if necessary. Questions were ordered in blocks of three questions representing each of the three units. This was done to ensure that participants would be exposed to questions from all of the units as they progressed through the test.</p>
<table-wrap id="table2-1534508413489724" position="float">
<label>Table 2.</label>
<caption>
<p>Examples of Factual and Applied Questions From Knowledge Pre- and Posttests.</p>
</caption>
<graphic alternate-form-of="table2-1534508413489724" xlink:href="10.1177_1534508413489724-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Question Type</th>
<th align="center">Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td>Factual</td>
<td>The green leaf-like structure that supports a flower is called a:</td>
</tr>
<tr>
<td/>
<td> A. petal</td>
</tr>
<tr>
<td/>
<td> B. leaf</td>
</tr>
<tr>
<td/>
<td> C. stamen</td>
</tr>
<tr>
<td/>
<td> D. sepal</td>
</tr>
<tr>
<td/>
<td>The outside layer of a paramecium is called the:</td>
</tr>
<tr>
<td/>
<td> A. pellicle</td>
</tr>
<tr>
<td/>
<td> B. nuclei</td>
</tr>
<tr>
<td/>
<td> C. protective vacuole</td>
</tr>
<tr>
<td/>
<td> D. waxy layer</td>
</tr>
<tr>
<td>Applied</td>
<td>In science class, Alan crossed tall pea plants with short pea plants, but all the plants he grew turned out to be tall. The reason for this is:</td>
</tr>
<tr>
<td/>
<td> A. tall is the dominant trait</td>
</tr>
<tr>
<td/>
<td> B. short is the dominant trait</td>
</tr>
<tr>
<td/>
<td> C. tall is the recessive trait</td>
</tr>
<tr>
<td/>
<td> D. neither trait is dominant</td>
</tr>
<tr>
<td/>
<td>Joe soaked two beans in water and removed the seed coat from one of the beans. The bean that will germinate more easily is:</td>
</tr>
<tr>
<td/>
<td> A. the bean with the seed coat.</td>
</tr>
<tr>
<td/>
<td> B. the bean without the seed coat.</td>
</tr>
<tr>
<td/>
<td> C. both beans will germinate at the same time.</td>
</tr>
<tr>
<td/>
<td> D. neither bean will germinate because they have been soaked.</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Science grades were students’ mean grades in the class across two grading periods. Letter grades were converted to numeric values on a 14-point scale, with 13 representing an A+, 12 for an A, 11 an A−, 10 a B+, and so forth. A score of 0 was assigned for a grade of F. Students who did not pass the class were able to retake it in a 4-week afterschool makeup session. Students who passed this session received a passing grade of “P,” which for our analysis was assigned a numeric value of 1. Course grades were based on homework, quizzes, labs, and unit tests. The two teachers who participated in the study had collaborated closely for several years on the development of curricula and activities used in their classrooms. All grading rubrics used to assign student grades were generated collaboratively between the two teachers. The high degree of collaboration between the two teachers, plus the use of consistent grading rubrics, helped to ensure that student grades were assigned similarly across the two teachers.</p>
<p>Students had completed the ITBS (Form K, Level 12) in the spring of the year prior to the beginning of the study. Scores were obtained from school records. Questions on the science subtest of the ITBS assessed students’ knowledge of scientific principles and information, as well as techniques and procedures for scientific inquiry. Questions included scenarios that presented real-life science investigations mimicking what one might do when designing and conducting research and analyzing data. Four major content areas were covered by the ITBS science subtest: scientific inquiry, life science, earth and space science, and physical science. The content validity of the ITBS was established through the use of curriculum guides, textbooks, and research to generate item groups; the items of the ITBS were reviewed for content fit and item bias by field experts and then tested on a large sample across the United States, Guam, and the Virgin Islands. The technical manual of the test reports internal consistency reliability for the science subtest ranging from .85 to .90 (<xref ref-type="bibr" rid="bibr30-1534508413489724">Salvia &amp; Ysseldyke, 1998</xref>). No data were reported for test–retest reliability or construct or criterion validity. Standard scores were used for all analyses.</p>
</sec>
<sec id="section7-1534508413489724">
<title>Procedure</title>
<p>Classroom teachers administered all vocabulary measures to students during their science class periods. One CBM vocabulary-matching probe was administered to students each week for 14 weeks. Probes were administered to the students as a group. Students were given 5 min to complete each probe and were instructed to match terms with definitions. Scores on the vocabulary-matching probe were the number of correct matches. Teachers were observed three times to ensure fidelity of implementation. A fidelity checklist used by observers contained items including correctly giving scripted directions and giving an appropriate amount of time to complete the probes. Teachers implemented all measures correctly.</p>
<p>The knowledge test was administered by the research team prior to the beginning of the study and after the completion of the study to measure the amount learned during the study. Students were given as much time as was necessary to complete the 45-item multiple-choice test. The number of correct answers was scored.</p>
<p>Vocabulary-matching probes and knowledge pre- and posttests were scored by the research team. Accuracy of scoring was checked for 20% of all probes and pre- and posttests by having a second person score the measures. Accuracy was calculated by dividing agreements by agreements plus disagreements. Accuracy of scoring was 94% for the vocabulary-matching probes, 95% for the knowledge pretests, and 98% for knowledge posttests. Most disagreements were due to illegible handwriting by the participants. Such disagreement were resolved through discussion between the two scorers, and if necessary, the opinions of a third scorer. If a disagreement in scoring revealed a systematic problem (e.g., the student wrote an “a” that looked like a “d”), all protocols for that student were rescored.</p>
</sec>
<sec id="section8-1534508413489724">
<title>Statistical Analysis</title>
<p>To examine the reliability of the measures, Pearson correlations were calculated between adjacent alternate forms of the measures. To examine validity of the measures as indicators of performance, Pearson correlations were calculated between scores on the vocabulary-matching probes and the criterion measures. Finally, to examine the validity of the measures as indicators of growth, HLM (<xref ref-type="bibr" rid="bibr6-1534508413489724">Bryk &amp; Raudenbush, 1992</xref>) using HLM 7 software was used. Our principal objective was to ascertain the measures’ sensitivity to growth of student performance over time, as well as the sensitivity to interindividual differences in growth rates. An additional item of interest was to determine the validity of the growth rates produced by the probes. Model testing was used by considering both unconditional and conditional HLM models. Unconditional models were determined to meet the standards of appropriate analysis to examine the sensitivity of the probes for measuring student growth over time and for determining interindividual differences in growth rates. In these analyses, the significance of the mean growth rates and growth parameter variances estimated by the science vocabulary probes were statistically examined. To address the validity of growth rates relative to the predictor variables, course grades, scores from the ITBS, and gain scores on the knowledge test were examined as Level 2 predictors in HLM.</p>
</sec>
</sec>
<sec id="section9-1534508413489724" sec-type="results">
<title>Results</title>
<p>The first research question addressed the reliability and validity of the vocabulary-matching measures. Alternate-form reliability was calculated by examining correlations between adjacent probes (i.e., Week 1 with Week 2, Week 2 with Week 3, etc.). Means and standard deviations for the vocabulary-matching probes are reported in <xref ref-type="table" rid="table3-1534508413489724">Table 3</xref>. Alternate-form reliability coefficients for adjacent probes, and the mean reliability across all adjacent probes, are reported in <xref ref-type="table" rid="table4-1534508413489724">Table 4</xref>. Alternate-form reliabilities ranged from <italic>r</italic> = 0.64 to 0.84, with a mean reliability of <italic>r</italic> = .77. Reliability coefficients increased steadily with time: Beginning with probes 8/9, all coefficients were above <italic>r</italic> = .80. Alternate-form reliabilities for combined scores across two probes were also calculated. Coefficients for combined scores ranged from <italic>r</italic> = .80 to .89, with a mean of .85.</p>
<table-wrap id="table3-1534508413489724" position="float">
<label>Table 3.</label>
<caption>
<p>Means and Standard Deviations for Science Vocabulary-Matching Measures.</p>
</caption>
<graphic alternate-form-of="table3-1534508413489724" xlink:href="10.1177_1534508413489724-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Probe</th>
<th align="center"><italic>n</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Probe 1</td>
<td>188</td>
<td>6.09</td>
<td>3.38</td>
</tr>
<tr>
<td>Probe 2</td>
<td>185</td>
<td>6.07</td>
<td>3.36</td>
</tr>
<tr>
<td>Probe 3</td>
<td>181</td>
<td>5.77</td>
<td>3.87</td>
</tr>
<tr>
<td>Probe 4</td>
<td>181</td>
<td>7.00</td>
<td>4.31</td>
</tr>
<tr>
<td>Probe 5</td>
<td>192</td>
<td>9.69</td>
<td>4.44</td>
</tr>
<tr>
<td>Probe 6</td>
<td>184</td>
<td>7.78</td>
<td>4.24</td>
</tr>
<tr>
<td>Probe 7</td>
<td>182</td>
<td>8.47</td>
<td>4.56</td>
</tr>
<tr>
<td>Probe 8</td>
<td>184</td>
<td>8.63</td>
<td>4.24</td>
</tr>
<tr>
<td>Probe 9</td>
<td>180</td>
<td>11.51</td>
<td>4.90</td>
</tr>
<tr>
<td>Probe 10</td>
<td>183</td>
<td>10.90</td>
<td>5.86</td>
</tr>
<tr>
<td>Probe 11</td>
<td>176</td>
<td>12.48</td>
<td>5.39</td>
</tr>
<tr>
<td>Probe 12</td>
<td>175</td>
<td>10.25</td>
<td>6.23</td>
</tr>
<tr>
<td>Probe 13</td>
<td>176</td>
<td>13.02</td>
<td>5.62</td>
</tr>
<tr>
<td>Probe 14</td>
<td>173</td>
<td>12.25</td>
<td>6.02</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="table4-1534508413489724" position="float">
<label>Table 4.</label>
<caption>
<p>Alternate-Form Reliability for Science Vocabulary-Matching Measures.</p>
</caption>
<graphic alternate-form-of="table4-1534508413489724" xlink:href="10.1177_1534508413489724-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Adjacent Measures</th>
<th align="center">Reliability Coefficient</th>
</tr>
</thead>
<tbody>
<tr>
<td> 1 with 2</td>
<td>.68</td>
</tr>
<tr>
<td> 2 with 3</td>
<td>.64</td>
</tr>
<tr>
<td> 3 with 4</td>
<td>.74</td>
</tr>
<tr>
<td> 4 with 5</td>
<td>.75</td>
</tr>
<tr>
<td> 5 with 6</td>
<td>.74</td>
</tr>
<tr>
<td> 6 with 7</td>
<td>.78</td>
</tr>
<tr>
<td> 7 with 8</td>
<td>.73</td>
</tr>
<tr>
<td> 8 with 9</td>
<td>.81</td>
</tr>
<tr>
<td> 9 with 10</td>
<td>.82</td>
</tr>
<tr>
<td>10 with 11</td>
<td>.81</td>
</tr>
<tr>
<td>11 with 12</td>
<td>.82</td>
</tr>
<tr>
<td>12 with 13</td>
<td>.83</td>
</tr>
<tr>
<td>13 with 14</td>
<td>.84</td>
</tr>
<tr>
<td><italic>M</italic></td>
<td>.77</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1534508413489724">
<p><italic>Note.</italic> All coefficients statistically significant at <italic>p</italic> &lt; .01 level.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>To examine the validity of the vocabulary-matching measures as indicators of performance, correlations were calculated between scores on the vocabulary-matching probes and scores on the knowledge pre- and posttest, the science subtest of the ITBS, and the mean of students’ third- and fourth-quarter grades in their science classes. Means and standard deviations for the measures are reported in <xref ref-type="table" rid="table5-1534508413489724">Table 5</xref>. Scores for the vocabulary-matching measures were the means across the first three (vocabulary-matching pretest) and last three vocabulary-matching probes (vocabulary-matching posttests).</p>
<table-wrap id="table5-1534508413489724" position="float">
<label>Table 5.</label>
<caption>
<p>Means and Standard Deviations for Vocabulary-Matching and Criterion Measures.</p>
</caption>
<graphic alternate-form-of="table5-1534508413489724" xlink:href="10.1177_1534508413489724-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Measure</th>
<th align="center"><italic>n</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="4">Vocabulary-matching measures</td>
</tr>
<tr>
<td> Pretest (probes 1–3)</td>
<td>198</td>
<td>5.97</td>
<td>3.17</td>
</tr>
<tr>
<td> Posttest (probes 12–14)</td>
<td>193</td>
<td>11.74</td>
<td>5.67</td>
</tr>
<tr>
<td>Knowledge pretest<sup><xref ref-type="table-fn" rid="table-fn2-1534508413489724">a</xref></sup></td>
<td>190</td>
<td>19.25</td>
<td>6.32</td>
</tr>
<tr>
<td>Knowledge posttest<sup><xref ref-type="table-fn" rid="table-fn2-1534508413489724">a</xref></sup></td>
<td>169</td>
<td>33.20</td>
<td>6.16</td>
</tr>
<tr>
<td><italic>Iowa Test of Basic Skills</italic><sup><xref ref-type="table-fn" rid="table-fn3-1534508413489724">b</xref></sup></td>
<td>193</td>
<td>250.28</td>
<td>36.55</td>
</tr>
<tr>
<td>Mean course grades<sup><xref ref-type="table-fn" rid="table-fn4-1534508413489724">c</xref></sup></td>
<td>192</td>
<td>8.77</td>
<td>2.73</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1534508413489724">
<label>a</label>
<p>Number correct out of a possible 45.</p>
</fn>
<fn id="table-fn3-1534508413489724">
<label>b</label>
<p>Score reported is a standard score.</p>
</fn>
<fn id="table-fn4-1534508413489724">
<label>c</label>
<p>Grades are on a scale of 0 to 13: 0 = F, 1 = P, 2 = D −, 3 = D, 4 = D+, 5 = C−, 6 = C, 7 = C+, 8 = B−, 9 = B, 10 = B+, 11 = A−, 12 = A, 13 = A+.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Correlations between the vocabulary-matching and criterion measures ranged from .55 to .76 (see <xref ref-type="table" rid="table6-1534508413489724">Table 6</xref>). The strongest correlations were between the vocabulary-matching and knowledge pretests (<italic>r</italic> = .72) and posttests (<italic>r</italic> = .76). Correlations with the ITBS and course grades were somewhat lower, ranging from <italic>r</italic> = .57 to .66, and were similar to the correlations between the vocabulary-matching pretest and knowledge posttest (<italic>r</italic> = .67).</p>
<table-wrap id="table6-1534508413489724" position="float">
<label>Table 6.</label>
<caption>
<p>Correlations Between Vocabulary-Matching Measures and Criterion Measures.</p>
</caption>
<graphic alternate-form-of="table6-1534508413489724" xlink:href="10.1177_1534508413489724-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Measure</th>
<th align="center">Vocabulary-Matching Pretest<sup><xref ref-type="table-fn" rid="table-fn6-1534508413489724">a</xref></sup></th>
<th align="center">Vocabulary-Matching Posttest<sup><xref ref-type="table-fn" rid="table-fn7-1534508413489724">b</xref></sup></th>
<th align="center">Knowledge Pretest</th>
<th align="center">Knowledge Posttest</th>
<th align="center">ITBS<sup><xref ref-type="table-fn" rid="table-fn8-1534508413489724">c</xref></sup></th>
<th align="center">Course Grades</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vocabulary-matching pretest</td>
<td>—</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Vocabulary-matching posttest</td>
<td>.73</td>
<td>—</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Knowledge pretest</td>
<td>.72</td>
<td>.55</td>
<td>—</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Knowledge posttest</td>
<td>.67</td>
<td>.76</td>
<td>.61</td>
<td>—</td>
<td/>
<td/>
</tr>
<tr>
<td>ITBS</td>
<td>.66</td>
<td>.64</td>
<td>.57</td>
<td>.67</td>
<td>—</td>
<td/>
</tr>
<tr>
<td>Course grades</td>
<td>.57</td>
<td>.65</td>
<td>.49</td>
<td>.60</td>
<td>.54</td>
<td>—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-1534508413489724">
<p><italic>Note.</italic> ITBS = <italic>Iowa Test of Basic Skills</italic>. All coefficients statistically significant at <italic>p</italic> &lt; .001 level.</p>
</fn>
<fn id="table-fn6-1534508413489724">
<label>a</label>
<p>Mean score on vocabulary-matching Probes 1 to 3.</p>
</fn>
<fn id="table-fn7-1534508413489724">
<label>b</label>
<p>Mean score on vocabulary-matching Probes 14 to 16.</p>
</fn>
<fn id="table-fn8-1534508413489724">
<label>c</label>
<p>ITBS, science subtest.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Intercorrelation coefficients also are presented in <xref ref-type="table" rid="table6-1534508413489724">Table 6</xref>. Comparing the correlations between the vocabulary measures and criterion variables with the correlations among the criterion variables themselves, one sees that correlations between vocabulary-matching and the ITBS (<italic>r</italic> = .66 and .64) were similar to or slightly higher than correlations between the knowledge tests and the ITBS (<italic>r</italic> = .57 and .67) and between course grades and the ITBS (<italic>r</italic> = .54). Correlations between the vocabulary-matching measures and course grades (<italic>r</italic> = .57 and .65) were similar to or slightly higher than the correlations between the knowledge tests and course grades (<italic>r</italic> = .49 and .60) and between the ITBS and course grades (<italic>r</italic> = .54).</p>
<sec id="section10-1534508413489724">
<title>Sensitivity to Growth Over Time and Individual Differences</title>
<p>The second research question addressed the reliability and validity of a vocabulary-matching measure as an indicator of progress or learning in science. The initial step in the analysis was to determine whether the science vocabulary-matching probes were sensitive to growth over time and whether the measures revealed interindividual differences in growth rates. Descriptive statistics of repeated measures of students’ performance on the measures are presented in <xref ref-type="table" rid="table7-1534508413489724">Table 7</xref>. The growth in performance scores and interindividual differences in growth rates were examined using HLM. The statistical significance of the mean growth rate and of the group growth parameter variance was tested. These tests of significance addressed the questions of whether the growth rate for the entire group of students was statistically different from a null growth rate. The statistical test of significance of the growth parameter variance addressed the question of whether individual students differed in their rates of growth over time.</p>
<table-wrap id="table7-1534508413489724" position="float">
<label>Table 7.</label>
<caption>
<p>Growth Rates and Variance Parameter of Science Vocabulary-Matching Probes.</p>
</caption>
<graphic alternate-form-of="table7-1534508413489724" xlink:href="10.1177_1534508413489724-table7.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Effect</th>
<th align="center">Coefficient</th>
<th align="center"><italic>SE</italic></th>
<th align="center"><italic>t</italic> Ratio</th>
<th align="center"><italic>p</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Intercept (β00)</td>
<td>4.74</td>
<td>.30</td>
<td>15.63</td>
<td>.00</td>
</tr>
<tr>
<td>Mean growth (β10)</td>
<td>.63</td>
<td>.01</td>
<td>48.10</td>
<td>.00</td>
</tr>
<tr>
<th align="center">Effect</th>
<th align="center">Variance</th>
<th align="center">χ<sup>2</sup></th>
<th/>
<th align="center"><italic>p</italic></th>
</tr>
<tr>
<td>Intercept (β00)</td>
<td>15.27</td>
<td>5636.70</td>
<td/>
<td>.00</td>
</tr>
<tr>
<td>Mean growth (β10)</td>
<td>7.50</td>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn9-1534508413489724">
<p><italic>Note. df</italic> = 191.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>We posited that as a group, students would improve significantly in science content knowledge as a result of the teachers’ instruction. In addition, we posited that students would not share the same growth rates because of individual differences. To test the validity of these hypotheses, the following unconditional models were used in this study.</p>
<disp-formula id="disp-formula1-1534508413489724">
<mml:math display="block" id="math1-1534508413489724">
<mml:mtable columnalign="left">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>w</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mo>−</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>u</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>l</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>T</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula1-1534508413489724" xlink:href="10.1177_1534508413489724-eq1.tif"/>
</disp-formula>
<disp-formula id="disp-formula2-1534508413489724">
<mml:math display="block" id="math2-1534508413489724">
<mml:mtable columnalign="left">
<mml:mtr>
<mml:mtd>
<mml:mi>b</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>w</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>v</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>u</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>l</mml:mi>
<mml:mo>:</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>00</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula2-1534508413489724" xlink:href="10.1177_1534508413489724-eq2.tif"/>
</disp-formula>
<p>where <italic>Y<sub>ti</sub></italic> is the observed outcome score for student <italic>i</italic> at time <italic>t; Time</italic> is the measurement time minus 14, so that <italic>π<sub>0i</sub></italic> is the intercept or the expected outcome score for student <italic>i</italic> at the final measurement time (the 14th time point); <italic>π<sub>1i</sub></italic> is the slope or the average growth rate in the outcome measure between each measurement time for student <italic>i</italic>; <italic>e<sub>ti</sub></italic> is the error for student <italic>i</italic>; <italic>β<sub>00</sub></italic> is the average intercept or average outcome score for the group of students at the final measurement time; <italic>β<sub>10</sub></italic> is the average slope or average growth rate between each measurement time for the group of students; and <italic>u<sub>1i</sub></italic> is the random error for the average intercept and slope. The intercept was centered at the initial occasion of data collection to determine individual differences in the students’ science vocabulary knowledge at the beginning of the study. The statistical test of the significance of mean growth rates revealed that the mean growth rates estimated were statistically significant from a null growth rate (the measures were sensitive for presence of significant student growth over time). The mean growth rate estimated an increase of .63 correct matches per week (see <xref ref-type="table" rid="table7-1534508413489724">Table 7</xref>).</p>
<p>The statistical test of the significance of the growth parameter variance revealed that there were statistically significant differences from no variability in students’ growth rates, indicating that there were individual differences in growth rates on the measures. Regarding the performance at the beginning of the study, the mean intercept was significantly different from zero. These results reflected the existence of interindividual differences in science vocabulary knowledge at the beginning of the study (see <xref ref-type="table" rid="table7-1534508413489724">Table 7</xref>).</p>
</sec>
<sec id="section11-1534508413489724">
<title>Validity of Growth Rates</title>
<p>The validity of the growth rates of the probes were examined by considering the relations between the growth rates generated by the vocabulary measures and course grades, scores on the science subtest of the ITBS, and the residualized gain scores on the content knowledge test. The three criterion measures were analyzed separately as Level 2 predictor variables, as the primary goal of the analysis was to examine the direct relation between growth rates on the probes and the criterion measure, not the relative contribution of the criterion measures to predicting the students’ growth rates. The three Level 2 models used in the analysis were as follows:</p>
<disp-formula id="disp-formula3-1534508413489724">
<mml:math display="block" id="math3-1534508413489724">
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mtext>1i</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>C</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>u</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>G</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
<graphic alternate-form-of="disp-formula3-1534508413489724" xlink:href="10.1177_1534508413489724-eq3.tif"/>
</disp-formula>
<disp-formula id="disp-formula4-1534508413489724">
<mml:math display="block" id="math4-1534508413489724">
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mtext>1i</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mi>T</mml:mi>
<mml:mi>B</mml:mi>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mspace width="0.25em"/>
<mml:mtext>and</mml:mtext>
</mml:math>
<graphic alternate-form-of="disp-formula4-1534508413489724" xlink:href="10.1177_1534508413489724-eq4.tif"/>
</disp-formula>
<disp-formula id="disp-formula5-1534508413489724">
<mml:math display="block" id="math5-1534508413489724">
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mtext>1i</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>G</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
<graphic alternate-form-of="disp-formula5-1534508413489724" xlink:href="10.1177_1534508413489724-eq5.tif"/>
</disp-formula>
<p>where <italic>π<sub>1i</sub></italic> is the slope or linear growth rate for student <italic>i</italic>, <italic>β<sub>00</sub></italic> is the average intercept or average growth rate score for the group of students at the final measurement time, <italic>β<sub>10</sub></italic> is the average slope or average growth rate between each measurement time for the group of students, <italic>β<sub>11</sub></italic> is the regression coefficient showing the relation between the mean growth rate and each corresponding criterion measure, and <italic>u<sub>1i</sub></italic> is the random error related to the mean growth rate.</p>
<p>Before analyzing the relations between the criterion measures and the growth rates, we needed to establish the reliability of the growth rate parameter for each criterion. HLM literature describes reliability of the growth parameter as the proportion of observed variance to true variance (<xref ref-type="bibr" rid="bibr3-1534508413489724">Bikel, 2007</xref>; <xref ref-type="bibr" rid="bibr6-1534508413489724">Bryk &amp; Raudenbush 1992</xref>; <xref ref-type="bibr" rid="bibr32-1534508413489724">Singer &amp; Willett, 2003</xref>). Reliability coefficients less than .30 are considered to be unsound, and their relation to other variables cannot be examined in a dependable manner. The reliability of the growth rate variance was reported as .57 in the null model. This statistic would suggest that 57% of the growth rate variance estimated could be attributed to the true variance, thereby indicating that the relation between the mean growth rates and the criterion variables could be examined reliably in this study.</p>
<p>The results of the validity analyses revealed that the growth rate estimated by the vocabulary-matching measures was significantly related to the ITBS score, course grades, and the pre–posttest gain scores on the knowledge test (see <xref ref-type="table" rid="table8-1534508413489724">Table 8</xref>). In practical terms, the results mean that the students who grew more on the vocabulary-matching probes also had higher scores on the ITBS, had higher grades in science, and improved more on the knowledge test over the course of the study. These results support the validity of the science vocabulary-matching measures as an indicator of growth in performance.</p>
<table-wrap id="table8-1534508413489724" position="float">
<label>Table 8.</label>
<caption>
<p>Relations Between Growth Rates and Predictor Variables.</p>
</caption>
<graphic alternate-form-of="table8-1534508413489724" xlink:href="10.1177_1534508413489724-table8.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Criterion variable</th>
<th align="center">Coefficient</th>
<th align="center"><italic>SE</italic></th>
<th align="center"><italic>t</italic> Ratio</th>
<th align="center"><italic>p</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Course grades</td>
<td>.670</td>
<td>.083</td>
<td>8.10</td>
<td>.00</td>
</tr>
<tr>
<td>ITBS science scores</td>
<td>.630</td>
<td>.024</td>
<td>25.64</td>
<td>.00</td>
</tr>
<tr>
<td>Knowledge test gain score</td>
<td>.641</td>
<td>.071</td>
<td>18.75</td>
<td>.00</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn10-1534508413489724">
<p><italic>Note.</italic> ITBS = <italic>Iowa Test of Basic Skills. df</italic> = 190.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section12-1534508413489724" sec-type="discussion">
<title>Discussion</title>
<p>In this study, we investigated the technical adequacy of a vocabulary-matching measure as an indicator of performance and progress in science. Two research questions were addressed in the study:</p>
<list id="list2-1534508413489724" list-type="simple">
<list-item><p><italic>Research Question 1</italic>: What are the alternate-form reliability and validity of vocabulary-matching measures as indicators of performance in science?</p></list-item>
<list-item><p><italic>Research Question 2</italic>: What are the reliability and validity of vocabulary-matching measures as indicators of progress (growth) in science?</p></list-item>
</list>
<p>In general, the data provided support for the technical adequacy of a 5-min vocabulary-matching measure as an indicator of performance and progress in the science content area. Our first research question addressed the alternate-form reliability of the measures. Results of the research revealed mean alternate-form reliabilities across different forms of the measures of <italic>r</italic> = .77. Reliability coefficients increased steadily over time, from <italic>r</italic> = .68 at the beginning of the study to .84 at the end of the study. Thus, as students increased their scores on the probes—presumably because they were learning more science content—their performance on the probes became more stable. From Week 8/9 on, reliability coefficients were above <italic>r</italic> = .80. Combining scores across 2 weeks also served to increase reliability coefficients, implying that if the measures were to be used as screening measures, especially at the beginning of the school year, it would be wise to administer at least two probes to obtain a stable picture of students’ performance. Mean alternate-form reliabilities in this study were higher (mean reliability, <italic>r</italic> = .77) than those found in a previous study in social studies (<xref ref-type="bibr" rid="bibr12-1534508413489724">Espin et al., 2001</xref>; mean reliability <italic>r</italic> = .70), perhaps because science has a more specified vocabulary than does social studies.</p>
<p>Our second analysis addressed the validity of the measure as indicators of performance in science. To address this question, we compared mean scores on three vocabulary-matching probes administered at the beginning and end of the study with scores on knowledge pre- and posttests, the science subtest of the ITBS, and course grades in science. In general, the results supported the validity of the vocabulary-matching measure as an indicator of general performance in the science content area. Concurrent correlations between the vocabulary-matching pre- and posttest measures and the knowledge pre- and posttest were <italic>r =</italic> .72 and .76, respectively, suggesting that the measures could be used to rank-order students at a given time point on knowledge of classroom content. The correlation between the vocabulary-matching test administered at the beginning of the study and performance on the knowledge posttest administered at the end of the study was <italic>r =</italic> .67, suggesting that the measures could be used to predict future performance.</p>
<p>Correlations between the vocabulary measures and the ITBS were somewhat lower than for the knowledge tests, a not unexpected result given the fact that the ITBS was less closely matched to instruction than was the knowledge test, but correlations with the ITBS were still in the mid-60s. Correlations with course grades (<italic>r</italic> = .57 and .65) were also somewhat lower than with the knowledge tests, again a not unexpected result given the fact that grades often take into account multiple factors such as task completion and behavior. The correlations found in the present study are similar to those found in the previous research at the secondary school level in social studies (<xref ref-type="bibr" rid="bibr12-1534508413489724">Espin et al., 2001</xref>). Of interest is the fact that the correlations between the vocabulary measures and the criterion measures were, for the most part, the same as or higher than the correlations among the criterion measures themselves. Although the results imply that the simple, brief CBM measures served as reliable and valid indicators of performance, it is important to note that for the validity analyses, we combined scores across three measurement time points. Thus, although the measures were “brief,” they were still three 5-min probes, that is, a total of 15 min of measurement.</p>
<p>Our final question addressed the reliability and validity of the vocabulary-matching measure as an indicator of progress or learning in science. Students completed alternate forms of the measures over a period of 14 weeks. HLM analysis was used to examine the stability of the growth rates produced by repeated measures of the probes, and the relation between growth on the probes and growth and performance on criterion variables. Results supported the vocabulary-matching measures as indicators of growth in the science content area.</p>
<p>The mean growth rate on the measures was .63 matches per week, which was significantly different from no growth. This number is remarkably similar to the social studies results (<xref ref-type="bibr" rid="bibr12-1534508413489724">Espin et al., 2001</xref>) where the mean growth rate for student-read probes was .65, and also to the growth rates for elementary school students in science reported by <xref ref-type="bibr" rid="bibr37-1534508413489724">Vannest et al. (2011)</xref>. Results also revealed expected interindividual differences in growth rates and supported the validity of the growth rates produced by the vocabulary-matching measures. The growth parameter was found to be reliable, implying that the relation between growth in vocabulary-matching and the criterion variables could be estimated reliably. A significant relation was found between change in scores on the vocabulary-matching measures and scores on the ITBS, course grades, and growth on the knowledge test, supporting the validity of the measures as measures of progress in science.</p>
<sec id="section13-1534508413489724">
<title>Limitations and Future Research</title>
<p>There were several limitations to this study. First, the sample was selected from only one school in the Midwest and was limited to students in eighth grade. Also, the study involved progress monitoring in only one science curriculum. Replication of the study across other schools and geographic areas, other age/grade levels, and other science curricula is needed before strong conclusions can be drawn about the use of vocabulary-matching as a progress measure in science. Second, psychometric data for two of the criterion variables, the knowledge test and course grades, were unknown. These variables have “practical validity” in the sense that they represent the type of measures typically used to evaluate student performance in science, but in future research, it would be prudent to include other measures with known psychometric properties as criterion measures. Third, many questions remain unanswered regarding implementation of progress monitoring in the classroom situation. For example, who should do the monitoring and who should use/interpret the data? Should special educators monitor the progress of students with disabilities in their content-area classes, and use the data to make instructional decision, or should the content-area teachers collect, interpret, and use the data? In addition, if teachers collect the data, will they correctly interpret and then use the data to modify their instruction? And if they do use the data, does this use result in improved achievement for students with disabilities? These are questions not only of practicality but of validity (<xref ref-type="bibr" rid="bibr25-1534508413489724">Messick, 1989a</xref>, <xref ref-type="bibr" rid="bibr26-1534508413489724">1989b</xref>, <xref ref-type="bibr" rid="bibr27-1534508413489724">1994</xref>) and should be addressed in future Stage 3 (<xref ref-type="bibr" rid="bibr19-1534508413489724">L. S. Fuchs, 2004</xref>) research.</p>
</sec>
<sec id="section14-1534508413489724">
<title>Implications and Conclusions</title>
<p>Our results provide initial support for the technical adequacy of a vocabulary-matching probe as an indicator of performance and progress in science. The results are similar to those found for student-read probes in social studies at the secondary school level (<xref ref-type="bibr" rid="bibr12-1534508413489724">Espin et al., 2001</xref>), implying that the use of a vocabulary-matching measure may prove to be a generic method for use in measuring performance and progress in content-area learning for secondary school students.</p>
<p>Given the heavy vocabulary load found in science, it is not surprising that a vocabulary-matching measure might serve as a critical indicator of performance and progress in science. However, it is important to note that using a vocabulary-matching measure as an indicator of performance and progress does <italic>not</italic> imply that instruction in science should be focused solely on the development of vocabulary. Although good science instruction might include the development of science vocabulary, it is important that students develop an understanding of the scientific process and of scientific phenomena. If vocabulary-matching were to be used as an indicator of performance and progress in science, it would be important to ensure that teachers do not “teach to the test.”</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Armbruster</surname><given-names>B. B.</given-names></name>
<name><surname>Anderson</surname><given-names>T. H.</given-names></name>
</person-group> (<year>1988</year>). <article-title>On selecting “considerate” content area textbooks</article-title>. <source>Remedial and Special Education</source>, <volume>9</volume>, <fpage>47</fpage>–<lpage>52</lpage>. doi:<pub-id pub-id-type="doi">10.1177/-74193258800900109</pub-id></citation>
</ref>
<ref id="bibr2-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bean</surname><given-names>R. M.</given-names></name>
<name><surname>Zigmond</surname><given-names>N.</given-names></name>
<name><surname>Hartman</surname><given-names>D. K.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Adapted use of social studies textbooks in elementary classrooms: Views of classroom teachers</article-title>. <source>Remedial and Special Education</source>, <volume>9</volume>, <fpage>47</fpage>–<lpage>52</lpage>.</citation>
</ref>
<ref id="bibr3-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bikel</surname><given-names>R.</given-names></name>
</person-group> (<year>2007</year>). <source>Multilevel analysis for applied research: It’s just regression!</source> <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford</publisher-name>. doi:<pub-id pub-id-type="doi">10.1111/j.1744-6570.2008.00111_6.x</pub-id></citation>
</ref>
<ref id="bibr4-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Borsuk</surname><given-names>E. R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Examination of an administrator-read vocabulary-matching measure as an indicator of science achievement</article-title>. <source>Assessment for Effective Intervention</source>, <volume>35</volume>, <fpage>168</fpage>–<lpage>177</lpage>.</citation>
</ref>
<ref id="bibr5-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bryk</surname><given-names>A. S.</given-names></name>
<name><surname>Raudenbush</surname><given-names>S. W.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Application of hierarchical linear models to assessing change</article-title>. <source>Psychological Bulletin</source>, <volume>101</volume>, <fpage>147</fpage>–<lpage>158</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0033-2909.101.1.147</pub-id></citation>
</ref>
<ref id="bibr6-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bryk</surname><given-names>A. S.</given-names></name>
<name><surname>Raudenbush</surname><given-names>S. W.</given-names></name>
</person-group> (<year>1992</year>). <source>Hierarchical linear models in social and behavioral research: Applications and data analysis methods</source>. <publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr7-1534508413489724">
<citation citation-type="web">
<collab>Business-Higher Education Forum</collab>. (<year>2005</year>). <source>A commitment to America’s future: Responding to the crisis in mathematics &amp; science education</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.bhef.com/publications/documents/commitment_future_05.pdf">http://www.bhef.com/publications/documents/commitment_future_05.pdf</ext-link></citation>
</ref>
<ref id="bibr8-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carlisle</surname><given-names>J. F.</given-names></name>
<name><surname>Andrews</surname><given-names>E.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Monitoring learning-disabled students in mainstream science classes</article-title>. <source>Annals of Dyslexia</source>, <volume>43</volume>, <fpage>217</fpage>–<lpage>237</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BF02928183</pub-id></citation>
</ref>
<ref id="bibr9-1534508413489724">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Carnevale</surname><given-names>A. P.</given-names></name>
<name><surname>Smith</surname><given-names>N.</given-names></name>
<name><surname>Melton</surname><given-names>M.</given-names></name>
</person-group> (<year>2011</year>). <source>STEM: Science, technology, engineering, mathematics: Executive summary</source> (<publisher-name>Report of the Center on Education and the Workforce</publisher-name>, <publisher-loc>Georgetown University</publisher-loc>). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://cew.georgetown.edu/stem/">http://cew.georgetown.edu/stem/</ext-link></citation>
</ref>
<ref id="bibr10-1534508413489724">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Coble</surname><given-names>C.</given-names></name>
<name><surname>Allen</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <source>Keeping America competitive: Five strategies to improve mathematics and science education</source>. <publisher-loc>Denver, CO</publisher-loc>: <publisher-name>Education Commission of the States</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://sdsa.org/resources/publications/Keeping%20America%20Competitive.pdf">http://sdsa.org/resources/publications/Keeping%20America%20Competitive.pdf</ext-link></citation>
</ref>
<ref id="bibr11-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Deno</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Curriculum-based measurement: The emerging alternative</article-title>. <source>Exceptional Children</source>, <volume>52</volume>, <fpage>219</fpage>–<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr12-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Busch</surname><given-names>T.</given-names></name>
<name><surname>Shin</surname><given-names>J.</given-names></name>
<name><surname>Kruschwitz</surname><given-names>R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Curriculum-based measures in the content areas: Validity of vocabulary-matching measures as indicators of performance in social studies</article-title>. <source>Learning Disabilities Research &amp; Practice</source>, <volume>16</volume>, <fpage>142</fpage>–<lpage>151</lpage>. doi:<pub-id pub-id-type="doi">10.111/0938-8982.00015</pub-id></citation>
</ref>
<ref id="bibr13-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Deno</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Performance in reading from content-area text as an indicator of achievement</article-title>. <source>Remedial and Special Education</source>, <volume>14</volume>(<issue>6</issue>), <fpage>47</fpage>–<lpage>59</lpage>. doi:<pub-id pub-id-type="doi">10.1177/074193259301400610</pub-id></citation>
</ref>
<ref id="bibr14-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Foegen</surname><given-names>A.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Validity of three general outcome measures for predicting secondary students’ performance on content-area tasks</article-title>. <source>Exceptional Children</source>, <volume>62</volume>, <fpage>497</fpage>–<lpage>514</lpage>.</citation>
</ref>
<ref id="bibr15-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Shin</surname><given-names>J.</given-names></name>
<name><surname>Busch</surname><given-names>T. W.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Curriculum-based measurement in the content areas: Vocabulary matching as an indicator of progress in social studies learning</article-title>. <source>Journal of Learning Disabilities</source>, <volume>38</volume>, <fpage>353</fpage>–<lpage>363</lpage>. doi:<pub-id pub-id-type="doi">10.1177/00222194050380041301</pub-id></citation>
</ref>
<ref id="bibr16-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Tindal</surname><given-names>G.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Curriculum-based measurement for secondary students</article-title>. In <person-group person-group-type="editor">
<name><surname>Shinn</surname><given-names>M.</given-names></name>
</person-group> (Ed.), <source>Advanced applications of curriculum-based measurement</source> (pp. <fpage>214</fpage>–<lpage>253</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford</publisher-name>.</citation>
</ref>
<ref id="bibr17-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fang</surname><given-names>Z.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The language demands of science reading in middle school</article-title>. <source>International Journal of Science Education</source>, <volume>28</volume>, <fpage>491</fpage>–<lpage>520</lpage>. doi:<pub-id pub-id-type="doi">10.1080/09500690500339092</pub-id></citation>
</ref>
<ref id="bibr18-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fuchs</surname><given-names>D.</given-names></name>
<name><surname>Mock</surname><given-names>D.</given-names></name>
<name><surname>Morgan</surname><given-names>P. L.</given-names></name>
<name><surname>Young</surname><given-names>C. S.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Responsiveness-to-intervention: Definitions, evidence, and implications for the learning disabilities construct</article-title>. <source>Learning Disabilities Research &amp; Practice</source>, <volume>18</volume>, <fpage>157</fpage>–<lpage>171</lpage>. doi:<pub-id pub-id-type="doi">10.1111/1540-5826.00072</pub-id></citation>
</ref>
<ref id="bibr19-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fuchs</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2004</year>). <article-title>The past, present, and future of curriculum-based measurement research</article-title>. <source>School Psychology Review</source>, <volume>33</volume>, <fpage>188</fpage>–<lpage>192</lpage>.</citation>
</ref>
<ref id="bibr20-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Groves</surname><given-names>F. H.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Science vocabulary load of selected secondary science textbooks</article-title>. <source>School Sciences &amp; Mathematics</source>, <volume>95</volume>, <fpage>231</fpage>–<lpage>235</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1949-8594.1995.tb15772.x</pub-id></citation>
</ref>
<ref id="bibr21-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hoover</surname><given-names>H. D.</given-names></name>
<name><surname>Dunbar</surname><given-names>S. B.</given-names></name>
<name><surname>Frisbie</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1993</year>). <source>Iowa Tests of Basic Skills</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Riverside</publisher-name>.</citation>
</ref>
<ref id="bibr22-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mason</surname><given-names>L. H.</given-names></name>
<name><surname>Hedin</surname><given-names>L. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Reading science text: Challenges for students with learning disabilities and considerations for teachers</article-title>. <source>Learning Disabilities Research &amp; Practice</source>, <volume>26</volume>, <fpage>214</fpage>–<lpage>222</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1540-5826.2011.00342.x</pub-id></citation>
</ref>
<ref id="bibr23-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mastropieri</surname><given-names>M.</given-names></name>
<name><surname>Scruggs</surname><given-names>T. E.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Science for students with disabilities</article-title>. <source>Review of Educational Research</source>, <volume>62</volume>, <fpage>377</fpage>–<lpage>410</lpage>. doi:<pub-id pub-id-type="doi">10.3102/00346543062004377</pub-id></citation>
</ref>
<ref id="bibr24-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mastropieri</surname><given-names>M.</given-names></name>
<name><surname>Scruggs</surname><given-names>T. E.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Text versus hands-on science curriculum: Implications for students with disabilities</article-title>. <source>Remedial and Special Education</source>, <volume>15</volume>, <fpage>72</fpage>–<lpage>85</lpage>. doi:<pub-id pub-id-type="doi">10.1177/074193259401500203</pub-id></citation>
</ref>
<ref id="bibr25-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Messick</surname><given-names>S.</given-names></name>
</person-group> (<year>1989a</year>). <article-title>Meaning and values in test validation: The science and ethics of assessment</article-title>. <source>Educational Researcher</source>, <volume>18</volume>(<issue>2</issue>), <fpage>5</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr26-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Messick</surname><given-names>S.</given-names></name>
</person-group> (<year>1989b</year>). <source>Validity</source>. In <person-group person-group-type="editor">
<name><surname>Linn</surname><given-names>R. L.</given-names></name>
</person-group> (Ed.), <source>Educational measurement</source> (<edition>3rd ed.</edition>, pp. <fpage>13</fpage>–<lpage>103</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Macmillan</publisher-name>.</citation>
</ref>
<ref id="bibr27-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Messick</surname><given-names>S.</given-names></name>
</person-group> (<year>1994</year>). <article-title>The interplay of evidence and consequences in the validation of performance assessments</article-title>. <source>Educational Researcher</source>, <volume>23</volume>(<issue>2</issue>), <fpage>13</fpage>–<lpage>23</lpage>.</citation>
</ref>
<ref id="bibr28-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moin</surname><given-names>L. J.</given-names></name>
<name><surname>Magiera</surname><given-names>K.</given-names></name>
<name><surname>Zigmond</surname><given-names>N.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Instructional activities and group work in the US inclusive high school co-taught science class</article-title>. <source>International Journal of Science and Mathematics Education</source>, <volume>7</volume>, <fpage>677</fpage>–<lpage>697</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10763-008-9133</pub-id></citation>
</ref>
<ref id="bibr29-1534508413489724">
<citation citation-type="book">
<collab>National Center for Education Statistics</collab>. (<year>2012</year>). <source>The Nation’s Report Card: Science 2011 (NCES 2012-465)</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr30-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Salvia</surname><given-names>J.</given-names></name>
<name><surname>Ysseldyke</surname><given-names>J.</given-names></name>
</person-group> (<year>1998</year>). <source>Assessment</source> (<edition>6th ed.</edition>). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Houghton Mifflin</publisher-name>.</citation>
</ref>
<ref id="bibr31-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scruggs</surname><given-names>T. E.</given-names></name>
<name><surname>Mastropieri</surname><given-names>M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Science learning in special education: The case for constructed versus instructed learning</article-title>. <source>Exceptionality</source>, <volume>15</volume>, <fpage>57</fpage>–<lpage>74</lpage>. doi:<pub-id pub-id-type="doi">10.1080/09362830701294144</pub-id></citation>
</ref>
<ref id="bibr32-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Singer</surname><given-names>J. D.</given-names></name>
<name><surname>Willett</surname><given-names>J. B.</given-names></name>
</person-group> (<year>2003</year>). <source>Applied longitudinal data analysis: Modeling change and event occurrence</source>. <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr33-1534508413489724">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Therrien</surname><given-names>W. J.</given-names></name>
<name><surname>Hughes</surname><given-names>C.</given-names></name>
<name><surname>Hand</surname><given-names>B.</given-names></name>
</person-group> (Eds.). (<year>2011</year>). <article-title>Special issue on science</article-title>. <source>Learning Disabilities Research &amp; Practice</source>, <volume>26</volume>(<issue>4</issue>), <fpage>186</fpage>–<lpage>240</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1540-5826.2011.00340.x</pub-id></citation>
</ref>
<ref id="bibr34-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tindal</surname><given-names>G.</given-names></name>
<name><surname>Nolet</surname><given-names>V.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Curriculum-based measurement in middle and high schools: Critical thinking skills in content areas</article-title>. <source>Focus on Exceptional Children</source>, <volume>27</volume>(<issue>7</issue>), <fpage>1</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr35-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tindal</surname><given-names>G.</given-names></name>
<name><surname>Nolet</surname><given-names>V.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Serving students in middle school content classes: A heuristic study of critical variables linking instruction and assessment</article-title>. <source>Journal of Special Education</source>, <volume>29</volume>, <fpage>414</fpage>–<lpage>432</lpage>.</citation>
</ref>
<ref id="bibr36-1534508413489724">
<citation citation-type="gov">
<collab>U.S. Department of Education</collab>. (<year>2006</year>). <source>Increasing America’s competitiveness</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ed.gov/teachers/how/prep/higher/competitiveness.html">http://www.ed.gov/teachers/how/prep/higher/competitiveness.html</ext-link></citation>
</ref>
<ref id="bibr37-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vannest</surname><given-names>K. J.</given-names></name>
<name><surname>Parker</surname><given-names>R.</given-names></name>
<name><surname>Dyer</surname><given-names>N.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Progress monitoring in grade 5 science for low achievers</article-title>. <source>Journal of Special Education</source>, <volume>44</volume>, <fpage>221</fpage>–<lpage>233</lpage>.</citation>
</ref>
<ref id="bibr38-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Fuchs</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Redefining learning disabilities as inadequate response to instruction: The promise and potential problems</article-title>. <source>Learning Disabilities Research &amp; Practice</source>, <volume>18</volume>, <fpage>137</fpage>–<lpage>146</lpage>. doi:<pub-id pub-id-type="doi">10.1111/1540-5826.00070</pub-id></citation>
</ref>
<ref id="bibr39-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wayman</surname><given-names>M. M.</given-names></name>
<name><surname>Wallace</surname><given-names>T.</given-names></name>
<name><surname>Wiley</surname><given-names>H. I.</given-names></name>
<name><surname>Tichá</surname><given-names>R.</given-names></name>
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Literature synthesis on curriculum-based measurement in reading</article-title>. <source>Journal of Special Education</source>, <volume>41</volume>, <fpage>85</fpage>–<lpage>120</lpage>. doi:<pub-id pub-id-type="doi">10.1177/00224669070410020401</pub-id></citation>
</ref>
<ref id="bibr40-1534508413489724">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yager</surname><given-names>R. E.</given-names></name>
</person-group> (<year>1983</year>). <article-title>The importance of terminology in teaching K-12 science</article-title>. <source>Journal of Research in Science Teaching</source>, <volume>20</volume>, <fpage>577</fpage>–<lpage>588</lpage>. doi:<pub-id pub-id-type="doi">10.1002/tea.3660200610</pub-id></citation>
</ref>
</ref-list>
</back>
</article>