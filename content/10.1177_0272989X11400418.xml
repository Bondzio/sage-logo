<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MDM</journal-id>
<journal-id journal-id-type="hwp">spmdm</journal-id>
<journal-id journal-id-type="nlm-ta">Med Decis Making</journal-id>
<journal-title>Medical Decision Making</journal-title>
<issn pub-type="ppub">0272-989X</issn>
<issn pub-type="epub">1552-681X</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0272989X11400418</article-id>
<article-id pub-id-type="publisher-id">10.1177_0272989X11400418</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Natural Language Processing Improves Identification of Colorectal Cancer Testing in the Electronic Medical Record</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Denny</surname><given-names>Joshua C.</given-names></name>
<degrees>MD, MS</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Choma</surname><given-names>Neesha N.</given-names></name>
<degrees>MD, MPH</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Peterson</surname><given-names>Josh F.</given-names></name>
<degrees>MD, MPH</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Miller</surname><given-names>Randolph A.</given-names></name>
<degrees>MD</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Bastarache</surname><given-names>Lisa</given-names></name>
<degrees>BS, MS</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Li</surname><given-names>Ming</given-names></name>
<degrees>PhD</degrees>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Peterson</surname><given-names>Neeraja B.</given-names></name>
<degrees>MD, MSc</degrees>
</contrib>
</contrib-group>
<aff id="aff1-0272989X11400418">Division of General Internal Medicine and Public Health, Department of Medicine, Vanderbilt University Medical Center, Nashville, Tennessee (JCD, NNC, JFP, NBP)</aff>
<aff id="aff2-0272989X11400418">Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, Tennessee (JCD, JFP, RAM, LB)</aff>
<aff id="aff3-0272989X11400418">Veterans Administration, Tennessee Valley Healthcare System, Tennessee Valley Geriatric Research Education Clinical Center (GRECC), Nashville, Tennessee (NNC, JFP)</aff>
<aff id="aff4-0272989X11400418">Department of Biostatistics, Vanderbilt University, Nashville, Tennessee (ML)</aff>
<author-notes>
<corresp id="corresp1-0272989X11400418">Neeraja B. Peterson, Division of General Internal Medicine and Public Health, Department of Medicine, Vanderbilt University Medical Center, Suite 6108, Medical Center East, North Tower, Nashville, TN 37232-8300; telephone: (615) 936-1010; fax: (615) 936-1269; e-mail: <email>neeraja.peterson@vanderbilt.edu</email>.</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>32</volume>
<issue>1</issue>
<fpage>188</fpage>
<lpage>197</lpage>
<history>
<date date-type="received">
<day>3</day>
<month>5</month>
<year>2010</year>
</date>
<date date-type="accepted">
<day>9</day>
<month>1</month>
<year>2011</year>
</date>
</history>
<abstract>
<p><bold>Background</bold>. Difficulty identifying patients in need of colorectal cancer (CRC) screening contributes to low screening rates. <bold>Objective</bold>. To use Electronic Health Record (EHR) data to identify patients with prior CRC testing. <bold>Design</bold>. A clinical natural language processing (NLP) system was modified to identify 4 CRC tests (colonoscopy, flexible sigmoidoscopy, fecal occult blood testing, and double contrast barium enema) within electronic clinical documentation. Text phrases in clinical notes referencing CRC tests were interpreted by the system to determine whether testing was planned or completed and to estimate the date of completed tests. <bold>Setting</bold>. Large academic medical center. <bold>Patients</bold>. 200 patients ≥50 years old who had completed ≥2 non-acute primary care visits within a 1-year period. <bold>Measures</bold>. Recall and precision of the NLP system, billing records, and human chart review were compared to a reference standard of human review of all available information sources. <bold>Results</bold>. For identification of all CRC tests, recall and precision were as follows: NLP system (recall 93%, precision 94%), chart review (74%, 98%), and billing records review (44%, 83%). Recall and precision for identification of patients in need of screening were: NLP system (recall 95%, precision 88%), chart review (99%, 82%), and billing records (99%, 67%). <bold>Limitations</bold>. Small sample size and requirement for a robust EHR. <bold>Conclusions</bold>. Applying NLP to EHR records detected more CRC tests than either manual chart review or billing records review alone. NLP had better precision but marginally lower recall to identify patients who were due for CRC screening than billing record review.</p>
</abstract>
<kwd-group>
<kwd>colorectal cancer screening</kwd>
<kwd>cancer screening</kwd>
<kwd>preventive health</kwd>
<kwd>natural language processing</kwd>
<kwd>electronic health records</kwd>
<kwd>electronic medical records</kwd>
</kwd-group>
<custom-meta-wrap>
<custom-meta>
<meta-name>cover-date</meta-name>
<meta-value>January–February 2012</meta-value>
</custom-meta>
</custom-meta-wrap>
</article-meta>
</front>
<body>
<p>Colorectal cancer (CRC) is the third most common cancer and second leading cause of cancer death for both men and women in the United States. In 2009, an expected 146 970 new cases of colorectal cancer will lead to an estimated 49 920 deaths.<sup><xref ref-type="bibr" rid="bibr1-0272989X11400418">1</xref></sup> Timely screening and removal of precancerous adenomatous polyps can prevent many CRC cases.<sup><xref ref-type="bibr" rid="bibr2-0272989X11400418">2</xref></sup> The US Preventive Services Task Force recommends that all average-risk people (asymptomatic, age ≥50 years, having no personal or family history of CRCor of adenomatous polyps, no history of inflammatory bowel disease, and no family history of a genetic syndrome of colorectal neoplasia) undergo scheduled screenings for CRC with an approved test.<sup><xref ref-type="bibr" rid="bibr3-0272989X11400418">3</xref></sup> Despite widespread public health knowledge about the benefits of CRC screening, performance rates are low nationally. Only 40%–60% of eligible patients have been found to have received appropriate screening.<sup><xref ref-type="bibr" rid="bibr4-0272989X11400418">4</xref>,<xref ref-type="bibr" rid="bibr5-0272989X11400418">5</xref></sup></p>
<p>Accurate and timely identification of patients due for CRC screening constitutes the first critical step toward increasing screening rates. Traditional methods of identifying these individuals, including patient self-report, physician report, and use of billing data, are frequently inaccurate, unreliable, or incomplete.<sup><xref ref-type="bibr" rid="bibr6-0272989X11400418">6</xref>–<xref ref-type="bibr" rid="bibr10-0272989X11400418">10</xref></sup> Manual chart abstraction, often accepted to be the gold standard, is costly, time consuming, and limited by the thoroughness of individual abstractors. An automated approach based on available Electronic Health Record (EHR)data would potentially improve results while requiring no additional chart review or data entry. Increasingly, EHR records contain sufficient information to determine whether CRC testing is due, because EHR systems integrate laboratory results, procedure and radiology reports, and clinical narratives, such as primary care and gastroenterology clinic notes. Although EHR systems provide quick access to an individual patient’s documents, the volume of data recorded for thousands of patients can hinder rapid location of references to CRC testing. Furthermore, much relevant patient information exists as unstructured free text, which for computational purposes must be converted into structured content. The field of natural language processing (NLP) creates approaches and tools that can “recognize” concepts from free text narratives, including clinical documents.<sup><xref ref-type="bibr" rid="bibr11-0272989X11400418">11</xref>–<xref ref-type="bibr" rid="bibr16-0272989X11400418">16</xref></sup> For this study, a locally developed NLP system<sup><xref ref-type="bibr" rid="bibr17-0272989X11400418">17</xref>–<xref ref-type="bibr" rid="bibr20-0272989X11400418">20</xref></sup> (KnowledgeMap Concept Identifier, or KMCI) was applied to a large set of clinical documents from EHR records to quickly identify references to CRC tests. The NLP system was modified to detect 4 common forms of CRC testing: colonoscopy, flexible sigmoidoscopy (FSIG), double-contrast barium enema (DCBE), and fecal occult blood testing (FOBT). Our system also identified and recorded key contextual elements for each CRC test, such as the timing of the test and its status (e.g., completed v. planned). We hypothesized that the NLP-based approach would outperform the traditional methods of CRC test status determination, including billing code queries and manual chart review, in precision and recall. We also examined NLP-identified references to uncompleted CRC tests to explore reasons that patients had not completed testing.</p>
<sec id="section1-0272989X11400418" sec-type="methods">
<title>Methods</title>
<sec id="section2-0272989X11400418">
<title>Study Setting</title>
<p>The study was conducted at 4 Vanderbilt University Medical Center (VUMC) affiliated ambulatory health care clinics in Nashville, Tennessee. Collectively, professional staff at these sites includes more than 30 attending physicians, 75 resident physicians, and 10 nurse practitioners. For more than a decade, clinical practices within VUMC have used a common, internally developed EHR system that provides integrated access to inpatient and outpatient free-text clinical notes, reports of radiology and pathology studies, procedural (e.g., endoscopy) notes, and laboratory results. In addition, each EHR record includes a free-text, multidisciplinary patient summary in which providers enter brief descriptions of the patient’s medical history (problems), procedural history, preventive health maintenance events (e.g., CRC testing or vaccinations), medications, allergies, family medical history, and social history.</p>
</sec>
<sec id="section3-0272989X11400418">
<title>Patient Eligibility</title>
<p>Entry criteria included age 50 years and older with a minimum of 2 nonacute primary care outpatient visits to 1 of the 4 ambulatory health clinics during a 1-year period (October 1, 2006-September 30, 2007). From more than 15 000 patients meeting inclusion criteria, we randomly selected 500 patients’ complete EHR records, which captured all health care documentation occurring within any VUMC inpatient or outpatient setting. Of note, we made no requirement that these patients received subspecialist care at VUMC (e.g., gastroenterology). We divided the 500 EHR records into 2 cohorts, 1 for development (300 in the training cohort) and 1 for evaluation (200 in the test cohort). The Vanderbilt Institutional Review Board approved this study.</p>
</sec>
<sec id="section4-0272989X11400418">
<title>Manual EHR Abstraction</title>
<p>Manual EHR abstraction involved review of clinical EHR patient records by at least 1 of 2 board-certified internal medicine physicians trained on use of a standardized case abstraction form. Physician reviewers each examined 110 records randomly selected from the test cohort of 200 patient EHRs. Prior to the study start, both physicians completed training using 5 sample charts and the standardized case abstraction form. The study constrained physicians to review each patient’s record in the Vanderbilt clinical EHR interface (the same format available to clinicians during patient care). The manual physician review thus omitted review of billing records or access to any KMCI abstractions of EHR records. Reviewers recorded information regarding patient age, ethnicity, family history of CRC, and personal history of CRC. They recorded all references to completed CRC tests, associated dates, test results, and data source (e.g., clinic note, problem list). To calculate interrater reliability, physician reviewers abstracted 20 of the same patient records. The physician reviewers were not involved in development of the NLP algorithms described below.</p>
</sec>
<sec id="section5-0272989X11400418">
<title>Development of NLP System to Detect CRC Testing</title>
<p>The KMCI system, used in this study, is a general-purpose medical NLP system developed by several authors and colleagues at VUMC.<sup><xref ref-type="bibr" rid="bibr17-0272989X11400418">17</xref>–<xref ref-type="bibr" rid="bibr20-0272989X11400418">20</xref></sup> The KMCI system identifies Unified Medical Language System (UMLS) concepts from biomedical text documents and produces XML-tagged output containing lists of UMLS concepts found in each sentence with relevant context (e.g., is the concept negated?). The UMLS is composed of more than 100 individual vocabularies such as SNOMED-CT, the <italic>International Classification of Diseases</italic>, and Medical Subject Headings (MeSH). Common identifiers link about 8 million strings (synonyms) into more than 2 million “concepts.” For example, KMCI would encode the document phrase “no evidence of colon cancer” as “C0699790, Carcinoma of the colon, negated,” indicating that the concept was not present in the patient. The KMCI algorithm uses rigorous NLP techniques and document- and context-based disambiguation methods to accurately identify UMLS concepts. Although KMCI was originally developed for medical curriculum documents,<sup><xref ref-type="bibr" rid="bibr17-0272989X11400418">17</xref></sup> it has been used in research and production for a wide variety of clinical documents.<sup><xref ref-type="bibr" rid="bibr19-0272989X11400418">19</xref>–<xref ref-type="bibr" rid="bibr22-0272989X11400418">22</xref></sup> KMCI is similar to several other systems that also identify UMLS concepts, such as the National Library of Medicine’s MetaMap<sup><xref ref-type="bibr" rid="bibr23-0272989X11400418">23</xref></sup> or the Medical Language Extraction and Encoding system (MedLEE).<sup><xref ref-type="bibr" rid="bibr13-0272989X11400418">13</xref></sup></p>
<p>To improve KMCI’s ability to recognize CRC-related concepts, we added 23 synonyms (e.g., “flex sig,” “guaiac card”) related to CRC testing to the existing UMLS Metathesaurus. Synonyms were added by physician review of sample training records augmented by queries of all words found in the training corpus of documents. The algorithmic modifications of the NLP system for use in this study have been previously described in detail.<sup><xref ref-type="bibr" rid="bibr24-0272989X11400418">24</xref></sup> Briefly, we developed an algorithm that identifies and interprets time and date descriptors and then associates them with identified CRC tests (e.g., “colonoscopy in 2005” or “flexible sigmoidoscopy 5 years ago”). Relative date references such as the latter (“5 years ago”) were calculated by subtracting the relative time period from the date of note as a reference point by the NLP system. We also created a status indicator algorithm that could identify negated phrases (i.e., “no” or “never”) as well as common verbs and other modifiers that change the status of CRC related testing (e.g., refused, declined, scheduled). A prior evaluation of these algorithms applied to colonoscopies found that the date detection algorithm had a recall of 0.91 and a precision of 0.95, and the status algorithm had a recall of 0.82 and a precision of 0.95.<sup><xref ref-type="bibr" rid="bibr24-0272989X11400418">24</xref></sup> The NLP methods for time/date interpretation and recognition of status modifiers were applied unchanged from prior studies.<sup><xref ref-type="bibr" rid="bibr24-0272989X11400418">24</xref></sup></p>
<p>The output of the NLP system included CRC test concepts and their associated date and status information in each clinical note for each patient. To identify actually completed CRC tests, we selected all CRC test concepts with identified dates of either “today” or dates occuring in the past and ignored all CRC test concepts with status modifiers other than “completed.” Thus, discussions of CRC test scheduling, a patient’s need of CRC testing, or tests that were declined by the patient were not marked as “completed” CRC tests.</p>
<p>Many patient records contained multiple references to each unique CRC test. To aggregate these into a single set of unique CRC events for each patient, we developed algorithms that combined multiple date references for each procedure type (e.g., colonoscopy, FSIG, DCBE, FOBT). First, the algorithm collapsed exact date matches and overlapping date ranges for each procedure type to the most specific date retrieved by the system (e.g., “2005” and “2005-03-05” would be combined into 2 references to the same event). Second, the algorithm also combined any date reference (or range) overlapping another reference to the same procedure type if their dates occurred within 30 days of each other. This limit was chosen empirically through review of records in the training set. No EHR records from the test cohort were used in development of these algorithms.</p>
</sec>
<sec id="section6-0272989X11400418">
<title>Adjudicated Reference Standard</title>
<p>The study examined 4 CRC-related tests: colonoscopy, FSIG, DCBE, and serial FOBT. Multiple information resources contributed to our reference standard determination of the status of each test (completed or not completed; date of completion). The reference standard was created for each patient record in the test cohort by adjudicated review of all available primary data sources (results of previous physicians’ manual EHR record abstraction, institutional billing records, KMCI automated chart abstraction output, and access to the primary EHR records to resolve questions). Two physicians reviewed all discrepancies among manual abstraction, KMCI, and billing records to score each as either a true positive (i.e., a completed CRC test validated by presence of an EHR document) or a false positive (i.e., a reported CRC test for which no supporting EHR records could be found). In each case, the EHR was taken as the gold standard, limiting the level of accuracy to that which was recorded in the patient’s record. The study used this adjudicated reference standard determination to classify whether KMCI correctly identified each unique reference to CRC-related testing for the patient during the study interval of interest. If the date determined by the adjudicated reference standard included the date of an individual CRC-related test, the instance was considered correct. We also used the adjudicated reference standard to determine whether each patient was up to date for recommended CRC screening, according to current guidelines available at the time of the study<sup><xref ref-type="bibr" rid="bibr25-0272989X11400418">25</xref></sup>; a patient was considered up to date with a colonoscopy in the previous 10 years, an FSIG or DCBE in the previous 5 years, or 3 FOBTs in the previous year.</p>
</sec>
<sec id="section7-0272989X11400418">
<title>Statistical Analysis</title>
<p>We determined recall and precision to evaluate the performance of the following methods: manual EHR review, billing record review, and the NLP system. We calculated recall (or sensitivity) as the proportion of reference standard tests correctly identified by each method. McNemar’s chi-squared test enabled comparison of recall metrics among the different methods. We calculated precision (or positive predictive value) as the proportion of reference standard tests correctly identified by each method divided by the number of unique CRC-related test instances identified by each respective method. To compare precision among the methods, we applied a 2-sample test for equality of proportions. The <italic>F</italic>-measure was calculated as the harmonic mean between the recall and precision (2 × Recall × Precision / [Recall + Precision]). We calculated interrater reliability for the 2 physicians’ manual EHR reviews using Cohen’s kappa.</p>
</sec>
</sec>
<sec id="section8-0272989X11400418" sec-type="results">
<title>Results</title>
<sec id="section9-0272989X11400418">
<title>Patient Characteristics</title>
<p>The study population for the 200 EHR test cohort was 62% female with a median age of 64 years (<xref ref-type="table" rid="table1-0272989X11400418">Table 1</xref>). Patients attended the primary care clinics for a median of 5 years; 77% of patients had attending physician caregivers, and 23% had care provided primarily by resident physicians. Forty-five patients had documented risk factors for CRC<sup><xref ref-type="bibr" rid="bibr26-0272989X11400418">26</xref></sup>; of these, 4 patients had personal histories of previous CRC, 1 had inflammatory bowel disease, 22 had personal histories of adenomatous polyps, and 18 had documented family histories of colorectal cancer or polyps in first-degree relatives.</p>
<table-wrap id="table1-0272989X11400418" position="float">
<label>Table 1</label>
<caption>
<p>Characteristics of the Study Patients</p>
</caption>
<graphic alternate-form-of="table1-0272989X11400418" xlink:href="10.1177_0272989X11400418-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Patient Characteristics (N = 200)</th>
<th align="center">%<sup><xref ref-type="table-fn" rid="table-fn1-0272989X11400418">a</xref></sup>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Age, years, median (interquartile range)</td>
<td>64 (51–97)</td>
</tr>
<tr>
<td>Gender, female</td>
<td>62</td>
</tr>
<tr>
<td colspan="2">Race</td>
</tr>
<tr>
<td> White</td>
<td>78</td>
</tr>
<tr>
<td> Black</td>
<td>16</td>
</tr>
<tr>
<td> Asian</td>
<td>3</td>
</tr>
<tr>
<td colspan="2">Personal history of<sup><xref ref-type="table-fn" rid="table-fn2-0272989X11400418">b</xref></sup></td>
</tr>
<tr>
<td> Adenomatous polyps</td>
<td>11</td>
</tr>
<tr>
<td> Inflammatory bowel disease</td>
<td>0.5</td>
</tr>
<tr>
<td> Colorectal cancer</td>
<td>2</td>
</tr>
<tr>
<td> Colectomy</td>
<td>4</td>
</tr>
<tr>
<td colspan="2">Family history of<sup><xref ref-type="table-fn" rid="table-fn2-0272989X11400418">b</xref></sup></td>
</tr>
<tr>
<td> 1st degree relative with polyps</td>
<td>3</td>
</tr>
<tr>
<td> 1st degree relative with colorectal cancer</td>
<td>6</td>
</tr>
<tr>
<td> 2nd degree relative with colorectal cancer</td>
<td>3</td>
</tr>
<tr>
<td colspan="2">No. of colonoscopies performed per patient</td>
</tr>
<tr>
<td> 0</td>
<td>40</td>
</tr>
<tr>
<td> 1</td>
<td>39</td>
</tr>
<tr>
<td> 2 or more</td>
<td>21</td>
</tr>
<tr>
<td colspan="2">No. of flexible sigmoidoscopies performed per patient</td>
</tr>
<tr>
<td> 0</td>
<td>94</td>
</tr>
<tr>
<td> 1</td>
<td>5</td>
</tr>
<tr>
<td> 2 or more</td>
<td>0</td>
</tr>
<tr>
<td colspan="2">No. of 3-home fecal occult blood testing completed per patient<sup><xref ref-type="table-fn" rid="table-fn3-0272989X11400418">c</xref></sup></td>
</tr>
<tr>
<td> 0</td>
<td>86.5</td>
</tr>
<tr>
<td> 1</td>
<td>8</td>
</tr>
<tr>
<td> 2 or more</td>
<td>5.5</td>
</tr>
<tr>
<td colspan="2">No. of double contrast barium enemas performed per patient</td>
</tr>
<tr>
<td> 0</td>
<td>92.5</td>
</tr>
<tr>
<td> 1</td>
<td>5.5</td>
</tr>
<tr>
<td> 2 or more</td>
<td>2</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0272989X11400418">
<label>a.</label>
<p>Age presented as median (interquartile range). All other values are percentages.</p>
</fn>
<fn id="table-fn2-0272989X11400418">
<label>b.</label>
<p>Percentages not mutually exclusive.</p>
</fn>
<fn id="table-fn3-0272989X11400418">
<label>c.</label>
<p>Required 3 separate at-home fecal occult blood tests.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section10-0272989X11400418">
<title>Detection of CRC Test Results</title>
<p>The interrater agreement regarding patient need for CRC testing in study patients was high, with a kappa value of 0.80. Within these 20 patient charts, the adjudicated reference standard identified 29 CRC-related completed tests. Agreement between the 2 reviewers was 79% regarding identification of any completed CRC tests (κ = 0.54). Upon review of the 6 disagreements by a third reviewer, all were judged false negatives by 1 of the primary reviewers. On average, it took physician reviewers 11 minutes to complete 1 manual chart review (range, 3–35 minutes).</p>
<p><xref ref-type="table" rid="table2-0272989X11400418">Table 2</xref> indicates the recall and precision for each of KMCI, manual chart review, and billing record review in identifying references to individually completed CRC-related tests and for all 4 CRC-related tests combined. For both individual and combined CRC tests, KMCI had higher recall (93%) than chart review (74%) and billing record review (44%). Precision was higher for chart review (98%) and for billing record review (99%) than for KMCI (94%) for detecting references to colonoscopy. KMCI’s precision (94%) was higher than billing record review (83%) but lower than chart review (98%) for detecting references to any CRC testing.</p>
<table-wrap id="table2-0272989X11400418" position="float">
<label>Table 2</label>
<caption>
<p>Comparison of Methods to Detect Colorectal Cancer (CRC) Tests Compared with Adjudicated Reference Standard in 200 Patients (All Values Are %)</p>
</caption>
<graphic alternate-form-of="table2-0272989X11400418" xlink:href="10.1177_0272989X11400418-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">All CRC Tests (<italic>n</italic> = 265)</th>
<th align="center">Colonoscopy (<italic>n</italic> = 190)</th>
<th align="center">FSIG (<italic>n</italic> = 10)</th>
<th align="center">DCBE (<italic>n</italic> = 9)</th>
<th align="center">FOBT (<italic>n</italic> = 46)</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">NLP system</td>
</tr>
<tr>
<td> Recall</td>
<td>.93<sup><xref ref-type="table-fn" rid="table-fn5-0272989X11400418">a</xref></sup></td>
<td>92</td>
<td>100</td>
<td>100</td>
<td>96</td>
</tr>
<tr>
<td> Precision</td>
<td>.94<sup><xref ref-type="table-fn" rid="table-fn6-0272989X11400418">b</xref>,<xref ref-type="table-fn" rid="table-fn7-0272989X11400418">c</xref></sup></td>
<td>94</td>
<td>91</td>
<td>100</td>
<td>92</td>
</tr>
<tr>
<td> <italic>F</italic>-measure</td>
<td>.94</td>
<td>93</td>
<td>95</td>
<td>100</td>
<td>94</td>
</tr>
<tr>
<td colspan="6">Chart review</td>
</tr>
<tr>
<td> Recall</td>
<td>.74</td>
<td>72</td>
<td>80</td>
<td>53</td>
<td>91</td>
</tr>
<tr>
<td> Precision</td>
<td>.98</td>
<td>98</td>
<td>89</td>
<td>100</td>
<td>98</td>
</tr>
<tr>
<td> <italic>F</italic>-measure</td>
<td>.84</td>
<td>83</td>
<td>84</td>
<td>69</td>
<td>94</td>
</tr>
<tr>
<td colspan="6">Billing records</td>
</tr>
<tr>
<td> Recall</td>
<td>.44</td>
<td>56</td>
<td>20</td>
<td>42</td>
<td>2</td>
</tr>
<tr>
<td> Precision</td>
<td>.83</td>
<td>99</td>
<td>67</td>
<td>100</td>
<td>4</td>
</tr>
<tr>
<td> <italic>F</italic>-measure</td>
<td>.58</td>
<td>71</td>
<td>31</td>
<td>59</td>
<td>3</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0272989X11400418">
<p>Note: CRC, colorectal cancer; DCBE, double contrast barium enema; FOBT, fecal occult blood testing; FSIG, flexible sigmoidoscopy; NLP, natural language processing.</p>
</fn>
<fn id="table-fn5-0272989X11400418">
<label>a.</label>
<p><italic>P</italic> &lt; 0.001 when comparing recall of NLP to both chart review and billing records.</p>
</fn>
<fn id="table-fn6-0272989X11400418">
<label>b.</label>
<p><italic>P</italic> = 0.1 when comparing precision of NLP to chart review.</p>
</fn>
<fn id="table-fn7-0272989X11400418">
<label>c.</label>
<p><italic>P</italic> = 0.001 when comparing precision of NLP to billing records.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>To highlight how each method performed to detect CRC test receipt for an individual patient, we compared the performance of each method using only the most recent CRC screening test for each patient. For this evaluation, each patient had a maximum of 1 CRC test, which minimized bias toward any method that detected multiple CRC tests better than other methods. Recall and precision for detecting the most recent CRC test of all CRC test types were 91% and 95% for NLP, 79% and 99% for manual review, and 50% and 85% for billing records. Performance to detect the most recent of each individual CRC test type was not significantly different from the test-level data presented in <xref ref-type="table" rid="table2-0272989X11400418">Table 2</xref>.</p>
</sec>
<sec id="section11-0272989X11400418">
<title>KMCI Performance by Note Type</title>
<p><xref ref-type="table" rid="table3-0272989X11400418">Table 3</xref> shows the recall and precision of KMCI for identifying references to CRC-related testing in different clinical note types available in the EHR. These note types include clinical narratives (inpatient and outpatient notes) as well as procedure reports (lower endoscopy reports, radiology reports, or laboratory reports). The precision of KMCI to correctly identify references to any CRC testing in semistructured reports was consistently above 95%; recall varied from 55% to 90% depending on the CRC test reference. In all cases, recall and <italic>F</italic>-measure improved by combining both note types. Poorer recall from semistructured reports resulted from an absence of the corresponding document type describing the given events (e.g., no operative report for a colonoscopy performed at another institution). Most precision errors resulted from physician errors in date estimation (e.g., “3 years ago” when the test was actually 4 years prior) or from failure of the NLP algorithm to identify a status word in the context of the sentence (e.g., “Her last colonic evaluation was 5 years ago when Dr. [Name] attempted to perform a colonoscopy”). When we applied KMCI to the combination of clinical narratives and semistructured reports, precision was highest for references to DCBE (100%), followed by references to colonoscopy (94%), FOBT (92%), and FSIG (91%). Recall was highest for references to DCBE and FSIG (both 100%) when KMCI was applied to the combination of clinical narratives and procedure reports.</p>
<table-wrap id="table3-0272989X11400418" position="float">
<label>Table 3</label>
<caption>
<p>Recall and Precision of Natural Language Processing Algorithms</p>
</caption>
<graphic alternate-form-of="table3-0272989X11400418" xlink:href="10.1177_0272989X11400418-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">NLP of Clinical Narratives only</th>
<th align="center">NLP of Semistructured Reports only</th>
<th align="center">NLP of All Notes</th>
<th align="center">Adjudicated Reference Standard</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="5"><bold>Unique colonoscopy tests</bold></td>
</tr>
<tr>
<td>Discovered, <italic>n</italic></td>
<td>157</td>
<td>105</td>
<td>185</td>
<td>190</td>
</tr>
<tr>
<td>Correctly identified, <italic>n</italic></td>
<td>146</td>
<td>105</td>
<td>174</td>
<td align="center">—</td>
</tr>
<tr>
<td> Recall, %</td>
<td>77</td>
<td>55</td>
<td>92</td>
<td align="center">—</td>
</tr>
<tr>
<td> Precision, %</td>
<td>93</td>
<td>100</td>
<td>94</td>
<td align="center">—</td>
</tr>
<tr>
<td> <italic>F</italic>-measure, %</td>
<td>84</td>
<td>71</td>
<td>93</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="5"><bold>Unique FSIG tests</bold></td>
</tr>
<tr>
<td>Discovered, <italic>n</italic></td>
<td>9</td>
<td>6</td>
<td>11</td>
<td>10</td>
</tr>
<tr>
<td>Correctly identified, <italic>n</italic></td>
<td>8</td>
<td>6</td>
<td>10</td>
<td align="center">—</td>
</tr>
<tr>
<td> Recall, %</td>
<td>80</td>
<td>60</td>
<td>100</td>
<td align="center">—</td>
</tr>
<tr>
<td> Precision, %</td>
<td>89</td>
<td>100</td>
<td>91</td>
<td align="center">—</td>
</tr>
<tr>
<td> <italic>F</italic>-measure, %</td>
<td>84</td>
<td>75</td>
<td>95</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="5"><bold>Unique DCBE tests</bold></td>
</tr>
<tr>
<td>Discovered, <italic>n</italic></td>
<td>6</td>
<td>17</td>
<td>19</td>
<td>19</td>
</tr>
<tr>
<td>Correctly identified, <italic>n</italic></td>
<td>6</td>
<td>17</td>
<td>19</td>
<td align="center">—</td>
</tr>
<tr>
<td> Recall, %</td>
<td>32</td>
<td>89</td>
<td>100</td>
<td align="center">—</td>
</tr>
<tr>
<td> Precision, %</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td align="center">—</td>
</tr>
<tr>
<td> <italic>F</italic>-measure, %</td>
<td>48</td>
<td>94</td>
<td>100</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="5"><bold>Unique FOBT tests</bold></td>
</tr>
<tr>
<td>Discovered, <italic>n</italic></td>
<td>11</td>
<td>42</td>
<td>48</td>
<td>46</td>
</tr>
<tr>
<td>Correctly identified, <italic>n</italic></td>
<td>9</td>
<td>40</td>
<td>44</td>
<td align="center">—</td>
</tr>
<tr>
<td> Recall, %</td>
<td>20</td>
<td>87</td>
<td>96</td>
<td align="center">—</td>
</tr>
<tr>
<td> Precision, %</td>
<td>82</td>
<td>95</td>
<td>92</td>
<td align="center">—</td>
</tr>
<tr>
<td> <italic>F</italic>-measure, %</td>
<td>32</td>
<td>91</td>
<td>94</td>
<td align="center">—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn8-0272989X11400418">
<p>Note: CRC, colorectal cancer; DCBE, double contrast barium enema; FOBT, fecal occult blood testing; FSIG, flexible sigmoidoscopy; NLP, natural language processing.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section12-0272989X11400418">
<title>Status for Patients in Need of Colonoscopy andMetrics</title>
<p>Among the 200 test cohort patients, 83 patients (42%) were not up to date for recommended CRC screening (assuming average risk) as determined by the adjudicated reference standard (<xref ref-type="fig" rid="fig1-0272989X11400418">Figure 1</xref>). Using the NLP methods, 90 patients would be recommended for screening, including 11 patients who were actually up to date and did not need screening (<xref ref-type="table" rid="table4-0272989X11400418">Table 4</xref>). Four patients would be missed for screening (falsely recorded as being up to date) by NLP alone. Using billing records alone, 122 patients would be recommended for CRC testing, 40 of whom did not need screening. One patient would be missed for screening. Using manual chart review, screening would be recommended for 100 patients, 18 of whom did not need screening, and missing 1 patient who needed screening. In summary, for detecting patients in need of screening, NLP had a recall of 95% and precision of 88%; billing records had a recall of 99% and precision of 67%; and manual chart review had a recall of 99% and precision of 82%.</p>
<fig id="fig1-0272989X11400418" position="float">
<label>Figure 1</label>
<caption>
<p>Detection of colorectal cancer testing (CRC) and discussions by natural language processing. DCBE, double-contrast barium enema; FSIG, flexible sigmoidoscopy; FOBT, fecal occult blood testing.</p>
</caption>
<graphic xlink:href="10.1177_0272989X11400418-fig1.tif"/>
</fig>
<table-wrap id="table4-0272989X11400418" position="float">
<label>Table 4</label>
<caption>
<p>Number of Patients Recommended for CRC Screening by Each Method</p>
</caption>
<graphic alternate-form-of="table4-0272989X11400418" xlink:href="10.1177_0272989X11400418-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">NLP</th>
<th align="center">Billing Records</th>
<th align="center">Chart Review</th>
</tr>
</thead>
<tbody>
<tr>
<td>No. of patients recommended for screening (all positives)</td>
<td>90</td>
<td>122</td>
<td>100</td>
</tr>
<tr>
<td>No. of patients correctly labeled “not up to date” (true positives)</td>
<td>79</td>
<td>82</td>
<td>82</td>
</tr>
<tr>
<td>No. of patients correctly labeled “up to date” (true negatives)</td>
<td>106</td>
<td>77</td>
<td>99</td>
</tr>
<tr>
<td>No. of patients incorrectly labeled “not up to date” (false positives)</td>
<td>11</td>
<td>40</td>
<td>18</td>
</tr>
<tr>
<td>No. of patients incorrectly labeled “up to date” (false negatives)</td>
<td>4</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>Recall</td>
<td align="left"> 95<sup><xref ref-type="table-fn" rid="table-fn9-0272989X11400418">a</xref></sup></td>
<td>99</td>
<td>99</td>
</tr>
<tr>
<td>Precision</td>
<td align="left"> 88<sup><xref ref-type="table-fn" rid="table-fn10-0272989X11400418">b</xref></sup></td>
<td>67</td>
<td>82</td>
</tr>
<tr>
<td><italic>F</italic>-measure</td>
<td>91</td>
<td>80</td>
<td>90</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn9-0272989X11400418">
<label>a.</label>
<p><italic>P</italic> = 0.17 when comparing recall of NLP to either chart review or billing records</p>
</fn>
<fn id="table-fn10-0272989X11400418">
<label>b.</label>
<p><italic>P</italic> &lt; 0.001 when comparing precision of NLP to billing records</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>For the patients not up to date, the majority (59 patients; 71%) contained no documentation regarding CRC-related testing (Figure). For the remaining 24 patients not up to date, EHR review indicated that CRC-related testing was “needed,” “recommended,” or “due” for 15. Six patients had refused CRC testing, whereas 3 patients had scheduled but not completed CRC testing.</p>
</sec>
</sec>
<sec id="section13-0272989X11400418" sec-type="discussion">
<title>Discussion</title>
<p>In the current study, NLP of electronic health records outperformed the use of billing records to identify patients who received previous CRC-related testing. Many patients’ CRC-related tests performed at other institutions did not have corresponding billing records at our institution. This is a common scenario when cross-institutionally linked electronic health records, such as Health Information Exchanges (HIEs), do not exist. The NLP system also detected more CRC tests than physician chart review with only a modest number of false positives. The NLP system categorized the context of decisions to initiate CRC testing, such as whether the test was recommended, scheduled, or declined. Such details are typically not available in admininstrative data yet are valuable to qualitymetrics that evaluate whether physicians are appropriately recommending CRC screening to their patents.</p>
<p>Although NLP detected prior CRC screening tests better than either physician chart review or billing records, the clinical utility of the NLP method is mildly diminished when identifying patients in need of screening. NLP methods have superior precision (fewer patients were incorrectly identified as due for screening) but slightly poorer recall (95% v. 99%, <italic>P</italic> = 0.17). In our cohort of 200 patients, a system based on NLP alone would have recommended screening for 11 people who did not need it and failed to recommend screening for 4 people who were due. In contrast, billing records would have recommended screening on 40 people who did not need it but would have missed only 1 person who was due. Future efforts should be made in improving NLP methods or combining them with billing records to improve recall while maintaining high precision.</p>
<p>Several previous studies have documented that NLP can identify a variety of important clinical events documented within EHR systems. These include, among others, adverse events in discharge summaries<sup><xref ref-type="bibr" rid="bibr27-0272989X11400418">27</xref></sup> and clinical conditions from radiology reports.<sup><xref ref-type="bibr" rid="bibr28-0272989X11400418">28</xref>–<xref ref-type="bibr" rid="bibr30-0272989X11400418">30</xref></sup> Our study demonstrates the potential of NLP in CRC testing. For a busy primary care provider, tracking CRC test status while also trying to address patients’ current medical problems can be challenging. Implementing a comprehensive EHR is no panacea, as demonstrated by the large gap between observed and ideal rates of CRC testing. Organized and highly accessible data are required to make informed CRC testing decisions. NLP technology can rapidly and efficiently extract information about previous CRC testing from each patient’s electronic record, sometimes with better recall than trained physician abstractors. Indeed, physician abstractors performed especially poorly in finding DCBE testing, likely because of the heterogenous ways in which these were recorded in the chart (e.g., nonstandardized note titles and results reported via physician referral letters instead of radiology reports, etc.). The studied NLP system has many potential applications when linked to other types of electronic systems that address CRC testing. NLP could enhance procedure completion tracking systems, quality metric monitoring systems, and reminder systems that feed back to patients, providers, or institutions. For example, a clinical reminder system using NLP could provide real-time recommendations for CRC screening to providers as they access the patient’s electronic chart.</p>
<p>Our NLP system is one of the first to combine concept detection, temporal extraction and application, and status identification in the context of CRC testing. Required NLP features included detection of events, their timing, and their status across many clinical note types. Of note, KMCI achieved high precision despite the “multiple reference problem.” For example, in any given chart, there may exist 10 references to the same event, making it easy for 1 or more references to be misinterpreted. Many NLP system evaluation approaches would report this as 90% precision (assuming 1 of 10 references interpreted incorrectly); the current study would report this as 50% precision because the 9 similar references collapsed into 1 event occurrence. Despite this stringent constraint, KMCI system precision was high enough to allay concerns that false-positive events might prevent future systems from categorizing patients incorrectly as having received CRC-related testing when they actually had not.</p>
<p>Our study has limitations. It was performed at a single institution with a comprehensive, locally developed EHR system, and results may not be generalizable to other institutions. There was moderate interrater reliability (κ = 0.54) between physician chart reviewers regarding completed CRC tests despite physicians receiving training regarding standardized data collection. This finding reflects the difficulty of identifying test results scattered among electronic documentation and highlights the importance of automated approaches. In terms of limitations of our NLP system, KMCI can only be applied if medical text exists in an electronic format; it will not work for any portions of the chart that are handwritten or scanned. In addition, KMCI was tested on only a small number of test charts. Our reference standard incorporated the manually verified correct output from KMCI; because we were testing the accuracy of KMCI, this could represent a form of incorporation bias. However, it would be unrealistic to expect an accurate manual review (the traditional gold standard) of every single line of text present in an EHR; thus, development of most NLP systems allow for incorporation of the system’s output into the reference standard. Finally, the ability of KMCI to detect CRC tests is limited by the information available in the EHR. If CRC testing is done at an outside site, it may not be documented in the EHR.</p>
<p>We must develop simple, fast, and cost-effective interventions to ameliorate currently low CRC screening rates in the United States. The literature describes a spectrum of potential interventions, such as educating providers,<sup><xref ref-type="bibr" rid="bibr31-0272989X11400418">31</xref>,<xref ref-type="bibr" rid="bibr32-0272989X11400418">32</xref></sup> assessing physicians’ health beliefs regarding screening,<sup><xref ref-type="bibr" rid="bibr33-0272989X11400418">33</xref></sup> incorporating new screening technologies,<sup><xref ref-type="bibr" rid="bibr34-0272989X11400418">34</xref></sup> and using direct patient communication via print, e-mail, and office encounters.<sup><xref ref-type="bibr" rid="bibr35-0272989X11400418">35</xref>–<xref ref-type="bibr" rid="bibr37-0272989X11400418">37</xref></sup> The current study documents that an additional viable method for improving screening rates is the incorporation of automated data analysis systems into daily care practice. By improving identification of past receipt of CRC-related testing via automated data systems, it becomes readily transparent which patients still require screening. Our study results suggest that a robust system to identify CRC-related testing in EHR systems should incorporate NLP methods. Our NLP system allows for precise and timely identification of references to CRC testing in the EHR compared with traditional identification methods.</p>
</sec>
</body>
<back>
<ack>
<p>We thank Dr. Jennifer K. Green at Vanderbilt University Medical Center for assisting in chart reviews.</p>
</ack>
<fn-group>
<fn fn-type="supported-by">
<p>This work was supported by grants R21 CA116573 from the National Cancer Institute and, in part, by R01 LM007995 from the National Library of Medicine and Vanderbilt CTSA grant 1 UL1 RR024975 from the National Center for Research Resources, National Institutes of Health.</p>
</fn>
<fn fn-type="conflict">
<p>None of the authors have dual commitments or conflicts of interest.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0272989X11400418">
<label>1.</label>
<citation citation-type="book">
<collab>American Cancer Society</collab>. <source>Cancer Facts and Figures 2009</source>. <publisher-loc>Atlanta, GA</publisher-loc>: <publisher-name>American Cancer Society</publisher-name>; <year>2009</year>.</citation>
</ref>
<ref id="bibr2-0272989X11400418">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Winawer</surname><given-names>SJ</given-names></name>
<name><surname>Zauber</surname><given-names>AG</given-names></name>
<name><surname>Ho</surname><given-names>MN</given-names></name>
<etal/>
</person-group>. <article-title>Prevention of colorectal cancer by colonoscopic polypectomy</article-title>. <collab>The National Polyp Study Workgroup</collab>. <source>N Engl J Med</source>. <year>1993</year>;<volume>329</volume>:<fpage>1977</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr3-0272989X11400418">
<label>3.</label>
<citation citation-type="journal">
<collab>U.S. Preventive Services Task Force</collab>. <article-title>Screening for colorectal cancer: recommendation and rationale</article-title>. <source>Ann Intern Med</source>. <year>2002</year>;<volume>137</volume>:<fpage>129</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr4-0272989X11400418">
<label>4.</label>
<citation citation-type="journal">
<collab>Use of colorectal cancer tests—United States, 2002, 2004, and 2006</collab>. <source>MMWR Morb Mortal Wkly Rep</source>. <year>2008</year>;<volume>57</volume>:<fpage>253</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr5-0272989X11400418">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Swan</surname><given-names>J</given-names></name>
<name><surname>Breen</surname><given-names>N</given-names></name>
<name><surname>Coates</surname><given-names>RJ</given-names></name>
<etal/>
</person-group>. <article-title>Progress in cancer screening practices in the United States: results from the 2000 National Health Interview Survey</article-title>. <source>Cancer</source>. <year>2003</year>;<volume>97</volume>:<fpage>1528</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr6-0272989X11400418">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Freeman</surname><given-names>JL</given-names></name>
<name><surname>Klabunde</surname><given-names>CN</given-names></name>
<name><surname>Schussler</surname><given-names>N</given-names></name>
<etal/>
</person-group>. <article-title>Measuring breast, colorectal, and prostate cancer screening with medicare claims data</article-title>. <source>Med Care</source>. <year>2002</year>;<volume>40</volume>(<issue>8 Suppl</issue>):<fpage>IV</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr7-0272989X11400418">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gordon</surname><given-names>NP</given-names></name>
<name><surname>Hiatt</surname><given-names>RA</given-names></name>
<name><surname>Lampert</surname><given-names>DI</given-names></name>
</person-group>. <article-title>Concordance of self-reported data and medical record audit for six cancer screening procedures</article-title>. <source>J Natl Cancer Inst</source>. <year>1993</year>;<volume>85</volume>:<fpage>566</fpage>–<lpage>70</lpage>.</citation>
</ref>
<ref id="bibr8-0272989X11400418">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Montano</surname><given-names>DE</given-names></name>
<name><surname>Phillips</surname><given-names>WR</given-names></name>
</person-group>. <article-title>Cancer screening by primary care physicians: a comparison of rates obtained from physician self-report, patient survey, and chart audit</article-title>. <source>Am J Public Health</source>. <year>1995</year>;<volume>85</volume>:<fpage>795</fpage>–<lpage>800</lpage>.</citation>
</ref>
<ref id="bibr9-0272989X11400418">
<label>9.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Payne</surname><given-names>TH</given-names></name>
<name><surname>Murphy</surname><given-names>GR</given-names></name>
<name><surname>Salazar</surname><given-names>AA</given-names></name>
</person-group>. <article-title>How well does ICD9 represent phrases used in the medical record problem list?</article-title> <source>Proc Annu Symp Comput Appl Med Care</source>. <year>1992</year>;<fpage>654</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr10-0272989X11400418">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zack</surname><given-names>DL</given-names></name>
<name><surname>DiBaise</surname><given-names>JK</given-names></name>
<name><surname>Quigley</surname><given-names>EM</given-names></name>
<etal/>
</person-group>. <article-title>Colorectal cancer screening compliance by medicine residents: perceived and actual</article-title>. <source>Am J Gastroenterol</source>. <year>2001</year>;<volume>96</volume>:<fpage>3004</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr11-0272989X11400418">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aronsky</surname><given-names>D</given-names></name>
<name><surname>Fiszman</surname><given-names>M</given-names></name>
<name><surname>Chapman</surname><given-names>WW</given-names></name>
<etal/>
</person-group>. <article-title>Combining decision support methodologies to diagnose pneumonia</article-title>. <source>Proc AMIA Symp</source>. <year>2001</year>;<fpage>12</fpage>–<lpage>6</lpage>.</citation>
</ref>
<ref id="bibr12-0272989X11400418">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chapman</surname><given-names>WW</given-names></name>
<name><surname>Fiszman</surname><given-names>M</given-names></name>
<name><surname>Dowling</surname><given-names>JN</given-names></name>
<etal/>
</person-group>. <article-title>Identifying respiratory findings in emergency department reports for biosurveillance using MetaMap</article-title>. <source>Stud Health Technol Inform</source>. <year>2004</year>;<volume>107</volume>(<issue>Pt 1</issue>):<fpage>487</fpage>–<lpage>91</lpage>.</citation>
</ref>
<ref id="bibr13-0272989X11400418">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Friedman</surname><given-names>C</given-names></name>
</person-group>. <article-title>Towards a comprehensive medical language processing system: methods and issues</article-title>. <source>Proc AMIA Annu Fall Symp</source>. <year>1997</year>;<fpage>595</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr14-0272989X11400418">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Friedman</surname><given-names>C</given-names></name>
<name><surname>Hripcsak</surname><given-names>G</given-names></name>
</person-group>. <article-title>Evaluating natural language processors in the clinical domain</article-title>. <source>Methods Inf Med</source>. <year>1998</year>;<volume>37</volume>:<fpage>334</fpage>–<lpage>44</lpage>.</citation>
</ref>
<ref id="bibr15-0272989X11400418">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Friedman</surname><given-names>C</given-names></name>
<name><surname>Hripcsak</surname><given-names>G</given-names></name>
<name><surname>Shablinsky</surname><given-names>I</given-names></name>
</person-group>. <article-title>An evaluation of natural language processing methodologies</article-title>. <source>Proc AMIA Symp</source>. <year>1998</year>;<fpage>855</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr16-0272989X11400418">
<label>16.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haug</surname><given-names>PJ</given-names></name>
<name><surname>Ranum</surname><given-names>DL</given-names></name>
<name><surname>Frederick</surname><given-names>PR</given-names></name>
</person-group>. <article-title>Computerized extraction of coded findings from free-text radiologic reports: work in progress</article-title>. <source>Radiology</source>. <year>1990</year>;<volume>174</volume>:<fpage>543</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr17-0272989X11400418">
<label>17.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Smithers</surname><given-names>JD</given-names></name>
<name><surname>Miller</surname><given-names>RA</given-names></name>
<etal/>
</person-group>. <article-title>“Understanding” medical school curriculum content using KnowledgeMap</article-title>. <source>J Am Med Inform Assoc</source>. <year>2003</year>;<volume>10</volume>:<fpage>351</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr18-0272989X11400418">
<label>18.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Peterson</surname><given-names>JF</given-names></name>
</person-group>. <article-title>Identifying QT prolongation from ECG impressions using natural language processing and negation detection</article-title>. <source>Stud Health Technol Inform</source>. <year>2007</year>;<volume>129</volume>(<issue>Pt 2</issue>):<fpage>1283</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr19-0272989X11400418">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Bastarache</surname><given-names>L</given-names></name>
<name><surname>Sastre</surname><given-names>EA</given-names></name>
<etal/>
</person-group>. <article-title>Tracking medical students’ clinical experiences using natural language processing</article-title>. <source>J Biomed Inform</source>. <year>2009</year>;<volume>42</volume>:<fpage>781</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr20-0272989X11400418">
<label>20.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Miller</surname><given-names>RA</given-names></name>
<name><surname>Waitman</surname><given-names>LR</given-names></name>
<etal/>
</person-group>. <article-title>Identifying QT prolongation from ECG impressions using a general-purpose Natural Language Processor</article-title>. <source>Int J Med Inform</source>. <year>2009</year>;<volume>78</volume>(<issue>Suppl 1</issue>):<fpage>S34</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr21-0272989X11400418">
<label>21.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Arndt</surname><given-names>FV</given-names></name>
<name><surname>Dupont</surname><given-names>WD</given-names></name>
<etal/>
</person-group>. <article-title>Increased hospital mortality in patients with bedside hippus</article-title>. <source>Am J Med</source>. <year>2008</year>;<volume>121</volume>:<fpage>239</fpage>–<lpage>45</lpage>.</citation>
</ref>
<ref id="bibr22-0272989X11400418">
<label>22.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ritchie</surname><given-names>MD</given-names></name>
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Crawford</surname><given-names>DC</given-names></name>
<etal/>
</person-group>. <article-title>Robust replication of genotype-phenotype associations across multiple diseases in an electronic medical record</article-title>. <source>Am J Hum Genet</source>. <year>2010</year>;<volume>86</volume>:<fpage>560</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr23-0272989X11400418">
<label>23.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aronson</surname><given-names>AR</given-names></name>
</person-group>. <article-title>Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program</article-title>. <source>Proc AMIA Symp</source>. <year>2001</year>;<fpage>17</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr24-0272989X11400418">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Denny</surname><given-names>JC</given-names></name>
<name><surname>Peterson</surname><given-names>JF</given-names></name>
<name><surname>Choma</surname><given-names>NN</given-names></name>
<etal/>
</person-group>. <article-title>Extracting timing and status descriptors for colonoscopy testing from electronic medical records</article-title>. <source>J Am Med Inform Assoc</source>. <year>2010</year>;<volume>17</volume>:<fpage>383</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr25-0272989X11400418">
<label>25.</label>
<citation citation-type="journal">
<article-title>Screening for colorectal cancer: recommendation and rationale</article-title>. <source>Ann Intern Med</source>. <year>2002</year>;<volume>137</volume>:<fpage>129</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr26-0272989X11400418">
<label>26.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Levin</surname><given-names>B</given-names></name>
<name><surname>Lieberman</surname><given-names>DA</given-names></name>
<name><surname>McFarland</surname><given-names>B</given-names></name>
<etal/>
</person-group>. <article-title>Screening and surveillance for the early detection of colorectal cancer and adenomatous polyps, 2008: a joint guideline from the American Cancer Society, the US Multi-Society Task Force on Colorectal Cancer, and the American College of Radiology</article-title>. <source>Gastroenterology</source>. <year>2008</year>;<volume>134</volume>:<fpage>1570</fpage>–<lpage>95</lpage>.</citation>
</ref>
<ref id="bibr27-0272989X11400418">
<label>27.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Melton</surname><given-names>GB</given-names></name>
<name><surname>Hripcsak</surname><given-names>G</given-names></name>
</person-group>. <article-title>Automated detection of adverse events using natural language processing of discharge summaries</article-title>. <source>J Am Med Inform Assoc</source>. <year>2005</year>;<volume>12</volume>:<fpage>448</fpage>–<lpage>457</lpage>.</citation>
</ref>
<ref id="bibr28-0272989X11400418">
<label>28.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fiszman</surname><given-names>M</given-names></name>
<name><surname>Chapman</surname><given-names>WW</given-names></name>
<name><surname>Aronsky</surname><given-names>D</given-names></name>
<etal/>
</person-group>. <article-title>Automatic detection of acute bacterial pneumonia from chest X-ray reports</article-title>. <source>J Am Med Inform Assoc</source>. <year>2000</year>;<volume>7</volume>:<fpage>593</fpage>–<lpage>604</lpage>.</citation>
</ref>
<ref id="bibr29-0272989X11400418">
<label>29.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hripcsak</surname><given-names>G</given-names></name>
<name><surname>Friedman</surname><given-names>C</given-names></name>
<name><surname>Alderson</surname><given-names>PO</given-names></name>
<etal/>
</person-group>. <article-title>Unlocking clinical data from narrative reports: a study of natural language processing</article-title>. <source>Ann Intern Med</source>. <year>1995</year>;<volume>122</volume>:<fpage>681</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr30-0272989X11400418">
<label>30.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mendonca</surname><given-names>EA</given-names></name>
<name><surname>Haas</surname><given-names>J</given-names></name>
<name><surname>Shagina</surname><given-names>L</given-names></name>
<etal/>
</person-group>. <article-title>Extracting information on pneumonia in infants using natural language processing of radiology reports</article-title>. <source>J Biomed Inform</source>. <year>2005</year>;<volume>38</volume>:<fpage>314</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr31-0272989X11400418">
<label>31.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walsh</surname><given-names>JM</given-names></name>
<name><surname>Salazar</surname><given-names>R</given-names></name>
<name><surname>Terdiman</surname><given-names>JP</given-names></name>
<etal/>
</person-group>. <article-title>Promoting use of colorectal cancer screening tests: can we change physician behavior?</article-title> <source>J Gen Intern Med</source>. <year>2005</year>;<volume>20</volume>:<fpage>1097</fpage>–<lpage>101</lpage>.</citation>
</ref>
<ref id="bibr32-0272989X11400418">
<label>32.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lane</surname><given-names>DS</given-names></name>
<name><surname>Messina</surname><given-names>CR</given-names></name>
<name><surname>Cavanagh</surname><given-names>MF</given-names></name>
<etal/>
</person-group>. <article-title>A provider intervention to improve colorectal cancer screening in county health centers</article-title>. <source>Med Care</source>. <year>2008</year>;<volume>46</volume>(<issue>9 Suppl 1</issue>):<fpage>S109</fpage>–<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr33-0272989X11400418">
<label>33.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shieh</surname><given-names>K</given-names></name>
<name><surname>Gao</surname><given-names>F</given-names></name>
<name><surname>Ristvedt</surname><given-names>S</given-names></name>
<etal/>
</person-group>. <article-title>The impact of physicians’ health beliefs on colorectal cancer screening practices</article-title>. <source>Dig Dis Sci</source>. <year>2005</year>;<volume>50</volume>:<fpage>809</fpage>–<lpage>14</lpage>.</citation>
</ref>
<ref id="bibr34-0272989X11400418">
<label>34.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zauber</surname><given-names>AG</given-names></name>
<name><surname>Levin</surname><given-names>TR</given-names></name>
<name><surname>Jaffe</surname><given-names>CC</given-names></name>
<etal/>
</person-group>. <article-title>Implications of new colorectal cancer screening technologies for primary care practice</article-title>. <source>Med Care</source>. <year>2008</year>;<volume>46</volume>(<issue>9 Suppl 1</issue>):<fpage>S138</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr35-0272989X11400418">
<label>35.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rawl</surname><given-names>SM</given-names></name>
<name><surname>Champion</surname><given-names>VL</given-names></name>
<name><surname>Scott</surname><given-names>LL</given-names></name>
<etal/>
</person-group>. <article-title>A randomized trial of two print interventions to increase colon cancer screening among first-degree relatives</article-title>. <source>Patient Educ Couns</source>. <year>2008</year>;<volume>71</volume>:<fpage>215</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr36-0272989X11400418">
<label>36.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carcaise-Edinboro</surname><given-names>P</given-names></name>
<name><surname>Bradley</surname><given-names>CJ</given-names></name>
</person-group>. <article-title>Influence of patient-provider communication on colorectal cancer screening</article-title>. <source>Med Care</source>. <year>2008</year>;<volume>46</volume>:<fpage>738</fpage>–<lpage>45</lpage>.</citation>
</ref>
<ref id="bibr37-0272989X11400418">
<label>37.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chan</surname><given-names>EC</given-names></name>
<name><surname>Vernon</surname><given-names>SW</given-names></name>
</person-group>. <article-title>Implementing an intervention to promote colon cancer screening through e-mail over the Internet: lessons learned from a pilot study</article-title>. <source>Med Care</source>. <year>2008</year>;<volume>46</volume>(<issue>9 Suppl 1</issue>):<fpage>S117</fpage>–<lpage>22</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>