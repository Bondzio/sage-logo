<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JIS</journal-id>
<journal-id journal-id-type="hwp">spjis</journal-id>
<journal-title>Journal of Information Science</journal-title>
<issn pub-type="ppub">0165-5515</issn>
<issn pub-type="epub">1741-6485</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0165551512464140</article-id>
<article-id pub-id-type="publisher-id">10.1177_0165551512464140</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>General learning approach for event extraction: Case of management change event</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Elloumi</surname><given-names>Samir</given-names></name>
<aff id="aff1-0165551512464140">Department of Computer Science and Engineering, Qatar University, Qatar</aff>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Jaoua</surname><given-names>Ali</given-names></name>
<aff id="aff2-0165551512464140">Department of Computer Science and Engineering, Qatar University, Qatar</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Ferjani</surname><given-names>Fethi</given-names></name>
<aff id="aff3-0165551512464140">Department of Computer Science and Engineering, Qatar University, Qatar</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Semmar</surname><given-names>Nasredine</given-names></name>
<aff id="aff4-0165551512464140">CEA, LIST, Vision and Content Engineering Laboratory, France</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Besançon</surname><given-names>Romaric</given-names></name>
<aff id="aff5-0165551512464140">CEA, LIST, Vision and Content Engineering Laboratory, France</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Al-Jaam</surname><given-names>Jihad</given-names></name>
<aff id="aff6-0165551512464140">Department of Computer Science and Engineering, Qatar University, Qatar</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Hammami</surname><given-names>Helmi</given-names></name>
<aff id="aff7-0165551512464140">College of Business and Economics, Qatar University, Qatar</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0165551512464140">Ali Jaoua, Department of Computer Science and Engineering, College of Engineering Qatar University PO Box 2713, Doha, Qatar. Email: <email>jaoua@qu.edu.qa</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2013</year>
</pub-date>
<volume>39</volume>
<issue>2</issue>
<fpage>211</fpage>
<lpage>224</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Chartered Institute of Library and Information Professionals</copyright-holder>
</permissions>
<abstract>
<p>Starting from an ontology of a targeted financial domain corresponding to <italic>transaction, performance</italic> and <italic>management change</italic> news, relevant segments of text containing at least a domain keyword are extracted. The linguistic pattern of each segment is automatically generated to serve initially as a learning model. Each pattern is composed of named entities, keywords and articulation words. Some generic named entities like organizations, persons, locations, dates and grammatical annotations are generated by an automatic tool. During the learning step, each relevant segment is manually annotated with respect to the targeted entities (roles) structuring an event of the ontology. Information extraction is processed by associating a role with a specific entity. By alignment of generic entities to specific entities, some strings of a text are automatically annotated. An original learning approach is presented. Experiments with the <italic>management change</italic> event showed how recognition rates are improved by using different generalization tools.</p>
</abstract>
<kwd-group>
<kwd>automatic pattern generation</kwd>
<kwd>generic model</kwd>
<kwd>information extraction levels</kwd>
<kwd>management change event</kwd>
<kwd>named entities</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0165551512464140" sec-type="intro">
<title>1. Introduction</title>
<p>Information extraction (IE) is the identification of structured information from unstructured text. This task usually covers the automatic recognition of given entities, relations or targeted events in texts. Its purpose is to help the human reader deal with huge amount of text available in electronic format and find the specific information they are looking for efficiently. Even if IE is closely related to a given domain, the current approach to information extraction is general. Starting from a targeted events domain, like <italic>transaction, performance, management change</italic> (to cite a few), linguistic patterns associated with each one of them can be automatically generated with a well-selected sample of news stories. The extraction process can be ‘the same’ for different domains. However, each pattern is composed by domain’s specific information (i.e. specific named entities, keywords and articulation words). Some of this specific information should be provided by experts as a system input in order to produce adequate patterns for each domain. In the current research we propose a new approach for automatic annotation based on patterns extraction and we show some case application scenarios for a <italic>management change</italic> event domain followed by experimental result in terms of recognition rates.</p>
<p>This paper is organized as follows. In Section 2 we present the state-of-the-art for the IE domain and recall the different levels concerned with the IE task, namely the entity, relation and event levels. In Section 3 we present our new approach for IE, particularly concerned with the event level. The general architecture is presented as a generic framework that can be applied to different domain types. In fact, specific domain knowledge is embedded within the system in terms of keywords and cue words as input parameters. Our proposed algorithms for learning, as well as pattern alignment, are presented and illustrative examples given. Section 4 reports the results of the carried out experiments and shows the efficiency of our approach in terms of recognition rates, for both roles and event recognition. Section 5 concludes and indicates potential avenues for future work.</p>
</sec>
<sec id="section2-0165551512464140">
<title>2. State of the art in information extraction</title>
<p>In this section we present an overview of the IE domain and explain its different levels.</p>
<sec id="section3-0165551512464140">
<title>2.1. Overview</title>
<p>The IE field developed in the late 1980s and 1990s with the Message Understanding Conferences (MUC) [<xref ref-type="bibr" rid="bibr1-0165551512464140">1</xref>], in which a set of evaluation campaigns were suggested. These campaigns have defined the various tasks of IE systems and set up the protocols and metrics for the evaluations of these tasks. Other evaluation campaigns on IE have followed, including the Automatic Content Extraction (ACE) evaluation and, more recently, the Text Analysis Conference. For an overview of the domain of IE we refer the reader to the literature [<xref ref-type="bibr" rid="bibr2-0165551512464140">2</xref><xref ref-type="bibr" rid="bibr3-0165551512464140"/><xref ref-type="bibr" rid="bibr4-0165551512464140"/>–<xref ref-type="bibr" rid="bibr5-0165551512464140">5</xref>].</p>
</sec>
<sec id="section4-0165551512464140">
<title>2.2. Different levels of information extraction</title>
<p>According to the type of information extracted, different tasks are defined in the domain of IE. In this section we give a general overview of these tasks and elaborate further in subsequent sections.</p>
<list id="list1-0165551512464140" list-type="bullet">
<list-item><p>Named Entity Recognition (NER) – NER consists of identifying some specific entities with their types in texts. More advanced NER includes a co-reference task, which corresponds to the association of different occurrences of entities that actually refer to the same entity. It includes the matching of entity name variations and the matching of pronouns with corresponding entities (anaphora resolution). Co-reference resolution is also called Entity Tracking (for instance in the ACE campaigns).</p></list-item>
<list-item><p>Relation identification – this consists of the identification of relation existing between two entities. These relations can be of an attributive nature (for instance, the date-of-birth is a relation between a person and a date) or of an event-related nature (for instance, ‘acquisition’ is a relation between two companies). In MUC campaigns, attributive relations are part of the Template Element construction task whereas event relations are part of the Scenario Template production task.</p></list-item>
<list-item><p>Event identification – the identification of a given set of relations tied by a template structure (for instance, an acquisition event is a structure combining two companies, a date, an amount of money, etc.) [<xref ref-type="bibr" rid="bibr6-0165551512464140">6</xref>]. An event template can also be seen as an <italic>n</italic>-ary relation between several entities. In MUC campaigns, event detection is called Scenario Template production.</p></list-item>
</list>
<p><disp-quote>
<p><bold>Example 1</bold>. Once we consider the text in <xref ref-type="fig" rid="fig1-0165551512464140">Figure 1</xref> related to a management change event, the NER task (level 1) will identify the information depicted in <xref ref-type="table" rid="table1-0165551512464140">Table 1</xref>. The discovered relations (level 2) between entities are presented in <xref ref-type="table" rid="table2-0165551512464140">Table 2</xref> and finally, the extracted event (level 3) is presented in <xref ref-type="table" rid="table3-0165551512464140">Table 3</xref>.</p>
</disp-quote></p>
<fig id="fig1-0165551512464140" position="float">
<label>Figure 1.</label>
<caption>
<p>Text describing a management change event (<ext-link ext-link-type="uri" xlink:href="http://www.minelco.com/en/News/Bob-Boulton-has-been-appointed-President-of-Minelco/">http://www.minelco.com/en/News/Bob-Boulton-has-been-appointed-President-of-Minelco/</ext-link>; access date 30 April 2012).</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig1.tif"/>
</fig>
<table-wrap id="table1-0165551512464140" position="float">
<label>Table 1.</label>
<caption>
<p>Level 1 in information extraction (Named Entity)</p>
</caption>
<graphic alternate-form-of="table1-0165551512464140" xlink:href="10.1177_0165551512464140-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Entity</th>
<th align="left">Entity type</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bob Boulton</td>
<td>PERSON</td>
</tr>
<tr>
<td>1950</td>
<td>DATE</td>
</tr>
<tr>
<td>Minelco</td>
<td>ORG</td>
</tr>
<tr>
<td>1 December 2010</td>
<td>DATE</td>
</tr>
<tr>
<td>Markus Petäjäniemi</td>
<td>PERSON</td>
</tr>
<tr>
<td>LKAB</td>
<td>ORG</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="table2-0165551512464140" position="float">
<label>Table 2.</label>
<caption>
<p>Level 2 in information extraction (Relation between Entities)</p>
</caption>
<graphic alternate-form-of="table2-0165551512464140" xlink:href="10.1177_0165551512464140-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Entity 1</th>
<th align="left">Entity 2</th>
<th align="left">Relation type</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bob Boulton</td>
<td>1950</td>
<td>date-of-birth</td>
</tr>
<tr>
<td>Bob Boulton</td>
<td>Minelco</td>
<td>president-of</td>
</tr>
<tr>
<td>Markus Petäjäniemi</td>
<td>Minelco</td>
<td>former-president-of</td>
</tr>
<tr>
<td>Markus Petäjäniemi</td>
<td>LKAB</td>
<td>senior-vice-president-of</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="table3-0165551512464140" position="float">
<label>Table 3.</label>
<caption>
<p>Level 3 in information extraction (Management Change Event Detection)</p>
</caption>
<graphic alternate-form-of="table3-0165551512464140" xlink:href="10.1177_0165551512464140-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Entity</th>
<th align="left">Entity type</th>
<th align="left">Role</th>
</tr>
</thead>
<tbody>
<tr>
<td>Minelco</td>
<td>ORG</td>
<td>Organization</td>
</tr>
<tr>
<td>Bob Boulton</td>
<td>PERSON</td>
<td>ComingPerson</td>
</tr>
<tr>
<td>Markus Petäjäniemi</td>
<td>PERSON</td>
<td>LeavingPerson</td>
</tr>
<tr>
<td>President</td>
<td>POSITION</td>
<td>Position</td>
</tr>
<tr>
<td>December 1, 2010</td>
<td>DATE</td>
<td>ChangeDate</td>
</tr>
<tr>
<td>Senior Vice President</td>
<td>POSITION</td>
<td>LeavingPersonNewPosition</td>
</tr>
<tr>
<td>LKAB</td>
<td>ORG</td>
<td>LeavingPersonNewOrganization</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section5-0165551512464140">
<title>2.3. Named Entity Recognition</title>
<p>Named Entity Recognition has benefitted from the attention of many researchers and has produced the most successful results. The accuracy of entity recognition for standard entities reaches 95% [<xref ref-type="bibr" rid="bibr7-0165551512464140">7</xref>], very close to human annotation results. The methods used for NER can be classified according to different dimensions. One of these dimensions is the <italic>manual vs automatic</italic> opposition: some techniques use manually developed resources, whereas others use learning algorithms to automatically build a model from annotated training data. Another dimension is the nature of the model for the entity identification: some models are symbolic (the resources are explicit and understandable, such as rule-based systems), whereas others are numerical (statistical models).</p>
<p>The hand-coded systems use rules that represent the form or the context of a specific entity. For instance, for the recognition of a person’s name, we can encode the fact that person names can be found after a specific title by a rule like ‘Mr. + capitalized_word’. These rules are developed manually by experts who have the responsibility to organize and maintain the rule set in such a way that it is the most compact and efficient possible.</p>
<p>Even though they were developed in the early years of research in IE [<xref ref-type="bibr" rid="bibr8-0165551512464140">8</xref>], rule-based systems are still efficient for real-world systems dealing with controlled domains and entities. In particular, such rules are usually compiled into finite-state automatons that are very efficient.</p>
<p>On the other hand, learning-based methods use annotated data to learn models that will recognize the entities. Annotated data correspond to documents in which the entities, with their types, are indicated. The models learned can be symbolic or statistical. The symbolic models use a rule-learning algorithm to automatically build a set of rules for the recognition of named entities that will work similarly to the manual systems.</p>
<p>The statistical models are standard statistical machine learning algorithms that are based on various features to represent the context or the nature of the entities. For these models, the NER task is generally seen as a classification task that is token-based, not entity-based. The annotated data take the form of annotations associated with each token of the text (words and symbols), to indicate if the token is part of an entity or not. The annotation model is actually defined by three classes: B (for Begin), indicating that the token is the first token of an entity; I (for Inside), indicating that the token is part of the entity; and O (for Outside), indicating that the token is not part of an entity. This redefinition of the NER task into a classification task allows using all kinds of classification learning algorithms to perform the task, based on features extracted from the text.</p>
<p>Several learning algorithms have been tested for NER. Some of these algorithms are based on the classification of words like Decision trees [<xref ref-type="bibr" rid="bibr9-0165551512464140">9</xref>], Boosting [<xref ref-type="bibr" rid="bibr10-0165551512464140">10</xref>], Support Vector Models [<xref ref-type="bibr" rid="bibr11-0165551512464140">11</xref>, <xref ref-type="bibr" rid="bibr12-0165551512464140">12</xref>] or Maximum Entropy Models (MaxEnt) [<xref ref-type="bibr" rid="bibr13-0165551512464140">13</xref>, <xref ref-type="bibr" rid="bibr14-0165551512464140">14</xref>].</p>
<p>Since token sequence (words and punctuation) in the text is particularly meaningful, models based on sequence classification, such as Hidden Markov Models [<xref ref-type="bibr" rid="bibr15-0165551512464140">15</xref>], Maximum Entropy Markov Models [<xref ref-type="bibr" rid="bibr16-0165551512464140">16</xref>] and, more recently, Conditional Random Fields [<xref ref-type="bibr" rid="bibr17-0165551512464140">17</xref>, <xref ref-type="bibr" rid="bibr18-0165551512464140">18</xref>], have also been intensively tested.</p>
<p>To give a more precise idea of what elements are used in the text to detect the entities, we present some of the different features generally used in these models:</p>
<list id="list2-0165551512464140" list-type="bullet">
<list-item><p>Word features – the words themselves can be used as a feature. They are useful both to compose internal name dictionaries from the training corpus and mostly to capture the property of certain words to trigger a named entity (e.g. <italic>M</italic>. generally precedes a person name).</p></list-item>
<list-item><p>Orthographic features – orthographic properties of the word can be used as features, such as its capitalization pattern (e.g. begins with a capital letter), the presence of special symbols and alphanumeric characters in the token (e.g. composed with numbers).</p></list-item>
<list-item><p>Morpho-syntactic features – if a linguistic analysis is available, morpho-syntactic information associated with the words can be useful features, such as the grammatical category of the word.</p></list-item>
<list-item><p>Dictionary lookup features – additional knowledge can be added in the learning systems when an existing database of entities is available by adding, as a feature, the matching of a word to a dictionary entry.</p></list-item>
</list>
<p>These methods give good results; however, they require massive annotated data. Some techniques have been tested to limit the amount of annotated data using bootstrapping. This method uses only a few examples to learn a system that will be used to annotate more data, from which a new system will be learned, and the process can be iterative. Bootstrapping usually leads to NER systems that achieve relatively good performance with less training data [<xref ref-type="bibr" rid="bibr19-0165551512464140">19</xref>, <xref ref-type="bibr" rid="bibr20-0165551512464140">20</xref>].</p>
<p>Another recent trend for named entity recognition is the use of external resources, such as Wikipedia, that provide encyclopaedic information about entities in a semi-structured framework, and can be used to automatically build structured databases or gazetteers [<xref ref-type="bibr" rid="bibr21-0165551512464140">21</xref>, <xref ref-type="bibr" rid="bibr22-0165551512464140">22</xref>]. Another interest for these kinds of resources is the multilingual aspect, since a resource like Wikipedia provides cross-lingual links [<xref ref-type="bibr" rid="bibr23-0165551512464140">23</xref>]. Such approaches are particularly suited for the disambiguation of named entities and the co-reference resolution (encyclopaedic knowledge often proposes alternative names for one entity).</p>
</sec>
<sec id="section6-0165551512464140">
<title>2.4. Relation identification</title>
<p>The objective of the relation identification task is to find the mention of a binary relation between two entities in a text. For instance, we could consider the relations <italic>is-acquired-by</italic> for two organizations or <italic>is-appointed-CEO-of</italic> for a person and an organization.</p>
<p>We can distinguish two cases for relation identification. The first one concerns the identification of a relation when the two entities are pre-identified in the text; the second one concerns the identification of all existing relations between all entities that can be found in an open corpus (this case can be referred to as unsupervised information extraction or open information extraction). For the current research, we are interested in the first case.</p>
<p>In this case, the task can be defined as follows: in a text where two entities E1 and E2 are identified, and for a set of possible relations between these two types of entities, the question is: are E1 and E2 in a relation of this set in this text? As for the named entity recognition task, techniques used to identify relations may be grouped in two sets: rule-based methods that use manually developed rules that take into account the structure of the context of the entities, and feature-based methods that use several features as criteria for the identification of the relation.</p>
<p>Here are some of the features used for relation extraction [<xref ref-type="bibr" rid="bibr24-0165551512464140">24</xref>]:</p>
<list id="list3-0165551512464140" list-type="bullet">
<list-item><p>Entity features – the value and type of the entities that are candidates for the relation have been shown to be important features.</p></list-item>
<list-item><p>Word features – the words between the entities and around the entities are also often used as features, either alone (in a bag-of-words representation) or in sequences (as n-grams of words). Other features can be associated with the words, such as morpho-syntactic categories.</p></list-item>
<list-item><p>Syntactic features – the association of the two entities in a sentence generally relies on the syntactic analysis of the sentence. Syntactic features are then useful to detect a relation between two entities, such as the syntactic path between the entities. If a dependency grammar model is used for the analysis, the syntactic path is formed by the set of syntactic dependency relations between the entities, along with the grammatical categories of the words along the path (if a tree grammar model is used, the feature will be the minimal sub-tree covering the two entities).</p></list-item>
</list>
<p>Another set of methods is kernel-based and uses a kernel function between two contexts that captures the similarity between the two contexts and then uses a Support Vector Machine to classify the considered example according to its similarity with the different contexts in the training corpus. The kernel function is generally based on the syntactic analysis of the text (for example on the dependency graph [<xref ref-type="bibr" rid="bibr25-0165551512464140">25</xref>]).</p>
</sec>
<sec id="section7-0165551512464140">
<title>2.5. Event detection</title>
<p>The event detection task is intended to extract from the text a characterization of an event, defined by a set of entities associated with a specific role in the event. For instance, in the event <italic>management change</italic>, these entities will be the organization (company), the name of the person joining the organization, their new position, date of the managerial change, etc. The event detection task may be considered as a generalization of the relation identification task, by considering the event as a set of binary relations between the event itself and the entities involved, or by a generic <italic>n</italic>-ary relation involving all the entities.</p>
<p>Therefore, the techniques for event extraction are similar to the one used for relation extraction. They generally rely on the first step of NER and possible syntactic analysis. Then, some techniques use rule-based approaches, where the patterns in the rules are associated with a sub-set of the event template. For instance, such a rule is presented in <xref ref-type="fig" rid="fig2-0165551512464140">Figure 2</xref>.</p>
<fig id="fig2-0165551512464140" position="float">
<label>Figure 2.</label>
<caption>
<p>A sample of using a rule-based approach for IE.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig2.tif"/>
</fig>
<p>Other approaches use learning-based models. These models can be directly targeted to fill the template or can use a two-step approach. In the direct models, each word or entity in the sentence is associated with its role in the event, and a classifier model is built from annotated data to reproduce this association in new texts. In the two-step approach, a first step of relation extraction is performed in order to build the binary relations between all entities in the text and then, in a second step, these relations are gathered in the more structured template describing the event. For instance, consider a system for the extraction of the binary relations <italic>has-position</italic>(PERSON,POSITION) and <italic>position-in</italic>(POSITION,ORG) and a second step to associate these relations in a single Management Change event.</p>
<p>In the sequel, we present the different steps related to development of a new direct model learning-based approach that extracts annotations rules (or patterns) after a learning phase. This new approach integrates the parameters’ entities, words and syntactic features as sets of keywords and articulation words (or cue-words) provided by an expert. Furthermore, a segmentation step is applied on the new document annotation phase. A relaxed alignment process is performed until meaningful annotations are obtained.</p>
</sec>
</sec>
<sec id="section8-0165551512464140">
<title>3. Our approach: towards a generic learning model</title>
<sec id="section9-0165551512464140">
<title>3.1. General architecture</title>
<p>As a direct model learning-based approach, we consider both learning and annotation phases as reported in <xref ref-type="fig" rid="fig6-0165551512464140">Figure 6</xref>. The main objective of the learning phase is to build a set of patterns describing the possible occurrences of the event. A pattern contains the required information, in a given sequence, describing an event, as for example:
<disp-quote>
<p><bold>Example 2</bold>. As described below in <xref ref-type="fig" rid="fig3-0165551512464140">Figure 3</xref>, pattern 1 describes the appointment event with indications on the new joining person name (CP_NAME), the date of joining/appointment (Date_Coming) and the new position (CP_New_Position). In pattern 2 (<xref ref-type="fig" rid="fig4-0165551512464140">Figure 4</xref>) we have a scenario of a management change relating to changing from the current Position (CP_Previous_Position) to the new one (CP_New_Position).</p>
</disp-quote></p>
<fig id="fig3-0165551512464140" position="float">
<label>Figure 3.</label>
<caption>
<p>Pattern 1.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig3.tif"/>
</fig>
<fig id="fig4-0165551512464140" position="float">
<label>Figure 4.</label>
<caption>
<p>Pattern 2.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig4.tif"/>
</fig>
<p>Each pattern can be considered as a rule that reflects a possible occurrence of an event. It can contain keywords, cue words, Named Entities and ROLES Tags.</p>
<p><disp-quote>
<p><bold>Example 3</bold>. Elements of pattern 1 are depicted in <xref ref-type="fig" rid="fig5-0165551512464140">Figure 5</xref>.</p>
</disp-quote></p>
<fig id="fig5-0165551512464140" position="float">
<label>Figure 5.</label>
<caption>
<p>Interpretation of elements in Pattern 1.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig5.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig6-0165551512464140">Figure 6</xref> outlines several steps for learning to occur. First, an expert defines the set of keywords as well as the cue words for the chosen domain. The definition of these words is based on his expertise and well-selected documents. The cue words represent the most important word features that can be found between the entities, or around them, and may inform the possible annotation. As for example, the cue word ‘&lt;With_effect_FROM&gt;’ specifically informs that the following entity is a Date.</p>
<fig id="fig6-0165551512464140" position="float">
<label>Figure 6.</label>
<caption>
<p>General architecture.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig6.tif"/>
</fig>
<p>Keywords play a crucial role in the identification of information in an Event. In fact, they represent the event’s bag-of-words or the event’s detector. Therefore, no information could be extracted if any of these words is detected in the text. For instance, in <italic>management change</italic> event, we should find words like ‘appoints’, ‘names’, ‘resign’, etc., in order to realize the extraction of existing ROLES, for example, ‘Coming_Person_Name’, ‘Leaving_Person_Name’, ‘Date_of_ Leaving’.</p>
<p>Some keywords can be verbs. If the tense of the verb is considered, then the extracted patterns can be more precise since morpho-syntactic features were considered. For example, we differentiate between patterns reporting ‘appoints’ and ‘has been appointed’. Even though these verbs are ‘equivalent’, they imply two different patterns. Hence, we obtain:
<disp-quote>
<p>As a first pattern: P1 = (ORG + appoints PERSON)</p>
<p>As a second pattern: P2 = ( PERSON + has been appointed + ORG).</p>
</disp-quote></p>
<p>The annotation process depends on the entity positions, which clearly depend on the tense of the verb. To improve the matching efficiency between a new segment (from a new text) and the learning set, a reduced format of the latter is generated. This reduction consists of eliminating all tags of the segment except the keywords and the cue words. Hence an initial matching between reduced formats is performed before the complete matching.</p>
</sec>
<sec id="section10-0165551512464140">
<title>3.2. Algorithms</title>
<p>Pattern learning can be considered as a general framework for IE. The whole process is not necessarily specific to a given domain. Once the experts perform their task with high accuracy (as mentioned in Algorithm ‘PatternLearning’), phase 2 integrates the set of keywords, cue words or articulation words and produces patterns related to the specified input. As a first step in phase 2, the procedure ‘Extract simple pattern’ makes a call to a POS tagger [<xref ref-type="bibr" rid="bibr7-0165551512464140">7</xref>] and gives out the different tokens in a text annotated by linguistic tags. During this learning step, each relevant segment (containing at least one keyword) is manually annotated with respect to the targeted entities structuring an event as provided in the input.</p>
<p>In step 2, the IE from a new text is processed by associating a string to a specific entity by making a call to the ‘Alignment’ procedure. In fact, by alignment of generic entities to specific entities, some strings of a text are automatically annotated. In some cases, initial complete matching can fail. In that case, a reduced format of the pattern is generated, by eliminating cue tags of the segment except the keywords. Hence a soft matching between reduced formats is performed for efficiency improvement.</p>
<sec id="section11-0165551512464140">
<title>3.2.1. Step 1: Pattern generation, using a sample of training set of documents</title>
<fig id="fig11-0165551512464140" position="float">
<graphic xlink:href="10.1177_0165551512464140-fig11.tif"/>
</fig>
<fig id="fig12-0165551512464140" position="float">
<graphic xlink:href="10.1177_0165551512464140-fig12.tif"/>
</fig>
<p>Selection of the initial sample is based on a cycle of crawling and keyword selection. From the current sample, relevant keywords were extracted. Starting from decided keywords, we continue crawling with general search engines and news providers. Then, automatic pattern generation based on keywords and articulation words was initiated. Descending to stop the crawling process should be done with caution. A decision element (hypothesis) is to compare new generated patterns with existing ones. If no new significant patterns are generated then the process is stopped.</p>
</sec>
<sec id="section12-0165551512464140">
<title>3.2.2. Step 2: Patterns generation and automatic annotation of a new document</title>
<fig id="fig13-0165551512464140" position="float">
<graphic xlink:href="10.1177_0165551512464140-fig13.tif"/>
</fig>
<fig id="fig14-0165551512464140" position="float">
<graphic xlink:href="10.1177_0165551512464140-fig14.tif"/>
</fig>
</sec>
</sec>
<sec id="section13-0165551512464140">
<title>3.3. Illustrations</title>
<p>In this sub-section we illustrate our new approach. We consider samples of parameters used in the different steps for the algorithms PatternLearning and AnnotateNewText.</p>
<sec id="section14-0165551512464140">
<title>3.3.1. Algorithm PatternLearning</title>
<p><disp-quote>
<p><bold>Phase 1</bold>: Keywords and cue words are manually extracted and encoded for optimization purposes. <xref ref-type="table" rid="table4-0165551512464140">Table 4</xref> presents samples of entities encoding as well as samples of encoded keywords and cue words.</p>
</disp-quote></p>
<table-wrap id="table4-0165551512464140" position="float">
<label>Table 4.</label>
<caption>
<p>Keywords, cue words and entities encoding</p>
</caption>
<graphic alternate-form-of="table4-0165551512464140" xlink:href="10.1177_0165551512464140-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Keywords</th>
<th align="left">Cue words</th>
<th align="left">Entities</th>
</tr>
</thead>
<tbody>
<tr>
<td>Appoints k1</td>
<td>Succeeds C1</td>
<td>PERSON E1</td>
</tr>
<tr>
<td>Names k1</td>
<td>Starting from C2</td>
<td>POSITION E2</td>
</tr>
<tr>
<td>has been Appointed k2</td>
<td>At C3</td>
<td>Date E3</td>
</tr>
<tr>
<td>has been Named k2</td>
<td>Effective C4</td>
<td>ORG E4</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Note that the same code can be related to different elements, specifically in the case of synonyms (i.e. the keywords ‘appoint’ and ‘names’ have the same code k1). This contributes towards avoiding pattern redundancy.</p>
<p><disp-quote>
<p><bold>Phase 2</bold>. For each text in the learning set, its corresponding pattern is generated with respect to the manual annotation. A pattern contains a sequence of keywords, cue words and entities, with their associated annotations.</p>
</disp-quote></p>
<p>For example, if we consider the text T1 in <xref ref-type="fig" rid="fig7-0165551512464140">Figure 7</xref> and its corresponding manual annotation, we can produce the pattern as depicted in <xref ref-type="fig" rid="fig8-0165551512464140">Figure 8</xref>.</p>
<fig id="fig7-0165551512464140" position="float">
<label>Figure 7.</label>
<caption>
<p>Sample of a learning text and its associated manual annotation.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig7.tif"/>
</fig>
<fig id="fig8-0165551512464140" position="float">
<label>Figure 8.</label>
<caption>
<p>Encoded pattern extracted from phase 2 of Pattern Learning algorithm.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig8.tif"/>
</fig>
</sec>
<sec id="section15-0165551512464140">
<title>3.3.2. Algorithm AnnotateNewText</title>
<p>In order to annotate the new text as depicted in <xref ref-type="fig" rid="fig9-0165551512464140">Figure 9</xref>, phase 1 of algorithm AnnotateNewText allows us to extract an encoded segment that contains the most important information cited in the text in terms of entities, keywords and cue words. The objective of the alignment process (phase 2) is to identify the possible roles of some entities as event description. For instance, the alignment between the pattern of <xref ref-type="fig" rid="fig8-0165551512464140">Figure 8</xref> and a new text is depicted in <xref ref-type="fig" rid="fig9-0165551512464140">Figure 9</xref>.</p>
<p><disp-quote>
<p><bold>Example 4</bold>. <xref ref-type="fig" rid="fig10-0165551512464140">Figure 10</xref> presents the final output of the event extraction for a new text announcing the appointment of a new deputy Group Chief Executive Officer in a major real estate company.</p>
</disp-quote></p>
<fig id="fig9-0165551512464140" position="float">
<label>Figure 9.</label>
<caption>
<p>Event extraction for a new text after alignment step.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig9.tif"/>
</fig>
<fig id="fig10-0165551512464140" position="float">
<label>Figure 10.</label>
<caption>
<p>Event Extraction for a new text.</p>
</caption>
<graphic xlink:href="10.1177_0165551512464140-fig10.tif"/>
</fig>
</sec>
</sec>
</sec>
<sec id="section16-0165551512464140">
<title>4. Evaluation</title>
<p>In the evaluation we consider the <italic>management change</italic> event, as requested by potential end-users. <xref ref-type="table" rid="table5-0165551512464140">Table 5</xref> presents detailed event role descriptions.</p>
<table-wrap id="table5-0165551512464140" position="float">
<label>Table 5.</label>
<caption>
<p>Management change event description</p>
</caption>
<graphic alternate-form-of="table5-0165551512464140" xlink:href="10.1177_0165551512464140-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Role</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>CP_NAME</td>
<td>Coming (joining) person name</td>
</tr>
<tr>
<td>ORG</td>
<td>Organization</td>
</tr>
<tr>
<td>Date_Coming</td>
<td>Date coming (for CP)</td>
</tr>
<tr>
<td>Date_Leaving</td>
<td>Date leaving (for LP)</td>
</tr>
<tr>
<td>LP_Name</td>
<td>Leaving person name</td>
</tr>
<tr>
<td>LP_Prev_Position</td>
<td>The previous position of the leaving person</td>
</tr>
<tr>
<td>CP_New_Position</td>
<td>The new position of the coming person</td>
</tr>
<tr>
<td>CP_Previous_Position</td>
<td>The previous position of the coming person</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="table6-0165551512464140" position="float">
<label>Table 6.</label>
<caption>
<p>Correct answers by role</p>
</caption>
<graphic alternate-form-of="table6-0165551512464140" xlink:href="10.1177_0165551512464140-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Role</th>
<th align="left">Correct recognition</th>
</tr>
</thead>
<tbody>
<tr>
<td>CP_NAME</td>
<td>66.66%</td>
</tr>
<tr>
<td>ORG</td>
<td>85.36%</td>
</tr>
<tr>
<td>Date_Coming</td>
<td>88.88%</td>
</tr>
<tr>
<td>Date_Leaving</td>
<td>60.00%</td>
</tr>
<tr>
<td>LP_Name</td>
<td>33.33%</td>
</tr>
<tr>
<td>LP_Prev_Position</td>
<td>50.00%</td>
</tr>
<tr>
<td>CP_New_Position</td>
<td>84.90%</td>
</tr>
<tr>
<td>CP_Previous_Position</td>
<td>82.35%</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Financial experts have participated in defining the different input parameters for the system. For the management change event, a set of 138 keywords and a set of 89 cue words were defined. News stories about <italic>management change</italic> events were collected by RSS-feeds during the period 15 August 2010 until 30 November 2011. As management change is usually a strategic decision for corporation, therefore these event occurrences are limited. For the current setting, 50 files for the learning phase are collected and 40 others for the testing phase. We automatically extracted 102 patterns corresponding to <italic>management change</italic>. Redundancy between patterns is included in the count.</p>
<p>The average recognition rate for the 40 new files is 76.90%, which is a very promising result. It is important to note that an accurate definition of input parameters is an extremely important factor for system efficiency. In fact, these parameters play roles in both precision and generalization aspects. Also, the algorithm for pattern alignment is another decisive factor. The alignment between patterns and a new text is not often guaranteed because of the diversity of writing styles that we may find in the news. For this reason, we have proposed soft matching between reduced formats with the objective of maximal utilization of the pattern expressiveness. In several cases, this reduced format successfully allows the assignment of the same role to similar entities cited on the same side, with respect to some keywords or cue words. However, in other cases it fails to make a distinction between opposite roles (i.e. CP_name, LP_name), yielding a weak recognition rate (33.33%). Obviously, this low rate concerns only the event level recognition. This system succeeds in correctly identifying persons, organizations and positions, since appropriate gazetteers have been already integrated.</p>
</sec>
<sec id="section17-0165551512464140" sec-type="conclusions">
<title>5. Conclusion and perspectives</title>
<p>Automated IE is a challenging and difficult task, requiring the resources of both expert skills and natural language processing tools. Moreover, for the purpose of this study IE is domain-dependent and context-sensitive. For instance, the information extracted for describing a management change event is completely different from that describing transaction or performance events.</p>
<p>Despite all these considerations, we defend, in this paper, the idea of building a general learning approach that may be applied for different types of events. In fact, we observed that, even if a natural language text appears unstructured, it may be seen as structured if we replace instances by their types. From one text to another, when dealing with the same event, there are some fixed parts as well as varying ones. The keywords and the cue words are the same, but the person’s names or the organizations may be different. Based on these observations, we have proposed a new generic approach for information extraction, including a manual preparation of inputs and automatic pattern generation built on a pre-prepared learning set. We applied our approach to a management change event and obtained around 80% recognition.</p>
<p>Further developments will focus on:</p>
<list id="list4-0165551512464140" list-type="bullet">
<list-item><p>The domain data preparation – including the application of sampling techniques in order to select an adequate learning set for a given domain. The better the quality of this learning set is, the better the extracted patterns are able to cover the domain. Consequently, covering a domain is very important in writing styles recognition.</p></list-item>
<list-item><p>The patterns representation and reasoning – in order to increase the efficiency of the system, formal representation (i.e. formal context and formal concept) of the pattern sets can be considered for two reasons: first, to avoid the redundancy between patterns; and second, to enhance the support mismatching between patterns in cases of semantically possible alignment.</p></list-item>
</list>
</sec>
</body>
<back>
<ack>
<p>This publication was made possible by a grant from the Qatar National Research Fund NPRP 08-583-1-101. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the QNRF. Also, the authors would like to thank Dr Christopher J. Leonard for proofreading the paper.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="bibr1-0165551512464140">
<label>[1]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Grishman</surname><given-names>R</given-names></name>
<name><surname>Sundheim</surname><given-names>B.</given-names></name>
</person-group> <article-title>Message understanding conference-6: a brief history</article-title>. In: <conf-name>Proceedings of the 16th conference on Computational linguistics</conf-name>, <conf-loc>Morristown, NJ</conf-loc>, <conf-date>1996</conf-date>; <volume>vol: 1</volume>, pp. <fpage>466</fpage>–<lpage>471</lpage>.</citation>
</ref>
<ref id="bibr2-0165551512464140">
<label>[2]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cunningham</surname><given-names>H.</given-names></name>
</person-group> <source>Encyclopedia of Language and Linguistics</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>, <year>2006</year>, chapter ‘Information Extraction, Automatic’.</citation>
</ref>
<ref id="bibr3-0165551512464140">
<label>[3]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Grishman</surname><given-names>R.</given-names></name>
</person-group> <source>The Oxford handbook of computational linguistics</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>, <year>2003</year>, ‘Information Extraction’ chapter.</citation>
</ref>
<ref id="bibr4-0165551512464140">
<label>[4]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sarawagi</surname><given-names>S</given-names></name>
</person-group>. <article-title>Information extraction. Found</article-title>. <source>Trends databases</source>, <year>2008</year>; <volume>1</volume>: <fpage>261</fpage>–<lpage>377</lpage>.</citation>
</ref>
<ref id="bibr5-0165551512464140">
<label>[5]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wimalasuriya</surname><given-names>DC</given-names></name>
<name><surname>Dou</surname><given-names>D.</given-names></name>
</person-group> <article-title>Ontology-based information extraction: An introduction and a survey of current approaches</article-title>. <source>Journal of Information Science</source> <year>2010</year>, <volume>36</volume>: <fpage>306</fpage>.</citation>
</ref>
<ref id="bibr6-0165551512464140">
<label>[6]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ludovic</surname><given-names>JL</given-names></name>
<name><surname>Besançon</surname><given-names>R</given-names></name>
<name><surname>Ferret</surname><given-names>O</given-names></name>
</person-group>. <article-title>Using temporal cues for segmenting texts into events</article-title>. In: <conf-name>Advances in natural language processing, 7th international conference on NLP, IceTAL</conf-name>, <conf-loc>Reykjavik</conf-loc>, <conf-date>August 2010</conf-date>. <source>Lecture Notes in Computer Science</source>, <volume>vol. 6233</volume>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, pp. <fpage>150</fpage>–<lpage>161</lpage>.</citation>
</ref>
<ref id="bibr7-0165551512464140">
<label>[7]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Besançon</surname><given-names>R</given-names></name>
<name><surname>De Chalendar</surname><given-names>G</given-names></name>
<name><surname>Ferret</surname><given-names>O</given-names></name>
<name><surname>Gara</surname><given-names>Fa</given-names></name>
<name><surname>Mesnard</surname><given-names>O</given-names></name>
<name><surname>Laïb</surname><given-names>M</given-names></name>
<name><surname>Semmar</surname><given-names>N</given-names></name>
</person-group>. <article-title>LIMA: A multilingual framework for linguistic analysis and linguistic resources development and evaluation</article-title>. In: <conf-name>Proceedings of the seventh conference on international language resources and evaluation (LREC’10)</conf-name>, <conf-loc>Valletta, Malta</conf-loc>, <conf-date>May 2010</conf-date>.</citation>
</ref>
<ref id="bibr8-0165551512464140">
<label>[8]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hobbs</surname><given-names>JR</given-names></name>
<name><surname>Douglas</surname><given-names>A</given-names></name>
<name><surname>Bear</surname><given-names>J</given-names></name>
<etal/>
</person-group>. <article-title>A system for extracting information from text</article-title>. In: <source>Proceedings of the workshop on human language technology, HLT ’93</source>, <publisher-loc>Morristown, NJ</publisher-loc>, <year>1993</year>, pp. <fpage>133</fpage>–<lpage>137</lpage>.</citation>
</ref>
<ref id="bibr9-0165551512464140">
<label>[9]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sekine</surname><given-names>S</given-names></name>
<name><surname>Grishman</surname><given-names>R</given-names></name>
<name><surname>Shinnou</surname><given-names>H</given-names></name>
</person-group>. <article-title>A decision tree method for finding and classifying names in Japanese texts</article-title>. In: <source>Proceedings of the sixth workshop on very large corpora</source>, <publisher-name>Montreal</publisher-name>, <year>1998</year>.</citation>
</ref>
<ref id="bibr10-0165551512464140">
<label>[10]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Carreras</surname><given-names>X</given-names></name>
<name><surname>Màrquez</surname><given-names>L</given-names></name>
<name><surname>Padró</surname><given-names>L</given-names></name>
</person-group>. <article-title>A simple named entity extractor using adaboost</article-title>. In: <conf-name>Proceedings of the seventh conference on natural language learning at HLT-NAACL</conf-name>, <conf-loc>Morristown, NJ</conf-loc>, <conf-date>2003</conf-date>, <volume>vol. 4</volume>, pp. <fpage>152</fpage>–<lpage>155</lpage>.</citation>
</ref>
<ref id="bibr11-0165551512464140">
<label>[11]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ekbal</surname><given-names>A</given-names></name>
<name><surname>Bandyopadhyay</surname><given-names>S.</given-names></name>
</person-group> <article-title>Named entity recognition using support vector machine: A language independent approach</article-title>. <source>International Journal of Computer Systems Science and Engineering</source> <year>2008</year>; <volume>4</volume>(<issue>2</issue>): <fpage>155</fpage>–<lpage>170</lpage>.</citation>
</ref>
<ref id="bibr12-0165551512464140">
<label>[12]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Isozaki</surname><given-names>H</given-names></name>
<name><surname>Kazawa</surname><given-names>H</given-names></name>
</person-group>. <article-title>Efficient support vector classifiers for named entity recognition</article-title>. In: <conf-name>Proceedings of the 19th international conference on computational linguistics</conf-name>, <conf-loc>Morristown, NJ</conf-loc>, <conf-date>2002</conf-date>; <volume>vol. 1</volume>, pp. <fpage>1</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr13-0165551512464140">
<label>[13]</label>
<citation citation-type="thesis">
<person-group person-group-type="author">
<name><surname>Borthwick</surname><given-names>AE.</given-names></name>
</person-group> <article-title>A maximum entropy approach to named entity recognition. AAI9945252</article-title>. PhD thesis, <publisher-loc>New York</publisher-loc>, <year>1999</year>.</citation>
</ref>
<ref id="bibr14-0165551512464140">
<label>[14]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Chieu</surname><given-names>HL</given-names></name>
<name><surname>Hwee</surname><given-names>TN</given-names></name>
</person-group>. <article-title>Named entity recognition with a maximum entropy approach</article-title>. In: <conf-name>Proceedings of the seventh conference on natural language learning at HLT-NAACL</conf-name>, <conf-loc>Morristown, NJ</conf-loc>, <conf-date>2003</conf-date>; <volume>vol. 4</volume>, pp. <fpage>160</fpage>–<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr15-0165551512464140">
<label>[15]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bikel</surname><given-names>DM</given-names></name>
<name><surname>Schwartz</surname><given-names>R</given-names></name>
<name><surname>Weischedel</surname><given-names>RM.</given-names></name>
</person-group> <article-title>An algorithm that learns what’s in a name</article-title>. <source>Machine Learning</source> <year>1999</year>; <volume>34</volume>,pp. <fpage>211</fpage>–<lpage>231</lpage>.</citation>
</ref>
<ref id="bibr16-0165551512464140">
<label>[16]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>McCallum</surname><given-names>A</given-names></name>
<name><surname>Freitag</surname><given-names>D</given-names></name>
<name><surname>Pereira</surname><given-names>F</given-names></name>
</person-group>. <article-title>Maximum entropy markov models for information extraction and segmentation</article-title>. In: <source>Proceedings of the International Conference on Machine Learning (ICML)</source>, <year>2000</year>, pp. <fpage>591</fpage>–<lpage>598</lpage>.</citation>
</ref>
<ref id="bibr17-0165551512464140">
<label>[17]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lafferty</surname><given-names>J</given-names></name>
<name><surname>MacCallum</surname><given-names>A</given-names></name>
<name><surname>Pereira</surname><given-names>F</given-names></name>
</person-group>. <article-title>Conditional random fields: Probabilistic models for segmenting and labelling sequence data</article-title>. In: <conf-name>Proceedings of the 18th international conference on machine learning</conf-name>. <conf-loc>London: Morgan Kaufmann</conf-loc>, <conf-date>2001</conf-date>, pp. <fpage>282</fpage>–<lpage>289</lpage>.</citation>
</ref>
<ref id="bibr18-0165551512464140">
<label>[18]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>McCallum</surname><given-names>A</given-names></name>
<name><surname>Li</surname><given-names>W</given-names></name>
</person-group>. <article-title>Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons</article-title>. In: <conf-name>Proceedings of the seventh conference on natural language learning at HLT-NAACL</conf-name>, <conf-loc>Morristown, NJ</conf-loc>, <conf-date>2003</conf-date>, pp. <fpage>188</fpage>–<lpage>191</lpage>.</citation>
</ref>
<ref id="bibr19-0165551512464140">
<label>[19]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Becker</surname><given-names>M</given-names></name>
<name><surname>Hachey</surname><given-names>B</given-names></name>
<name><surname>Alex</surname><given-names>B</given-names></name>
<name><surname>Grover</surname><given-names>C</given-names></name>
</person-group>. <article-title>Optimizing selective sampling for bootstrapping named entity recognition</article-title>. In: <source>Proceedings of the ICML workshop on learning with multiple views</source>, <year>2005</year>; pp. <fpage>5</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr20-0165551512464140">
<label>[20]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nadeau</surname><given-names>D</given-names></name>
<name><surname>Sekine</surname><given-names>S.</given-names></name>
</person-group> <article-title>A survey of named entity recognition and classification</article-title>. <source>Linguistic Investigations</source> <year>2007</year>; <volume>30</volume>(<issue>1</issue>): <fpage>3</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr21-0165551512464140">
<label>[21]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bunescu</surname><given-names>R</given-names></name>
<name><surname>Pasca</surname><given-names>M</given-names></name>
</person-group>. <article-title>Using encyclopedic knowledge for named entity disambiguation</article-title>. In: <conf-name>Proceedings of the 11th conference of the European Chapter of the Association for Computational Linguistics (EACL)</conf-name>, <conf-loc>Trento, Italy</conf-loc>, <conf-date>April 2006</conf-date>.</citation>
</ref>
<ref id="bibr22-0165551512464140">
<label>[22]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Kazama</surname><given-names>J</given-names></name>
<name><surname>Torisawa</surname><given-names>K</given-names></name>
</person-group>. <article-title>Exploiting Wikipedia as external knowledge for named entity recognition</article-title>. In: <conf-name>Joint conference on empirical methods in natural language processing and computational natural language learning</conf-name>, <conf-date>2007</conf-date>, pp. <fpage>698</fpage>–<lpage>707</lpage>.</citation>
</ref>
<ref id="bibr23-0165551512464140">
<label>[23]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Richman</surname><given-names>AE</given-names></name>
<name><surname>Schone</surname><given-names>P.</given-names></name>
</person-group> <article-title>Mining wiki resources for multilingual named entity recognition</article-title>, <year>2008</year>, <ext-link ext-link-type="uri" xlink:href="http://mt-archive.info/ACL-2008-Richman.pdf">http://mt-archive.info/ACL-2008-Richman.pdf</ext-link>
</citation>
</ref>
<ref id="bibr24-0165551512464140">
<label>[24]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jiang</surname><given-names>J</given-names></name>
<name><surname>Zhai</surname><given-names>C</given-names></name>
</person-group>. <article-title>A systematic exploration of the feature space for relation extraction</article-title>. In: <source>Proceedings of NAACL HLT</source>, <month>April</month> <year>2007</year>, pp. <fpage>113</fpage>–<lpage>120</lpage>.</citation>
</ref>
<ref id="bibr25-0165551512464140">
<label>[25]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bunescu</surname><given-names>RC</given-names></name>
<name><surname>Mooney</surname><given-names>RJ</given-names></name>
</person-group>. <article-title>A shortest path dependency kernel for relation extraction</article-title>. In: <conf-name>Proceedings of the conference on human language technology and empirical methods in natural language processing, HLT ‘05</conf-name>, <conf-loc>Morristown, NJ</conf-loc>, <conf-date>2005</conf-date>, pp. <fpage>724</fpage>–<lpage>731</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>