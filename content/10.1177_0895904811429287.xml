<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPX</journal-id>
<journal-id journal-id-type="hwp">spepx</journal-id>
<journal-title>Educational Policy</journal-title>
<issn pub-type="ppub">0895-9048</issn>
<issn pub-type="epub">1552-3896</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0895904811429287</article-id>
<article-id pub-id-type="publisher-id">10.1177_0895904811429287</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Prelude to the Common Core</article-title>
<subtitle>Internationally Benchmarking a State’s Math Standards</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Woolard</surname><given-names>J. Christopher</given-names></name>
<xref ref-type="aff" rid="aff1-0895904811429287">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0895904811429287"><label>1</label>Ohio Department of Education, Columbus, OH, USA</aff>
<author-notes>
<corresp id="corresp1-0895904811429287">J. Christopher Woolard, Ohio Department of Education, 25 S. Front St., Columbus, OH 43215, USA. Email: <email>christopher.woolard@ode.state.oh.us</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>27</volume>
<issue>4</issue>
<fpage>615</fpage>
<lpage>644</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>As states struggle with the notion of international competitiveness, the quality and rigor of academic content standards has come into question. While Ohio’s content standards are well regarded, the state initiated a process to revise the standards and eventually joined with the majority of states in adopting a voluntary set of national standards—the Common Core. This study uses the Surveys of Enacted Curriculum (SEC) methodology to examine Ohio’s current math content standards in comparison to TIMSS, PISA, high performing international counterparts, and the recently released Common Core. Specifically, it examines whether the state’s standards are “a mile wide and inch deep.” Second, this study analyzes whether high performing countries’ standards are more aligned to Trends in International Mathematics and Science Study (TIMSS) and Program for International Student Assessment (PISA) through the SEC lens of topic and cognitive expectations. Ohio’s standards generally are less focused than the international comparisons, not very aligned to TIMSS and PISA, and have lower cognitive expectations. The CCSS have greatly increased that focus by reducing the number of topics in the analyzed grade levels while increasing the levels of cognitive expectations. These results provide a baseline for comparison to the full implementation of the Common Core. Once fully implemented, policy makers will have a reference point for evaluation of policy goals.</p>
</abstract>
<kwd-group>
<kwd>international benchmarking</kwd>
<kwd>content standards</kwd>
<kwd>standards-based reform</kwd>
<kwd>common core</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0895904811429287" sec-type="intro">
<title>Introduction</title>
<p>A standards-based educational system relies on coordination and alignment between three elements: standards, assessments, and instruction. Each of these three pillars is vital to insure that students receive a rigorous and high quality education. Teachers have specific guidance for expectations. Students receive instruction based on those expectations. Assessments measure against those expectations. States by and large have been developing their own standards and assessment systems. While these reforms have taken root, students in high performing international education systems have frequently outperformed their American counterparts.</p>
<p>The 2010 <italic>EdWeek</italic> Quality Counts report graded Ohio as an “A” for standards, assessments and accountability, which was third highest nationally (<xref ref-type="bibr" rid="bibr27-0895904811429287">2010</xref>). Nonetheless, the state recently began development of revised standards. Concurrently, the Obama administration made education reform a key priority and focused extensive resources toward states—including the multibillion dollar Race to the Top competitive grant initiative. Rigorous, common, and internationally competitive expectations are a key component of Race to the Top and accordingly, the vast majority of states signed on to implement a voluntary set of national standards—the Common Core. Ohio was one of those states.</p>
<p>A report from the <xref ref-type="bibr" rid="bibr18-0895904811429287">National Governor’s Association (NGA), the Council of Chief State School Officers (CCSSO), and Achieve Inc. (2008)</xref> emphasized that governments are eager to compare themselves to high performers around the globe. Likewise, this study was designed to produce actionable research for policy makers by providing a baseline comparison of Ohio’s system of standards to high performing international counterparts, especially in relation to the Trends in International Mathematics and Science Study (TIMSS) and Program for International Student Assessment (PISA). This comparison attempts to provide explanations for performance on international assessments by focusing on “potential opportunities to learn.” This is accomplished by examining the alignment of standards to the international assessments and exploring the mile wide, inch deep phenomenon. State standards tend to include extensive amounts of topics making it difficult to cover any topic in great depth. This emphasis on quantity, not quality, often lacks focus and coherence from grade to grade (<xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt, Wang, &amp; McKnight, 2005</xref>). In addition, this study will examine relevant grade levels of the Common Core to determine whether the new standards reflect an improvement in focus and depth of expectations.</p>
<p>The two international assessments are high profile efforts to compare students across countries. American students, including Ohioans, are frequently outperformed by their international counterparts. For example, the TIMSS 2007 results show that fourth-grade students in the United States performed higher than average but below several Asian and European countries. The results were similar in eighth grade—above average, but trailing high performing peers (<xref ref-type="bibr" rid="bibr12-0895904811429287">Gonzales et al., 2008</xref>; <xref ref-type="bibr" rid="bibr17-0895904811429287">Mullis, Martin, &amp; Foy, 2008</xref>). The 2006 PISA mathematics results show that American students were outperformed by high achievers such as Finland, Korea, and Hong Kong (<xref ref-type="bibr" rid="bibr19-0895904811429287">Organisation for Economic Co-operation and Development [OECD], 2007</xref>). Similar themes were evident in the 2009 PISA, that is, American students were above average but not at the level of the highest performers (<xref ref-type="bibr" rid="bibr20-0895904811429287">OECD, 2010</xref>). These latter results were referred to by U.S. Education Secretary Arne Duncan as “an absolute wake-up call for America” (<xref ref-type="bibr" rid="bibr4-0895904811429287">Armario, 2010</xref>, para. 4).</p>
<p>Clearly, U.S. education policy makers are paying attention to results on these international assessments. Numerous authors have examined the average performance of U.S. students (see numerous recent examples such as <xref ref-type="bibr" rid="bibr5-0895904811429287">Baines, 2008</xref>; <xref ref-type="bibr" rid="bibr16-0895904811429287">Min-Hsiung, 2009</xref>; <xref ref-type="bibr" rid="bibr28-0895904811429287">Richland, Zur, &amp; Holyoak, 2007</xref>) in regard to performance, instruction, and curriculum in relation to higher performing countries. To help understand the implications at a state level, this study examines Ohio’s math standards in comparison to TIMSS, PISA, high performing international counterparts, and the Common Core. The Surveys of Enacted Curriculum (SEC) methodology is employed to provide data on depth, breath, and cognitive expectations. Specifically, this study examines two legs of the standards-based system, standards and assessments. Clearly, a standards-based system relies on alignment between all three legs. While the SEC methodology provides a mechanism for collecting data on instruction, it is beyond the scope of this study. This research uses standards as a proxy for instruction in framing an analysis of opportunity to learn. In other words, this study considers standards as a representation of the content that is delivered to students in Ohio and the comparison countries. <xref ref-type="bibr" rid="bibr29-0895904811429287">Schmidt, Bates, and Leroi (2009)</xref> emphasize that standards represent <italic>potential</italic> opportunities to learn. Future research should build on this theme by collecting data on the enacted curriculum to examine the degree of alignment between instruction and the standards.</p>
<p>The results find evidence to support the mile wide, inch deep phenomenon, and while the standards are considered to be high quality, there is room to improve. The current standards will remain in place for at least 2 school years until the Common Core and related assessments are phased in. Initial analysis of the Common Core in this study provides evidence that the process was successful in creating more focused and rigorous standards for the grades analyzed. This analysis can be expanded on with full implementation of the Common Core and future updates/revisions. The SEC methodology provides a mechanism for in-depth analysis of standards, assessment, and instruction across states and countries. This study models how the SEC methodology can be used for future policy research.</p>
</sec>
<sec id="section2-0895904811429287">
<title>International Benchmarking</title>
<p>In <xref ref-type="bibr" rid="bibr2-0895904811429287">2007</xref>, Achieve, Inc. conducted a sweeping review of the education system in Ohio and presented a series of recommendations in its report <italic>Creating a World-Class Education System in Ohio</italic>. The very first recommendation suggested that Ohio benchmark its standards against the highest performing countries in the world:
<disp-quote>
<p>Research indicates that the best systems in the world create a high challenge for their child that includes high standards and rigorous, equitable assessments. This will require Ohio to go beyond the strong progress in this area over the last 10 years by aligning K-12 standards with knowledge and skills needed for success in postsecondary education and the global economy and by benchmarking its standards against those of high-performing states and especially nations that compete with the United States. (p. 4)</p>
</disp-quote></p>
<p>This study takes up that challenge.</p>
<sec id="section3-0895904811429287">
<title>Comparing the United States to High-Performing Countries</title>
<p>Scholars and policy makers have an extensive interest in international benchmarking (<xref ref-type="bibr" rid="bibr21-0895904811429287">Phillips, 2009</xref>; <xref ref-type="bibr" rid="bibr22-0895904811429287">Phillips &amp; Dossey, 2008</xref>; <xref ref-type="bibr" rid="bibr30-0895904811429287">Schmidt, McKnight, &amp; Raizen, 1997</xref>) as states realize that they are not just in competition with each other but with advancing societies in the global economy. This is not a revelation, but recent economic conditions have made it more clear and urgent.</p>
<p>The NGA/CCSSO/Achieve report defines international benchmarking as not just setting performance targets but “to indentify and learn from top performers and rapid improvers—from nations and states that offer ideas for boosting their own performance” (<xref ref-type="bibr" rid="bibr18-0895904811429287">2008</xref>, p. 5). As states are trying to raise standards and improve instruction and performance, benchmarking efforts can help make that process more effective. A series of recommendations includes raising standards by adopting a then newly phrased common core of standards, and measuring “state-level education performance globally” (p. 6).</p>
<p>Scholars have made comparisons on performance, standards, and practice for much of the last decade. Student performance data from the TIMSS and PISA provide a window into these educational settings. One common theme of international benchmarking research is that the United States does not always perform at the highest levels and may be falling further behind. If policy makers do not address these issues, American students may be stuck in the middle of the pack. The phrase that best describes much of the recent research explaining poor U.S. results on international assessments is the “mile wide, inch deep” curriculum problem. That is, American schools tend to cover too many topics, at insufficient depth. For example, <xref ref-type="bibr" rid="bibr30-0895904811429287">Schmidt et al. (1997)</xref> found that countries with more focused curricula performed better on TIMSS than the United States, which not only covers too many topics but repeats many of them in successive years. Similar findings were echoed in subsequent studies (<xref ref-type="bibr" rid="bibr33-0895904811429287">Schmidt et al., 2001</xref>, <xref ref-type="bibr" rid="bibr32-0895904811429287">2005</xref>) that conclude state content standards are unfocused compared to high performing countries. Higher achieving countries focus more intensely on fewer topics as well as on reasoning skills and application (<xref ref-type="bibr" rid="bibr8-0895904811429287">Darling-Hammond &amp; McCloskey, 2008</xref>). <xref ref-type="bibr" rid="bibr24-0895904811429287">Porter, Politkoff, and Smithson (2009)</xref> note that, in general, standards tend to ignore big ideas in favor of “laundry lists of small topics” (p. 240), while noting that analysis of this trend in individual states is lacking.</p>
<p><xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al. (2005)</xref> examined the coherence of content standards and found that not only do states often teach more topics but they also allow topics to linger without a progression of depth. Higher performing countries demonstrate more curriculum coherence by introducing a topic, and then progressing the depth of instruction from simple to more complicated expectations. They describe different conceptions of coherent standards that includes alignment, and more specifically “[articulates] over time as a sequence of topics and performance consistent with the logical and, if appropriate, hierarchical nature of the disciplinary content” (p. 528). In other words, the laundry list not only includes more topics but often lacks a logical and sequential progression. They ask the question of how U.S. standards compare to the rest of the TIMSS world and posit that national standards may be the solution for addressing coherence and rigor. <xref ref-type="bibr" rid="bibr31-0895904811429287">Schmidt and Prawat (2006)</xref> reexamine that question later in more depth and argue that it may not be the centralization of standards that is important, but the credibility that comes with it.</p>
<p>The recent large scale emphasis on standards-based reform sets the context for these benchmarking activities. Education policy makers have gone from decades of input-based decisions, to an outcome-based system emphasizing student learning and achievement. This is a major paradigm shift that has changed the roles of states, districts, and education systems as a whole. For such a system to work, standards-based reform hypothesizes that states must create systems with a focus on alignment between what is taught, what is required, and what is tested. Research efforts have been made to understand the relationship between curriculum and performance. For example, <xref ref-type="bibr" rid="bibr13-0895904811429287">Hook, Bishop, and Hook (2007)</xref> found that a quality curriculum, as modeled after and aligned with high performers, could be transplanted in local schools as an effort to overcome achievement concerns.</p>
<p>Alignment is an important tenet of standards-based reform and rests on the principle that what students learn can be explained by what is taught (<xref ref-type="bibr" rid="bibr24-0895904811429287">Porter et al., 2009</xref>). Alignment is a key concept when analyzing student performance on tests. A Council of Chief State School Officers (CCSSO) report examining alignment contained six assumptions of alignment; number six is particularly critical for this analysis: “Valid and meaningful data-based decision-making depends on the degree of alignment between standards and assessments” (<xref ref-type="bibr" rid="bibr15-0895904811429287">La Marca, Redfield, Winter, Bailey, &amp; Despriet, 2000</xref>, p. iii). Alignment analysis is a critical step in interpreting student test performance. According to <xref ref-type="bibr" rid="bibr14-0895904811429287">La Marca (2001)</xref>,
<disp-quote>
<p>a post hoc review of alignment should be conducted. This step is important where standards-based custom assessments are used and absolutely essential when states choose to use assessment products not specifically designed to measure their state standards. (p. 4)</p>
</disp-quote></p>
<p>The related argument is that state standards should be compared to international assessments such as TIMSS and PISA. While complete alignment would not be expected, it could be reasonably argued that higher performing countries would likely have content standards that are more aligned to the international assessments. In other words, students should be expected to perform better on assessments when they have been taught the respective subject matter (<xref ref-type="bibr" rid="bibr11-0895904811429287">Gamoran, Porter, Smithson, &amp; White, 1997</xref>). For this analysis, the question is how aligned are standards to the international assessments that states and countries are evaluated on. This does not mean to imply that alignment is purposeful, but based on this assumption it is reasonable to expect better results with better alignment and worse results with lower alignment. Results on international assessments should at least be considered in the light of how aligned the system is to those assessments.</p>
<p>Porter’s model of alignment indicators offers numerous advantages in quantitatively analyzing alignment of standards, assessments, and instruction. His model permits analysis of any combination of these three pillars. According to <xref ref-type="bibr" rid="bibr23-0895904811429287">Porter (2002)</xref>,
<disp-quote>
<p>An index of alignment also can be used as a descriptive variable in assessing the coherence of a state’s or district’s curriculum policy system. At the heart of systemic reform is the concept of alignment. When a system is aligned, all the messages from the policy environment are consistent with each other, content standards drive the system, and assessments, materials, and professional development are all tightly aligned to the content standards. (p. 11)</p>
</disp-quote></p>
<p>In a standards-based system, assessments are expected to be aligned to the curriculum. In fact, NCLB requires that state assessments must be aligned with state academic content standards and uses a peer review process to evaluate such evidence (<xref ref-type="bibr" rid="bibr34-0895904811429287">U.S. Department of Education [DOE], 2007</xref>). The theoretical framework is that an aligned system of standards and assessments will provide valid measures of student achievement on said standards. The standards-based system relies on the notion of alignment and it is a basic principle that achievement is directly related to the alignment of standards to the assessments. States strive to, and are held accountable for, the alignment of their tests to their content standards. Thus, a valid research concern for international comparisons is just how aligned are a particular state’s (or country’s) standards to the international assessments on which they are being evaluated.</p>
</sec>
<sec id="section4-0895904811429287">
<title>Contributions to the Literature</title>
<p><xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al. (2005)</xref> emphasize that it is important to ask whether “US content standards [are] similar to those of the rest of the ‘TIMSS world’?” (p. 531). This study contributes to the research by specifically testing principles from the literature at a state level. It provides a detailed micro-level analysis to contribute to the macro-level literature. This state-level analysis provides insights to Schmidt et al.’s question from one specific state by conducting an in-depth analysis of its current standards and preliminary analysis of the Common Core. The state standards are still relevant as they will be in place at least 2 years until the Common Core is fully implemented. Once the state fully implements the Common Core, this analysis could be expanded to all grade levels and incorporate teacher data on the enacted curriculum. Finally, this study models how the SEC methodology can be used for international benchmarking work. The SEC’s unique multidimensional metrics and ability to standardize comparisons of standards, assessments, and instruction across states and countries hold great promise for robust international comparisons.</p>
<sec id="section5-0895904811429287">
<title>Research questions</title>
<p>Based on the foundational principles and questions in the literature, this study will conduct an international benchmarking analysis for a specific state. Accordingly, this research will address critical themes including the breadth and depth of content standards, and SEC alignment, which considers both topic and cognitive expectations. The two primary research questions are as follows:</p>
<list id="list1-0895904811429287" list-type="simple">
<list-item><p><italic>Research Question 1</italic>: Are Ohio’s standards “a mile wide and an inch deep,” especially as compared to high performing countries?</p></list-item>
<list-item><p><italic>Research Question 2</italic>: Are high performing countries’ standards more aligned to TIMSS and PISA than Ohio?</p></list-item>
</list>
</sec>
<sec id="section6-0895904811429287">
<title>The comparison countries</title>
<p>The comparison countries are based on performance on international assessments as well as guidance from the literature. For example, <xref ref-type="bibr" rid="bibr8-0895904811429287">Darling-Hammond and McClosky (2008)</xref> conclude we can learn lessons from the education systems in Finland, Sweden, United Kingdom, Hong Kong, and Australia. <xref ref-type="bibr" rid="bibr21-0895904811429287">Phillips’ (2009)</xref> statistical linking study ranked Ohio’s performance in fourth and eighth grade as a “C+” ahead of the national average but behind several countries including Hong Kong, Singapore, and Japan. One frequently cited classification system identifies “A+” countries based on TIMSS performance (<xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al., 2005</xref>; <xref ref-type="bibr" rid="bibr35-0895904811429287">Valverde &amp; Schmidt, 2000</xref>) including Singapore, Japan, and Hong Kong. Based on the literature, test performance, and data availability; England, Hong Kong, Japan, Singapore, and Finland are included as high-performing comparisons for this study.</p>
</sec>
</sec>
</sec>
<sec id="section7-0895904811429287" sec-type="methods">
<title>Method and Data</title>
<sec id="section8-0895904811429287">
<title>Surveys of Enacted Curriculum (SEC) Method</title>
<p>The Surveys of Enacted Curriculum (SEC) is a research-based tool that provides data on the alignment between the enacted curriculum (what is taught), the intended curriculum (what is required), and the assessed curriculum (what is tested). Several studies have used the SEC methodology and contain detailed descriptions of the data coding process (<xref ref-type="bibr" rid="bibr24-0895904811429287">Porter et al., 2009</xref>; Smithson &amp; Porter, 2001). The SEC methodology uses a neutral grid that considers two dimensions: topic and cognitive demand. This standardizing feature allows for the comparison of standards and assessments across districts, states, and countries. The SEC coding process examines individual items (indicators, benchmarks, assessment questions) on two dimensions: topic and cognitive demand (expectations for students).</p>
<p>The SEC mathematics matrix includes 16 coarse grain topics (number sense/properties/relationships, operations, measurement, consumer applications, basic algebra, advanced algebra, geometric concepts, advanced geometry, data displays, statistics, probability, analysis, trigonometry, special topics, functions, instructional technology) and 183 fine grain subtopics.</p>
<p>The second axis evaluates the level of cognitive expectation. The math matrix includes five levels: (a) memorize facts, definitions, formulas; (b) perform procedures; (c) demonstrate understanding; (d) conjecture, analyze, generalize, prove; and (e) solve nonroutine problems, make connections. Particular items may have more than one level of cognitive expectation.</p>
<p>Groups of content experts from state departments, research institutions, universities, and schools follow standard protocols to code documents on this neutral, standardizing grid. These experts work in teams to analyze each item of a specific document (a set of standards, an assessment, etc.). For the data in this study, groups contained at least four members, and employed a generalizabililty method to analyze documents. That is, their aggregate scores, not consensus scores, were used to determine the final data report for each document. Previous studies (<xref ref-type="bibr" rid="bibr23-0895904811429287">Porter, 2002</xref>; <xref ref-type="bibr" rid="bibr25-0895904811429287">Porter, Politkoff, Zeidner, &amp; Smithson, 2008</xref>) have confirmed high levels of reliability among the generalizablity coefficients using these standard procedures.</p>
<p>Numerous variables, measures, and data are generated from these analyses. For this study, a few key measures are used. First, the data for each document can be aggregated to determine the total number of subtopics covered. That is, of the 183 possible subtopics, the analysis can identify how many a particular set of standards or assessment covers. For example, a set of fourth-grade standards that covers 100 subtopics has different implications than a set that covers 20 and may allow teachers to get more in-depth with their instruction. This variable allows researchers to examine the breadth of standards and assessments and, for this study’s purposes, to test the mile wide hypothesis.</p>
<p>Second, the SEC methodology calculates an alignment index with values from 0 (<italic>not aligned</italic>) to 1.0 (<italic>perfectly aligned</italic>). This is accomplished by examining the proportion of each document’s subtopic by cognitive demand grid in comparison to another document’s subtopic by cognitive demand grid. The formula is as follows:</p>
<p><disp-formula id="disp-formula1-0895904811429287">
<mml:math display="block" id="math1-0895904811429287">
<mml:mrow>
<mml:mtext>Alignment</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mtext>Index</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0895904811429287" xlink:href="10.1177_0895904811429287-eq1.tif"/>
</disp-formula></p>
<p>In this equation, <italic>X</italic> = cell proportions in one comparison matrix such a specific set of standards, an assessment, or teacher data; and <italic>Y</italic> = cell proportions in a corresponding comparison target. So for example, <italic>X</italic> could represent fifth-grade math standards and <italic>Y</italic> could represent the fifth-grade state assessment. The alignment index compares the proportion of content in each respective cell between two comparison documents. Thus a set of standards that has the exact same cell-by-cell proportion of subtopic by cognitive demand, to a comparison document would have a 1.0 alignment index. However, with the sheer number of cells involved, perfect alignment is highly unlikely</p>
<p>The SEC math grid has 915 total data points (183 subtopics × 5 levels of cognitive demand). For content standards, it measures the proportion of items (indicators, benchmarks, etc.) coded at each level. For assessments, it measures the proportion of test questions (or points if weighted) at each level. Items can be coded at multiple subtopics and cognitive expectations. For example, a test question that asks students to calculate proportions and present the data in a table might be coded as two different subtopics: “ratio and proportion” and “summarize data in a table or graph.” In that case, the content would be assigned evenly across the two subtopics in the SEC grid. While much of the previous literature’s emphasis has been on the SEC alignment that considers both dimensions (<xref ref-type="bibr" rid="bibr23-0895904811429287">Porter, 2002</xref>), the methodology also produces alignment indices for both individual axes: a subtopic to subtopic alignment, and a cognitive demand to cognitive demand alignment. These marginal measures of alignment are generated by the same process as Porter’s alignment index, that is, a marginal-by-marginal comparison of proportions. Accordingly, this study will consider two kinds of alignment:</p>
<list id="list2-0895904811429287" list-type="order">
<list-item><p><italic>Topic Alignment</italic>—the alignment of topics between the comparison documents, with each item (e.g., individual indicators) coded separately.</p></list-item>
<list-item><p><italic>SEC Alignment</italic>—considers two dimensions, both topic and cognitive expectation.</p></list-item>
</list>
<p>Graphic content maps that display the relative emphasis of topics and subtopics on both axes are a unique feature of the SEC methodology. These maps are useful in visually displaying alignment and misalignment. The following analysis includes the course grain and fine grain SEC content maps to provide more extensive details and an additional visual lens through which this robust data can be examined.</p>
<sec id="section9-0895904811429287">
<title>Data</title>
<p>This study uses data from several sources that has been analyzed with the SEC methodology including the Ohio Academic Content Standards (grade-band benchmarks and grade-level indicators). Ohio’s academic content standards use both grade-level indicators and grade-band benchmarks. The state defines benchmarks as “the specific components of the knowledge or skill identified by [a standard]” and an indicator as “what students should know and be able to do. The indicators are the checkpoints that monitor progress towards the benchmarks” (<xref ref-type="bibr" rid="bibr1-0895904811429287">“Academic Content Standards,” 2010</xref>). In principle, the benchmarks are the general statements of knowledge and skills, while the indicators are the stepping stones to reaching the benchmarks. The test blueprints for state assessments use the benchmarks. The documents themselves were created separately. Thus there is some confusion among educators as some focus on indicators, some focus on benchmarks, and some focus on both. Accordingly, this research must include both in the analysis.</p>
<p>The second major source of data is SEC analysis of the 2007 TIMSS assessment (fourth and eighth grade) and 2006 PISA assessment for mathematics, which were SEC-coded in November 2008 by teams of state content experts with participation from the U.S. Department of Education (U.S. DOE), Institute of Educational Sciences (IES), and members of the CCSSO collaborative. A validity analysis of the TIMSS and PISA coding determined that the data represent a fair and valid description of the content assessed by those items (<xref ref-type="bibr" rid="bibr6-0895904811429287">Blank &amp; Smithson, 2009</xref>, p. 4). The third set of data represents SEC-analyzed academic content standards from high performing countries such as England, Hong Kong, Japan, Singapore, and Finland. Availability of full documents (standards and assessments) was a limiting factor. The fourth set of data represents SEC analysis of the Common Core State Standards (CCSS). These standards were coded shortly after public release in 2010. The coded documents represent the mathematics standards for grades four and eight, and an aggregated analysis of the high school standards. The Standards for Mathematical Practice are not included in these analyses.</p>
</sec>
</sec>
</sec>
<sec id="section10-0895904811429287">
<title>Analysis</title>
<p>The 2010 <italic>EdWeek</italic> Quality Counts report graded Ohio as an “A” for standards, assessments, and accountability, which was third highest nationally. Although it should be noted that not all reviews have given high marks to Ohio’s math standards. <xref ref-type="bibr" rid="bibr9-0895904811429287">Finn, Julian, and Petrelli (2006)</xref> graded them a “D” and found issue with holes in some areas, ordering and overemphasis in others. The following analyses examine these standards through the SEC lens based on the research questions discussed above.</p>
<sec id="section11-0895904811429287">
<title>Mile Wide, Inch Deep</title>
<p>These data can test the mile wide, inch deep hypothesis, that is, how many subtopics are in the standards at any particular grade level? Many policy makers and educators argue that too many topics make it difficult to thoroughly cover topics and spend time at higher cognitive levels. In addition, as <xref ref-type="bibr" rid="bibr15-0895904811429287">La Marca et al. (2000)</xref> noted, “Standards that contain excessive detail also impede the development of assessments, making an acceptable degree of alignment difficult to achieve” (p. 5).</p>
<p>This first section of analysis tests the mile wide, inch deep hypothesis using SEC-coded data of Ohio’s math standards compared to international counterparts. Thus it is hypothesized as follows:</p>
<list id="list3-0895904811429287" list-type="simple">
<list-item><p><italic>Hypothesis 1</italic>: Ohio’s standards cover more topics than the standards of high performing countries.</p></list-item>
</list>
<p>Since Ohio uses both grade-level indicators and grade-band benchmarks, and educators focus on one or both when making instructional decisions, it is valuable to consider both in this analysis. This builds on <xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al.’s (2005)</xref> use of the General Topic Trace Mapping (GTTM) model that examines the mean number of intended grade topics at each grade level. This analysis examines the quantity of the 183 possible subtopics addressed by each document.</p>
<p>Using the TIMSS and PISA respective test grading levels (fourth, eighth, and ninth grade), the results show that generally speaking, Ohio’s math indicators tend to cover substantially more subtopics at fourth and eighth grades than high performing counties using grade-level standards such as Japan, Singapore, Hong Kong, and Finland. The Common Core standards reflect a major improvement in focus by reducing the number of topics covered in fourth and eighth grade.</p>
<p><xref ref-type="table" rid="table1-0895904811429287">Table 1</xref> examines these data in detail and separates out the documents by grade level and grade band. Ohio’s grade-level indicators cover more subtopics at fourth grade (67) and eighth grade (81) than the comparisons. Many of these differences are substantial, such as fourth grade in Hong Kong and eighth grade in Japan, each of which only address 26 of the SEC subtopics. The Ohio benchmarks fare better in comparison, especially to England, which covers the most subtopics. However, again there are some substantial differences such as Japan, which covers 32 SEC subtopics at the high school level. Ohio’s standards structure that includes both grade-level indicators and grade-band benchmarks further confounds the issue.</p>
<table-wrap id="table1-0895904811429287" position="float">
<label>Table 1.</label>
<caption>
<p>Number of Subtopics by Grade-Level and Grade-Band.</p>
</caption>
<graphic alternate-form-of="table1-0895904811429287" xlink:href="10.1177_0895904811429287-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Grade-level standards</th>
<th align="center">Subtopics</th>
<th align="center">Grade-band standards</th>
<th align="center">Subtopics</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="4">Fourth grade</td>
</tr>
<tr>
<td> <italic>Ohio indicators</italic></td>
<td>67</td>
<td>England (3-4)</td>
<td>61</td>
</tr>
<tr>
<td> Japan</td>
<td>55</td>
<td><italic>Ohio benchmarks (3-4)</italic></td>
<td>57</td>
</tr>
<tr>
<td> Common core</td>
<td>45</td>
<td/>
<td/>
</tr>
<tr>
<td> Singapore</td>
<td>35</td>
<td/>
<td/>
</tr>
<tr>
<td> Hong Kong</td>
<td>26</td>
<td/>
<td/>
</tr>
<tr>
<td colspan="4">Eighth grade</td>
</tr>
<tr>
<td> <italic>Ohio Indicators</italic></td>
<td>81</td>
<td>England (6-8)</td>
<td>116</td>
</tr>
<tr>
<td> Finland</td>
<td>50</td>
<td>Hong Kong (7-9)</td>
<td>100</td>
</tr>
<tr>
<td> Common core</td>
<td>49</td>
<td><italic>Ohio benchmarks (8-10)</italic></td>
<td>91</td>
</tr>
<tr>
<td> Singapore</td>
<td>27</td>
<td/>
<td/>
</tr>
<tr>
<td> Japan</td>
<td>26</td>
<td/>
<td/>
</tr>
<tr>
<td colspan="4">Ninth grade (high school)</td>
</tr>
<tr>
<td> <italic>Ohio indicators</italic></td>
<td>70</td>
<td>England (9-10)</td>
<td>127</td>
</tr>
<tr>
<td/>
<td/>
<td>Common core (HS)</td>
<td>105</td>
</tr>
<tr>
<td/>
<td/>
<td>Hong Kong (7-9)</td>
<td>100</td>
</tr>
<tr>
<td/>
<td/>
<td><italic>Ohio benchmarks (8-10)</italic></td>
<td>91</td>
</tr>
<tr>
<td/>
<td/>
<td>Singapore (9-10)</td>
<td>73</td>
</tr>
<tr>
<td/>
<td/>
<td>Japan (9-12)</td>
<td>32</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>These results are consistent with the literature that argues that U.S. standards tend to cover too many topics compared to their counterparts. This trend is emphasized through the SEC lens. Ohio’s grade-level indicators cover substantially more SEC subtopics than the international comparisons. However, analysis of the Common Core shows that in fourth and eighth grade, the newly adopted standards have addressed this lack of focus by reducing the number of subtopics that are required. In fourth grade, the number drops by almost 33% from 67 to 45. In eighth grade, the number of subtopics drops by almost 40% from 81 in the current indicators to 49 in the CCSS. In ninth grade, the CCSS focus is less clear since the new standards cover all high school grades making it difficult to compare to the respective Ohio grade-level indicator or benchmark in this analysis.</p>
</sec>
<sec id="section12-0895904811429287">
<title>Alignment of Standards to International Tests</title>
<p>As previously discussed, a valid question for this type of analysis is an examination of how aligned standards are to the international assessments that states and countries are evaluated on. Results on international assessments should at least be considered in the light of how aligned the system is to those assessments. Thus the second hypothesis is as follows:</p>
<list id="list4-0895904811429287" list-type="simple">
<list-item><p><italic>Hypothesis 2</italic>: Higher performing countries’ standards are more aligned to TIMSS and PISA than Ohio.</p></list-item>
</list>
<p>Topic alignment is a frequent consideration when examining “alignment.” The SEC methodology strengthens the analysis as studies have shown strong, positive relationships between SEC alignment and achievement gains (<xref ref-type="bibr" rid="bibr11-0895904811429287">Gamoran et al., 1997</xref>; <xref ref-type="bibr" rid="bibr26-0895904811429287">Porter &amp; Smithson, 2001</xref>). The SEC alignment index ranges from 0 (<italic>no alignment</italic>) to 1.0 (<italic>complete alignment</italic>). There is no magic number or threshold that signifies “good” alignment, but rather it is a relative concept. A higher alignment index score indicates better alignment. <xref ref-type="bibr" rid="bibr6-0895904811429287">Blank and Smithson (2009)</xref> found that an analysis of all states with standards and corresponding assessment data had a mean overall SEC alignment of state assessment to standard/framework = .26, with the highest = .5 (<italic>n</italic> = 118). Analysis here will focus on relative alignment. That is, while there is no threshold for good alignment, when comparing across countries and documents, a higher alignment index indicates more overall alignment.</p>
<sec id="section13-0895904811429287">
<title>Fourth grade</title>
<p>In fourth grade, the countries with grade-level indicators tend to be more aligned to TIMSS than Ohio. As displayed in <xref ref-type="table" rid="table2-0895904811429287">Table 2</xref>, Singapore and Japan’s fourth-grade standards are more aligned to TIMSS than Ohio’s fourth-grade indicators in both topic (Singapore, .48; Japan, .45) and SEC alignment (Singapore, .39; Japan, .30). Ohio’s indicators and Hong Kong have fairly similar topic (.39 and .36, respectively) and SEC (both = .29) alignment. Some of these differences in the alignment index comparisons are small in scale. While Singapore has the highest SEC alignment index score, the others are not dramatically different. Nonetheless, the data show differences in relative alignment that are consistent with the initial hypothesis. Interestingly, Ohio’s 3 to 4 benchmarks rank in the upper half of the standards on the topic comparison (.41), but drop to the bottom on the SEC comparison (.25), which also factors in cognitive expectations. The CCSS alignment to TIMSS is similar to the Ohio indicators and does not represent a substantial change in either topic (+.01) or SEC (−.01) alignment.</p>
<table-wrap id="table2-0895904811429287" position="float">
<label>Table 2.</label>
<caption>
<p>Alignment of Fourth-Grade Standards to Fourth-Grade TIMSS.</p>
</caption>
<graphic alternate-form-of="table2-0895904811429287" xlink:href="10.1177_0895904811429287-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Topic alignment</th>
<th/>
<th align="center">SEC alignment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Singapore</td>
<td>.48</td>
<td>Singapore</td>
<td>.39</td>
</tr>
<tr>
<td>Japan</td>
<td>.45</td>
<td>Japan</td>
<td>.30</td>
</tr>
<tr>
<td><italic>Ohio Benchmarks (3-4)</italic></td>
<td>.41</td>
<td><italic>Ohio Indicators</italic></td>
<td>.29</td>
</tr>
<tr>
<td>Common core</td>
<td>.40</td>
<td>Hong Kong</td>
<td>.29</td>
</tr>
<tr>
<td><italic>Ohio Indicators</italic></td>
<td>.39</td>
<td>Common core</td>
<td>.28</td>
</tr>
<tr>
<td>Hong Kong</td>
<td>.36</td>
<td>England (3-4)</td>
<td>.25</td>
</tr>
<tr>
<td>England (3-4)</td>
<td>.36</td>
<td><italic>Ohio Benchmarks (3-4)</italic></td>
<td>.25</td>
</tr>
</tbody>
</table>
</table-wrap>
<p><xref ref-type="fig" rid="fig1-0895904811429287">Figure 1</xref> presents the coarse grain SEC analysis comparing Ohio’s fourth-grade indicators to TIMSS and the CCSS. The SEC’s unique maps provide the topic list on the Y axis and the cognitive demand on the X axis, with data points at each intersection. <xref ref-type="fig" rid="fig1-0895904811429287">Figure 1</xref> shows that Ohio’s indicators focus heavily on performing procedures, especially in number sense/properties/relationship and measurement. While some areas appear similar to the TIMSS data, other areas of misalignment are readily apparent. Ohio generally covers more topic areas than TIMSS. TIMSS has areas of focus such as operations (23%) and geometric concepts (24%) that have less emphasis in the Ohio standards (10% and 14%, respectively). Conversely, the Ohio indicators have more probability (11%), which is not covered on TIMSS. The CCSS map appears much more aligned to TIMSS at a coarse grain level. However, the overall SEC alignment is determined at the fine grain level and, as mentioned above, the CCSS SEC alignment to TIMSS is very similar to the current fourth-grade indicators. The CCSS map does show the increased focus of the new standards and a shift away from Level 2 cognitive expectations.</p>
<fig id="fig1-0895904811429287" position="float">
<label>Figure 1.</label>
<caption>
<p>SEC map of Ohio indicators, TIMSS, and CCSS (fourth grade).</p>
</caption>
<graphic xlink:href="10.1177_0895904811429287-fig1.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig2-0895904811429287">Figure 2</xref> drills down into the fine grain view of operations to further examine that area of misalignment. This map shows that the TIMSS items include topics that are not covered by the Ohio indicators. For example, 3.6% of the items involve ratio and proportion, which are not covered by the Ohio indicators at fourth grade. Almost 6% of items involve adding and subtracting whole numbers and integers, which are not emphasized by the standards (only .5%). The CCSS map shows more emphasis on operations including adding and subtracting whole numbers and integers (9.1%). However, the CCSS map is similar to the current Ohio indicators with no emphasis on ratio or proportion. From a potential opportunity to learn perspective, should fourth-grade students be expected to perform well on these assessment items if the state standards do not address them at the respective grade level? This may not be an issue if a subtopic was taught at a previous grade although the span of time between previous grade coverage and the assessment may itself be problematic. For example, if a test is based on third to fifth grade-band benchmarks, material that is taught at the beginning of third grade and tested at the end of the fifth grade may have different implications than material covered late in fifth grade then tested at the end of fifth grade.</p>
<fig id="fig2-0895904811429287" position="float">
<label>Figure 2.</label>
<caption>
<p>Fine grain SEC map of Ohio indicators, TIMSS, and CCSS (fourth-grade operations).</p>
</caption>
<graphic xlink:href="10.1177_0895904811429287-fig2.tif"/>
</fig>
</sec>
<sec id="section14-0895904811429287">
<title>Eighth grade</title>
<p>The eighth-grade analysis shows that Ohio’s eighth-grade indicators are fairly well aligned to the TIMSS (topic = .41; SEC = .31) in comparison to the other countries. However, the 8-10 benchmarks are the lowest of the sample. Hong Kong (topic = .48; SEC = .38) is the most aligned to the eighth-grade TIMSS. The CCSS alignment to TIMSS is less than the Ohio indicators in both topic (.26 compared to .41) and SEC (.20 compared to .31) alignment; and slightly higher than the benchmarks. <xref ref-type="table" rid="table3-0895904811429287">Table 3</xref> displays these results.</p>
<table-wrap id="table3-0895904811429287" position="float">
<label>Table 3.</label>
<caption>
<p>Alignment of Eighth-Grade Standards to Eighth-Grade TIMSS.</p>
</caption>
<graphic alternate-form-of="table3-0895904811429287" xlink:href="10.1177_0895904811429287-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Topic Alignment</th>
<th/>
<th align="center">SEC Alignment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hong Kong (7-9)</td>
<td>.48</td>
<td>Hong Kong (7-9)</td>
<td>.38</td>
</tr>
<tr>
<td><italic>Ohio indicators</italic></td>
<td>.41</td>
<td>England</td>
<td>.36</td>
</tr>
<tr>
<td>England</td>
<td>.40</td>
<td><italic>Ohio indicators</italic></td>
<td>.31</td>
</tr>
<tr>
<td>Finland</td>
<td>.38</td>
<td>Singapore</td>
<td>.27</td>
</tr>
<tr>
<td>Singapore</td>
<td>.33</td>
<td>Finland</td>
<td>.25</td>
</tr>
<tr>
<td>Japan</td>
<td>.27</td>
<td>Japan</td>
<td>.22</td>
</tr>
<tr>
<td>Common core</td>
<td>.26</td>
<td>Common core</td>
<td>.20</td>
</tr>
<tr>
<td><italic>Ohio benchmarks (8-10)</italic></td>
<td>.24</td>
<td><italic>Ohio benchmarks (8-10)</italic></td>
<td>.17</td>
</tr>
</tbody>
</table>
</table-wrap>
<p><xref ref-type="fig" rid="fig3-0895904811429287">Figure 3</xref> displays the coarse grain SEC map of the Ohio eighth-grade indicators compared to the TIMSS and the CCSS. Similar to the fourth-grade map in <xref ref-type="fig" rid="fig1-0895904811429287">Figure 1</xref>, Ohio’s indicators focus on performing procedures. The SEC maps show areas of incongruity when examining of alignment of topics. For example, Ohio’s eighth-grade indicators have a heavy emphasis on measurement (16%) that is not as emphasized by TIMSS (8%) or the CCSS (1.7%). Vice versa, in a very substantial incongruity, TIMSS emphasizes operations (19.3%) that are not as heavily emphasized by Ohio (2.2%) or the CCSS (3.4%). The CCSS maps again display the increased focus and shift away from Level 2 cognitive expectations.</p>
<fig id="fig3-0895904811429287" position="float">
<label>Figure 3.</label>
<caption>
<p>SEC map of Ohio indicators, TIMSS, and CCSS (eighth grade).</p>
</caption>
<graphic xlink:href="10.1177_0895904811429287-fig3.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig4-0895904811429287">Figure 4</xref> examines the eighth-grade maps in more detail specifically focusing on the fine grain view of operations. In this view, the incongruity is readily apparent as TIMSS tests several subtopics such as ratio and proportion (4.3%), multiplying fractions (1.9%), and computing with percents (2.6%) that are either not covered or barely emphasized (less than .5%) by the Ohio indicators or the CCSS. Again, this represents a misalignment in potential opportunities to learn and it may be reflected in student performance on TIMSS.</p>
<fig id="fig4-0895904811429287" position="float">
<label>Figure 4.</label>
<caption>
<p>Fine grain SEC map of Ohio indicators, TIMSS, and CCSS (eighth-grade operations).</p>
</caption>
<graphic xlink:href="10.1177_0895904811429287-fig4.tif"/>
</fig>
</sec>
<sec id="section15-0895904811429287">
<title>Ninth grade</title>
<p>As shown in <xref ref-type="table" rid="table4-0895904811429287">Table 4</xref>, Ohio’s ninth-grade indicators have the lowest alignment to the PISA of all the standards in the sample (topic = .14; SEC = .12). The 8-10 benchmarks fared slightly better, but still had relatively low alignment (topic = .22, SEC = .14). The high school Common Core was similar in both topic and SEC alignment to the Ohio indicators although it should be noted that the CCSS data reflect all the high school standards. Similar to the eighth-grade analysis, Hong Kong and England scored the highest of the comparison countries.</p>
<table-wrap id="table4-0895904811429287" position="float">
<label>Table 4.</label>
<caption>
<p>Alignment of Ninth-Grade Standards to PISA.</p>
</caption>
<graphic alternate-form-of="table4-0895904811429287" xlink:href="10.1177_0895904811429287-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Topic alignment</th>
<th/>
<th align="center">SEC alignment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hong Kong (7-9)</td>
<td>.33</td>
<td>Hong Kong (7-9)</td>
<td>.27</td>
</tr>
<tr>
<td>England (9-10)</td>
<td>.23</td>
<td>England (9-10)</td>
<td>.17</td>
</tr>
<tr>
<td><italic>Ohio benchmarks (8-10)</italic></td>
<td>.22</td>
<td><italic>Ohio benchmarks (8-10)</italic></td>
<td>.14</td>
</tr>
<tr>
<td>Japan</td>
<td>.18</td>
<td>Japan</td>
<td>.14</td>
</tr>
<tr>
<td>Singapore (9-10)</td>
<td>.16</td>
<td>Singapore (9-10)</td>
<td>.12</td>
</tr>
<tr>
<td><italic>Ohio indicators</italic></td>
<td>.14</td>
<td><italic>Ohio indicators</italic></td>
<td>.12</td>
</tr>
<tr>
<td>Common core</td>
<td>.14</td>
<td>Common core</td>
<td>.10</td>
</tr>
</tbody>
</table>
</table-wrap>
<p><xref ref-type="fig" rid="fig5-0895904811429287">Figure 5</xref> displays the SEC analysis of the Ohio 8-10 benchmarks compared to PISA. The benchmarks were chosen for this comparison since the PISA may encompass multiple grade levels based on the age status of the students. Since the high school CCSS represents a drastically different age range than the Ohio comparison, it was not included. As noted in <xref ref-type="table" rid="table4-0895904811429287">Table 4</xref>, the benchmarks are not very well aligned to PISA and some very specific areas of incongruity are evident in the SEC maps. For example, Ohio emphasizes trigonometry (4%) and other special topics (5%) that are only minimally addressed by PISA (0% and 1%, respectively). Conversely, PISA emphasizes topics such as operations (13%) and data displays (18.9%) that have less emphasis in the Ohio benchmarks, (4% and .5%, respectively).</p>
<fig id="fig5-0895904811429287" position="float">
<label>Figure 5.</label>
<caption>
<p>SEC map of Ohio 8-10 benchmarks and PISA.</p>
</caption>
<graphic xlink:href="10.1177_0895904811429287-fig5.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig6-0895904811429287">Figure 6</xref> examines the substantial incongruities in the fine grain comparison of data displays. PISA asks students to summarize data in tables and graphs (11.1%), use bar graphs and histograms (3.7%), and use line graphs (3.2%), whereas the Ohio benchmarks only minimally address any subtopic (.5%) within data displays. A lack of alignment clearly exists, which does not necessarily mean that the benchmarks are inadequate but may help explain why students do not perform at high levels. PISA asks students to address data display subtopics that their respective benchmarks do not require.</p>
<fig id="fig6-0895904811429287" position="float">
<label>Figure 6.</label>
<caption>
<p>Fine grain SEC map of Ohio indicators and PISA (data displays).</p>
</caption>
<graphic xlink:href="10.1177_0895904811429287-fig6.tif"/>
</fig>
</sec>
<sec id="section16-0895904811429287">
<title>Dissecting depth of knowledge (cognitive expectations)</title>
<p>The previous analysis points to differences in cognitive expectations—one axis of the SEC methodology. SEC alignment is lower than topic alignment for each comparison on each of the three assessments suggesting differences in cognitive expectations. One benefit of the SEC methodology is the ability to explore this factor. Accordingly, the depth of cognitive expectations across the countries’ standards can be specifically examined to determine whether Ohio’s standards have the same level of depth. <xref ref-type="table" rid="table5-0895904811429287">Table 5</xref> displays the cognitive expectations of the various countries’ standards in relation to Ohio’s indicators and benchmarks.</p>
<table-wrap id="table5-0895904811429287" position="float">
<label>Table 5.</label>
<caption>
<p>Country Specific Cognitive Expectations by Grade.</p>
</caption>
<graphic alternate-form-of="table5-0895904811429287" xlink:href="10.1177_0895904811429287-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">Fourth grade</td>
</tr>
<tr>
<td> Ohio indicators</td>
<td>7.5</td>
<td>61.2</td>
<td>29.1</td>
<td>1.2</td>
<td>1.0</td>
</tr>
<tr>
<td> Ohio benchmarks</td>
<td>29.7</td>
<td>34.2</td>
<td>25.7</td>
<td>10.1</td>
<td>0.3</td>
</tr>
<tr>
<td> Common core</td>
<td>12.3</td>
<td>47.6</td>
<td>29.7</td>
<td>7.2</td>
<td>3.2</td>
</tr>
<tr>
<td> England</td>
<td>22.9</td>
<td>50.3</td>
<td>15.2</td>
<td>10.7</td>
<td>1.0</td>
</tr>
<tr>
<td> Japan</td>
<td>29.0</td>
<td>30.7</td>
<td>28.3</td>
<td>11.6</td>
<td>0.5</td>
</tr>
<tr>
<td> Hong Kong</td>
<td>5.3</td>
<td>50.0</td>
<td>37.1</td>
<td>7.5</td>
<td>0.0</td>
</tr>
<tr>
<td> Singapore</td>
<td>3.5</td>
<td>76.3</td>
<td>17.5</td>
<td>2.8</td>
<td>0.0</td>
</tr>
<tr>
<td colspan="6">Eighth grade</td>
</tr>
<tr>
<td> Ohio indicators</td>
<td>13.1</td>
<td>50.7</td>
<td>25.2</td>
<td>8.8</td>
<td>2.2</td>
</tr>
<tr>
<td> Ohio benchmarks</td>
<td>12.4</td>
<td>50.8</td>
<td>24.2</td>
<td>10.8</td>
<td>1.9</td>
</tr>
<tr>
<td> Common core</td>
<td>14.2</td>
<td>37.8</td>
<td>30.6</td>
<td>12.9</td>
<td>4.5</td>
</tr>
<tr>
<td> Japan</td>
<td>0.0</td>
<td>79.8</td>
<td>20.2</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr>
<td> Finland</td>
<td>0.0</td>
<td>76.5</td>
<td>19.6</td>
<td>4.0</td>
<td>0.0</td>
</tr>
<tr>
<td> Singapore</td>
<td>9.3</td>
<td>81.4</td>
<td>0.0</td>
<td>9.3</td>
<td>0.0</td>
</tr>
<tr>
<td> England</td>
<td>7.3</td>
<td>73.4</td>
<td>13.3</td>
<td>6.0</td>
<td>0.0</td>
</tr>
<tr>
<td> Hong Kong</td>
<td>15.3</td>
<td>52.4</td>
<td>25.9</td>
<td>6.4</td>
<td>0.0</td>
</tr>
<tr>
<td colspan="6">Ninth grade</td>
</tr>
<tr>
<td> Ohio indicators</td>
<td>12.5</td>
<td>65.1</td>
<td>18.2</td>
<td>4.0</td>
<td>0.3</td>
</tr>
<tr>
<td> Ohio benchmarks</td>
<td>12.4</td>
<td>50.8</td>
<td>24.2</td>
<td>10.8</td>
<td>1.9</td>
</tr>
<tr>
<td> Common core</td>
<td>6.0</td>
<td>52.7</td>
<td>33.5</td>
<td>6.4</td>
<td>1.3</td>
</tr>
<tr>
<td> England</td>
<td>2.4</td>
<td>75.5</td>
<td>20.2</td>
<td>1.8</td>
<td>0.0</td>
</tr>
<tr>
<td> Singapore</td>
<td>3.5</td>
<td>92.6</td>
<td>2.8</td>
<td>1.1</td>
<td>0.0</td>
</tr>
<tr>
<td> Japan</td>
<td>0.0</td>
<td>88.4</td>
<td>11.6</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr>
<td> Hong Kong</td>
<td>15.3</td>
<td>52.4</td>
<td>25.9</td>
<td>6.4</td>
<td>0.0</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>In fourth grade, Ohio’s indicators are primarily focused on Level 2: perform procedures (61.2%). Almost 30% of Ohio’s 3-4 benchmarks are coded at Level 1: memorize facts, definitions, and formulas; which is similar to Japan (29%) but higher than Hong Kong (5.3%) and Singapore (3.4%). Hong Kong has the highest percentage (37.1) of standards coded at Level 3: demonstrate understanding. The Common Core standards represent an increase in the higher level cognitive levels for Ohio compared to the state indicators. With the fourth-grade math indicators, the CCSS represents a shift away from Level 2 to more emphasis on Levels 4 and 5 (7.2% and 3.2%). The CCSS show much less emphasis on Level 1 expectations (12.3%) than the benchmarks.</p>
<p>In eighth grade, a majority of Ohio’s indicators (50.7%) and benchmarks (50.8%) are coded at Level 2. While Ohio does have many Level 1 indicators (13.1%) at this grade level, it fares relatively well at the higher levels. That is, the number of Level 4 and 5 indicators and benchmarks are similar to and in some cases greater than the international comparisons. The SEC analysis of the eighth-grade CCSS emphasize a shift into higher level cognitive levels. For Ohio, the CCSS has less emphasis on Level 2 in comparison to the indicators and benchmarks, and more emphasis on each of the three higher levels 3, 4, and 5. The CCSS is less coded at Level 2 (37.8%) with higher percentages of items coded at Level 3, 4, and 5. In fact, the Common Core has the highest percentage of emphasis in these three highest levels when compared to all the high performing countries with 12.9% at Level 4: conjecture, analyze, generalize, and prove; and 4.5% at Level 5: solve nonroutine problems and make connections.</p>
<p>The ninth-grade results are similar as Ohio’s indicators focus on Level 2: perform procedures (65.1%). Both the Ohio indicators (12.5%) and benchmarks (12.4%) have relatively high amounts of Level 1 items. Ohio’s 8-10 benchmarks have the highest percentage of items coded at Level 4 (10.8%). The Common Core represents a shift to higher level expectations in comparison to Ohio’s ninth-grade indicators. Specifically, there is a shift to more Level 3 standards (33.5%) and less Level 1 and 2. The Common Core has the highest percentage of emphasis of Level 3 standards of all the comparison countries.</p>
<p>The results of this analysis show that a majority of the current Ohio indicators, at the respective grade levels, are focused on Level 2: perform procedures, and Ohio tends to have more items coded at Level 1 than many of the comparison countries especially at Grades 8 and 9. The Common Core aims to have more rigorous set of standards. The SEC analysis of cognitive expectations provides some evidence to support this for Ohio.</p>
</sec>
</sec>
</sec>
<sec id="section17-0895904811429287" sec-type="discussion">
<title>Discussion and Policy Considerations</title>
<p>As <xref ref-type="bibr" rid="bibr36-0895904811429287">Viadero (2006)</xref> noted, it is important to examine the data from international assessments and relate findings to policy interests. <xref ref-type="bibr" rid="bibr16-0895904811429287">Min-Hsiung (2009)</xref> argued that researchers need to get beyond the symbolic rankings and understand the data. This study attempted to understand the potential opportunities to learn by benchmarking a state’s math standards against high performing countries and TIMSS and PISA. The analysis reveals some interesting findings that researchers and policy makers should consider when implementing the Common Core and evaluating recent reforms. The focus on current state standards is relevant for three reasons. First, the existing state standards were not immediately replaced and will remain state policy for at least 2 years until the Common Core is fully implemented. Second, states are permitted to add up to an additional 15% of content in addition to the Core. Third, standards are a political process and states can always revisit or replace their standards.</p>
<sec id="section18-0895904811429287">
<title>A Baseline Analysis</title>
<p>The first important policy consideration is a state-level baseline analysis for the Common Core. Studies such as Schmidt (2001) emphasize that international high performers are more focused and this may be a competitive advantage on international assessments. <xref ref-type="bibr" rid="bibr8-0895904811429287">Darling-Hammond and McClosky (2008)</xref> describe how Finland’s lean documents went from hundreds of pages of prescription to a few sets of core concepts. Standards-writing tends to be an incremental process where more and more items are added to avoid political conflict. <xref ref-type="bibr" rid="bibr9-0895904811429287">Finn et al. (2006)</xref> find that standards fall short when vision is sacrificed for consensus and that committee processes lead to “kitchen-sinkism” (p. 12). <xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al. (2005)</xref> describe “an exercise in democratic consensus-making” (p. 530) that requires political compromise and moves away from a structured process. <xref ref-type="bibr" rid="bibr37-0895904811429287">Wirt and Kirst (2005)</xref> describe the process as disjointed incrementalism, with only marginal changes considered, piecemeal alteration, lack of a comprehensive strategy, and avoidance of conflict by “using vague language concerning standards and covering so many topics that no major interest group feels left out. Content priority is sacrificed to the political necessity in breadth of coverage” (p. 346). In other words, the political process often results in increasing the breadth of standards to achieve pluralist support. If a policy goal is to reduce the breadth of standards and focus content, then maintaining that focus may be challenging.</p>
<p><xref ref-type="bibr" rid="bibr18-0895904811429287">The NGA/CCSSO/Achieve report (2008)</xref> recommending creation of a Common Core specifically addressed the notion of focus and thus reducing the number of topics per grade level. This initiative aimed to provide more focus, rigor, and coherence to state standards. When considering the number of topics covered, Ohio’s math standards tend to cover more topics than the comparison countries providing evidence of the mile wide, inch deep syndrome. Initial analysis of the Common Core in specific grades provides evidence that the process was successful in meeting those goals. In fourth and eighth grades, the CCSS represent a substantially more focused set of standards.</p>
<p>Policy makers should remember these policy goals when fully implementing the CCSS and for future revisions. While states voluntarily agree to adopt all the Common Core elements, they are also permitted under the 15% Rule to add up to an additional 15% of content. This allows states some local discretion, but should be used sparingly to maintain the focus of the standards. As pressures build around this, states will also consider future revisions. Policy makers need to stay true to this theory of action when considering marginal additions and future revisions.</p>
</sec>
<sec id="section19-0895904811429287">
<title>Understanding Assessment Results</title>
<p>Policy makers are attuned to results on international assessments such as TIMSS and PISA as they are typically high profile in the media and often drive calls for reform. For example, a recent Associated Press column referred to PISA results as a “’Wake-up call’: U.S. students trail global leaders” (2010). An Ohio newspaper reporting PISA results, argued <xref ref-type="bibr" rid="bibr3-0895904811429287">“A country doing ‘average’ in education, is falling behind” (2010)</xref>. Whether American students’ performance on international assessments should be a policy goal is debatable, but regardless policy makers and the public do pay attention. <xref ref-type="bibr" rid="bibr14-0895904811429287">La Marca’s (2001)</xref> review of alignment claims, “It would be a disservice to students and schools to judge achievement of academic expectations based on a poorly aligned system of assessment” (p. 5). This study provides some potential explanation for the mediocre performance of American students. When considering performance on TIMSS and PISA, it should be noted that Ohio’s current standards are not particularly well aligned to these tests—especially PISA. Other countries’ standards, especially at fourth and ninth grade, are more aligned than Ohio.</p>
<p>Overall, Ohio’s alignment to the international assessments in relation to the higher performing comparison countries ranges from <italic>poor</italic> (at worst) to <italic>mixed</italic> (at best). This is complicated by the inclusion of both Ohio indicators and benchmarks, which have varying degrees of alignment by grade level. Japan and Singapore are more aligned than Ohio and the other countries at the fourth grade. Hong Kong and England are best aligned at both eighth and ninth grades. The alignment of the new CCSS is similar at Grade 4 and lower than the current eighth grade indicators. These indicators were not necessarily designed to be aligned to the TIMSS and PISA, so this should be considered when analyzing student performance data. If policy makers want higher student performance on TIMSS and PISA, then the state standards and assessment system could consider a system that is more tightly aligned to those frameworks. If that is not a policy goal, then results on future international assessments should be viewed through that moderated lens of expectations.</p>
</sec>
<sec id="section20-0895904811429287">
<title>Future Research</title>
<p>This study has identified and generated several avenues of future research. First, the intent of this study was to conduct a state-level analysis of standards in relation to high performing countries and international assessments—using the SEC methodology. The Common Core promises a more focused and rigorous set of standards designed to make American students more competitive. The results of this analysis provide some preliminary evidence supporting that principle in terms of reducing the number of topics covered and increasing the levels of cognitive expectations. This baseline data should be compared to the fully implemented Common Core across all grade levels and expanded to examine other participating states. In addition, while this study specifically addressed questions of focus, future SEC research should specifically address coherence issues. As <xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al. (2005)</xref> emphasize, it is not just about reducing the number of topics but also creating a coherent structure built on progressions. This is a point that the Common Core framers address in the introduction to the standards—focus is not enough, there must be coherent progressions (<xref ref-type="bibr" rid="bibr7-0895904811429287">Common Core State Standards Initiative, 2010</xref>). For example, Ohio’s grade-level indicators are generally most aligned to the grade levels immediately before and after (<xref ref-type="bibr" rid="bibr38-0895904811429287">Woolard, 2007</xref>) In other words, across all grade levels, there is a correlation of subtopic/cognitive demand that is often repeated from grade to grade. Additional SEC research should examine whether that repetitiveness is reduced both in Ohio and in other states.</p>
<p>A second area where the SEC methodology can specifically add to the research base is by examining the enacted curriculum in the comparison countries. As much research has pointed out (<xref ref-type="bibr" rid="bibr26-0895904811429287">Porter &amp; Smithson, 2001</xref>; <xref ref-type="bibr" rid="bibr29-0895904811429287">Schmidt et al., 2009</xref>), there is variation between the intended and implemented curriculum. This study used the SEC to compare potential opportunities to learn by focusing the alignment of the standards to assessments. Adding data on the enacted curriculum, while representing a resource intensive task, would provide additional insights on instructional practices and help understand differences across borders.</p>
<p>The SEC methodology can be useful in these types of studies. Future SEC development could increase the value of such analysis. This includes the coding of additional standards across all states, analysis of any 15% rule additions, and coding of other high performing international standards. The methodology could benefit from additional research that examines the question of “what is the threshold of good alignment?”</p>
<p><xref ref-type="bibr" rid="bibr32-0895904811429287">Schmidt et al. (2005)</xref> note that “coherence and rigor might only be possible in the United States if curriculum standards are national in scope” (p. 556). With the implementation of the Common Core, that may come to fruition. This particular research has provided a baseline to examine against. Future research should build on this by further developing the use of the SEC methodology in addressing these questions, examining more states in detail, and revisiting these questions when the states fully implement their versions of the Common Core and the subsequent assessments.</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<bio>
<title>Author Biography</title>
<p><bold>J. Christopher Woolard</bold> is a research and evaluation manager for the Ohio Department of Education - Office of Policy and Research. His work focuses on data tools for educators, teacher evaluation, curriculum alignment, and state-level research. Chris received his PhD/MA (Political Science) from Miami University and BA (Education, Political Science) from Muskingum College. His current research interests include international benchmarking of state standards and assessments, and best practices in online education. Chris also teaches adjunct courses at Ohio University-Pickerington.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0895904811429287">
<citation citation-type="web">
<collab>Academic content standards frequently asked questions</collab>. (<year>2010</year>). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ode.state.oh.us/GD/Templates/Pages/ODE/ODEDetail.aspx?page=3&amp;TopicRelationID=1696&amp;ContentID=1929&amp;Content=88486">http://www.ode.state.oh.us/GD/Templates/Pages/ODE/ODEDetail.aspx?page=3&amp;TopicRelationID=1696&amp;ContentID=1929&amp;Content=88486</ext-link></citation>
</ref>
<ref id="bibr2-0895904811429287">
<citation citation-type="web">
<collab>Achieve Inc</collab>. (<year>2007</year>). <source>Creating a world-class education system in Ohio</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.achieve.org/files/World_Class_Edu_Ohio_FINAL.pdf">http://www.achieve.org/files/World_Class_Edu_Ohio_FINAL.pdf</ext-link></citation>
</ref>
<ref id="bibr3-0895904811429287">
<citation citation-type="web">
<collab>A country doing ‘average’ in education, is falling behind</collab>. (<year>2010</year>, <month>December</month> <day>30</day>). <source>Youngstown Vindicator</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.vindy.com/news/2010/dec/30/a-country-doing-8216average8217-in-educa/?print">http://www.vindy.com/news/2010/dec/30/a-country-doing-8216average8217-in-educa/?print</ext-link></citation>
</ref>
<ref id="bibr4-0895904811429287">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Armario</surname><given-names>C.</given-names></name>
</person-group> (<year>2010</year>, <month>December</month> <day>7</day>). <article-title>“Wake-up call”: U.S. students trail global leaders</article-title>. <source>MSNBC.com</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.msnbc.msn.com/id/40544897/ns/us_news-life/">http://www.msnbc.msn.com/id/40544897/ns/us_news-life/</ext-link></citation>
</ref>
<ref id="bibr5-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Baines</surname><given-names>L.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Learning from the world: Achieving more by doing less</article-title>. <source>Education Digest: Essential Readings Condensed for Quick Review</source>, <volume>73</volume>(<issue>5</issue>), <fpage>23</fpage>-<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr6-0895904811429287">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Blank</surname><given-names>R.</given-names></name>
<name><surname>Smithson</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>, <month>February</month>). <source>Alignment content analysis of TIMSS and PISA mathematics and science assessments using the Surveys of Enacted Curriculum methodology</source>. <conf-name>A CCSSO paper prepared for National Center for Education Statistics and American Institutes for Research</conf-name>, <conf-loc>Washington, DC</conf-loc>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ccsso.org/Documents/2009/Alignment_Content_Analysis_of_TIMSS_2009.pdf">http://www.ccsso.org/Documents/2009/Alignment_Content_Analysis_of_TIMSS_2009.pdf</ext-link></citation>
</ref>
<ref id="bibr7-0895904811429287">
<citation citation-type="web">
<collab>Common Core State Standards Initiative</collab>. (<year>2010</year>). <source>Toward greater focus and coherence</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.corestandards.org/the-standards/mathematics">http://www.corestandards.org/the-standards/mathematics</ext-link></citation>
</ref>
<ref id="bibr8-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Darling-Hammond</surname><given-names>L.</given-names></name>
<name><surname>McCloskey</surname><given-names>L.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Assessment for learning around the world: What would it mean to be internationally competitive?</article-title> <source>Phi Delta Kappan</source> <volume>90</volume>, <fpage>263</fpage>-<lpage>272</lpage>.</citation>
</ref>
<ref id="bibr9-0895904811429287">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Finn</surname><given-names>C. E.</given-names></name>
<name><surname>Julian</surname><given-names>L.</given-names></name>
<name><surname>Petrelli</surname><given-names>M. J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The state of the state standards 2006</article-title>. <source>Thomas B. Fordham Foundation</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.edexcellencemedia.net/publications/2006/200608_thestateofstatestandards2006/State%20of%20State%20Standards2006FINAL.pdf">http://www.edexcellencemedia.net/publications/2006/200608_thestateofstatestandards2006/State%20of%20State%20Standards2006FINAL.pdf</ext-link></citation>
</ref>
<ref id="bibr10-0895904811429287">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Frelindich</surname><given-names>N.</given-names></name>
</person-group> (<year>1998</year>). <article-title>From Sputnik to TIMSS: Reforms in science education make headway despite Setback</article-title>. <source>Harvard Education Letter</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.project2061.org/publications/articles/articles/harvard.htm">http://www.project2061.org/publications/articles/articles/harvard.htm</ext-link></citation>
</ref>
<ref id="bibr11-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
<name><surname>Smithson</surname><given-names>J.</given-names></name>
<name><surname>White</surname><given-names>P. A.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Upgrading high school mathematics instruction: Improving learning opportunities for low-achieving, low-income youth</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>19</volume>, <fpage>325</fpage>-<lpage>338</lpage>.</citation>
</ref>
<ref id="bibr12-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gonzales</surname><given-names>P.</given-names></name>
<name><surname>Williams</surname><given-names>T.</given-names></name>
<name><surname>Jocelyn</surname><given-names>L.</given-names></name>
<name><surname>Roey</surname><given-names>S.</given-names></name>
<name><surname>Kastberg</surname><given-names>D.</given-names></name>
<name><surname>Brenwald</surname><given-names>S.</given-names></name>
</person-group> (<year>2008</year>). <source>Highlights from TIMSS 2007: Mathematics and science achievement of U.S. fourth- and eighth-grade students in an international context</source> (NCES 2009-001 Revised). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Center for Education Statistics, Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr13-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hook</surname><given-names>W.</given-names></name>
<name><surname>Bishop</surname><given-names>W.</given-names></name>
<name><surname>Hook</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A quality math curriculum in support of effective teaching for elementary schools</article-title>. <source>Educational Studies in Mathematics</source>, <volume>65</volume>(<issue>2</issue>), <fpage>125</fpage>-<lpage>148</lpage>.</citation>
</ref>
<ref id="bibr14-0895904811429287">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>La Marca</surname><given-names>P. M.</given-names></name>
</person-group> (<year>2001</year>). <source>Alignment of standards and assessments as an accountability criterion</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://PAREonline.net/getvn.asp?v=7&amp;n=21">http://PAREonline.net/getvn.asp?v=7&amp;n=21</ext-link></citation>
</ref>
<ref id="bibr15-0895904811429287">
<citation citation-type="gov">
<person-group person-group-type="author">
<name><surname>La Marca</surname><given-names>P. M.</given-names></name>
<name><surname>Redfield</surname><given-names>D.</given-names></name>
<name><surname>Winter</surname><given-names>P. C.</given-names></name>
<name><surname>Bailey</surname><given-names>A.</given-names></name>
<name><surname>Despriet</surname><given-names>L. H.</given-names></name>
</person-group> (<year>2000</year>). <source>State standards and state assessment systems: A guide to alignment</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.eric.ed.gov/PDFS/ED466497.pdf">http://www.eric.ed.gov/PDFS/ED466497.pdf</ext-link></citation>
</ref>
<ref id="bibr16-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Min-Hsiung</surname><given-names>H.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Beyond horse race comparisons of national performance averages: Math performance variation within and between classrooms in 38 countries</article-title>. <source>Educational Research &amp; Evaluation</source>, <volume>15</volume>, <fpage>327</fpage>-<lpage>342</lpage>. doi:<pub-id pub-id-type="doi">10.1080/13803610903087003</pub-id></citation>
</ref>
<ref id="bibr17-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mullis</surname><given-names>I. V. S.</given-names></name>
<name><surname>Martin</surname><given-names>M. O.</given-names></name>
<name><surname>Foy</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <source>TIMSS 2007 International mathematics report: Findings from IEA’s trends in international mathematics and science study at the fourth and eighth grades</source>. <publisher-loc>Chestnut Hill, MA</publisher-loc>: <publisher-name>Boston College</publisher-name>.</citation>
</ref>
<ref id="bibr18-0895904811429287">
<citation citation-type="web">
<collab>National Governors Association, the Council of Chief State School Officers, &amp; Achieve, Inc</collab>. (<year>2008</year>). <source>Benchmarking for success: Ensuring U.S. students receive a world-class education</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.achieve.org/BenchmarkingforSuccess">http://www.achieve.org/BenchmarkingforSuccess</ext-link></citation>
</ref>
<ref id="bibr19-0895904811429287">
<citation citation-type="web">
<collab>Organisation for Economic Co-operation and Development</collab>. (<year>2007</year>). <source>PISA 2006: Science competencies for tomorrow’s world</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.oecd.org/dataoecd/30/17/39703267.pdf">http://www.oecd.org/dataoecd/30/17/39703267.pdf</ext-link></citation>
</ref>
<ref id="bibr20-0895904811429287">
<citation citation-type="web">
<collab>Organisation for Economic Co-operation and Development</collab>. (<year>2010</year>). <source>PISA 2009 Results: Executive summary</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.pisa.oecd.org/dataoecd/34/60/46619703.pdf">http://www.pisa.oecd.org/dataoecd/34/60/46619703.pdf</ext-link></citation>
</ref>
<ref id="bibr21-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Phillips</surname><given-names>G. W.</given-names></name>
</person-group> (<year>2009</year>). <source>The second derivative: International benchmarks in mathematics for U.S. states and school districts</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Institutes for Research</publisher-name>.</citation>
</ref>
<ref id="bibr22-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Phillips</surname><given-names>G. W.</given-names></name>
<name><surname>Dossey</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <source>Counting on the future: International benchmarks in mathematics for American school districts</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Institutes for Research</publisher-name>.</citation>
</ref>
<ref id="bibr23-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Measuring the content of instruction: Uses in research and practice</article-title>. <source>Educational Researcher</source> <volume>31</volume>(<issue>7</issue>), <fpage>3</fpage>-<lpage>14</lpage>.</citation>
</ref>
<ref id="bibr24-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
<name><surname>Polikoff</surname><given-names>M. S.</given-names></name>
<name><surname>Smithson</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Is there a defacto national intended curriculum? Evidence from state content standards</article-title>. <source>Education Evaluation and Policy Analysis</source> <volume>31</volume>, <fpage>238</fpage>-<lpage>268</lpage>.</citation>
</ref>
<ref id="bibr25-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
<name><surname>Politkoff</surname><given-names>M. S.</given-names></name>
<name><surname>Zeidner</surname><given-names>T.</given-names></name>
<name><surname>Smithson</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>The quality of content analyses of state student achievement tests and state content standards</article-title>. <source>Educational Measurement: Issues and Practice</source>, <volume>27</volume>(<issue>4</issue>), <fpage>2</fpage>-<lpage>14</lpage>.</citation>
</ref>
<ref id="bibr26-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
<name><surname>Smithson</surname><given-names>J.</given-names></name>
</person-group> (<year>2001</year>). <source>Defining, developing, and using curriculum indicators</source> (CPRE Research Report Series). <publisher-loc>Philadelphia</publisher-loc>: <publisher-name>Consortium for Policy Research in Education: University of Pennsylvania</publisher-name>.</citation>
</ref>
<ref id="bibr27-0895904811429287">
<citation citation-type="web">
<collab>Quality Counts</collab> <year>2010</year>. (<year>2010</year>). <source>Ed Week</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.edweek.org/ew/qc/2010/17src.h29.html">http://www.edweek.org/ew/qc/2010/17src.h29.html</ext-link></citation>
</ref>
<ref id="bibr28-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Richland</surname><given-names>L. E.</given-names></name>
<name><surname>Zur</surname><given-names>O.</given-names></name>
<name><surname>Holyoak</surname><given-names>K. J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Cognitive supports for analogies in the mathematics classroom: Variations in the effective use of analogies in math instruction across countries may contribute to performance differences in the TIMSS studies</article-title>. <source>Science</source>, <volume>316</volume>, <fpage>1128</fpage>-<lpage>1129</lpage>.</citation>
</ref>
<ref id="bibr29-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schmidt</surname><given-names>W. H.</given-names></name>
<name><surname>Bates</surname><given-names>P.</given-names></name>
<name><surname>Leroi</surname><given-names>G.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Research Report—Opportunities to learn in PROM/SE classrooms: Teachers’ reported coverage of mathematics content</article-title>. <source>Promoting Rigorous Outcomes in Mathematics and Science Education (PROM/SE)</source>, <volume>6</volume>, <fpage>1</fpage>-<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr30-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Schmidt</surname><given-names>W. H.</given-names></name>
<name><surname>McKnight</surname><given-names>C.</given-names></name>
<name><surname>Raizen</surname><given-names>S.</given-names></name>
</person-group> (<year>1997</year>). <source>A splintered vision: An investigation of U.S. science and mathematics education</source>. <publisher-loc>Dordrecht, Netherlands</publisher-loc>: <publisher-name>Kluwer Academic</publisher-name>.</citation>
</ref>
<ref id="bibr31-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schmidt</surname><given-names>W. H.</given-names></name>
<name><surname>Prawat</surname><given-names>R. S.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Curriculum coherence and national control of education: Issue or non-issue?</article-title> <source>Journal of Curriculum Studies</source>, <volume>38</volume>, <fpage>641</fpage>-<lpage>658</lpage>.</citation>
</ref>
<ref id="bibr32-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schmidt</surname><given-names>W. H.</given-names></name>
<name><surname>Wang</surname><given-names>H.</given-names></name>
<name><surname>McKnight</surname><given-names>C. C.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Curriculum coherence: An examination of US mathematics and science standards from an international perspective</article-title>. <source>Journal of Curriculum Studies</source>, <volume>37</volume>, <fpage>525</fpage>-<lpage>559</lpage>.</citation>
</ref>
<ref id="bibr33-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Schmidt</surname><given-names>W. H.</given-names></name>
<name><surname>McKnight</surname><given-names>C. C.</given-names></name>
<name><surname>Houang</surname><given-names>R. T.</given-names></name>
<name><surname>Wang</surname><given-names>H.</given-names></name>
<name><surname>Wiley</surname><given-names>D. E.</given-names></name>
<name><surname>Cogan</surname><given-names>L. S.</given-names></name>
<name><surname>Wolfe</surname><given-names>R. G.</given-names></name>
</person-group> (<year>2001</year>). <source>Why schools matter: A cross-national comparison of curriculum and learning</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr34-0895904811429287">
<citation citation-type="gov">
<collab>U.S. Department of Education</collab>. (<year>2007</year>). <source>Standards and assessments peer review guidance: Information and examples for meeting requirements of the No Child Left Behind Act of 2001</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ed.gov/policy/elsec/guid/saaprguidance.pdf">http://www.ed.gov/policy/elsec/guid/saaprguidance.pdf</ext-link></citation>
</ref>
<ref id="bibr35-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Valverde</surname><given-names>G. A.</given-names></name>
<name><surname>Schmidt</surname><given-names>W. H.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Greater expectations: learning from other nations in the quest for ‘world-class standards’ in US school mathematics and science</article-title>. <source>Journal of Curriculum Studies</source>, <volume>32</volume>(<issue>5</issue>), <fpage>651</fpage>-<lpage>687</lpage>.</citation>
</ref>
<ref id="bibr36-0895904811429287">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Viadero</surname><given-names>D.</given-names></name>
</person-group> (<year>2006</year>, <month>November</month> <day>01</day>). <article-title>Potential of global tests seen as unrealized: Scholars urged to scour TIMSS, PISA for policy insights</article-title>. <source>Education Week</source>, <volume>26</volume>(<issue>13</issue>), <fpage>1</fpage>-<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr37-0895904811429287">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wirt</surname><given-names>F.</given-names></name>
<name><surname>Kirst</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <source>The political dynamics of American education</source>. <publisher-loc>Richmond, CA</publisher-loc>: <publisher-name>McCutcheon</publisher-name>.</citation>
</ref>
<ref id="bibr38-0895904811429287">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Woolard</surname><given-names>J. C.</given-names></name>
</person-group> (<year>2007</year>, <month>April</month>). <source>Measuring systemic alignment of a state’s instruction, standards, and assessments: A baseline analysis</source>. <conf-name>Paper presented at the 2007 Annual Meeting of the American Educational Research Association</conf-name>, <conf-loc>Chicago, IL</conf-loc>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://programs.ccsso.org/content/pdfs/woolard%2007%20AERA.doc">http://programs.ccsso.org/content/pdfs/woolard%2007%20AERA.doc</ext-link></citation>
</ref>
</ref-list>
</back>
</article>