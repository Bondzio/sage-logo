<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="editorial">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">RSW</journal-id>
<journal-id journal-id-type="hwp">sprsw</journal-id>
<journal-title>Research on Social Work Practice</journal-title>
<issn pub-type="ppub">1049-7315</issn>
<issn pub-type="epub">1552-7581</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1049731511431970</article-id>
<article-id pub-id-type="publisher-id">10.1177_1049731511431970</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Editorial</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Voyage on Turbulent Quantitative Waters: A Response to Ian Shaw’s Editorial</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Holosko</surname>
<given-names>Michael J.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1049731511431970">1</xref>
<xref ref-type="corresp" rid="corresp1-1049731511431970"/>
</contrib>
<aff id="aff1-1049731511431970"><label>1</label>School of Social Work, University of Georgia, Athens, GA, USA</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1049731511431970">Michael J. Holosko, School of Social Work, University of Georgia, Athens, GA 30602, USA Email: <email>mholosko@uga.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2012</year>
</pub-date>
<volume>22</volume>
<issue>2</issue>
<fpage>135</fpage>
<lpage>137</lpage>
<permissions>
<copyright-statement>© SAGE Publications 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<p>Ironically, professor Ian Shaw’s editorial focused primarily on the merits of qualitative methodology, not quantitative methods. So with all due respect Dr. Shaw, I would therefore suggest a friendly amendment to your article title: “<italic>The Positivist [not Positive] Contributions of Quantitative Methodology to Social Work Research: A View from the Sidelines.</italic>” Quite frankly, I found that Shaw’s editorial tended to ignore the positives of quantitative research [of which there are many], and he chose instead to focus on some of its widely recognized methodological limitations. In my life, I have reached the point where I realize that the need to be right is toxic. It truly does nothing to advance meaningful discussion, conversation, and/or thinking—in fact, just the opposite. Thus, I do not need to be right, but I should convey how I arrived at this appraisal of Dr. Shaw’s statement. I will provide some empirical facts to support my contention, as for me it was the “problème majeur” [I do think it sounds so much nicer in French] with Dr. Shaw’s article. His view of quantitative methods appears to have a “position flaw,” that is, he argued from the outside-in (qualitative to quantitative), rather than the reverse. And this obfuscated many of his claims in the article, some of which had real merit.</p>
<p>Evidence abounds in his think piece about this “position flaw.” Some noteworthy quotations are “I am prepared to hold quantitative objectivisms in one hand and qualitative revelations in the other” (para. 2); “to get to the point, writing as a convinced qualitative methodologist—roughly speaking, epistemologically constructivist and ontologically realist’s” (para. 5); and a bit later when he states, “I want to refer to the ways that qualitative strategies may gain from borrowing” [from quantitative ones—my words here]. Given that these quotations may be viewed as a bit out of context by some, I offer additional empirical proof through the Internet tool “Wordle,” found at <ext-link ext-link-type="uri" xlink:href="www.wordle.com">www.wordle.com</ext-link>.</p>
<p>Wordle allows one to upload any number or words/texts into a program that instantaneously forms a magical “word cloud.” The size of the words in the cloud [which you can alter in appearance but not content] is determined by the frequency [or perceived relevance] in the uploaded word file. So one can visually inspect which words in the file “pop up” in the word cloud, more prominently. <xref ref-type="fig" rid="fig1-1049731511431970">Figure 1</xref>
 shows the uploaded word cloud of Dr. Shaw’s article on “<italic>Positive Contributions of Quantitative Methodology…</italic>” And Sheezam! Without a histogram, pie chart, frequency table, parametric or non-parametric test, one can clearly see how the word “QUALITATIVE,” pops up in the cloud more prominently.</p>
<fig id="fig1-1049731511431970" position="float">
<label>Figure 1.</label>
<caption>
<p>A “Wordle Cloud” of Ian Shaw’s editorial on quantitative methods.</p>
</caption>
<graphic alternate-form-of="fig1-1049731511431970" xlink:href="10.1177_1049731511431970-fig1.tif"/>
</fig>
<p>Wordle also has a singular word count feature for each character in the uploaded text, including commas (,’s). “Qualitative” is mentioned 31 times, and “quantitative” is mentioned 26 times in your article. So Dr. Shaw, the empirical proof is “in the pudding”—or “pudding cloud,” in this case.</p>
<p>Turning to the arguments offered about quantitative methods, I was also a bit confused about the point of departure for braiding your culminating thoughts so narrowly—“quantitative solutions to the problem of comparison, in particular through experimental and quasi-experimental intervention research” (para. 5). The truth is that at no point in social work’s research history have experimental and quasi-experimental been the mainstay research designs of either social work academics or practitioners. For example, in a content analysis of <italic>N</italic> = 329 articles published between 2005 and 2007 in the three main North American empirical social work journals (<italic>Research on Social Work Practice, Journal of Social Service Research,</italic> and <italic>Social Work Research</italic>), I found (<xref ref-type="bibr" rid="bibr5-1049731511431970">Holosko, 2010</xref>) that only 2.3% studies used experimental designs, and 5.1% used quasi-experimental designs. Conversely, 72.9% used a simple one shot case study design without an intervention, with 9.3% using a single posttest after an intervention. I reiterate then, that the research methods you are referring to in the previous quotation, quasi-experiments and true experimental studies, are rarely used and decidedly uncharacteristic of the “bread and butter” designs used by social work researchers, as reflected in our professional journals.</p>
<p>I do both applaud and laud you for acknowledging and unearthing some crucial “research chestnuts” that laid the foundation stones for today’s social work research and evaluation enterprise: <italic>The Origins of Scientific Sociology</italic> (<xref ref-type="bibr" rid="bibr6-1049731511431970">Madge, 1963</xref>), <italic>Quasi-Experimentation: Design and Analysis in Field Settings</italic> (<xref ref-type="bibr" rid="bibr2-1049731511431970">Cook &amp; Campbell, 1979</xref>); <italic>The Effectiveness of Social Casework</italic> (<xref ref-type="bibr" rid="bibr4-1049731511431970">Fischer, 1976</xref>); and <italic>Toward Reform of Program Evaluation</italic> (<xref ref-type="bibr" rid="bibr3-1049731511431970">Cronbach et al., 1980</xref>), to name a few, that I also occasionally reread in awe from my own personal library. I was also rather moved by your correct assumption that our field seems to have not progressed significantly in our research methods or intervention-based studies as articulated by these earlier authors.</p>
<p>One notable exception was William Reid’s jump-starting the social work profession on pragmatic approaches to intervention research, and by default, more outcome-based studies. Both <xref ref-type="bibr" rid="bibr7-1049731511431970">Rubin and Parrish (2007)</xref> and <xref ref-type="bibr" rid="bibr5-1049731511431970">Holosko (2010)</xref>, in similar reviews of social work research, cited the rather startling and encouraging findings that 96.7% (<xref ref-type="bibr" rid="bibr5-1049731511431970">Holosko, 2010</xref>), and 91.3% (<xref ref-type="bibr" rid="bibr7-1049731511431970">Rubin &amp; Parrish, 2007</xref>) of the studies that were published had specified outcomes. This reveals that intervention-based research indeed has a very firm footing in our journals and revealed an important development in the design of our empirical research and evaluation studies, and their relationship to practice.</p>
<p>I was also pleased that you acknowledged in the <italic>Gifts</italic> sub-section, how <xref ref-type="bibr" rid="bibr2-1049731511431970">Cook and Campbell’s (1979)</xref> seminal linking of a design hierarchy to threats to validity of measurement and findings has been a rather mixed blessing on our quantitative research methods. In this subsection you artfully noted how <xref ref-type="bibr" rid="bibr3-1049731511431970">Cronbach et al. (1980)</xref>, and <xref ref-type="bibr" rid="bibr8-1049731511431970">Scriven (1986)</xref> delicately tightrope walked the virtues of internal and external validity, and more importantly tabled these issues in the context of how and where social work research is conducted—in our health and human service organizations.</p>
<p>Bringing your earlier arguments from the Godfather of empirical pragmatism, William Reid forward, that is, his reservations about the hegemony of particular assumptions of the nature of our scientific knowledge [being generated by quantitative social work researchers], and how our practice research allegedly directs and informs practice—would have shown “the other side of the coin” of <xref ref-type="bibr" rid="bibr1-1049731511431970">Campbell and Stanley’s (1963)</xref> pervasive invalidity hysteria, which is still apparent among many social workers who design their research studies. Few in our field have offered solutions and fewer have offered any apologies for our current use of lower level designs [as it is our reality], and their alleged flaws with respect to internal validity. The reality is that many responsible social work researchers offset such “design problems” by strengthening the methodological rigor of their studies in a variety of ways, for example, using standardized instruments, applying more appropriate and selective sampling techniques, enhancing intervention fidelity, and so on. (see <xref ref-type="bibr" rid="bibr5-1049731511431970">Holosko, 2010</xref>, p. 671, for a more complete list of these offsetting strategies). Thus, the more obvious positive contributions of well-constructed reality-based [in our work cultures] quantitative social work research easily rise above the pervasive and niggling design ⇒⇐ invalidity argument. As noted above, extending some other well-founded arguments in the article a bit further on this positive quantitative path would have strengthened this work considerably—in my humble opinion.</p>
<p>Finally Dr. Shaw, I disagree with your concluding remark when you said “I have referred to the work of several quantitative scholars, whose sensitivity to the limits (and limitations) of science makes for more greater rather than lesser impact on research thinking and practice.” In my thinking, your piece could have been enriched by discussing <italic>more</italic> about the actual positives of quantitative research and truly exploring and extolling its many virtues and marvels. Ergo, my earlier contention of your “position flaw.”</p>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="bibr1-1049731511431970">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Campbell</surname>
<given-names>D. T.</given-names>
</name>
<name>
<surname>Stanley</surname>
<given-names>J. C.</given-names>
</name>
</person-group> (<year>1963</year>). <source>Experimental and quasi-experimental designs for research</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Rand McNally</publisher-name>.</citation>
</ref>
<ref id="bibr2-1049731511431970">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cook</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Campbell</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>1979</year>). <source>Quasi-experimentation: Design and analysis issues for field settings</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Rand McNally</publisher-name>.</citation>
</ref>
<ref id="bibr3-1049731511431970">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cronbach</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Ambron</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Dornbusch</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Hess</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Hornik</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Phillips</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Weiner</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>1980</year>). <source>Toward reform of program evaluation</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr4-1049731511431970">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Fischer</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1976</year>). <source>The effectiveness of social casework</source>. <publisher-loc>Springfield, IL</publisher-loc>: <publisher-name>Charles C Thomas</publisher-name>.</citation>
</ref>
<ref id="bibr5-1049731511431970">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Holosko</surname>
<given-names>M. J.</given-names>
</name>
</person-group> (<year>2010</year>). <article-title>What types of designs are we using in social work research and evaluation?</article-title> <source>Research on Social Work Practice</source>, <volume>20</volume>, <fpage>665</fpage>–<lpage>673</lpage>.</citation>
</ref>
<ref id="bibr6-1049731511431970">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Madge</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1963</year>). <source>The origins of scientific sociology</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Tavistock</publisher-name>.</citation>
</ref>
<ref id="bibr7-1049731511431970">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Parrish</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>2007</year>). <article-title>Problematic phrases in the conclusions of published outcome studies: Implications for evidence-based practice</article-title>. <source>Research on Social Work Practice</source>, <volume>17</volume>, <fpage>334</fpage>–<lpage>347</lpage>.</citation>
</ref>
<ref id="bibr8-1049731511431970">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Scriven</surname>
<given-names>M.</given-names>
</name>
</person-group> (<year>1986</year>). <article-title>New frontiers of evaluation</article-title>. <source>Evaluation Practice</source>, <volume>7</volume>, <fpage>7</fpage>–<lpage>44</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>