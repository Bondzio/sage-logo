<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EVI</journal-id>
<journal-id journal-id-type="hwp">spevi</journal-id>
<journal-title>Evaluation</journal-title>
<issn pub-type="ppub">1356-3890</issn>
<issn pub-type="epub">1461-7153</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1356389012472248</article-id>
<article-id pub-id-type="publisher-id">10.1177_1356389012472248</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A triangulation approach to impact evaluation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Bjurulf</surname><given-names>Staffan</given-names></name>
<aff id="aff1-1356389012472248">Karlstad University and Region Värmland, Sweden</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Vedung</surname><given-names>Evert</given-names></name>
<aff id="aff2-1356389012472248">Uppsala University, Sweden</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Larsson</surname><given-names>C. G.</given-names></name>
<aff id="aff3-1356389012472248">Larsson Consulting, Sweden</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-1356389012472248">Staffan Bjurulf, Region Värmland, SE-651 15 Karlstad, Sweden. Email: <email>staffan.bjurulf@regionvarmland.se</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>19</volume>
<issue>1</issue>
<fpage>56</fpage>
<lpage>73</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>This article presents a viable method to overcome the challenge of producing reliable cause–effect findings in impact evaluation. The Measuring Cluster Effects through Triangulation method (MCET) involves <italic>methodological triangulation</italic>. Three designs − shadow controls, generic controls, and process tracing − are combined to shed light on causality. When these three approaches are triangulated, cause–effect findings will be more reliable. The MCET combination is a feasible alternative when randomized controlled trials and matched controls are impossible or impracticable. It is also an alternative to using a single non-experimental design, particularly in situations where expenditure is great and the causality issue is pressing. In this article, the MCET approach is illustrated by information drawn from a set of evaluations performed on the activities of the Compare Foundation, a cluster organization in Sweden in the Information and Communication Technology sector. Regionally based in Karlstad, County Värmland, and founded in 2000, the Compare cluster organization has adapted the MCET to its own activities.</p>
</abstract>
<kwd-group>
<kwd>cause effect</kwd>
<kwd>cluster organization</kwd>
<kwd>compare cluster organization</kwd>
<kwd>generic controls</kwd>
<kwd>impact evaluation</kwd>
<kwd>Measuring Cluster Effects through Triangulation (MCET)</kwd>
<kwd>process tracing</kwd>
<kwd>shadow controls</kwd>
<kwd>triangulation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1356389012472248" sec-type="intro">
<title>Introduction: Intervention impact evaluation</title>
<p><disp-quote>
<p>Although a perennial preoccupation, establishing the effect of interventions is resurging in importance … There are some daunting methodological problems in identifying robust causal links between interventions … and desired outcomes. (<xref ref-type="bibr" rid="bibr14-1356389012472248">Saunders, 2011</xref>: 89)</p>
</disp-quote></p>
<p>We agree with Saunders: the intervention impact problem is challenging. When it comes to the evaluation enterprise it is one of the most difficult aspects, if not <italic>the</italic> most difficult. The complexities of impact evaluation are many. For example, would the recorded outcome have taken place without the intervention? What, if anything, may indicate a positive connection between an intervention and an outcome? How can one discern the particular impact of the intervention, when there are many other potential causal factors? Furthermore, an intervention often consists of several components and these components can play out over a long period of time, which also increases levels of complexity. Once an intervention has been identified, which component, or even combination of components, has contributed to the results?</p>
<p>According to <xref ref-type="bibr" rid="bibr13-1356389012472248">Rossi et al. (1999)</xref>, <xref ref-type="bibr" rid="bibr16-1356389012472248">Vedung (2000)</xref>, and others, identifying the intervention impact could be undertaken in a number of ways. Some evaluation methodologists argue that randomized controlled trials (RCTs) are the gold standard and should be used wherever possible, although weaker, matched controls are deemed acceptable if RCTs cannot be carried out.</p>
<p>However, since the two types of experimentation mentioned above are often not possible or ethically acceptable in real-world circumstances, evaluation theorists usually recommend the application of other designs, such as generic controls, cross-sectional controls, intensive case studies (<xref ref-type="bibr" rid="bibr13-1356389012472248">Rossi et al., 1999</xref>), or, more recently, contribution analysis (see the special issue of <italic>Evaluation</italic>, 18(3) <xref ref-type="bibr" rid="bibr7-1356389012472248">2012</xref>; <xref ref-type="bibr" rid="bibr11-1356389012472248">Mayne, 2012</xref>).</p>
</sec>
<sec id="section2-1356389012472248">
<title>Purpose</title>
<p>The purpose of the article is to present a practicable and ethically acceptable approach to the assessment of intervention effects in impact evaluation. Our approach involves <italic>methodological triangulation</italic>. It combines three distinct designs, which investigate the cause–effect issue: namely <italic>shadow controls, generic controls</italic> and <italic>process tracing</italic>. When these three approaches are combined they provide more reliable cause–effect findings than when only one approach is employed. This is a mixed-method design (see e.g. <xref ref-type="bibr" rid="bibr8-1356389012472248">Fitzpatrick et al., 2004</xref>), in line with the European Evaluation Society’s call for a ‘multiple methods approach’. (This is also supported by <xref ref-type="bibr" rid="bibr14-1356389012472248">Saunders [2011]</xref> cited above.) As such, it is a less demanding and often more feasible approach to public-sector evaluation than experimentalism. While shadow controls and generic controls involve counterfactuals and control groups, process tracing is a ‘one-group-only’ design without a control group.</p>
</sec>
<sec id="section3-1356389012472248">
<title>Illustration in three parts</title>
<p>We exemplify how the triangulation approach might be applied by drawing on evaluative studies that have been carried out in a real-world cluster organization made up of private companies. The cluster organization, named <italic>Compare</italic>, is located in the County of Värmland (<italic>Värmlands län</italic>) in North Mid Sweden. We have called our approach Measuring Cluster Effects through Triangulation − MCET for short − to reflect this setting. Before elaborating on the approach, we clarify the term ‘cluster organization’.</p>
<sec id="section4-1356389012472248">
<title>What is a cluster organization?</title>
<p>As early as 1991, the Kellogg Foundation had already identified a need to define a cluster organization (<xref ref-type="bibr" rid="bibr18-1356389012472248">Worthen and Schmitz, 1997</xref>: 304). The term can be somewhat ‘slippery’; however, in this article the term <italic>cluster organization</italic> is defined minimally as <italic>a social arrangement characterized by the following properties</italic>:</p>
<list id="list1-1356389012472248" list-type="bullet">
<list-item><p>coordinating a set of multiple companies in an industry or a sector; and</p></list-item>
<list-item><p>having the objective of supporting increased sales, as well as innovations among the member companies.</p></list-item></list>
<p>In addition this particular case is a formal organization with the following properties:</p>
<list id="list2-1356389012472248" list-type="bullet">
<list-item><p>being a legal entity;</p></list-item>
<list-item><p>having a board and an administrative unit;</p></list-item>
<list-item><p>working within a specific geographical area.</p></list-item></list>
<p>As stated earlier, our understanding and definition of a cluster organization is a <italic>minimal</italic> one (i.e. the smallest set of features a cooperation arrangement should include in order to be called a cluster organization). In our general definition we have not further specified what ‘multiple companies’ means. This may, for example, include cooperation with organizations or actors of different types (e.g. in this case from academia and/or the public sector). However, this is not a precondition for being defined as a cluster organization.</p>
<p>In our understanding, a formal cluster organization must include a board and an administrative unit. The administrative unit might be one person only (e.g. a process leader, or an employee director). It could also be a larger body (for more on clusters, see <xref ref-type="bibr" rid="bibr15-1356389012472248">Sölvell, 2009</xref>).</p>
</sec>
<sec id="section5-1356389012472248">
<title>Impact evaluation: A clarification</title>
<p>In evaluative studies of causality it is important to determine precisely what is taken to be the intervention and what is taken to be the outcome potentially produced by the intervention (i.e. its impacts or effects). In our case illustration, we want to demonstrate how a cluster organization’s activities may impact upon the well-being of its members (i.e. the cluster of companies). The activities of the cluster organization are therefore regarded as the ‘intervention’; and the performance of its members (i.e. the companies) is regarded as the potential outcome. Admittedly, company performance is a wide-ranging term. Without delving too deeply into its meaning, it might be specified as company performance in terms of growth, sales and efficient use of resources, but also investments, innovation capacity, competiveness, recruitment of employees, and R&amp;D collaboration with academia. While insufficient for serious empirical research, this specification is sufficient to illustrate the general thrust and logic of a method, which is our intention here.</p>
<p>For reasons of practical convenience, we chose to illustrate our argument empirically using a cluster organization, more specifically selecting the case of the <italic>Compare</italic> cluster organization, and its effects on the success of its regional member companies. The MCET design has been developed and piloted in this particular domain in this part of Europe. Another reason is that regional development through cluster organizations and clusters is the subject of enormous efforts by both the European Union and its member states, and is therefore of considerable practical importance. Nevertheless, it is crucial to state from the outset that the MCET is conceived as a general design for the assessment of causal impact and is potentially applicable in many policy areas, even though the MCET is still under-developed.</p>
</sec></sec>
<sec id="section6-1356389012472248">
<title>Successive steps in the MCET</title>
<p>The MCET combines three different designs: starting with shadow controls, continuing with generic controls, and concluding with process tracing.</p>
<sec id="section7-1356389012472248">
<title>Shadow controls</title>
<p>The first step in our approach, shadow controls, involves inviting individuals with special insights to estimate the net outcome of an intervention, or more precisely, to estimate which elements of an outcome are at least to some extent generated by the intervention. To start with, statistical and other empirical outcome data relating to targets, both prior to, during and after the intervention, are collected and organized. Second, the actual outcome data thus acquired are compared to the estimates of what would have happened without the intervention (counterfactual reference case) supplied by intervention managers, staff, recipients and other people with supposedly special or privileged information. The experts are asked to project outcomes honestly and to the best of their knowledge. The differences between actual outcome data and estimated counterfactual outcome data are taken to provide some indication of intervention impact. Alternatively, individual informants can be asked to estimate impacts directly based on available empirical information, their own theoretical insights and their knowledge and experiences from similar cases.</p>
<p>One should bear in mind that intervention impact may refer to indirect/direct, positive/negative, partial/complete, and intended/unintended consequences (effects) of the intervention.</p>
<p>Our illustration of how the shadow controls component of our suggested triangulation approach might work is drawn from a series of investigations in which individuals with special insights were defined as the leaders of the companies forming the <italic>Compare</italic> cluster organization. In this case, a survey containing relevant causality questions was administered to the managers of the companies in the cluster organization. The questions centred on <italic>if</italic> and <italic>how</italic> the current growth of the company might be attributed, at least partially, to the fact that the company is and has been a member of the cluster organization.</p>
<p>While providing some clues on intervention impact, the shadow controls procedure elicits the views of people with special knowledge only. Their views may be biased. They may exaggerate impacts. They may miss some impacts. In order to say something about intervention impacts that is more solidly grounded, this data must be supplemented with other data. In the MCET, generic controls and process tracing are intended to fulfil these supplementary functions.</p>
</sec>
<sec id="section8-1356389012472248">
<title>Generic controls</title>
<p>Like shadow controls, the second step in our tripartite approach, generic controls, involves working with one, or several, groups that are compared to the target group. These control groups are constructed in a rather specific way: before-after outcome scores for the intervention’s target group are contrasted to typical, or average, before-after outcome data for (reasonably equivalent) reference groups not affected by the intervention and to which the target group could potentially belong.</p>
<p>The collated outcome data from generic controls is usually of a quantitative, statistical nature. This strengthens the qualitative clues on intervention impact obtained from the shadow controls data. However, the generic controls data only highlights covariation, not causal direction from intervention to outcome. It is to be more specific about intervention impact that justifies the third step in the evaluation process, namely process tracing.</p>
</sec>
<sec id="section9-1356389012472248">
<title>Process tracing</title>
<p>Process tracing requires careful mapping of implementation by the evaluator of how the intervention unfolds step by step in its actual context. The evidence is selected and analysed in the light of research questions from the investigator and works as a descriptive component by providing snapshots at a series of specific moments (<xref ref-type="bibr" rid="bibr6-1356389012472248">Collier, 2011</xref>). In order to find out the extent to which the intervention influences outcomes, intervention implementation – including intermediary and target group responses as well as contextual factors – is studied in order to discover and establish factors and generative mechanisms in the implementation chain that have or have not, at least to some extent, been causal drivers.</p>
<p>Process tracing, as the third tenet of the MCET approach, proceeds in two stages. First, the raw theory of action embedded in the actual intervention is teased out, clarified and organized into a reconstructed intervention theory, showing how, through a series of steps of implementation, the intervention is intended or supposed to contribute, at least to some extent, to desired (or not desired) outcomes. Second, the reconstructed intervention theory is used as a hypothesis or guiding instrument to find out empirically whether there is some causal connection, however weak, between the intervention and (some parts of) the outcomes (<xref ref-type="bibr" rid="bibr1-1356389012472248">Bennett, 2010</xref>; <xref ref-type="bibr" rid="bibr6-1356389012472248">Collier, 2011</xref>). Process tracing is used to clarify the direction and strength of the causal sequence over time. It is used to identify tipping points (windows of opportunity) in the process and isolate items of evidence tested against the reconstructed intervention theory. The use of process tracing thus complements other designs offering a way of describing the causal chain from the intervention to the possible outcomes.</p>
<p>In contrast to shadow controls and generic controls, no comparison group is involved in a process-tracing design. It involves the careful study of a single case only. One further difference is that the implementation activities are traced step-by-step in detail from intervention adoption via outputs through outcome (hence the name <italic>process tracing</italic>). Provided the evaluator can demonstrate empirically that the various steps of the implementation process causally link the intervention to some parts of the outcome, and simultaneously demonstrate that other present factors do not, the intervention might be said to have caused these outcomes. The evaluator is aided in tracing the process by a reconstructed theory of the intervention embedded in the intervention itself (an intervention theory or programme theory; <xref ref-type="bibr" rid="bibr4-1356389012472248">Chen 2005a</xref>, <xref ref-type="bibr" rid="bibr5-1356389012472248">2005b</xref>; <xref ref-type="bibr" rid="bibr10-1356389012472248">McLaughlin and Jordan, 1999</xref>).</p>
</sec></sec>
<sec id="section10-1356389012472248">
<title>Case illustration: The MCET design applied to the <italic>Compare</italic> ICT cluster organization activities</title>
<p>We argue that MCET shows positive indications of being able to elucidate cause and effect in the field of public funds utilization in innovation projects (<xref ref-type="bibr" rid="bibr3-1356389012472248">Bjurulf and Vedung, 2009</xref>). As stated in the introduction, there are other approaches to evaluating intervention impact, contribution analysis being the most recent and promising. In the field of innovation through cluster organization activities, however, we argue that MCET is a reasonably promising option although it has been adopted and used for a rather short period of time and only in three regions in North Mid Sweden.</p>
<p>In North Mid Sweden the Regional Development Councils of <italic>Region Värmland, Region Dalarna</italic> and <italic>Region Gävleborg</italic> are working together in the so-called SLIM project (Systemledning för innovativa miljöer och klusterprocesser i norra Mellansverige [<italic>Systems Management for Innovative Platforms and Cluster Organizations in North Mid Sweden</italic>]). The Project aims to support the development of cluster organizations. The counties where the three regional development councils act have in total approximately 750,000 inhabitants. A regional development council is a political organization that is managed by politicians appointed by municipal and county councils (<italic>kommunfullmäktige, landstingsfullmäktige</italic>) with public officials administering the decisions taken by the politicians. The purpose of a development council is to set priorities for the enhancement of innovation and regional growth within its area. Forming one of eight NUTS regions (Nomenclature of Units Territorial for Statistics – a EUROSTAT regional designation) in Sweden, the three development councils together receive €170 million from the European Regional Development Fund to stimulate the start of 3000 new companies and the creation of 6000 new jobs between 2007 and 2014. Another €170 million is expected as national cofinancing for the period, making a total of €340 million. The SLIM project includes 15 cluster organizations comprising around 700 companies with approximately 60,000 employees.</p>
<p>Our specific case illustration, the <italic>Compare Foundation</italic>, is located in the County of Värmland (<italic>Värmlands län</italic>) in North Mid Sweden. Founded in 2000, <italic>Compare</italic> has recruited 100 information and communication technology (ICT) member companies, with approximately 3000 employees. Of these, around 80 per cent work in small- to medium-sized companies and the remaining 20 per cent in units belonging to larger companies or groups whose main operations take place in other regions and/or countries.</p>
<p>The purpose of the <italic>Compare</italic> cluster organization is to create economic growth in the ICT sector by working in four areas: business development, entrepreneurship, research and education, and membership services. The objective is to increase the innovation capacity, growth and competitiveness of the member companies by encouraging collaboration with other actors (i.e. companies, universities and public-sector agencies). The <italic>Compare</italic> organization also runs the <italic>Compare Test Laboratory</italic>, founded in 2007, and which is at the time of writing one of Sweden’s most advanced centres for independent software testing.</p>
</sec>
<sec id="section11-1356389012472248">
<title>The shadow controls component</title>
<p>As stated above, the shadow controls component of our three part method involves inviting individuals with supposedly privileged knowledge to estimate the impact of an intervention. Region Värmland has commissioned a series of studies conducted by the Ramböll Management consulting firm from which we draw our illustration of how this component can be applied (<xref ref-type="bibr" rid="bibr12-1356389012472248">Region Dalarna et al., 2009</xref>). The individuals with privileged knowledge were identified as the CEOs of each member company of the <italic>Compare</italic> organization. These managers were asked to respond to a questionnaire containing causally pertinent questions (i.e. the shadow controls component in this illustration is based on a self-assessment exercise).</p>
<sec id="section12-1356389012472248">
<title>The data collection methodology used in the shadow controls exercise</title>
<p>The self-assessment survey has been carried out annually since 2006. It is a web-based questionnaire consisting of approximately 40 questions to be answered by the CEOs of each member company. The questions concern four different types of measures carried out by the <italic>Compare</italic> cluster organization:</p>
<list id="list3-1356389012472248" list-type="bullet">
<list-item><p>Activities intended to promote increased sales for member companies;</p></list-item>
<list-item><p>Activities intended to promote the development of staff competence within the current organization and for the future recruitment of trained staff in the ICT sector in collaborations with academics and other participants from nearby Karlstad University in order to develop and launch suitable programmes and courses and facilitate student recruitment to these courses;</p></list-item>
<list-item><p>Activities intended to promote enhanced member company innovation capacity and competitiveness by research cooperation and joint agreements with research departments such as the Department of Computer Sciences at Karlstad University; and</p></list-item>
<list-item><p>Activities intended to promote investment in member companies and to facilitate commercialization of generated ideas in new spin-off companies in the region.</p></list-item></list>
</sec>
<sec id="section13-1356389012472248">
<title>Compare – findings from the shadow controls illustration</title>
<p>The key question guiding our shadow controls illustration is: to what extent and in what ways have the activities of the <italic>Compare</italic> cluster organization contributed to growth and competitiveness of the member companies?</p>
<p>The answers from the above-mentioned Ramböll surveys conducted between 2006 and 2009 indicate that around 40 per cent of the <italic>Compare</italic> member companies stated that they increased their sales as a result of their membership. This figure was constant over the four-year period. In 2009, around 30 per cent of the respondents stated that they had increased the number of employees (20% in the 2006 measurement), and around 10 per cent of the companies cut their costs as a result of the membership. The increase in investments, as a result of membership in <italic>Compare</italic>, varied over the time period examined, as illustrated in <xref ref-type="fig" rid="fig1-1356389012472248">Figure 1</xref> from less than 10 per cent to more than 20 per cent (<xref ref-type="bibr" rid="bibr12-1356389012472248">Region Dalarna et al., 2009</xref>).</p>
<fig id="fig1-1356389012472248" position="float">
<label>Figure 1</label>
<caption>
<p>The contribution of <italic>Compare</italic> membership to company growth.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig1.tif"/></fig>
<p>After 2007, a large proportion of the respondent companies stated that their <italic>Compare</italic> membership contributed to increased innovation capacity and competitiveness, meaning that new products and services were developed as a result of cluster organization membership. The percentage increased from 40 per cent for 2006 to between 60−80 per cent for 2007 through 2009 (see <xref ref-type="fig" rid="fig2-1356389012472248">Figure 2</xref>).</p>
<fig id="fig2-1356389012472248" position="float">
<label>Figure 2</label>
<caption>
<p>Estimated increased innovation capacity and competitiveness as a result of being a member of <italic>Compare</italic>.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig2.tif"/></fig>
<p>In addition, the surveys showed that CEOs of the responding companies asserted strongly that collaboration with other member companies, which is encouraged and promoted by the <italic>Compare</italic> organization, was likely to increase their competitiveness further in the future. This view, that improved collaboration between the member companies would be beneficial, increased between 2008 and 2009 (see <xref ref-type="fig" rid="fig3-1356389012472248">Figure 3</xref>).</p>
<fig id="fig3-1356389012472248" position="float">
<label>Figure 3</label>
<caption>
<p>Areas in which increased collaboration among member companies may benefit company competitiveness.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig3.tif"/></fig>
<p>A majority of the respondents stated that membership of the <italic>Compare</italic> cluster increased their company’s activities within the area of R&amp;D. This is especially significant in relation to the collaboration with universities and industrial research institutes; however, it also highlights obvious concerns in relation to collaboration with other companies as illustrated in <xref ref-type="fig" rid="fig4-1356389012472248">Figure 4</xref>.</p>
<fig id="fig4-1356389012472248" position="float">
<label>Figure 4.</label>
<caption>
<p>Increased R&amp;D activities as a result of Compare membership.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig4.tif"/></fig>
</sec>
<sec id="section14-1356389012472248">
<title>Conclusions from the shadow controls illustration</title>
<p>A majority of the companies that responded to the survey maintained that membership of the <italic>Compare</italic> cluster (and accompanying cluster activities), contributed to enhanced innovation capacity, and led to both new products and new services. The credibility of their statements is strengthened by their arguments that the collaboration opportunities with other companies as well as prospects to open up new business in home markets are the most important driving forces for continued participation in the cluster initiative. Initially positive effects of membership in the cluster also strengthened the participating companies’ resolve to renew their membership as well as to expand and to intensify their participation in the cluster organization’s activities.</p>
<p>The studies also show that companies have opportunities for personnel recruitment as a result of participation in the <italic>Compare</italic> cluster organization through the competence development and collaboration initiatives with university students. Furthermore, the companies say themselves that this collaboration has also increased partnerships with academia.</p>
<p>In summary, from the self-assessment questionnaires filled out by CEOs we can see that, as a result of their membership in <italic>Compare</italic>, the companies reported:</p>
<list id="list4-1356389012472248" list-type="bullet">
<list-item><p>increased sales by 40 per cent during the period 2006–09;</p></list-item>
<list-item><p>increased investments by about 10 per cent from 2007 to 2009;</p></list-item>
<list-item><p>increased innovation capacity (i.e. development of new products and new services) by 60 per cent from 2007 to 2009;</p></list-item>
<list-item><p>increased employee recruitment by 20 per cent in 2006 which rose to 30 per cent in 2009; and</p></list-item>
<list-item><p>increased R&amp;D collaboration with universities by 30 per cent in 2006 which rose to 50 per cent in 2009.</p></list-item></list>
<p>Overall, participation in the activities of the <italic>Compare</italic> cluster organization appears to have generated very encouraging results for the member companies. However, these favourable findings arose only from the self-assessment of those with potentially relevant knowledge. Does this general picture hold when we triangulate these findings with information from generic controls? Furthermore, it is hard to appraise whether the activities and other properties of a cluster organization might possibly release other forms of creativity and innovation in participating member companies. However, we believe that process tracing can provide us with some clues regarding this important issue.</p>
</sec></sec>
<sec id="section15-1356389012472248">
<title>The generic controls component</title>
<p>The generic controls component is the second step in our tripartite methodological approach for assessing intervention effectiveness. In generic controls, the basic measurement is carried out on the group targeted by the intervention. These data are then contrasted with the findings from supplementary measurements carried out on one or more reference groups that are considered reasonably comparable, but which are not exposed to the intervention.</p>
<p>In the case of <italic>Compare</italic>, the basic measurement is performed on the group of companies that are members of the <italic>Compare</italic> cluster organization. A reference case (control group, counterfactual case) of companies in the same business sector and operating in the same geographical area, but not members of <italic>Compare</italic>, is used for comparison. Therefore, the findings gleaned from these two sets of measurements should indicate covariation between cluster membership and company performance (in this case company growth). This, in turn, may provide information concerning the impact on company growth from being a member of <italic>Compare</italic>.</p>
<sec id="section16-1356389012472248">
<title>The generic controls component and the simpler methodology</title>
<p>The measurements were carried out using the ‘Simpler Methodology’ (<xref ref-type="bibr" rid="bibr9-1356389012472248">Grufman, 2001</xref>). The Simpler Methodology was developed by a Swedish consulting firm, Grufman Reje Management AB, as a device for measuring the efficiency of a group of companies, a single company or a part of a company. In our illustration, the ‘Simpler’ method appraises how efficiently a group of companies uses its available resources (i.e. personnel and/or capital) and how that efficiency evolves over time.</p>
<p>The starting point is company turnover, that is to say the total sales within a time-period, normally one year. Procurements required to produce the sales are subtracted, as are depreciations (i.e. the decrease in value of all investments made in the company, such as machinery). The result gives the value added, which should also cover costs for personnel and for capital (which includes interests and owner’s profit, i.e. shareholders’ dividend). If the value added exceeds the costs of capital and personnel, the company generates pure (net) profit. Adding the costs of personnel to capital costs and then dividing the result with the value added yields the ‘Grufman Reje index’ value.</p>
<p>If the index value equals one, the company is profitable (i.e. it can pay salaries, interest on loans and provide shareholders [owners] a return on investments). If the Grufman Reje index value is greater than one (i.e. the value added is less than the sum of the cost of capital and the cost of personnel), the company is not efficient and should reduce its costs (e.g. rationalize capital flow or reduce personnel). If, on the other hand, the value added is greater than the sum of capital and personnel costs (i.e. a Grufman Reje index of less than one), then the company is using its resources efficiently and is extra profitable. This is illustrated in <xref ref-type="fig" rid="fig5-1356389012472248">Figure 5</xref> below. The X axis in the figure represents the cost of capital divided by the value added whereas the Y axis represents the cost of personnel divided by the value added. This means that the straight line represents a Grufman Reje index equal to one (illustrating a standard profitable company). The area to the left of this line represents highly efficient companies generating extra profits, while the area to the right indicates unprofitable companies with low efficiency.</p>
<fig id="fig5-1356389012472248" position="float">
<label>Figure 5</label>
<caption>
<p>The Grufman Reje Index.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig5.tif"/></fig>
<p>Resource utilization of the companies in this group can be studied by following the change in the Grufman Reje index for a group of companies over time.</p>
</sec>
<sec id="section17-1356389012472248">
<title>Findings from the generic controls illustration</title>
<p>Grufman Reje Management AB studied the development of ICT companies in County Värmland in North Mid Sweden in the period between 2001 and the end of 2009. The study’s aim was to analyse whether there are any differences in the development of companies that are members of the <italic>Compare</italic> cluster organization and those of similar companies that are not.</p>
<p>The study focused on two groups of ICT companies, all of them registered and operating within County Värmland: one group consisted of companies that were members of the <italic>Compare</italic> cluster organization; the other group of companies that were not. The second group of companies was referred to as the comparison group.</p>
<p><xref ref-type="fig" rid="fig6-1356389012472248">Figure 6</xref> illustrates the development of the value added for the two groups. In contrast to the baseline year (2001), during the period studied, the <italic>Compare</italic> cluster companies increased their value added by more than 160 per cent, whereas the comparison group increased value added only by approximately 60 per cent.</p>
<fig id="fig6-1356389012472248" position="float">
<label>Figure 6</label>
<caption>
<p>Percentage increase in value for Compare ITC companies compared to a reference group (base year 2001).</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig6.tif"/></fig>
<p>In order to provide a more holistic understanding, the consolidated growth percentage for all companies operating within County Värmland as a whole has been included in <xref ref-type="fig" rid="fig6-1356389012472248">Figure 6</xref>. This shows that during the same time period, 2001−09, the figure was less than 25 per cent.</p>
<p>The Grufman Reje index highlights some very interesting results. As a group, the <italic>Compare</italic> member companies have shifted from an index value of 1.1 (indicating a less efficient group of companies) in 2001 to a value of 0.97 (indicating a more efficient group of companies) in 2009. Contrast this result with that of the reference group companies that have remained static at the same index value of 1.08, and demonstrate no change between 2001 and 2009.</p>
<p>In financial terms, the <italic>Compare</italic> companies have increased their annual pure profits from minus SEK 46 million in 2001 to plus SEK 41 million in 2009 (i.e. a total increase of SEK 87 million). The reference group companies, on the other hand, declined in the same period from minus SEK 52 million to minus SEK 75 million. If one accumulates each year’s profit during the period 2001–09, the result would be plus SEK 49 million for the <italic>Compare</italic> companies and minus SEK 541 million for the reference group companies.</p>
<p>For the <italic>Compare</italic> companies there was a breakthrough in 2005: the year when the <italic>Compare</italic> group reached a value index of less than 1 on the Grufman Reje index. This meant that in 2005 they became an efficient group of companies with positive additional profits. By totalling the additional profit for the group between 2005 and 2009 the result is profits of SEK 446 million in contrast to the loss of SEK 324 million for the reference group. This is illustrated in <xref ref-type="fig" rid="fig7-1356389012472248">Figure 7</xref>, where black is the annual pure profit for <italic>Compare</italic> member companies and dark grey illustrates the pure loss for reference group companies.</p>
<fig id="fig7-1356389012472248" position="float">
<label>Figure 7.</label>
<caption>
<p>Annual pure profits 2005−09: Compare members and reference group companies.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig7.tif"/></fig>
</sec></sec>
<sec id="section18-1356389012472248">
<title>The process-tracing component</title>
<sec id="section19-1356389012472248">
<title>Process tracing and general findings on the causal chain</title>
<p>Interviews were carried out in the course of the SLIM project (<xref ref-type="bibr" rid="bibr2-1356389012472248">Bjurulf, 2010</xref>). The interviewees generally described the <italic>Compare</italic> cluster organization as a catalyst for linking together hitherto dispersed talents and creating cross-company teams that transformed problems into opportunities, projects and investments.</p>
<p><disp-quote>
<p>An important part of the role <italic>Compare</italic> plays is to link different talents. The management of <italic>Compare</italic> is also good at connecting different entrepreneurs with each other. (Respondent #1)</p>
<p>The <italic>Compare</italic> cluster manager has a special talent for communicating and convincing other people to see future opportunities using trends, changes and strategic information to put together company teams and transform problems and opportunities into business projects toggling engagement and investments. (Respondent #5)</p>
</disp-quote></p>
<p>The interviewees also described how <italic>Compare</italic> had positive effects not only on R&amp;D collaboration and company skills but also in relation to innovations, sales and investments by linking companies, researchers and public actors. This was also identified in the shadow controls and generic controls elements of the evaluation.</p>
<p><disp-quote>
<p>Today the <italic>Compare</italic> Test Lab enables and catalyses different types of business projects that lead to increased sales, which we did not know when we started to implement the idea. (Respondent #2)</p>
<p>In the end the <italic>Compare</italic> Test Lab led to the establishment of large companies in the region. (Respondent #5)</p>
<p>The number of new jobs that have been developed as a result of the <italic>Compare</italic> Test Lab [and its activities] can be viewed in two ways. Directly there is a team of 5−10 people working at the Lab. But it also brings people and companies from various parts of the world together to test new products and services in the region. (Respondent #4)</p>
</disp-quote></p>
<p>As previously mentioned, the <italic>Compare</italic> cluster organization runs the <italic>Compare</italic> Test Laboratory. Founded in 2007, the <italic>Compare</italic> Test Lab is one of Sweden’s most advanced centres for independent software testing. The <italic>Compare</italic> Test Lab was built by Stockholm-based Coromatic AB, a business corporation that constructs, hosts, and supports computer centres and runs businesses in Sweden, Norway and Denmark. During the construction of the <italic>Compare</italic> Test Lab, Coromatic learned about the <italic>Compare</italic> cluster organization and became a member of it. Coromatic established a branch in the region, and as a result strengthened ICT competence within <italic>Compare</italic>. Coromatic plays an important role in our example of the causal chain from an idea to a new series of innovations in the market.</p>
<p><xref ref-type="fig" rid="fig8-1356389012472248">Figure 8</xref> illustrates the intended role of the <italic>Compare</italic> cluster organization and the <italic>Compare</italic> Test Lab in connecting companies and working interactively with them in a successive series of steps in order to encourage them to develop new products (goods and services) and market them. It reveals the intended intervention theory inherent in <italic>Compare</italic>. In process tracing, the evaluator collects actual empirical data to assess whether individual cluster processes follow the pattern shown in the intervention theory all the way down to innovative products sold in the market place or whether they diverge from the intended intervention theory.</p>
<fig id="fig8-1356389012472248" position="float">
<label>Figure 8.</label>
<caption>
<p>Compare cluster organization – intended intervention theory: causal chain of Compare activities from member company problem to increased company sales.</p>
</caption>
<graphic xlink:href="10.1177_1356389012472248-fig8.tif"/></fig>
<p>With regard to <xref ref-type="fig" rid="fig8-1356389012472248">Figure 8</xref>, the following describes further the intended steps in the process.</p>
<list id="list5-1356389012472248" list-type="order">
<list-item><p>The starting point is a problem identified by a <italic>Compare</italic> member company. If the problem is considered too complex for the company to solve by itself, the <italic>Compare</italic> cluster organization is contacted for support. After a clarifying dialogue with the initiator company, the Compare project manager attempts to determine whether the suggested problem falls inside or outside the cluster organization’s area of competence. If it falls outside, the process stops here; if it falls within, the process continues. Now the project manager tries to understand which specific competencies are relevant and important. It is crucial to identify and attract these competencies that exist in the member companies and persuade them to invest time in the project.</p></list-item>
<list-item><p>The project manager contacts potential sub-suppliers (other member companies) and researchers from Karlstad University with expertise that may be relevant for solving the problem. He investigates opportunities to attract funds and attempts to map potential customers of the planned product. It is necessary to identify potential customers as they may be the first purchasers and in that capacity become the early adopters who develop as trendsetters and spread the message to other customers. Again, if he does not succeed with this, the process stops here, but if he succeeds, a project group is formed. Compare and its project coordinator acts as a project owner in tackling the pertinent problem. The project members, led by a project manager from Compare, create a plan for the development process. Attempts are made to generate a solution of the problem, for example, a new product that may be tested and marketed.</p>
<p>Project work leads to a preliminary product.</p></list-item>
<list-item><p>The preliminary product is tested in a pilot trial. The trial is led by the <italic>Compare</italic> project manager together with the project group, and involves potential product customers and potential early product adopters identified by <italic>Compare</italic>.</p></list-item>
<list-item><p>All participants evaluate the pilot test. The project group determines the need for any further improvements.</p></list-item>
<list-item><p>A second test is conducted, on the improved product. Tests may be arranged at the <italic>Compare</italic> Test Lab or off-site in the market by identified pilot customers (potential purchasers and users of the product, i.e. at different locations). The project manager helps to draw up a business agreement clarifying the legal aspects and intellectual property rights. The companies decide how to proceed together.</p></list-item>
<list-item><p>On the basis of the new product, the companies develop a business strategy and a plan for the market introduction in which they invest their own capital. The companies then start offering the product on the market.</p></list-item>
<list-item><p>The first product is sold in the market.</p></list-item></list>
</sec>
<sec id="section20-1356389012472248">
<title>Process-tracing conclusions</title>
<p>The findings of the process-tracing section of the impact evaluation, in the <italic>Compare</italic> case indicate outcomes with respect to increased sales, investments and recruitment. Informed by statements from various participating actors, these findings can be traced stepwise to activities of the <italic>Compare</italic> cluster organization.</p>
<p>The case illustration in <xref ref-type="fig" rid="fig8-1356389012472248">Figure 8</xref> describes the added value of tracing the chain. The value gained by the member company and other companies includes new products, which, in turn, enhance business opportunities and competitiveness of the companies concerned. As an additional benefit, academic researchers can benefit from working with real-life problems thereby strengthening their interactions and collaboration with the surrounding community and increasing the quality of their research.</p>
</sec></sec>
<sec id="section21-1356389012472248">
<title>Summary of the three-steps illustration</title>
<p>From the findings from the shadow controls procedure, evaluators can learn that membership of the <italic>Compare</italic> cluster organization is associated with very favourable outcomes for member companies. This might, at least partially, be an effect of <italic>Compare</italic> activities. Nevertheless, in relying on the judgements of knowledgeable people only, shadow controls always run the risk of producing biased or exaggeratedly positive findings on main effects or overlooking important potential positive or negative side effects. Therefore they should be supplemented by findings from the generic controls design. In our case illustration, these findings pinpoint a substantial difference between the <italic>Compare</italic> member companies and the control group (i.e. non-member companies). The former have increased their value added by more than 160 per cent whereas the latter have increased only by about 60 per cent. Again, there seems to be a positive association, or co-variation, between membership of <italic>Compare</italic> and a positive outcome. This association might be spurious, yet it seems likely that <italic>Compare</italic> activities may have, in one way or another, caused the outcome.</p>
<p>In order to further clarify the prevalence, strength and direction of possible causal linkages between the intervention (the <italic>Compare</italic> cluster organization activities) and outcome effects (company performance, seen here as positive value added and profitability in the member companies), a process-tracing procedure was adopted. The process-tracing element in this case was undertaken through in-depth interviews with five respondents. The information elicited from these interviews demonstrated that the positive outcomes are associated with <italic>Compare</italic>-induced activities that support its member companies. The outcomes are due to processes in which <italic>Compare</italic> matches competencies and thus makes it easier and quicker for actors to find collaborating partners. The result is that these partners are able to develop knowledge and products that can be taken to market more easily. In this way the positive outcomes elicited through the combined shadow controls and generic controls are further substantiated. By process tracing we have been able to unpick the causal chain step-by-step and understand why the <italic>Compare</italic> cluster organization’s activities make a difference for its member companies. In summary, this highlights the benefit of using the MCET evaluation design, namely that it can identify and substantiate the consecutive links of causal paths through which a given intervention (in this case, the activities of a cluster organization) makes a difference for its targets (the performance of its member companies).</p>
</sec>
<sec id="section22-1356389012472248">
<title>The MCET approach: Strengths and weaknesses</title>
<p>To determine whether interventions achieve their intended outcome and create side-effects involves addressing the causality issue: the challenge of producing reliable cause–effect findings in impact evaluation. The purpose of the present article has been to suggest a methodological alternative to experimental approaches<sup><xref ref-type="fn" rid="fn1-1356389012472248">1</xref></sup> to shed light on this issue. The approach suggested is the <italic>MCET approach</italic>, a three-step design developed, tested and refined as an evaluation tool in the field of regional innovation policy in County Värmland in North Mid Sweden. The method involves combining shadow controls, generic controls and process tracing in this specific order. While each of the three designs involved are well-known features of the standard tool kit suggested in evaluation literature, the novelty of the MCET approach lies in their combination, together with the order in which the three designs are combined.</p>
<p>The <italic>strength</italic> of the MCET approach to the establishment of social-intervention impacts resides in the triangulation of a trio of evaluative designs that are usually kept separate. The triangulation idea is not new in evaluation or in applied social research. To the best of our knowledge, however, no triangulation of designs for impact assessment has hitherto been devised and proposed.</p>
<p>The triangulation approach proposed here is progressive. It starts with shadow controls which provide soft data interpretations of what would have happened without the intervention. This can be used for studying similarities and differences with other data sets relating to factual outcomes and these findings can provide input for reasoning about probable effects. This reasoning can be further substantiated by findings from the application of the generic controls design to the same situation. Generic controls moves towards a deeper empirical understanding by generating one or more theoretically constituted reference groups. Process tracing further reinforces available findings on intervention impact by providing detailed information on causal linkages and causal mechanisms between the adoption of the intervention and the actual outcome. This is achieved by formulating the intended intervention theory inherent in the activities of the cluster organization that shows how these activities might contribute to increased sales and innovation capacity among its member companies. Using data provided by different informants and other data collection methods enables the evaluator to determine whether the processes in at least some instances follow those of the intervention theory. It is also possible to investigate whether there is a causal sequence from the intended intervention to the possible outcome in terms of increased sales and greater innovative capacity among the member companies. The process-tracing component provides the possibility of matching and contrasting the evidence against the intended intervention theory. In this way process tracing will yield insights into the causal mechanisms (<xref ref-type="bibr" rid="bibr6-1356389012472248">Collier, 2011</xref>). This underlines the importance of performing careful, detailed, systematic analyses of the various potential consecutive linkages in real-world implementation chains.</p>
<p>In combination, the three designs provide a progressive and deepening understanding of intervention impacts and the various linkage mechanisms in the causal chain between intervention and outcomes. Therefore, it may be argued that the three designs applied in concert provide far greater validity for findings about intervention effects than any one of them can on its own.</p>
<p>However, there are <italic>weaknesses</italic> with the MCET approach. First, it is resource-intensive in terms of time, competence and money, as three methodological designs are combined. It can only be used when time constraints are less tight, when experienced evaluators and researchers are available, and when sufficient funds are provided. Because of this, the approach is likely to be most suitable for programmes where substantial public funds are involved, as is the case with large EU-funded programmes; and when private companies can see real and direct benefits.</p>
<p>The MCET approach has only been tried out over the last five years and is therefore at an early stage of development. Furthermore, it has only been tested in Sweden and may well pose a significant challenge to adapt the method to the circumstances and cultures of other parts of the European Union.</p>
</sec>
<sec id="section23-1356389012472248" sec-type="discussion">
<title>Discussion: Ways of developing the MCET approach for impact assessment</title>
<p>Establishing a relationship between cause and effect is an enduring issue and naturally our proposed approach will not constitute the last word. There are several alternative methodological designs that may provide equally adequate ways of evaluating impact as the approach we have developed. Relevant literature on contribution analysis, attribution analysis, and other proposed solutions to the issue has not hitherto been used to deepen and develop the MCET (<xref ref-type="bibr" rid="bibr11-1356389012472248"><italic>Evaluation</italic> [2012]</xref> special issue 18[3]; <xref ref-type="bibr" rid="bibr11-1356389012472248">Mayne, 2012</xref>). Another obvious direction to pursue would be to better integrate the intervention-theory idea more fully (theory-driven approaches, logic-model thinking; <xref ref-type="bibr" rid="bibr4-1356389012472248">Chen 2005a</xref>, <xref ref-type="bibr" rid="bibr5-1356389012472248">2005b</xref>; <xref ref-type="bibr" rid="bibr10-1356389012472248">McLaughlin and Jordan, 1999</xref>). A somewhat more-determined use of the intervention-theory idea might make the process-tracing component more focused, reliable, simple, and less resource-demanding. There is also a lively discussion outside the field of evaluation on process tracing which should obviously be studied (<xref ref-type="bibr" rid="bibr1-1356389012472248">Bennett 2010</xref>, <xref ref-type="bibr" rid="bibr6-1356389012472248">Collier 2011</xref>).</p>
<p>This approach could be further developed in the direction of cost-efficiency and cost-effectiveness studies. Efficiency studies have been undertaken in the SLIM project with which the <italic>Compare</italic> cluster organization evaluation efforts are associated. During the period between 2005 and 2009 approximately €500,000 was invested in <italic>Compare</italic> by its member companies. This investment was generated through membership fees. During the same period, findings from generic controls suggest that its member companies have benefited to the tune of approximately €77 million in contrast to the comparison group of non-member reference companies. Findings from shadow controls indicate that 40 per cent of the companies state that their <italic>Compare</italic> membership has contributed to increased sales. An estimate of the impact is €30 million (0.4 x 77,000,000), this for the period 2005–09. This relates to the issue identified by <xref ref-type="bibr" rid="bibr17-1356389012472248">White (2010)</xref>, as well as many others, that impact analysis should be used for investigation of cost-effectiveness. From a company perspective, using the figures above, a rate of return of 60 times the combined membership investment through fees is a significant, positive rate of return. The process-tracing component indicate that there is evidence to suggest that the <italic>Compare</italic> cluster organization has contributed to increased sales and enhanced innovative capacity among its member companies. Nevertheless, there remain many uncertainties that require further investigation to demonstrate a clear link between the intervention and the possible outcome including eliminating other possible explanations of the improved performance of <italic>Compare</italic> cluster companies.</p>
</sec>
</body>
<back>
<ack><p>The research for this article has been financed by (1) the European Regional Development Fund (ERDF), 2) the Swedish Agency for Economic and Regional Growth (Tillväxtverket, Stockholm) and its ongoing evaluation and interactive research on the eight Swedish ERDF programmes, and (3) Region Dalarna, Region Gävleborg, and Region Värmland. Two anonymous peer reviewers provided precious comments. Fil dr Wendy Maycraft Kall, the Department of Government, Uppsala University, has done vital English-language checking. Emma Hamilton and Elliot Stern have helped with inestimable editing, clarification and language suggestions. It is a true pleasure for the three of us to extend our cordial thanks to them all. Yet, as always, the responsibility for the content, structure and language of the article rests entirely upon us authors.</p></ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.</p></fn>
</fn-group>
<notes><fn-group>
<fn fn-type="other" id="fn1-1356389012472248">
<label>1.</label>
<p>The MCET approach might also be an alternative to contribution analysis: it is strengthened by its process-tracing element and draws lessons from this. Unfortunately, we have not been able to penetrate contribution analysis sufficiently because our work on the MCET approach commenced well before contribution analysis attracted our attention.</p></fn>
</fn-group></notes>
<bio>
<p>Staffan Bjurulf is a PhD student attached to CTF- Service Science Centre at Karlstad University. He is also employed by Region Värmland.</p>
<p>Evert Vedung is Emeritus Professor of political science at Uppsala University (Gävle and Uppsala). ‘Four waves of evaluation diffusion’ (2010) was published in <italic>Evaluation</italic>.</p>
<p>C. G. Larsson holds a PhD in Physics from Chalmers University in Gothenburg. He is presently working as an evaluator in EU projects as well as project coordinator for projects in developing countries.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>A</given-names></name>
</person-group> (<year>2010</year>) <article-title>Process tracing and causal inference</article-title>. In: <person-group person-group-type="editor">
<name><surname>Brady</surname><given-names>H</given-names></name>
<name><surname>Collier</surname><given-names>D</given-names></name>
</person-group> (eds), <source>Rethinking Social Inquiry</source>, <edition>2nd edn.</edition> <publisher-loc>Lanham, MD</publisher-loc>: <publisher-name>Rowman and Littlefield</publisher-name>, <fpage>207</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr2-1356389012472248">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Bjurulf</surname><given-names>S</given-names></name>
</person-group> (<year>2010</year>) <article-title>Interview material</article-title>. <publisher-loc>Karlstad</publisher-loc>: <publisher-name>Region Värmland</publisher-name>, unpublished.</citation>
</ref>
<ref id="bibr3-1356389012472248">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Bjurulf</surname><given-names>S</given-names></name>
<name><surname>Vedung</surname><given-names>E</given-names></name>
</person-group> (<year>2009</year>) <article-title>Do public interventions for innovation hit their targets? Evaluating cluster organizations in Northern Central Sweden. Presented at the European Union Warsaw Conference</article-title>. URL: <ext-link ext-link-type="uri" xlink:href="http://ec.europa.eu/regional_policy/conferences/evaluation2009/">http://ec.europa.eu/regional_policy/conferences/evaluation2009/</ext-link>.</citation>
</ref>
<ref id="bibr4-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>H-T</given-names></name>
</person-group> (<year>2005a</year>) <source>Practical Program Evaluation: Assessing and Improving Planning, Implementation, and Effectiveness</source>. <publisher-loc>Thousand Oaks, CA and London</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr5-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>H-T</given-names></name>
</person-group> (<year>2005b</year>) <article-title>Program theory</article-title>. In: <person-group person-group-type="editor">
<name><surname>Mathison</surname><given-names>S</given-names></name>
</person-group> (ed.), <source>Encyclopedia of Evaluation</source>. <publisher-loc>Thousand Oaks, CA and London</publisher-loc>: <publisher-name>SAGE</publisher-name>, <fpage>340</fpage>–<lpage>2</lpage>.</citation>
</ref>
<ref id="bibr6-1356389012472248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Collier</surname><given-names>D</given-names></name>
</person-group> (<year>2011</year>) <article-title>Understanding process tracing</article-title>. <source>PS: Political Science and Politics</source> <volume>44</volume>(<issue>4</issue>): <fpage>823</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr7-1356389012472248">
<citation citation-type="other"><collab><italic>Evaluation</italic></collab> (<year>2012</year>) <volume>18</volume>(<issue>3</issue>): <comment>special issue on Contribution analysis</comment>.</citation>
</ref>
<ref id="bibr8-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fitzpatrick</surname><given-names>JL</given-names></name>
<name><surname>Sanders</surname><given-names>JR</given-names></name>
<name><surname>Worthen</surname><given-names>BR</given-names></name>
</person-group> (<year>2004</year>) <source>Program Evaluation: Alternative Approaches and Practical Guidelines</source>, <edition>3rd edn.</edition> <publisher-loc>London</publisher-loc>: <publisher-name>Pearson Education</publisher-name>.</citation>
</ref>
<ref id="bibr9-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Grufman</surname><given-names>A</given-names></name>
</person-group> (<year>2001</year>) <source>Simpler Management: en enklare väg till effektiv företagsstyrning</source> (<source>Simpler Management: An Unassuming Pathway to Efficient Company Direction</source>). <publisher-loc>Stockholm</publisher-loc>: <publisher-name>Ekerlid Förlag</publisher-name>.</citation>
</ref>
<ref id="bibr10-1356389012472248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McLaughlin</surname><given-names>J</given-names></name>
<name><surname>Jordan</surname><given-names>G</given-names></name>
</person-group> (<year>1999</year>) <article-title>Logic models: a tool for telling your program’s performance story</article-title>. <source>Evaluation and Program Planning</source> <volume>22</volume>(<issue>1</issue>): <fpage>65</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr11-1356389012472248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mayne</surname><given-names>J</given-names></name>
</person-group> (<year>2012</year>) <article-title>Contribution analysis: coming of age</article-title>. <source>Evaluation</source> <volume>18</volume>(<issue>3</issue>): <fpage>270</fpage>–<lpage>80</lpage>.</citation>
</ref>
<ref id="bibr12-1356389012472248">
<citation citation-type="book">
<collab>Region Dalarna, Region Gävleborg and Region Värmland</collab> (<year>2009</year>) <source>Made in Sweden, Cluster Cooperation in Northern Central Sweden Assessments</source>. <publisher-loc>Karlstad</publisher-loc>: <publisher-name>Region Värmland</publisher-name>.</citation>
</ref>
<ref id="bibr13-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rossi</surname><given-names>PH</given-names></name>
<name><surname>Freeman</surname><given-names>HE</given-names></name>
<name><surname>Lipsey</surname><given-names>MW</given-names></name>
</person-group> (<year>1999</year>) <source>Evaluation: A Systematic Approach</source>, <edition>6th edn.</edition> <publisher-loc>London</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr14-1356389012472248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Saunders</surname><given-names>M</given-names></name>
</person-group> (<year>2011</year>) <article-title>Capturing effects of interventions, policies and programmes in the European context: a social practice perspective</article-title>. <source>Evaluation</source> <volume>17</volume>(<issue>1</issue>): <fpage>89</fpage>–<lpage>102</lpage>.</citation>
</ref>
<ref id="bibr15-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Sölvell</surname><given-names>Ö</given-names></name>
</person-group> (ed.) (<year>2009</year>) <source>Clusters: Balancing Evolutionary and Constructive Forces</source>. <publisher-loc>Stockholm</publisher-loc>: <publisher-name>Ivory Power Publishers</publisher-name>.</citation>
</ref>
<ref id="bibr16-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vedung</surname><given-names>E</given-names></name>
</person-group> (<year>2000[1997]</year>) <source>Public Policy and Program Evaluation</source>. <publisher-loc>New Brunswick, NJ and London</publisher-loc>: <publisher-name>Transaction</publisher-name>.</citation>
</ref>
<ref id="bibr17-1356389012472248">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>White</surname><given-names>H</given-names></name>
</person-group> (<year>2010</year>) <article-title>A contribution to current debates in impact evaluation</article-title>. <source>Evaluation</source> <volume>16</volume>(<issue>2</issue>): <fpage>153</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr18-1356389012472248">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Worthen</surname><given-names>BR</given-names></name>
<name><surname>Schmitz</surname><given-names>CC</given-names></name>
</person-group> (<year>1997</year>) <article-title>Conceptual challenges confronting cluster evaluation</article-title>. In: <source>Encyclopedia of Evaluation</source>. <publisher-loc>Thousand Oaks, CA and London</publisher-loc>: <publisher-name>SAGE</publisher-name>, <fpage>300</fpage>–<lpage>19</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>