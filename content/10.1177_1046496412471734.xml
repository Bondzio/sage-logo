<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">SGR</journal-id>
<journal-id journal-id-type="hwp">spsgr</journal-id>
<journal-title>Small Group Research</journal-title>
<issn pub-type="ppub">1046-4964</issn>
<issn pub-type="epub">1552-8278</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1046496412471734</article-id>
<article-id pub-id-type="publisher-id">10.1177_1046496412471734</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Accepting Rotation in the Method Prism</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Keyton</surname><given-names>Joann</given-names></name>
<xref ref-type="aff" rid="aff1-1046496412471734">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1046496412471734"><label>1</label>North Carolina State University, Raleigh, NC, USA</aff>
<author-notes>
<corresp id="corresp1-1046496412471734">Joann Keyton, North Carolina State University, Box 8104, Raleigh, NC 27695-8104, USA. Email: <email>jkeyton@ncsu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2013</year>
</pub-date>
<volume>44</volume>
<issue>2</issue>
<issue-title>Special Issue: Research Presented at the 2012 Conference of the Interdisciplinary Network for Group Research</issue-title>
<fpage>212</fpage>
<lpage>216</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Methodological differences among group and team scholars are heightened when scholars submit manuscripts to interdisciplinary conferences and publications. Although multiple philosophical and theoretical frames for the study of group phenomena are often accepted, it seems that scholars are less accepting of methodological differences. This is problematic in that the study of groups and teams is prismatic—wonderfully rich and complex. This article describes some of these types of problems and describes how scholars can bridge methodological differences.</p>
</abstract>
<kwd-group>
<kwd>research methods</kwd>
<kwd>interdisciplinary review</kwd>
<kwd>groups</kwd>
<kwd>teams</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>One does not need to attend but a few conferences at which scholars from several disciplines present their research to identify differing philosophical, theoretical, and methodological assumptions. These effects are heightened when the conference is intended and planned to be an interdisciplinary event. At these events, philosophical and theoretical differences are often more tolerated than methodological differences. But when it comes to methodology our differences are more open to criticism. This criticism can be identified when we ask one another, “What data did you collect?,” “How did you collect that data?,” and “What findings can you develop from your results?” Although we often accept multiple philosophical and theoretical frames for the study of group phenomena, it seems to me that we are less accepting of methodological differences.</p>
<p>Obviously, we are products of our training and exposure, and those foundational educational experiences (i.e., courses we chose to take or not) create a frame for evaluating one’s own and others’ scholarship. At a conference such as INGRoup, we can agree that groups and teams are the focal point of scholarship. But a group or team provides many methodological entry points. We can study</p>
<list id="list1-1046496412471734" list-type="bullet">
<list-item><p>individuals across teams,</p></list-item>
<list-item><p>individuals within teams,</p></list-item>
<list-item><p>dyads or other subgroups within teams,</p></list-item>
<list-item><p>groups as a unit,</p></list-item>
<list-item><p>groups as compared to other groups, and</p></list-item>
<list-item><p>groups as representative of a macro-level construct (e.g., organizational culture).</p></list-item>
</list>
<p>Thus, the study of groups and teams is prismatic—it is wonderfully rich and complex and can be approached from a variety of levels (see <xref ref-type="bibr" rid="bibr2-1046496412471734">Kerr &amp; Tindale, in press</xref>) and methods (see <xref ref-type="bibr" rid="bibr4-1046496412471734">Runkle &amp; McGrath, 1972</xref>): experiments in all of their forms, questionnaires, interaction analysis, content analysis, textual/discourse analysis, field observation, interviews and focus groups, ethnography, case studies, and more (see <xref ref-type="bibr" rid="bibr1-1046496412471734">Hollingshead &amp; Poole, 2012</xref>, for one list of group research methods). As delightful as I find this state of affairs, the study of groups and teams remains methodologically contested. Philosophical and theoretical differences are more tolerated than our methodological differences. Why is that?</p>
<p>Research is a personal process—and a process that supports and serves our professional identity and success. I believe this is what makes us <italic>hold</italic> onto methodological preferences and discourages us from learning from others when their methodology is different from our own.</p>
<p>Although differences can be enlightening, we often focus on differences as being—well different. And when something is different we tend to evaluate it negatively. As coeditor of <italic>Small Group Research</italic> that draws submissions from group and team scholars across disciplines and nations, I often get this response: “I can’t review this, I don’t use [fill in your favorite methodology].” This fascinates me, as I have selected the reviewer for his or her expertise in the content of the manuscript with the hope that his or her expertise in leadership, for example, would trump any methodological difference. Certainly, I don’t expect that potential reviewer to learn a new method, but I do want that reviewer to contribute to the conversation about the content and to give his or her professional evaluation on the basis of his or her knowledge of the method (regardless of how limited).</p>
<p>This type of methodological difference is also evident at conferences. Some questioners (and, at some times, respondents) ask questions in such a way as to negatively evaluate how the presenter has collected data. (I am presuming that I’m not the only conference presenter who has felt this type of public stinging criticism.)</p>
<p>What can we do to bridge methodological differences in the more public venue of conferences and the more critical venue of publishing? First, let’s ask how the theory and methods used by an author are congruent? By using this metric, minimally, we may discover something new about the theory, or we may learn about a method with which we have little training or exposure. Second, rather than asking, “Why did you do it that way?,” let’s try questions along the line of, for example, “How do you see that methodology as illuminating [a particular concept/construct]?” Third, if a method is unfamiliar, let’s ask where we can find expert sources to learn more about it. As you can see, I advocate a <italic>learn</italic> rather than <italic>evaluate</italic> mode when approaching the work of other scholars. This does not mean that we avoid questioning one another, but our questions should be formed in such a way as to interrogate our own methodological preferences and privileges as much as they interrogate the methodological choices of others.</p>
<p>Beck’s questions ask us to view methodological differences in even broader ways. First, how can scholars use comments outside their discipline to enhance their discipline-specific research? There are standards by which each methodology is evaluated, and those standards focus on two different aspects of research reporting, such as that done at conferences. First, standards illuminate how well the research study was designed and then conducted. Second, standards can illuminate the validity, reliability, and/or credibility of the data analysis. I separate these out, as an expertly designed study can be poorly conducted or data from a well-executed method can be poorly analyzed.</p>
<p>One way group and team scholars could help one another and advance the study of groups and teams is to ask questions specifically targeted toward design, execution, and analysis. If you see a flaw in my design, believe you have spotted a flaw in the execution, or identify lack of logic in the analysis, I want to know. How others react to my scholarship is important because presenting at a conference is a test for the potential publication of the manuscript. Rather than deriding all aspects of my chosen method, guide me toward the specific weakness you observed. Engage me in a dialogue about my choices. When group and team scholars from different disciplines have open dialogue about method and analysis, we all gain. I get a preview of what might happen if I submit the manuscript for review for publication. You might learn something new about a method with which you are less familiar. This is how we could help one another and advance the study of groups and teams.</p>
<p>Beck’s second question asked, “How can scholars from different disciplines integrate methodological differences to enhance group research?” One way to accomplish this is to engage group scholars from other disciplines in your research. Recently I was on an interdisciplinary research team (communication, management, and psychology). As a team we were preparing an interview guide for field interviews. The guide was long, as it was the first set of interviews to be conducted and we were uncertain of where this research might take us. Something interesting happened as we independently reviewed the interview guide. Team Member A thought that the interview guide was overdirective, as very specific prompts and secondary questions were listed in the margin next to each major question. In other words, she believed that the interview guide would restrict her from following the interviewee’s lead. Team Member B believed the interview was not structured enough, as she was concerned how interviewees’ responses to different secondary questions could be analyzed. And, of course, Team Member C thought the interview guide was fine as written. Exposing our different viewpoints to one another caused us to have a conversation about the design and execution of the interview study—a good thing to happen before any data were collected. Thus, we integrated our disciplinary differences on what constitutes good field interviewing, which we hope will result in publications in disciplinary and interdisciplinary outlets.</p>
<p><xref ref-type="bibr" rid="bibr1-1046496412471734">Hollingshead and Poole (2012)</xref> credit Joe McGrath with saying, “Every research method is flawed” (p. 4). They go on to cite <xref ref-type="bibr" rid="bibr3-1046496412471734">McGrath, Martin, and Kulka’s (1982)</xref> book in which these authors describe research design as consisting of three dilemmas: precision, realism, and generalizability. They also note that it is impossible to achieve all three in a single study. I agree with this evaluation by both sets of scholars. But rather than saying <italic>every research method is flawed</italic>, I would rephrase this as <italic>every research method is partial</italic>. Regardless of our methodological and analytical choices, one set of choices cannot describe, predict, and explain a group or team phenomenon in totality. A group or team scholar’s methodological differences should not be evaluated simply because they are different than a research design I would conduct. Rather, our differences should be part of a conversation, not the basis of methodological one-upmanship.</p>
<p>Let’s rotate the prism to learn rather than rotating the prism to focus on what we already know.</p>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<bio>
<title>Author Biography</title>
<p><bold>Joann Keyton</bold> (PhD, The Ohio State University) is professor of communication at North Carolina State University and vice-chair and conference coordinator of Interdisciplinary Network for Group Research (INGRoup). She is also coeditor of <italic>Small Group Research</italic>.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1046496412471734">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Hollingshead</surname><given-names>A. B.</given-names></name>
<name><surname>Poole</surname><given-names>M. S.</given-names></name>
</person-group> (Eds.). (<year>2012</year>). <source>Research methods for studying groups and teams: A guide to approaches, tools, and technologies</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr2-1046496412471734">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kerr</surname><given-names>N. R.</given-names></name>
<name><surname>Tindale</surname><given-names>R. S.</given-names></name>
</person-group> (<year>in press</year>).<article-title>Methods of small group research</article-title>. In <person-group person-group-type="editor">
<name><surname>Reis</surname><given-names>H. T.</given-names></name>
<name><surname>Judd</surname><given-names>C. M.</given-names></name>
</person-group> (Eds.) <source>Handbook of research methods in social and personality psychology</source> (<edition>2nd ed.</edition>). <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-1046496412471734">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McGrath</surname><given-names>J. E.</given-names></name>
<name><surname>Martin</surname><given-names>J.</given-names></name>
<name><surname>Kulka</surname><given-names>R. A.</given-names></name>
</person-group> (<year>1982</year>). <source>Judgment calls in research</source>. <publisher-loc>Beverly Hills, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr4-1046496412471734">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Runkle</surname><given-names>P.</given-names></name>
<name><surname>McGrath</surname><given-names>J. E.</given-names></name>
</person-group> (<year>1972</year>). <source>Research on human behavior: A systematic guide to method</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Holt, Rinehart and Winston</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>