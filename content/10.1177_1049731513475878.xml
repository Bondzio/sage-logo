<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">RSW</journal-id>
<journal-id journal-id-type="hwp">sprsw</journal-id>
<journal-title>Research on Social Work Practice</journal-title>
<issn pub-type="ppub">1049-7315</issn>
<issn pub-type="epub">1552-7581</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1049731513475878</article-id>
<article-id pub-id-type="publisher-id">10.1177_1049731513475878</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Invited Reaction Paper to Issues in Differential Response</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Critical Appraisal of Issues in Differential Response</article-title>
<subtitle>Moving the Field Forward</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Winokur</surname>
<given-names>Marc A.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1049731513475878">1</xref>
<xref ref-type="corresp" rid="corresp1-1049731513475878"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gabel</surname>
<given-names>George</given-names>
</name>
<xref ref-type="aff" rid="aff2-1049731513475878">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-1049731513475878"><label>1</label>School of Social Work, Colorado State University, Fort Collins, CO, USA</aff>
<aff id="aff2-1049731513475878"><label>2</label>Westat, Inc., Rockville, MD, USA</aff>
<author-notes>
<corresp id="corresp1-1049731513475878">Marc A. Winokur, School of Social Work, Colorado State University, Fort Collins, CO 80523, USA. Email: <email>marc.winokur@colostate.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2013</year>
</pub-date>
<volume>23</volume>
<issue>5</issue>
<issue-title>Special Issue on: Issues in Differential Response</issue-title>
<fpage>531</fpage>
<lpage>534</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>This reaction article highlights areas of agreement and disagreement with the study conducted by Hughes, Rycus, Saunders-Adams, Hughes, and Hughes on the current state of research and practice in differential response (DR). Overall, we agree with several of the arguments put forth by Hughes et al. regarding the limitations of DR research and the lack of a consistently defined and implemented DR practice model. These areas of agreement offer common ground on which to work together to move the field forward. However, we have concerns about the methodological rigor of the Hughes et al. study and questions about some of their findings and conclusions. We draw upon our current evaluation of a five-county DR research and demonstration project in Colorado to provide recommendations for enhancing the design and implementation of research on DR.</p>
</abstract>
<kwd-group>
<kwd>child welfare</kwd>
<kwd>differential response</kwd>
<kwd>randomized controlled trial</kwd>
<kwd>practice model</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>We are thankful for the opportunity to respond to “Issues in Differential Response” by Hughes, Rycus, Saunders-Adams, Hughes, and Hughes (2013). As the lead evaluators for the Colorado Consortium on Differential Response (CCDR), which is part of a three-site (CO, IL, OH) federal research and demonstration project funded by the Children’s Bureau and administered by the National Quality Improvement Center on Differential Response in Child Protective Services (QIC-DR), we have a unique perspective from which to react to this provocative white paper on differential response (DR). We are excited that this special issue of <italic>Research on Social Work Practice</italic> will bring renewed attention to this emerging practice in child welfare. We agree with Hughes et al. (2013) that, “DR has been a powerful stimulus for child welfare organizations to transform their organizational structures, policies, and procedures, and in some cases, their laws, to be more in line with principles of family centered, strengths-based practice” (p. 506–507). As such, it is imperative that a dialogue occur on the relative merits of DR policy and practice and that this dialogue be informed by a critical appraisal of the literature with an eye toward building a stronger empirical foundation. As an overview, our reaction paper will focus on where we agree with Hughes et al., where we disagree with them, and how we can work together to move the field forward.</p>
<sec id="section1-1049731513475878">
<title>Where We Agree</title>
<p>We agree with several of the arguments put forth by Hughes et al. regarding the limitations of DR research and the lack of a consistently defined and implemented DR practice model. Based on our understanding of the literature, we too are concerned with insufficient control for differences between groups, the lack of standardized instruments to measure outcomes, and the challenge in generalizing findings because of wide variations in settings and practice models. One area of agreement, and something we are addressing in our evaluation, is the need to statistically control for pre-experimental differences between groups. For example, Hughes et al. point to differences between experimental and comparison groups on abuse rates and safety issues as barriers to concluding that postexperimental differences in recurrence of abuse and child safety result from the DR intervention. Another criticism lodged by Hughes et al. is that “DR research has attempted to measure child safety in a variety of ways, but none of the studies used standardized and validated measures or safety assessment protocols implemented by well trained raters” (p. 502). Although safety is typically measured by subsequent referrals and assessments collected from administrative databases, we too are troubled that validated instruments used to measure such constructs as engagement and satisfaction are not widely available (<xref ref-type="bibr" rid="bibr5-1049731513475878">Yatchmenoff, 2005</xref>).</p>
<p>From a national perspective, we agree that there is no defined or consistently implemented DR practice model. It should be noted that child welfare systems do not adhere to a uniform practice model nor is one implemented consistently across jurisdictions (<xref ref-type="bibr" rid="bibr3-1049731513475878">U.S. Department of Health and Human Services, 2009</xref>). It is unfortunate that the Colorado DR model was not in the population of studies considered by Hughes et al., because it addresses many of the concerns expressed in Finding #1 (p. 497). For example, the Colorado DR model is very consistent in the use of a uniform agency response guide with firm eligibility criteria, and a RED (review, evaluate, direct) team approach to assigning families to tracks (<xref ref-type="bibr" rid="bibr4-1049731513475878">Winokur et al., 2012</xref>). Additionally, all five counties in the CCDR have agreed upon a list of questions for screeners to use at the referral stage along with providing uniform training for screeners (<xref ref-type="bibr" rid="bibr4-1049731513475878">Winokur et al., 2012</xref>). According to <xref ref-type="bibr" rid="bibr4-1049731513475878">Winokur et al. (2012</xref>), the five Colorado counties do not explicitly prioritize services to either track, and the same array of community-based services, including an increase in the amount of financial support available through the grant, is available to families in both the family assessment response (FAR) and investigation response (IR) tracks.</p>
<p>Underlying the concerns of Hughes et al. is the perceived conflict of interest by researchers in the field. The QIC-DR has engaged an independent evaluation firm to conduct a cross-site evaluation, and has facilitated an ongoing National Advisory Committee, which includes practitioners and researchers tasked with providing oversight for the design and implementation of the evaluation. As independent evaluators working with the QIC-DR, we are sensitive to these charges and have worked with our evaluation colleagues to address some of the limitations of past research on DR including cognitive testing of survey instruments, weighting of study samples, and ongoing dissemination of evaluation findings.</p>
<p>We concur with Hughes et al. on “the critical importance of rigorous and valid outcome research and open, transparent, rational public discourse” (p. 507). The areas of agreement outlined here offer common ground on which to work together to move the field forward. However, we wish the authors had provided more direction on how to bring this about.</p>
</sec>
<sec id="section2-1049731513475878">
<title>Where We Disagree</title>
<p>Our areas of disagreement stem from our concerns about the methodology, findings, and conclusions from this white paper. Hughes et al. criticize other researchers for failing to “fully articulate and explain study limitations” (p. 516), when they fail to report limitations in their own discussion section. This is problematic in light of the significant weaknesses in their study. Specifically, we believe the study lacks both rigor and transparency, especially with the study design, sampling procedures, data collection strategies, and data analysis decisions. Furthermore, the study is inadequately reported with overstated and undersupported conclusions, unfortunate echoes of their criticisms of the so-called <italic>DR advocacy movement</italic> (p. 506).</p>
<p>The first red flag was raised with their claim that, “we triangulated the data to derive our conclusions” (p. 495). This is somewhat misleading, as Hughes et al. did not collect data from multiple sources to support the key informant interviews they conducted, but simply did a literature review. To truly triangulate the informant interviews, the researchers could have analyzed administrative data or conducted document review on implementation fidelity and outcome measures from the studies they reviewed. Furthermore, Hughes et al. could have conducted a systematic review and meta-analysis of the DR evidence base, which would have yielded quantitative evidence on study quality and outcomes to support the findings from the qualitative interviews.</p>
<p>The next red flag was how Hughes et al. implemented and reported their sampling procedures, which raised more questions than answers. For example, how was the “most appropriate respondent” defined? What roles did these individuals play in the implementation of DR in their state? Were all attendees of the DR conference and all individuals identified in American Humane Association reports considered key informants? Which states did not respond to the interview request? Did nonrespondents mainly represent closed DR programs? Even though the authors promised confidentiality, we believe they should have reported which states participated, especially in light of their concerns about the variance in implementation of DR across the country.</p>
<p>Perhaps, our biggest concern is the mismatch between the length of the interview protocol and the time allotted for the interviews. This was a protocol with 47 open-ended questions, many of which required additional information to answer properly (e.g., what outcomes has the program achieved)? We believe this protocol would take at least several hours to properly complete. Instead, respondents were given between 30 and 60 minutes to answer the questions. This would allow for only the most cursory responses for each question, which would require the authors to fill in the blanks with their own interpretations or preconceived notions. The interview procedures also were inconsistent, as three key informants were given the questions ahead of time, while the other respondents did not have this opportunity.</p>
<p>Another point of contention is their decision to “not attempt any quantification of interview responses” (p. 496). It would have been helpful to know how many respondents reported each finding to protect against cherry-picking responses or using one response as “evidence.” Interestingly, these are two tactics that Hughes et al. attribute to research that is based on advertising and marketing rather than science (p. 516). For what is arguably the most important outcome of DR, the findings on child safety were inadequate. This is where a meta-analysis is required if you are going to make a claim that there is insufficient data relative to child safety (p. 500). One finding from one study is hardly definitive on this issue.</p>
<p>Perhaps the most obvious example of an undersupported claim is that, “DR’s stated preference that workers focus on family needs rather than incidents of maltreatment would clearly discourage practitioners from having the sometimes difficult conversations with families that are necessary to fully assess risk and to address safety concerns” (p. 503). Hughes et al. provide no empirical evidence for this contention and do not support it with information from key informants. Furthermore, the assertion that, “motives aside, we found unsupported, inflated, and unfounded promotional claims to be a significant problem in the DR research we reviewed” (p. 516) is disconcerting. If their argument is that DR researchers have willfully misrepresented their findings, the motives to commit such malpractice should be identified and supported.</p>
</sec>
<sec id="section3-1049731513475878">
<title>How We Move Forward</title>
<p>Our motivation for responding to this white paper is to help move past our differences on issues of differential response and work together to move the field forward. Hughes et al. should be commended for challenging the conventional wisdom on DR and for setting a very high bar for research in child welfare. We agree there is a need “to ensure that our marketing and implementation efforts are truly a force for constructive positive change” (p. 507). Unfortunately, the authors did not spend much time talking about how to make this happen or what it would look like. We take the view that research on DR is evolving and believe that the evaluations in Colorado, Illinois, and Ohio as part of the QIC-DR can serve as a catalyst for future research in the field. We draw specifically upon our current evaluation in Colorado to provide recommendations for improving the methodology and implementation of DR research.</p>
<p>We are conducting a 3-year randomized controlled trial (RCT), in which eligible low and moderate risk families with a screened-in referral in one of the five Colorado counties are randomly assigned to either the FAR or IR track. Our study is comprised of a process, outcome, and cost evaluation. As displayed in <xref ref-type="fig" rid="fig1-1049731513475878">Figure 1</xref>, “the model is an integration of the eight core elements defined by the QIC-DR, practice principles that guide decision points, promising practice components, and procedure as defined in Colorado law” (<xref ref-type="bibr" rid="bibr1-1049731513475878">Colorado Consortium on Differential Response, 2012</xref>).</p>
<fig id="fig1-1049731513475878" position="float">
<label>Figure 1.</label>
<caption>
<p>Colorado’s differential response model.</p>
</caption>
<graphic xlink:href="10.1177_1049731513475878-fig1.tif"/>
</fig>
<p>This section is organized around the specific findings reported by Hughes et al. concerning the internal validity, external validity, measurement reliability and validity, and implementation fidelity of research on DR. There were several concerns expressed about the internal validity of research on DR. First, Hughes et al. argue that it is hard to isolate the DR intervention as being responsible for changes in outcomes because of other competing policy or practice changes. The issue of extraneous variables is mitigated in an RCT by the notion that both groups would be equally exposed to other interventions (<xref ref-type="bibr" rid="bibr2-1049731513475878">Shadish, Cook, &amp; Campbell, 2002</xref>). For example, the Colorado Practice Model (CPM) is being implemented simultaneously with DR in Colorado, but families from both tracks should be equally exposed to CPM, leaving DR as the intervention that differs. We recommend that other states implement RCTs to evaluate the effectiveness of their DR practice models.</p>
<p>We agree with Hughes et al. that internal validity is threatened by the self-selection of caseworkers to serve either FAR or IR cases. Without the random assignment of caseworkers, there may be differences between the pathways that could be related to outcomes. Although we were unable to randomly assign caseworkers in our study, we will statistically control for differences in caseworker characteristics, such as experience, tenure, and education. We recommend that additional caseworker characteristics be collected through surveys and administrate data sources. As for the concern about inequality in training, caseworkers in Colorado received very similar training for certain DR model components (e.g., solution-focused engagement), although there were differences in the amount of DR-specific training received by caseworkers (<xref ref-type="bibr" rid="bibr4-1049731513475878">Winokur et al., 2012</xref>). We recommend that greater attention be paid to the differences in training between caseworkers from both an equity and evaluation lens.</p>
<p>The primary critique about the external validity of DR research is that there is a lack of random sampling. This is not specific to DR research, but to all social science research (<xref ref-type="bibr" rid="bibr2-1049731513475878">Shadish et al., 2002</xref>). In our evaluation, counties were not randomly selected for DR, but were required to demonstrate readiness for the practice and provide a financial match in order to participate. Although the results may not be generalizable to all jurisdictions, new counties can use the same readiness approach to judge their fit for the Colorado DR model. Furthermore, our evaluation adds to the literature in this regard, as we randomly selected eligible families for our study sample for the outcome and costs evaluations.</p>
<p>The findings for measurement reliability and validity center on the lack of validated instruments, the importance of multiple data sources, and the need to account for survey nonresponse. Hughes et al. argue that in most studies they reviewed, “there was no discussion of how the instruments, questionnaires, and scales used in the study had been tested to ensure either validity” (p. 500). We recommend instrument development and validation studies to better measure key DR outcomes including engagement, well-being, and safety.</p>
<p>We recommend that the evaluation of DR be informed by multiple data sources. For our process evaluation, we are conducting site visits to all five counties, in which we facilitate focus groups with caseworkers, supervisors, and community stakeholders. We also are collecting administrative and survey data for the fidelity assessment. For the outcome evaluation, we have four data sources: family exit surveys, caseworker general surveys, caseworker case-specific reports, and administrative data. For the cost evaluation, we are collecting data from administrative databases and county-specific financial records to compare initial and follow-up costs for worker time and service provision between families in the FAR and IR tracks.</p>
<p>For survey nonresponse, Hughes et al. raise concerns that “there was no reported attention given to the reasons other families may not have responded to the surveys, or how their perspectives might have differed” (p. 516). This is an oversight that is being addressed in our evaluation through nonresponse bias testing and weighting of the family and caseworker surveys. We also conducted incentive experiments to increase our response rate. We recommend that new and innovative ways to engage families in the evaluation process be explored.</p>
<p>We are hopeful that the QIC-DR will add to the evidence base on the replicability and model fidelity of child welfare interventions like DR. First, the project directors from all three sites are developing an implementation guide that will allow new DR counties and states to have the “benefit of a standardized program manual to guide implementation and to promote fidelity in implementation” (p. 498). Second, the evaluation directors are conducting fidelity assessments, which will demonstrate the “capacity to test and standardize processes that best achieved desired results” (p. 498). We are using administrative and survey data to determine if the practices and practice principles that define the Colorado DR model were adhered to by the five counties during the research and demonstration project.</p>
<p>Finally, there is a need for continuous evaluation of DR practice through a partnership between practitioners, policy makers, and researchers. As an example, the pilot counties and the State have built the capacity to track their eligibility and assignment patterns, outcomes, and costs. Our hope is that this white paper and the corresponding reactions jump start this conversation with a focus on genuine collaboration, empirical evidence, and practice improvement.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict" id="fn1-1049731513475878">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn2-1049731513475878">
<label>Funding</label>
<p>The authors received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1049731513475878">
<citation citation-type="book">
<collab collab-type="author">Colorado Consortium on Differential Response</collab>. (<year>2012, August</year>). <source>Colorado’s differential response model</source>. <publisher-loc>Denver, CO</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr2-1049731513475878">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Shadish</surname>
<given-names>W. R.</given-names>
</name>
<name>
<surname>Cook</surname>
<given-names>T. D.</given-names>
</name>
<name>
<surname>Campbell</surname>
<given-names>D. T.</given-names>
</name>
</person-group> (<year>2002</year>). <source>Experimental and quasi-experimental designs for generalized causal inference</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Houghton Mifflin</publisher-name>.</citation>
</ref>
<ref id="bibr3-1049731513475878">
<citation citation-type="web">
<collab collab-type="author">U.S. Department of Health and Human Services</collab>. (<year>2009</year>). <source>Recent trends in local child protective services practices</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Government Printing Office</publisher-name>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://aspe.hhs.gov/hsp/09/TrendsinCPS/">http://aspe.hhs.gov/hsp/09/TrendsinCPS/</ext-link>
</citation>
</ref>
<ref id="bibr4-1049731513475878">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Winokur</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Drury</surname>
<given-names>I.</given-names>
</name>
<name>
<surname>Batchelder</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Mace</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Amell</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Bundy-Fazioli</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Tungate</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>2012</year>). <source>Colorado year 1 site visit final report: Colorado consortium on differential response</source>. <publisher-loc>Fort Collins, CO</publisher-loc>: <publisher-name>Social Work Research Center, Colorado State University</publisher-name>.</citation>
</ref>
<ref id="bibr5-1049731513475878">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yatchmenoff</surname>
<given-names>D. K.</given-names>
</name>
</person-group> (<year>2005</year>). <article-title>Measuring child engagement from the client’s perspective in nonvoluntary child protective services</article-title>. <source>Research on Social Work Practice</source>, <volume>15</volume>, <fpage>84</fpage>–<lpage>96</lpage>. <comment>doi:10.1177/1049731504271605</comment>
</citation>
</ref>
</ref-list>
</back>
</article>