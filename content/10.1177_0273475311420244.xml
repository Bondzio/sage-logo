<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JMD</journal-id>
<journal-id journal-id-type="hwp">spjmd</journal-id>
<journal-title>Journal of Marketing Education</journal-title>
<issn pub-type="ppub">0273-4753</issn>
<issn pub-type="epub">1552-6550</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0273475311420244</article-id>
<article-id pub-id-type="publisher-id">10.1177_0273475311420244</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>From the Field and Into the Classroom</article-title>
<subtitle>Information Architecture Assessment and Website Usability Tests</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Clayton</surname><given-names>Michael J.</given-names></name>
<xref ref-type="aff" rid="aff1-0273475311420244">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hettche</surname><given-names>Matt</given-names></name>
<xref ref-type="aff" rid="aff1-0273475311420244">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0273475311420244"><label>1</label>Christopher Newport University, Newport News, VA, USA</aff>
<author-notes>
<corresp id="corresp1-0273475311420244">Michael J. Clayton, Christopher Newport University, 1 University Place, Newport News, VA 23606, USA Email: <email>michael.clayton@cnu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2012</year>
</pub-date>
<volume>34</volume>
<issue>1</issue>
<fpage>30</fpage>
<lpage>43</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Although it is difficult these days to find a company that does not have a website, you do not have to look very far for to find a website with significant design and architecture flaws. Getting a visitor to your website is one thing, making the experience effortless and allowing them to find exactly what they need is another story. That being said, understanding how the consumer comprehends and navigates webpage content is an important part of the interactive marketing process that demands extra attention. Although this field is well established among marketing research practitioners, information architecture assessment and website usability tests are user-centric methods of website analysis that receive little attention from marketing academics. This article discusses the importance of user-centric methods of website analysis for the field of direct and interactive marketing and outlines strategies for implementing qualitative research techniques in an educational context. Classroom exercises and take-home assignments for an undergraduate curriculum are provided and discussed.</p>
</abstract>
<kwd-group>
<kwd>interactive marketing</kwd>
<kwd>website usability</kwd>
<kwd>information architecture</kwd>
<kwd>qualitative analysis</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>It is no secret that marketing undergraduate students want real-world experiences in the classroom, and recently, a number of scholars have agreed on the need to prepare students to “do marketing” (<xref ref-type="bibr" rid="bibr15-0273475311420244">Diamond, Koernig, &amp; Iqbal, 2008</xref>; <xref ref-type="bibr" rid="bibr48-0273475311420244">Stanton, 2006</xref>; <xref ref-type="bibr" rid="bibr55-0273475311420244">Young, 2010</xref>). AACSB International, when framing its accreditation standards for collegiate schools of business, also stresses the importance of bridging the academic/practitioner divide by encouraging educational opportunities that have relevance and currency with actual business practice (<xref ref-type="bibr" rid="bibr1-0273475311420244">AACSB, 2010</xref>). Hands-on learning experiences that are grounded in current marketing practices can provide students several important lessons, such as developing necessary skill sets to be successful professionally, establishing a familiarity with “time on task” workplace activities, and revealing possible career opportunities that exist on graduation (<xref ref-type="bibr" rid="bibr3-0273475311420244">Ackerman, Gross, &amp; Perner, 2003</xref>; <xref ref-type="bibr" rid="bibr53-0273475311420244">Walker et al., 2009</xref>). Yet one such opportunity, which receives relatively little attention from marketing academics, is the growing field of information architecture assessment and the corresponding methodologies for website usability testing. Although well represented in other academic disciplines, such as applied psychology, library and information science, and educational instructional design, these methods of information analysis are often overlooked by marketing academics.</p>
<p>From a practitioner’s perspective, information architecture assessment and usability tests serve as tools in an ongoing iterative process for measuring and managing website quality and engagement (<xref ref-type="bibr" rid="bibr24-0273475311420244">Krug, 2005</xref>; Morville &amp; Rosenfeld, 2007; <xref ref-type="bibr" rid="bibr38-0273475311420244">Nielsen, 2008</xref>). Understanding how and why end users interact both cognitively and functionally with a website interface can provide valuable information for designers and marketers alike. Differing slightly from the more data-driven and behaviorist approaches to website analysis, such as clickstream data analysis and controlled studies, information architecture assessment and usability testing rely centrally on qualitative techniques for abstracting the end user’s perspective at various points in the design process. And although issues in qualitative research in general are well covered in the academic marketing literature (e.g., <xref ref-type="bibr" rid="bibr17-0273475311420244">Gummesson, 2005</xref>; <xref ref-type="bibr" rid="bibr32-0273475311420244">Milliken, 2001</xref>; <xref ref-type="bibr" rid="bibr47-0273475311420244">Spiggle, 1994</xref>), even as there is growing interest to understand website quality and interface engagement (e.g., <xref ref-type="bibr" rid="bibr9-0273475311420244">Calder, Malthouse, &amp; Schaedel, 2009</xref>; <xref ref-type="bibr" rid="bibr23-0273475311420244">Kim &amp; Niehm, 2009</xref>), there is very little research on qualitative user-centric methods of website analysis.</p>
<p>This article aims to highlight the value and importance of user-centric website analysis for interactive marketing. We believe, in particular, there is an opportunity for marketing educators to embrace an evolving field of marketing research while answering a perennial call to provide training and instruction in sound qualitative research techniques. Relevant for several courses in a marketing curriculum, including “consumer behavior,” “marketing research,” and “Internet/digital marketing,” we suggest that advances in the classroom can be spawned by combing new and emerging topics from industry with well-established marketing theory. To this end, after reviewing some of the more prominent methods of website analysis used by practitioners in the field, we outline two theoretical frameworks for interpreting website interactivity and discuss how information architecture assessment and usability testing are relevant. By modeling how these user-centric methods of website analysis can be applied to discipline-specific theories, we aim to illustrate how research technique remains fundamentally tied to well-thought-out research objectives and grounded marketing theory. To illustrate proper qualitative research methods, including the processes for scripted and unbiased moderation of research participants, we provide a description of three class activities with sample assignment instructions. Designed for the students at the undergraduate level, these class activities involve role-play, the completion of written research reports, and mock client presentations.</p>
<sec id="section1-0273475311420244">
<title>Webpage Analysis From the End User’s Perspective</title>
<p>As a communication medium, the Internet enables a personal and expressive means for interaction. Not only “what is said” but “how it is said” and “where it appears online” are rarely dictated by a central authority. Online content results from the individual decisions of a genuine multitude who are all attempting to communicate and make connections in cyberspace. In the earliest days of the World Wide Web (e.g., as the Internet first took hold in mass culture and society during the mid 1990s), it was web browsers, such as <italic>Netscape</italic> and <italic>Gopher</italic> that provided end users with a means for interface standardization. In many ways, the web browser (itself) became the very conduit of mass communication. Over time, the basic controls of a URL address bar, foreword/backward page navigation, and the page refresh button have provided a common interface that has led to various norms and standards for website design. Understanding how end users engage website content from a first person (goal-oriented) perspective, therefore, is an important area of inquiry for anyone interested in facilitating an online exchange.</p>
<p>The academic literature on webpage analysis from an end user’s perspective is perhaps most developed in the field of applied psychology. Research into human–computer interaction, such as eyetracking and biometrics, has far-reaching implications for the advance of computer technology and human communication (see, <xref ref-type="bibr" rid="bibr7-0273475311420244">Braddy, Meade, &amp; Kroustalis, 2008</xref>; <xref ref-type="bibr" rid="bibr13-0273475311420244">Danielson, 2003</xref>). One blossoming area of research in this field examines the role of age as a possible moderator for interface interactivity (<xref ref-type="bibr" rid="bibr4-0273475311420244">Becker, 2004</xref>; <xref ref-type="bibr" rid="bibr10-0273475311420244">Chadwick-Dias, McNulty, &amp; Tullis, 2003</xref>; <xref ref-type="bibr" rid="bibr18-0273475311420244">Hart, Chaparro, &amp; Halcomb, 2008</xref>). Metrics for assessing information literacy, processing fluency, task-success, and end user satisfaction are incorporated into an evolving set of design guidelines that are adopted by government and nongovernment organizations, such as the National Institute on Aging, the National Library of Medicine, and the Association for Advancement of Retired Persons (<xref ref-type="bibr" rid="bibr18-0273475311420244">Hart, Chaparro, &amp; Halcomb, 2008</xref>). In particular, aligning characteristics of older adults with their preferences and behavior tendencies have lead to very precise recommendations on font size, font color, foreground and background colors, link size, required cursor movement, and webpage scroll down limits (<xref ref-type="bibr" rid="bibr4-0273475311420244">Becker, 2004</xref>).</p>
<p>Other specialized disciplines including library and information science as well as educational instructional design also have a dedicated literature to understand end user behavior and decision making (<xref ref-type="bibr" rid="bibr16-0273475311420244">George, 2005</xref>; <xref ref-type="bibr" rid="bibr28-0273475311420244">Li, 2005</xref>; <xref ref-type="bibr" rid="bibr41-0273475311420244">Nyman &amp; Yardley, 2009</xref>; <xref ref-type="bibr" rid="bibr50-0273475311420244">VandeCreek, 2005</xref>). Spawning from practical concerns of making information available in the digital age, institutions such as university libraries, hospitals, the military, and legal magistrates have increasingly favored a user-centric design approach. Using many of the tried-and-true methods of marketing research, such as user-surveys, focus groups, and one-on-one interviews, these applied academic fields aim to align information processing needs with efficient means of delivery. One approach to website design and evaluation discussed in the literature, and closely emulating information architecture assessment, is “cognitive task analysis” or CTA (<xref ref-type="bibr" rid="bibr26-0273475311420244">Kushniruk, 2001</xref>; <xref ref-type="bibr" rid="bibr27-0273475311420244">Kushniruk &amp; Patel, 2004</xref>; <xref ref-type="bibr" rid="bibr28-0273475311420244">Li, 2005</xref>). As <xref ref-type="bibr" rid="bibr28-0273475311420244">Li (2005)</xref> explains, CTA “emphasizes the fact that users must gain sufficient knowledge, skill, and familiarity with a website in order to use it effectively and safely” (p. 254). CTA presupposes that end users possess a certain degree of competence and knowledge in a given domain before reaching a sufficient degree of processing fluency and task-success (<xref ref-type="bibr" rid="bibr28-0273475311420244">Li, 2005</xref>). CTA models and research tend to focus on developing website features such as help menus, support artifacts (e.g., whitepapers), and decision prompts.</p>
<p>More recently in marketing, there is increased interest in the organizational layout of webpage design as well as direct observation of end user interface behavior. <xref ref-type="bibr" rid="bibr40-0273475311420244">Novak, Hoffman, and Yung (2000)</xref> proposed a quantitative modeling framework to understand the psychological state of “flow” for online shopping behavior. Flow, very briefly, is the psychological state where a person exhibits focused attention, complete involvement in an activity or task, high levels of skill and control, and (often) a misperception or distortion of time (<xref ref-type="bibr" rid="bibr40-0273475311420244">Novak et al., 2000</xref>). <xref ref-type="bibr" rid="bibr40-0273475311420244">Novak et al. (2000)</xref> conclude that online consumers not only interact with firms and other consumers but also with the tools of the interactive environment (itself) and indicate that flow can be facilitated in the online shopping environment (<xref ref-type="bibr" rid="bibr40-0273475311420244">Novak et al., 2000</xref>). They recommend, in particular, further study of online consumer behavior is needed, including direct observation of customer engagement to assess flow.</p>
<p><xref ref-type="bibr" rid="bibr46-0273475311420244">Smith and Sivakumar (2004)</xref> also considered how flow is relevant for Internet shopping behavior, analyzing the construct within four parameters: (a) buying situation (e.g., browsing, one-time purchases, and repeat purchases), (b) consumer disposition (e.g., perceived risk, willingness to buy, consumer self-confidence), (c) product type (e.g., good vs. service), and (d) purchase occasion (e.g., planned vs. impulse). Under the managerial implications of their study, they concluded that firms should invest in a strategic understanding of their consumers’ flow from, among other things, an analysis of site design. Although not specifically mentioning usability tests, they recommend the need for e-tailers to learn more about customer preferences from the very beginning of the shopping experience (<xref ref-type="bibr" rid="bibr46-0273475311420244">Smith &amp; Sivakumar, 2004</xref>).</p>
<p><xref ref-type="bibr" rid="bibr43-0273475311420244">Resnick and Sanchez (2004)</xref> argue a compelling case for a marketing-led website design conducted from user-centric input. Using a controlled study involving 60 participants in a mock e-shopping environment, they concluded that the user-initiated labeling of products was superior to a firm’s labeling of products when measuring task success and customer satisfaction. In a much larger study involving 757 respondents, <xref ref-type="bibr" rid="bibr52-0273475311420244">Venkatesh and Agarwal (2006)</xref> evaluated end user interaction on websites from four different industries (i.e., airlines, online bookstores, automobile manufacturers, and car rental agencies). They concluded that website usability is particularly important for transaction purposes as well as for websites that can be narrowly targeted to gender and consumers searching for specific product types.</p>
<p>On the whole, academic researchers are slow to emulate marketing research practitioners in the field in an effort to clarify the norms and patterns of consumer behavior as it is realized in an online interactive environment. For many high-tech marketing research companies, however, website information analysis is now considered a staple of the interactive marketer’s toolbox. In the AMA’s <italic>2010 Marketing News Directory of Interactive Marketing and Software Products and Services</italic>, for example, 5 of the 35 categories listed in the index of the directory include or involve services related to webpage information analysis (<xref ref-type="bibr" rid="bibr2-0273475311420244">American Marketing Association, 2010</xref>). A quick search of firms offering website usability testing online will uncover everything from $40,000 in-depth qualitative studies from the likes of Jakob Nielsen’s Nielsen Norman Group to more rudimentary findings of the Feedback Army (an online web usability test service) for just $15 (Feedback Army, <ext-link ext-link-type="uri" xlink:href="http://www.feedbackarmy.com/">http://www.feedbackarmy.com/</ext-link>; Nielsen Norman Group, <ext-link ext-link-type="uri" xlink:href="http://www.nngroup.com/">http://www.nngroup.com/</ext-link>). Like anything, you get what you pay for; so it is important for students and practitioners to understand the value of these tools and how they can be applied and leveraged in website development and information analysis.</p>
</sec>
<sec id="section2-0273475311420244">
<title>Information Architecture Assessment</title>
<p>Although cloud computing and the democratization of website development enables even the smallest of businesses to create a website, the reality is that not all marketers are making the most of this opportunity. Fields such as search engine optimization have received the most attention in recent years, but information architecture is a burgeoning field that may have greater applicability to marketing research than most other web 2.0 careers. Although search engine optimization focuses on site-centric aspects and generalized behavioral tendencies, information architecture and website usability focus on the more fickle and discriminating preferences of human visitors. The purview of information architecture is simple; while the limitless boundaries of the online universe is of unquestionable merit, this value is dramatically diminished if consumers are unable to find what they are looking for quickly, easily, and in the preferred format (<xref ref-type="bibr" rid="bibr36-0273475311420244">Morville &amp; Rosenfeld, 2006</xref>).</p>
<p>For our purposes, there are three factors important for the practice of information architecture assessment. The first is navigation design. Although navigation indexes along the top and left hand side of webpages have become the norm, the balance of these two instruments when used together is a complicated matter. Is there, for example, one type of navigational orientation that proves to be most intuitive for visitors to a given page? Or is effective navigational design perhaps tied to other (more traditional) rhetorical features of a text, such as audience, author’s intent, and tone? Although scholars have demonstrated the importance of keeping navigational links consistent among web pages (<xref ref-type="bibr" rid="bibr13-0273475311420244">Danielson, 2003</xref>), the formulation of the navigational choices is clearly less scientific. Often, for example, the goal of redundancy and multiple pathways from a web designer’s perspective translates into a frustrating maze of information seeking for the end user.</p>
<p>A second important factor in information architecture assessment is the labeling of navigational terms in a manner that is clear and intuitive for the typical end user. For instance, if consumers see the term <italic>industrial</italic> as a navigational link, do they have clear expectations of the type of content that will be shown if the link is clicked? Research has shown that when a user clicks on a link and finds unexpected information, which fails to address the desired outcome or need within 8 seconds, this leads to frustration and abandonment of the site (<xref ref-type="bibr" rid="bibr12-0273475311420244">Coupey, 2004</xref>; <xref ref-type="bibr" rid="bibr14-0273475311420244">Dellaert &amp; Kahn, 1999</xref>). <xref ref-type="bibr" rid="bibr38-0273475311420244">Nielsen (2008)</xref> further maintains a “thirty second rule”—that is, if the end user cannot answer the questions of “who are you,” “what do you do,” and “what should I (the user) do next?” within 30 seconds, there is little chance the site will achieve its intended purpose for a mass audience (<xref ref-type="bibr" rid="bibr38-0273475311420244">Nielsen, 2008</xref>). While creating intuitive labels may seem like a simple task, the proximity effect of marketers to their field and product occasionally leads companies to “client speak,” which is unfamiliar or ambiguous to consumers/end users.</p>
<p>A third area of information assessment that receives moderate attention from practitioners is the design decision to either use a product-based organization (which delineates content based on product categories) or a task-based orientation (which organizes content based on user’s goals). In an online shopping context, it is perhaps not surprising to find that consumers often put the product or brand as a primary object of attention, followed by concerns for price, and then perhaps channels for distribution. <xref ref-type="bibr" rid="bibr43-0273475311420244">Resnick and Sanchez (2004)</xref>, for example, identified stronger performance in their study for product-based schemas when compared with task-based orientations. To be sure, this aspect of online consumer behavior diverges significantly from the brick-and-mortar shopping experience where point of purchase marketing strategy often narrowly considers a shopper’s goals when arranging and placing merchandise. Research for online shopping, however, is still very preliminary and, as of yet, inconclusive.</p>
</sec>
<sec id="section3-0273475311420244">
<title>Website Testing and Development</title>
<p>Among website designers and marketing-led content providers there are six basic methodologies for testing and developing new sites. They are expert testing, field testing, website usability testing (including heuristic evaluation and comparative usability evaluation), clickstream data analysis, controlled studies, and participatory design. Expert testing involves the use of several professionals who systematically evaluate websites and identify specific usability issues (<xref ref-type="bibr" rid="bibr19-0273475311420244">Hertzum, Jocobsen, &amp; Molich, 2002</xref>). Typically, the problem-identification percentage increases as additional evaluators are introduced. Expert evaluators may either bring to bear technical know-how about website design and construction or they may be simply trained as professional browsers who evaluate user interface features on a generic basis. Field testing, in contrast, uses an ethnographic approach where the “researcher as instrument” observes users in a typical or usual setting, such as work, school, or home. This approach is preferred when the context of the usage or the peripherals being used by the participant are of significant interest (<xref ref-type="bibr" rid="bibr21-0273475311420244">Jeffries, Miller, Wharton, &amp; Uyeda, 1991</xref>). Although time consuming and often expensive or impractical to perform on a large scale, field tests provide in-depth knowledge on how specific users engage and cope with their technological environments.</p>
<p>Usability testing involves the recruitment of target consumers to enter a laboratory or controlled environment where a scripted session is led by a moderator who directs research participants to attempt and/or complete specific tasks (<xref ref-type="bibr" rid="bibr11-0273475311420244">Chaffey, Ellis-Chadwick, Mayer, &amp; Johnston, 2009</xref>). Usability, defined broadly, is “how well and how easily a user, without formal training, can interact with an information system of a website” (<xref ref-type="bibr" rid="bibr5-0273475311420244">Benbunan-Fich, 2001</xref>, p. 152). In a well-know design manual, <xref ref-type="bibr" rid="bibr24-0273475311420244">Krug (2005)</xref> explains usability as when “a person of average ability and experience can use the thing . . . for its intended purpose without getting hopelessly frustrated” (p. 5). Often instructed to attempt specific navigational tasks, a usability test-subject may report personal navigational preferences while communicating perceived strengths and weaknesses of a website’s design. Although the discreet actions of the research participant are typically recorded with screen capturing software, the predominant value of this approach is the ability of the end user to articulate his/her thoughts while performing a specified task. One method, known as protocol analysis or the “thinking aloud” method, requires verbal descriptions from the end user while interacting with a website (<xref ref-type="bibr" rid="bibr5-0273475311420244">Benbunan-Fich, 2001</xref>; <xref ref-type="bibr" rid="bibr39-0273475311420244">Nielsen &amp; Loranger, 2005</xref>). Rather than attributing meaning to an end user’s actions as may be the case with rudimentary observational research, protocol analysis allows for the end user to describe his/her thought processes when executing tasks to reveal any potential problems and ambiguities of the website. In a consumer e-marketing context, usability tests prove to be particularly helpful in exposing aspects of a website that provoke uncertainty, confusion, and frustration, all factors that lead to website abandonment (see <xref ref-type="bibr" rid="bibr20-0273475311420244">Hill, 2001</xref>).</p>
<p>One form of usability testing used extensively in the field is heuristic evaluation (<xref ref-type="bibr" rid="bibr29-0273475311420244">Levi &amp; Conrad, 1996</xref>; <xref ref-type="bibr" rid="bibr37-0273475311420244">Nielsen, 1994</xref>). Using a checklist or rubric of recognized usability principles, multiple evaluators inspect a website interface for potential problems. Results for heuristic tests involve, first, recording the number of problems detected by each evaluator and, second, noting commonality or overlap of design defects reported in total. Heuristic evaluation, therefore, aims to detect unique instances of a defect as well as establish frequency measures for specific defect types. As noted by <xref ref-type="bibr" rid="bibr37-0273475311420244">Nielsen (1994)</xref>, one benefit of the approach is that although some usability problems are so easy to find that everyone seems to find them, there are also some problems that are still nonetheless important, yet found by only a few. Very generally, as the pool of test-subjects increases in heuristic evaluation, results become more comprehensive and exhaustive for detecting usability problems.</p>
<p>One hybrid method of website evaluation, partially involving usability testing as well as expert testing, is comparative usability evaluation (<xref ref-type="bibr" rid="bibr35-0273475311420244">Molich, Ede, Kaasgaard, &amp; Karyukin, 2004</xref>; <xref ref-type="bibr" rid="bibr34-0273475311420244">Molich &amp; Dumas, 2008</xref>). Comparative usability evaluation aims to mitigate the weaknesses inherent in each singular approach while aiming to improve the overall reliability and reproducibility of evaluation results. On the one hand, by incorporating expert testing alongside standard usability tests, the propensity to overdiagnose a design problem is avoided. <xref ref-type="bibr" rid="bibr34-0273475311420244">Molich and Dumas (2008)</xref> conclude that usability testing often favors an oversensitivity for design problems, where test-subjects sometimes raise more issues than developers can realistically address (<xref ref-type="bibr" rid="bibr34-0273475311420244">Molich &amp; Dumas, 2008</xref>). And, on the other hand, by including nonexpert users among expert evaluators, tendencies for myopic design evaluation can be controlled for and potentially eliminated.</p>
<p>Clickstream data analysis is another method of website evaluation used frequently in the field (<xref ref-type="bibr" rid="bibr22-0273475311420244">Kalczynski, Senecal, &amp; Nantel, 2006</xref>; <xref ref-type="bibr" rid="bibr33-0273475311420244">Moe, 2003</xref>; <xref ref-type="bibr" rid="bibr45-0273475311420244">Sismeiro &amp; Bucklin, 2004</xref>). <xref ref-type="bibr" rid="bibr8-0273475311420244">Bucklin and Sismeiro (2009)</xref> define clickstream data as “the electronic record of Internet usage collected by Web servers or third-party services” (p. 35). Coextensive with a number of other different data-mining processes, clickstream data analysis provide web designers insight into end user preferences and behavioral tendencies, such as website entry and exits points, search terms, and navigational choices. Although less able to reveal end user motivations or rationale for particular browsing behavior, clickstream data allow for seamless comparisons between user-centric and site-centric statistics (<xref ref-type="bibr" rid="bibr8-0273475311420244">Bucklin &amp; Sismeiro, 2009</xref>, p. 37).</p>
<p>Controlled studies on website design features are a method of website analysis used by marketing practitioners and marketing academics alike. Typically focused on a specific site feature or narrow research question, such as the impact of animation on ad recall (see <xref ref-type="bibr" rid="bibr25-0273475311420244">Kuisma, Simola, Uusitalo, &amp; Öörni, 2010</xref>) or the importance of picture–text congruence for information processing (see <xref ref-type="bibr" rid="bibr51-0273475311420244">van Rompay, de Vries, &amp; van Venrooij, 2010</xref>), controlled studies aim to provide statistically significant conclusions about what site features support what strategic and tactical goals.</p>
<p>Participatory design research requires focus group participants to actively engage in the content, labels, and navigational design of a particular website. Using various methods for template construction, participants can demonstrate to interactive marketing researchers how a website should look and function. As illustrated in <xref ref-type="table" rid="table1-0273475311420244">Table 1</xref>, participatory design contrasts with the other methods of website analysis by including the research participant in the design and layout of the user interface.</p>
<table-wrap id="table1-0273475311420244" position="float">
<label>Table 1.</label>
<caption>
<p>Methods of Website Analysis</p>
</caption>
<graphic alternate-form-of="table1-0273475311420244" xlink:href="10.1177_0273475311420244-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Website Analysis Method</th>
<th align="center">Description</th>
<th align="center">Reference Studies</th>
</tr>
</thead>
<tbody>
<tr>
<td>Expert testing</td>
<td>Industry experts decide the features, design, and navigational structure of a given website. Poor design features and ineffective redundancy are typically determined from prior experience and trial and error.</td>
<td><xref ref-type="bibr" rid="bibr19-0273475311420244">Hertzum, Jocobsen, and Molich (2002)</xref></td>
</tr>
<tr>
<td>Field testing</td>
<td>As an ethnographic-based method of market research, field testing involves close observation of end user behavior in various contexts. Detailed accounts of how end users make decisions, solve problems, and cope with informational constraints are collected and serve as a basis for further design.</td>
<td><xref ref-type="bibr" rid="bibr21-0273475311420244">Jeffries, Miller, Wharton, and Uyeda (1991)</xref></td>
</tr>
<tr>
<td>Website usability tests</td>
<td>Often assembled into a focus group like setting, website usability tests require respondents to volunteer information, thoughts, beliefs, and preferences about website design. Observed behavior and statistically significant patterns of website engagement help establish future design.</td>
<td><xref ref-type="bibr" rid="bibr6-0273475311420244">Bevan (1999)</xref>, <xref ref-type="bibr" rid="bibr38-0273475311420244">Nielsen (2008)</xref></td>
</tr>
<tr>
<td>Heuristic evaluation</td>
<td>A form of usability testing. The systematic inspection of interface and design features by end user subjects who are led by a (heuristic) checklist or rubric designed by experts.</td>
<td><xref ref-type="bibr" rid="bibr29-0273475311420244">Levi and Conrad (1996)</xref>, <xref ref-type="bibr" rid="bibr37-0273475311420244">Nielsen (1994)</xref></td>
</tr>
<tr>
<td>Comparative usability evaluation</td>
<td>A hybrid method of website analysis where usability and expert testing are both used. Aims to mitigate the weaknesses inherent in each singular approach while improving the overall reliability of evaluation results.</td>
<td><xref ref-type="bibr" rid="bibr34-0273475311420244">Molich and Dumas (2008)</xref></td>
</tr>
<tr>
<td>Clickstream data analysis</td>
<td>Evaluates the electronic record of end user discrete inputs from web server log files and/or third party monitoring services. Clickstream data can provide information on the number of visits to a site, click through rates, conversion rates, frequency, and duration.</td>
<td><xref ref-type="bibr" rid="bibr8-0273475311420244">Bucklin and Sismeiro (2009)</xref>, <xref ref-type="bibr" rid="bibr33-0273475311420244">Moe (2003)</xref></td>
</tr>
<tr>
<td>Controlled studies</td>
<td>Typically performed in a laboratory environment, controlled studies require a sufficiently large pool of test subjects who through concomitant variation and control factors provide feedback on a variety of aspects including but not limited to user preferences, processing fluency, memory/recall, and task success.</td>
<td><xref ref-type="bibr" rid="bibr43-0273475311420244">Resnick and Sanchez (2004)</xref>, <xref ref-type="bibr" rid="bibr51-0273475311420244">van Rompay, de Vries, and van Venrooij (2010)</xref></td>
</tr>
<tr>
<td>Participatory design</td>
<td>Participants with the relevant background experience and interests are prompted to choose among several predesigned templates to contribute to a website’s design and layout. Customized and personalized designs are then compared and extrapolated.</td>
<td><xref ref-type="bibr" rid="bibr11-0273475311420244">Chaffey et al. (2009)</xref>, Robertson (2001)</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>One activity of participatory design is card sorting. As <xref ref-type="bibr" rid="bibr11-0273475311420244">Chaffey et al. (2009)</xref> explain, “Card sorting is a way in which users can become actively involved in the development process of information architecture . . . in order to facilitate information task completion or information goals (p. 407). Opportunities for customization and personalization, in particular, figure prominently for this qualitative research technique.</p>
<p>Traditionally within marketing education, the developing practices of marketing practitioners are communicated to professors and students through a variety of channels. These include, but are not limited to, professional development conferences, seminars, trade journals, and consultation with the discipline’s textbook authors and publishers. Yet as a new set of research techniques become more and more common within a given field, it is the onus of marketing educators to tie emerging practice to established marketing theory. It is our belief, in particular, that gains in strategic thinking and creative application are best nurtured when current practice is first modeled theoretically and then subsequently through classroom activities and mock demonstrations.</p>
</sec>
<sec id="section4-0273475311420244">
<title>Theoretical Frameworks for Website Interactivity</title>
<p><xref ref-type="bibr" rid="bibr31-0273475311420244">Malthouse and Shankar (2009)</xref> identify two core components of the interactive marketing environment: (a) website design, including the creation of engaging customer contact points; and (b) the measurement and management of website effectiveness. Whereas the first is typically led by industry innovation and prototype models, the second is a routine step of the iterative design/development process. Measures for tactical success include how well a website is able to facilitate the exchange process and affect performance drivers, such as loyalty intentions, customer satisfaction, and purchase intent (<xref ref-type="bibr" rid="bibr11-0273475311420244">Chaffey et al., 2009</xref>). For strategic planning, having in hand a clear model of website interactivity is undoubtedly useful. The Internet, as a communication medium and marketing channel, relies fundamentally on a series of opt-in choices and intentional decisions by the end user. Understanding the type and quality of interaction afforded by a website, therefore, is paramount for designers and marketers when drafting and revising content.</p>
<p>For marketing educators, study of website interactivity (as a theoretical construct) presents an opportunity to illustrate how research technique is closely tied to a marketer’s theoretical assumptions and research objectives. Decisions not only about the type of information sought in data collection but also how it should be used for drawing conclusions and making recommendations are elemental for establishing scientific rigor in the research process. For qualitative researchers, where worries of subjectivity, bias, and unsystematic process often cast suspicion on the reliability of results, recourse to process models and grounded theory are essential. As noted by <xref ref-type="bibr" rid="bibr34-0273475311420244">Molich and Dumas (2008)</xref>, the lack of developed theory early on in the field of usability testing gave rise to a detected “evaluator effect” (i.e., inconsistency among interpreters) in one study involving identical test sessions. Marketing educators interested to explore qualitative user-centric methods of website analysis, therefore, will find a discussion of website interactivity to be a helpful prologue for subsequent instruction in qualitative research technique.</p>
<p>Building on the research of <xref ref-type="bibr" rid="bibr49-0273475311420244">Tremayne (2005)</xref>, who systematically reviews the empirical literature on website interactivity and finds two distinct models beginning to dominate, we now turn to consider each and discuss their potential roles for information architecture assessment and usability testing. Although representing two separate models for how website interactivity is conceived in the marketing academic literature, each model does not prima facie exclude the other as a possible construct. In fact, given the particular goals and assumptions of the researcher, it is possible for both models to be used in concert.</p>
</sec>
<sec id="section5-0273475311420244">
<title>A Functional Model of Website Interactivity</title>
<p>In a functional model of website interactivity, content is juxtaposed with an end user’s private experience. Whereas the content of a site is “primary” and “action initiating,” the end user’s experience, by contrast, is “prompted” and “reactive.” A website is minimally interactive if and only if there is a completed message cycle that includes (a) a prompted end user’s response and (b) verifiable feedback. In a technical sense, “response” and “feedback” are two measurable variables in a communication process that establish reciprocity between designer/marketer-led content, on the one hand, and end user/customer experience, on the other (see <xref ref-type="fig" rid="fig1-0273475311420244">Figure 1</xref>). As the volume and complexity of response and feedback measures increase, so does the level of interactivity.</p>
<fig id="fig1-0273475311420244" position="float">
<label>Figure 1.</label>
<caption>
<p>Functional model of website interactivity</p>
<p>Source: Adapted from <xref ref-type="bibr" rid="bibr49-0273475311420244">Tremayne (2005)</xref>.</p>
</caption>
<graphic xlink:href="10.1177_0273475311420244-fig1.tif"/></fig>
<p>To give a very simple illustration: say the content of a given website includes a hyperlink to additional content or material. Insofar as the end user is prompted to make an intentional choice and click on the link, both the response (i.e., mouse click) and the feedback (i.e., the electronic record of the mouse click from a server log file) establish website interactivity. On this simple example, only if the mouse click was not an accident or mistake, and conversely, only if the designer cares enough to look and check the server log files (or use some other feedback mechanism) to verify that the end user did in fact click the link, can website interactivity be established. The real complexity and power of the functional model, however, resides in the different strategies the researcher can use to obtain confident measures for response and feedback. And to be sure, both quantitative and qualitative methods of data analysis can play a role. In fact, an effective research design might embrace both user-centric and site-centric data types when establishing response and feedback measures for a given website feature. If, for example, a server log file confirms a verbal cue from an actual user that a certain feature of the site was interacted with, response and feedback measures for website interactivity receive independent verification.</p>
<p>User-centric qualitative research is perhaps most relevant for exploratory-type research. Web designers and marketers who are interested in brainstorming for content and organizational design, for example, might implement various exercises in participatory design to gain user insight. In this respect, real end users of a website are involved early on in the design process allowing for a type of background communication to take place with designers who are interested in monitoring website interactivity. On the functional model, information architecture assessment belongs on the front-end of website design or just prior to a planned revision/upgrade event. Keeping strategic marketing objectives close in hand, qualitative researchers will solicit information from users to inform navigational layout, website aesthetics, and response and feedback measures.</p>
<p>For the functional model of website interactivity, usability testing can be leveraged by market researchers in a number of ways. Used in tandem with clickstream data analysis, as indicted briefly above, verbal cues from an end user test-subject can be used by researchers to independently establish response and feedback measures. As parameters for detailing the end user/customer experience evolve, qualitative researchers will be able to evaluate test-subjects on an array of tacit and explicit experience dimensions. <xref ref-type="bibr" rid="bibr30-0273475311420244">Loiacono, Watson, and Goodhue (2007)</xref>, for example, have developed a 12-dimension instrument, known as <italic>WebQual</italic>, that aims to assess customer experience across non–industry specific web environments. <xref ref-type="bibr" rid="bibr42-0273475311420244">Petre, Minocha, and Roberts (2006)</xref>, drawing from the field human–computer interaction, also developed an instrument, known as <italic>E-SEQUAL</italic>, that aims to assess online customer experience and service quality for both the e-shopping and e-travel environments. Again, depending on the strategic goals of the marketer, qualitative researchers will need to lead test-subjects through a careful scripted interview process to provide reliable data for response and feedback measures.</p>
</sec>
<sec id="section6-0273475311420244">
<title>A Perceptual Model of Website Interactivity</title>
<p>An alternative model for assessing website interactivity is the perceptual model. Here the end user/customer experience is parsed out into a number of categories, such as “enjoyment,” “ease of use,” and “trust” that maps closely with the goals and design of the user interface (see <xref ref-type="fig" rid="fig2-0273475311420244">Figure 2</xref>). Unlike the functional model, which allows for both tacit and explicit response measures, the perceptual model relies on conscious self-reporting from the end user/customer.</p>
<fig id="fig2-0273475311420244" position="float">
<label>Figure 2.</label>
<caption>
<p>Perceptual model of website interactivity (with a sample set of end user/customer experiences)</p>
<p>Source: Adapted from <xref ref-type="bibr" rid="bibr49-0273475311420244">Tremayne (2005)</xref>.</p>
</caption>
<graphic xlink:href="10.1177_0273475311420244-fig2.tif"/></fig>
<p>Through the use of postexperience surveys and/or qualitative questionnaires, website interactivity emerges as a second-order dimension that is useful for predicting consumer attitudes, intensions, and behavior. Although work in this area is still preliminary, perceptual measures, including the model for website interactivity, can be integrated into broader assessment for website quality (see, e.g., <xref ref-type="bibr" rid="bibr23-0273475311420244">Kim &amp; Niehm, 2009</xref>). As careful study of online behavioral tendencies and cultural preferences continue, it is reasonable to expect more and more precise instruments will be developed.</p>
<p>The roles for information architecture assessment and usability testing for the perceptual model reside principally in two tasks: (a) identifying useful and relevant experience categories and (b) qualitatively assessing the presence, intensity, and frequency of individual category experiences. In general, perceptual models provide qualitative researchers clear rolls for data collection. Although needing to control for consistent test-environments, cogent sampling methods, and nonleading questioning prompts, researchers can record precise details on a broad spectrum about how end users engage a given website. Recently, <xref ref-type="bibr" rid="bibr54-0273475311420244">Wang and Senecal (2007)</xref> designed a perceptual research model to assess usability (as a second-order factor) from three first-order experiences (viz., ease of navigation, speed, and interactivity). Although transposing the dimension categories slightly from the sample-set presented in <xref ref-type="fig" rid="fig2-0273475311420244">Figure 2</xref>, their study provides a useful jumping-off point in classroom discussions for exploring research design and objectives.</p>
</sec>
<sec id="section7-0273475311420244">
<title>Providing Learning Experiences</title>
<p>After introducing students to the basics of information architecture assessment and website usability tests, there is an excellent opportunity to engage them in several hands-on exercises to help bring these forms of research to life and demonstrate their applicability to the interactive marketing process. To accomplish this learning objective, we suggest three separate exercises to illustrate the research process and research outcomes. From our perspective, our insight into pedagogical strategy has been largely informed by lesson plans designed and implemented for an undergraduate consumer research class, done in the spring of 2010 (with a class size of 22 students, at the junior and senior levels). In the remaining sections of the article, we outline three exercises and provide commentary on how they may be implemented into future courses.</p>
</sec>
<sec id="section8-0273475311420244">
<title>Website Usability Testing in the Classroom</title>
<sec id="section9-0273475311420244">
<title>Classroom Activity 1: Mock “Think Aloud” Interview</title>
<p>To replicate a website usability test in the classroom, all students were asked to bring in their laptops. This exercise could also be done in a computer lab environment if not enough of your students have laptops, or if Internet access is not readily available. Although it is preferred that every student has access to a computer, in actuality only half of your students will need to have a computer for this exercise. The class was then asked to form pairs and to decide which individual would be the researcher and which would be the research participant.</p>
<p>Next, a brief one-page script was distributed to each student researcher (see <xref ref-type="app" rid="app1-0273475311420244">Appendix A</xref>). The script includes five sections: introduction to session, presentation of scenario, probing questions, debriefing questions, and concluding remarks. The introduction to the session includes a brief explanation of the purpose of the research, which the researcher was prompted to read to the participant. In addition, the introduction encourages the participant to use the “think aloud” method of completing the task so that the researcher can gain some insight into his/her intentions, behavior, and decision-making abilities. If the participant’s vocal input becomes too quiet or too sparse, the researcher is instructed to facilitate communication by asking questions and offering encouragement. Sample probing questions, such as “Why did you click on that link?” “What did you expect to find when you clicked on that link?” “Did that page provide you with the content you expected to find?” and “What are you searching for?” were provided for reference. Next, the researcher was provided a sample task for the participant to attempt. In our example scenario, the participant was asked to use two different websites (<ext-link ext-link-type="uri" xlink:href="http://IKEA.com">IKEA.com</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://Sears.com">Sears.com</ext-link>) to find a four-burner gas range less than $1,000. Participants were also notified that they were expected to identify warranty and delivery information for the specified product.</p>
<p>Although any task and combination of websites can be used, a few important factors to be considered are as follows. First, website usability tasks work best when a participant is unfamiliar with a website and thus is truly responding to the stimulus presented and not using past experiences or knowledge of the site to complete the task. Second, the task should be complicated enough that it requires a fairly significant amount of time, and the outcome of the search is perhaps in question. For instance, solely finding the four-burner gas range would likely have been too simple, but adding the warranty and delivery parts into the equation added extra steps, which were significant in the differentiation of the two sites. The instructor needs to use due diligence to select sites that are potentially seen as having some weaknesses or possible areas of confusion. In our IKEA versus Sears example, one of these sites was determined to be superior in its organization over the other. Website usability testing typically uses two to three websites in a session so that the participant can form a source of reference between the tested site and another site, even though the test and control site identities will not be revealed to the participant.</p>
<p>Once the participant begins the task, the researcher is expected to have an active role in recording the search process and feedback from the research participant. In our sample scenario, every student had a laptop, which aided the researcher in recording the session, but this could be eschewed for pen and paper if computers are unattainable for every participant. Although it is unrealistic that the researcher will be able to capture every movement and statement made by the subject, we found that most students were able to keep track of the subjects’ navigation through the site. After the completion of the task, with the prompting of appropriate probing questions, the researcher was provided a list of debriefing questions to ask the subject. Sample questions included “If you could tell the designer of <ext-link ext-link-type="uri" xlink:href="http://IKEA.com">IKEA.com</ext-link> any three things that you would change about their site what would they be?” “What about <ext-link ext-link-type="uri" xlink:href="http://Sears.com">Sears.com</ext-link>?” Participants were then read a sample fictitious statement, which thanked them for their time and described how they would receive their (mock) payment, and how they may be able to contact the researcher if they thought of anything else they wanted to share on the subject after they left.</p>
<p>For the next step of our classroom exercise, the first website was projected in front of the classroom and one by one the student researchers were asked to take the class through their subject’s search process, step by step. Researchers would explain, for instance, whether participants began by clicking on a navigational link such as “kitchens or appliances,” or whether they entered a specific term in the search field (and if so, they would indicate what the term was and what the results were). The instructor can replicate this search process onscreen for the entire class to view. By having each researcher identify the path of his/her subject, it demonstrates to students that multiple paths exist and that there is no right or wrong path, but depending on the path chosen, users experience different levels of success and satisfaction. Salient points to raise for class discussion include “what happens when you’re too specific or too vague when you enter a search query?” And “entering ‘four-burner gas range’ was a common starting point, but one which resulted in 0 returns or matches, what might explain that?”</p>
<p>After completing a review of each subject’s search process and roadblocks, a discussion was facilitated about the strengths and weaknesses of the site and what recommendations would be given to the (mock) client. In hindsight, this task could also be required of the student researcher and student participant to develop together at the conclusion of their website usability test session. Although understanding the website usability process is important, the development of critical thinking skills and the formulation of actionable research outcomes are also of significant importance (<xref ref-type="bibr" rid="bibr44-0273475311420244">Roy &amp; Macchlette, 2005</xref>). Although an instructor may choose to award points for participation in these in-class activities, one goal of this exercise can be to demonstrate a specific methodological tool and the types of results it can yield.</p>
</sec>
</sec>
<sec id="section10-0273475311420244">
<title>Website Usability Testing Outside the Classroom</title>
<sec id="section11-0273475311420244">
<title>Take-Home Assignment: Practice Field-Test and Research Report</title>
<p>To develop critical thinking skills further, a separate assignment was designed where students develop and execute their own website usability test and create a formal research summary (inclusive of research findings and client recommendations). An example of this assignment can be found in <xref ref-type="app" rid="app2-0273475311420244">Appendix B</xref>. Although the classroom exercise was effective in familiarizing students with website usability testing, this take-home-type assignment requires greater thought and application of the underlying principles involved in website usability tests.</p>
<p>For this assignment students were given the freedom to identify a website to be used as a mock client, but a website could also be assigned for the purpose of this exercise. First, students were asked to develop their own introduction to the session, presentation of scenario, possible probing questions, and debriefing questions. It was emphasized to students that the development of the presentation of the scenario would be the most critical component of developing the script. After completing the script, students were instructed to perform their website usability test using a friend or relative.</p>
<p>The last part of the assignment was for students to provide a research summary including a section for specific research findings and their actionable recommendations. Students were asked to create a formal research report using word processing software, but this exercise could also be complemented by having students create an oral presentation with visual aids to summarize their research (<xref ref-type="bibr" rid="bibr56-0273475311420244">Young &amp; Murphy, 2003</xref>).</p>
<p>For this assignment students were evaluated on several key factors. First, was their ability to design an appropriate task for testing the website’s usability sufficiently rigorous? If the task is too simple, involving only one click, it is unlikely to provide much analysis for improvement and thus little value to an actual client. If the student failed to put enough thought into the specific task you will likely notice that the report is very brief and they tend to offer little critique of the actual site. This is why it is important to direct your students to select nonmainstream sites. Leading retailers, such as Best Buy or Apple, for example, likely conducts extensive website usability tests before rolling out new websites and are apt to be more user friendly. Next, students should be evaluated on the data they actually captured from their respondents. Although some respondents are likely to be more forthcoming than others, it is the researcher’s duty to direct the subject through thoughtful questions regarding his/her specific actions or delays while navigating the site. Third, was the student able to explain specific obstacles encountered by the user and make strategic recommendations for how these hurdles could be remedied moving forward? Problem identification and the ability to outline tangible solutions are important marketing research skills for undergraduates to practice. Mastery of these two skills, to be sure, will go a long way to bridge the practitioner–academic divide. Finally, it is important to have students reflect on their own personal experience and challenge them to critique the job they did in creating and administering their usability test. If the student selected a task that was too simple, and thus failed to yield any significant findings, did he/she acknowledge this shortcoming? At the very least, most novice qualitative researchers should be able to identify opportunities that were missed to ask participants follow-up questions, which could then lead to a better understanding of behavior.</p>
</sec>
</sec>
<sec id="section12-0273475311420244">
<title>Information Architecture in the Classroom</title>
<sec id="section13-0273475311420244">
<title>Classroom Activity 2: Participatory Design Card Sort</title>
<p>Card sort exercises, specifically in the development of navigational bars, are a common technique used in information architecture research. The goal of this exercise is twofold. First is to determine the end user’s understanding and comprehension of certain terms. For instance, if end users are on an e-retailing site and they see the term <italic>office</italic>, what types of products do they expect to find under that category? If that categorization is unclear or inconsistent with an end user’s expectations, then the card sort exercise seeks to find a replacement modifier for that term. The second focus of this technique is to begin to develop a framework for presenting these modifiers in an organized manner that is both simplistic and intuitive. Research participants are typically asked to create a schema for grouping modifiers into “similar” and “closely related” categories.</p>
<p>Although this process can be described to students, it is also fairly easy to implement into a classroom exercise. The following details how this was recently conducted with great success in one 22-person class. First, students were divided into multiple groups of four to six individuals. Next, each group was provided an identical set of index cards containing all the major product categories offered by an e-retailer, <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link>. Instructions were then provided to organize the product categories by combining those goods that they think are related and can be clustered together. Students were then informed that there was no limit to the number of groupings they could create. Students were also provided blank cards and told that they could create new modifiers, duplicate modifiers, or could adjust the names on the cards provided. See <xref ref-type="app" rid="app3-0273475311420244">Appendix C</xref> for assignment instructions. When this exercise was conducted over the past semester, no two groups organized the product categories the same and none were even remotely close to <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link>’s current navigation. <xref ref-type="table" rid="table2-0273475311420244">Table 2</xref> provides a sample scenario of how students might organize the product categories featured on <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link> and illustrates how a classroom exercise could be concluded.</p>
<table-wrap id="table2-0273475311420244" position="float">
<label>Table 2.</label>
<caption>
<p>Sample Output of Card Sort Exercise</p>
</caption>
<graphic alternate-form-of="table2-0273475311420244" xlink:href="10.1177_0273475311420244-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Group 1</th>
<th align="center">Group 2</th>
<th align="center">Group 3</th>
<th align="center">Group 4</th>
<th align="center">Group 5</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Books</td>
<td>1. Books, Kindle</td>
<td>1. Books</td>
<td>1. Books, Kindle</td>
<td>1. Books, Kindle</td>
</tr>
<tr>
<td>2. Movies, Music</td>
<td>2. Movies</td>
<td>2. Movies, Digital Downloads</td>
<td>2. Movies, Music</td>
<td>2. Movies</td>
</tr>
<tr>
<td>3. Digital Downloads</td>
<td>3. Music</td>
<td>3. Music, Digital Downloads</td>
<td>3. Digital Downloads</td>
<td>3. Music</td>
</tr>
<tr>
<td>4. Electronics, Computers, Kindle</td>
<td>4. Digital Downloads</td>
<td>4. Kindle, Digital Downloads</td>
<td>4. Electronics, Computers, Office</td>
<td>4. Digital Downloads</td>
</tr>
<tr>
<td>5. Home, Office, Grocery</td>
<td>5. Electronics, Games</td>
<td>5. Electronics, Computers, Office</td>
<td>5. Grocery, Health, Beauty</td>
<td>5. Electronics, Computers</td>
</tr>
<tr>
<td>6. Health</td>
<td>6. Grocery, Health</td>
<td>6. Grocery, Health</td>
<td>6. Toys, Kids, Baby, Games</td>
<td>6. Grocery</td>
</tr>
<tr>
<td>7. Toys, Games, Sports</td>
<td>7. Toys, Kids, Baby</td>
<td>7. Toys, Games, Kids, Baby</td>
<td>7. Sports, Outdoor</td>
<td>7. Health, Beauty</td>
</tr>
<tr>
<td>8. Kids, Baby</td>
<td>8. Clothing, Shoes, Jewelry</td>
<td>8. Beauty, Jewelry</td>
<td>8. Home, Garden</td>
<td>8. Toys, Games, Sports</td>
</tr>
<tr>
<td>9. Clothing, Shoes</td>
<td>9. Office, Computers</td>
<td>9. Clothing, Shoes</td>
<td>9. Clothing, Shoes, Jewelry</td>
<td>9. Kids, Baby</td>
</tr>
<tr>
<td>10. Jewelry, Beauty</td>
<td>10. Sports, Outdoors</td>
<td>10. Sports</td>
<td>10. Tools, Auto, Industrial</td>
<td>10. Home, Garden, Outdoor</td>
</tr>
<tr>
<td>11. Tools, Industrial</td>
<td>11. Home, Garden</td>
<td>11. Home, Garden, Outdoors</td>
<td/>
<td>11. Auto, Office</td>
</tr>
<tr>
<td>12. Auto</td>
<td>12. Auto</td>
<td>12. Tools, Auto, Industrial</td>
<td/>
<td>12. Tools, Industrial</td>
</tr>
<tr>
<td>13. Outdoors, Garden</td>
<td>13. Tools, Industrial</td>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<p>After completing the card sort exercise each team was asked what specific terms they struggled defining in terms of meaning or products likely to be sold under that descriptor. “Games” was a common issue because it was strongly correlated with video games (electronic) as well as board games (toys). Some suggested that the word “video” could be added as a modifier and it could be placed with electronics or computers. Surprisingly, no one associated games with movies and music (where <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link> currently groups these products). As we began discussing confusion and meaning, students began to understand that the terms surrounding a modifier can sometimes help provide context. For instance, with the <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link> homepage, students understood that games refer to video games because it was grouped with movies and music. Other terms that groups struggled with as being too generic or ambiguous were “Industrial,” “Auto,” “Baby,” “Home,” and “Outdoors.” During class discussion, particular questions were raised about whether “auto” actually meant vehicles, or just vehicle accessories? Then using the document projector in class, each team presented their organizational schema and discussed their thought process in clustering the product categories in the manner they designed. This process fairly accurately reproduced what focus group participants are asked to do in actual participatory design exercises. This exercise should take approximately 30 to 45 minutes of class time to allow for formulation of classifications and for the discussion of potential implications for interactive marketing and website design. Again, this exercise is not intended to test a student’s mastery of a concept, but instead it is intended to provide a hands-on experience of how this methodological tool works.</p>
</sec>
</sec>
<sec id="section14-0273475311420244">
<title>Future Research Directions</title>
<p>Although usability testing and information architecture assessment are still evolving and only lightly discussed in the marketing academic literature and Internet marketing textbooks, there are plenty of resources online including companies that offer these services, which are a great resource when developing a module on this subject matter. Just in the past year we have had multiple students ask for assistance in applying these techniques in various contexts, such as student competitions (e.g., The DMEF Collegiate ECHO Direct/Interactive Marketing Challenge) and professional opportunities (e.g., internship positions and pro bono consulting). It is our hope that this article will initiate a productive dialog for discussing how these qualitative analytic methods can be further integrated into a marketing curriculum and possibly spawn other ideas for how they can be implemented and discussed in the classroom.</p>
<p>A conscious decision was made to downplay website analytics in this article, as this topic deserves its own discussion. Although the growing relevance and accessibility of Google analytics, for example, can provide for creative lesson plans for marketing educators, the goal of the teaching units described in this article was geared to provide students with the skills necessary to develop their own qualitative tests of website usability. In addition, we found that these exercises were eye opening to students who mentioned that it created an awareness of career opportunities that were of interest to them. In the future, the authors seek to create a companion piece to this unit that addresses the quantitative component to website performance through Google analytics and other web analytic tools. The goal will be to provide an overview of the topics, as well as specific exercises for engaging students inside and outside of the classroom.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0273475311420244">
<title>Appendix A</title>
<sec id="section15-0273475311420244">
<title>Classroom Activity 1: Mock “Think Out Loud” Interview</title>
<p>Researcher please read the following instructions to your research participant to introduce the session:</p>
<p>Thank you for joining me today. As the telephone recruiter described to you, the purpose of today’s researcher is to get consumers’ thoughts on the relative strengths and weaknesses of a couple of shopping websites that sell common household appliances. During our session today I will ask you to navigate each one of the selected sites and complete a specific task that I will read to you shortly. While conducting this task I ask that you do me a favor and think aloud while you’re completing your task. For instance, if you’re looking for something specific and having problems finding it, say “I’m looking for a link that says blank but I can’t seem to find that word or a similar word.” Ideally you will speak continuously throughout your time online. If you are quiet I will prompt you to tell me what you are thinking or will ask you specific questions regarding your actions online. Please remember that there is no right or wrong way to conduct this search, I’m simply interested in seeing how you might go about completing this task and what you encounter during your search.</p>
<p>Next, you will provide the following instructions to your research participant:</p>
<p>At this time I would like for you to imagine that you’re in the market for a new four-burner gas range (combo oven and cook top) for under $1,000. A friend recommended that you check out <ext-link ext-link-type="uri" xlink:href="http://IKEA.com">IKEA.com</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://sears.com">sears.com</ext-link> for this product. In addition to identifying what products are available you are also interested in determining what warranties are standard with your selected range and the costs for delivery and installation of this item. Please go to <ext-link ext-link-type="uri" xlink:href="http://IKEA.com">IKEA.com</ext-link> now and begin your search for this item.</p>
<p>While your subject is conducting his/her search you need to record his/her behavior. Document exactly how your subject navigates through the website and the results of each click. You also need to engage your participant to talk as much as possible. If your participant is too quiet please probe your participant to describe his/her process. Below are some sample probing questions you may want to ask during your test:</p>
<list id="list1-0273475311420244" list-type="bullet">
<list-item><p>Why did you click that?</p></list-item>
<list-item><p>How did you know you could click that?</p></list-item>
<list-item><p>What did you expect to find when you clicked that?</p></list-item>
<list-item><p>Why did you hit your browser back button?</p></list-item>
</list>
<p>Once your subject has completed all the assigned tasks on the <ext-link ext-link-type="uri" xlink:href="http://IKEA.com">IKEA.com</ext-link> website, please ask your participant to engage in the same set of activities on the <ext-link ext-link-type="uri" xlink:href="http://sears.com">sears.com</ext-link> site. Follow the same process of recording their actions and words, while probing your respondent if they fail to describe their actions.</p>
<p>After the completion of the task on <ext-link ext-link-type="uri" xlink:href="http://sears.com">sears.com</ext-link>, please ask your participant the following debriefing questions:</p>
<list id="list2-0273475311420244" list-type="bullet">
<list-item><p>Overall how would you rate your shopping experience on the <ext-link ext-link-type="uri" xlink:href="http://IKEA.com">IKEA.com</ext-link> site? If you could offer any suggestions to the designers of this site what would they be?</p></list-item>
<list-item><p>Overall how would you rate your shopping experience on the <ext-link ext-link-type="uri" xlink:href="http://sears.com">sears.com</ext-link> site? If you could offer any suggestions to the designers of this site what would they be?</p></list-item>
<list-item><p>Are there any other thoughts that you would like to share with me regarding the sites you visited today?</p></list-item>
</list>
</sec>
</app>
<app id="app2-0273475311420244">
<title>Appendix B</title>
<sec id="section16-0273475311420244">
<title>Take-Home Assignment: The Practice Field-Test and Research Report</title>
<p>Identify a corporate or e-retailing website that you think has some navigational flaws. Once you have identified the website, create a brief script for a website usability test for this site and one competitive site. Your script should have four essential areas, with the greatest focus being on the second area.</p>
<list id="list3-0273475311420244" list-type="bullet">
<list-item><p>Introduction to session</p></list-item>
<list-item><p>Presenting the scenario</p></list-item>
<list-item><p>Probing questions</p></list-item>
<list-item><p>Debriefing questions</p></list-item>
</list>
<p>Conduct your website usability test with a friend or family member. The participant does not need to be familiar with the site; in fact, the test will work better if the person is unfamiliar with the site. If your participant is able to complete your assigned task too easily, or quickly, you will likely struggle in writing a research report with actionable recommendations. If you find your first usability test unsuccessful, you may need to reevaluate your scenario and create a new script, change websites, or attempt a usability test with a second participant. (The more mainstream the website [i.e., BestBuy] the better the site is likely to perform, so I would recommend picking a more obscure site for best results.)</p>
<list id="list4-0273475311420244" list-type="bullet">
<list-item><p>Provide a brief research report similar to what a research company would provide to a paying client. The report should begin by summarizing your research methodology, subject description, and general approach to completing assigned task. Next you should outline specific findings you uncovered from your usability test. For example, were there navigational headers that were confusing or unclear? You should also acknowledge strengths as well as weaknesses. Last, you should clearly present actionable recommendations that you would make to this client. For instance, “make navigational links change color so that users know they are clickable.”</p></list-item>
<list-item><p>Once you have completed you research report, please reflect on your personal experience with this website usability test and identify specific elements of your website usability task that you would likely change if you had the opportunity to conduct this test again. This can be appended to your research report.</p></list-item>
</list>
</sec>
</app>
<app id="app3-0273475311420244">
<title>Appendix C</title>
<sec id="section17-0273475311420244">
<title>Classroom Activity 2: Participatory Design Card Sort</title>
<p>(Prior to performing this exercise in class, the instructor will need to create a series of note cards containing all necessary descriptors.)</p>
<p><italic>Instructions</italic>: Having already discussed the importance of information architecture in developing website navigation, today we’re going to look at a common technique used in consumer research, the card sort exercise. This technique is often used in interviews and focus groups to provide consumers an opportunity to develop a framework for grouping or organizing information contained on a website. We’re going to practice this technique today using the products offered by <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link>. At this time please form groups of four to five. Each group is going to receive an identical envelope containing two stacks of index cards. The first group of index cards has a word or phrase printed on the front of each card. These terms refer to categories of goods or products offered by <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link>. The second group of index cards provided to you should be blank. Your objective is to create an information architecture framework for <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link> that would enlighten their web developers on appropriate product groupings for their website navigational bars. To complete this task, please follow these steps:</p>
<list id="list5-0273475311420244" list-type="order">
<list-item><p>As a group review all the terms provided to you. When you see each term, is it clear to your group what types of products you would find on <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link> on clicking on that link? If you feel a term is unclear, confusing, or ambiguous, please cross through the term and add a new term, or add a modifier before or after the word to add clarification. Once your team has agreed on all the terms provided please continue to the next step.</p></list-item>
<list-item><p>Now, please take the 25 index cards containing product category titles and sort these terms into categories of goods that you would expect to see listed together on <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link>. There are no limitations as far as the number of your groupings you may create. If you feel that none of the product categories are related you may decide all 25 product categories should remain separate, but most likely you should be able to reduce the number of categories. In creating these groupings feel free to use the blank index cards provided to you to create headers to describe the products found each group.</p></list-item>
<list-item><p>Your entire team must agree on the structure of all 25 categories, as well as any additional classifications your group has introduced.</p></list-item>
</list>
</sec>
</app>
</app-group>
<fn-group>
<fn fn-type="conflict">
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0273475311420244">
<citation citation-type="web">
<collab>AACSB International</collab>. (<year>2010</year>, <month>January</month> <day>31</day>). <source>Eligibility procedures &amp; accreditation standards for business accreditation</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.aacsb.edu/accreditation/business/standards/aacsb_business_standards.pdf">http://www.aacsb.edu/accreditation/business/standards/aacsb_business_standards.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr2-0273475311420244">
<citation citation-type="web">
<collab>American Marketing Association</collab>. (<year>2010</year>, <month>March</month> <day>15</day>). <article-title>The digital issue</article-title>. <source>Marketing News</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.marketingpower.com/ResourceLibrary/MarketingNews/Pages/2010/3_15_10/The_State_of_Digital_Marketing.aspx">http://www.marketingpower.com/ResourceLibrary/MarketingNews/Pages/2010/3_15_10/The_State_of_Digital_Marketing.aspx</ext-link></comment></citation>
</ref>
<ref id="bibr3-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ackerman</surname><given-names>D. S.</given-names></name>
<name><surname>Gross</surname><given-names>B. L.</given-names></name>
<name><surname>Perner</surname><given-names>L.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Instructor, student, and employer perceptions on preparing marketing students for changing business landscapes</article-title>. <source>Journal of Marketing Education</source>, <volume>25</volume>, <fpage>46</fpage>-<lpage>56</lpage>.</citation>
</ref>
<ref id="bibr4-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Becker</surname><given-names>S. A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>A study of web usability for older adults seeking online health resources</article-title>. <source>ACM Transactions on Computer–Human Interaction</source>, <volume>11</volume>, <fpage>387</fpage>-<lpage>406</lpage>.</citation>
</ref>
<ref id="bibr5-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Benbunan-Fich</surname><given-names>R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Using protocol analysis to evaluate the usability of a commercial web site</article-title>. <source>Information &amp; Management</source>, <volume>39</volume>, <fpage>151</fpage>-<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr6-0273475311420244">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bevan</surname><given-names>N.</given-names></name>
</person-group> (<year>1999</year>, <month>June-July</month>). <source>Common industry format usability tests</source>. <conf-name>Paper presented at UPA’98, Usability Professionals Association</conf-name>, <conf-loc>Scottsdale, AZ</conf-loc>.</citation>
</ref>
<ref id="bibr7-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Braddy</surname><given-names>P. W.</given-names></name>
<name><surname>Meade</surname><given-names>A. W.</given-names></name>
<name><surname>Kroustalis</surname><given-names>C. M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Online recruiting: The effects of organizational familiarity, website usability, and website attractiveness on viewers’ impressions of organizations</article-title>. <source>Computers in Human Behavior</source>, <volume>24</volume>, <fpage>2992</fpage>-<lpage>3001</lpage>.</citation>
</ref>
<ref id="bibr8-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bucklin</surname><given-names>R. E.</given-names></name>
<name><surname>Sismeiro</surname><given-names>C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Click here for interact insight: Advances in clickstream data analysis in marketing</article-title>. <source>Journal of Interactive Marketing</source>, <volume>23</volume>, <fpage>35</fpage>-<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr9-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Calder</surname><given-names>B.</given-names></name>
<name><surname>Malthouse</surname><given-names>E.</given-names></name>
<name><surname>Schaedel</surname><given-names>U.</given-names></name>
</person-group> (<year>2009</year>). <article-title>An experimental study of the relationship between online engagement and advertising effectiveness</article-title>. <source>Journal of Interactive Marketing</source>, <volume>23</volume>, <fpage>321</fpage>-<lpage>331</lpage>.</citation>
</ref>
<ref id="bibr10-0273475311420244">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Chadwick-Dias</surname><given-names>A.</given-names></name>
<name><surname>McNulty</surname><given-names>M.</given-names></name>
<name><surname>Tullis</surname><given-names>T.</given-names></name>
</person-group> (<year>2003</year>, <month>November</month>). <source>Web usability and age: How design changes can improve performance</source>. <conf-name>Paper presented at 2003 Conference on Universal Usability</conf-name>, <conf-loc>Vancouver, British Columbia, Canada</conf-loc>.</citation>
</ref>
<ref id="bibr11-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chaffey</surname><given-names>D.</given-names></name>
<name><surname>Ellis-Chadwick</surname><given-names>F.</given-names></name>
<name><surname>Mayer</surname><given-names>R.</given-names></name>
<name><surname>Johnston</surname><given-names>K.</given-names></name>
</person-group> (<year>2009</year>). <source>Internet marketing: Strategy, implementation, and practice</source> (<edition>4th ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation>
</ref>
<ref id="bibr12-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Coupey</surname><given-names>E.</given-names></name>
</person-group> (<year>2004</year>). <source>Digital business: Concepts and strategy</source> (<edition>2nd ed.</edition>). <publisher-loc>New Jersey, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation>
</ref>
<ref id="bibr13-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Danielson</surname><given-names>D. R.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Transitional volatility in web navigation</article-title>. <source>IT &amp; Society</source>, <volume>1</volume>(<issue>3</issue>), <fpage>131</fpage>-<lpage>158</lpage>.</citation>
</ref>
<ref id="bibr14-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dellaert</surname><given-names>B.</given-names></name>
<name><surname>Kahn</surname><given-names>B. E.</given-names></name>
</person-group> (<year>1999</year>). <article-title>How tolerable is delay? Consumers’ evaluations of internet web sites after waiting</article-title>. <source>Journal of Interactive Marketing</source>, <volume>13</volume>(<issue>1</issue>), <fpage>41</fpage>-<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr15-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Diamond</surname><given-names>N.</given-names></name>
<name><surname>Koernig</surname><given-names>S. K.</given-names></name>
<name><surname>Iqbal</surname><given-names>Z.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Uniting active and deep learning to teach problem-solving skills: Strategic tools and the learning spiral</article-title>. <source>Journal of Marketing Education</source>, <volume>30</volume>, <fpage>116</fpage>-<lpage>129</lpage>.</citation>
</ref>
<ref id="bibr16-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>George</surname><given-names>C. A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Usability testing and design of a library website: An iterative approach</article-title>. <source>OCLC Systems &amp; Services</source>, <volume>21</volume>, <fpage>167</fpage>-<lpage>180</lpage>.</citation>
</ref>
<ref id="bibr17-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gummesson</surname><given-names>E.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Qualitative research in marketing: Road-map for a wilderness of complexity and unpredictability</article-title>. <source>European Journal of Marketing</source>, <volume>39</volume>, <fpage>309</fpage>-<lpage>327</lpage>.</citation>
</ref>
<ref id="bibr18-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hart</surname><given-names>T. A.</given-names></name>
<name><surname>Chaparro</surname><given-names>B. S.</given-names></name>
<name><surname>Halcomb</surname><given-names>C. G.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Evaluating websites for older adults: Adherence to “senior-friendly” guidelines and end-user performance</article-title>. <source>Behaviour &amp; Information Technology</source>, <volume>27</volume>, <fpage>191</fpage>-<lpage>199</lpage>.</citation>
</ref>
<ref id="bibr19-0273475311420244">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Hertzum</surname><given-names>M.</given-names></name>
<name><surname>Jacobsen</surname><given-names>N.</given-names></name>
<name><surname>Molich</surname><given-names>R.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Usability inspections by groups of specialists: perceived agreement in spite of disparate observations</article-title>. In <conf-name>Proceedings from CHI’02: Conference on Human Factors in Computing Systems</conf-name>. <conf-loc>Seattle: ACM Press</conf-loc>.</citation>
</ref>
<ref id="bibr20-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hill</surname><given-names>A.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Top 5 reasons your customers abandon their shopping carts</article-title>. <source>Ziff Davis Smart Business for the New Economy</source>, <volume>14</volume>(<issue>3</issue>), <fpage>80</fpage>-<lpage>85</lpage>.</citation>
</ref>
<ref id="bibr21-0273475311420244">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Jeffries</surname><given-names>R.</given-names></name>
<name><surname>Miller</surname><given-names>J. R.</given-names></name>
<name><surname>Wharton</surname><given-names>C.</given-names></name>
<name><surname>Uyeda</surname><given-names>K. M.</given-names></name>
</person-group> (<year>1991</year>, <month>April-May</month>). <article-title>User interface evaluation in the real world: A comparison of four techniques</article-title>. In <conf-name>Proceedings ACM CHI’91 Conference</conf-name>, <conf-date>27April-2 May</conf-date>, <conf-loc>New Orleans, LA. New York, NY: Association for Computing Machinery</conf-loc>.</citation>
</ref>
<ref id="bibr22-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kalczynski</surname><given-names>P. J.</given-names></name>
<name><surname>Senecal</surname><given-names>S.</given-names></name>
<name><surname>Nantel</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Predicting on-line task completion with clickstream complexity measures: A graph-based approach</article-title>. <source>International Journal of Electronic Commerce</source>, <volume>10</volume>(<issue>3</issue>), <fpage>121</fpage>-<lpage>141</lpage>.</citation>
</ref>
<ref id="bibr23-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kim</surname><given-names>H.</given-names></name>
<name><surname>Niehm</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The impact of website quality on information quality, value, and loyalty intentions in apparel retailing</article-title>. <source>Journal of Interactive Marketing</source>, <volume>23</volume>, <fpage>221</fpage>-<lpage>233</lpage>.</citation>
</ref>
<ref id="bibr24-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Krug</surname><given-names>S.</given-names></name>
</person-group> (<year>2005</year>). <source>Don’t make me think! A common sense approach to web usability</source> (<edition>2nd ed.</edition>). <publisher-loc>Berkeley, CA</publisher-loc>: <publisher-name>New Riders</publisher-name>.</citation>
</ref>
<ref id="bibr25-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kuisma</surname><given-names>J.</given-names></name>
<name><surname>Simola</surname><given-names>J.</given-names></name>
<name><surname>Uusitalo</surname><given-names>L.</given-names></name>
<name><surname>Öörni</surname><given-names>A.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The effects of animation and format on the perception and memory of online advertising</article-title>. <source>Journal of Interactive Marketing</source>, <volume>24</volume>, <fpage>269</fpage>-<lpage>282</lpage>.</citation>
</ref>
<ref id="bibr26-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kushniruk</surname><given-names>A. W.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Analysis of complex decision-making processes in health care: Cognitive approaches to health informatics</article-title>. <source>Journal of Biomedical Informatics</source>, <volume>34</volume>, <fpage>365</fpage>-<lpage>376</lpage>.</citation>
</ref>
<ref id="bibr27-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kushniruk</surname><given-names>A. W.</given-names></name>
<name><surname>Patel</surname><given-names>V. L.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Cognitive and usability engineering methods for the evaluation of clinical information systems</article-title>. <source>Journal of Biomedical Informatics</source> <volume>37</volume>(<issue>1</issue>), <fpage>56</fpage>-<lpage>76</lpage>.</citation>
</ref>
<ref id="bibr28-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Cognitive task analysis: A cognitive approach to evaluate evidence-based nursing websites</article-title>. <source>OCLC Systems &amp; Services</source>, <volume>21</volume>, <fpage>252</fpage>-<lpage>256</lpage>.</citation>
</ref>
<ref id="bibr29-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Levi</surname><given-names>M.</given-names></name>
<name><surname>Conrad</surname><given-names>F.</given-names></name>
</person-group> (<year>1996</year>, <month>July/August</month>). <article-title>A heuristic evaluation of a world wide web prototype</article-title>. <source>Interactions</source>, <volume>3</volume>(<issue>4</issue>), <fpage>50</fpage>-<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr30-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Loiacono</surname><given-names>E. T.</given-names></name>
<name><surname>Watson</surname><given-names>R. T.</given-names></name>
<name><surname>Goodhue</surname><given-names>D. L.</given-names></name>
</person-group> (<year>2007</year>). <article-title>WebQual: An instrument for consumer evaluation of web sites</article-title>. <source>International Journal of Electronic Commerce</source>, <volume>11</volume>(<issue>3</issue>), <fpage>51</fpage>-<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr31-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Malthouse</surname><given-names>E.</given-names></name>
<name><surname>Shankar</surname><given-names>V.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Measuring and managing interactive environments</article-title>. <source>Journal of Interactive Marketing</source>, <volume>23</volume>, <fpage>207</fpage>-<lpage>208</lpage>.</citation>
</ref>
<ref id="bibr32-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Milliken</surname><given-names>J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Qualitative research and marketing management</article-title>. <source>Management Decision</source>, <volume>39</volume>(<issue>1</issue>), <fpage>71</fpage>-<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr33-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moe</surname><given-names>W.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Buying, searching, or browsing: Differentiating between online shoppers using in-store navigational clickstream</article-title>. <source>Journal of Consumer Psychology</source>, <volume>13</volume>(<issue>1/2</issue>), <fpage>29</fpage>-<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr34-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Molich</surname><given-names>R.</given-names></name>
<name><surname>Dumas</surname><given-names>J. S.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Comparative usability evaluation (CUE-4)</article-title>. <source>Behaviour &amp; Information Technology</source>, <volume>27</volume>, <fpage>263</fpage>-<lpage>281</lpage>.</citation>
</ref>
<ref id="bibr35-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Molich</surname><given-names>R.</given-names></name>
<name><surname>Ede</surname><given-names>M.</given-names></name>
<name><surname>Kaasgaard</surname><given-names>K.</given-names></name>
<name><surname>Karyukin</surname><given-names>B.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Comparative usability evaluation</article-title>. <source>Behaviour &amp; Information Technology</source>, <volume>23</volume>, <fpage>65</fpage>-<lpage>74</lpage>.</citation>
</ref>
<ref id="bibr36-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Morville</surname><given-names>P.</given-names></name>
<name><surname>Rosenfeld</surname><given-names>L.</given-names></name>
</person-group> (<year>2006</year>). <source>Information architecture for the world wide web</source> (<edition>3rd ed.</edition>). <publisher-loc>Sebastopol, CA</publisher-loc>: <publisher-name>O’Reilly Media</publisher-name>.</citation>
</ref>
<ref id="bibr37-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nielsen</surname><given-names>J.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Heuristic evaluation</article-title>. In <person-group person-group-type="editor">
<name><surname>Nielsen</surname><given-names>J.</given-names></name>
<name><surname>Mack</surname><given-names>R. L.</given-names></name>
</person-group> (Eds.), <source>Usability inspection methods</source> (pp. <fpage>25</fpage>-<lpage>35</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr38-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nielsen</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <source>Designing web usability</source>. <publisher-loc>Indianapolis, IN</publisher-loc>: <publisher-name>New Riders</publisher-name>.</citation>
</ref>
<ref id="bibr39-0273475311420244">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nielsen</surname><given-names>J.</given-names></name>
<name><surname>Loranger</surname><given-names>H.</given-names></name>
</person-group> (<year>2005</year>). <source>Prioritizing web usability</source>. <publisher-loc>Indianapolis, IN</publisher-loc>: <publisher-name>New Riders</publisher-name>.</citation>
</ref>
<ref id="bibr40-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Novak</surname><given-names>T. P.</given-names></name>
<name><surname>Hoffman</surname><given-names>D. L.</given-names></name>
<name><surname>Yung</surname><given-names>Y.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Measuring the customer experience in online environments: A structural modeling approach</article-title>. <source>Marketing Science</source>, <volume>19</volume>(<issue>1</issue>), <fpage>22</fpage>-<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr41-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nyman</surname><given-names>S.</given-names></name>
<name><surname>Yardley</surname><given-names>L.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Usability and acceptability of a website that provides tailored advice on falls prevention activities for older people</article-title>. <source>Health Informatics Journal</source>, <volume>15</volume>(<issue>1</issue>), <fpage>27</fpage>-<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr42-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Petre</surname><given-names>M.</given-names></name>
<name><surname>Minocha</surname><given-names>S.</given-names></name>
<name><surname>Roberts</surname><given-names>D.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Usability beyond the website: An empirically-grounded e-commerce evaluation instrument for the total customer experience</article-title>. <source>Behaviour &amp; Information Technology</source>, <volume>25</volume>(<issue>2</issue>), <fpage>189</fpage>-<lpage>203</lpage>.</citation>
</ref>
<ref id="bibr43-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Resnick</surname><given-names>M. L.</given-names></name>
<name><surname>Sanchez</surname><given-names>J.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Effects of organizational scheme and labeling on task performance in product-centered and user-centered retail web sites</article-title>. <source>Human Factors</source>, <volume>46</volume>(<issue>1</issue>), <fpage>104</fpage>-<lpage>118</lpage>.</citation>
</ref>
<ref id="bibr44-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roy</surname><given-names>A.</given-names></name>
<name><surname>Macchlette</surname><given-names>B.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Debating the issues: A tool for augmenting critical thinking skills of marketing students</article-title>. <source>Journal of Marketing Education</source>, <volume>76</volume>, <fpage>264</fpage>-<lpage>276</lpage>.</citation>
</ref>
<ref id="bibr45-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sismeiro</surname><given-names>C.</given-names></name>
<name><surname>Bucklin</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Modeling purchase behavior at an e-commerce web site: A task-completion approach</article-title>. <source>Journal of Marketing Research</source>, <volume>41</volume>, <fpage>306</fpage>-<lpage>323</lpage>.</citation>
</ref>
<ref id="bibr46-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Smith</surname><given-names>D.</given-names></name>
<name><surname>Sivakumar</surname><given-names>K.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Flow and internet shopping behavior: A conceptual model and research propositions</article-title>. <source>Journal of Business Research</source>, <volume>57</volume>, <fpage>1199</fpage>-<lpage>1208</lpage>.</citation>
</ref>
<ref id="bibr47-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Spiggle</surname><given-names>S.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Analysis and interpretation of qualitative data in consumer research</article-title>. <source>Journal of Consumer Research</source>, <volume>21</volume>, <fpage>491</fpage>-<lpage>503</lpage>.</citation>
</ref>
<ref id="bibr48-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stanton</surname><given-names>A. D.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Bridging the academic/practitioner divide in marketing: An undergraduate course in data mining</article-title>. <source>Marketing Intelligence &amp; Planning</source>, <volume>24</volume>, <fpage>233</fpage>-<lpage>244</lpage>.</citation>
</ref>
<ref id="bibr49-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tremayne</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Lessons learned from experiments with interactivity on the web</article-title>. <source>Journal of Interactive Advertising</source>, <volume>5</volume>(<issue>2</issue>), <fpage>40</fpage>-<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr50-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>VandeCreek</surname><given-names>L. M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Usability analysis of Northern Illinois university libraries’ website: A case study</article-title>. <source>OCLC Systems &amp; Services</source>, <volume>21</volume>, <fpage>181</fpage>-<lpage>192</lpage>.</citation>
</ref>
<ref id="bibr51-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van Rompay</surname><given-names>T.</given-names></name>
<name><surname>de Vries</surname><given-names>P.</given-names></name>
<name><surname>van Venrooij</surname><given-names>X. G.</given-names></name>
</person-group> (<year>2010</year>). <article-title>More than words: On the importance of picture-text congruence in the online environment</article-title>. <source>Journal of Interactive Marketing</source>, <volume>24</volume>(<issue>1</issue>), <fpage>22</fpage>-<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr52-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Venkatesh</surname><given-names>V.</given-names></name>
<name><surname>Agarwal</surname><given-names>R.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Turning visitors into customers: A usability-centric perspective on purchase behavior in electronic channels</article-title>. <source>Management Science</source>, <volume>52</volume>, <fpage>367</fpage>-<lpage>382</lpage>.</citation>
</ref>
<ref id="bibr53-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walker</surname><given-names>I.</given-names></name>
<name><surname>Tsarenko</surname><given-names>Y.</given-names></name>
<name><surname>Wagstaff</surname><given-names>P.</given-names></name>
<name><surname>Powell</surname><given-names>I.</given-names></name>
<name><surname>Steel</surname><given-names>M.</given-names></name>
<name><surname>Brace-Govan</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The development of competent marketing professionals</article-title>. <source>Journal of Marketing Education</source>, <volume>31</volume>, <fpage>253</fpage>-<lpage>263</lpage>.</citation>
</ref>
<ref id="bibr54-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Senecal</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Measuring perceived website usability</article-title>. <source>Journal of Internet Commerce</source>, <volume>6</volume>(<issue>4</issue>), <fpage>97</fpage>-<lpage>112</lpage>.</citation>
</ref>
<ref id="bibr55-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Young</surname><given-names>M. R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Transforming the initial education experience: An action learning approach</article-title>. <source>Journal of Marketing Education</source>, <volume>32</volume>, <fpage>13</fpage>-<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr56-0273475311420244">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Young</surname><given-names>M. R.</given-names></name>
<name><surname>Murphy</surname><given-names>W.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Integrating communications skills into the marketing curriculum: A case study</article-title>. <source>Journal of Marketing Education</source>, <volume>25</volume>, <fpage>57</fpage>-<lpage>70</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>