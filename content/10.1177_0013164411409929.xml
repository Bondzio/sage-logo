<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPM</journal-id>
<journal-id journal-id-type="hwp">spepm</journal-id>
<journal-title>Educational and Psychological Measurement</journal-title>
<issn pub-type="ppub">0013-1644</issn>
<issn pub-type="epub">1552-3888</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0013164411409929</article-id>
<article-id pub-id-type="publisher-id">10.1177_0013164411409929</article-id>
<title-group>
<article-title>Difference Scores From the Point of View of Reliability and Repeated-Measures ANOVA</article-title>
<subtitle>In Defense of Difference Scores for Data Analysis</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Thomas</surname><given-names>D. Roland</given-names></name>
<xref ref-type="aff" rid="aff1-0013164411409929">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Zumbo</surname><given-names>Bruno D.</given-names></name>
<xref ref-type="aff" rid="aff2-0013164411409929">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0013164411409929"><label>1</label>Carleton University, Ottawa, Ontario, Canada</aff>
<aff id="aff2-0013164411409929"><label>2</label>University of British Columbia, Vancouver, British Columbia, Canada</aff>
<author-notes>
<corresp id="corresp1-0013164411409929">Bruno D. Zumbo, The University of British Columbia, Scarfe Building, 2125 Main Mall, Department of ECPS, Vancouver, British Columbia, Canada V6T 1Z4. Email: <email>bruno.zumbo@ubc.ca</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2012</year>
</pub-date>
<volume>72</volume>
<issue>1</issue>
<fpage>37</fpage>
<lpage>43</lpage>
<permissions>
<copyright-statement>© 2012 SAGE Publications</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>There is such doubt in research practice about the reliability of difference scores that granting agencies, journal editors, reviewers, and committees of graduate students’ theses have been known to deplore their use. This most maligned index can be used in studies of change, growth, or perhaps discrepancy between two measures taken on the same sampling unit. The most commonly stated problem with difference scores is the supposed associated increase in unreliability of difference scores. In this article, the authors examine difference scores from the point of view of reliability and repeated-measures ANOVA. The authors demonstrate that when the focus of difference scores is data analysis of aggregate models, their use should not be assessed in terms of reliability, and that the complete abolition of difference scores in research practice is unwarranted.</p>
</abstract>
<kwd-group>
<kwd>change scores</kwd>
<kwd>difference scores</kwd>
<kwd>reliability</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Difference scores are commonly considered in educational and psychological measurement and social, behavioral, and life sciences research as an index of change over time or discrepancy between two different measures taken on the same sampling unit. However, there is a widespread belief among applied researchers that difference scores should not be used in data analysis. <xref ref-type="bibr" rid="bibr1-0013164411409929">Cattell (1982)</xref> made an observation nearly three decades ago that still applies today. He stated that the doubts about differences scores are so strong that granting agencies, journal editors, and the committees of graduate students’ theses have been known to deplore the use of difference scores. He goes on to state that the mere mention of difference scores may result in immediate rejection of the work regardless of the context in which computation is performed. Even today, students and researchers are often advised not to use difference scores irrespective of the data analytical approach that is proposed. In essence, this has translated into a ban on difference scores.</p>
<p>This attitude stems from the observation that the reliability of difference scores is less, often much less, than the reliability of the two base measures themselves, and low reliability is then assumed to invalidate any and all uses of difference scores. Unfortunately, it is difficult to document such pervasive but incorrect advice, since it does not result in published work that can be criticized. Yet the current authors continue to encounter these erroneous beliefs about difference scores, and the objective of this article is to convince applied researchers that while the warnings about difference scores are legitimate in specific circumstances, there also are situations where difference scores can be validly used. Our objective is oriented toward exposition rather than the presentation of new results, and it should be noted that some of the observations made below have been made somewhat differently by <xref ref-type="bibr" rid="bibr2-0013164411409929">Collins (1996)</xref>, <xref ref-type="bibr" rid="bibr4-0013164411409929">Kane (1996)</xref>, and <xref ref-type="bibr" rid="bibr5-0013164411409929">Mellenbergh (1996</xref>, <xref ref-type="bibr" rid="bibr6-0013164411409929">1999</xref>). It will be shown that to prohibit difference scores is to prohibit one of the most popular experimental designs in the social, behavioral, and life sciences, namely, the repeated-measures design. The relationship between reliability, difference scores, and repeated-measures ANOVA will be examined in detail. Situations where classical reliability is the appropriate guide to the usefulness or otherwise of difference scores will be noted. From the viewpoint of repeated-measures ANOVA, on the other hand, it will be shown that the classical definition of reliability leads to the paradoxical situation of zero reliability in combination with a powerful repeated-measures test, a finding first demonstrated by <xref ref-type="bibr" rid="bibr7-0013164411409929">Overall and Woodward (1975)</xref> for the paired-samples Student’s <italic>t</italic> test, and we will demonstrate that the paradox arises from an inappropriate application of the classical definition. For pedagogical purposes, we will introduce an alternative definition of reliability that provides a direct link to the power of the repeated-measures test, and so removes the paradox entirely. The conclusion of the analysis is that the “zero reliability” of difference scores does not necessarily rule out their use in data analysis and that in repeated-measures analysis in particular their use can result in powerful tests of hypothesis.</p>
<sec id="section1-0013164411409929">
<title>Reliability and Difference Scores</title>
<p>Consider a pair of random variables <italic>y</italic><sub>1</sub> and <italic>y</italic><sub>2</sub>, with joint distribution <italic>f</italic>(<italic>y</italic><sub>1</sub>, <italic>y</italic><sub>2</sub>). We will examine the reliability of one of these variables, and since it does not matter which, the subscript will be omitted for now. The reliability of <italic>y</italic> is usually defined in terms of its partition into a “true score” τ and an error, ε, that is,</p>
<p>
<disp-formula id="disp-formula1-0013164411409929">
<label>(1)</label>
<mml:math display="block" id="math1-0013164411409929">
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>τ</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>ε</mml:mi>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula1-0013164411409929" xlink:href="10.1177_0013164411409929-eq1.tif"/>
</disp-formula></p>
<p>and it is usually assumed that the component random variables τ and ε are independent, with zero means and variances <inline-formula id="inline-formula1-0013164411409929">
<mml:math display="inline" id="math2-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula2-0013164411409929">
<mml:math display="inline" id="math3-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula>, respectively. The reliability <italic>r</italic><sub><italic>y</italic></sub> of <italic>y</italic> is then defined as</p>
<p>
<disp-formula id="disp-formula2-0013164411409929">
<label>(2)</label>
<mml:math display="block" id="math4-0013164411409929">
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mi>y</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula2-0013164411409929" xlink:href="10.1177_0013164411409929-eq2.tif"/>
</disp-formula></p>
<p>where the denominator represents the “total” variance of <italic>y</italic>. Clearly, if <inline-formula id="inline-formula3-0013164411409929">
<mml:math display="inline" id="math5-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> is large relative to <inline-formula id="inline-formula4-0013164411409929">
<mml:math display="inline" id="math6-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula>, then the reliability <italic>r</italic><sub><italic>y</italic></sub> will be close to one.</p>
<p>To explore difference scores, we will restore the subscripts and consider separate measurement models for <italic>y</italic><sub>1</sub> and <italic>y</italic><sub>2</sub>. Let</p>
<p>
<disp-formula id="disp-formula3-0013164411409929">
<label>(3)</label>
<mml:math display="block" id="math7-0013164411409929">
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>τ</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mspace width="0.25em"/>
<mml:mtext>and</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-0013164411409929" xlink:href="10.1177_0013164411409929-eq3.tif"/>
</disp-formula></p>
<p>where ε<sub>1</sub> are independent and ε<sub>2</sub>, τ<sub><italic>j</italic></sub> are independent, for <italic>i</italic> = 1, 2, <italic>j</italic> = 1, 2. Also, τ<sub>1</sub> and τ<sub>2</sub> have correlation ρ<sub>τ</sub> and common variance <inline-formula id="inline-formula5-0013164411409929">
<mml:math display="inline" id="math8-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>, and ε<sub>1</sub> and ε<sub>2</sub> have common variance <inline-formula id="inline-formula6-0013164411409929">
<mml:math display="inline" id="math9-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula>. From <xref ref-type="disp-formula" rid="disp-formula1-0013164411409929">Equation (1)</xref>, it follows that</p>
<p>
<disp-formula id="disp-formula4-0013164411409929">
<label>(4)</label>
<mml:math display="block" id="math10-0013164411409929">
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>τ</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>τ</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>ε</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula4-0013164411409929" xlink:href="10.1177_0013164411409929-eq4.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula7-0013164411409929">
<mml:math display="inline" id="math11-0013164411409929">
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>τ</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ρ</mml:mi>
<mml:mi>τ</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula8-0013164411409929">
<mml:math display="inline" id="math12-0013164411409929">
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ε</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula>. Thus, the reliability of the difference score <italic>y</italic><sub>1</sub> − <italic>y</italic><sub>2</sub> becomes</p>
<p><disp-formula id="disp-formula5-0013164411409929">
<label>(5)</label>
<mml:math display="block" id="math13-0013164411409929">
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>τ</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>τ</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ε</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ρ</mml:mi>
<mml:mi>τ</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ρ</mml:mi>
<mml:mi>τ</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula5-0013164411409929" xlink:href="10.1177_0013164411409929-eq5.tif"/>
</disp-formula></p>
<p>For any fixed value of the error variance, <inline-formula id="inline-formula9-0013164411409929">
<mml:math display="inline" id="math14-0013164411409929">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula>, it then follows that</p>
<p>
<disp-formula id="disp-formula6-0013164411409929">
<label>(6)</label>
<mml:math display="block" id="math15-0013164411409929">
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
</mml:msub>
<mml:mo>⇒</mml:mo>
<mml:mn>0</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mtext>as</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mi>ρ</mml:mi>
<mml:mi>τ</mml:mi>
</mml:msub>
<mml:mo>⇒</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula6-0013164411409929" xlink:href="10.1177_0013164411409929-eq6.tif"/>
</disp-formula></p>
<p>In other words, as the correlation between the true scores approaches one, the reliability of the difference score <italic>y</italic><sub>1</sub> − <italic>y</italic><sub>2</sub> approaches zero.</p>
<p>It appears that this result has persuaded many researchers that difference scores should be avoided at all costs. It has been noted previously (e.g., <xref ref-type="bibr" rid="bibr8-0013164411409929">Zimmerman, 2009</xref>; <xref ref-type="bibr" rid="bibr9-0013164411409929">Zimmerman &amp; Williams, 1998</xref>; <xref ref-type="bibr" rid="bibr10-0013164411409929">Zimmerman, Williams, &amp; Zumbo, 1993a</xref>, <xref ref-type="bibr" rid="bibr11-0013164411409929">1993b</xref>; <xref ref-type="bibr" rid="bibr12-0013164411409929">Zumbo, 1999</xref>) that the result given in <xref ref-type="disp-formula" rid="disp-formula6-0013164411409929">Equation (6)</xref> is not inevitable and that under less restrictive assumptions on the variances of τ* and ε*, the limiting reliability of the difference score is not necessarily zero. However, the general case is not of interest in this article. It is the restrictive case displayed in <xref ref-type="disp-formula" rid="disp-formula5-0013164411409929">Equation (5)</xref> that has given difference scores a bad name, and it is the restricted result <xref ref-type="disp-formula" rid="disp-formula6-0013164411409929">(6)</xref> that will be shown to be not relevant to the issue of difference scores in data analysis.</p>
<p>It must be stressed that the focus on data analysis implies estimation and testing on the parameters of aggregate models; we are not concerned with difference scores constructed to provide a particular education measure on an individual. For example, as noted by a reviewer, if learning potential is measured as the difference between a pretest score and a posttest score following a short test, then the reliability of this difference score is relevant if the learning potential of one individual is to be compared with some standard or if two individuals are to be compared.</p>
</sec>
<sec id="section2-0013164411409929">
<title>Repeated-Measures ANOVA and Reliability</title>
<p>Consider a single-group repeated-measures ANOVA, that is, a “purely within-subjects” design, having one repeated-measures factor. For ease of exposition, the analysis will focus on the case of a two-level factor, though the argument can be extended to any number of levels. The classical model for this design is given by</p>
<p>
<disp-formula id="disp-formula7-0013164411409929">
<label>(7)</label>
<mml:math display="block" id="math16-0013164411409929">
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula7-0013164411409929" xlink:href="10.1177_0013164411409929-eq7.tif"/>
</disp-formula></p>
<p>where <italic>s</italic> denotes a random effect due to the individual subject (sample subscripts are suppressed for notational simplicity), <italic>T</italic><sub><italic>j</italic></sub> is a fixed repeated-measures effect <italic>j</italic> = 1, 2, and ε<italic>j</italic> is an error term independent of <italic>s</italic>. It can be seen that <xref ref-type="disp-formula" rid="disp-formula7-0013164411409929">Equation (7)</xref> corresponds to the measurement model <xref ref-type="disp-formula" rid="disp-formula3-0013164411409929">(3)</xref> with</p>
<p>
<disp-formula id="disp-formula8-0013164411409929">
<label>(8)</label>
<mml:math display="block" id="math17-0013164411409929">
<mml:msub>
<mml:mi>τ</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mi>τ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula8-0013164411409929" xlink:href="10.1177_0013164411409929-eq8.tif"/>
</disp-formula></p>
<p>that is, for the variables <italic>y</italic><sub>1</sub> and <italic>y</italic><sub>2</sub> in the repeated-measures setup, an individual subject’s random effect is part of the “true” score for that subject. Furthermore, it can be seen from <xref ref-type="disp-formula" rid="disp-formula8-0013164411409929">Equation (8)</xref> that τ<sub>1</sub> and τ<sub>2</sub> are perfectly correlated. Hence, the classical repeated-measures analysis corresponds to the case of zero reliability of <italic>y</italic><sub>1</sub> − <italic>y</italic><sub>2</sub>. But a repeated-measures analysis is based on contrasts among the <italic>y</italic><sub><italic>j</italic></sub> scores, and when there are only two repeated-measures levels, the only contrast available is the difference score <italic>y</italic><sub>1</sub> − <italic>y</italic><sub>2</sub>. But few researchers object to repeated-measures designs, hence the paradox. The paradox is not restricted to the two-level case. A similar analysis reveals that the reliability of all contrasts in a multilevel repeated-measures setup will be zero.</p>
<p>The source of the apparent paradox can be revealed by examining the difference score equation, obtained from <xref ref-type="disp-formula" rid="disp-formula7-0013164411409929">Equation (7)</xref>, namely,</p>
<p>
<disp-formula id="disp-formula9-0013164411409929">
<label>(9)</label>
<mml:math display="block" id="math18-0013164411409929">
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula9-0013164411409929" xlink:href="10.1177_0013164411409929-eq9.tif"/>
</disp-formula></p>
<p>From <xref ref-type="disp-formula" rid="disp-formula9-0013164411409929">Equation (9)</xref>, it can be seen that the subject random effect has canceled. This is the beauty of a repeated-measures design: Each subject acts as its own control. However, a corollary of this cancellation is that the “true score” in the measurement model <xref ref-type="disp-formula" rid="disp-formula9-0013164411409929">(9)</xref> is now the fixed effect <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> that is, a constant. But the variance of a constant is zero, so when the classical reliability formula represented by <xref ref-type="disp-formula" rid="disp-formula1-0013164411409929">Equations (1)</xref> and <xref ref-type="disp-formula" rid="disp-formula2-0013164411409929">(2)</xref> is applied to <xref ref-type="disp-formula" rid="disp-formula9-0013164411409929">Equation (9)</xref>, the result is zero “reliability.” But repeated-measures designs are not analyzed using considerations of reliability. The standard approach for model <xref ref-type="disp-formula" rid="disp-formula9-0013164411409929">(9)</xref> would be to estimate the fixed effect <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> (using the difference of the sample means of <italic>y</italic><sub>1</sub> and <italic>y</italic><sub>2</sub>) and to then test this effect using an estimate of the variance of ε<sub>1</sub> − ε<sub>2</sub> (namely, the sample variance of the difference scores, <italic>y</italic><sub>1</sub> − <italic>y</italic><sub>2</sub>).</p>
<p>This procedure for testing the null hypothesis <italic>H</italic><sub>0</sub>: <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> = 0 yields an <italic>F</italic>-statistic, which in this two-level case is identical to the square of the paired <italic>t</italic> statistic. When the alternative hypothesis holds, that is, when <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> ≠ 0, the test statistic will have a noncentral <italic>F</italic> distribution, with the noncentrality parameter given by</p>
<p>
<disp-formula id="disp-formula10-0013164411409929">
<label>(10)</label>
<mml:math display="block" id="math19-0013164411409929">
<mml:msup>
<mml:mi>δ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>N</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mi>var</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>N</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula10-0013164411409929" xlink:href="10.1177_0013164411409929-eq10.tif"/>
</disp-formula></p>
<p>where <italic>N</italic> is the sample size. The noncentrality parameter, δ<sup>2</sup>, determines the divergence between the sampling distribution of the test statistic under the null and its sampling distribution under the alternative and hence determines the power of the test (for given degrees of freedom). For the repeated-measures setup described above, δ<sup>2</sup> need not be small. On the contrary, δ<sup>2</sup> may be large, depending on the magnitude of the fixed effects <italic>T</italic><sub>1</sub> and <italic>T</italic><sub>2</sub> and the sample size, so that a repeated-measures design can be extremely powerful, as is well known. Thus, high test power can occur in a situation where classical reliability theory indicates zero “reliability.” Clearly, classical reliability is not relevant to the evaluation of the utility of a repeated-measures analysis.</p>
</sec>
<sec id="section3-0013164411409929">
<title>The Relationship Between Reliability and Noncentrality</title>
<p>The earlier example of learning potential measured by means of a difference score illustrates the fact that classical reliability is relevant whenever the focus of the measure is the individual. Low reliability implies that it will not be a precise measure; high reliability implies that it will. However, the measure given in <xref ref-type="disp-formula" rid="disp-formula9-0013164411409929">Equation (9)</xref> <italic>always</italic> has zero classical reliability because the variance associated with an individual has cancelled, and therefore (9) should not be used when the focus of the measure is the individual. However, when the measure (9) is used in a data analytic framework to assess the parameters of an aggregate model, classical reliability is not relevant. Instead, the relevant measure is the noncentrality given (for a simple repeated-measures ANOVA) in <xref ref-type="disp-formula" rid="disp-formula10-0013164411409929">Equation (10)</xref>. Thus, the reliability paradox that continues to confuse many researchers is seen to be a misunderstanding about the focus of the measurement, namely, the individual or the group.</p>
<p>This resolution of the reliability paradox can be formalized for pedagogical purposes by slightly modifying the definition of reliability given in <xref ref-type="disp-formula" rid="disp-formula2-0013164411409929">Equation (2)</xref>, that is, by replacing variance (var) by mean squared error (<italic>mse</italic>). The mean squared error of a random quantity is defined as the expected value of its squared deviation from its true or hypothesized value and can be shown to equal its variance plus the square of its bias. Under the null hypothesis <italic>H</italic><sub>0</sub>: <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> = 0 the mean squared error of the “total score” in repeated-measures model (9) is given by <inline-formula id="inline-formula10-0013164411409929">
<mml:math display="inline" id="math20-0013164411409929">
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula> which follows because its bias under <italic>H</italic><sub>0</sub> (when the alternative <italic>H</italic><sub>A</sub>: <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> ≠ 0 is true) is <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub>, and its variance, which is equal to the variance of ε<sub>1</sub> − ε<sub>2</sub> is <inline-formula id="inline-formula11-0013164411409929">
<mml:math display="inline" id="math21-0013164411409929">
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> The mean squared error of the “true score” in the repeated-measures model (9), namely, the constant term <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> in <xref ref-type="disp-formula" rid="disp-formula9-0013164411409929">Equation (9)</xref>, is then just (<italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub>)<sup>2</sup>. Given these mean squared errors, the modified version of the classical reliability given in <xref ref-type="disp-formula" rid="disp-formula2-0013164411409929">Equation (2)</xref> becomes</p>
<p>
<disp-formula id="disp-formula11-0013164411409929">
<label>(11)</label>
<mml:math display="block" id="math22-0013164411409929">
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mi>M</mml:mi>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>ε</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula11-0013164411409929" xlink:href="10.1177_0013164411409929-eq11.tif"/>
</disp-formula></p>
<p>from which it can be seen that for a repeated-measures ANOVA the modified reliability, unlike the classical reliability, is zero only if the fixed effect <italic>T</italic><sub>1</sub> − <italic>T</italic><sub>2</sub> is zero. It immediately follows from <xref ref-type="disp-formula" rid="disp-formula10-0013164411409929">Equations (10)</xref> and <xref ref-type="disp-formula" rid="disp-formula11-0013164411409929">(11)</xref> that the noncentrality parameter and the modified reliability, <inline-formula id="inline-formula12-0013164411409929">
<mml:math display="inline" id="math23-0013164411409929">
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mi>M</mml:mi>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:math>
</inline-formula> are related by the expression</p>
<p>
<disp-formula id="disp-formula12-0013164411409929">
<label>(12)</label>
<mml:math display="block" id="math24-0013164411409929">
<mml:msup>
<mml:mi>δ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mi>N</mml:mi>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mi>M</mml:mi>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
<mml:mi>M</mml:mi>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula12-0013164411409929" xlink:href="10.1177_0013164411409929-eq12.tif"/>
</disp-formula></p>
<p>In other words, this modified version of reliability is directly related to the noncentrality parameter of the repeated-measures test, an entirely logical and intuitively reasonable result.</p>
</sec>
<sec id="section4-0013164411409929">
<title>Summary and Conclusions</title>
<p>It has been shown that evaluating the utility of a repeated-measures ANOVA by applying the classical definition of reliability to difference scores leads to an apparent paradox. A repeated-measures ANOVA can have arbitrarily high power even though the “reliability” of its individual difference scores is zero. This well-known paradox can be resolved by noting that classical reliability is relevant when the focus of a measure based on a difference score is the individual, but when the focus of the measurement is the data analysis of parameters of an aggregate model, the appropriate indicator is not classical reliability but the noncentrality (or equivalently the power) of the test statistic. This resolution of the paradox can be illustrated mathematically by means of a minor modification to the definition of reliability, which leads to a direct relationship between the noncentrality parameter and modified reliability. However, the redefinition of reliability is a pedagogical tool only and not the real issue. The real issue is that difference scores should not be assessed solely in terms of classical reliability and that to ban the use of difference scores in data analysis as a result of such assessments is totally unwarranted. This theme can be further illustrated with reference to a recent article in this journal by <xref ref-type="bibr" rid="bibr3-0013164411409929">Feldt (2011)</xref>. He quantified the extent to which changes in the reliability of criterion scores result in changes in the power of an ANOVA test for a one-way layout. If his criterion scores were difference scores, his formula relating the change in reliability to a change in the test noncentrality would not apply, the classical reliability of difference scores (under the simple assumptions of this article) being zero. However, <xref ref-type="bibr" rid="bibr3-0013164411409929">Feldt’s (2011)</xref> formula for the noncentrality parameter would still be valid and would return a nonzero value when specialized to the case of difference scores. Further examples can be given in which difference scores might validly be used, for example, multiple linear regression, though details are omitted.</p>
<p>The conclusion in all cases remains the same: Classical reliability is an inappropriate way of assessing the utility of difference scores in data analysis. If difference scores make sense from a subject matter perspective, and if the corresponding analysis is likely to have appropriate power, there is no reason to avoid their use.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author(s) received financial support for the research, authorship, and/or publication of this article: Roland Thomas wishes to acknowledge support from MITACS and Bruno Zumbo support from the Social Sciences and Humanities Research Council of Canada (SSHRC) and the Canadian Institutes of Health Research (CIHR) during the preparation of this work.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cattell</surname><given-names>R. B.</given-names></name>
</person-group> (<year>1982</year>). <article-title>The clinical use of difference scores: Some psychometric problems</article-title>. <source>Multivariate Experimental Clinical Research</source>, <volume>6</volume>, <fpage>87</fpage>-<lpage>98</lpage>.</citation>
</ref>
<ref id="bibr2-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Collins</surname><given-names>L. M.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Is reliability obsolete? A commentary on “Are simple gain scores obsolete?”</article-title> <source>Applied Psychological Measurement</source>, <volume>20</volume>, <fpage>289</fpage>-<lpage>292</lpage>.</citation>
</ref>
<ref id="bibr3-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Feldt</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Estimating the effect of changes in criterion score reliability on the power of the F test of equality of means</article-title>. <source>Educational and Psychological Measurement</source>, <volume>71</volume>, <fpage>420</fpage>-<lpage>430</lpage>.</citation>
</ref>
<ref id="bibr4-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kane</surname><given-names>M.</given-names></name>
</person-group> (<year>1996</year>). <article-title>The precision of measurements</article-title>. <source>Applied Measurement in Education</source>, <volume>9</volume>, <fpage>355</fpage>-<lpage>379</lpage>.</citation>
</ref>
<ref id="bibr5-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mellenbergh</surname><given-names>G. J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Measurement precision in test score and item response models</article-title>. <source>Psychological Methods</source>, <volume>1</volume>, <fpage>293</fpage>-<lpage>299</lpage>.</citation>
</ref>
<ref id="bibr6-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mellenbergh</surname><given-names>G. J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>A note on simple gain score precision</article-title>. <source>Applied Psychological Measurement</source>, <volume>23</volume>, <fpage>87</fpage>-<lpage>89</lpage>.</citation>
</ref>
<ref id="bibr7-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Overall</surname><given-names>J. E.</given-names></name>
<name><surname>Woodward</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1975</year>). <article-title>Unreliability of difference scores: A paradox for the measurement of change</article-title>. <source>Psychological Bulletin</source>, <volume>82</volume>, <fpage>85</fpage>-<lpage>86</lpage>.</citation>
</ref>
<ref id="bibr8-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zimmerman</surname><given-names>D. W.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The reliability of difference scores in populations and samples</article-title>. <source>Journal of Educational Measurement</source>, <volume>46</volume>, <fpage>19</fpage>-<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr9-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zimmerman</surname><given-names>D. W.</given-names></name>
<name><surname>Williams</surname><given-names>R. H.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Reliability of gain scores under realistic assumptions about properties of pretest and posttest scores</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>51</volume>, <fpage>343</fpage>-<lpage>351</lpage>.</citation>
</ref>
<ref id="bibr10-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zimmerman</surname><given-names>D. W.</given-names></name>
<name><surname>Williams</surname><given-names>R. H.</given-names></name>
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
</person-group> (<year>1993a</year>). <article-title>Reliability of measurement and power of significance tests based on differences</article-title>. <source>Applied Psychological Measurement</source>, <volume>17</volume>, <fpage>1</fpage>-<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr11-0013164411409929">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zimmerman</surname><given-names>D. W.</given-names></name>
<name><surname>Williams</surname><given-names>R. H.</given-names></name>
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
</person-group> (<year>1993b</year>). <article-title>Reliability, power, functions, and relations: A reply to Humphreys</article-title>. <source>Applied Psychological Measurement</source>, <volume>17</volume>, <fpage>15</fpage>-<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr12-0013164411409929">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Zumbo</surname><given-names>B. D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>The simple difference score as an inherently poor measure of change: Some reality, much mythology</article-title>. In <person-group person-group-type="editor">
<name><surname>Thompson</surname><given-names>B.</given-names></name>
</person-group> (Ed.), <source>Advances in social science methodology</source> (<volume>Vol. 5</volume>, pp. <fpage>269</fpage>-<lpage>304</lpage>). <publisher-loc>Greenwich, CT</publisher-loc>: <publisher-name>JAI Press</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>