<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">RSW</journal-id>
<journal-id journal-id-type="hwp">sprsw</journal-id>
<journal-title>Research on Social Work Practice</journal-title>
<issn pub-type="ppub">1049-7315</issn>
<issn pub-type="epub">1552-7581</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1049731512451060</article-id>
<article-id pub-id-type="publisher-id">10.1177_1049731512451060</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Invited Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Teaching Research and Practice Evaluation Skills to Graduate Social Work Students</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wong</surname>
<given-names>Stephen E.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1049731512451060">1</xref>
<xref ref-type="corresp" rid="corresp1-1049731512451060"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Vakharia</surname>
<given-names>Sheila P.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1049731512451060">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1049731512451060">
<label>1</label>Florida International University, Miami, FL, USA</aff>
<author-notes>
<corresp id="corresp1-1049731512451060">Stephen E. Wong, Florida International University, 11200 S.W. 8th Street, Miami, FL 33199, USA Email: <email>wongse@fiu.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>11</month>
<year>2012</year>
</pub-date>
<volume>22</volume>
<issue>6</issue>
<fpage>714</fpage>
<lpage>718</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Objective: The authors examined outcomes of a graduate course on evaluating social work practice that required students to use published research, quantitative measures, and single-system designs in a simulated practice evaluation project. Method: Practice evaluation projects from a typical class were analyzed for the number of research references cited, type of client, goals or problems, measures, interventions, single-system designs, and outcomes. Results: More than half of the students conducted self-improvement projects monitored with self-report measures, and goals or problems selected and interventions applied varied widely. More than 80% of the projects were evaluated with simple AB designs, over 45% of which were associated with statistically significant improvements and an additional 43% showed gains that did not reach statistical significance. Conclusions: Results suggest that students can be taught techniques and skills needed to formulate interventions derived from published research and to evaluate effects of these interventions using single-system designs.</p>
</abstract>
<kwd-group>
<kwd>teaching practice evaluation</kwd>
<kwd>teaching program evaluation</kwd>
<kwd>practice evaluation exercise</kwd>
<kwd>graduate social work students</kwd>
<kwd>single-case designs</kwd>
<kwd>single-subject designs</kwd>
<kwd>single-system designs</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>The Council on Social Work Education’s (CSWE) <xref ref-type="bibr" rid="bibr6-1049731512451060">
<italic>Educational Policy and Accreditation Standards</italic> (2008b)</xref> enjoins schools of social work to teach students how to evaluate interventions and the outcomes of their practice. The importance of practice evaluation is also reflected in the knowledge and practice behaviors contained in the instructional curriculum of the CSWE’s <italic>Advanced Social Work Practice in Clinical Social Work</italic> [ca. 2008a]. A well-developed method of program evaluation applicable to clinical practice is single-case or single-system research designs (SSDs). Not requiring large samples of homogenous subjects or random assignment to treatment and control groups, this methodology gauges treatment efficacy with procedures such as introducing and withdrawing, or successively administering treatment across individual problems or clients. Social work textbooks on single-system evaluation first appeared in the 1970s and that content has since infused mainstream social work education (<xref ref-type="bibr" rid="bibr4-1049731512451060">Bloom, Fischer, &amp; Orme, 2009</xref>; <xref ref-type="bibr" rid="bibr9-1049731512451060">Grinnell &amp; Unrau, 2011</xref>; <xref ref-type="bibr" rid="bibr12-1049731512451060">Noia &amp; Tripodi, 2008</xref>; <xref ref-type="bibr" rid="bibr13-1049731512451060">Royse, Thyer, &amp; Padgett, 2010</xref>).</p>
<p>One educational exercise that can give students direct experience in applying SSDs is a personal self-change project. <xref ref-type="bibr" rid="bibr3-1049731512451060">Barth (1984)</xref> assigned social work students self-change projects aimed at improving their professional skills in the practicum setting. Student beliefs and behaviors affecting interactions with clients, agency staff, and persons in the community were monitored during baseline and subsequent intervention phases. Barth  reported substantial gains in varied outcomes for several sample self-change projects during the intervention phases suggesting that these projects were effective educational assignments. <xref ref-type="bibr" rid="bibr2-1049731512451060">Anderson (2000)</xref> used more conventional self-change projects focused on personal concerns or desired goals while teaching upper-level undergraduate psychology students. These students selected projects on topics such as improving time and money management, promoting healthy habits, increasing appropriate assertiveness, and decreasing negative self-statements, which they attempted to change with behavioral interventions and evaluated with AB (baseline, intervention) designs. Anderson  reported that slightly more than half of these self-change projects reached the student’s goal and one third showed significant progress toward the goal. Similar to the previous study, <xref ref-type="bibr" rid="bibr11-1049731512451060">Morgan (2009)</xref> had undergraduate psychology students implement behavior change projects aimed at personal habits such as exercise, caffeine consumption, or study time. Baseline and intervention data from these projects were later graphed and analyzed with statistical process control procedures. <xref ref-type="bibr" rid="bibr11-1049731512451060">Morgan (2009)</xref> only described one sample student self-change project that obtained statistically significant improvements, but he reported that its results were “fairly typical” for the class.</p>
<p>An alternative assignment to self-change projects is applying evaluative methods in supervised practice with actual clients. In a study involving graduate-level social work students, <xref ref-type="bibr" rid="bibr7-1049731512451060">Dillenburger, Godina, and Burton (1997)</xref> taught behavioral principles to students who then applied these techniques with a client in their field placement and evaluated their effects. These authors presented two sample client behavior change projects evaluated within SSDs that appeared to significantly increase clients’ desired behaviors. In an examination of process variables associated with group therapy, <xref ref-type="bibr" rid="bibr10-1049731512451060">Johnson, Beckerman, and Auerbach (2001)</xref> instructed students on how to apply AB designs to evaluate effects of encouraging the development of trusting relationships between members on group attendance, and various interventions aimed at increasing verbal participation in a veterans’ support group. Employing statistical tests and software for SSDs, <xref ref-type="bibr" rid="bibr10-1049731512451060">Johnson et al. (2001)</xref> found that changes in group processes associated with students’ interventions in these two examples reached statistical significance.</p>
<p>This article describes a graduate-level social work course using personal self-change and client behavior change projects to teach students techniques to evaluate their own practice. This class was not a clinical course in behavior therapy, behavior analysis, or any particular treatment approach, although it presented numerous illustrations involving behavioral interventions. In addition, this article reports on multiple measures of student performance for all evaluation projects from one semester, rather than reporting on selected and perhaps unrepresentative student projects.</p>
<sec id="section1-1049731512451060">
<title>Framework for the Course</title>
<sec id="section2-1049731512451060">
<title>Assigned Readings and Class Lectures</title>
<p>The text for this course was <italic>Evaluating Practice: Guidelines for the Accountable Professional</italic> (<xref ref-type="bibr" rid="bibr4-1049731512451060">Bloom et al., 2009</xref>). The course content and weekly schedule closely followed the organization of the book. The first several chapters of the book present principles and strategies of measurement, and specific assessment procedures and instruments. The next set of chapters discusses uncontrolled case study and controlled single-system designs, and their appropriate applications and limitations. The final chapters of the book cover principles and methods of visual and statistical analyses. Class lectures explained key concepts and procedures, illustrated them with published studies relevant to social work practice, and provided opportunities for questions and discussion.</p>
</sec>
<sec id="section3-1049731512451060">
<title>Practice Evaluation Projects (PEPs)</title>
<p>The main assignment for teaching students how to formulate and evaluate evidence-based interventions was the PEP. All students were required to conduct a PEP, which incorporated the following four tasks:</p>
<list list-type="alpha-lower">
<list-item>
<p>use the research literature to conceptualize a problem or a goal and to find evidence-supported interventions to improve the condition;</p>
</list-item>
<list-item>
<p>conduct an individualized assessment involving quantitative measurement of the above problem or goal;</p>
</list-item>
<list-item>
<p>design and apply one or more evidence-supported interventions; and,</p>
</list-item>
<list-item>
<p>evaluate effectiveness of the intervention/interventions using a single-system design.</p>
</list-item>
</list>
<p>PEPs could be based on interventions revolving around a client, a client system, or a self-management project. Client or client system projects aimed at assessing a concern or problem of a person or a social system (e.g., family, small group, and agency), designing and applying an intervention for the problem, and evaluating effects of the intervention. As an alternative to working with an actual client, students were allowed to recruit family members, friends, and acquaintances to participate as voluntary “clients” for these projects. Topics of client or system service plans were significant concerns or goals such as improving parenting skills or staff supervision practices; advancing social, self-care, academic, job-seeking, or recreational skills; or decreasing verbal aggression, marital conflict, child misconduct, or other interpersonal problems.</p>
<p>Another type of PEP was a self-management project that assessed a personal goal or problematic behavior, designed and applied an intervention to achieve the goal or to alleviate the problem, and evaluated effects of the intervention. Previous self-management projects were aimed at improving diet, exercise, sleep hygiene, study habits, and time management as well as reducing annoying habits, tics, compulsions, angry outbursts, negative and self-defeating thoughts, smoking, drinking, excessive spending, and other addictive behaviors.</p>
<p>Students were required to write a detailed description of their evaluation project using a format for research reports derived from the Journal Article Reporting Standards of the <italic>Publication Manual of the American Psychological Association</italic> (<xref ref-type="bibr" rid="bibr1-1049731512451060">APA, 2010</xref>). Midway through the semester, students submitted a draft of their report and received feedback from the instructor that allowed them to improve their project methodology and to prepare a more refined final project report. At the end of the semester, students submitted their final report and gave an 8-min oral presentation that allowed students to learn about the procedures and results of all other evaluation projects in the class.</p>
</sec>
<sec id="section4-1049731512451060">
<title>Evaluation of PEPs From One Sample Class</title>
<p>To evaluate outcomes of the previously described educational activities and assignments, all student PEPs from one semester were reviewed and analyzed. This course had been taught by the first author with the same basic format for the last 8 years. The course selected for evaluation represented an average or middle-of-the distribution class, containing neither an exceptionally strong nor exceptionally weak group of students (indicators of this will be discussed in the Discussion section).</p>
</sec>
</sec>
<sec id="section5-1049731512451060">
<title>Results</title>
<p>A total of 29 student PEPs were analyzed and the results are summarized in <xref ref-type="table" rid="table1-1049731512451060">Table 1</xref>. The table presents the type of client, goals or problems, number of published references cited, measures used, interventions applied, and single-system designs employed.</p>
<table-wrap id="table1-1049731512451060" position="float">
<label>Table 1.</label>
<caption>
<p>Summary of Evaluation Project Reports</p>
</caption>
<graphic alternate-form-of="table1-1049731512451060" xlink:href="10.1177_1049731512451060-table1.tif"/>
<table>
<tbody>
<tr>
<td>Client</td>
</tr>
<tr>
<td> Self (16)</td>
</tr>
<tr>
<td> Family member, friend, or acquaintance (8)</td>
</tr>
<tr>
<td> Clients (5)</td>
</tr>
<tr>
<td>Goal/Problem</td>
</tr>
<tr>
<td> Repetitive habit (e.g., nail biting, hair pulling, lock checking; 6)</td>
</tr>
<tr>
<td> Time management, money management, or personal organization (5)</td>
</tr>
<tr>
<td> Stress, anxiety, or panic (3)</td>
</tr>
<tr>
<td> Weight loss or high blood pressure (3)</td>
</tr>
<tr>
<td> Depression or negative thoughts (2)</td>
</tr>
<tr>
<td> Marital communication or conflict (2)</td>
</tr>
<tr>
<td> Aggressive behavior (1)</td>
</tr>
<tr>
<td> Bedwetting (1)</td>
</tr>
<tr>
<td> Fear of lizards (1)</td>
</tr>
<tr>
<td> Hyperactive behavior (1)</td>
</tr>
<tr>
<td> Recurring nightmares (1)</td>
</tr>
<tr>
<td> Sleep difficulties (1)</td>
</tr>
<tr>
<td> Social skills deficit (1)</td>
</tr>
<tr>
<td> Substance abuse (1)</td>
</tr>
<tr>
<td>Published references cited</td>
</tr>
<tr>
<td> Mean: 7.2</td>
</tr>
<tr>
<td> Range: 3–14</td>
</tr>
<tr>
<td>Measures</td>
</tr>
<tr>
<td> Self-report log (22)</td>
</tr>
<tr>
<td> Behavioral observation (2)</td>
</tr>
<tr>
<td> Marital interaction diary (2)</td>
</tr>
<tr>
<td> Parental or family log (2)</td>
</tr>
<tr>
<td> Weight scale, skinfold fat caliper (2)</td>
</tr>
<tr>
<td> Behavior problem checklist (1)</td>
</tr>
<tr>
<td> Diastolic and systolic blood pressure (1)</td>
</tr>
<tr>
<td> Random urine drug test (1)</td>
</tr>
<tr>
<td>Interventions</td>
</tr>
<tr>
<td> Engaging in an alternative response to replace the problem behavior (4)</td>
</tr>
<tr>
<td> Habit reversal (4)</td>
</tr>
<tr>
<td> Progressive muscle relaxation (4)</td>
</tr>
<tr>
<td> Graduated exposure (3)</td>
</tr>
<tr>
<td> Self-monitoring (3)</td>
</tr>
<tr>
<td> Social reinforcement (3)</td>
</tr>
<tr>
<td> Tangible reinforcement (3)</td>
</tr>
<tr>
<td> Cognitive behavior therapy (2)</td>
</tr>
<tr>
<td> Exercise (2)</td>
</tr>
<tr>
<td> Improved diet (2)</td>
</tr>
<tr>
<td> Meditation and controlled breathing (2)</td>
</tr>
<tr>
<td> Awareness training (1)</td>
</tr>
<tr>
<td> Brief solution focused therapy (1)</td>
</tr>
<tr>
<td> Brief timeout from reinforcement (1)</td>
</tr>
<tr>
<td> Cognitive restructuring (1)</td>
</tr>
<tr>
<td> Goal setting (1)</td>
</tr>
<tr>
<td> Guided self-dialogue (1)</td>
</tr>
<tr>
<td> Listening to classical music (1)</td>
</tr>
<tr>
<td> Personal budgeting (1)</td>
</tr>
<tr>
<td> Problem solving (1)</td>
</tr>
<tr>
<td> Response prevention (1)</td>
</tr>
<tr>
<td> Scheduling work on smaller tasks (1)</td>
</tr>
<tr>
<td> Sleep hygiene techniques (1)</td>
</tr>
<tr>
<td> Social skills training (1)</td>
</tr>
<tr>
<td>Evaluation designs</td>
</tr>
<tr>
<td> AB (27)</td>
</tr>
<tr>
<td> AB with reconstructed baseline (1)</td>
</tr>
<tr>
<td> ABB<sub>1</sub> (1)</td>
</tr>
<tr>
<td> ABAB (1)</td>
</tr>
<tr>
<td> ABCB (1)</td>
</tr>
<tr>
<td> A-B-BC-BD-BC-BD-BC (1)</td>
</tr>
<tr>
<td> B (1)</td>
</tr>
</tbody>
</table>
</table-wrap>
<sec id="section6-1049731512451060">
<title>Type of Client</title>
<p>Students utilized themselves as clients in a slight majority of the projects (<italic>n</italic> = 16) focusing either on self-improvement or alleviating a personal problem. The remaining projects were divided between assisting a family member, a friend, an acquaintance or assisting actual clients.</p>
</sec>
<sec id="section7-1049731512451060">
<title>Goal or Problem Selected</title>
<p>The most common concern selected for the project was a repetitive habit (e.g., nail biting, hair pulling; <italic>n</italic> = 6), closely followed by self-management concerns (e.g., time management, money management; <italic>n</italic> = 5). Stress or anxiety problems (<italic>n</italic> = 3) and weight loss and other health issues (<italic>n</italic> = 3) were additional recurring concerns. The remaining goals or problems were highly individualized and varied widely from unconstructive negative thoughts to a fear of lizards.</p>
</sec>
<sec id="section8-1049731512451060">
<title>Published References Cited</title>
<p>The average number of published references (i.e., printed or online articles, book chapters, and books) cited in the PEPs was 7.2 (range = 3–14; <italic>SD</italic> = 2.73).</p>
</sec>
<sec id="section9-1049731512451060">
<title>Measures Utilized</title>
<p>Over two thirds of the measures utilized in the projects were self-report logs or social interaction diaries (<italic>n</italic> = 22). Behavioral observation or family logs accounted for a much smaller portion of the measures (<italic>n</italic> = 6). The rest of the measures relied on mechanical devices (e.g., weight scale, blood pressure meter) or other physical tests (e.g., urine drug assay).</p>
</sec>
<sec id="section10-1049731512451060">
<title>Interventions Applied</title>
<p>Multiple interventions were sometimes applied with a single concern, so the number of interventions exceeded the number of clients. Performing an alternative response to replace a problem behavior, habit reversal, and progressive muscle relaxation were the interventions used at the highest frequency (<italic>n</italic> = 4 for each). Graduated exposure, self-monitoring, and social or tangible reinforcement were the next most frequency utilized procedures (<italic>n</italic> = 3 for each). Cognitive behavior therapy, exercise, improved diet, and meditation were each used in two projects. A wide variety of interventions ranging from Brief Solution Focused Therapy to listening to classical music were applied once in the remaining projects.</p>
</sec>
<sec id="section11-1049731512451060">
<title>Evaluation Designs Utilized</title>
<p>An overwhelming majority of the students utilized a simple AB design (A = baseline phase; B = treatment phase) to evaluate their interventions (<italic>n</italic> = 27). An AB design with a reconstructed baseline was used in one project and an AB<sub>1</sub>B<sub>2</sub> design (revised treatment procedure in the third phase) was utilized in the second. One student used an ABAB or reversal design, and another student used a variant of this design, an ABCB. Finally, one student utilized a sophisticated A-B-BC-BD-BC-BD-BC design to analyze the combined and additive effects of multiple treatment procedures.</p>
</sec>
<sec id="section12-1049731512451060">
<title>Outcomes of Student PEPs</title>
<p>At the beginning of this class, students were informed that their PEPs would be graded on their quality of planning and execution, not their outcomes. Nevertheless, data on PEP outcomes might give some indication as to the care and competence with which these assignments were carried out. What is an appropriate statistical test of single-system design data is a complex question without an answer supported by a broad consensus. In an effort to objectively quantify the outcomes of the present evaluation projects, we utilized the Conservative Dual-Criteria (CDC) method, a relatively straightforward statistical test developed by single-case design researchers and presented in the <xref ref-type="bibr" rid="bibr4-1049731512451060">Bloom, Fischer, and Orme (2009)</xref> text. The CDC (<xref ref-type="bibr" rid="bibr8-1049731512451060">Fisher, Kelley, &amp; Lomas, 2003</xref>) requires the calculation of an adjusted baseline mean line and an adjusted baseline regression line that are projected into the treatment phase. In PEPs where the desired outcome of the intervention was to increase behavior, both the baseline mean line and regression line were adjusted by adding .25 standard deviation of the baseline data to the lines. In PEPs where the desired outcome was to decrease behavior, both the lines were lowered by .25 standard deviation of the baseline data. After this step was completed, the number of data points in the treatment phase above both lines was counted in PEPs where intervention behaviors were expected to increase, or the number of data points below both lines was counted in PEPs where behaviors were expected to decrease. If the number of data points in the treatment phase falling above (or below) these two lines equaled or exceeded the criterion number of points for the chosen significance level (based on the binomial test), the null hypothesis was rejected. The CDC test was run on each of the students’ evaluation projects graphs. Thus, if the student had more than one independent variable, she or he would have results from multiple CDC tests.</p>
<p>Results of CDC tests of evaluation project data showed that 15 of the 32 graphs contained statistically significant improvements at the .05 level in the transition from baseline to treatment phase. An additional 13 graphs displayed gains ranging from 23% to 600% where differences did not reach statistical significance or the data did not conform with requirements for the CDC test. The remaining graphs revealed no appreciable improvement from baseline to treatment phase, but in no instance was data in the treatment phase worse than in baseline.</p>
</sec>
</sec>
<sec id="section13-1049731512451060">
<title>Discussion and Applications to Social Work Education</title>
<p>The data obtained from the PEPs showed that as required by the course assignment students read and reviewed multiple research articles while formulating their simulated client’s goals or concerns. Using this research, students found or designed measures of those goals or concerns, and subsequently selected, adapted, applied, and evaluated evidence-based interventions to address those goals or concerns. Although PEPs were not graded on the basis of outcome, a large proportion of student projects were associated with statistically significant improvements or positive changes that did not reach statistical significance. These improvements suggested that student PEPs were well constructed and often efficacious in alleviating the targeted concern. PEPs encompassed a wide range of goals and problems, objective measures, and interventions, demonstrating during class presentations that social work practice aimed at a broad spectrum of personal and social concerns could be evaluated on an individualized and ongoing basis. In sum, PEPs appear to be a valuable classroom exercise for teaching social work students to evaluate their practice, as mandated by several CSWE standards.</p>
<p>One question about this study is whether the class chosen for analysis was representative of other classes, given the same instruction and assignments. In other words, could this particular class be giving an overly favorable impression about student performance and outcomes? It should be mentioned here that a deliberate effort was made to choose an average and not a superior or outstanding class for examination. Final grades and the number of projects employing innovative research designs (e.g., <xref ref-type="bibr" rid="bibr14-1049731512451060">Wong, 2010</xref>) are a couple of indicators of class performance, and this class did not earn an especially large number of “As” or employ numerous sophisticated evaluation designs as compared to other classes of this type (the project incorporating an A-B-BC-BD-BC-BD-BC design being the one exception).</p>
<p>Another possible criticism of this study and the described course is that issues selected for assessment and intervention in the student PEPs did not represent the sorts of clinical problems encountered by social workers in the field. Indeed, serious problems such as domestic violence and child abuse were not subjects of the PEPs, and students were discouraged from selecting urgent or dangerous issues for this classroom exercise. Difficulties addressed by self-improvement projects, which constituted more than half of the PEPs, were unlikely to have been as severe as problems encountered on the job by professional social workers. However, instructional exercises and illustrations used for training are often less complex and demanding than actual problems dealt with by experienced professionals. Moreover, this course was not primarily clinical in nature and the main focus was teaching the application of assessment and program evaluation techniques.</p>
<p>Future work in teaching practice evaluation to social work students should strive to better integrate this instruction with students’ field placements and agency operation. Classroom-based courses separated from students’ field placements, such as the present one, do not prepare students for the difficulties and obstacles of practice evaluation in actual service agencies (e.g., short-term treatments, lack of baseline phases, limited access to standardized measures). In addition, the weak connections between classroom curriculum and field placement settings do not promote the adaption of academic evaluation techniques to the demands and constraints of service settings. Finally, separating instruction in evaluative methods from students’ placement settings gives up the opportunity to demonstrate to agency staff the value of these procedures for gauging treatment outcomes and developing more effective interventions. Although PEPs appear to be a useful exercise for blending instruction in research and practice, it is only a preliminary step in teaching social work students to use evidence-based research and research methodology to formulate and evaluate their practice.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other" id="fn1-1049731512451060">
<label>Author’s Note</label>
<p>This article was invited and accepted at the discretion of the editor.</p>
</fn>
<fn fn-type="conflict" id="fn2-1049731512451060">
<label>Declaration of Conflicting Interests</label>
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn3-1049731512451060">
<label>Funding</label>
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1049731512451060">
<citation citation-type="book">
<collab collab-type="author">American Psychological Association</collab>. (<year>2010</year>). <source>Publication manual of the American Psychological Association</source> (<edition>6th ed</edition>.). [<comment>Journal Article Reporting Standards (JARS)</comment>, p. <fpage>247</fpage>–<lpage>249</lpage>]. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr2-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Anderson</surname>
<given-names>D. A.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Exposing undergraduates to behavior therapy: Self-change projects</article-title>. <source>Behavior Therapist</source>, <volume>23</volume>, <fpage>122</fpage>–<lpage>128</lpage>.</citation>
</ref>
<ref id="bibr3-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Barth</surname>
<given-names>R. P.</given-names>
</name>
</person-group> (<year>1984</year>). <article-title>Professional self-change projects: Bridging the clinical-research and classroom-agency gaps</article-title>. <source>Journal of Education for Social Work</source>, <volume>20</volume>, <fpage>13</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr4-1049731512451060">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bloom</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Fischer</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Orme</surname>
<given-names>J. G.</given-names>
</name>
</person-group> (<year>2009</year>). <source>Evaluating practice: Guidelines for the accountable professional</source> (<edition>6th ed</edition>.). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Pearson/Allyn &amp; Bacon</publisher-name>.</citation>
</ref>
<ref id="bibr5-1049731512451060">
<citation citation-type="book">
<collab collab-type="author">Council on Social Work Education</collab>. [<year>ca. 2008a</year>]. <source>Advanced social work practice in clinical social work</source> (p. <fpage>5</fpage>). <comment>Retrieved February 18, 2012, from the Council on Social Work Education’s Website</comment>: <ext-link ext-link-type="uri" xlink:href="http://www.cswe.org/File.aspx?id=26685">http://www.cswe.org/File.aspx?id=26685</ext-link>
</citation>
</ref>
<ref id="bibr6-1049731512451060">
<citation citation-type="book">
<collab collab-type="author">Council on Social Work Education</collab>. (<year>2008b</year>). <source>Educational policy and accreditation standards</source> (pp. <fpage>5</fpage>, <comment>7</comment>). <comment>Retrieved February 18, 2012, from the Council on Social Work Education’s Website</comment>: <ext-link ext-link-type="uri" xlink:href="http://www.cswe.org/File.aspx?id=13780">http://www.cswe.org/File.aspx?id=13780</ext-link>
</citation>
</ref>
<ref id="bibr7-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dillenburger</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Godina</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Burton</surname>
<given-names>M.</given-names>
</name>
</person-group> (<year>1997</year>). <article-title>Training in behavioral social work: A pilot study</article-title>. <source>Research on Social Work Practice</source>, <volume>7</volume>, <fpage>70</fpage>–<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr8-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fisher</surname>
<given-names>W. W.</given-names>
</name>
<name>
<surname>Kelley</surname>
<given-names>M. E.</given-names>
</name>
<name>
<surname>Lomas</surname>
<given-names>J. E.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Visual aids and structured criteria for improving visual inspection and interpretation of single-case designs</article-title>. <source>Journal of Applied Behavior Analysis</source>, <volume>36</volume>, <fpage>387</fpage>–<lpage>406</lpage>.</citation>
</ref>
<ref id="bibr9-1049731512451060">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Grinnell</surname>
<given-names>R. M.</given-names>
</name>
<name>
<surname>Unrau</surname>
<given-names>Y. A.</given-names>
</name>
</person-group> (<year>2011</year>). <source>Social work research and evaluation: Foundations of evidence-based practice</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Johnson</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Beckerman</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Auerbach</surname>
<given-names>C.</given-names>
</name>
</person-group> (<year>2001</year>). <article-title>Researching our own practice: Single system design for groupwork</article-title>. <source>Groupwork</source>, <volume>13</volume>, <fpage>57</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr11-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Morgan</surname>
<given-names>D. L.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Using single-case design and personalized behavior change projects to teach research methods</article-title>. <source>Teaching of Psychology</source>, <volume>36</volume>, <fpage>267</fpage>–<lpage>269</lpage>.</citation>
</ref>
<ref id="bibr12-1049731512451060">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Noia</surname>
<given-names>J. D.</given-names>
</name>
<name>
<surname>Tripodi</surname>
<given-names>T.</given-names>
</name>
</person-group> (<year>2008</year>). <source>A primer on single-case design for clinical social workers</source> (<edition>2nd ed</edition>.). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>NASW Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-1049731512451060">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Royse</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Thyer</surname>
<given-names>B. A.</given-names>
</name>
<name>
<surname>Padgett</surname>
<given-names>D. K.</given-names>
</name>
</person-group> (<year>2010</year>). <source>Program evaluation: An introduction</source>. (<edition>5th ed</edition>.). <publisher-loc>Belmont, CA</publisher-loc>: <publisher-name>Wadsworth, Cengage Learning</publisher-name>.</citation>
</ref>
<ref id="bibr14-1049731512451060">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wong</surname>
<given-names>S. E.</given-names>
</name>
</person-group> (<year>2010</year>). <article-title>Single-case evaluation designs for practitioners</article-title>. <source>Journal of Social Service Research</source>, <volume>36</volume>, <fpage>248</fpage>–<lpage>259</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>