<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">HFS</journal-id>
<journal-id journal-id-type="hwp">sphfs</journal-id>
<journal-title>Human Factors: The Journal of Human Factors and Ergonomics Society</journal-title>
<issn pub-type="ppub">0018-7208</issn>
<issn pub-type="epub">1547-8181</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0018720812443983</article-id>
<article-id pub-id-type="publisher-id">10.1177_0018720812443983</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Automation, Expert Systems</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Toward a Characterization of Adaptive Systems</article-title>
<subtitle>A Framework for Researchers and System Designers</subtitle>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Jacobs</surname><given-names>Karen</given-names></name>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Soares</surname><given-names>Marcelo</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Feigh</surname><given-names>Karen M.</given-names></name>
<aff id="aff1-0018720812443983">Georgia Institute of Technology, Atlanta, Georgia</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Dorneich</surname><given-names>Michael C.</given-names></name>
<aff id="aff2-0018720812443983">Honeywell Laboratories, Golden Valley, Minnesota</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Hayes</surname><given-names>Caroline C.</given-names></name>
<aff id="aff3-0018720812443983">University of Minnesota, Minneapolis, Minnesota</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0018720812443983">Karen M. Feigh, Georgia Institute of Technology, 270 Ferst Dr., Atlanta, GA 30332-0150, USA; <email>karen.feigh@gatech.edu</email>.</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>12</month>
<year>2012</year>
</pub-date>
<volume>54</volume>
<issue>6</issue>
<issue-title>Special Section: Keynote Addresses From the 18th Triennial Congress of the International Ergonomics Association</issue-title>
<fpage>1008</fpage>
<lpage>1024</lpage>
<history>
<date date-type="received">
<day>8</day>
<month>11</month>
<year>2010</year>
</date>
<date date-type="accepted">
<day>4</day>
<month>3</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© 2012, Human Factors and Ergonomics Society</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Human Factors and Ergonomics Society</copyright-holder>
</permissions>
<abstract>
<sec id="section1-0018720812443983">
<title>Objective:</title>
<p>This article presents a systematic framework characterizing adaptive systems.</p>
</sec>
<sec id="section2-0018720812443983">
<title>Background:</title>
<p>Adaptive systems are those that can appropriately modify their behavior to fit the current context. This concept is appealing because it offers the possibility of creating computer assistants that behave like good human assistants who can provide what is needed without being asked. However, the majority of adaptive systems have been experimental rather than practical because of the technical challenges in accurately perceiving and interpreting users’ current cognitive state; integrating cognitive state, environment, and task information; and using it to predict users’ current needs. The authors anticipate that recent developments in neurological and physiological sensors to identify users’ cognitive state will increase interest in adaptive systems research and practice over the next few years.</p>
</sec>
<sec id="section3-0018720812443983">
<title>Method:</title>
<p>To inform future efforts in adaptive sys-tems, this work provides an organizing framework for characterizing adaptive systems, identifying consider-ations and implications, and suggesting future research issues.</p>
</sec>
<sec id="section4-0018720812443983">
<title>Results:</title>
<p>A two-part framework is presented that (a) categorizes ways in which adaptive systems can modify their behavior and (b) characterizes trigger mechanisms through which adaptive systems can sense the current situation and decide how to adapt.</p>
</sec>
<sec id="section5-0018720812443983">
<title>Conclusion:</title>
<p>The framework provided in this article provides a tool for organizing and informing past, present, and future research and development efforts in adaptive systems.</p>
</sec>
</abstract>
<kwd-group>
<kwd>adaptive systems</kwd>
<kwd>adaptive automation</kwd>
<kwd>adaptable automation</kwd>
<kwd>dynamic function allocation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section6-0018720812443983" sec-type="intro">
<title>Introduction</title>
<p><italic>Adaptive systems</italic> are the technological component of joint human–machine systems that can change their behavior to meet the changing needs of their users, often without explicit instructions from their users. Adaptive systems do so by tracking and sensing information about their users, their current tasks, and their environment. Our motivation for examining adaptive systems at this time is that recent advances in sensor technology have created a renewed focus on adaptive systems among both researchers and software developers. The goal of our work is to assist this new surge of adaptive system researchers and software developers by providing a high-level characterization of adaptive systems and adaptive systems research.</p>
<p>The contribution of our framework is that it expands existing perspectives on what adaptive systems are. Previous characterizations of adaptive systems tended to focus primarily on one type of adaptation: modifications of the allocation of functions performed by the user and the adaptive system. However, there are many other ways in which adaptive systems can adapt; for example, by changing the amount of detail presented to users (which can be important when they are very stressed) or by changing the sensory modality in which information is presented: visual versus auditory. Our framework not only captures many <italic>types of adaptations</italic> but also describes and categorizes a variety of the <italic>trigger mechanisms</italic> by which the adaptations are invoked or disengaged. For each category, we provide technical descriptions, review the implications and considerations, and provide concrete examples drawn from the literature. We also discuss past and current challenges in creating successful adaptive systems, recent work to overcome those challenges, and future research directions to make adaptive systems more practical, usable, and reliable.</p>
<p>We start by describing adaptive systems in more detail. Adaptive systems may be components of larger joint human–machine systems such as the autopilot, warning, or navigation systems that assist a pilot in flying an airplane, a tutoring system that trains students, or a help system on a mobile device. The potential advantage in making such systems adaptive is that users’ needs may change as their current task, environment, and cognitive state also change. <italic>Cognitive state</italic> refers to properties such as the user’s mental workload, fatigue, or stress. For example, if a user is driving slowly through an urban environment, an adaptive GPS system might automatically adjust the map to show more detail than when the user is driving at high speed on a relatively featureless desert highway. As a second example, if an adaptive system senses that a user is focused on managing a complex and dangerous emergency, such as landing an airplane after an engine catches fire, it may prevent all interruptions except for those related to the most essential and pertinent alerts (<xref ref-type="bibr" rid="bibr25-0018720812443983">Dorneich, Mathan, Whitlow, &amp; Ververs, 2010</xref>). When implemented appropriately, adaptive systems act as skilled human assistants that unobtrusively observe their supervisors’ actions and state of mind, comprehend the evolving situation, and provide appropriate assistance without being asked. Such systems have the potential to enhance joint human–machine system performance.</p>
<p>To illustrate the general structure of an adaptive system, <xref ref-type="fig" rid="fig1-0018720812443983">Figure 1</xref> depicts a generalized flow diagram, patterned after the “perceive, select, act” cycle through which intelligent agents process information, make decisions, and interact with the environment (<xref ref-type="bibr" rid="bibr97-0018720812443983">Wickens, 1992</xref>). Data collected via sensors or data feeds from various sources can be used to make assessments of the state of the system, the external environment, the task, and the user. The assessments can then be used, in isolation or combination, to trigger an adaptations manager’s decision of which adaptations to select. The adaptive changes are executed by the automation and the human–machine interface. For example, the context assessment module may collect physiological sensor information that is classified into levels of workload. In addition to a workload assessment, the user’s current tasks and the system’s current state are all used by the adaptations manager to decide that high workload might compromise the user’s performance on the highest priority task; it offloads lower-priority tasks to automation so the user can focus on only the most critical task. Once this task is finished, the adaptations manger then decides to return to regular operation and disengage the adaptation.</p>
<fig id="fig1-0018720812443983" position="float">
<label>Figure 1.</label>
<caption>
<p>Diagram for a generic adaptive joint human–machine system.</p>
</caption>
<graphic xlink:href="10.1177_0018720812443983-fig1.tif"/></fig>
<p>Adaptive systems have remained limited because of the difficulty in assessing context; for example, they have often relied on static task models and user performance to gauge user state indirectly. However, recent advances in real-time, noninvasive, user cognitive state assessment have opened up the possibilities for more sophisticated adaptive systems that can sense user state directly. Nonetheless, multiple technological challenges remain, including the need for (a) more robust, accurate, wearable, and unobtrusive neurological and physiological sensors capable of providing the real-time information needed to determine user’s cognitive state; and (b) a better understanding of how to translate information on the user’s cognitive state, task, and environment into meaningful guidance for an adaptive system. These and other challenges made it difficult for adaptive systems to correctly and accurately ascertain the current situation and needs (<xref ref-type="bibr" rid="bibr7-0018720812443983">Bainbridge, 1983</xref>). When an adaptive system fails to do so, it may provide wrong, inappropriate, or untimely support, which can reduce the user’s effectiveness, become an annoyance, and, in the worst case, compromise safety. For example, an adaptive system that provides nonessential weather updates instead of nearby emergency landing sites to a pilot during an engine failure is not only a distraction and an annoyance but also a safety concern. An adaptive system that is not sufficiently accurate at assessing current needs is like an unobservant or poorly trained assistant who provides more hindrances than help (<xref ref-type="bibr" rid="bibr57-0018720812443983">Miller &amp; Funk, 1997</xref>; <xref ref-type="bibr" rid="bibr58-0018720812443983">Miller &amp; Hannen, 1999</xref>).</p>
<p>Although there were successful adaptive systems 10 years ago, they did not often use information about the user’s cognitive state to accomplish their jobs. For example, computer tutors could adapt their teaching style as the knowledge of the student grew (<xref ref-type="bibr" rid="bibr23-0018720812443983">Dorneich &amp; Jones, 2001</xref>; <xref ref-type="bibr" rid="bibr44-0018720812443983">Johnson, Shaw, Marshall, &amp; LaBore, 2003</xref>). However, such systems were limited in their ability to determine the user’s state of frustration or satisfaction and thus often added to their frustration. At that time, it was very difficult to use brain and physiological sensors to provide an adaptive system with real-time feedback on the user’s cognitive state because the sensors were so cumbersome to wear (e.g., many sensors, glued to the head, wired to computers), rendering them completely impractical for field and mobile applications. Signals from an electroencephalogram (EEG) were hard to read accurately, particularly in noisy environments. Methods for translating signals into cognitive state information must constantly be tuned and retuned for each individual. These are only a few of the many challenges.</p>
<p>Recent advances in multiple disciplines have brought adaptive systems that use cognitive state information closer to the practical realm. Examples of sensor advances include greater sensitivity, enabling them to more accurately detect very weak signals from the brain, even in noisy environments (<xref ref-type="bibr" rid="bibr53-0018720812443983">Mazaeva, Dorneich, Mathan, &amp; Ververs, 2005</xref>); and reductions in size, weight, and power requirements, rendering them easier and more practical to wear. These advances have enabled a new generation of “user sensitive” adaptive systems to be successfully built, fielded, and tested (<xref ref-type="bibr" rid="bibr26-0018720812443983">Dorneich, Ververs, Mathan, Whitlow, &amp; Reusser, 2006</xref>; <xref ref-type="bibr" rid="bibr75-0018720812443983">Prinzel, Freeman, Scerbo, Mikulka, &amp; Pope, 2000</xref>; <xref ref-type="bibr" rid="bibr84-0018720812443983">Scerbo et al., 2001</xref>). This has enabled the research community to experimentally measure some of the benefits that can be gained from adaptive systems and to identify some of the costs and practical complexities of using them. What has emerged is a richer understanding of the practical implications of using adaptive systems as intelligent assistants.</p>
<p>In this work, we aim to convey this emerging picture by first presenting a two-part framework characterizing the following:</p>
<list id="list1-0018720812443983" list-type="bullet">
<list-item><p><italic>Adaptation types</italic> describe ways in which a system’s behavior or interface can be adapted; for example, temporarily take over tasks for users to ease their burden during busy or stressful times, change the type and detail of information presented, or change the sensory mode (e.g., system, visual, auditory, haptic) in which users exchange information with the system.</p></list-item>
<list-item><p><italic>Adaptation triggers and methods</italic> are used to decide when and how to change the system’s behaviors or properties.</p></list-item></list>
<p>In addition, we discuss areas of future research needed to make adaptive systems more practical, usable, and beneficial, particularly those that use sensor input from users.</p>
<p>The framework extends existing integrative work characterizing adaptive systems, which has primarily focused on adaptations of function allocation, in which the system takes over one or more of the tasks performed by the human to lighten the user’s workload (<xref ref-type="bibr" rid="bibr28-0018720812443983">Endsley, 1987</xref>; <xref ref-type="bibr" rid="bibr29-0018720812443983">Endsley &amp; Kaber, 1999</xref>; <xref ref-type="bibr" rid="bibr73-0018720812443983">Parasuraman, Sheridan, &amp; Wickens, 2000</xref>; <xref ref-type="bibr" rid="bibr89-0018720812443983">Sheridan &amp; Verplank, 1978</xref>). Our framework goes beyond this to also describe other types of adaptations, including changes to the interface content, interaction, or task management. In addition, we characterize the triggering methods that include additional structure and effort necessary to manage a dynamically adaptive system on the part of both the system developer and the user. Our framework follows in the tradition of <xref ref-type="bibr" rid="bibr81-0018720812443983">Rouse (1988)</xref>, who postulated early on a broad framework for use in the conceptual design of what was then called adaptive aiding, and <xref ref-type="bibr" rid="bibr80-0018720812443983">Rothrock, Koubek, Fuchs, Haas, and Salvendy (2002)</xref>, who created a three-dimensional taxonomy to describe the effectiveness of an interface for task execution. The framework takes a broader view than Rothrock et al. and provides more detail than Rouse.</p>
<p>The intended audience includes designers, evaluators, and researchers of adaptive systems. The goals behind the framework are to (a) assist designers and evaluators of adaptive systems to systematically consider a broader range of system adaptations, methods for triggering such adaptations, and the trade-offs that may result from specific design choices, (b) tie together a diverse body of literature on adaptive systems, and (c) provide a context in which future research can be situated. The framework description is not exhaustive, nor is that the goal. Instead, the article aims to provide a useful guide for system designers, evaluators, and researchers.</p>
<p>The following sections describe the Taxonomy of Adaptations and the Taxonomy of Triggers and discuss their design considerations, implications, common benefits, and caveats. Where applicable, the literature is used to provide examples of the concepts presented. Supported by the framework, the article concludes by outlining areas where future research is needed.</p>
</sec>
<sec id="section7-0018720812443983">
<title>Taxonomy of Adaptations</title>
<p><xref ref-type="fig" rid="fig2-0018720812443983">Figure 2</xref> illustrates the Taxonomy of Adaptations for human–machine systems. The top-level categories capture the gamut of possible adaptations and show the four primary ways in which a system developer might make the automated portion of a human–machine system adaptive so that it may better meet the needs of the current situation:</p>
<list id="list2-0018720812443983" list-type="bullet">
<list-item><p><italic>Modification of function allocation</italic>. One can dynamically change <italic>who</italic> (human or machine) performs each function, task, or subtask. For example, the third generation of the Traffic Collision Avoidance System (TCAS III) will take over the function of flying an airplane when a collision with another aircraft is imminent; human reflexes are sometimes too slow to avoid the crash if the other plane is very close when it is first detected (<xref ref-type="bibr" rid="bibr15-0018720812443983">Botargues, 2008</xref>).</p></list-item>
<list-item><p><italic>Modification of task scheduling</italic>. A system may be designed to dynamically change when tasks are performed, including their duration and priority. For example, some smart phones change the ring tone to silent or vibrate when the calendar on the phone indicates that the operator has a scheduled activity.</p></list-item>
<list-item><p><italic>Modification of interaction</italic>. A system may be designed to dynamically change how it interacts with the users. Examples include changing the layout of a visual interface, the mode in which information is presented and received (e.g., visual, auditory, haptic), whether information is exchanged synchronously or asynchronously, and whether information is pushed or pulled. For example, the Communications Scheduler (<xref ref-type="bibr" rid="bibr25-0018720812443983">Dorneich et al., 2010</xref>) adapts soldiers’ communications during high workload times and changes the interaction so that instead of pushing information to soldiers as it comes in, the soldier must pull information from the system when workload allows.</p></list-item>
<list-item><p><italic>Modification of content</italic>. A system may be designed to dynamically change what information it presents to the user, including what categories of information are presented and at what level of detail or abstraction. For example, a map display for a car may sense its GPS position and speed, and can automatically adjust the scale of the map accordingly, changing the information content by providing detailed information when traveling slowly though an urban area and a larger view when traveling at highway speeds through a rural area.</p></list-item></list>
<fig id="fig2-0018720812443983" position="float">
<label>Figure 2.</label>
<caption>
<p>Taxonomy of Adaptations for adaptive systems.</p>
</caption>
<graphic xlink:href="10.1177_0018720812443983-fig2.tif"/></fig>
<p>Although the top-level categories are mutually exclusive, adaptations in one category may often be accompanied by adaptations in another. It is likely that a particular adaptive system will include adaptations in more than one of the four primary categories. For example, the Communications Scheduler (CoS) described above contains adaptations in three categories: function allocation, task scheduling, and interaction. By sensing when the user is experiencing high workload, it invokes a change in function allocation to take over the function of message triage. The CoS further changes the interaction from pushing data to requiring the user to pull data and influences task scheduling by modifying the order in which messages are displayed. The following sections discuss each type of modification in detail, including their implications and considerations, and provide examples.</p>
<sec id="section8-0018720812443983">
<title>Who: Modification of Function Allocation</title>
<p>Modification of function allocation is the process of dividing functions (or tasks) between people and machines and deciding who (or what) should perform each task. Function allocation is often considered the same concept as adaptive automation. This article uses adaptive automation as a broader descriptor that includes function allocation as well as the other three categories in the Taxonomy of Adaptations. If system designers allocate functions between humans and machines when they design the system, it is referred to as <italic>static function allocation</italic>. If they design the system so that tasks can be reassigned while the system is in use, it is referred to as <italic>dynamic function allocation</italic> (DFA; or adaptive function allocation). The latter is the primary concern in this work. A number of articles provide comprehensive reviews of systems that adapt themselves through DFA (<xref ref-type="bibr" rid="bibr46-0018720812443983">Kaber &amp; Endsley, 2004</xref>; <xref ref-type="bibr" rid="bibr82-0018720812443983">Scerbo, 1996</xref>). Changes in function allocation consist of changes to the <italic>assignment</italic> of functions to each agent and have significant implications for the distribution of <italic>responsibility</italic> and <italic>authority</italic> among agents. Taking an operator-centric view, function allocation manifests itself in a combination of <italic>task sharing</italic> (between the operator and automation) and <italic>task offloading</italic> (from the operator to the automation).</p>
<p>Assignment indicates which agent has been assigned to perform a specific function or task. The choice of task assignment is not simple, and many function allocation guidelines and corresponding critiques have surfaced over the years (<xref ref-type="bibr" rid="bibr1-0018720812443983">Abbott &amp; Rogers, 1993</xref>; <xref ref-type="bibr" rid="bibr4-0018720812443983">Alter et al., 1995</xref>; <xref ref-type="bibr" rid="bibr22-0018720812443983">Dekker &amp; Woods, 2002</xref>; <xref ref-type="bibr" rid="bibr27-0018720812443983">Duncan, 1986</xref>; <xref ref-type="bibr" rid="bibr31-0018720812443983">Fitts, 1951</xref>; <xref ref-type="bibr" rid="bibr45-0018720812443983">Jordan, 1963</xref>; <xref ref-type="bibr" rid="bibr51-0018720812443983">Lintern, 2012</xref>; <xref ref-type="bibr" rid="bibr74-0018720812443983">Price, 1985</xref>). Out of this literature, several function allocation categorizations have been developed to describe varying degrees of automation called levels of automation (LOAs). Initial LOAs assumed that the degree of automation varied along a unidimensional continuum; at the lower end the human performs all tasks, at the upper end the machine performs all tasks (<xref ref-type="bibr" rid="bibr28-0018720812443983">Endsley, 1987</xref>; <xref ref-type="bibr" rid="bibr29-0018720812443983">Endsley &amp; Kaber, 1999</xref>; <xref ref-type="bibr" rid="bibr89-0018720812443983">Sheridan &amp; Verplank, 1978</xref>). In the middle, only portions of a task are automated, creating a third category of “shared performance” (<xref ref-type="bibr" rid="bibr55-0018720812443983">McGuire et al., 1991</xref>; <xref ref-type="bibr" rid="bibr56-0018720812443983">Meister, 1985</xref>; <xref ref-type="bibr" rid="bibr87-0018720812443983">Sheridan, 2000</xref>; <xref ref-type="bibr" rid="bibr93-0018720812443983">Tenney, Rogers, &amp; Pew, 1995</xref>).</p>
<p>LOAs have been refined through the addition of a second dimension corresponding to specific information processing stages (<xref ref-type="bibr" rid="bibr73-0018720812443983">Parasuraman et al., 2000</xref>). This decomposition has been extensively used in the adaptive automation domain, by varying the LOA to improve performance (<xref ref-type="bibr" rid="bibr46-0018720812443983">Kaber &amp; Endsley, 2004</xref>; <xref ref-type="bibr" rid="bibr48-0018720812443983">Kaber, Wright, Prinzel, &amp; Clamann, 2005</xref>; <xref ref-type="bibr" rid="bibr49-0018720812443983">Kaber, Wright, &amp; Sheik-Nainar, 2006</xref>).</p>
<sec id="section9-0018720812443983">
<title>Implications and considerations</title>
<p>Changes to function assignment have significant implications for the distribution of responsibility and authority between agents.</p>
</sec>
<sec id="section10-0018720812443983">
<title>Responsibility</title>
<p>Responsibility indicates which agent is responsible for the outcome of a specific function or task. The responsible agent is not always the same as the assigned agent, especially in the case of joint human–machine systems, which include both human and automated agents. Historically, automated agents have been immune from responsibility, but the drive to minimize human error is changing this as automation is given more responsibility. Dividing the functionality between two (or more) agents requires particular care because dividing the work has an effect beyond just shifting task assignment between agents. Research has shown that the allocation of partial functionality to automation actually changes the nature of the work for the operator because the assignment and responsibility have been split (<xref ref-type="bibr" rid="bibr13-0018720812443983">Billings, 1997</xref>; <xref ref-type="bibr" rid="bibr59-0018720812443983">Miller &amp; Parasuraman, 2007</xref>; <xref ref-type="bibr" rid="bibr73-0018720812443983">Parasuraman et al., 2000</xref>; <xref ref-type="bibr" rid="bibr72-0018720812443983">Parasuraman &amp; Riley, 1997</xref>; <xref ref-type="bibr" rid="bibr101-0018720812443983">Woods, 1996</xref>). The split between assignment and responsibility adds additional “induced” functions such as monitoring, communicating, and coordinating (<xref ref-type="bibr" rid="bibr50-0018720812443983">Lee, Kim, &amp; Feigh, 2009</xref>).</p>
</sec>
<sec id="section11-0018720812443983">
<title>Authority</title>
<p>Authority indicates the level of control an agent has to modify the execution of the tasks and functions to achieve a goal, including changes to assignment. Authority is especially critical in off-nominal situations. Authority differs from responsibility in that authority affects the manner in which a goal or outcome is achieved, whereas responsibility affects the actual performance of the system toward that goal. Because the authorizing agent may mandate the way in which the responsible agents may act, it is possible to limit the ability of the responsible agent to meet its obligations, resulting in an authority–responsibility double bind (<xref ref-type="bibr" rid="bibr101-0018720812443983">Woods, 1996</xref>).</p>
<p>As changes to function allocation are made to task assignment, the use of LOAs to describe these changes has proven very beneficial to system designers to easily communicate concepts of operation for new automated systems. However, the reliance on LOAs to describe function allocation has significant implications because LOAs do not capture differences imposed on responsibility and authority. <xref ref-type="bibr" rid="bibr59-0018720812443983">Miller and Parasuraman (2007)</xref> argue that, for use with DFA, LOA decomposition needs to be extended beyond the four information processing stages and suggest a delegation method. They assert that tasks are routinely accomplished by hierarchical, decomposable sequences of activities, and it is necessary to differentially apply automation to every subtask. Over time, they believe that multiple, alternate decompositions will be needed depending on the context, where each alternative has a different combination of human and automation subtasks and consequently uses different methods to accomplish the parent task. Accordingly, a single adaptive system may occupy <italic>multiple</italic> points on the LOA continuum, and some systems may be impossible to classify using an LOA.</p>
<p>DFA imposes additional requirements for verification and validation of automated systems because consideration of overall human–computer performance in an adaptive system may come at the expense of suboptimization of local and specific task performance. In fact, this is a primary tenet of a human-centered design philosophy (<xref ref-type="bibr" rid="bibr63-0018720812443983">Norman, 1986</xref>; <xref ref-type="bibr" rid="bibr65-0018720812443983">Palmer, 1995</xref>). Accordingly, although changes to function allocation may enhance, preserve, or degrade capabilities at the task level, the joint human–machine system should be improved in some way. Usually this improvement comes through the reduction or leveling of workload, increase of situation awareness, and improved robustness to unforeseen and nonnominal circumstances. <xref ref-type="bibr" rid="bibr99-0018720812443983">Wickens, Li, Santamaria, Sebok, and Sarter (2010)</xref> used a meta-analysis to examine the degree of automation in both nominal and off-nominal conditions and found that the increase in performance with higher automation is accompanied by an increase in costs for fallible automation but that these results are mediated by situation awareness.</p>
<p>Other considerations surround the task transition between humans and automation; the transition requires explicit coordination and will create additional management and communication work for both agents. Finally, loss of skill, knowledge, and situation awareness may result from too frequent use of automation. It is well documented that use of automation can result in decay of skill or knowledge (<xref ref-type="bibr" rid="bibr18-0018720812443983">Byrne &amp; Parasuraman, 1996</xref>; <xref ref-type="bibr" rid="bibr37-0018720812443983">Hancock, Chignell, &amp; Loewenthal, 1985</xref>; <xref ref-type="bibr" rid="bibr67-0018720812443983">Parasuraman &amp; Bowers, 1987</xref>). Thus, adaptive systems, which automate some tasks only when needed, may help to mitigate these concerns as they provide opportunities for the human to conduct the task whenever possible.</p>
</sec>
<sec id="section12-0018720812443983">
<title>Examples</title>
<p>Kaber and colleagues (<xref ref-type="bibr" rid="bibr46-0018720812443983">Kaber &amp; Endsley, 2004</xref>; <xref ref-type="bibr" rid="bibr48-0018720812443983">Kaber et al., 2005</xref>; <xref ref-type="bibr" rid="bibr49-0018720812443983">Kaber et al., 2006</xref>) describe a series of investigations into adaptive systems that change the function allocation dynamically using an LOA to define the function allocations. According to <xref ref-type="bibr" rid="bibr46-0018720812443983">Kaber and Endsley (2004)</xref>, LOA was the dominant factor affecting performance. Unfortunately, the “best” LOA combination depended on the role and metric assessed. In addition, <xref ref-type="bibr" rid="bibr5-0018720812443983">Arciszewski, de Greef, and van Delft (2009)</xref> outlined an adaptive system that transitions between an automated and manual mode for target classification. The system adaptively changes modes when it has difficulty identifying the target. The use of the automated mode offloads routine target classification tasks and allows the operator to focus on more difficult cases.</p>
</sec>
</sec>
<sec id="section13-0018720812443983">
<title>When: Modification of Task Scheduling</title>
<p>The modification of the task scheduling category of the taxonomy describes automation adaptations to support individuals in multitasking, interruption-laden environments. Task scheduling modifications regulate the <italic>timing, duration</italic>, and <italic>prioritization</italic> of task execution.</p>
<sec id="section14-0018720812443983">
<title>Task timing</title>
<p>Task timing describes the time at which a task is initiated. Task timing does not always follow monotonically from task priority (<xref ref-type="bibr" rid="bibr94-0018720812443983">Tulga &amp; Sheridan, 1980</xref>). This is especially true if no tasks are considered truly urgent. Tasks usually occur in a sequence where certain preconditions (including the availability of information or resources or the completion of other tasks) must be satisfied before the task may commence and must be accomplished by some point in time, often dictated by the requirements of subsequent tasks. Task timing is a key challenge for humans working in complex, event-driven domains (<xref ref-type="bibr" rid="bibr40-0018720812443983">Ho, Nikolic, Waters, &amp; Sarter, 2004</xref>). <xref ref-type="bibr" rid="bibr3-0018720812443983">Adams, Tenney, and Pew’s (1994)</xref> review of the literature concludes that the cognitive management of multiple tasks requires the sequential scheduling of tasks because humans can truly work on only one task at a time; other tasks consequently must be queued. Task spin-up and spin-down place additional burdens on individuals in multitask environments (<xref ref-type="bibr" rid="bibr52-0018720812443983">MacMillan, Deutsch, &amp; Young, 1997</xref>). <xref ref-type="bibr" rid="bibr61-0018720812443983">Moray, Dessouky, Kijowski, and Adapathya (1991)</xref> studied the effects of time constraints on timing tasks and found that humans do not time tasks optimally in the presence of time constraints because the time taken to determine optimal timing erodes the gains from adopting an optimal timing. This echoes the findings of <xref ref-type="bibr" rid="bibr94-0018720812443983">Tulga and Sheridan (1980)</xref>, who found that people do not plan ahead when very busy. Adaptations in task timing may schedule tasks with the goal of short-term optimization of resources to minimize slack time.</p>
</sec>
<sec id="section15-0018720812443983">
<title>Task prioritization</title>
<p>Humans inherently place differential value on the tasks needed to accomplish their goals. A common prioritization scheme distinguishes task priority along two dimensions: urgency and importance (<xref ref-type="bibr" rid="bibr20-0018720812443983">Covey, 2004</xref>). Urgency can be affected by factors such as time to respond and the certainty of the information, whereas importance can be determined by factors such as the level of threat or the potential impact of task failure on safety or mission objectives. Higher priority is usually given to those tasks that are both urgent and important. Changes to the task context can alter the urgency and importance of a task and accordingly alter its priority (<xref ref-type="bibr" rid="bibr40-0018720812443983">Ho et al., 2004</xref>). Tasks that have a higher priority are often allowed to interrupt those that have a lower priority (<xref ref-type="bibr" rid="bibr62-0018720812443983">Navon &amp; Gopher, 1979</xref>). Adapting the priority of tasks may couple with other elements of a task scheduling scheme to change the timing of task execution, the order in which tasks are performed, or whether the task is even performed at all, given time and resource constraints.</p>
</sec>
<sec id="section16-0018720812443983">
<title>Task duration</title>
<p>Tasks take time. The time each task requires is a combination of the nature of the task itself, the tools available, the human’s experience performing the task, and other mediating contextual factors. Many tasks inherently have a finite window during which they must be accomplished. The time available to accomplish a task is subjective and highly variable, although some minimum time can usually be calculated if all needed information is available. Adaptations in time allocations may involve setting finite deadlines for the completion of a task or changing the time allotted once a task has been started.</p>
</sec>
<sec id="section17-0018720812443983">
<title>Implications and considerations</title>
<p>A recognizable portion of task scheduling centers on interruption management, which involves reassessing the task timing and duration to account for a new prioritization scheme. Literature from a variety of domains has confirmed that humans are easily interrupted and that poor handling of interruptions can increase errors, increase frustration and stress, and reduce efficiency and decision quality (<xref ref-type="bibr" rid="bibr19-0018720812443983">Chen &amp; Vertegaal, 2004</xref>; <xref ref-type="bibr" rid="bibr33-0018720812443983">Gillie &amp; Broadbent, 1989</xref>; <xref ref-type="bibr" rid="bibr42-0018720812443983">Iqbal, Adamczyk, Zheng, &amp; Bailey, 2005</xref>; <xref ref-type="bibr" rid="bibr54-0018720812443983">McFarlane &amp; Latorella, 2002</xref>). <xref ref-type="bibr" rid="bibr54-0018720812443983">McFarlane and Latorella (2002)</xref> conclude that a principled approach to improve interface design for interruption management is lacking, despite guidelines that recognize the operator’s need for greater control of tasks, such as those proposed by <xref ref-type="bibr" rid="bibr90-0018720812443983">Smith and Mosier (1986)</xref>.</p>
<p>Adaptations to task scheduling aim to create automated systems that are less frustrating to operators by endowing them with the same courtesies exhibited by human colleagues, such as an understanding of task priorities and interruptibility (<xref ref-type="bibr" rid="bibr11-0018720812443983">Bickmore, 2010</xref>; <xref ref-type="bibr" rid="bibr59-0018720812443983">Miller &amp; Parasuraman, 2007</xref>; <xref ref-type="bibr" rid="bibr69-0018720812443983">Parasuraman &amp; Miller, 2004</xref>). One of the challenges in designing effective interruption and task scheduling systems is the difficulty automated systems have predicting the interruptibility of a human operator. Having this ability would allow automated systems to take advantage of periods of high interruptibility to suggest the operator attend to a different program or switch tasks and use periods of low interruptibility to minimize disruptions. Although <xref ref-type="bibr" rid="bibr2-0018720812443983">Adamczyk, Iqbal, and Bailey (2005)</xref> were able to create models to predict interruptibility with a 78% accuracy compared to self-reports based on physiological measures and a task model, work is needed in this area to improve modifications to task scheduling.</p>
</sec>
<sec id="section18-0018720812443983">
<title>Examples</title>
<p>Alerting systems are good examples of automated systems that reprioritize tasks for humans and dictate the timing of certain tasks. <xref ref-type="bibr" rid="bibr77-0018720812443983">Pritchett (2001)</xref> categorizes alerting systems into three main types: signal detectors, hazard detectors, and hazard resolvers. All three seek to interrupt normal operator activities and to draw the operator’s attention. The roles that alerting systems play in the modification of task scheduling include task management aid, overlord, initiator of procedures, desired cue, trusted monitor, and attention director (<xref ref-type="bibr" rid="bibr77-0018720812443983">Pritchett, 2001</xref>). Alerting systems in modern commercial aircraft actively modify their behavior depending on the phase of flight. For example, minor warnings are routinely suppressed during the takeoff and landing phases of flight so as not to interrupt the pilot while performing other critical flight tasks.</p>
</sec>
</sec>
<sec id="section19-0018720812443983">
<title>How: Modification of Interaction</title>
<p>The modification of interaction adapts the interaction between the human and the automation and seeks to answer questions such as how information is exchanged, where the interaction locus of control is, how often the operator will interact with the automation, and when this interaction will happen. Modifications of interaction are typically not recognized as a class of adaptations by function allocation-centric taxonomies. Modifications to interaction comprise adaptations to the <italic>interface features, interaction style</italic>, and the <italic>amount of interaction</italic> required.</p>
<sec id="section20-0018720812443983">
<title>Interface features</title>
<p>One of the simplest adaptations is the modification of the way the information is displayed to the operator. Here, we take a narrower view than <xref ref-type="bibr" rid="bibr80-0018720812443983">Rothrock et al. (2002)</xref> and define modifications to interface features as only modifications to the information layout, ways to augment the information to direct attention (e.g., highlighting), and changes to the navigation of information (e.g., context-dependent menus).</p>
</sec>
<sec id="section21-0018720812443983">
<title>Amount of interaction</title>
<p>The amount of interaction an individual has with automation is defined along two dimensions: how much interaction and when that interaction occurs. How much interaction spans a continuum from very little to continuous. The interaction between the human and the automation can come at any point in the task. Historically, the majority of interaction has come either at the beginning (activation) or the end (response selection) of a task. Alternatively, interaction with the automation can be interspersed throughout a task or purposefully interrupt a task.</p>
</sec>
<sec id="section22-0018720812443983">
<title>Modality</title>
<p>The modality refers to the sensory channel (e.g., visual, auditory, haptic) in which information is exchanged (e.g., visual, auditory, haptic). Wickens’s multiple resource theory contends that the dynamic allocation of incoming information to the most readily available attentional resource pool will avoid overtaxing the operator. Separate resources are defined by auditory versus visual processing and spatial (analog) versus verbal (linguistic) processing (<xref ref-type="bibr" rid="bibr98-0018720812443983">Wickens &amp; Hollands, 2000</xref>). Information can be presented in a different modality (e.g., visual to text, or text to speech).</p>
</sec>
<sec id="section23-0018720812443983">
<title>Interaction style</title>
<p>The interaction style refers to the rules that govern the interaction employed by automation, how information is exchanged between agents, and the locus of authority and control of interaction (<xref ref-type="bibr" rid="bibr13-0018720812443983">Billings, 1997</xref>). The first aspect of interaction style governs whether the information exchange between agents is either given or requested. The act of requesting information is not the same as the task of giving information and may result in differential performance of the joint human–machine system (<xref ref-type="bibr" rid="bibr30-0018720812443983">Entin &amp; Entin, 2001</xref>; <xref ref-type="bibr" rid="bibr91-0018720812443983">Sperling, 2005</xref>). The second aspect of interaction style is the locus of control of the interaction, which can also be thought of as the automation’s authority level. Authority level over the joint set of tasks has two extremes: full human authority or full automation authority. Two points on this continuum are better known as <italic>management by delegation</italic> (also called management by permission) and <italic>management by exception</italic> (<xref ref-type="bibr" rid="bibr12-0018720812443983">Billings, 1996</xref>). Unlike modifications of function allocation, management by permission versus exception does not change who does the task (i.e., task assignment or function allocation) but rather who has final authority over the task. For instance, under management by delegation rules, one agent (traditionally the human) permits the automation to execute the task assigned to it; the locus of control remains with the agent who delegates tasks in real time.</p>
</sec>
<sec id="section24-0018720812443983">
<title>Implications and considerations</title>
<p>Modifications to the display features are some of the most widely used adaptations and the considerations for use are well documented in the literature (see <xref ref-type="bibr" rid="bibr80-0018720812443983">Rothrock et al., 2002</xref>, for a thorough review). However, adaptations to the other aspects of interaction, interaction amount and style, are not widely utilized by current adaptive systems. Changes to the amount of interaction may have been overlooked thus far or be seen to “fall out” from modifications of other dimensions. Changes to interaction style, on the other hand, have likely been actively avoided as changes to interaction style often violate the human factors tenant of consistent behavior. Operators work to construct mental models of the automation; thus, modifications to the interaction style have the potential to be disruptive. On the other hand, changes in the interaction style can be used to increase user engagement, a well-established practice in computer gaming (S. D. Whitlow, personal communication, November 8, 2011).</p>
<p>As authority and roles change between the human and the automation, another consideration is one of <italic>automaton etiquette</italic>, which facilitates smooth and effective interactions between people and automation (<xref ref-type="bibr" rid="bibr38-0018720812443983">Hayes &amp; Miller, 2010</xref>). A change in authority may carry implications for a change in the power and familiarity relationship between the human and the automation (<xref ref-type="bibr" rid="bibr11-0018720812443983">Bickmore, 2010</xref>). In addition, how those relationships are expressed can be culturally dependent.</p>
</sec>
<sec id="section25-0018720812443983">
<title>Examples</title>
<p>Many examples of adaptations to the interaction style can be found in educational fields in the form of tutoring or coaching systems. Several examples of adaptations in these areas include adapting to the learning styles of the student (<xref ref-type="bibr" rid="bibr44-0018720812443983">Johnson et al., 2003</xref>), adapting the amount of interaction with the automated tutor as the expertise of the student changes (<xref ref-type="bibr" rid="bibr23-0018720812443983">Dorneich &amp; Jones, 2001</xref>), and adapting the changing relationship between coach and student (<xref ref-type="bibr" rid="bibr11-0018720812443983">Bickmore, 2010</xref>).</p>
<p>Although adaptive systems that modify the locus of authority are rare, <xref ref-type="bibr" rid="bibr9-0018720812443983">Barnes and Grossman (1985)</xref> identified three types of adaptations to control authority: emergency logic, executive logic, and automated display logic. Emergency logic modifies authority based on the automation’s situation assessment. Emergency adaptations are taken without the consent of the human operator, thereby changing the interaction locus of control from the human to the automation. Executive adaptations, on the other hand, are taken with human approval and therefore retain the original interaction locus of control.</p>
</sec>
</sec>
<sec id="section26-0018720812443983">
<title>What: Modification of Content</title>
<p><italic>Modification of content</italic> describes changes to the information content itself (as opposed to the modification of interaction category, which governs how the information is interacted with but where the information stays largely unchanged). Often, these types of changes are designed to provide a subset of all available information to support short-term goals and tasks. Changes to content can usually be described as changes to <italic>quantity</italic>, level of <italic>abstraction</italic>, or <italic>quality</italic>.</p>
<sec id="section27-0018720812443983">
<title>Quantity</title>
<p>The most straightforward adaptation to information content is to decide whether to present the information at all. Dynamic display decluttering adaptations are used to help operators focus on only the most important information for the task at hand.</p>
</sec>
<sec id="section28-0018720812443983">
<title>Abstraction</title>
<p>Information can be aggregated or abstracted to focus on salient aspects and reduce the processing time for the human to interpret the presented information. Choosing the correct abstraction for the key functional relationships is often the aim of ecological interface design (<xref ref-type="bibr" rid="bibr17-0018720812443983">Burns &amp; Hajdukiewicz, 2004</xref>). As the functional relationships of interest change, so too should the information displayed to the operator.</p>
</sec>
<sec id="section29-0018720812443983">
<title>Quality</title>
<p>Similarly, the information may be presented at lower or higher quality, depending on the current context. If information is of a time-critical nature, then the system may provide a lower quality version if the full information content would exceed the deadline for task completion. For example, video streams may be reduced in frame rate or even converted to a series of lower-quality images (<xref ref-type="bibr" rid="bibr60-0018720812443983">Mohan, Smith, &amp; Li, 1999</xref>).</p>
</sec>
<sec id="section30-0018720812443983">
<title>Implications and considerations</title>
<p>Typically content adaptations are best suited for knowledge acquisition and analysis support tasks. Content adaptations are also suited to highlight key functional relationships that may need additional operator attention. When modifying the content, it is imperative to ensure that the user is provided with the information needed to successfully accomplish his or her work.</p>
</sec>
<sec id="section31-0018720812443983">
<title>Examples</title>
<p>With the proliferation of mobile handheld devices, there has been significant work to modify content based on factors such as the client display capabilities, quality of service considerations, and network state (<xref ref-type="bibr" rid="bibr85-0018720812443983">Shaha, Desai, &amp; Parashar, 2001</xref>). Modifications typically include reducing the quality of images and video for lower-bandwidth transmission and aggregating the content into a simpler navigational scheme.</p>
</sec>
</sec>
</sec>
<sec id="section32-0018720812443983">
<title>Taxonomy of Triggers</title>
<p>By definition, adaptations are designed for specific situations as defined by context and as such, changes in context can trigger the system to adapt the automation. Triggers are based on several classes of information that can be sensed, observed, or modeled to create an understanding of context or “what is happening in the world” relevant to the adaptive system’s decision making. An adaptive system needs triggers to identify when to engage an adaptation, how long an adaptation should persist, and when to disengage the adaptation. Previous discussions of adaptation management have focused primarily on engagement triggers, with less discussion on duration and disengagement criterion, the importance of which has been highlighted with aviation accidents caused by unanticipated autopilot disengagement (<xref ref-type="bibr" rid="bibr12-0018720812443983">Billings, 1996</xref>). Expanding on previous categorizations (<xref ref-type="bibr" rid="bibr18-0018720812443983">Byrne &amp; Parasuraman, 1996</xref>; <xref ref-type="bibr" rid="bibr70-0018720812443983">Parasuraman, Mouloua, &amp; Molloy, 1996</xref>; <xref ref-type="bibr" rid="bibr81-0018720812443983">Rouse, 1988</xref>; <xref ref-type="bibr" rid="bibr88-0018720812443983">Sheridan &amp; Parasuraman, 2006</xref>), this taxonomy classifies adaptation triggers into five broad categories (see <xref ref-type="fig" rid="fig3-0018720812443983">Figure 3</xref>): operator, system, environment, task, and spatiotemporal.</p>
<fig id="fig3-0018720812443983" position="float">
<label>Figure 3.</label>
<caption>
<p>Taxonomy of Triggers for adaptive systems.</p>
</caption>
<graphic xlink:href="10.1177_0018720812443983-fig3.tif"/></fig>
<list id="list3-0018720812443983" list-type="bullet">
<list-item><p><italic>Operator-based triggers</italic>. Adaptations can be triggered by the operator directly or by a system assessment of the operator state.</p></list-item>
<list-item><p><italic>System-based triggers</italic>. Current or predicted states of the system can be used to trigger adaptations. Different modes of system operations can also trigger adaptations.</p></list-item>
<list-item><p><italic>Environment-based triggers</italic>. States of the environment or events external to the operator and the system can be used to trigger adaptations.</p></list-item>
<list-item><p><italic>Task- and mission-based triggers</italic>. A mission is typically composed of a coherent set of goals and subgoals and accomplished by a set of tasks. Triggers can be based on task state or mission state.</p></list-item>
<list-item><p><italic>Spatiotemporal triggers</italic>. Both time and location can be used as adaptation triggers.</p></list-item></list>
<p>Often adaptive systems consider multiple triggers, used in conjunction, to identify when the operator needs additional (or reduced) automation support.</p>
<sec id="section33-0018720812443983">
<title>Operator-Based Triggers</title>
<p>The simplest and original method for adaptation management is human request, where human operators engage and disengage automation as needed or desired. Recently, researchers have been exploring direct means for measuring operator state using model-based or sensor-based information to enable automation to trigger adaptations.</p>
<sec id="section34-0018720812443983">
<title>Operator initiated</title>
<p>Who controls automation adaptations is a question that has received a fair amount of attention (<xref ref-type="bibr" rid="bibr47-0018720812443983">Kaber, Riley, Tan, &amp; Endsley, 2001</xref>; <xref ref-type="bibr" rid="bibr59-0018720812443983">Miller &amp; Parasuraman, 2007</xref>; <xref ref-type="bibr" rid="bibr64-0018720812443983">Opperman, 1994</xref>; <xref ref-type="bibr" rid="bibr70-0018720812443983">Parasuraman et al., 1996</xref>; <xref ref-type="bibr" rid="bibr71-0018720812443983">Parasuraman, Mouloua, Molloy, &amp; Hilburn, 1993</xref>; <xref ref-type="bibr" rid="bibr75-0018720812443983">Prinzel et al., 2000</xref>; <xref ref-type="bibr" rid="bibr83-0018720812443983">Scerbo, Freeman, &amp; Mikulka, 2003</xref>), resulting in a distinction between those adaptations that are under human control (<italic>adaptable</italic>) and those that are not under human control (<italic>adaptive</italic>; <xref ref-type="bibr" rid="bibr64-0018720812443983">Opperman, 1994</xref>). This article has included both types in its discussions without distinction since the Taxonomy of Adaptations is applicable to systems with both automation- and human-initiated triggers. Recent work on operator-initiated adaptive automation has included delegation methods where the human commander delegates tasks to automation as he or she might to a junior teammate (<xref ref-type="bibr" rid="bibr5-0018720812443983">Arciszewski et al., 2009</xref>). <xref ref-type="bibr" rid="bibr59-0018720812443983">Miller and Parasuraman (2007)</xref> maintain that delegation is inherently powerful because the supervisor (or human) can choose which tasks to delegate to automation, the method by which the task is to be accomplished, and how much monitoring, approving, and reviewing are required. Operator-initiated automation, however, is limited in scope as it requires direct operator input, time, and attention—which may be unavailable—to initiate any automated function.</p>
</sec>
<sec id="section35-0018720812443983">
<title>Operator measurement</title>
<p>As the goal of adaptations is to improve joint human–machine system performance and human workload, measurement of these operator characteristics can be used to trigger adaptations. Other operator characteristics such as fatigue, visual load, and stress can also be measured. When direct measurement is not possible, estimations or models have been substituted (<xref ref-type="bibr" rid="bibr83-0018720812443983">Scerbo et al., 2003</xref>).</p>
<p>The reduction (<xref ref-type="bibr" rid="bibr41-0018720812443983">Huey &amp; Wickens, 1993</xref>) and stabilizing (<xref ref-type="bibr" rid="bibr59-0018720812443983">Miller &amp; Parasuraman, 2007</xref>) of workload are major drivers for adaptive systems. If one could measure workload, a workload reducing automation could be designed to turn on when the user’s workload is high to help shoulder some of the burden and to turn off when workload is low to avoid boredom. As physiological measures have become easier to obtain and research has shown them to be more reliable, it is now possible to use physiologically derived workload measures to drive adaptations (<xref ref-type="bibr" rid="bibr6-0018720812443983">Bailey, Scerbo, Freeman, Mikulka, &amp; Scott, 2006</xref>; <xref ref-type="bibr" rid="bibr18-0018720812443983">Byrne &amp; Parasuraman, 1996</xref>; <xref ref-type="bibr" rid="bibr75-0018720812443983">Prinzel et al., 2000</xref>; <xref ref-type="bibr" rid="bibr76-0018720812443983">Prinzel, Freeman, Scerbo, Mikulka, &amp; Pope, 2003</xref>; <xref ref-type="bibr" rid="bibr86-0018720812443983">Sharma, 2006</xref>; <xref ref-type="bibr" rid="bibr100-0018720812443983">Wilson &amp; Russell, 2007</xref>). <xref ref-type="bibr" rid="bibr83-0018720812443983">Scerbo et al. (2003)</xref> assessed the positive and negative attributes of possible physiological measures and concluded that the most promising is EEG. <xref ref-type="bibr" rid="bibr75-0018720812443983">Prinzel et al. (2000)</xref> showed how EEG could be used to provide a real-time assessment of workload using an engagement index as well as negative feedback to drive an adaptive system to successfully improve performance and decrease workload for simple tracking tasks. The success of EEG-based methods has led to an emphasis on the development of more robust EEG measurement devices and classification algorithms (<xref ref-type="bibr" rid="bibr24-0018720812443983">Dorneich, Mathan, Ververs, &amp; Whitlow, 2008</xref>).</p>
<p>Performance, the second widely measured operator parameter characteristic, is often seen as being roughly inversely proportional to workload (<xref ref-type="bibr" rid="bibr97-0018720812443983">Wickens, 1992</xref>). Performance models aim to evaluate the human operator’s present goals (including behavior) and his or her ability to perform tasks efficiently, maintain situation awareness, gauge information processing resources, and plan actions and goals (<xref ref-type="bibr" rid="bibr34-0018720812443983">Gray, 2007</xref>; <xref ref-type="bibr" rid="bibr81-0018720812443983">Rouse, 1988</xref>). They have been used in many adaptive systems (<xref ref-type="bibr" rid="bibr10-0018720812443983">Benyon &amp; Murray, 1993</xref>; <xref ref-type="bibr" rid="bibr16-0018720812443983">Brusilovsky, 1996</xref>; <xref ref-type="bibr" rid="bibr96-0018720812443983">Virvou, 1999</xref>; <xref ref-type="bibr" rid="bibr97-0018720812443983">Wickens, 1992</xref>).</p>
</sec>
</sec>
<sec id="section36-0018720812443983">
<title>System-Based Triggers</title>
<p>Knowledge of the system is often used to support adaptation decisions. The system knowledge encapsulated in a system model may include its structure, modes, internal states, anticipated future states, and range of potential actions. Thus, system-based triggers include the <italic>system state</italic> and the <italic>system mode</italic>.</p>
<sec id="section37-0018720812443983">
<title>System state</title>
<p>System state is a description of the current configuration of the automation and is a relatively straightforward trigger (<xref ref-type="bibr" rid="bibr66-0018720812443983">Parasuraman, Bahri, Deaton, Morrison, &amp; Barnes, 1992</xref>). For example, in an automobile, system state includes position, speed, and acceleration. An adaptive system might use such information to increase steering sensitivity at high speeds, a feature found on many luxury cars.</p>
</sec>
<sec id="section38-0018720812443983">
<title>System mode</title>
<p>System modes describe a grouping of several system configurations under one label where typically each mode corresponds to a set of unique system behaviors (<xref ref-type="bibr" rid="bibr43-0018720812443983">Johnson, 1990</xref>). This has also been described as <italic>functional modes</italic> of a system (<xref ref-type="bibr" rid="bibr21-0018720812443983">Degani, Shafto, &amp; Kirlik, 1999</xref>). The human operator can monitor or select system modes, which are typically designed to help operators develop an understanding of automation behavior (e.g., automobile cruise control). Modes are often used in combination with other triggers to afford greater specificity.</p>
</sec>
</sec>
<sec id="section39-0018720812443983">
<title>Environment-Based Triggers</title>
<p>The environment can be modeled as a representation of the relevant facets of the world outside the immediate system and operator (<xref ref-type="bibr" rid="bibr78-0018720812443983">Pritchett, Feigh, Kim, &amp; Kannan, 2011</xref>). This model can be conceived of as a model of the work domain (<xref ref-type="bibr" rid="bibr95-0018720812443983">Vicente, 1999</xref>). Often, environment models are knowledge-based and relatively static compared to the other models except in cases where the world is rapidly changing, which would generate situations that might require adaptations. Two categories of the environment-based triggers are <italic>states</italic> and <italic>events</italic>.</p>
<sec id="section40-0018720812443983">
<title>Environment state</title>
<p>States in the environment can be a description of the environmental parameters. Examples of environmental state triggers include changes in ambient light level (e.g., hand-held displays that change the display background color), temperature or humidity (e.g., programmable thermostats), or even wind speed (e.g., large wind turbines that feather their blades when wind speeds exceed safe velocities; <xref ref-type="bibr" rid="bibr14-0018720812443983">Bossanyi, 2000</xref>).</p>
</sec>
<sec id="section41-0018720812443983">
<title>Environment event</title>
<p>Adaptations can be triggered when external events occur in the environment. For example, an event might be an external threat event that triggers the automation of aircraft defensive measures following the detection of antiaircraft radar detection (<xref ref-type="bibr" rid="bibr9-0018720812443983">Barnes &amp; Grossman, 1985</xref>).</p>
</sec>
</sec>
<sec id="section42-0018720812443983">
<title>Task- and Mission-Based Triggers</title>
<p>A mission is typically composed of a set of tasks designed to achieve a set of goals, subject to constraints. Triggers can be based on <italic>mission state or task state.</italic></p>
<sec id="section43-0018720812443983">
<title>Mission state</title>
<p>A mission is typically organized into phases or subgoals, each of which is subject to constraints such as the time to complete and pre- and postconditions. Many adaptive systems identify the need for adaptation by comparing expected actions to observed actions based on knowledge of the mission, plan, intent, or goals of the joint human–machine system. In addition, completion of mission phases can be used as the basis of engagement, persistence, and disengagement triggers. Mission-based triggers are specified at a higher level of abstraction than task-based triggers.</p>
</sec>
<sec id="section44-0018720812443983">
<title>Task state</title>
<p>Adaptation management based on task state uses the initialization, completion, or partial completion of tasks (regardless of their impact on mission goals or objectives) to drive changes in automation. The challenge is how to identify which task the human is currently working on without requiring the human to continually inform the automation manually (<xref ref-type="bibr" rid="bibr57-0018720812443983">Miller &amp; Funk, 1997</xref>; <xref ref-type="bibr" rid="bibr92-0018720812443983">Stiles, Bodenhorn, &amp; Baker, 1998</xref>). Typically, this is done by monitoring the human’s interaction with the automated system (<xref ref-type="bibr" rid="bibr57-0018720812443983">Miller &amp; Funk, 1997</xref>). For example, SEDAR is a CAD system to assist roofing designers that includes a critiquing agent that automatically adapts its comments to fit the current design task, as identified by monitoring the objects that the designer selects from SEDAR’s menus (<xref ref-type="bibr" rid="bibr32-0018720812443983">Fu, Hayes, &amp; East, 2007</xref>). In another example, the Cockpit Information Manager Rotorcraft Pilot’s Associate triggered cockpit configuration adaptations based on a model of active, planned, and completed tasks (<xref ref-type="bibr" rid="bibr57-0018720812443983">Miller &amp; Funk, 1997</xref>; <xref ref-type="bibr" rid="bibr92-0018720812443983">Stiles et al., 1998</xref>).</p>
</sec>
</sec>
<sec id="section45-0018720812443983">
<title>Spatiotemporal Triggers</title>
<p>Time and location can be used to trigger adaptations.</p>
<sec id="section46-0018720812443983">
<title>Time based</title>
<p>The temporal criterion is a simple mechanism to manage the engagement and disengagement of automation. In the DFA literature, researchers have found the benefits (<xref ref-type="bibr" rid="bibr39-0018720812443983">Hilburn, Molloy, Wong, &amp; Parasuraman, 1993</xref>; <xref ref-type="bibr" rid="bibr68-0018720812443983">Parasuraman, Hilburn, Mol, &amp; Singh, 1991</xref>) and costs (<xref ref-type="bibr" rid="bibr8-0018720812443983">Ballas, Heitmeyer, &amp; Perez, 1992</xref>) of short-cycle versus long-cycle adaptive automation (where the system oscillated between manual and automatic control). Time triggers alone, however, are seen as having limited applicability (<xref ref-type="bibr" rid="bibr18-0018720812443983">Byrne &amp; Parasuraman, 1996</xref>; <xref ref-type="bibr" rid="bibr76-0018720812443983">Prinzel et al., 2003</xref>).</p>
</sec>
<sec id="section47-0018720812443983">
<title>Location based</title>
<p>The location of the automated system can be used as a trigger. The location can be absolute (e.g., GPS location of an aircraft) or relative (e.g., 10 miles from the top of descent in an aircraft flight path).</p>
</sec>
</sec>
</sec>
<sec id="section48-0018720812443983">
<title>Summary</title>
<p>Adaptive systems are those that automatically sense or track information from the environment, task, system, or user and adapt to help people to be more effective despite changing conditions. The drive to design effective adaptive systems is based on a desire to support the changing needs of people who perform highly complex work in dynamic environments. The introduction of adaptive systems has been a direct response to the need to provide multiple automation configurations that can be invoked based on the automation’s assessment of specific contextual features—a move from point design to robust design.</p>
<p>Challenges and roadblocks to practical implementation of adaptive systems include the difficulty of implementing and controlling automation that can adapt itself and automatically and unobtrusively sense and interpret the user’s cognitive state. Recent improvements, however, in neurophysiological and physiological sensing as well as explorations in how to interpret and use this information effectively have made adaptive systems more practicable and encouraged new applications and additional research.</p>
<p>The framework presented in this article provides a structure that can help researchers to organize a diverse range of literature on adaptive systems and help systems developers systematically consider the range of possible adaptations. What is known about the impact of adaptations and how best to trigger them has been uneven, with much more emphasis on modifications to function allocation and content.</p>
<p>The research and development community is still learning the implications and effects of adaptive systems, regardless of how well implemented. As such, many research questions remain open, including better understanding of the following:</p>
<list id="list4-0018720812443983" list-type="bullet">
<list-item><p>The nature of disruptions experienced by users caused by the specific types of adaptations or triggers remains unclear. What happens when the automation adapts in a way that surprises, confuses, irritates, or creates extra work for the user? Is it possible to avoid surprises and confusion, and if so, how?</p></list-item>
<list-item><p>What are the inherent trade-offs caused by specific adaptations that system developers need to anticipate? For example, the ability to focus on a single safety-critical task may need to be achieved at the cost of situation awareness on the secondary tasks temporarily shouldered by the automation.</p></list-item>
<list-item><p>What are the short-term and long-term implications of the changes in workload (both positive and negative) and performance caused by specific system adaptations and combinations of adaptations?</p></list-item>
<list-item><p>What is the best way to leverage ever-improving approaches for measuring, interpreting, and using information on the user’s cognitive state, by itself or in combination with other types of triggers given in the taxonomy?</p></list-item>
<list-item><p>What are empirical methods and metrics to assess the reliability, accuracy, and robustness of adaptive systems? For example, how may one determine whether an adaptive system is adapting at the “right” time (<xref ref-type="bibr" rid="bibr79-0018720812443983">Pritchett, Kim, Kannan, &amp; Feigh, 2011</xref>) or in the right direction?</p></list-item>
<list-item><p>Better understanding of the impact of task and context on cognition is needed, including a better theory of context (<xref ref-type="bibr" rid="bibr35-0018720812443983">Hammond, 1996</xref>; <xref ref-type="bibr" rid="bibr36-0018720812443983">Hammond, Hamm, Grassia, &amp; Pearson, 1987</xref>).</p></list-item></list>
</sec>
<sec id="section49-0018720812443983">
<title>Key Points</title>
<list id="list5-0018720812443983" list-type="bullet">
<list-item><p>Unlike traditional human–automation systems that fix the roles of humans and automation at the design stage, adaptive systems aim to enhance joint human–automation performance by having the technological portion of the joint human–machine system invoke varying levels of automation support in real-time during task execution.</p></list-item>
<list-item><p>Adaptive systems are defined here as having three key characteristics: a range of capabilities often configured into modes of operation, contextual awareness, and the authority to initiate changes to the system’s functionality and operator interface.</p></list-item>
<list-item><p>This article proposes a framework to categorize the two key elements of an adaptive system: the aspects of automated systems open to adaptation (Taxonomy of Adaptations) and the methods to trigger those adaptations (Taxonomy of Triggers).</p></list-item>
<list-item><p>The Taxonomy of Adaptations categorized the wide range of methods to adapt automation into four areas: modification of function allocation, modification of interaction, modification of content management, and modification of task management.</p></list-item>
<list-item><p>The Taxonomy of Triggers described the different methods by which adaptations could be triggered: operator, system, environment, task/mission, and spatiotemporal.</p></list-item>
<list-item><p>The framework taxonomies provide a systematic way to organize research on specific adaptations or triggers.</p></list-item>
<list-item><p>The framework presented here is a starting point for system designers by illuminating both the great opportunities afforded by the range of adaptations and the potential pitfalls that system designers must guard against.</p></list-item>
</list>
<p>Such future investigations will enable the community to understand why and when to use adaptive systems and how to create more practical, more accurate, more usable, less obtrusive, and more responsive user-centered systems to help us in our work and our lives.</p>
</sec>
</body>
<back>
<ack><p>The authors would like to thank Chris Miller and William Rogers for extensive review of the article. In addition, the authors would like to acknowledge the efforts of colleagues who participated in related projects that informed much of the thinking of this article: Patricia May Ververs, Stephen D. Whitlow, Santosh Mathan, Jim Carciofini, Janet Creaser, Trent Reusser, and Jeff Rye.</p></ack>
<bio>
<p>Karen M. Feigh is an assistant professor at the Georgia Institute of Technology’s School of Aero-space Engineering. She earned a PhD in industrial and systems engineering from the Georgia Institute of Technology in 2008.</p>
<p>Michael C. Dorneich is a principal research scientist in the Human Centered Systems Group at Honeywell Laboratories. He earned his PhD in industrial engineering in the Human Factors Program at the University of Illinois at Urbana-Champaign in 1999.</p>
<p>Caroline C. Hayes is a professor at the University of Minnesota’s Department of Mechanical Engineering. She earned a PhD in robotics from Carnegie Mellon University in 1990.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Abbott</surname><given-names>T. S.</given-names></name>
<name><surname>Rogers</surname><given-names>W. H.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Functional categories for human-centered flight deck design</article-title>. In <conf-name>Proceedings of 12th American Institute of Aeronautics and Astronautics—Institute of Electrical and Electronics Engineers Digital Avionics Systems Conference (DASC)</conf-name> (pp. <fpage>66</fpage>–<lpage>74</lpage>). <conf-loc>Reston, VA: American Institute of Aeronautics and Astronautics</conf-loc>.</citation>
</ref>
<ref id="bibr2-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Adamczyk</surname><given-names>P. D.</given-names></name>
<name><surname>Iqbal</surname><given-names>S. T.</given-names></name>
<name><surname>Bailey</surname><given-names>B. P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>A method, system, and tools for intelligent interruption management</article-title>. In <source>TAMODIA</source> (pp. <fpage>123</fpage>–<lpage>126</lpage>). <publisher-loc>Gdansk, Poland</publisher-loc>: <publisher-name>ACM Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Adams</surname><given-names>M. J.</given-names></name>
<name><surname>Tenney</surname><given-names>Y. J.</given-names></name>
<name><surname>Pew</surname><given-names>R. W.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Situation awareness and the cognitive management of complex systems</article-title>. <source>Human Factors</source>, <volume>37</volume>, <fpage>85</fpage>–<lpage>104</lpage>.</citation>
</ref>
<ref id="bibr4-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Alter</surname><given-names>K. W.</given-names></name>
<name><surname>Goins</surname><given-names>J. B.</given-names></name>
<name><surname>Hofer</surname><given-names>E. F.</given-names></name>
<name><surname>Koehn</surname><given-names>W. L.</given-names></name>
<name><surname>Miles</surname><given-names>W. L.</given-names></name>
<name><surname>Mowry</surname><given-names>R. S.</given-names></name>
<name><surname>Pfaff</surname><given-names>T. A.</given-names></name>
</person-group> (<year>1995</year>). <source>High speed research flight deck design and integration flight deck concepts</source> (Tech. rep.) <publisher-loc>Seattle, WA</publisher-loc>: <publisher-name>Boeing/McDonnell Douglas Industry Team</publisher-name>.</citation>
</ref>
<ref id="bibr5-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Arciszewski</surname><given-names>H.</given-names></name>
<name><surname>de Greef</surname><given-names>T.</given-names></name>
<name><surname>van Delft</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Adaptive automation in a naval combat management system</article-title>. <source>IEEE Transactions on Systems, Man, and Cybernetics, Part A: Systems and Human</source>, <volume>39</volume>(<issue>6</issue>), <fpage>1188</fpage>–<lpage>1199</lpage>.</citation>
</ref>
<ref id="bibr6-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bailey</surname><given-names>N. R.</given-names></name>
<name><surname>Scerbo</surname><given-names>M. W.</given-names></name>
<name><surname>Freeman</surname><given-names>F. G.</given-names></name>
<name><surname>Mikulka</surname><given-names>P. J.</given-names></name>
<name><surname>Scott</surname><given-names>L. A.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Comparison of a brain-based adaptive system and a manual adaptable system for invoking automation</article-title>. <source>Human Factors</source>, <volume>48</volume>, <fpage>693</fpage>–<lpage>709</lpage>.</citation>
</ref>
<ref id="bibr7-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bainbridge</surname><given-names>L.</given-names></name>
</person-group> (<year>1983</year>). <article-title>Ironies of automation</article-title>. <source>Automatica</source>, <volume>19</volume>, <fpage>775</fpage>–<lpage>779</lpage>.</citation>
</ref>
<ref id="bibr8-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ballas</surname><given-names>J. A.</given-names></name>
<name><surname>Heitmeyer</surname><given-names>C. L.</given-names></name>
<name><surname>Perez</surname><given-names>M. A.</given-names></name>
</person-group> (<year>1992</year>). <source>Direct manipulation and intermittent automation in advanced</source> cockpits (Final rep. NRL/FR/5534–92-9375). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Naval Research Laboratory</publisher-name>.</citation>
</ref>
<ref id="bibr9-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Barnes</surname><given-names>M.</given-names></name>
<name><surname>Grossman</surname><given-names>J.</given-names></name>
</person-group> (<year>1985</year>). <source>The intelligent assistant concept for electronic warfare systems</source> (NWC TP 5585). <publisher-loc>China Lake, CA</publisher-loc>: <publisher-name>Naval Warfare College</publisher-name>.</citation>
</ref>
<ref id="bibr10-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Benyon</surname><given-names>D. R.</given-names></name>
<name><surname>Murray</surname><given-names>D. M.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Applying user modeling to human-computer interaction design</article-title>. <source>Artificial Intelligence Review</source>, <volume>6</volume>, <fpage>43</fpage>–<lpage>69</lpage>.</citation>
</ref>
<ref id="bibr11-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bickmore</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Etiquette in motivational agents: Engaging users and developing relationships</article-title>. In <person-group person-group-type="editor">
<name><surname>Hayes</surname><given-names>C.C.</given-names></name>
<name><surname>Miller</surname><given-names>C.A.</given-names></name>
</person-group> (Eds.), <source>Human-computer etiquette: Understanding the impact of human culture and expectations on the use and effectiveness of computers and technology</source> (pp. <fpage>205</fpage>–<lpage>230</lpage>). <publisher-loc>Abingdon, UK</publisher-loc>: <publisher-name>Taylor &amp; Francis</publisher-name>.</citation>
</ref>
<ref id="bibr12-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Billings</surname><given-names>C. E.</given-names></name>
</person-group> (<year>1996</year>). <source>Human-centered aviation automation: Principles and guidelines</source> (Technical Memorandum 110381). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>NASA</publisher-name>.</citation>
</ref>
<ref id="bibr13-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Billings</surname><given-names>C. E.</given-names></name>
</person-group> (<year>1997</year>). <source>Aviation automation: The search for a human centered approach</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr14-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bossanyi</surname><given-names>E. A.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The design of closed loop controllers for wind turbines</article-title>. <source>Wind Energy</source>, <volume>3</volume>(<issue>3</issue>), <fpage>149</fpage>–<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr15-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Botargues</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <source>Airbus AP/FD TCAS mode: A new step towards safety improvement</source>. <publisher-loc>Haren, Brussels</publisher-loc>: <publisher-name>Eurocontrol</publisher-name>.</citation>
</ref>
<ref id="bibr16-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brusilovsky</surname><given-names>P.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Methods and techniques of adaptive hypermedia</article-title>. <source>User Modeling and User-Adapted Interaction</source>, <volume>6</volume>, <fpage>87</fpage>–<lpage>129</lpage>.</citation>
</ref>
<ref id="bibr17-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Burns</surname><given-names>C. M.</given-names></name>
<name><surname>Hajdukiewicz</surname><given-names>J. R.</given-names></name>
</person-group> (<year>2004</year>). <source>Ecological interface design</source>. <publisher-loc>Boca Raton, FL</publisher-loc>: <publisher-name>CRC Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Byrne</surname><given-names>E. A.</given-names></name>
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Psychophysiology and adaptive automation</article-title>. <source>Biological Psychology</source>, <volume>42</volume>, <fpage>249</fpage>–<lpage>268</lpage>.</citation>
</ref>
<ref id="bibr19-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>D.</given-names></name>
<name><surname>Vertegaal</surname><given-names>R.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Using mental load for managing interruptions in physiologically attentive user interfaces</article-title>. In <source>Proceedings of CHI</source> (pp. <fpage>1513</fpage>–<lpage>1516</lpage>). <publisher-loc>Gdansk, Poland</publisher-loc>: <publisher-name>ACM</publisher-name>.</citation>
</ref>
<ref id="bibr20-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Covey</surname><given-names>S. R.</given-names></name>
</person-group> (<year>2004</year>). <source>The seven habits of highly effective people</source> (<edition>9th ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Free Press</publisher-name>.</citation>
</ref>
<ref id="bibr21-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Degani</surname><given-names>A.</given-names></name>
<name><surname>Shafto</surname><given-names>M.</given-names></name>
<name><surname>Kirlik</surname><given-names>A.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Modes in human–machine systems: Review, classification, and application</article-title>. <source>International Journal of Aviation Psychology</source>, <volume>9</volume>(<issue>2</issue>), <fpage>125</fpage>–<lpage>138</lpage>.</citation>
</ref>
<ref id="bibr22-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dekker</surname><given-names>S.</given-names></name>
<name><surname>Woods</surname><given-names>D. D.</given-names></name>
</person-group> (<year>2002</year>). <article-title>MABA-MABA or abracadabra? Progress on human-automation co-ordination</article-title>. <source>Cognition Technology &amp; Work</source>, <volume>4</volume>, <fpage>240</fpage>–<lpage>244</lpage>.</citation>
</ref>
<ref id="bibr23-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dorneich</surname><given-names>M. C.</given-names></name>
<name><surname>Jones</surname><given-names>P. M.</given-names></name>
</person-group> (<year>2001</year>). <article-title>The UIUC virtual spectrometer: A java-based collaborative learning environment</article-title>. <source>Journal of Engineering Education</source>, <volume>90</volume>(<issue>4</issue>), <fpage>721</fpage>–<lpage>728</lpage>.</citation>
</ref>
<ref id="bibr24-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dorneich</surname><given-names>M. C.</given-names></name>
<name><surname>Mathan</surname><given-names>S.</given-names></name>
<name><surname>Ververs</surname><given-names>P. M.</given-names></name>
<name><surname>Whitlow</surname><given-names>S. D.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Cognitive state estimation in mobile environments</article-title>. In <person-group person-group-type="editor">
<name><surname>Schmorrow</surname><given-names>D.</given-names></name>
<name><surname>Stanney</surname><given-names>K.</given-names></name>
</person-group> (Eds.), <source>Augmented cognition: A practitioner’s guide</source> (pp. <fpage>75</fpage>–<lpage>111</lpage>). <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>Human Factors and Ergonomics Society</publisher-name>.</citation>
</ref>
<ref id="bibr25-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dorneich</surname><given-names>M. C.</given-names></name>
<name><surname>Mathan</surname><given-names>S.</given-names></name>
<name><surname>Whitlow</surname><given-names>S. D.</given-names></name>
<name><surname>Ververs</surname><given-names>P. M.</given-names></name>
<name><surname>Hayes</surname><given-names>C.C.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Etiquette considerations for adaptive systems that interrupt: Cost and benefits</article-title>. In <person-group person-group-type="editor">
<name><surname>Hayes</surname><given-names>C. C.</given-names></name>
<name><surname>Miller</surname><given-names>C. A.</given-names></name>
</person-group> (Eds.), <source>Human-computer etiquette: Understanding the impact of human culture and expectations on the use and effectiveness of computers and technology</source> (pp. <fpage>289</fpage>–<lpage>322</lpage>). <publisher-loc>Abingdon, UK</publisher-loc>: <publisher-name>Taylor &amp; Francis</publisher-name>.</citation>
</ref>
<ref id="bibr26-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Dorneich</surname><given-names>M.</given-names></name>
<name><surname>Ververs</surname><given-names>P.</given-names></name>
<name><surname>Mathan</surname><given-names>S.</given-names></name>
<name><surname>Whitlow</surname><given-names>S. C. J.</given-names></name>
<name><surname>Reusser</surname><given-names>T.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Neuro-physiologically-driven adaptive automation to improve decision making under stress</article-title>. In <conf-name>Proceedings of the Human Factors and Ergonomics Society Conference</conf-name>. <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>Human Factors and Ergonomics Society</publisher-name>.</citation>
</ref>
<ref id="bibr27-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Duncan</surname><given-names>J.</given-names></name>
</person-group> (<year>1986</year>). <article-title>Disorganisation of behaviour after frontal lobe damage</article-title>. <source>Cognitive Neurophychology</source>, <volume>3</volume>, <fpage>271</fpage>–<lpage>290</lpage>.</citation>
</ref>
<ref id="bibr28-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Endsley</surname><given-names>M. R.</given-names></name>
</person-group> (<year>1987</year>). <article-title>The application of human factors to the development of expert systems for advanced cockpits</article-title>. In <source>Proceedings of the Human Factors Society 31st annual meeting</source> (pp. <fpage>1388</fpage>–<lpage>1392</lpage>). <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>Human Factors and Ergonomics Society</publisher-name>.</citation>
</ref>
<ref id="bibr29-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Endsley</surname><given-names>M. R.</given-names></name>
<name><surname>Kaber</surname><given-names>D. B.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Level of automation effects on performance, situation awareness and workload in a dynamic control task</article-title>. <source>Ergonomics</source>, <volume>42</volume>(<issue>6</issue>), <fpage>462</fpage>–<lpage>492</lpage>.</citation>
</ref>
<ref id="bibr30-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Entin</surname><given-names>E. E.</given-names></name>
<name><surname>Entin</surname><given-names>E. B.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Measures for evaluation of team process and performance in experiments and exercises</article-title>. In <conf-name>Proceedings of the 6th International Command and Control Research and Technology Symposium</conf-name>. <conf-loc>Washington, D.C.: Command and Control Research Program</conf-loc>.</citation>
</ref>
<ref id="bibr31-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fitts</surname><given-names>M. P.</given-names></name>
</person-group> (<year>1951</year>). <source>Human engineering for an effective air-navigation and traffic control system</source> (Tech. rep.). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Research Council, Committee on Aviation Psychology</publisher-name>.</citation>
</ref>
<ref id="bibr32-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fu</surname><given-names>M. C.</given-names></name>
<name><surname>Hayes</surname><given-names>C. C.</given-names></name>
<name><surname>East</surname><given-names>E. W.</given-names></name>
</person-group> (<year>2007</year>). <article-title>SEDAR: Expert critiquing system for flat and low-slope roof design and review</article-title>. <source>Journal of Computing in Civil Engineering</source>, <volume>2</volume>(<issue>1</issue>), <fpage>60</fpage>–<lpage>68</lpage>.</citation>
</ref>
<ref id="bibr33-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gillie</surname><given-names>T.</given-names></name>
<name><surname>Broadbent</surname><given-names>D. E.</given-names></name>
</person-group> (<year>1989</year>). <article-title>What makes interruptions disruptive? A study of length, similarity, and complexity</article-title>. <source>Psychological Research</source>, <volume>50</volume>, <fpage>243</fpage>–<lpage>250</lpage>.</citation>
</ref>
<ref id="bibr34-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gray</surname><given-names>W. D.</given-names></name>
</person-group> (<year>2007</year>). <source>Integrated models of cognitive systems</source>. <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr35-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hammond</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1996</year>). <source>Human judgment and social policy</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr36-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hammond</surname><given-names>K. R.</given-names></name>
<name><surname>Hamm</surname><given-names>R. M.</given-names></name>
<name><surname>Grassia</surname><given-names>J.</given-names></name>
<name><surname>Pearson</surname><given-names>T.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Direct comparison of the efficacy of intuitive and analytical cognition in expert judgment</article-title>. <source>IEEE Transactions on Systems Man and Cybernetics</source>, <volume>17</volume>, <fpage>753</fpage>–<lpage>770</lpage>.</citation>
</ref>
<ref id="bibr37-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Hancock</surname><given-names>P. A.</given-names></name>
<name><surname>Chignell</surname><given-names>M. H.</given-names></name>
<name><surname>Loewenthal</surname><given-names>A.</given-names></name>
</person-group> (<year>1985</year>). <article-title>An adaptive human–machine system</article-title>. In <conf-name>IEEE 1985 Proceedings of the International Conference on Cybernetics and Society</conf-name> (pp. <fpage>627</fpage>–<lpage>630</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Institute of Electrical and Electronics Engineers</publisher-name>.</citation>
</ref>
<ref id="bibr38-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hayes</surname><given-names>C. C.</given-names></name>
<name><surname>Miller</surname><given-names>C. A.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Should computers be polite?</article-title> In <person-group person-group-type="editor">
<name><surname>Hayes</surname><given-names>C. C.</given-names></name>
<name><surname>Miller</surname><given-names>C. A.</given-names></name>
</person-group> (Eds.), <source>Human-computer etiquette: Cultural expectations and the design implications they place on computers and technology</source> (pp. <fpage>1</fpage>–<lpage>14</lpage>). <publisher-loc>Abingdon, UK</publisher-loc>: <publisher-name>Taylor &amp; Francis</publisher-name>.</citation>
</ref>
<ref id="bibr39-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Hilburn</surname><given-names>B.</given-names></name>
<name><surname>Molloy</surname><given-names>R.</given-names></name>
<name><surname>Wong</surname><given-names>D.</given-names></name>
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Operator versus computer control of adaptive automation</article-title>. In <conf-name>7th International Symposium on Aviation Psychology</conf-name>.</citation>
</ref>
<ref id="bibr40-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ho</surname><given-names>C.-Y.</given-names></name>
<name><surname>Nikolic</surname><given-names>M. I.</given-names></name>
<name><surname>Waters</surname><given-names>M. J.</given-names></name>
<name><surname>Sarter</surname><given-names>N. B.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Not now! Supporting interruption management by indicating the modality and urgency of pending tasks</article-title>. <source>Human Factors</source>, <volume>46</volume>, <fpage>399</fpage>–<lpage>409</lpage>.</citation>
</ref>
<ref id="bibr41-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Huey</surname><given-names>B. M.</given-names></name>
<name><surname>Wickens</surname><given-names>C. D.</given-names></name>
</person-group> (<year>1993</year>). <source>Workload transition: Implications for individual and team performance</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academy Press</publisher-name>.</citation>
</ref>
<ref id="bibr42-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Iqbal</surname><given-names>S.</given-names></name>
<name><surname>Adamczyk</surname><given-names>P. D.</given-names></name>
<name><surname>Zheng</surname><given-names>X. S.</given-names></name>
<name><surname>Bailey</surname><given-names>B. P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Towards an index of opportunity: Understanding changes in mental workload during task execution</article-title>. In <source>Proceedings of CHI</source> (pp. <fpage>311</fpage>–<lpage>320</lpage>). <publisher-loc>Gdansk, Poland</publisher-loc>: <publisher-name>ACM</publisher-name>.</citation>
</ref>
<ref id="bibr43-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>J.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Modes in non-computer devices</article-title>. <source>International Journal of Man-Machine Studies</source>, <volume>32</volume>, <fpage>423</fpage>–<lpage>438</lpage>.</citation>
</ref>
<ref id="bibr44-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>W.</given-names></name>
<name><surname>Shaw</surname><given-names>E.</given-names></name>
<name><surname>Marshall</surname><given-names>A.</given-names></name>
<name><surname>LaBore</surname><given-names>C.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Evolution of user interaction: The case of agent Adele</article-title>. In <conf-name>Proceedings of the 8th International Conference on Intelligent User Interfaces</conf-name> (pp. <fpage>93</fpage>–<lpage>100</lpage>). <publisher-loc>Gdansk, Poland</publisher-loc>: <publisher-name>ACM</publisher-name>.</citation>
</ref>
<ref id="bibr45-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jordan</surname><given-names>N.</given-names></name>
</person-group> (<year>1963</year>). <article-title>Allocation of functions between man and machines in automated systems</article-title>. <source>Journal of Applied Psychology</source>, <volume>47</volume>, <fpage>161</fpage>–<lpage>165</lpage>.</citation>
</ref>
<ref id="bibr46-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaber</surname><given-names>D. B.</given-names></name>
<name><surname>Endsley</surname><given-names>M. R.</given-names></name>
</person-group> (<year>2004</year>). <article-title>The effects of level of automation and adaptive automation on human performance, situation awareness and workload in a dynamic control task</article-title>. <source>Theoretical Issues in Ergonomic Science</source>, <volume>5</volume>(<issue>2</issue>), <fpage>113</fpage>–<lpage>153</lpage>.</citation>
</ref>
<ref id="bibr47-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaber</surname><given-names>D. B.</given-names></name>
<name><surname>Riley</surname><given-names>J. M.</given-names></name>
<name><surname>Tan</surname><given-names>K.-W.</given-names></name>
<name><surname>Endsley</surname><given-names>M. R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>On the design of adaptive automation for complex systems</article-title>. <source>International Journal of Cognitive Ergonomics</source>, <volume>5</volume>(<issue>1</issue>), <fpage>37</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr48-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaber</surname><given-names>D. B.</given-names></name>
<name><surname>Wright</surname><given-names>M. C.</given-names></name>
<name><surname>Prinzel</surname><given-names>L. J.</given-names></name>
<name><surname>Clamann</surname><given-names>M. P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Adaptive automation of human–machine system information-processing functions</article-title>. <source>Human Factors</source>, <volume>47</volume>, <fpage>730</fpage>–<lpage>741</lpage>.</citation>
</ref>
<ref id="bibr49-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaber</surname><given-names>D. B.</given-names></name>
<name><surname>Wright</surname><given-names>M. C.</given-names></name>
<name><surname>Sheik-Nainar</surname><given-names>M. A.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Investigation of multi-modal interface features for adaptive automation of a human–robot system</article-title>. <source>International Journal of Human-Computer Studies</source>, <volume>64</volume>, <fpage>527</fpage>–<lpage>540</lpage>.</citation>
</ref>
<ref id="bibr50-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>S. M.</given-names></name>
<name><surname>Kim</surname><given-names>S. Y.</given-names></name>
<name><surname>Feigh</surname><given-names>K. M.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Structural framework for performance-based assessment of ATM systems</article-title>. In <conf-name>Aviation Technology, Information, and Operations Conference</conf-name>. <publisher-loc>Hilton Head, SC</publisher-loc>: <publisher-name>American Institute of Aeronautics and Astronautics</publisher-name>.</citation>
</ref>
<ref id="bibr51-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lintern</surname><given-names>G.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Work-focused analysis and design</article-title>. <source>Cognition Technology &amp; Work</source>, <volume>14</volume>(<issue>1</issue>), <fpage>71</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr52-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>MacMillan</surname><given-names>J.</given-names></name>
<name><surname>Deutsch</surname><given-names>S. E.</given-names></name>
<name><surname>Young</surname><given-names>M. J.</given-names></name>
</person-group> (<year>1997</year>). <article-title>A comparison of alternatives for automated decision support in a multi-task environment</article-title>. In <conf-name>Proceedings of the Human Factors and Ergonomics Society 41st annual meeting</conf-name> (pp. <fpage>190</fpage>–<lpage>195</lpage>). <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>Human Factors and Ergonomics Society</publisher-name>.</citation>
</ref>
<ref id="bibr53-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Mazaeva</surname><given-names>N.</given-names></name>
<name><surname>Dorneich</surname><given-names>M. S. W.</given-names></name>
<name><surname>Mathan</surname><given-names>S.</given-names></name>
<name><surname>Ververs</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Characterization of changes in electrophysiological activity in an operational environment</article-title>. In <conf-name>Proceedings of the Human Factors and Ergonomics Society conference</conf-name> (pp. <fpage>1177</fpage>–<lpage>1181</lpage>). <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>Human Factors and Ergonomics Society</publisher-name>.</citation>
</ref>
<ref id="bibr54-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McFarlane</surname><given-names>D. C.</given-names></name>
<name><surname>Latorella</surname><given-names>K. A.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The scope and importance of human interruption in human-computer interaction design</article-title>. <source>Human-Computer Interaction</source>, <volume>17</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr55-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McGuire</surname><given-names>J. C.</given-names></name>
<name><surname>Zich</surname><given-names>J. A.</given-names></name>
<name><surname>Goins</surname><given-names>R. T.</given-names></name>
<name><surname>Dwyer</surname><given-names>J. B. E. J. P.</given-names></name>
<name><surname>Cody</surname><given-names>W. J.</given-names></name>
<name><surname>Rouse</surname><given-names>W. B.</given-names></name>
</person-group> (<year>1991</year>). <source>An exploration of function analysis and function allocation in the commercial flight domain</source> (Tech. rep., NASA Contractor rep. 4374). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>NASA</publisher-name>.</citation>
</ref>
<ref id="bibr56-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Meister</surname><given-names>D.</given-names></name>
</person-group> (<year>1985</year>). <source>Behavioral analysis and measurement methods</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr57-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Miller</surname><given-names>C. A.</given-names></name>
<name><surname>Funk</surname><given-names>H. B.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Knowledge requirements for information management: A rotorcraft pilot’s associate example</article-title>. In <person-group person-group-type="editor">
<name><surname>Mouloua</surname><given-names>M.</given-names></name>
<name><surname>Koonce</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>Human-automation interaction: Research and practice</source> (pp. <fpage>186</fpage>–<lpage>192</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr58-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Miller</surname><given-names>C. A.</given-names></name>
<name><surname>Hannen</surname><given-names>M. D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>The rotorcraft pilot’s associate: Design and evaluation of an intelligent user interface tool for cockpit information management</article-title>. <source>Knowledge-Based Systems</source>, <volume>12</volume>(<issue>8</issue>), <fpage>443</fpage>–<lpage>456</lpage>.</citation>
</ref>
<ref id="bibr59-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Miller</surname><given-names>C. A.</given-names></name>
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Designing for flexible interaction between humans and automation: Delegation interfaces for supervisory control</article-title>. <source>Human Factors</source>, <volume>49</volume>, <fpage>57</fpage>–<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr60-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mohan</surname><given-names>R.</given-names></name>
<name><surname>Smith</surname><given-names>J. R.</given-names></name>
<name><surname>Li</surname><given-names>C.-S.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Adapting multimedia internet content for universal access</article-title>. <source>IEEE Transactions on Multimedia</source>, <volume>1</volume>(<issue>1</issue>), <fpage>104</fpage>–<lpage>114</lpage>.</citation>
</ref>
<ref id="bibr61-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moray</surname><given-names>N.</given-names></name>
<name><surname>Dessouky</surname><given-names>M. I.</given-names></name>
<name><surname>Kijowski</surname><given-names>B. A.</given-names></name>
<name><surname>Adapathya</surname><given-names>R.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Strategic behavior, workload, and performance in task scheduling</article-title>. <source>Human Factors</source>, <volume>33</volume>, <fpage>607</fpage>–<lpage>629</lpage>.</citation>
</ref>
<ref id="bibr62-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Navon</surname><given-names>D.</given-names></name>
<name><surname>Gopher</surname><given-names>D.</given-names></name>
</person-group> (<year>1979</year>). <article-title>On the economy of the human-processing system</article-title>. <source>Psychological Review</source>, <volume>86</volume>(<issue>3</issue>), <fpage>214</fpage>–<lpage>255</lpage>.</citation>
</ref>
<ref id="bibr63-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Norman</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1986</year>). <source>User centered design: New perspectives on human–computer interaction: Cognitive engineering</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr64-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Opperman</surname><given-names>R.</given-names></name>
</person-group> (<year>1994</year>). <source>Adaptive user support</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr65-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Palmer</surname><given-names>E.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Ooops, “it didn’t arm”: A case study of two automation surprises</article-title>. In <conf-name>Proceedings of the Eighth International Symposium on Aviation Psychology</conf-name> (pp. <fpage>227</fpage>–<lpage>232</lpage>).</citation>
</ref>
<ref id="bibr66-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Bahri</surname><given-names>T.</given-names></name>
<name><surname>Deaton</surname><given-names>J. E.</given-names></name>
<name><surname>Morrison</surname><given-names>J. G.</given-names></name>
<name><surname>Barnes</surname><given-names>M.</given-names></name>
</person-group> (<year>1992</year>). <source>Theory and design of adaptive automation in aviation systems</source> (Progress rep. NAWCADWAR-9023-60). <publisher-loc>Warminster, PA</publisher-loc>: <publisher-name>Naval Air Warfare Center</publisher-name>.</citation>
</ref>
<ref id="bibr67-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Bowers</surname><given-names>J. C.</given-names></name>
</person-group> (<year>1987</year>). <source>Psychophysiology of the electronic workplace: Attention and vigilance in human computer interaction</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr68-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Hilburn</surname><given-names>B.</given-names></name>
<name><surname>Mol</surname><given-names>R.</given-names></name>
<name><surname>Singh</surname><given-names>I.</given-names></name>
</person-group> (<year>1991</year>). <source>Adaptive automation and human performance: III. Effects of practice on the benefits and costs of automation shifts</source> (Tech. rep.). <publisher-loc>Warminster, PA</publisher-loc>: <publisher-name>Naval Air Warfare Center</publisher-name>.</citation>
</ref>
<ref id="bibr69-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Miller</surname><given-names>C.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Trust and etiquette in high-criticality automated systems</article-title>. <source>Communications of the Association for Computing Machinery</source>, <volume>47</volume>, <fpage>51</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr70-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Mouloua</surname><given-names>M.</given-names></name>
<name><surname>Molloy</surname><given-names>R.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Effects of adaptive task allocation on monitoring of automated systems</article-title>. <source>Human Factors</source>, <volume>38</volume>, <fpage>665</fpage>–<lpage>579</lpage>.</citation>
</ref>
<ref id="bibr71-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Mouloua</surname><given-names>M.</given-names></name>
<name><surname>Molloy</surname><given-names>R.</given-names></name>
<name><surname>Hilburn</surname><given-names>B.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Adaptive function allocation reduces performance cost of static automation</article-title>. In <conf-name>7th International Symposium on Aviation Psychology</conf-name> (pp. <fpage>37</fpage>–<lpage>42</lpage>).</citation>
</ref>
<ref id="bibr72-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Riley</surname><given-names>V.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Humans and automation: Use, misuse, disuse, abuse</article-title>. <source>Human Factors</source>, <volume>39</volume>, <fpage>230</fpage>–<lpage>253</lpage>.</citation>
</ref>
<ref id="bibr73-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Sheridan</surname><given-names>T. B.</given-names></name>
<name><surname>Wickens</surname><given-names>C. D.</given-names></name>
</person-group> (<year>2000</year>). <article-title>A model for types and levels of human interaction with automation</article-title>. <source>IEEE Transactions on Systems, Man, and Cybernetics—Part A: Systems and Humans</source>, <volume>30</volume>(<issue>3</issue>), <fpage>286</fpage>–<lpage>298</lpage>.</citation>
</ref>
<ref id="bibr74-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Price</surname><given-names>H.</given-names></name>
</person-group> (<year>1985</year>). <article-title>The allocation of functions in systems</article-title>. <source>Human Factors</source>, <volume>27</volume>, <fpage>33</fpage>–<lpage>45</lpage>.</citation>
</ref>
<ref id="bibr75-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Prinzel</surname><given-names>L. J.</given-names></name>
<name><surname>Freeman</surname><given-names>F. G.</given-names></name>
<name><surname>Scerbo</surname><given-names>M. W.</given-names></name>
<name><surname>Mikulka</surname><given-names>P. J.</given-names></name>
<name><surname>Pope</surname><given-names>A. T.</given-names></name>
</person-group> (<year>2000</year>). <article-title>A closed-loop system for examining psychophysiological measures for adaptive automation</article-title>. <source>International Journal of Aviation Psychology</source>, <volume>10</volume>, <fpage>393</fpage>–<lpage>410</lpage>.</citation>
</ref>
<ref id="bibr76-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Prinzel</surname><given-names>L. J.</given-names></name>
<name><surname>Freeman</surname><given-names>F. G.</given-names></name>
<name><surname>Scerbo</surname><given-names>M. W.</given-names></name>
<name><surname>Mikulka</surname><given-names>P. J.</given-names></name>
<name><surname>Pope</surname><given-names>A. T.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Effects of a psychophysiological system for adaptive automation on performance, workload, and the event-related potential p300 component</article-title>. <source>Human Factors</source>, <volume>45</volume>, <fpage>601</fpage>–<lpage>613</lpage>.</citation>
</ref>
<ref id="bibr77-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pritchett</surname><given-names>A. R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Reviewing the role of cockpit alerting systems</article-title>. <source>Human Factors and Aerospace Safety</source>, <volume>1</volume>, <fpage>5</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr78-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pritchett</surname><given-names>A. R.</given-names></name>
<name><surname>Feigh</surname><given-names>K. M.</given-names></name>
<name><surname>Kim</surname><given-names>S. Y.</given-names></name>
<name><surname>Kannan</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <source>Work models that compute to support the design of multi-agent socio-technical systems</source>. Manuscript submitted for publication.</citation>
</ref>
<ref id="bibr79-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Pritchett</surname><given-names>A.</given-names></name>
<name><surname>Kim</surname><given-names>S. Y.</given-names></name>
<name><surname>Kannan</surname><given-names>S. K.</given-names></name>
<name><surname>Feigh</surname><given-names>K.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Simulating situated work</article-title>. In <conf-name>IEEE Conference on Cognitive Methods in Situation Awareness and Support</conf-name> (pp. <fpage>66</fpage>–<lpage>73</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Institute of Electrical and Electronics Engineers</publisher-name>.</citation>
</ref>
<ref id="bibr80-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rothrock</surname><given-names>L.</given-names></name>
<name><surname>Koubek</surname><given-names>R.</given-names></name>
<name><surname>Fuchs</surname><given-names>F.</given-names></name>
<name><surname>Haas</surname><given-names>M.</given-names></name>
<name><surname>Salvendy</surname><given-names>G.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Review and reappraisal of adaptive interfaces: Toward biologically inspired paradigms</article-title>. <source>Theoretical Issues in Ergonomic Science</source>, <volume>3</volume>(<issue>1</issue>), <fpage>47</fpage>–<lpage>84</lpage>.</citation>
</ref>
<ref id="bibr81-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rouse</surname><given-names>W.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Adaptive interfaces for human/computer control</article-title>. <source>Human Factors</source>, <volume>30</volume>, <fpage>431</fpage>–<lpage>488</lpage>.</citation>
</ref>
<ref id="bibr82-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scerbo</surname><given-names>M. W.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Theoretical perspectives on adaptive automation</article-title>. In <person-group person-group-type="editor">
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>Mouloua</surname><given-names>M.</given-names></name>
</person-group> (Eds.), <source>Automation and human performance: Theory and applications</source> (pp. <fpage>37</fpage>–<lpage>63</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr83-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scerbo</surname><given-names>M. W.</given-names></name>
<name><surname>Freeman</surname><given-names>F. G.</given-names></name>
<name><surname>Mikulka</surname><given-names>P. J.</given-names></name>
</person-group> (<year>2003</year>). <article-title>A brain-based system for adaptive automation</article-title>. <source>Theoretical Issues in Ergonomic Science</source>, <issue>4</issue>(<issue>1–2</issue>), <fpage>200</fpage>–<lpage>219</lpage>.</citation>
</ref>
<ref id="bibr84-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scerbo</surname><given-names>M. W.</given-names></name>
<name><surname>Freeman</surname><given-names>F. G.</given-names></name>
<name><surname>Mikulka</surname><given-names>P. J.</given-names></name>
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
<name><surname>DiNocero</surname><given-names>F.</given-names></name>
<name><surname>Prinzell</surname><given-names>L. J. I.</given-names></name>
</person-group> (<year>2001</year>). <source>The efficacy of psychophysiological measures for implementing adaptive technology</source> (Tech. Rep. NASA/TP-2001-211018). <publisher-loc>Hampton, VA</publisher-loc>: <publisher-name>NASA Langley Research Center</publisher-name>.</citation>
</ref>
<ref id="bibr85-0018720812443983">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Shaha</surname><given-names>N.</given-names></name>
<name><surname>Desai</surname><given-names>A.</given-names></name>
<name><surname>Parashar</surname><given-names>M.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Multimedia content adaptation for QOS management over heterogeneous networks</article-title>. In <conf-name>International Conference on Internet Computing</conf-name> (pp. <fpage>642</fpage>–<lpage>648</lpage>). <conf-loc>Las Vegas, NV: CSREA Press</conf-loc>.</citation>
</ref>
<ref id="bibr86-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sharma</surname><given-names>S.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Linear temporal characteristics of heart interbeat interval as an index of the pilot’s perceived risk</article-title>. <source>Ergonomics</source>, <volume>49</volume>(<issue>9</issue>), <fpage>874</fpage>–<lpage>884</lpage>.</citation>
</ref>
<ref id="bibr87-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sheridan</surname><given-names>T. B.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Function allocation: Algorithm, alchemy or apostasy?</article-title> <source>International Journal of Human-Computer Studies</source>, <volume>52</volume>, <fpage>203</fpage>–<lpage>216</lpage>.</citation>
</ref>
<ref id="bibr88-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sheridan</surname><given-names>T. B.</given-names></name>
<name><surname>Parasuraman</surname><given-names>R.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Human-automation interaction</article-title>. <source>Reviews of Human Factors and Ergonomics</source>, <volume>1</volume>, <fpage>89</fpage>–<lpage>129</lpage>.</citation>
</ref>
<ref id="bibr89-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sheridan</surname><given-names>T. B.</given-names></name>
<name><surname>Verplank</surname><given-names>W. L.</given-names></name>
</person-group> (<year>1978</year>). <source>Human and computer control of undersea teleoperators</source> (Tech. Rep. 780815025). <publisher-loc>Arlington, VA</publisher-loc>: <publisher-name>Office of Naval Research</publisher-name>.</citation>
</ref>
<ref id="bibr90-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Smith</surname><given-names>S. L.</given-names></name>
<name><surname>Mosier</surname><given-names>J. N.</given-names></name>
</person-group> (<year>1986</year>). <source>Guidelines for designing user interface software</source> (Tech. Rep. ESD–TR-86-278). <publisher-loc>Bedford, MA</publisher-loc>: <publisher-name>MITRE</publisher-name>.</citation>
</ref>
<ref id="bibr91-0018720812443983">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Sperling</surname><given-names>B. K.</given-names></name>
</person-group> (<year>2005</year>). <source>Information distribution in complex systems to improve team performance</source> (Unpublished doctoral dissertation). <publisher-name>Georgia Institute of Technology</publisher-name>, <publisher-loc>Atlanta</publisher-loc>.</citation>
</ref>
<ref id="bibr92-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stiles</surname><given-names>P.</given-names></name>
<name><surname>Bodenhorn</surname><given-names>C.</given-names></name>
<name><surname>Baker</surname><given-names>B.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Decision aiding on rotorcraft pilot’s associate</article-title>. In <source>Proceedings of the Annual Forum of American Helicopter Society</source> (<volume>Vol. 54</volume>, pp. <fpage>1212</fpage>–<lpage>1224</lpage>). <publisher-loc>Alexandria, VA</publisher-loc>: <publisher-name>American Helicopter Society</publisher-name>.</citation>
</ref>
<ref id="bibr93-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tenney</surname><given-names>Y. J.</given-names></name>
<name><surname>Rogers</surname><given-names>W. H.</given-names></name>
<name><surname>Pew</surname><given-names>R. W.</given-names></name>
</person-group> (<year>1995</year>). <source>Pilot opinions on high level flight deck automation issues: Toward the development of a design philosophy</source> (Contractor Rep. 4669). <publisher-loc>Hampton, VA</publisher-loc>: <publisher-name>NASA Langley Research Center</publisher-name>.</citation>
</ref>
<ref id="bibr94-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tulga</surname><given-names>M. K.</given-names></name>
<name><surname>Sheridan</surname><given-names>T. B.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Dynamic decisions and work load in multitask supervisory control</article-title>. <source>IEEE Transactions on Systems, Man and Cybernetics</source>, <volume>10</volume>(<issue>5</issue>), <fpage>217</fpage>–<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr95-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vicente</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1999</year>). <source>Cognitive work analysis: Toward safe, productive, and healthy computer-based work</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr96-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Virvou</surname><given-names>M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Automatic reasoning and help about human errors in using an operating system</article-title>. <source>Interacting with Computers</source>, <volume>11</volume>, <fpage>545</fpage>–<lpage>573</lpage>.</citation>
</ref>
<ref id="bibr97-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wickens</surname><given-names>C. D.</given-names></name>
</person-group> (<year>1992</year>). <source>Engineering psychology and human performance</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>HarperCollins</publisher-name>.</citation>
</ref>
<ref id="bibr98-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wickens</surname><given-names>C. D.</given-names></name>
<name><surname>Hollands</surname><given-names>J. G.</given-names></name>
</person-group> (<year>2000</year>). <source>Engineering psychology and human performance</source>. <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation>
</ref>
<ref id="bibr99-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wickens</surname><given-names>C. D.</given-names></name>
<name><surname>Li</surname><given-names>H.</given-names></name>
<name><surname>Santamaria</surname><given-names>A.</given-names></name>
<name><surname>Sebok</surname><given-names>A.</given-names></name>
<name><surname>Sarter</surname><given-names>N. B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Stages and levels of automation: An integrated meta-analysis</article-title>. <source>Human Factors and Ergonomics Society Annual Meeting Proceedings</source>, <volume>54</volume>, <fpage>389</fpage>–<lpage>393</lpage>.</citation>
</ref>
<ref id="bibr100-0018720812443983">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>G. F.</given-names></name>
<name><surname>Russell</surname><given-names>C. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Performance enhancement in an uninhabited air vehicle task using psychophysiologically determined adaptive aiding</article-title>. <source>Human Factors</source>, <volume>49</volume>, <fpage>1005</fpage>–<lpage>1018</lpage>.</citation>
</ref>
<ref id="bibr101-0018720812443983">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Woods</surname><given-names>D.</given-names></name>
</person-group> (<year>1996</year>). <source>Decomposing automation: Apparent simplicity, real complexity</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>