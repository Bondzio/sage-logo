<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">SMX</journal-id>
<journal-id journal-id-type="hwp">spsmx</journal-id>
<journal-title>Sociological Methodology</journal-title>
<issn pub-type="ppub">0081-1750</issn>
<issn pub-type="epub">1467-9531</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0081175012444861</article-id>
<article-id pub-id-type="publisher-id">10.1177_0081175012444861</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Inference and Causality</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Comparing Regression Coefficients Between Same-sample Nested Models Using Logit and Probit</article-title>
<subtitle>A New Method</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Karlson</surname><given-names>Kristian Bernt</given-names></name>
<xref ref-type="aff" rid="aff1-0081175012444861">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Holm</surname><given-names>Anders</given-names></name>
<xref ref-type="aff" rid="aff1-0081175012444861">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Breen</surname><given-names>Richard</given-names></name>
<xref ref-type="aff" rid="aff2-0081175012444861">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0081175012444861"><label>1</label>Aarhus University</aff>
<aff id="aff2-0081175012444861"><label>2</label>Yale University</aff>
<author-notes>
<corresp id="corresp1-0081175012444861">Kristian Bernt Karlson, SFI—The Danish National Centre for Social Research, Herlufs Trolle Gade 11, DK-1052 Copenhagen K, Denmark Email: <email>kbk@dpu.dk</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2012</year>
</pub-date>
<volume>42</volume>
<issue>1</issue>
<fpage>286</fpage>
<lpage>313</lpage>
<permissions>
<copyright-statement>© American Sociological Association 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">American Sociological Association</copyright-holder>
</permissions>
<abstract>
<p>Logit and probit models are widely used in empirical sociological research. However, the common practice of comparing the coefficients of a given variable across differently specified models fitted to the same sample does not warrant the same interpretation in logits and probits as in linear regression. Unlike linear models, the change in the coefficient of the variable of interest cannot be straightforwardly attributed to the inclusion of confounding variables. The reason for this is that the variance of the underlying latent variable is not identified and will differ between models. We refer to this as the problem of rescaling. We propose a solution that allows researchers to assess the influence of confounding relative to the influence of rescaling, and we develop a test to assess the statistical significance of confounding. A further problem in making comparisons is that, in most cases, the error distribution, and not just its variance, will differ across models. Monte Carlo analyses indicate that other methods that have been proposed for dealing with the rescaling problem can lead to mistaken inferences if the error distributions are very different. In contrast, in all scenarios studied, our approach performs as least as well as, and in some cases better than, others when faced with differences in the error distributions. We present an example of our method using data from the National Education Longitudinal Study.</p>
</abstract>
<kwd-group>
<kwd>Logit</kwd>
<kwd>probit</kwd>
<kwd>rescaling</kwd>
<kwd>attenuation</kwd>
<kwd>indirect effects</kwd>
<kwd>confounding</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0081175012444861" sec-type="intro">
<title>1. Introduction</title>
<p>Nonlinear probability models such as binary logit and probit models are widely used in quantitative sociological research. One of their most common applications is to estimate the effect of a particular variable of interest on a binary outcome when potentially confounding variables are controlled. Interest in such genuine or “true” coefficients) has a long history in the social sciences and is usually associated with the elaboration procedure in cross-tabulation suggested by <xref ref-type="bibr" rid="bibr14-0081175012444861">Lazarsfeld (1955</xref>, <xref ref-type="bibr" rid="bibr15-0081175012444861">1958</xref>; <xref ref-type="bibr" rid="bibr13-0081175012444861">Kendall and Lazarsfeld 1950</xref> see also <xref ref-type="bibr" rid="bibr22-0081175012444861">Simon [1954]</xref> for partial product moment correlations). Nevertheless, controlled logit or probit coefficients do not have the same straightforward interpretation as controlled coefficients in linear regression. In fact, comparing uncontrolled and controlled coefficients across nested logit models is not directly feasible, but this appears to have gone unrecognized in much applied social research, despite an early statement of the problem by <xref ref-type="bibr" rid="bibr28-0081175012444861">Winship and Mare (1984)</xref>.</p>
<p>In this paper we offer a method that gives unbiased comparisons of logit or probit coefficients of the same variable (<italic>x</italic>) across same-sample nested models successively including control variables (<italic>z</italic>). This solution decomposes the difference in the logit or probit coefficient of <italic>x</italic> between a model excluding <italic>z</italic> and a model including <italic>z</italic>, into a part attributable to confounding (i.e., the part mediated or explained by <italic>z</italic>) and a part attributable to rescaling of the coefficient of <italic>x</italic>. Our method also deals with an additional problem in making comparisons—namely, that in most cases the error distribution, and not just its variance, will differ across models excluding and including <italic>z</italic>. Under the assumption that the full model (i.e., the model including both <italic>x</italic> and <italic>z</italic>) is correctly specified, Monte Carlo analyses indicate that while other methods suggested for resolving the rescaling problem, <italic>y</italic>-standardization, average partial effects derived from logit or probit models, and the linear probability model effectively deal with rescaling, they can lead to mistaken inferences about confounding if the error distributions are very different across models. In contrast, in all scenarios studied, our approach performs at least as well, and in some cases better than, others when faced with differences in the error distributions across models.</p>
<p>We proceed as follows. We first review the problem of comparing coefficients across nested logit or probit models, then we present our solution and show how to assess the magnitude of confounding relative to the magnitude of rescaling. Next we develop a test statistic that enables a formal test of confounding. Using Monte Carlo simulations, we show that our method is preferable to other methods for comparing coefficients across nested models. We illustrate our approach using data from the National Education Longitudinal Study. A short concluding section summarizes our arguments and suggests further applications.</p>
</sec>
<sec id="section2-0081175012444861">
<title>2. Comparing Coefficients across Logit and Probit Models</title>
<p>In linear regression, the concept of controlling for confounding variables is well understood and has great practical value. For example, a researcher might want to assess how much the effect of years of education on log annual income changes when holding constant academic ability and gender by comparing the uncontrolled coefficient for years of education with its counterpart controlling for ability and gender. The difference between the two coefficients reflects the degree to which the impact of years of education is mediated or confounded by ability and gender.<sup><xref ref-type="fn" rid="fn1-0081175012444861">1</xref></sup> This kind of design is straightforward within the OLS modeling framework and is probably one of the most widespread practices in empirical social research (<xref ref-type="bibr" rid="bibr6-0081175012444861">Clogg, Petkova, and Haritou 1995</xref>).</p>
<p>In logit and probit models, however, uncontrolled and controlled coefficients can differ not only because of confounding but also because of a rescaling of the model. By rescaling we refer to the situation where the size of the estimated coefficient of the variable of interest depends on the error variance of the model and, consequently, on which other variables are included in the model. Including a control variable, <italic>z</italic>, in a logit or probit model will alter the coefficient of <italic>x</italic> whether or not <italic>z</italic> is correlated with <italic>x</italic> because, if <italic>z</italic> explains any of the variation in the outcome variable, its inclusion will reduce the error variance. Consequently, logit or probit coefficients from different nested models are not measured on the same scale and are therefore not directly comparable. This is because, unlike linear models, in nonlinear probability models the error variance is not independently identified and is fixed at a given value (<xref ref-type="bibr" rid="bibr7-0081175012444861">Cramer 2003</xref>:22). This identification restriction is well known in the literature on limited dependent variable models (<xref ref-type="bibr" rid="bibr3-0081175012444861">Amemiya 1975</xref>; <xref ref-type="bibr" rid="bibr18-0081175012444861">Maddala 1983</xref>; <xref ref-type="bibr" rid="bibr28-0081175012444861">Winship and Mare 1984</xref>; <xref ref-type="bibr" rid="bibr30-0081175012444861">Yatchew and Griliches 1985</xref>; <xref ref-type="bibr" rid="bibr16-0081175012444861">Long 1997</xref>; <xref ref-type="bibr" rid="bibr21-0081175012444861">Powers and Xie 2000</xref>; <xref ref-type="bibr" rid="bibr1-0081175012444861">Agresti 2002</xref>; <xref ref-type="bibr" rid="bibr7-0081175012444861">Cramer 2003</xref>), but the consequences of rescaling for the interpretation of logit or probit coefficients are seldom recognized in applied social research (for similar statements, see <xref ref-type="bibr" rid="bibr2-0081175012444861">Allison [1999]</xref>; <xref ref-type="bibr" rid="bibr11-0081175012444861">Hoetker [2004</xref>, <xref ref-type="bibr" rid="bibr12-0081175012444861">2007</xref>]; <xref ref-type="bibr" rid="bibr27-0081175012444861">Williams [2009]</xref>; or <xref ref-type="bibr" rid="bibr20-0081175012444861">Mood [2010]</xref>).</p>
<p>There are at least two important reasons why we should be concerned with these problems. The first arises when we have a policy variable, <italic>z</italic>, which we believe will mediate the relationship between <italic>x</italic> and a binary outcome, <italic>y</italic>. Typically, we might first use a logit model to regress <italic>y</italic> on <italic>x</italic> to gauge the magnitude of the relationship, and then we might add <italic>z</italic> as a control to find out how much of the relationship is mediated via <italic>z</italic>. This would seem to tell us how much we could affect the <italic>x</italic>-<italic>y</italic> relationship by manipulating <italic>z</italic>. But, as we show below, such a strategy will in general tend to underestimate the mediating role of <italic>z</italic>, increasing the likelihood of our concluding, incorrectly, that changing <italic>z</italic> would have little or no impact on the <italic>x-y</italic> relationship. The second reason arises when <italic>z</italic> is a common cause of <italic>x</italic> and <italic>y</italic>. In this situation we would control for <italic>z</italic> to assess the extent to which the <italic>x-y</italic> relationship is spurious. However, similar to the first example, because of rescaling, this strategy will underestimate the confounding role of <italic>z</italic>, thereby increasing the risk of drawing erroneous conclusions about the <italic>x-y</italic> relationship.</p>
</sec>
<sec id="section3-0081175012444861">
<title>3. Separating Confounding and Rescaling</title>
<p>In this section we first show how coefficient rescaling operates in binary nonlinear probability models such as the logit and probit. Then we introduce a novel method that decomposes the change in logit or probit coefficients across nested models into a confounding component and a rescaling component, and we also explain why our method is unaffected not only by rescaling (i.e., changes in variance of the error distribution) but also by the changes in the shape of the error distribution across nested models. We also derive standard errors and <italic>Z</italic>-statistics for formally assessing the degree of confounding, and we present results from a Monte Carlo study showing that the statistical test performs well.</p>
<sec id="section4-0081175012444861">
<title>3.1. Latent Linear Formulation of a Logit Model</title>
<p>Let <italic>y</italic>* be a continuous latent variable, <italic>x</italic> a predictor variable of interest, and <italic>z</italic> one or more control variables. In this general formulation, <italic>y</italic>* may be truly latent in the sense of being a construct not directly measurable as a continuous variable (for example, an attitude or a propensity to do something), but it may also be directly measurable in principle but treated as latent because, in the particular case at hand, it was only measured partially (for example, we might only know whether someone’s income exceeded a particular amount or not). In both cases we would like to estimate the relationship between the predictor variables and the underlying latent <italic>y</italic>*.</p>
<p>In this exposition we assume that <italic>x</italic> and <italic>z</italic> are correlated and that <italic>z</italic> may thus confound the <italic>x-y</italic>* relationship. Omitting individual subscripts and centering <italic>x</italic> and <italic>z</italic> on their respective means (i.e., omitting the intercepts), we follow the notation for linear models in <xref ref-type="bibr" rid="bibr6-0081175012444861">Clogg et al. (1995</xref>; cf. <xref ref-type="bibr" rid="bibr5-0081175012444861">Blalock 1979</xref>) and specify two latent variable models:</p>
<p><disp-formula id="disp-formula1-0081175012444861">
<label>(1)</label>
<mml:math display="block" id="math1-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>:</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0081175012444861" xlink:href="10.1177_0081175012444861-eq1.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula2-0081175012444861">
<label>(2)</label>
<mml:math display="block" id="math2-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>:</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>z</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>v</mml:mi>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0081175012444861" xlink:href="10.1177_0081175012444861-eq2.tif"/>
</disp-formula></p>
<p>where <italic>e</italic> and <italic>v</italic> are error terms. <italic>H<sub>R</sub></italic> and <italic>H<sub>F</sub></italic> denote the reduced and full model respectively and we take <italic>H<sub>F</sub></italic> to be the true model.<sup><xref ref-type="fn" rid="fn2-0081175012444861">2</xref></sup> However, we do not observe <italic>y</italic>*; instead, we observe <italic>y</italic>, a dichotomized version of the latent propensity such that</p>
<p><disp-formula id="disp-formula3-0081175012444861">
<label>(3)</label>
<mml:math display="block" id="math3-0081175012444861">
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mtext>if</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mi>y</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo>&gt;</mml:mo>
<mml:mi>τ</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mtext>otherwise,</mml:mtext>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0081175012444861" xlink:href="10.1177_0081175012444861-eq3.tif"/>
</disp-formula></p>
<p>where τ is a threshold, normally set to zero.<sup><xref ref-type="fn" rid="fn3-0081175012444861">3</xref></sup> The expected outcome of this binary indicator is the probability of choosing <inline-formula id="inline-formula1-0081175012444861">
<mml:math display="inline" id="math4-0081175012444861">
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>; that is, <inline-formula id="inline-formula2-0081175012444861">
<mml:math display="inline" id="math5-0081175012444861">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. Assuming that the error term in (2) follows a logistic distribution, we can write <inline-formula id="inline-formula3-0081175012444861">
<mml:math display="inline" id="math6-0081175012444861">
<mml:mrow>
<mml:mi>v</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>u</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula4-0081175012444861">
<mml:math display="inline" id="math7-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is a scale parameter and u is a standard logistic random variable with mean 0 and standard deviation <inline-formula id="inline-formula5-0081175012444861">
<mml:math display="inline" id="math8-0081175012444861">
<mml:mrow>
<mml:mi>π</mml:mi>
<mml:mo stretchy="false">/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula> (<xref ref-type="bibr" rid="bibr7-0081175012444861">Cramer 2003</xref>:22; <xref ref-type="bibr" rid="bibr16-0081175012444861">Long 1997</xref>:119). The scale parameter rescales the variance of the error term relative to the variance of the standard logistic distribution to obtain <inline-formula id="inline-formula6-0081175012444861">
<mml:math display="inline" id="math9-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>v</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>π</mml:mi>
<mml:mo stretchy="false">/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula>. We can also write <inline-formula id="inline-formula7-0081175012444861">
<mml:math display="inline" id="math10-0081175012444861">
<mml:mrow>
<mml:mi>e</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>ζ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula8-0081175012444861">
<mml:math display="inline" id="math11-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>×</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula> and we define <inline-formula id="inline-formula9-0081175012444861">
<mml:math display="inline" id="math12-0081175012444861">
<mml:mrow>
<mml:mi>ζ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>e</mml:mi>
<mml:mo stretchy="false">/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. That is, the standard deviation of the error in the reduced model is written as equal to the standard deviation of the standard logisticmultiplied by a scale factor (cf. <xref ref-type="bibr" rid="bibr30-0081175012444861">Yatchew and Griliches 1985</xref>).</p>
<p>However, although we can express <inline-formula id="inline-formula10-0081175012444861">
<mml:math display="inline" id="math13-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> in these terms, <italic>e</italic> is unlikely to follow the same distribution as <italic>v</italic>. The distribution of the error of the reduced model depends on the distribution of <italic>v</italic>, the error of the full model, and on the distribution of the omitted confounder, <italic>z</italic>. Thus, the two models will differ not only in their scaling but also in the distribution of their error terms.<sup><xref ref-type="fn" rid="fn4-0081175012444861">4</xref></sup> This can have consequences for our ability to make cross-model comparisons when the logistic functional form (or whichever functional form we believe appropriate) is a much poorer approximation to the actual error distribution in one model than in the other.</p>
<p>Using this additional notation and setting <inline-formula id="inline-formula11-0081175012444861">
<mml:math display="inline" id="math14-0081175012444861">
<mml:mrow>
<mml:mi>τ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, we obtain the following two logit models, corresponding to (1) and (2) above:</p>
<p><disp-formula id="disp-formula4-0081175012444861">
<label>(4)</label>
<mml:math display="block" id="math15-0081175012444861">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
</mml:mrow>
</mml:msubsup>
<mml:mo>:</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>e</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>⇔</mml:mo>
<mml:mtext>logit</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0081175012444861" xlink:href="10.1177_0081175012444861-eq4.tif"/>
</disp-formula></p>
<p>In a similar way we obtain the full model</p>
<p><disp-formula id="disp-formula5-0081175012444861">
<label>(5)</label>
<mml:math display="block" id="math16-0081175012444861">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
</mml:mrow>
</mml:msubsup>
<mml:mo>:</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>z</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>z</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>⇔</mml:mo>
<mml:mtext>logit</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>z</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>z</mml:mi>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0081175012444861" xlink:href="10.1177_0081175012444861-eq5.tif"/>
</disp-formula></p>
<p>where the scale parameters, <inline-formula id="inline-formula12-0081175012444861">
<mml:math display="inline" id="math17-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula13-0081175012444861">
<mml:math display="inline" id="math18-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, are defined as above. We can immediately see that the coefficients for <italic>x</italic> from the two models, <inline-formula id="inline-formula14-0081175012444861">
<mml:math display="inline" id="math19-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula15-0081175012444861">
<mml:math display="inline" id="math20-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, are identified relative to the equation-specific scale parameters, and they are therefore influenced by the magnitude of the residual variance. While the above holds for the logit case, in the probit case we assume that <italic>v</italic> in (2) is normally distributed and, because the standard normal has a standard deviation of unity, we have <inline-formula id="inline-formula16-0081175012444861">
<mml:math display="inline" id="math21-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>v</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. In (4) and (5) we would replace the logistic function with the cumulative normal to yield the following (as the counterpart to [5]):</p>
<p><disp-formula id="disp-formula6-0081175012444861">
<mml:math display="block" id="math22-0081175012444861">
<mml:mrow>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>Φ</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mi>z</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0081175012444861" xlink:href="10.1177_0081175012444861-eq6.tif"/>
</disp-formula></p>
<p>The coefficients from the probit are thus identified relative to the scale parameters and will therefore be influenced by the residual variance in the same way as coefficients from the logit. Because of this equivalence between the logit and probit case, in what follows we develop our method only for the logit, but our results extend readily to the probit.</p>
</sec>
<sec id="section5-0081175012444861">
<title>3.2. Two Sources of Change: Confounding and Rescaling</title>
<p>From the logit models in (4) and (5) we see that, because we cannot estimate the variance of <italic>y</italic>* (i.e., we only observe <italic>y</italic> as in [3]), a restriction is necessary for identifying the model. This means that we cannot estimate the regression coefficients of <italic>x</italic> in the underlying models in (1) and (2), but only</p>
<p><disp-formula id="disp-formula7-0081175012444861">
<label>(6)</label>
<mml:math display="block" id="math23-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0081175012444861" xlink:href="10.1177_0081175012444861-eq7.tif"/>
</disp-formula></p>
<p>The estimated logit coefficients are equal to the underlying coefficients divided by the scale parameter. Therefore, controlling a variable of interest (<italic>x</italic>) for a confounding variable (<italic>z</italic>) that explains variation in the outcome variable (<italic>y</italic>*) will alter the coefficient of interest as a result of both confounding and rescaling. Confounding occurs whenever <italic>x</italic> and <italic>z</italic> are correlated and <italic>z</italic> has an independent effect on <italic>y</italic>* in the full model. Rescaling occurs because the model without the confounding variable, <italic>z</italic>, has a different residual standard deviation than the model that includes the confounding variable; indeed, because we always explain at least as much variation in the full model as in the reduced model, it holds that <inline-formula id="inline-formula17-0081175012444861">
<mml:math display="inline" id="math24-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. The logit coefficients of <italic>x</italic> are therefore measured on different scales, except for the situation where <italic>z</italic> has no effect on <italic>y</italic>*.</p>
<p>When employing the logit model, we are interested in the difference between the underlying coefficients, <inline-formula id="inline-formula18-0081175012444861">
<mml:math display="inline" id="math25-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula19-0081175012444861">
<mml:math display="inline" id="math26-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> in (1) and (2), because this difference is the result of confounding only (and not rescaling). However, because we observe only the coefficients in (6) we cannot distinguish between changes in <inline-formula id="inline-formula20-0081175012444861">
<mml:math display="inline" id="math27-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> compared to <inline-formula id="inline-formula21-0081175012444861">
<mml:math display="inline" id="math28-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> due to rescaling and to confounding:</p>
<p><disp-formula id="disp-formula8-0081175012444861">
<label>(7)</label>
<mml:math display="block" id="math29-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>≠</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0081175012444861" xlink:href="10.1177_0081175012444861-eq8.tif"/>
</disp-formula></p>
<p>Researchers using the naïve difference on the left-hand side of (7) as a proxy for the difference on the right-hand side will generally underestimate the role played by confounding, because <inline-formula id="inline-formula22-0081175012444861">
<mml:math display="inline" id="math30-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. In certain circumstances, rescaling and confounding will operate in opposite directions such that the difference on the left-hand side of (7) is zero, which may lead to the (incorrect) impression that <italic>z</italic> does not mediate or confound the effect of <italic>x</italic>. Researchers may also incorrectly report a suppression effect, which is not a result of confounding (i.e., <italic>x</italic> and <italic>z</italic> are uncorrelated), but only a result of rescaling (i.e., <italic>z</italic> has an independent effect on <italic>y</italic>). The inequality stated in (7) may be known by most sociologists specializing in quantitative methods but the sociological literature is replete with examples in which the naïve comparison is made and interpreted as though it reflected pure confounding.<sup><xref ref-type="fn" rid="fn5-0081175012444861">5</xref></sup></p>
</sec>
<sec id="section6-0081175012444861">
<title>3.3. A Solution</title>
<p>We now present a method that overcomes the cross-model coefficient comparability problem. Let <inline-formula id="inline-formula23-0081175012444861">
<mml:math display="inline" id="math31-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> be a set of <italic>x</italic>-residualized <italic>z</italic>-variables such that their correlation with <italic>x</italic> is zero: In other words, <inline-formula id="inline-formula24-0081175012444861">
<mml:math display="inline" id="math32-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is the residual from a regression of <italic>z</italic> on <italic>x</italic>.<sup><xref ref-type="fn" rid="fn6-0081175012444861">6</xref></sup>
<inline-formula id="inline-formula25-0081175012444861">
<mml:math display="inline" id="math33-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> will have mean zero, and we specify a new latent linear model:</p>
<p><disp-formula id="disp-formula9-0081175012444861">
<label>(8)</label>
<mml:math display="block" id="math34-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>:</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>+</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>sd</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mi>π</mml:mi>
<mml:mo stretchy="false">/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msqrt>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0081175012444861" xlink:href="10.1177_0081175012444861-eq9.tif"/>
</disp-formula></p>
<p>Compared to the full latent linear model in (2), which includes the control variables (<italic>z</italic>), the model in (8) includes instead the <italic>x</italic>-residualized counterparts, <inline-formula id="inline-formula26-0081175012444861">
<mml:math display="inline" id="math35-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>. Because models (1), (2), and (8) are linear, it follows, by the principles of population moments, that</p>
<p><disp-formula id="disp-formula10-0081175012444861">
<label>(9)</label>
<mml:math display="block" id="math36-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0081175012444861" xlink:href="10.1177_0081175012444861-eq10.tif"/>
</disp-formula></p>
<p>That is, taking a linear regression with a predictor, <italic>x</italic>, and adding a variable uncorrelated with <italic>x</italic> will leave the coefficient for <italic>x</italic> unchanged. We want to show that the residual standard deviation of <inline-formula id="inline-formula27-0081175012444861">
<mml:math display="inline" id="math37-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> equals the residual standard deviation of <inline-formula id="inline-formula28-0081175012444861">
<mml:math display="inline" id="math38-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> :</p>
<p><disp-formula id="disp-formula11-0081175012444861">
<label>(10)</label>
<mml:math display="block" id="math39-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0081175012444861" xlink:href="10.1177_0081175012444861-eq11.tif"/>
</disp-formula></p>
<p>This is equivalent to demonstrating that models <inline-formula id="inline-formula29-0081175012444861">
<mml:math display="inline" id="math40-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula30-0081175012444861">
<mml:math display="inline" id="math41-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> return the same fitted values.<sup><xref ref-type="fn" rid="fn7-0081175012444861">7</xref></sup> We show this for the general case in which <italic>z</italic>, rather than being a scalar, is a vector of control variables. We define <inline-formula id="inline-formula31-0081175012444861">
<mml:math display="inline" id="math42-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi mathvariant="bold">θ</mml:mi>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula> where <bold>θ</bold> is the vector of parameters from the regressions of the individual elements of <italic>z</italic> on <italic>x</italic>.</p>
<p>We need to demonstrate that</p>
<p><disp-formula id="disp-formula12-0081175012444861">
<mml:math display="block" id="math43-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0081175012444861" xlink:href="10.1177_0081175012444861-eq12.tif"/>
</disp-formula></p>
<p>Given (9) we can write the right-hand side of the above as</p>
<p><disp-formula id="disp-formula13-0081175012444861">
<mml:math display="block" id="math44-0081175012444861">
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>θ</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula13-0081175012444861" xlink:href="10.1177_0081175012444861-eq13.tif"/>
</disp-formula></p>
<p>This follows from the rules of path analysis for linear models (<xref ref-type="bibr" rid="bibr10-0081175012444861">Goldberger 1991</xref>): We have expanded the total effect of <italic>x</italic>, <inline-formula id="inline-formula32-0081175012444861">
<mml:math display="inline" id="math45-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, into its direct and indirect paths. Given the definition of a partial regression coefficient, we have <inline-formula id="inline-formula33-0081175012444861">
<mml:math display="inline" id="math46-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and so</p>
<p><disp-formula id="disp-formula14-0081175012444861">
<mml:math display="block" id="math47-0081175012444861">
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>θ</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mover accent="true">
<mml:mi>z</mml:mi>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mstyle>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>θ</mml:mi>
</mml:mstyle>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>−</mml:mo>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>θ</mml:mi>
</mml:mstyle>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi mathvariant="bold">β</mml:mi>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi mathvariant="bold">z</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula14-0081175012444861" xlink:href="10.1177_0081175012444861-eq14.tif"/>
</disp-formula></p>
<p>Given the equality in (10), we see that <inline-formula id="inline-formula34-0081175012444861">
<mml:math display="inline" id="math48-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> in (8) is a reparameterization of <inline-formula id="inline-formula35-0081175012444861">
<mml:math display="inline" id="math49-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> in (2)—that is, they reflect the same latent linear model.</p>
<p>We now rewrite the latent linear model in (8) into a corresponding logit model. We employ the same strategy defined by (3), (4), and (5) and obtain the following:<sup><xref ref-type="fn" rid="fn8-0081175012444861">8</xref></sup></p>
<p><disp-formula id="disp-formula15-0081175012444861">
<label>(11)</label>
<mml:math display="block" id="math50-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>:</mml:mo>
<mml:mtext>logit</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula15-0081175012444861" xlink:href="10.1177_0081175012444861-eq15.tif"/>
</disp-formula></p>
<p>Similar to the linear case, this model is a reparameterization of <inline-formula id="inline-formula36-0081175012444861">
<mml:math display="inline" id="math51-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>—that is, the two models have the same fit to the data. We can exploit the equalities in (9) and (10) as well as the specifications of the logit models to overcome the comparison issue encountered in (7). In other words, we can make an unbiased comparison of the coefficients of <italic>x</italic> without and with a confounding variable, <italic>z</italic>, in the model.</p>
<p>Our method is not only a solution to the coefficient comparability issue stated in (7) but also a solution to the problem mentioned earlier, that the distributions of the errors of the reduced and full model will differ, leading to cross-model differences in how closely the error term approximates the assumed logistic distribution. These differences may produce differences in coefficient estimates across models over and above those produced by confounding and rescaling. But our method is free of this problem because we do not draw comparisons between two differently specified models: instead we compare across reparameterizations of the same model, both of which have not only the same scale parameter but also exactly the same error distribution.<sup><xref ref-type="fn" rid="fn9-0081175012444861">9</xref></sup> We will see the advantages of this in our Monte Carlo analyses when we compare our method with alternatives.</p>
<p>We propose three measures of coefficient change that hold rescaling constant (i.e., that measure confounding net of rescaling). The first is a difference measure:</p>
<p><disp-formula id="disp-formula16-0081175012444861">
<label>(12a)</label>
<mml:math display="block" id="math52-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula16-0081175012444861" xlink:href="10.1177_0081175012444861-eq16.tif"/>
</disp-formula></p>
<p>where the first equality follows from (6) and the second from (9) and (10). This result tells us that the difference between the two logit coefficients of <italic>x</italic> in <inline-formula id="inline-formula37-0081175012444861">
<mml:math display="inline" id="math53-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula38-0081175012444861">
<mml:math display="inline" id="math54-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> stated in (12a) measures the impact of confounding given the scale of the full model. The difference in (12a) is a logit coefficient, and like the usual logit coefficient it is identified only up to scale. It measures the change in the coefficient of <italic>x</italic> attributable to confounding due to the inclusion of <italic>z</italic>, conditional on the full model holding true. Since we usually prefer basing our inference on the full model rather than the reduced model (see <xref ref-type="bibr" rid="bibr6-0081175012444861">Clogg et al. 1995</xref>), this is an important result.</p>
<p>The second measure is a ratio measure, which is a scale-free measure of confounding net of coefficient rescaling:</p>
<p><disp-formula id="disp-formula17-0081175012444861">
<label>(12b)</label>
<mml:math display="block" id="math55-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula17-0081175012444861" xlink:href="10.1177_0081175012444861-eq17.tif"/>
</disp-formula></p>
<p>In other words, the ratio between the two logit coefficients of <italic>x</italic> in <inline-formula id="inline-formula39-0081175012444861">
<mml:math display="inline" id="math56-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula40-0081175012444861">
<mml:math display="inline" id="math57-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> measures the impact of confounding net of the rescaling. In (12b) the scale parameter disappears, making it a scale-free measure of coefficient change. A third measure, which we believe has considerable practical relevance, is the percentage change in the coefficients attributable to confounding, net of rescaling:</p>
<p><disp-formula id="disp-formula18-0081175012444861">
<label>(12c)</label>
<mml:math display="block" id="math58-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mi>%</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mi>%</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mi>%</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mn>100</mml:mn>
<mml:mi>%</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula18-0081175012444861" xlink:href="10.1177_0081175012444861-eq18.tif"/>
</disp-formula></p>
<p>The choice of the scale-dependent difference measure stated in (12a) or the scale-free ratio and percentage change measures given in (12b) and (12c) should depend on the objective of the research because they have different interpretations. The difference measure in (12a) has the same properties as a normal logit coefficient and can be treated as such: Researchers interested in the coefficients of the logit model might therefore prefer this measure. The ratio and percentage change measures have a different interpretation, because they are concerned with the regression coefficients in the latent model. The ratio in (12b) and the percentage change in (12c) measure change in the underlying partial effects on the latent propensity rather than in the logit coefficients. Thus, if researchers are interested in the underlying partial effects they should probably prefer to use these scale-free measures.</p>
<p>If, in addition, we want to know the magnitude of rescaling net of the impact of confounding, we need to know the relation <inline-formula id="inline-formula41-0081175012444861">
<mml:math display="inline" id="math59-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, which is equal to the ratio between the error standard deviations in the reduced and full model. Given (9) and (10), we find that</p>
<p><disp-formula id="disp-formula19-0081175012444861">
<label>(13)</label>
<mml:math display="block" id="math60-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula19-0081175012444861" xlink:href="10.1177_0081175012444861-eq19.tif"/>
</disp-formula></p>
<p>In other words, the ratio between the two observed coefficients of <italic>x</italic> in <inline-formula id="inline-formula42-0081175012444861">
<mml:math display="inline" id="math61-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula43-0081175012444861">
<mml:math display="inline" id="math62-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>H</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>Logit</mml:mtext>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> measures the impact of rescaling, net of confounding. Because <inline-formula id="inline-formula44-0081175012444861">
<mml:math display="inline" id="math63-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>≥</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, we know that <inline-formula id="inline-formula45-0081175012444861">
<mml:math display="inline" id="math64-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>≥</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>. From (12b) and (13) we have the ratio decomposition of the observed change in the coefficient for <italic>x</italic> across nested models:</p>
<p><disp-formula id="disp-formula20-0081175012444861">
<label>(14a)</label>
<mml:math display="block" id="math65-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula20-0081175012444861" xlink:href="10.1177_0081175012444861-eq20.tif"/>
</disp-formula></p>
<p>where the first term on the right-hand side captures confounding and the second captures rescaling itself. Similarly we derive the additive decomposition:</p>
<p><disp-formula id="disp-formula21-0081175012444861">
<label>(14b)</label>
<mml:math display="block" id="math66-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula21-0081175012444861" xlink:href="10.1177_0081175012444861-eq21.tif"/>
</disp-formula></p>
<p>where the first term on the right-hand side equals rescaling and the second captures confounding. Notice that the component induced by rescaling is equal to</p>
<p><disp-formula id="disp-formula22-0081175012444861">
<label>(15)</label>
<mml:math display="block" id="math67-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula22-0081175012444861" xlink:href="10.1177_0081175012444861-eq22.tif"/>
</disp-formula></p>
<p>and it thus captures the effect, on the logit coefficients, of the change in the residual standard deviation, holding constant the underlying coefficient.</p>
</sec>
<sec id="section7-0081175012444861">
<title>3.4. Significance Tests</title>
<p>The null hypothesis we want to test is that the effect of confounding, net of rescaling, is zero. To derive a formal statistical test of confounding, we use the delta method, drawing on <xref ref-type="bibr" rid="bibr23-0081175012444861">Sobel (1982</xref>, <xref ref-type="bibr" rid="bibr24-0081175012444861">1987</xref>). The null is</p>
<p><disp-formula id="disp-formula23-0081175012444861">
<label>(16)</label>
<mml:math display="block" id="math68-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula23-0081175012444861" xlink:href="10.1177_0081175012444861-eq23.tif"/>
</disp-formula></p>
<p>and so we need to find the standard error of the difference between the coefficients in (16). But, as we noted earlier, since <inline-formula id="inline-formula46-0081175012444861">
<mml:math display="inline" id="math69-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> (where <inline-formula id="inline-formula47-0081175012444861">
<mml:math display="inline" id="math70-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is the coefficient from the linear regression of <italic>z</italic> on <italic>x</italic>), testing <inline-formula id="inline-formula48-0081175012444861">
<mml:math display="inline" id="math71-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> amounts to testing <inline-formula id="inline-formula49-0081175012444861">
<mml:math display="inline" id="math72-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, because</p>
<p><disp-formula id="disp-formula24-0081175012444861">
<label>(17)</label>
<mml:math display="block" id="math73-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula24-0081175012444861" xlink:href="10.1177_0081175012444861-eq24.tif"/>
</disp-formula></p>
<p>Since the hypothesis in (16) is equal to a hypothesis that the indirect effect of <italic>x</italic> on <italic>y</italic> is zero, either <inline-formula id="inline-formula50-0081175012444861">
<mml:math display="inline" id="math74-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> or <inline-formula id="inline-formula51-0081175012444861">
<mml:math display="inline" id="math75-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> is a sufficient condition for (16) to hold but neither is necessary.</p>
<p>We deal with the general case in which, instead of just one confounder, we have <italic>J</italic> confounders, <inline-formula id="inline-formula52-0081175012444861">
<mml:math display="inline" id="math76-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. This means that we have <italic>J</italic> regressions, one for each element of <bold>z</bold> on <italic>x</italic>, with coefficient estimates in the vector <bold>θ</bold>. We also have <italic>J</italic> coefficients for the coefficient estimates of each of the <italic>z</italic> variables on <italic>y</italic> in the vector <bold>b</bold>. For notational convenience we define <inline-formula id="inline-formula53-0081175012444861">
<mml:math display="inline" id="math77-0081175012444861">
<mml:mrow>
<mml:mi>f</mml:mi>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi mathvariant="bold">b</mml:mi>
<mml:mo mathvariant="bold">′</mml:mo>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, so <italic>f</italic> is equal to the difference between the uncontrolled and controlled coefficient of <italic>x</italic> measured on the scale of the full model. We want to obtain the standard error of this difference. <inline-formula id="inline-formula54-0081175012444861">
<mml:math display="inline" id="math78-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is defined as the variance-covariance matrix of the estimates of the coefficients <inline-formula id="inline-formula55-0081175012444861">
<mml:math display="inline" id="math79-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yz</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula56-0081175012444861">
<mml:math display="inline" id="math80-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>zx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. This has the form <inline-formula id="inline-formula57-0081175012444861">
<mml:math display="inline" id="math81-0081175012444861">
<mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>Σ</mml:mi>
<mml:mstyle mathvariant="bold">
<mml:mi>b</mml:mi>
</mml:mstyle>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mn>0</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mn>0</mml:mn>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>Σ</mml:mi>
<mml:mstyle mathvariant="bold">
<mml:mi>θ</mml:mi>
</mml:mstyle>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> with <inline-formula id="inline-formula58-0081175012444861">
<mml:math display="inline" id="math82-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> being the variance-covariance matrix of the estimates of <italic>b</italic> and <inline-formula id="inline-formula59-0081175012444861">
<mml:math display="inline" id="math83-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> the variance-covariance matrix of the estimates of <bold>θ</bold>. The off-diagonal blocks of <inline-formula id="inline-formula60-0081175012444861">
<mml:math display="inline" id="math84-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> contain zeros because the estimates of <bold>b</bold> and <bold>θ</bold> are asymptotically independent (<xref ref-type="bibr" rid="bibr23-0081175012444861">Sobel 1982</xref>:294–95). The covariances among the <bold>b</bold> coefficients are easily obtained since they come from the same regression (<xref ref-type="disp-formula" rid="disp-formula5-0081175012444861">equation 5</xref>, but now with more than one <italic>z</italic> variable), but the <bold>θ</bold> coefficients are estimated from <italic>J</italic> separate regressions. To compute the covariances among their estimates, we use the following formula from <xref ref-type="bibr" rid="bibr25-0081175012444861">Turner and Rockel (1988)</xref>. Let <italic>z<sub>k</sub></italic> and <italic>z<sub>l</sub></italic> be two confounders, with associated regression coefficients <inline-formula id="inline-formula61-0081175012444861">
<mml:math display="inline" id="math85-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula62-0081175012444861">
<mml:math display="inline" id="math86-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>l</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. Then <inline-formula id="inline-formula63-0081175012444861">
<mml:math display="inline" id="math87-0081175012444861">
<mml:mrow>
<mml:mrow>
<mml:mtext>cov</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>l</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>ik</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>il</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msup>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>i</italic> indexes observations. We insert these quantities into the off-diagonal positions in <inline-formula id="inline-formula64-0081175012444861">
<mml:math display="inline" id="math88-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> while the diagonal elements of this submatrix are simply the variances of the estimates of the elements of <bold>θ</bold>.<sup><xref ref-type="fn" rid="fn10-0081175012444861">10</xref></sup></p>
<p>Finally, we define <bold>a</bold> to be the column vector of partial derivatives of the indirect effect with respect to the parameters, <bold>b</bold> and <bold>θ</bold>. That is, <bold>a</bold> is the 2<italic>J</italic>×1 column vector whose entries are</p>
<p><disp-formula id="disp-formula25-0081175012444861">
<label>(17)</label>
<mml:math display="block" id="math89-0081175012444861">
<mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>J</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula25-0081175012444861" xlink:href="10.1177_0081175012444861-eq25.tif"/>
</disp-formula></p>
<p>The asymptotic standard error of the indirect effect is given by</p>
<p><disp-formula id="disp-formula26-0081175012444861">
<label>(18)</label>
<mml:math display="block" id="math90-0081175012444861">
<mml:mrow>
<mml:mi>se</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mi mathvariant="bold">a</mml:mi>
<mml:mo mathvariant="bold">′</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi mathvariant="bold">a</mml:mi>
</mml:mrow>
</mml:msqrt>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula26-0081175012444861" xlink:href="10.1177_0081175012444861-eq26.tif"/>
</disp-formula></p>
<p>In the case where there is a single <italic>z</italic>, the asymptotic standard error in (18) is the square root of the matrix expression</p>
<p><disp-formula id="disp-formula27-0081175012444861">
<label>(19)</label>
<mml:math display="block" id="math91-0081175012444861">
<mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>b</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>b</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mn>0</mml:mn>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mn>0</mml:mn>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>θ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>b</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi>b</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>θ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mi>θ</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>b</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula27-0081175012444861" xlink:href="10.1177_0081175012444861-eq27.tif"/>
</disp-formula></p>
<p>We use (18) to test the hypothesis of whether change in the logit coefficient attributable to confounding, net of rescaling, is statistically significant, via the test statistic <italic>Z</italic><sub><italic>C</italic></sub> (where the subscript <italic>C</italic> denotes confounding), which in large samples will be normally distributed under the null:</p>
<p><disp-formula id="disp-formula28-0081175012444861">
<label>(20)</label>
<mml:math display="block" id="math92-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi mathvariant="bold">z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mi mathvariant="bold">a</mml:mi>
<mml:mo mathvariant="bold">′</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi mathvariant="bold">a</mml:mi>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula28-0081175012444861" xlink:href="10.1177_0081175012444861-eq28.tif"/>
</disp-formula></p>
<p>In other words, the statistic enables a direct test of the change in the logit coefficients that is attributable to confounding, net of rescaling.</p>
</sec>
<sec id="section8-0081175012444861">
<title>3.5. A Monte Carlo Study</title>
<p>In <xref ref-type="table" rid="table1-0081175012444861">Table 1</xref> we report the results of a Monte Carlo study to assess the performance of the statistical test across a range of different scenarios, reporting the percentage of times the null hypothesis is rejected. The model used to generate the data is</p>
<table-wrap id="table1-0081175012444861" position="float">
<label>Table 1.</label>
<caption>
<p>Monte Carlo Study of Power of Proposed Test: Percentage of 1,000 Replications in Which the Test Rejects H<sub>0</sub></p>
</caption>
<graphic alternate-form-of="table1-0081175012444861" xlink:href="10.1177_0081175012444861-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="9">(a) <italic>x</italic> Normal, <italic>z</italic> Normal<hr/></th>
</tr>
<tr>
<th align="left">Scenario</th>
<th align="center">θ</th>
<th align="center">γ</th>
<th align="center">Null True?</th>
<th align="center">Percentage of Confounding<sup><xref ref-type="table-fn" rid="table-fn1-0081175012444861">a</xref></sup></th>
<th align="center" colspan="4">% Times <italic>H</italic><sub>0</sub> Rejected<hr/></th>
</tr>
<tr>
<th/>
<th/>
<th/>
<th/>
<th/>
<th align="center"><italic>N</italic> = 200</th>
<th align="center"><italic>N</italic>=500</th>
<th align="center"><italic>N</italic>=1,000</th>
<th align="center"><italic>N</italic>=5,000</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>0.0</td>
<td>0.0</td>
<td>Yes</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>B</td>
<td>1.0</td>
<td>0.0</td>
<td>Yes</td>
<td>0</td>
<td>3</td>
<td>5</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>C</td>
<td>0.0</td>
<td>1.0</td>
<td>Yes</td>
<td>0</td>
<td>3</td>
<td>5</td>
<td>5</td>
<td>5</td>
</tr>
<tr>
<td>D</td>
<td>0.2</td>
<td>0.2</td>
<td>No</td>
<td>4</td>
<td>6</td>
<td>44</td>
<td>85</td>
<td>100</td>
</tr>
<tr>
<td>E</td>
<td>0.2</td>
<td>0.6</td>
<td>No</td>
<td>11</td>
<td>24</td>
<td>59</td>
<td>89</td>
<td>100</td>
</tr>
<tr>
<td>F</td>
<td>0.6</td>
<td>0.2</td>
<td>No</td>
<td>11</td>
<td>55</td>
<td>97</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>G</td>
<td>0.5</td>
<td>0.5</td>
<td>No</td>
<td>20</td>
<td>91</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>H</td>
<td>0.7</td>
<td>0.7</td>
<td>No</td>
<td>33</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>I</td>
<td>1.0</td>
<td>1.0</td>
<td>No</td>
<td>50</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>J</td>
<td>1.5</td>
<td>3.0</td>
<td>No</td>
<td>82</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>K</td>
<td>3.0</td>
<td>1.5</td>
<td>No</td>
<td>82</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<th align="left" colspan="9">(b) <italic>x</italic> Lognormal, <italic>z</italic> Normal-Lognormal Mixture</th>
</tr>
<tr>
<th align="left">Scenario</th>
<th align="center">θ</th>
<th align="center">γ</th>
<th align="center">Null True?</th>
<th align="center">Percentage of Confounding<sup><xref ref-type="table-fn" rid="table-fn1-0081175012444861">a</xref></sup></th>
<th align="center" colspan="4">% Times <italic>H</italic><sub>0</sub> Rejected<hr/></th>
</tr>
<tr>
<th/>
<th/>
<th/>
<th/>
<th/>
<th align="center"><italic>N</italic> = 200</th>
<th align="center"><italic>N</italic>=500</th>
<th align="center"><italic>N</italic>=1,000</th>
<th align="center"><italic>N</italic>=5,000</th>
</tr>
<tr>
<td>A</td>
<td>0.0</td>
<td>0.0</td>
<td>Yes</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>B</td>
<td>1.0</td>
<td>0.0</td>
<td>Yes</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>C</td>
<td>0.0</td>
<td>1.0</td>
<td>Yes</td>
<td>0</td>
<td>3</td>
<td>5</td>
<td>5</td>
<td>5</td>
</tr>
<tr>
<td>D</td>
<td>0.2</td>
<td>0.2</td>
<td>No</td>
<td>4</td>
<td>1</td>
<td>8</td>
<td>19</td>
<td>83</td>
</tr>
<tr>
<td>E</td>
<td>0.2</td>
<td>0.6</td>
<td>No</td>
<td>11</td>
<td>5</td>
<td>14</td>
<td>24</td>
<td>84</td>
</tr>
<tr>
<td>F</td>
<td>0.6</td>
<td>0.2</td>
<td>No</td>
<td>11</td>
<td>7</td>
<td>59</td>
<td>95</td>
<td>100</td>
</tr>
<tr>
<td>G</td>
<td>0.5</td>
<td>0.5</td>
<td>No</td>
<td>20</td>
<td>22</td>
<td>61</td>
<td>89</td>
<td>100</td>
</tr>
<tr>
<td>H</td>
<td>0.7</td>
<td>0.7</td>
<td>No</td>
<td>33</td>
<td>45</td>
<td>88</td>
<td>99</td>
<td>100</td>
</tr>
<tr>
<td>I</td>
<td>1.0</td>
<td>1.0</td>
<td>No</td>
<td>50</td>
<td>75</td>
<td>99</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>J</td>
<td>1.5</td>
<td>3.0</td>
<td>No</td>
<td>82</td>
<td>97</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>K</td>
<td>3.0</td>
<td>1.5</td>
<td>No</td>
<td>82</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0081175012444861">
<p><italic>Note</italic>. Two-sided test with 5% significance level,β throughout.
</p>
</fn>
<fn id="table-fn2-0081175012444861">
<label>a</label>
<p>Size of indirect effect relative to the total effect.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p><disp-formula id="disp-formula29-0081175012444861">
<mml:math display="block" id="math93-0081175012444861">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>z</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>θ</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:mi>v</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mtext>if</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>median</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mn>0</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mtext>otherwise</mml:mtext>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula29-0081175012444861" xlink:href="10.1177_0081175012444861-eq29.tif"/>
</disp-formula>
</p>
<p>Here, <italic>u</italic> has a standard logistic distribution, <italic>v</italic> has a standard normal distribution, and <italic>x</italic> is drawn from a standard normal distribution (panel [a] of <xref ref-type="table" rid="table1-0081175012444861">Table 1</xref>) or from a log-normal distribution (panel [b]).</p>
<p>We consider three situations in which the null is true: when both θ and γ are zero and when one is zero and the other nonzero. We also consider eight additional scenarios in which different combinations of these parameters yield situations with increasing confounding (measured as the ratio of the indirect to the total effect). For a variety of sample sizes we report how often, in 1,000 replications, the null hypothesis is rejected, using a two-sided test and 0.05 significance level.</p>
<p><xref ref-type="table" rid="table1-0081175012444861">Table 1</xref> shows that, as we would expect, increasing the sample size leads to a greater frequency of rejections of the null hypothesis, but, when the null is true, our method’s rejection rate is never more than 5%. Except in small samples and with a low degree of confounding, for normal <italic>x</italic> and <italic>z</italic> the test performs well in rejecting a false null. For log-normal <italic>x</italic> and <italic>z</italic> drawn from a mixture of a normal and a log-normal distribution, the test’s power is lower for smaller sample sizes and less confounding. For smaller sample sizes and less confounding the test appears more sensitive to the size of θ (the effect of <italic>x</italic> on <italic>z</italic>) than to γ (the effect of <italic>z</italic> on <italic>y</italic>). Whether the test is more sensitive to one or the other will depend on the relative sizes of the error variances of the linear model for <italic>z</italic> and of the latent linear model for <italic>y</italic>*.</p>
</sec>
</sec>
<sec id="section9-0081175012444861">
<title>4. Comparing Our Method with Other Proposed Solutions</title>
<p>In this section we compare our method with three other solutions to the rescaling problem that have been proposed (e.g., see <xref ref-type="bibr" rid="bibr20-0081175012444861">Mood 2010</xref>:80): These are (1) <italic>Y</italic>-standardization, (2) average partial effects derived from logit or probit models, and (3) the linear probability model. Our comparisons are based on the performance of the methods in Monte Carlo simulations. Before we turn to the results of the simulations, we first briefly describe each of the three alternative methods.</p>
<p><xref ref-type="bibr" rid="bibr28-0081175012444861">Winship and Mare (1984)</xref> suggested <italic>y</italic>-standardization as a solution to the problem of making within-sample comparisons of logit coefficients of <italic>x</italic> across models without and with control variables, <italic>z</italic>. The idea is to estimate the standard deviation of <italic>y</italic>* using the following formula given by <xref ref-type="bibr" rid="bibr19-0081175012444861">McKelvey and Zavoina (1975)</xref> for different nested models:</p>
<p><disp-formula id="disp-formula30-0081175012444861">
<label>(21)</label>
<mml:math display="block" id="math94-0081175012444861">
<mml:mrow>
<mml:mi>SD</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>′</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msqrt>
<mml:mo>=</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>′</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula30-0081175012444861" xlink:href="10.1177_0081175012444861-eq30.tif"/>
</disp-formula></p>
<p>Then, for each model, the coefficient of <italic>x</italic> is divided by the estimated latent standard deviation, <inline-formula id="inline-formula65-0081175012444861">
<mml:math display="inline" id="math95-0081175012444861">
<mml:mrow>
<mml:mi>SD</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. The calculated coefficients are thus <italic>y</italic>-standardized because they compensate for the rescaling of the “nonstandardized” coefficients. The <italic>y</italic>-standardized logit coefficient of <italic>x</italic> is <inline-formula id="inline-formula66-0081175012444861">
<mml:math display="inline" id="math96-0081175012444861">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>sdY</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">/</mml:mo>
<mml:mi>SD</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>, and comparing <italic>y</italic>-standardized coefficients from different nested models is thus a potential method for making cross-model coefficient comparisons unaffected by rescaling.</p>
<p>In logit models, the marginal effect (ME) of <italic>x</italic> is the derivative of the predicted probability with respect to <italic>x</italic>, given by (when <italic>x</italic> is continuous<sup><xref ref-type="fn" rid="fn11-0081175012444861">11</xref></sup> and differentiable):</p>
<p><disp-formula id="disp-formula31-0081175012444861">
<label>(22)</label>
<mml:math display="block" id="math97-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>dx</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula31-0081175012444861" xlink:href="10.1177_0081175012444861-eq31.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula67-0081175012444861">
<mml:math display="inline" id="math98-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> is the predicted probability given <italic>x</italic> and <inline-formula id="inline-formula68-0081175012444861">
<mml:math display="inline" id="math99-0081175012444861">
<mml:mrow>
<mml:mi>b</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula> is the logit coefficient of <italic>x</italic>. The ME of <italic>x</italic> is evaluated at some fixed values of the other predictor variables in the model, typically their means. But this implies that whenever we include control variables in a model we change the set of other variables at whose mean the ME is evaluated, which introduces indeterminacy into cross-model comparisons. We therefore ignore MEs in the following and focus instead on the more general average partial effect (APE).</p>
<p>The APE of <italic>x</italic> is the derivative of the predicted probability with respect to <italic>x</italic> evaluated over the whole population. Let <italic>x</italic> be continuous and differentiable; then, using <italic>i</italic> (=1, . . .,<italic>N</italic>) to denote observations, we write the APE of <italic>x</italic> as</p>
<p><disp-formula id="disp-formula32-0081175012444861">
<label>(23)</label>
<mml:math display="block" id="math100-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mi>β</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula32-0081175012444861" xlink:href="10.1177_0081175012444861-eq32.tif"/>
</disp-formula></p>
<p>Thus the APE is a weighted average of the marginal effects over the sample. If the sample is drawn randomly from the population, the APE estimates the average marginal effect of <italic>x</italic> in the population (<xref ref-type="bibr" rid="bibr29-0081175012444861">Wooldridge 2002</xref>).<sup><xref ref-type="fn" rid="fn12-0081175012444861">12</xref></sup> APEs have been suggested for cross-model comparisons because simulation studies show that they are unaffected by rescaling whenever <italic>x</italic> and <italic>z</italic> are uncorrelated (<xref ref-type="bibr" rid="bibr8-0081175012444861">Cramer 2007</xref>).</p>
<p>Finally, the linear probability model (LPM) is simply an OLS regression of the dichotomous <italic>y</italic> on the predictor variables. In this model, the coefficients for <italic>x</italic> are unbiased estimates of the expected change in Pr(y = 1) for a unit-change in <italic>x</italic> (either conditionally, if <italic>z</italic> is included, or unconditionally). Because of its simple interpretation, economists often prefer the LPM to the nonlinear counterparts such as the probit or logit. However, we know of no studies investigating the use of linear probability models for assessing confounding: Our Monte Carlo study will be the first to show its performance.</p>
<p>To compare these three methods against the method proposed in this paper, we conducted Monte Carlo analyses based on the following model:</p>
<p><disp-formula id="disp-formula33-0081175012444861">
<mml:math display="block" id="math101-0081175012444861">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>β</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula33-0081175012444861" xlink:href="10.1177_0081175012444861-eq33.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula34-0081175012444861">
<mml:math display="block" id="math102-0081175012444861">
<mml:mrow>
<mml:mi>ρ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>r</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>sd</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>sd</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula34-0081175012444861" xlink:href="10.1177_0081175012444861-eq34.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula35-0081175012444861">
<mml:math display="block" id="math103-0081175012444861">
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mtext>if</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>τ</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mtext>otherwise</mml:mtext>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula35-0081175012444861" xlink:href="10.1177_0081175012444861-eq35.tif"/>
</disp-formula></p>
<p>In <xref ref-type="table" rid="table5-0081175012444861">Table A1</xref> in the <xref ref-type="app" rid="app1-0081175012444861">Appendix</xref> we report the results from 120 simulations, each using 5,000 cases and each replicated 250 times.<sup><xref ref-type="fn" rid="fn13-0081175012444861">13</xref></sup> The five panels in this table each report simulations with six values of <italic>r</italic>: 0, 0.1, 0.3, 0.5, 0.7, and 0.9. For each value of <italic>r</italic>, we varied the cut-point, τ, letting it take the values 0.5, 0.7, 0.9, and 0.95 (the last corresponding to a very skewed <italic>y</italic>). The correlation and the cut-point are listed in columns 1 and 2 of each panel in the table. Column 3 shows the true ratio of the direct (controlling for <italic>z</italic>) effect of <italic>x</italic> on <italic>y</italic>* to the total effect of <italic>x</italic> on <italic>y</italic>* (not controlling for <italic>z</italic>). This ratio is what we ideally want to recover with our method, APEs, <italic>y</italic>-standardization, or the LPM. Column 4 reports the average (over 250 replications) of the naïve estimate of this ratio based on the coefficients from two logit or probit models. Column 5 shows the average using the ratio of OLS regression coefficients derived from models using the latent outcome variable, <italic>y</italic>*. The figures in column 5 are necessarily quite close to those of column 3 but, obviously, in a real application, we could not estimate either of them. Column 6 shows the mean estimate derived from our method and columns 7, 8, and 9 report, respectively, the mean estimates of the ratio based on the use of APEs, <italic>y</italic>-standardization, and the linear probability model.</p>
<p>In <xref ref-type="table" rid="table5-0081175012444861">Table A1(a)</xref> we set <inline-formula id="inline-formula69-0081175012444861">
<mml:math display="inline" id="math104-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> ; <italic>x</italic> and <italic>z</italic> are draws from a normal distribution and <italic>e</italic> is a draw from a standard normal distribution. The reported results for the naïve approach (column 4), our method (column 6), APEs (column 7), and <italic>y</italic>-standardization (column 8) are based on the probit model. In panels (b) and (c) we set <inline-formula id="inline-formula70-0081175012444861">
<mml:math display="inline" id="math105-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, and in both cases <italic>e</italic> is a draw from a standard logistic distribution and the results in columns 4 and 6 through 8 derive from logit models. Panels (b) and (c) differ, however, in the distributions of <italic>x</italic> and <italic>z</italic>. In (b), <italic>x</italic> and <italic>z</italic> are both normal while in (c) they are both lognormal. Panels (d) and (e) replicate panels (b) and (c) except that we set <inline-formula id="inline-formula71-0081175012444861">
<mml:math display="inline" id="math106-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, which means that confounding is weaker in (d) and (e) than in (b) and (c). In all our simulations we fix the two predictor variables to have a standard deviation of one.</p>
<p>These five sets of Monte Carlo results allow us to assess the performance of our approach both absolutely and relative to that of the other methods under different scenarios. Panel (a) addresses pure rescaling because the errors of both the full and reduced model have a normal distribution. The reason for this is that we fix <italic>e</italic> to be normal, and, because the sum of normal variables is normal, excluding or including <italic>z</italic> in the model will not change the shape of the error distribution across models.<sup><xref ref-type="fn" rid="fn14-0081175012444861">14</xref></sup> Panels (b) through (e) deal with cases in which the error distributions of the full and reduced models are different although the full model always has the true (logistic in this case) distribution. Panels (b) and (c) differ from (d) and (e) in the extent of confounding, while (b) and (d) differ from (c) and (e) in the degree to which the error distribution of the reduced model departs from the logistic. In (b) and (d) this error is a mixture of logistic and normal while in (c) and (e) it is a mixture of logistic and lognormal. Taken together the simulations allow us to evaluate the performance of these approaches under pure rescaling and in the presence of rescaling together with differences between models in their error distributions.</p>
<p>We can summarize the results with the aid of <xref ref-type="table" rid="table2-0081175012444861">Table 2</xref>, which shows the mean absolute difference, across all the simulations in each panel, between the population ratio and the estimated ratio from the method in question. The most obvious result was the one we expected: The naïve estimator performs very poorly, always overestimating the ratio (and thus underestimating the extent of true confounding) and performing more poorly when confounding is greater (panels [b] and [c] compared with [d] and [e]). As far as our method is concerned, it always returns estimates very close to the true ratio. It is unaffected by rescaling (panel [a]) and it is also unaffected by differences in the error distributions of the reduced and full models (panels [b] through [e]). The reason for this is that our method compares the full model with a reparameterization of the full model, thereby holding the error distribution constant across the full and reduced models. Neither <italic>y</italic>-standardization nor the APEs nor the LPM are sensitive to rescaling, but as the difference between full and reduced error distributions becomes greater, they perform less well. In particular, in simulations (c) and (e) where the error of the reduced model is the sum of a logistic distribution and a mixture of log-normals (which is the distribution of <italic>z</italic> in this case), all except our method perform poorly, and APEs and <italic>y</italic>-standardization perform more poorly when the effect of the confounding variable is larger.<sup><xref ref-type="fn" rid="fn15-0081175012444861">15</xref></sup></p>
<table-wrap id="table2-0081175012444861" position="float">
<label>Table 2.</label>
<caption>
<p>Mean Absolute Error (Multiplied by 1,000) in Monte Carlo Simulations in <xref ref-type="app" rid="app1-0081175012444861">Appendix</xref> <xref ref-type="table" rid="table5-0081175012444861">Table A1</xref></p>
</caption>
<graphic alternate-form-of="table2-0081175012444861" xlink:href="10.1177_0081175012444861-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Naïve</th>
<th align="center">Our Method</th>
<th align="center">APE</th>
<th align="center"><italic>y</italic>-stand</th>
<th align="center">LPM</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">Panel</td>
</tr>
<tr>
<td>A</td>
<td>213.1968</td>
<td>1.2612</td>
<td>1.3717</td>
<td>1.3264</td>
<td>1.3673</td>
</tr>
<tr>
<td>B</td>
<td>72.3232</td>
<td>0.9511</td>
<td>1.0126</td>
<td>20.4050</td>
<td>0.9534</td>
</tr>
<tr>
<td>C</td>
<td>75.3598</td>
<td>1.2180</td>
<td>18.5213</td>
<td>19.5937</td>
<td>49.8109</td>
</tr>
<tr>
<td>D</td>
<td>24.4546</td>
<td>1.0647</td>
<td>1.1610</td>
<td>5.6495</td>
<td>0.9314</td>
</tr>
<tr>
<td>E</td>
<td>28.4790</td>
<td>1.2792</td>
<td>5.5756</td>
<td>5.4452</td>
<td>51.8660</td>
</tr>
<tr>
<td>Mean</td>
<td>82.7627</td>
<td>1.1548</td>
<td>5.5284</td>
<td>10.4840</td>
<td>20.9858</td>
</tr>
</tbody>
</table>
</table-wrap>
<sec id="section10-0081175012444861">
<title>4.1. Applying Our Method to APEs</title>
<p>Using APEs for assessing confounding may return noticeably different results to those produced by our method. However, by applying our method to APEs we obtain a measure that may, for many purposes, be more useful than one based on logit coefficients.<sup><xref ref-type="fn" rid="fn16-0081175012444861">16</xref></sup> Effects measured on the probability scale are intuitive, both for researchers and policy makers. We can apply the method developed in this paper to APEs, thereby avoiding the problems shown in the Monte Carlo study and yielding measures based on the probability scale.</p>
<p>Using (23) to calculate the APE for two logit models involving <italic>z</italic> and <inline-formula id="inline-formula72-0081175012444861">
<mml:math display="inline" id="math107-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>, respectively, and taking a ratio similar to (12b), we obtain the following</p>
<p><disp-formula id="disp-formula36-0081175012444861">
<label>(24)</label>
<mml:math display="block" id="math108-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula36-0081175012444861" xlink:href="10.1177_0081175012444861-eq36.tif"/>
</disp-formula></p>
<p>which follows because of (9) and (10) and because <inline-formula id="inline-formula73-0081175012444861">
<mml:math display="inline" id="math109-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. While (24) casts the change in APEs in ratios as in (12b), we can easily derive the change in differences between APEs similar to (12a):</p>
<p><disp-formula id="disp-formula37-0081175012444861">
<label>(25)</label>
<mml:math display="block" id="math110-0081175012444861">
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>·</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula37-0081175012444861" xlink:href="10.1177_0081175012444861-eq37.tif"/>
</disp-formula></p>
<p>Note that we cannot be certain that the difference in (25) will equal the difference we would normally calculate—namely, <inline-formula id="inline-formula74-0081175012444861">
<mml:math display="inline" id="math111-0081175012444861">
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>—because of the sensitivity of APEs to changes in the error distributions of the models. Applying our method to APEs, however, removes this uncertainty while also providing effect measures that might be considered more interpretable than logit coefficients.</p>
</sec>
</sec>
<sec id="section11-0081175012444861">
<title>5. Example: Parental Income and High School Graduation</title>
<p>To illustrate the method of decomposing the change in logit coefficients into confounding and rescaling, we turn to an example using data from the National Education Longitudinal Study of 1988 (NELS88).<sup><xref ref-type="fn" rid="fn17-0081175012444861">17</xref></sup> We examine how the effect of parental income on high school graduation changes when we control for student academic ability and parental educational attainment. We use NELS88, and our final sample consists of 8,173 students. The observed outcome variable is a dichotomy indicating whether the student completed high school (= 1) or not (= 0). This variable has a skewed distribution because 95.9% of the sample completed high school. The predictor variable of interest is a measure of yearly family income. Although the variable is measured on an ordered scale with 15 categories, for simplicity we use it here as a continuous variable. We include three control variables: These are student academic ability and the educational attainment of the mother and of the father.<sup><xref ref-type="fn" rid="fn18-0081175012444861">18</xref></sup> We derive the ability measure from test scores in four different subjects using a principal component analysis.<sup><xref ref-type="fn" rid="fn19-0081175012444861">19</xref></sup> We standardize the family income variable and the three control variables to have mean zero and variance of unity. We estimate five logistic models and report the results in <xref ref-type="table" rid="table3-0081175012444861">Table 3</xref>.</p>
<table-wrap id="table3-0081175012444861" position="float">
<label>Table 3.</label>
<caption>
<p>Controlling the Effect of Family Income on High School Graduation: Logit Coefficients</p>
</caption>
<graphic alternate-form-of="table3-0081175012444861" xlink:href="10.1177_0081175012444861-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">M1<hr/></th>
<th align="center">M2<hr/></th>
<th align="center">M3<hr/></th>
<th align="center">M4<hr/></th>
<th align="center">M5<hr/></th>
</tr>
<tr>
<th align="left">Controls</th>
<th align="center">None</th>
<th align="center"><italic>z</italic></th>
<th align="center"><inline-formula id="inline-formula75-0081175012444861">
<mml:math display="inline" id="math112-0081175012444861">
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:math>
</inline-formula></th>
<th align="center"><italic>z</italic></th>
<th align="center"><inline-formula id="inline-formula76-0081175012444861">
<mml:math display="inline" id="math113-0081175012444861">
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:math>
</inline-formula></th>
</tr>
</thead>
<tbody>
<tr>
<td>Family income</td>
<td>0.800(0.047)</td>
<td>0.460(0.052)</td>
<td>1.094(0.058)</td>
<td>0.311(0.057)</td>
<td>1.349(0.073)</td>
</tr>
<tr>
<td>Academic ability</td>
<td/>
<td>1.659(0.101)</td>
<td>1.659(0.101)</td>
<td>1.508(0.104)</td>
<td>1.508(0.104)</td>
</tr>
<tr>
<td>Father’s education</td>
<td/>
<td/>
<td/>
<td>0.642(0.125)</td>
<td>0.642(0.125)</td>
</tr>
<tr>
<td>Mother’s education</td>
<td/>
<td/>
<td/>
<td>0.340(0.106)</td>
<td>0.340(0.106)</td>
</tr>
<tr>
<td>Intercept</td>
<td>3.473(0.070)</td>
<td>4.446(0.126)</td>
<td>4.446(0.126)</td>
<td>4.796(0.147)</td>
<td>4.796(0.147)</td>
</tr>
<tr>
<td>Pseudo-<italic>R</italic><sup>2</sup></td>
<td>0.098</td>
<td>0.237</td>
<td>0.237</td>
<td>0.265</td>
<td>0.265</td>
</tr>
<tr>
<td>LogL</td>
<td>−1272.6</td>
<td>−1076.7</td>
<td>−1076.7</td>
<td>−1037.3</td>
<td>−1037.3</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0081175012444861">
<p><italic>Note.</italic> Standard errors in parentheses. <italic>N</italic> = 8,173.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In M1 we find a positive logit coefficient of 0.800 for the effect of family income on high school completion. Controlling for student academic ability in M2 reduces the effect to 0.460. A naïve comparison would thus suggest that the effect of family income on high school graduation declines by 100*(0.800 − 0.460)/0.800 = 42.5% once academic ability is controlled for. However, such a comparison conflates confounding and rescaling. To remedy this deficiency, we use the estimate of family income in M3, where we have included the residualized student academic ability measure, and we compare it with the estimate in M2. We obtain a 100*(1.094 − 0.460)/1.094 = 58.0% reduction due to confounding, net of rescaling. We use the test-statistic in (20) to assess whether confounding is statistically significant and obtain <italic>Z<sub>C</sub></italic> = 0.634/0.042 ≈ 15.00, leading us to conclude that controlling for academic ability reduces the effect of family income on high school completion.</p>
<p>In <xref ref-type="table" rid="table3-0081175012444861">Table 3</xref> we also report estimates from two further logistic models. M4 adds father’s and mother’s educational attainment and M5 includes the family income residualized counterparts of all three control variables. Comparing, naively, the effect of family income in M1 (0.800) and M4 (0.311) gives a reduction of 61.1%. However, using our method we would compare the effect of family income in M5 (1.349) and M4 (0.311). This suggests a substantially larger reduction of 77.0%. Using the formula in (20), we obtain a <italic>Z<sub>C</sub></italic> of 14.83 and thereby conclude that the reduction is statistically significant. Moreover, our method also provides us with an estimate of how much rescaling masks the change caused by confounding. Using the decomposition expressed in ratios in (14a), we obtain</p>
<p><disp-formula id="disp-formula38-0081175012444861">
<mml:math display="block" id="math114-0081175012444861">
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>z</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>⇒</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>311</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>800</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>311</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>349</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>349</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>800</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>⇒</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>389</mml:mn>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>231</mml:mn>
<mml:mo>×</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>686</mml:mn>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula38-0081175012444861" xlink:href="10.1177_0081175012444861-eq38.tif"/>
</disp-formula></p>
<p>Interpreted naively, adding the confounders reduces the effect of <italic>x</italic> to 0.39 of its original size. But this is the product of the true reduction caused by confounding (which would reduce the effect to 0.23 of its original size) and the offsetting impact of rescaling that increases the naïve estimate by a factor of 1.69. In this case rescaling plays an important role in masking the change due to confounding.</p>
<p>In <xref ref-type="table" rid="table4-0081175012444861">Table 4</xref> we show the APEs from the same models as reported in <xref ref-type="table" rid="table3-0081175012444861">Table 3</xref>.<sup><xref ref-type="fn" rid="fn20-0081175012444861">20</xref></sup> In M1 we observe that a standard deviation increase in family income increases, on average, the probability of completing high school by 3.0 percentage points. Controlling for student academic ability in M2 changes the average effect to 1.6 percentage points, a reduction of 46.8%. However, using the specification in M3 returns a different result—namely, a 58.0% reduction. This reduction exactly equals that calculated with the logit coefficients in <xref ref-type="table" rid="table3-0081175012444861">Table 3</xref>. In light of <xref ref-type="disp-formula" rid="disp-formula36-0081175012444861">equation (24)</xref>, this finding is what we would have expected. Moreover, the bias arising from using APEs for the decomposition is smaller than the bias arising from naively comparing logit coefficients. The naïve comparison using logit coefficients returned a 42.5% reduction, while the naïve use of APEs returned a 46.8% reduction. The naïve comparison based on APEs is thus closer to the reduction we find using our method (58.0%).</p>
<table-wrap id="table4-0081175012444861" position="float">
<label>Table 4.</label>
<caption>
<p>APE Counterparts to Logit Coefficients in <xref ref-type="table" rid="table3-0081175012444861">Table 3</xref> (Standard Errors in Parenthesis)</p>
</caption>
<graphic alternate-form-of="table4-0081175012444861" xlink:href="10.1177_0081175012444861-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="1">M1</th>
<th align="center" colspan="1">M2</th>
<th align="center" colspan="1">M3</th>
<th align="center" colspan="1">M4</th>
<th align="center" colspan="1">M5</th>
</tr>
<tr>
<th align="left">Controls</th>
<th align="center">None</th>
<th align="center"><italic>z</italic></th>
<th align="center">
<inline-formula id="inline-formula77-0081175012444861">
<mml:math display="inline" id="math115-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula></th>
<th align="center"><italic>z</italic></th>
<th align="center">
<inline-formula id="inline-formula78-0081175012444861">
<mml:math display="inline" id="math116-0081175012444861">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
</thead>
<tbody>
<tr>
<td>Family income</td>
<td>0.030(0.002)</td>
<td>0.016(0.002)</td>
<td>0.038(0.002)</td>
<td>0.011(0.002)</td>
<td>0.046(0.003)</td>
</tr>
<tr>
<td>Academic ability</td>
<td/>
<td>0.058(0.004)</td>
<td>0.058(0.004)</td>
<td>0.052(0.004)</td>
<td>0.052(0.004)</td>
</tr>
<tr>
<td>Father’s education</td>
<td/>
<td/>
<td/>
<td>0.022(0.004)</td>
<td>0.022(0.004)</td>
</tr>
<tr>
<td>Mother’s education</td>
<td/>
<td/>
<td/>
<td>0.012(0.004)</td>
<td>0.012(0.004)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0081175012444861">
<p><italic>N</italic> = 8,173</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Turning to models M4 and M5 in <xref ref-type="table" rid="table4-0081175012444861">Table 4</xref>, naïvely comparing the APE of family income in M1 and M4 returns a 63% reduction, while correctly comparing the APE in M5 and M4 returns a 76% reduction, equal to the reduction found when applying our method to the logit coefficients in <xref ref-type="table" rid="table4-0081175012444861">Table 4</xref>. Moreover, conditional on M1 holding true, we would estimate that a standard deviation increase in family income would, on average, increase the probability of completing high school by around 3 percentage points. However, conditional on M4 (the model which, in this example, we would take as the full model) holding true, the average effect is around 4.5 percentage points (see M5). Although the results point in the same direction, the effect sizes are quite different.</p>
<p>Similar to the decomposition of the naïve ratio of logit coefficients into confounding and rescaling, we can report an APE counterpart:</p>
<p><disp-formula id="disp-formula39-0081175012444861">
<mml:math display="block" id="math117-0081175012444861">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>APE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>⇒</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>011</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>030</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>011</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>046</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>×</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>046</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>030</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>⇒</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>367</mml:mn>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>239</mml:mn>
<mml:mo>×</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>534</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula39-0081175012444861" xlink:href="10.1177_0081175012444861-eq39.tif"/>
</disp-formula></p>
<p>From the decomposition we see that the ratio measuring confounding equals the one found with logit coefficients (the slight discrepancy—0.239 compared with 0.231—vanishes if we go to more decimal places than shown here). However, the distortion for APEs, 1.534, is less than for logit coefficients, 1.686.</p>
</sec>
<sec id="section12-0081175012444861" sec-type="conclusions">
<title>6. Conclusion</title>
<p><xref ref-type="bibr" rid="bibr28-0081175012444861">Winship and Mare (1984)</xref> noted that logit coefficients are not directly comparable across same-sample nested models because the logit fixes the error variance at an arbitrary constant. While the consequences of this identification restriction for the binary logistic model may be well known in the econometric literature, many quantitative sociologists believe that confounding works the same way for the binary logit or probit regression model as for the linear regression model.</p>
<p>Naïve comparisons of logit coefficients across same-sample nested models should be avoided because the rescaling problem may mask or underestimate the true change due to confounding. Rescaling will always tend to increase the apparent magnitude of the coefficient of a variable<sup><xref ref-type="fn" rid="fn21-0081175012444861">21</xref></sup> and this commonly counteracts the effect of the inclusion of confounding variables, which are most often expected to reduce the effect of the variable of interest. Furthermore, the error distributions will almost always differ between the reduced and the full model. Our Monte Carlo analyses indicate that although <italic>y</italic>-standardization, APEs, and the LPM are effective in dealing with pure rescaling, in certain circumstances they are sensitive to differences in the error distribution across models. But the method we have presented in this paper performs at least as well as, and in some cases better than, others when faced with differences in the error distributions, because it holds constant across equations, scaling, and error distributions. It permits the decomposition of change in the naïve coefficient into a part attributable to confounding and a part attributable to rescaling, and we have provided a test statistic to assess the significance of confounding. It can also be applied to average partial effects to yield unbiased decompositions measured on the probability scale. We applied the approach to binary nonlinear probability models, but both the problem and the solution also apply to cumulative probability models for ordinal data, such as the ordered logit and probit. This follows immediately because the latent variable in such models is defined in exactly the same way as for logits and probits: The models differ only in the degree to which the latent Y* is observed. A Stata program called khb (<ext-link ext-link-type="uri" xlink:href="http://fmwww.bc.edu/RePEc/bocode/k">http://fmwww.bc.edu/RePEc/bocode/k</ext-link>) is available to apply our method to all these cases as well as others.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0081175012444861">
<title>Appendix</title>
<sec id="section13-0081175012444861">
<title>A.1. Coefficient Comparisons Without Assuming a Latent Outcome Variable</title>
<p>The problem in comparing coefficients across nested logit models also applies when the logit model is derived without assuming a latent outcome variable. The problem arises because the logit indices of the reduced and full models differ. To see this, we use the rules for approximating the variance of a function. Let g(.) be the logistic link function, let <italic>y</italic> be a binary outcome variable, and let <italic>x</italic> and <italic>z</italic> be centered on their respective means. For the reduced model we obtain <inline-formula id="inline-formula79-0081175012444861">
<mml:math display="inline" id="math118-0081175012444861">
<mml:mrow>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, which approximates <inline-formula id="inline-formula80-0081175012444861">
<mml:math display="inline" id="math119-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msubsup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, where</p>
<p><disp-formula id="disp-formula40-0081175012444861">
<mml:math display="block" id="math120-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula40-0081175012444861" xlink:href="10.1177_0081175012444861-eq40.tif"/>
</disp-formula></p>
<p>For the full model we obtain the approximation <inline-formula id="inline-formula81-0081175012444861">
<mml:math display="inline" id="math121-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mtext>cov</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, where</p>
<p><disp-formula id="disp-formula41-0081175012444861">
<mml:math display="block" id="math122-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula41-0081175012444861" xlink:href="10.1177_0081175012444861-eq41.tif"/>
</disp-formula></p>
<p>The ratio between the two variances is</p>
<p><disp-formula id="disp-formula42-0081175012444861">
<mml:math display="block" id="math123-0081175012444861">
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msubsup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mtext>cov</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>π</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula42-0081175012444861" xlink:href="10.1177_0081175012444861-eq42.tif"/>
</disp-formula></p>
<p>which approximates the proportional reduction in the variance caused by the inclusion of the confounder <italic>z</italic> and is always less than or equal to one. It follows that <inline-formula id="inline-formula82-0081175012444861">
<mml:math display="inline" id="math124-0081175012444861">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>≈</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula>, where θ is obtained from a linear regression of <italic>z</italic> on <italic>x</italic>. We can thus restate the difference in (7) in the main text as <inline-formula id="inline-formula83-0081175012444861">
<mml:math display="inline" id="math125-0081175012444861">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>−</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mi>θ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msqrt>
<mml:mo>−</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula>, from which we find that the difference in coefficients across models reflects, at least approximately, not only confounding (captured by <inline-formula id="inline-formula84-0081175012444861">
<mml:math display="inline" id="math126-0081175012444861">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>), but also the change in the variance of the logit index (captured by <inline-formula id="inline-formula85-0081175012444861">
<mml:math display="inline" id="math127-0081175012444861">
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula>).</p>
</sec>
<sec id="section14-0081175012444861">
<title>A.2. Simulation Results</title>
<table-wrap id="table5-0081175012444861" position="float">
<label>Table A1:</label>
<caption>
<p>Simulation Results (Ratio of Partial Effect of x to Gross Effect) under the Latent Model: <inline-formula id="inline-formula86-0081175012444861">
<mml:math display="inline" id="math128-0081175012444861">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>β</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mi>z</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, <italic>N</italic> = 5,000, 250 reps</p>
</caption>
<graphic alternate-form-of="table5-0081175012444861" xlink:href="10.1177_0081175012444861-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="9">(a) Probit Model, <italic>e</italic>, <italic>x</italic> and <italic>z</italic> All <italic>N</italic>(0,1), <inline-formula id="inline-formula87-0081175012444861">
<mml:math display="inline" id="math129-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
<tr>
<th align="left"><italic>r (x,z)</italic></th>
<th align="center">Cut-point</th>
<th align="center">True Ratio</th>
<th align="center">Naïve</th>
<th align="center">Latent</th>
<th align="center">Our Method</th>
<th align="center">APE</th>
<th align="center"><italic>y</italic>-Stand</th>
<th align="center">LPM</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.0000</td>
<td>0.5000</td>
<td>1.0007</td>
<td>1.4145</td>
<td>1.0007</td>
<td>1.0008</td>
<td>1.0011</td>
<td>1.0010</td>
<td>1.0007</td>
</tr>
<tr>
<td>0.0017</td>
<td>0.7000</td>
<td>0.9973</td>
<td>1.4096</td>
<td>0.9973</td>
<td>0.9972</td>
<td>0.9959</td>
<td>0.9962</td>
<td>0.9972</td>
</tr>
<tr>
<td>0.0009</td>
<td>0.9000</td>
<td>0.9989</td>
<td>1.4144</td>
<td>0.9989</td>
<td>0.9990</td>
<td>0.9991</td>
<td>0.9989</td>
<td>0.9990</td>
</tr>
<tr>
<td>0.0007</td>
<td>0.9500</td>
<td>0.9994</td>
<td>1.4158</td>
<td>0.9994</td>
<td>0.9994</td>
<td>1.0008</td>
<td>0.9994</td>
<td>0.9993</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.5000</td>
<td>0.8333</td>
<td>1.1763</td>
<td>0.8337</td>
<td>0.8343</td>
<td>0.8342</td>
<td>0.8342</td>
<td>0.8343</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.7000</td>
<td>0.8333</td>
<td>1.1747</td>
<td>0.8330</td>
<td>0.8334</td>
<td>0.8336</td>
<td>0.8332</td>
<td>0.8335</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9000</td>
<td>0.8333</td>
<td>1.1748</td>
<td>0.8335</td>
<td>0.8322</td>
<td>0.8327</td>
<td>0.8325</td>
<td>0.8323</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9500</td>
<td>0.8333</td>
<td>1.1736</td>
<td>0.8336</td>
<td>0.8320</td>
<td>0.8305</td>
<td>0.8309</td>
<td>0.8319</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.5000</td>
<td>0.6250</td>
<td>0.8637</td>
<td>0.6235</td>
<td>0.6236</td>
<td>0.6242</td>
<td>0.6240</td>
<td>0.6231</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.7000</td>
<td>0.6250</td>
<td>0.8618</td>
<td>0.6255</td>
<td>0.6242</td>
<td>0.6239</td>
<td>0.6239</td>
<td>0.6243</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9000</td>
<td>0.6250</td>
<td>0.8649</td>
<td>0.6251</td>
<td>0.6242</td>
<td>0.6249</td>
<td>0.6246</td>
<td>0.6241</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9500</td>
<td>0.6250</td>
<td>0.8628</td>
<td>0.6239</td>
<td>0.6241</td>
<td>0.6236</td>
<td>0.6237</td>
<td>0.6240</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.5000</td>
<td>0.5000</td>
<td>0.6623</td>
<td>0.4996</td>
<td>0.5003</td>
<td>0.5002</td>
<td>0.5003</td>
<td>0.4999</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.7000</td>
<td>0.5000</td>
<td>0.6601</td>
<td>0.4995</td>
<td>0.4986</td>
<td>0.4989</td>
<td>0.4988</td>
<td>0.4988</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9000</td>
<td>0.5000</td>
<td>0.6611</td>
<td>0.4999</td>
<td>0.4992</td>
<td>0.4998</td>
<td>0.4994</td>
<td>0.4986</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9500</td>
<td>0.5000</td>
<td>0.6580</td>
<td>0.5004</td>
<td>0.4951</td>
<td>0.4958</td>
<td>0.4953</td>
<td>0.4961</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.5000</td>
<td>0.4167</td>
<td>0.5131</td>
<td>0.4174</td>
<td>0.4174</td>
<td>0.4179</td>
<td>0.4176</td>
<td>0.4178</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.7000</td>
<td>0.4167</td>
<td>0.5125</td>
<td>0.4162</td>
<td>0.4174</td>
<td>0.4176</td>
<td>0.4174</td>
<td>0.4170</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9000</td>
<td>0.4167</td>
<td>0.5115</td>
<td>0.4176</td>
<td>0.4164</td>
<td>0.4162</td>
<td>0.4163</td>
<td>0.4167</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9500</td>
<td>0.4167</td>
<td>0.5087</td>
<td>0.4151</td>
<td>0.4122</td>
<td>0.4128</td>
<td>0.4124</td>
<td>0.4134</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.5000</td>
<td>0.3571</td>
<td>0.3880</td>
<td>0.3555</td>
<td>0.3557</td>
<td>0.3558</td>
<td>0.3557</td>
<td>0.3562</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.7000</td>
<td>0.3571</td>
<td>0.3883</td>
<td>0.3564</td>
<td>0.3561</td>
<td>0.3561</td>
<td>0.3561</td>
<td>0.3558</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9000</td>
<td>0.3571</td>
<td>0.3868</td>
<td>0.3548</td>
<td>0.3544</td>
<td>0.3545</td>
<td>0.3545</td>
<td>0.3550</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9500</td>
<td>0.3571</td>
<td>0.3845</td>
<td>0.3573</td>
<td>0.3532</td>
<td>0.3528</td>
<td>0.3530</td>
<td>0.3483</td>
</tr>
<tr>
<th align="left" colspan="9">(b) Logit Model, <italic>x</italic> and <italic>z</italic> are <italic>N</italic>(0,1), <italic>e</italic> is standard logistic, <inline-formula id="inline-formula88-0081175012444861">
<mml:math display="inline" id="math130-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
<tr>
<th align="left"><italic>r (x,z)</italic></th>
<th align="center">Cut-point</th>
<th align="center">True Ratio</th>
<th align="center">Naïve</th>
<th align="center">Latent</th>
<th align="center">Our Method</th>
<th align="center">APE</th>
<th align="center"><italic>y</italic>-Stand</th>
<th align="center">LPM</th>
</tr>
<tr>
<td>0.0000</td>
<td>0.5000</td>
<td>1.0007</td>
<td>1.2056</td>
<td>1.0007</td>
<td>1.0007</td>
<td>1.0004</td>
<td>1.0525</td>
<td>1.0007</td>
</tr>
<tr>
<td>0.0012</td>
<td>0.7000</td>
<td>0.9984</td>
<td>1.1819</td>
<td>0.9984</td>
<td>0.9983</td>
<td>0.9983</td>
<td>1.0333</td>
<td>0.9983</td>
</tr>
<tr>
<td>−0.0008</td>
<td>0.9000</td>
<td>1.0022</td>
<td>1.1093</td>
<td>1.0022</td>
<td>1.0021</td>
<td>1.0021</td>
<td>0.9730</td>
<td>1.0021</td>
</tr>
<tr>
<td>−0.0006</td>
<td>0.9500</td>
<td>1.0021</td>
<td>1.0736</td>
<td>1.0022</td>
<td>1.0019</td>
<td>1.0050</td>
<td>0.9426</td>
<td>1.0019</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.5000</td>
<td>0.8333</td>
<td>0.9993</td>
<td>0.8327</td>
<td>0.8321</td>
<td>0.8321</td>
<td>0.8727</td>
<td>0.8322</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.7000</td>
<td>0.8333</td>
<td>0.9850</td>
<td>0.8324</td>
<td>0.8321</td>
<td>0.8322</td>
<td>0.8600</td>
<td>0.8322</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9000</td>
<td>0.8333</td>
<td>0.9233</td>
<td>0.8331</td>
<td>0.8318</td>
<td>0.8330</td>
<td>0.8105</td>
<td>0.8318</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9500</td>
<td>0.8333</td>
<td>0.8907</td>
<td>0.8330</td>
<td>0.8317</td>
<td>0.8312</td>
<td>0.7832</td>
<td>0.8320</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.5000</td>
<td>0.6250</td>
<td>0.7387</td>
<td>0.6257</td>
<td>0.6246</td>
<td>0.6248</td>
<td>0.6498</td>
<td>0.6245</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.7000</td>
<td>0.6250</td>
<td>0.7294</td>
<td>0.6256</td>
<td>0.6251</td>
<td>0.6249</td>
<td>0.6424</td>
<td>0.6250</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9000</td>
<td>0.6250</td>
<td>0.6882</td>
<td>0.6250</td>
<td>0.6235</td>
<td>0.6240</td>
<td>0.6110</td>
<td>0.6236</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9500</td>
<td>0.6250</td>
<td>0.6653</td>
<td>0.6246</td>
<td>0.6215</td>
<td>0.6218</td>
<td>0.5925</td>
<td>0.6216</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.5000</td>
<td>0.5000</td>
<td>0.5762</td>
<td>0.5017</td>
<td>0.5022</td>
<td>0.5021</td>
<td>0.5168</td>
<td>0.5022</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.7000</td>
<td>0.5000</td>
<td>0.5698</td>
<td>0.5008</td>
<td>0.5011</td>
<td>0.5010</td>
<td>0.5114</td>
<td>0.5007</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9000</td>
<td>0.5000</td>
<td>0.5432</td>
<td>0.5010</td>
<td>0.4994</td>
<td>0.4996</td>
<td>0.4925</td>
<td>0.4996</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9500</td>
<td>0.5000</td>
<td>0.5302</td>
<td>0.4991</td>
<td>0.4995</td>
<td>0.4994</td>
<td>0.4827</td>
<td>0.4998</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.5000</td>
<td>0.4167</td>
<td>0.4584</td>
<td>0.4155</td>
<td>0.4164</td>
<td>0.4165</td>
<td>0.4238</td>
<td>0.4162</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.7000</td>
<td>0.4167</td>
<td>0.4542</td>
<td>0.4163</td>
<td>0.4154</td>
<td>0.4154</td>
<td>0.4206</td>
<td>0.4149</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9000</td>
<td>0.4167</td>
<td>0.4431</td>
<td>0.4178</td>
<td>0.4168</td>
<td>0.4172</td>
<td>0.4137</td>
<td>0.4162</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9500</td>
<td>0.4167</td>
<td>0.4351</td>
<td>0.4156</td>
<td>0.4166</td>
<td>0.4170</td>
<td>0.4086</td>
<td>0.4172</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.5000</td>
<td>0.3571</td>
<td>0.3714</td>
<td>0.3595</td>
<td>0.3582</td>
<td>0.3581</td>
<td>0.3602</td>
<td>0.3575</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.7000</td>
<td>0.3571</td>
<td>0.3705</td>
<td>0.3610</td>
<td>0.3581</td>
<td>0.3581</td>
<td>0.3596</td>
<td>0.3575</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9000</td>
<td>0.3571</td>
<td>0.3639</td>
<td>0.3523</td>
<td>0.3554</td>
<td>0.3554</td>
<td>0.3546</td>
<td>0.3560</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9500</td>
<td>0.3571</td>
<td>0.3618</td>
<td>0.3554</td>
<td>0.3560</td>
<td>0.3558</td>
<td>0.3537</td>
<td>0.3540</td>
</tr>
<tr>
<th align="left" colspan="9">(c) Logit Model, <italic>x</italic> Log-normal with <italic>SD</italic> = 1, <italic>z</italic> is Mixture of log-normals with <italic>SD</italic> = 1, and <italic>e</italic> is Standard Logistic, <inline-formula id="inline-formula89-0081175012444861">
<mml:math display="inline" id="math131-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
<tr>
<th align="left"><italic>r (x,z)</italic></th>
<th align="center">Cut-point</th>
<th align="center">True Ratio</th>
<th align="center">Naïve</th>
<th align="center">Latent</th>
<th align="center">Our Method</th>
<th align="center">APE</th>
<th align="center"><italic>y</italic>-Stand</th>
<th align="center">LPM</th>
</tr>
<tr>
<td>−0.0004</td>
<td>0.5000</td>
<td>1.0015</td>
<td>1.0801</td>
<td>1.0017</td>
<td>1.0018</td>
<td>0.9803</td>
<td>0.9486</td>
<td>1.0010</td>
</tr>
<tr>
<td>0.0003</td>
<td>0.7000</td>
<td>1.0003</td>
<td>1.1176</td>
<td>1.0002</td>
<td>1.0003</td>
<td>0.9739</td>
<td>0.9808</td>
<td>0.9997</td>
</tr>
<tr>
<td>−0.0003</td>
<td>0.9000</td>
<td>1.0013</td>
<td>1.1789</td>
<td>1.0012</td>
<td>1.0010</td>
<td>0.9618</td>
<td>1.0298</td>
<td>1.0008</td>
</tr>
<tr>
<td>−0.0002</td>
<td>0.9500</td>
<td>1.0011</td>
<td>1.2179</td>
<td>1.0011</td>
<td>1.0011</td>
<td>0.9510</td>
<td>1.0630</td>
<td>1.0015</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.5000</td>
<td>0.8333</td>
<td>0.8980</td>
<td>0.8330</td>
<td>0.8327</td>
<td>0.8147</td>
<td>0.7913</td>
<td>0.8582</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.7000</td>
<td>0.8333</td>
<td>0.9285</td>
<td>0.8326</td>
<td>0.8318</td>
<td>0.8101</td>
<td>0.8154</td>
<td>0.8543</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9000</td>
<td>0.8333</td>
<td>0.9804</td>
<td>0.8336</td>
<td>0.8330</td>
<td>0.8013</td>
<td>0.8570</td>
<td>0.8331</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9500</td>
<td>0.8333</td>
<td>1.0069</td>
<td>0.8336</td>
<td>0.8324</td>
<td>0.7872</td>
<td>0.8785</td>
<td>0.8171</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.5000</td>
<td>0.6250</td>
<td>0.6712</td>
<td>0.6241</td>
<td>0.6249</td>
<td>0.6117</td>
<td>0.5984</td>
<td>0.6521</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.7000</td>
<td>0.6250</td>
<td>0.6912</td>
<td>0.6253</td>
<td>0.6227</td>
<td>0.6071</td>
<td>0.6127</td>
<td>0.6433</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9000</td>
<td>0.6250</td>
<td>0.7280</td>
<td>0.6254</td>
<td>0.6277</td>
<td>0.6044</td>
<td>0.6427</td>
<td>0.6292</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9500</td>
<td>0.6250</td>
<td>0.7471</td>
<td>0.6255</td>
<td>0.6264</td>
<td>0.5952</td>
<td>0.6569</td>
<td>0.6109</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.5000</td>
<td>0.5000</td>
<td>0.5319</td>
<td>0.4985</td>
<td>0.4995</td>
<td>0.4900</td>
<td>0.4837</td>
<td>0.4727</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.7000</td>
<td>0.5000</td>
<td>0.5447</td>
<td>0.5020</td>
<td>0.4986</td>
<td>0.4867</td>
<td>0.4932</td>
<td>0.4746</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9000</td>
<td>0.5000</td>
<td>0.5679</td>
<td>0.4995</td>
<td>0.5000</td>
<td>0.4846</td>
<td>0.5100</td>
<td>0.4919</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9500</td>
<td>0.5000</td>
<td>0.5794</td>
<td>0.4999</td>
<td>0.4991</td>
<td>0.4790</td>
<td>0.5184</td>
<td>0.5022</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.5000</td>
<td>0.4167</td>
<td>0.4360</td>
<td>0.4171</td>
<td>0.4152</td>
<td>0.4095</td>
<td>0.4086</td>
<td>0.2767</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.7000</td>
<td>0.4167</td>
<td>0.4444</td>
<td>0.4169</td>
<td>0.4152</td>
<td>0.4084</td>
<td>0.4140</td>
<td>0.3040</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9000</td>
<td>0.4167</td>
<td>0.4590</td>
<td>0.4163</td>
<td>0.4190</td>
<td>0.4114</td>
<td>0.4252</td>
<td>0.4046</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9500</td>
<td>0.4167</td>
<td>0.4606</td>
<td>0.4157</td>
<td>0.4141</td>
<td>0.4037</td>
<td>0.4245</td>
<td>0.4494</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.5000</td>
<td>0.3571</td>
<td>0.3611</td>
<td>0.3542</td>
<td>0.3528</td>
<td>0.3506</td>
<td>0.3518</td>
<td>0.0022</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.7000</td>
<td>0.3571</td>
<td>0.3673</td>
<td>0.3576</td>
<td>0.3565</td>
<td>0.3544</td>
<td>0.3570</td>
<td>0.1323</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9000</td>
<td>0.3571</td>
<td>0.3727</td>
<td>0.3585</td>
<td>0.3591</td>
<td>0.3578</td>
<td>0.3613</td>
<td>0.3596</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9500</td>
<td>0.3571</td>
<td>0.3706</td>
<td>0.3541</td>
<td>0.3562</td>
<td>0.3548</td>
<td>0.3589</td>
<td>0.4819</td>
</tr>
<tr>
<th align="left" colspan="9">(d) Logit Model, <italic>x</italic> and <italic>z</italic> are <italic>N</italic>(0,1), <italic>e</italic> is Standard Logistic, <inline-formula id="inline-formula90-0081175012444861">
<mml:math display="inline" id="math132-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
<tr>
<th align="left"><italic>r (x,z)</italic></th>
<th align="center">Cut-point</th>
<th align="center">True Ratio</th>
<th align="center">Naïve</th>
<th align="center">Latent</th>
<th align="center">Our Method</th>
<th align="center">APE</th>
<th align="center"><italic>y</italic>-Stand</th>
<th align="center">LPM</th>
</tr>
<tr>
<td>0.0006</td>
<td>0.5000</td>
<td>0.9998</td>
<td>1.0521</td>
<td>0.9997</td>
<td>0.9998</td>
<td>0.9997</td>
<td>1.0110</td>
<td>0.9998</td>
</tr>
<tr>
<td>0.0006</td>
<td>0.7000</td>
<td>0.9998</td>
<td>1.0481</td>
<td>0.9998</td>
<td>0.9997</td>
<td>0.9998</td>
<td>1.0078</td>
<td>0.9997</td>
</tr>
<tr>
<td>−0.0002</td>
<td>0.9000</td>
<td>1.0002</td>
<td>1.0305</td>
<td>1.0002</td>
<td>1.0002</td>
<td>1.0001</td>
<td>0.9944</td>
<td>1.0002</td>
</tr>
<tr>
<td>−0.0005</td>
<td>0.9500</td>
<td>1.0003</td>
<td>1.0225</td>
<td>1.0003</td>
<td>1.0003</td>
<td>1.0021</td>
<td>0.9884</td>
<td>1.0003</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.5000</td>
<td>0.9524</td>
<td>1.0013</td>
<td>0.9521</td>
<td>0.9524</td>
<td>0.9523</td>
<td>0.9625</td>
<td>0.9524</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.7000</td>
<td>0.9524</td>
<td>0.9977</td>
<td>0.9523</td>
<td>0.9521</td>
<td>0.9522</td>
<td>0.9594</td>
<td>0.9521</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9000</td>
<td>0.9524</td>
<td>0.9809</td>
<td>0.9524</td>
<td>0.9527</td>
<td>0.9526</td>
<td>0.9478</td>
<td>0.9527</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9500</td>
<td>0.9524</td>
<td>0.9721</td>
<td>0.9524</td>
<td>0.9527</td>
<td>0.9528</td>
<td>0.9412</td>
<td>0.9526</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.5000</td>
<td>0.8696</td>
<td>0.9108</td>
<td>0.8699</td>
<td>0.8697</td>
<td>0.8699</td>
<td>0.8776</td>
<td>0.8697</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.7000</td>
<td>0.8696</td>
<td>0.9077</td>
<td>0.8699</td>
<td>0.8711</td>
<td>0.8709</td>
<td>0.8764</td>
<td>0.8711</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9000</td>
<td>0.8696</td>
<td>0.8937</td>
<td>0.8696</td>
<td>0.8691</td>
<td>0.8691</td>
<td>0.8654</td>
<td>0.8694</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9500</td>
<td>0.8696</td>
<td>0.8860</td>
<td>0.8692</td>
<td>0.8694</td>
<td>0.8691</td>
<td>0.8603</td>
<td>0.8694</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.5000</td>
<td>0.8000</td>
<td>0.8296</td>
<td>0.8001</td>
<td>0.7989</td>
<td>0.7986</td>
<td>0.8041</td>
<td>0.7987</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.7000</td>
<td>0.8000</td>
<td>0.8281</td>
<td>0.7992</td>
<td>0.7999</td>
<td>0.7999</td>
<td>0.8038</td>
<td>0.7997</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9000</td>
<td>0.8000</td>
<td>0.8197</td>
<td>0.8007</td>
<td>0.8008</td>
<td>0.8008</td>
<td>0.7983</td>
<td>0.8007</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9500</td>
<td>0.8000</td>
<td>0.8131</td>
<td>0.8010</td>
<td>0.7986</td>
<td>0.7991</td>
<td>0.7927</td>
<td>0.7986</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.5000</td>
<td>0.7407</td>
<td>0.7567</td>
<td>0.7395</td>
<td>0.7372</td>
<td>0.7373</td>
<td>0.7404</td>
<td>0.7375</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.7000</td>
<td>0.7407</td>
<td>0.7578</td>
<td>0.7398</td>
<td>0.7402</td>
<td>0.7400</td>
<td>0.7423</td>
<td>0.7399</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9000</td>
<td>0.7407</td>
<td>0.7520</td>
<td>0.7405</td>
<td>0.7401</td>
<td>0.7398</td>
<td>0.7385</td>
<td>0.7393</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9500</td>
<td>0.7407</td>
<td>0.7506</td>
<td>0.7405</td>
<td>0.7420</td>
<td>0.7418</td>
<td>0.7384</td>
<td>0.7407</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.5000</td>
<td>0.6897</td>
<td>0.6986</td>
<td>0.6905</td>
<td>0.6921</td>
<td>0.6922</td>
<td>0.6931</td>
<td>0.6921</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.7000</td>
<td>0.6897</td>
<td>0.6993</td>
<td>0.6916</td>
<td>0.6933</td>
<td>0.6933</td>
<td>0.6940</td>
<td>0.6931</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9000</td>
<td>0.6897</td>
<td>0.6909</td>
<td>0.6911</td>
<td>0.6864</td>
<td>0.6865</td>
<td>0.6860</td>
<td>0.6874</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9500</td>
<td>0.6897</td>
<td>0.6964</td>
<td>0.6913</td>
<td>0.6934</td>
<td>0.6933</td>
<td>0.6923</td>
<td>0.6917</td>
</tr>
<tr>
<th align="left" colspan="9">(e) Logit Model, <italic>x</italic> log-normal with <italic>SD</italic> = 1, <italic>z</italic> is mixture of log-normals with <italic>SD</italic> = 1 and <italic>e</italic> is Standard Logistic, <inline-formula id="inline-formula91-0081175012444861">
<mml:math display="inline" id="math133-0081175012444861">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula></th>
</tr>
<tr>
<th align="left"><italic>r (x,z)</italic></th>
<th align="center">Cut-point</th>
<th align="center">True Ratio</th>
<th align="center">Naïve</th>
<th align="center">Latent</th>
<th align="center">Our Method</th>
<th align="center">APE</th>
<th align="center"><italic>y</italic>-Stand</th>
<th align="center">LPM</th>
</tr>
<tr>
<td>0.0005</td>
<td>0.5000</td>
<td>0.9998</td>
<td>1.0293</td>
<td>0.9998</td>
<td>0.9998</td>
<td>0.9915</td>
<td>0.9935</td>
<td>0.9997</td>
</tr>
<tr>
<td>−0.0003</td>
<td>0.7000</td>
<td>1.0002</td>
<td>1.0403</td>
<td>1.0002</td>
<td>1.0002</td>
<td>0.9921</td>
<td>1.0023</td>
<td>1.0002</td>
</tr>
<tr>
<td>−0.0010</td>
<td>0.9000</td>
<td>1.0006</td>
<td>1.0518</td>
<td>1.0006</td>
<td>1.0006</td>
<td>0.9939</td>
<td>1.0110</td>
<td>1.0006</td>
</tr>
<tr>
<td>−0.0009</td>
<td>0.9500</td>
<td>1.0005</td>
<td>1.0566</td>
<td>1.0005</td>
<td>1.0005</td>
<td>0.9919</td>
<td>1.0139</td>
<td>1.0004</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.5000</td>
<td>0.9524</td>
<td>0.9797</td>
<td>0.9524</td>
<td>0.9522</td>
<td>0.9444</td>
<td>0.9465</td>
<td>0.9372</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.7000</td>
<td>0.9524</td>
<td>0.9905</td>
<td>0.9519</td>
<td>0.9517</td>
<td>0.9441</td>
<td>0.9537</td>
<td>0.9417</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9000</td>
<td>0.9524</td>
<td>1.0006</td>
<td>0.9524</td>
<td>0.9523</td>
<td>0.9464</td>
<td>0.9621</td>
<td>0.9521</td>
</tr>
<tr>
<td>0.1000</td>
<td>0.9500</td>
<td>0.9524</td>
<td>1.0039</td>
<td>0.9525</td>
<td>0.9522</td>
<td>0.9443</td>
<td>0.9642</td>
<td>0.9574</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.5000</td>
<td>0.8696</td>
<td>0.8928</td>
<td>0.8690</td>
<td>0.8680</td>
<td>0.8617</td>
<td>0.8641</td>
<td>0.8168</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.7000</td>
<td>0.8696</td>
<td>0.9018</td>
<td>0.8693</td>
<td>0.8692</td>
<td>0.8631</td>
<td>0.8712</td>
<td>0.8357</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9000</td>
<td>0.8696</td>
<td>0.9092</td>
<td>0.8699</td>
<td>0.8693</td>
<td>0.8641</td>
<td>0.8765</td>
<td>0.8674</td>
</tr>
<tr>
<td>0.3000</td>
<td>0.9500</td>
<td>0.8696</td>
<td>0.9140</td>
<td>0.8695</td>
<td>0.8698</td>
<td>0.8640</td>
<td>0.8799</td>
<td>0.8880</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.5000</td>
<td>0.8000</td>
<td>0.8207</td>
<td>0.8007</td>
<td>0.8018</td>
<td>0.7969</td>
<td>0.7995</td>
<td>0.7018</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.7000</td>
<td>0.8000</td>
<td>0.8230</td>
<td>0.7994</td>
<td>0.7980</td>
<td>0.7931</td>
<td>0.7994</td>
<td>0.7370</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9000</td>
<td>0.8000</td>
<td>0.8305</td>
<td>0.7995</td>
<td>0.8001</td>
<td>0.7971</td>
<td>0.8055</td>
<td>0.8018</td>
</tr>
<tr>
<td>0.5000</td>
<td>0.9500</td>
<td>0.8000</td>
<td>0.8331</td>
<td>0.8002</td>
<td>0.8002</td>
<td>0.7966</td>
<td>0.8069</td>
<td>0.8340</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.5000</td>
<td>0.7407</td>
<td>0.7522</td>
<td>0.7399</td>
<td>0.7394</td>
<td>0.7361</td>
<td>0.7385</td>
<td>0.5822</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.7000</td>
<td>0.7407</td>
<td>0.7570</td>
<td>0.7407</td>
<td>0.7406</td>
<td>0.7378</td>
<td>0.7420</td>
<td>0.6447</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9000</td>
<td>0.7407</td>
<td>0.7608</td>
<td>0.7417</td>
<td>0.7416</td>
<td>0.7405</td>
<td>0.7448</td>
<td>0.7484</td>
</tr>
<tr>
<td>0.7000</td>
<td>0.9500</td>
<td>0.7407</td>
<td>0.7632</td>
<td>0.7422</td>
<td>0.7435</td>
<td>0.7425</td>
<td>0.7470</td>
<td>0.8075</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.5000</td>
<td>0.6897</td>
<td>0.6926</td>
<td>0.6907</td>
<td>0.6874</td>
<td>0.6861</td>
<td>0.6875</td>
<td>0.4274</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.7000</td>
<td>0.6897</td>
<td>0.6893</td>
<td>0.6897</td>
<td>0.6829</td>
<td>0.6822</td>
<td>0.6837</td>
<td>0.5376</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9000</td>
<td>0.6897</td>
<td>0.6997</td>
<td>0.6917</td>
<td>0.6935</td>
<td>0.6937</td>
<td>0.6943</td>
<td>0.7313</td>
</tr>
<tr>
<td>0.9000</td>
<td>0.9500</td>
<td>0.6897</td>
<td>0.7004</td>
<td>0.6883</td>
<td>0.6946</td>
<td>0.6951</td>
<td>0.6952</td>
<td>0.8138</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
</app>
</app-group>
<ack>
<p>We thank Mads Meier Jæger, Robert Mare, the reviewers, a board member and the editor of <italic>Sociological Methodology</italic>, and participants at the RC28 conference at Yale 2009 for very helpful comments.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0081175012444861">
<label>1.</label>
<p>We use “confounding” as a general term to cover all cases in which additional variables, <italic>z</italic>, are correlated with the original predictor variable, <italic>x</italic>, and also affect the outcome variable, <italic>y.</italic> This includes cases where the additional variables are believed to “mediate” the original <italic><italic>x-y</italic></italic> relationship. In terms of path analyses, the part of the <italic><italic>x-y</italic></italic> relationship mediated or confounded by <italic>z</italic> is the indirect effect.</p>
</fn>
<fn fn-type="other" id="fn2-0081175012444861">
<label>2.</label>
<p>Following <xref ref-type="bibr" rid="bibr6-0081175012444861">Clogg et al. (1995)</xref> we use the term “full model” to denote the model including controls, while we denote the model without controls the “reduced model.” Since both models cannot be true simultaneously, we hold the full model to be the “true” model—that is, the model on which we will base our inferences. In this context, “reduced model” should not be confused with “reduced form model.”</p>
</fn>
<fn fn-type="other" id="fn3-0081175012444861">
<label>3.</label>
<p>Whenever the threshold constant is nonzero, it is absorbed in the intercept of the logit model. Because it does not affect the effect estimates, setting it to zero, as we do here, is innocuous.</p>
</fn>
<fn fn-type="other" id="fn4-0081175012444861">
<label>4.</label>
<p>An exception occurs when both <italic>v</italic> and <italic>z</italic> are normally distributed (and we would fit a probit to the data). In this case <italic>e</italic> will also be normally distributed and so the two models will differ in scale parameters but not in the shapes of the distributions of their errors. We exploit this property later in our simulations.</p>
</fn>
<fn fn-type="other" id="fn5-0081175012444861">
<label>5.</label>
<p>Sociologists sometimes prefer not to invoke a latent variable model to motivate the logit model. However, the problem in comparing coefficients across nested logit models stated in (7) also applies when the models are derived without assuming a latent outcome variable. We show this in the <xref ref-type="app" rid="app1-0081175012444861">Appendix</xref>.</p>
</fn>
<fn fn-type="other" id="fn6-0081175012444861">
<label>6.</label>
<p>Here, and throughout the paper, <italic>z</italic> is a continuous variable, but the method can be applied when <italic>z</italic> is nominal or ordinal. In both cases we define one or more dummy variables (using the same omitted category for them all) and use OLS to regress each of them on <italic>x</italic> to generate a set of residualized <italic>z</italic> variables.</p>
</fn>
<fn fn-type="other" id="fn7-0081175012444861">
<label>7.</label>
<p>We can write the residual standard deviation as <inline-formula id="inline-formula92-0081175012444861">
<mml:math display="inline" id="math134-0081175012444861">
<mml:mrow>
<mml:mi>sd</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> and so if two models for the same outcome variable have the same fitted values they will have the same residual standard deviation.</p>
</fn>
<fn fn-type="other" id="fn8-0081175012444861">
<label>8.</label>
<p>The probit is trivially similar: <inline-formula id="inline-formula93-0081175012444861">
<mml:math display="inline" id="math135-0081175012444861">
<mml:mrow>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>Φ</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
<mml:mo>.</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>.</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mover>
<mml:mrow>
<mml:mi>z</mml:mi>
</mml:mrow>
<mml:mo>~</mml:mo>
</mml:mover>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula> and, in <xref ref-type="disp-formula" rid="disp-formula9-0081175012444861">equation (8)</xref>, <italic>k</italic> is drawn from a normal distribution with standard deviation <inline-formula id="inline-formula94-0081175012444861">
<mml:math display="inline" id="math136-0081175012444861">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</fn>
<fn fn-type="other" id="fn9-0081175012444861">
<label>9.</label>
<p>Because, as we have demonstrated, the linear predictors of the two models equal each other, <inline-formula id="inline-formula95-0081175012444861">${\beta _{yx.{\bf{z}}}}x + {\bf{\rbeta}}_{y{\bf{z}}.x}}{\bf{z}} = {\beta _{yx.{\tilde{\bf z}}}}x + {\bf{\rbeta}}_{y{\tilde{\bf z}}.x}}{\tilde{\bf z}}$</inline-formula>, we find that <inline-formula id="inline-formula96-0081175012444861">${y^* } = {\beta _{yx.{\tilde{\bf z}}}}x + {\bf{\rbeta}}_{y{\tilde{\bf z}}.x}}{\tilde{\bf z}} + k = {\beta _{yx.{\bf{z}}}}x + {\bf{\rbeta}}_{y{\bf{z}}.x}}{\bf{z}} + k$</inline-formula>, implying that the error terms on both sides of the final equality have the same distribution.</p>
</fn>
<fn fn-type="other" id="fn10-0081175012444861">
<label>10.</label>
<p><inline-formula id="inline-formula97-0081175012444861">
<mml:math display="inline" id="math137-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> can also be obtained directly by estimating the regressions of each <italic>z</italic> on <italic>x</italic> as a set of seemingly unrelated regressions. <inline-formula id="inline-formula98-0081175012444861">
<mml:math display="inline" id="math138-0081175012444861">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is then the variance-covariance matrix of the estimates of the parameters of the system.</p>
</fn>
<fn fn-type="other" id="fn11-0081175012444861">
<label>11.</label>
<p>Whenever <italic>x</italic> is discrete, the ME is the difference(s) in expected probabilities for each discrete category. In this paper, we refer to the continuous case. The discrete case follows directly from these derivations.</p>
</fn>
<fn fn-type="other" id="fn12-0081175012444861">
<label>12.</label>
<p>For discrete <italic>x</italic>’s, see <xref ref-type="bibr" rid="bibr4-0081175012444861">Bartus (2005)</xref>.</p>
</fn>
<fn fn-type="other" id="fn13-0081175012444861">
<label>13.</label>
<p>The results reported here are robust to other specifications of the simulation procedure (not reported but available from the authors). We find virtually identical results with <italic>N</italic> = 5,000 and 500 replications and, although less precise, the results from a study using <italic>N</italic> = 1,000 and 500 replications tell the same story as the results reported here.</p>
</fn>
<fn fn-type="other" id="fn14-0081175012444861">
<label>14.</label>
<p>This will not be true in the logit models where the error term of the reduced model will be a mixture of the distributions of <italic>z</italic> and of the error of the full model, and consequently not logistically distributed.</p>
</fn>
<fn fn-type="other" id="fn15-0081175012444861">
<label>15.</label>
<p>In real applications, of course, we have to make an assumption about the distribution of the error, since we cannot know what it is in either the full or reduced model. Previous work suggests that the logit and probit are fairly robust against misspecification of the error (e.g., <xref ref-type="bibr" rid="bibr8-0081175012444861">Cramer 2007</xref>:554), and simulations that we have undertaken (not reported but available from the authors) show that our method is very good at recovering the true confounding ratio from a logit model even when the error distribution of the full model is not logistic.</p>
</fn>
<fn fn-type="other" id="fn16-0081175012444861">
<label>16.</label>
<p>We could also apply our method to <italic>y</italic>-standardization, but this would be redundant because the predicted logit index in either of the full models (with <italic>z</italic> or residualized <italic>z</italic>) is identical.</p>
</fn>
<fn fn-type="other" id="fn17-0081175012444861">
<label>17.</label>
<p>NELS88 is a sample of students who were in the 8th grade in 1988 and who were reinterviewed in 1990, 1992, 1994, and 2000. We have relevant background information and information on the educational careers of the students. For a full description of the variables used in this example, see <xref ref-type="bibr" rid="bibr9-0081175012444861">Curtin et al. (2002)</xref>.</p>
</fn>
<fn fn-type="other" id="fn18-0081175012444861">
<label>18.</label>
<p>Parental education is coded in seven ordered categories. To keep the example simple, we include father’s and mother’s education as continuous covariates, although a dummy-specification might have given a more precise picture of the relationship with the outcome variable.</p>
</fn>
<fn fn-type="other" id="fn19-0081175012444861">
<label>19.</label>
<p>These tests are in reading, mathematics, science, and history. The variables are provided in the public use version of NELS88. The eigenvalue decomposition revealed one factor accounting for 78.1% of the total variation in the four items.</p>
</fn>
<fn fn-type="other" id="fn20-0081175012444861">
<label>20.</label>
<p>We use the user-written <italic>margeff</italic> command in Stata to calculate the APEs (<xref ref-type="bibr" rid="bibr4-0081175012444861">Bartus 2005</xref>). One reviewer noted that earlier versions of <italic>margeff</italic> suffered from errors. We have used the most recent version. Moreover, using Stata version 11 command <italic>margins</italic> returns identical results.</p>
</fn>
<fn fn-type="other" id="fn21-0081175012444861">
<label>21.</label>
<p>This happens when both <italic>y*</italic> and <italic>x, y*</italic> and <italic>z</italic>, and <italic>x</italic> and <italic>z</italic> are all positively correlated. For example, when <italic>y*</italic> is passing an educational threshold, <italic>x</italic> is some parental background characteristic, and <italic>z</italic> is cognitive ability.</p>
</fn>
</fn-group>
</notes>
<bio>
<title>Bios</title>
<p><bold>Kristian Bernt Karlson</bold> is a PhD student at SFI - The Danish National Centre for Social Research and the Department of Education, Aarhus University. He works in the areas of social stratification and mobility research with particular interest in the modeling of discrete choice processes.</p>
<p><bold>Anders Holm</bold> is professor in quantitative methods at the Department of Education, Aarhus University. He holds a PhD in economics and works in the areas of sociology of education, industrial relations, and micro econometrics. He has previously published in <italic>Social Science Research, Sociological Methods and Research</italic>, and <italic>Research in Social Stratification and Mobility.</italic></p>
<p><bold>Richard Breen</bold> is professor of Sociology and Co-Director of the Center for the Study of Inequality and the Life Course at Yale University. Recent papers have appeared in <italic>American Journal of Sociology, European Sociological Review</italic>, and <italic>Sociological Methods and Research.</italic>
</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Agresti</surname><given-names>Alan</given-names></name>
</person-group>. <year>2002</year>. <source>Categorical Data Analysis</source>. <edition>2nd ed</edition>. <publisher-loc>New Jersey</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr2-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Allison</surname><given-names>Paul D.</given-names></name>
</person-group> <year>1999</year>. “<article-title>Comparing Logit and Probit Coefficients Across Groups</article-title>.” <source>Sociological Methods and Research</source> <volume>28</volume>(<issue>3</issue>):<fpage>186</fpage>–<lpage>208</lpage>.</citation>
</ref>
<ref id="bibr3-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Amemiya</surname><given-names>Takeshi</given-names></name>
</person-group> <year>1975</year>. “<article-title>Qualitative Response Models</article-title>.” <source>Annals of Economic and Social Measurement</source> <volume>4</volume>:<fpage>363</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr4-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bartus</surname><given-names>Tamás</given-names></name>
</person-group>. <year>2005</year>. “<article-title>Estimation of Marginal Effects Using</article-title> <source>margeff</source>.” <source>Stata Journal</source> <volume>5</volume>(<issue>3</issue>):<fpage>309</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr5-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Blalock</surname><given-names>Hubert M.</given-names></name>
</person-group> <year>1979</year>. <source>Social Statistics</source>. <edition>2nd ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</citation>
</ref>
<ref id="bibr6-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clogg</surname><given-names>Clifford C.</given-names></name>
<name><surname>Petkova</surname><given-names>Eva</given-names></name>
<name><surname>Haritou</surname><given-names>Adamantios</given-names></name>
</person-group>. <year>1995</year>. “<article-title>Statistical Methods for Comparing Regression Coefficients between Models</article-title>.” <source>American Journal of Sociology</source> <volume>100</volume>(<issue>5</issue>):<fpage>1261</fpage>–<lpage>93</lpage>.</citation>
</ref>
<ref id="bibr7-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cramer</surname><given-names>J. S.</given-names></name>
</person-group> <year>2003</year>. <article-title>Logit Models. From Economics and Other Fields</article-title>. <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr8-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cramer</surname><given-names>J. S.</given-names></name>
</person-group> <year>2007</year>. “<article-title>Robustness of Logit Analysis: Unobserved Heterogeneity and Mis-specified Disturbances</article-title>.” <source>Oxford Bulletin of Economics and Statistics</source> <volume>69</volume>(<issue>4</issue>):<fpage>545</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr9-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Curtin</surname><given-names>Thomas R.</given-names></name>
<name><surname>Ingels</surname><given-names>Steven J.</given-names></name>
<name><surname>Wu</surname><given-names>Shiying</given-names></name>
<name><surname>Heuer</surname><given-names>Ruth</given-names></name>
</person-group>. <year>2002</year>. <source>User’s Manual. National Education Longitudinal Study of 1988: Base-Year to Fourth Follow-up Data File User’s Manual (NCES 2002–323)</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Department of Education, National Center for Education Statistics</publisher-name>.</citation>
</ref>
<ref id="bibr10-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Goldberger</surname><given-names>Arthur S.</given-names></name>
</person-group> <year>1991</year>. <source>A Course in Econometrics</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Chapman and Hall</publisher-name>.</citation>
</ref>
<ref id="bibr11-0081175012444861">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Hoetker</surname><given-names>Glenn</given-names></name>
</person-group>. <year>2004</year>. “<article-title>Confounded Coefficients: Accurately Comparing Logit and Probit Coefficients across Groups</article-title>.” Working paper <fpage>03</fpage>-<lpage>0100</lpage>. College of Business Working Papers, <publisher-name>University of Illinois at Urbana-Champaign</publisher-name>.</citation>
</ref>
<ref id="bibr12-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hoetker</surname><given-names>Glenn</given-names></name>
</person-group> <year>2007</year>. “<article-title>The Use of Logit and Probit Models in Strategic Management Research: Critical Issues</article-title>.” <source>Strategic Management Journal</source> <volume>28</volume>(<issue>4</issue>):<fpage>331</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr13-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kendall</surname><given-names>Patricia</given-names></name>
<name><surname>Lazarsfeld</surname><given-names>Paul L.</given-names></name>
</person-group> <year>1950</year>. “<article-title>Problems of Survey Analysis</article-title>.” Pp. <fpage>133</fpage>–<lpage>96</lpage> in <source>Continuities in Social Research</source>, edited by <person-group person-group-type="editor">
<name><surname>Merton</surname><given-names>Robert K.</given-names></name>
<name><surname>Lazarsfeld</surname><given-names>Paul L.</given-names></name>
</person-group> <publisher-loc>Glencoe, IL</publisher-loc>: <publisher-name>Free Press</publisher-name>.</citation>
</ref>
<ref id="bibr14-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lazarsfeld</surname><given-names>Paul L.</given-names></name>
</person-group> <year>1955</year>. “<article-title>The Interpretation of Statistical Relations as a Research Operation</article-title>.” Pp. <fpage>115</fpage>–<lpage>25</lpage> in <source>The Language of Social Research</source>, edited by <person-group person-group-type="editor">
<name><surname>Lazarsfeld</surname><given-names>Paul L.</given-names></name>
<name><surname>Rosenberg</surname><given-names>Morris</given-names></name>
</person-group>. <publisher-loc>Glencoe, IL</publisher-loc>: <publisher-name>Free Press</publisher-name>.</citation>
</ref>
<ref id="bibr15-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lazarsfeld</surname><given-names>Paul L.</given-names></name>
</person-group> <year>1958</year>. “<article-title>Evidence and Inference in Social Research</article-title>.” <source>Daedalus</source> <volume>87</volume>(<issue>4</issue>):<fpage>99</fpage>–<lpage>130</lpage>.</citation>
</ref>
<ref id="bibr16-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Long</surname><given-names>J. Scott</given-names></name>
</person-group> <year>1997</year>. <source>Regression Models for Categorical and Limited Dependent Variables</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr17-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Long</surname><given-names>J. Scott</given-names></name>
<name><surname>Freese</surname><given-names>Jeremy</given-names></name>
</person-group>. <year>2005</year>. <source>Regression Models for Categorical Dependent Variables Using Stata</source>. <edition>2nd ed</edition>. <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>Stata Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Maddala</surname><given-names>G. S.</given-names></name>
</person-group> <year>1983</year>. <source>Limited-dependent Variables and Qualitative Variables in Economics</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr19-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McKelvey</surname><given-names>Richard D.</given-names></name>
<name><surname>Zavoina</surname><given-names>William</given-names></name>
</person-group>. <year>1975</year>. “<article-title>A Statistical Model for the Analysis of Ordinal Level Dependent Variables</article-title>.” <source>Journal of Mathematical Sociology</source> <volume>4</volume>(<issue>1</issue>):<fpage>103</fpage>–<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr20-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mood</surname><given-names>Carina</given-names></name>
</person-group>. <year>2010</year>. “<article-title>Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do about It</article-title>.” <source>European Sociological Review</source> <volume>26</volume>(<issue>1</issue>):<fpage>67</fpage>–<lpage>82</lpage>.</citation>
</ref>
<ref id="bibr21-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Powers</surname><given-names>Daniel A.</given-names></name>
<name><surname>Xie</surname><given-names>Yu</given-names></name>
</person-group>. <year>2000</year>. <source>Statistical Methods for Categorical Data Analysis</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>Herbert A.</given-names></name>
</person-group> <year>1954</year>. “<article-title>Spurious Correlation: A Causal Interpretation</article-title>.” <source>Journal of the American Statistical Association</source> <volume>49</volume>(<issue>267</issue>):<fpage>467</fpage>–<lpage>79</lpage>.</citation>
</ref>
<ref id="bibr23-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sobel</surname><given-names>Michael E.</given-names></name>
</person-group> <year>1982</year>. “<article-title>Asymptotic Confidence Intervals for Indirect Effects in Structural Equation Models</article-title>.” Pp. <fpage>290</fpage>–<lpage>312</lpage> in <source>Sociological Methodology</source>, <volume>vol. 13</volume>, edited by <person-group person-group-type="editor">
<name><surname>Leinhardt</surname><given-names>Samuel</given-names></name>
</person-group>. <publisher-loc>San Francisco</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr24-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sobel</surname><given-names>Michael E.</given-names></name>
</person-group> <year>1987</year>. “<article-title>Direct and Indirect Effects in Linear Structural Equation Models</article-title>.” <source>Sociological Methods and Research</source> <volume>16</volume>(<issue>1</issue>):<fpage>155</fpage>–<lpage>76</lpage>.</citation>
</ref>
<ref id="bibr25-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Turner</surname><given-names>Robert W.</given-names></name>
<name><surname>Rockel</surname><given-names>Mark L.</given-names></name>
</person-group> <year>1988</year>. “<article-title>Estimating Covariances of Parameter Estimates from Different Models</article-title>.” <source>Economics Letters</source> <volume>26</volume>(<issue>2</issue>): <fpage>137</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr26-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>White</surname><given-names>Halbert</given-names></name>
</person-group>. <year>1982</year>. “<article-title>Maximum Likelihood Estimation of Misspecified Models</article-title>.” <source>Econometrica</source> <volume>50</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr27-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Williams</surname><given-names>Richard</given-names></name>
</person-group>. <year>2009</year>. “<article-title>Using Heterogeneous Choice Models to Compare Logit and Probit Coefficients across Groups</article-title>.” <source>Sociological Methods and Research</source> <volume>37</volume>(<issue>4</issue>):<fpage>531</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr28-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Winship</surname><given-names>Christopher</given-names></name>
<name><surname>Mare</surname><given-names>Robert D.</given-names></name>
</person-group> <year>1984</year>. “<article-title>Regression Models with Ordinal Variables</article-title>.” <source>American Sociological Review</source> <volume>49</volume>(<issue>4</issue>):<fpage>512</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr29-0081175012444861">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wooldridge</surname><given-names>Jeffrey M.</given-names></name>
</person-group> <year>2002</year>. <source>Econometric Analysis of Cross Section and Panel Data</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr30-0081175012444861">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yatchew</surname><given-names>Adonis</given-names></name>
<name><surname>Griliches</surname><given-names>Zvi</given-names></name>
</person-group>. <year>1985</year>. “<article-title>Specification Error in Probit Models</article-title>.” <source>Review of Economics and Statistics</source> <volume>67</volume>(<issue>1</issue>):<fpage>134</fpage>–<lpage>39</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>