<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">GCQ</journal-id>
<journal-id journal-id-type="hwp">spgcq</journal-id>
<journal-title>Gifted Child Quarterly</journal-title>
<issn pub-type="ppub">0016-9862</issn>
<issn pub-type="epub">1934-9041</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0016986211424132</article-id>
<article-id pub-id-type="publisher-id">10.1177_0016986211424132</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Methodological Brief</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Examining Relationships and Effects in Gifted Education Research</article-title>
<subtitle>An Introduction to Structural Equation Modeling</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Adelson</surname><given-names>Jill L.</given-names></name>
<xref ref-type="aff" rid="aff1-0016986211424132">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0016986211424132"><label>1</label>University of Louisville, Louisville, KY, USA</aff>
<author-notes>
<corresp id="corresp1-0016986211424132">Jill L. Adelson, Department of Educational and Counseling Psychology, University of Louisville, Louisville, KY 40292, USA Email: <email>jill.adelson@louisville.edu</email></corresp>
<fn fn-type="other" id="bio1-0016986211424132">
<p>Jill L. Adelson, PhD, is an assistant professor in the Educational Psychology, Measurement, and Evaluation program, which is housed in the Department of Educational and Counseling Psychology at the University of Louisville. Her research involves applying and studying advanced methodologies, such as hierarchical linear modeling, structural equation modeling, and propensity score analysis. Her substantive interests include the effects of gifted programming, the talent development of mathematically talented elementary students, and attitudes toward mathematics.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>56</volume>
<issue>1</issue>
<fpage>47</fpage>
<lpage>55</lpage>
<permissions>
<copyright-statement>© 2012 National Association for Gifted Children</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">National Association for Gifted Children</copyright-holder>
</permissions>
<abstract>
<p>The aim of this Methodological Brief to structural equation modeling (SEM) is to help readers become more aware of its uses and how to understand research using it. SEM provides many benefits over traditional multiple regression, including the ability to model multiple outcomes simultaneously and to account for measurement error. This Brief provides a general overview of the purposes of SEM and reviews how SEM can estimate models with both observed variables as well as their underlying constructs and how the adequacy of models is assessed in SEM. Finally, this Brief introduces path diagrams and latent variable models with an illustration of how to understand diagrams and standardized estimates.</p>
</abstract>
<kwd-group>
<kwd>structural equation modeling</kwd>
<kwd>confirmatory factor analysis</kwd>
<kwd>latent constructs</kwd>
<kwd>measurement error</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>In this Methodological Brief, Dr. Jill Adelson introduces the reader to structural equation modeling (SEM). SEM is a statistical technique that combines elements of traditional multivariate models (e.g., regression analysis, factor analysis, path analysis). One of the strengths of SEM is the ability to account for less than perfect reliability for observed variables, a common occurrence in the field of gifted education and other social sciences. Happy modeling!</p>
<p><disp-quote>
<attrib>Tonya R. Moon, PhD</attrib>
<attrib><italic>Editor, Methodological Briefs</italic></attrib>
</disp-quote></p>
<p>What is giftedness? Is it a score on an IQ test?; a rating from a parent or teacher?; a nomination from a peer?; or a score on a portfolio? Although the field does not have a universal definition of giftedness, there is general agreement that the measures used to identify giftedness all have limitations but collectively measure different yet related aspects of the construct of giftedness. That is, each indicator of giftedness used has flaws and does not fully represent giftedness, the construct of interest for identification. Many, including <xref ref-type="bibr" rid="bibr11-0016986211424132">Johnsen (2009)</xref> and <xref ref-type="bibr" rid="bibr17-0016986211424132">Pfeiffer (2002)</xref>, advocate for the use of multiple measures, such as teacher rating scales, achievement tests, and nonverbal intelligence tests, to identify gifted children and acknowledge that there is no perfect indicator of giftedness. However, traditional statistical techniques such as multiple regression allow for only one outcome measure (or one score created by combining other scores). Moreover, multiple regression requires the assumption that the predictors are perfectly reliable, that is, that it is measured without error. However, no measure is perfectly reliable, and the degree to which there is measurement error affects the observed relationships between the measure and other variables, such as achievement, aptitude, and creativity. As such, just as practitioners ideally want to use multiple measures for identification, researchers ideally want to use multiple measures of giftedness within the same study to better assess the construct. In doing so, it is important to use statistical procedures to adequately estimate how the gestalt of these multiple measures of giftedness relates to other constructs, such as academic self-perceptions or motivation.</p>
<p>The following scenario illustrates this problem with measurement error and single measures in research on giftedness. A researcher is studying how giftedness relates to creativity. Using an IQ test as a measure of giftedness and a score from a flexibility scale as a measure of creativity, she might find that they have a small relationship (i.e., <italic>r</italic> = .15). However, both the IQ score and the flexibility score were measured with error and are not perfect indicators of giftedness or of creativity. Moreover, the researcher is not actually interested in the IQ score or the flexibility score but rather in the latent (i.e., not directly measurable or observable) constructs of giftedness and creativity that underlie the observations. Rather than using traditional regression, the researcher does have another option—she can use structural equation modeling (SEM), which allows the use of multiple indicators of a construct and accounts for measurement error in each of them. For instance, to study the relationship between giftedness and creativity, the researcher might use a traditional IQ score, a nonverbal IQ score, a teacher rating scale score (such as the Motivation score on the <italic>Scales for Rating the Behavioral Characteristics of Superior Students</italic>), an achievement test score, and whether the student was previously identified as gifted by the school district as measures of giftedness. Then, she might use the flexibility, fluency, originality, and elaboration scores from a creativity test as well as expert ratings on a portfolio as indicators of creativity. Because she is using multiple measures of her latent constructs (i.e., the multiple scores indicating giftedness and creativity) and is accounting for the fact that each of the indicators was measured with error, she might find that they actually have a moderate relationship (i.e., <italic>r</italic> = .34) as (a) the measurement error does not obscure the true relationship among the constructs and (b) she is better modeling the true constructs in which she is interested rather than simply two specific indicators of them.</p>
<p>The research scenario above is not uncommon in the field of gifted education. Typically, researchers are interested in latent constructs, such as giftedness, creativity, ability, academic self-perceptions, and intelligence, which are not directly observable or measureable. Rather than observing or measuring a latent construct directly, researchers use multiple items on a measure that are purported to assess the construct or, ideally, have multiple measures of each construct. In contrast to multiple regression, SEM allows the use of multiple indicators, whether they are overall scores on multiple assessments or multiple items from the same assessment. Thus, researchers are able to distinguish between observed variables (e.g., the scores or the items) and the underlying constructs (e.g., giftedness or creativity). Furthermore, researchers can examine the relationships, including the causes and effects, of these latent constructs rather than a single proxy of the constructs. Because SEM corrects for the unreliability within the measured variables, it allows for more accurate estimates of the relationships between these constructs. That is, SEM, in general, reduces the overall effect of measurement error of any individual observed variable on the accuracy of the results.</p>
<p>As alluded to above, SEM can be used with multiple assessments and also with multiple items of a scale. One benefit to this is that SEM accounts for the measurement error in each item or assessment. Additionally, SEM allows the items to relate differentially to the latent construct or factor. These latent constructs are similar to factors from an exploratory factor analysis. We know that items load on a factor or scale differentially (e.g., Item 1 may correlate with the total scale at <italic>r</italic> = .88, whereas Item 2 may correlate with the total scale at <italic>r</italic> = .38). The issue is whether these items should be allowed to have equal weight on the total scale score. Unlike the sum or average score for a scale score, which typically gives items an equal weight, in SEM each item can have different weights on the latent construct or factor.</p>
<sec id="section1-0016986211424132">
<title>Uses of Structural Equation Modeling in Research</title>
<p>SEM is a family of techniques that explore the relationships among variables by analyzing their covariances. The researcher must specify the hypothesized relationships among the set of variables, whether they are latent (unobservable constructs, such as giftedness or creativity) or observed (e.g., score on an IQ test or Likert-type response for an item of a scale). Using SEM, researchers can test a range of models. For instance, a researcher may hypothesize a model prior to conducting the analysis and then examine how well the data fit that model. Among the many types of analyses for which SEM can be used are the following: (a) examinations of patterns of interrelationships among variables (e.g., whether an achievement test with eight subscales measures one overarching construct—academic achievement, or two distinct but related constructs—mathematics achievement and language achievement); (b) mediation effects, including the direct, indirect, and total effects of the variables (e.g., whether teachers’ preparation to teach gifted students affects the average class achievement directly or if it does so indirectly through the challenging curriculum that the teacher chooses); (c) comparisons of groups (e.g., whether an academic self-efficacy scale functions similarly for students in a gifted program and students not in a gifted program); (d) modeling of latent means (e.g., whether those students in or not in a gifted program differ in their average academic self-efficacy, rather than on a single score that includes error); or (e) examinations of change over time (e.g., what the rate of language acquisition is in verbally precocious children from age 3 to 5 years). In gifted education research, SEM may be especially useful as many of the constructs of interest, such as giftedness, talent, and creativity, are unobservable constructs that may have multiple measures or indicators.</p>
</sec>
<sec id="section2-0016986211424132">
<title>Types of Variables in Structural Equation Modeling</title>
<p>Researchers typically are interested in <italic>latent constructs</italic> or variables that cannot be directly measured. For instance, although the field is interested in giftedness, we cannot measure it directly but must use indicators of the construct that, based on psychometric characteristics of the indicators, we believe assess giftedness. As such, latent constructs, such as giftedness, require a specific operational definition, and in SEM, researchers must select indicators of the construct. Ideally, the researcher has at least two if not three or more indicators of each construct of interest (<xref ref-type="bibr" rid="bibr12-0016986211424132">Kline, 2010</xref>). The primary benefit of SEM is that researchers can conduct statistical analyses of the latent constructs that they are actually interested in (such as giftedness) rather than the <italic>observed variables</italic> that they measured (such as IQ score, aptitude score, or scores for items on a rating scale). As such, based on the observed variables or measured items, researchers can examine both the effects of latent constructs on other variables and the causes of latent constructs. In this way, SEM accounts for measurement error, which is inevitable in all measures or observations.</p>
<p>SEM also has its own terminology. In particular, SEM researchers refer to endogenous and exogenous variables. <italic>Endogenous variables</italic> are effect variables. That is, there are other variables in the model that predict endogenous variables. An endogenous variable can cause other variables in the model, but the key here is that there is another variable in the model predicting them. For instance, if academic self-perceptions in middle school affects achievement in high school (see the top portion of <xref ref-type="fig" rid="fig1-0016986211424132">Figure 1</xref>), then achievement is an endogenous variable because it is the effect of academic self-perceptions. If we have a model in which academic self-perceptions in middle school affects achievement in high school which affects achievement in college (see the bottom portion of <xref ref-type="fig" rid="fig1-0016986211424132">Figure 1</xref>), then achievement in high school is still endogenous. Even though it is causing later achievement, because it is the effect of prior academic self-perceptions, it is considered an endogenous variable. Similarly, college achievement (the effect of high school achievement) also would be an endogenous variable. On the other hand, middle school academic self-perceptions is a causal variable only. The variation in school academic self-perceptions is outside the model; in this model, there are no variables predicting academic self-perceptions. Thus, academic self-perceptions is considered an <italic>exogenous variable</italic>, a variable that is <italic>only</italic> a cause. Each endogenous variable in SEM has a <italic>disturbance term</italic>, which is like an “error” term or residual. Disturbances are the sum of <italic>all</italic> unexplained effects, including measurement error and causes that are unspecified in the model. For instance, high school achievement might also be caused by number of hours spent studying. Additionally, high school achievement is not measured without measurement error. Thus, the disturbance captures the unexplained variability in the endogenous variable.</p>
<fig id="fig1-0016986211424132" position="float">
<label>Figure 1.</label>
<caption>
<p>An illustration of two research questions with exogenous variables (i.e., those that are causes only) and endogenous variables (i.e., those that are effects) labeled</p>
</caption>
<graphic xlink:href="10.1177_0016986211424132-fig1.tif"/>
</fig>
</sec>
<sec id="section3-0016986211424132">
<title>Reading a Path Diagram</title>
<p>There are four standard symbols in a path diagram, as shown in <xref ref-type="fig" rid="fig2-0016986211424132">Figure 2</xref>. A rectangle indicates an observed variable (e.g., the score on an assessment or the Likert-type rating on an item) while a circle indicates a latent variable (i.e., the factor or construct). Because disturbances are unobserved, they are considered latent variables and are represented by a circle, similar to latent constructs. Therefore, as shown in <xref ref-type="fig" rid="fig3-0016986211424132">Figure 3</xref>, the illustration of endogenous and exogenous variables presented above would also include circles to represent the disturbances for the endogenous variables. A single-headed arrow indicates a causal path, and a double-headed curved arrow indicates a correlation, or covariance path.</p>
<fig id="fig2-0016986211424132" position="float">
<label>Figure 2.</label>
<caption>
<p>Standard symbols in path diagrams</p>
</caption>
<graphic xlink:href="10.1177_0016986211424132-fig2.tif"/>
</fig>
<fig id="fig3-0016986211424132" position="float">
<label>Figure 3.</label>
<caption>
<p>A path diagram example indicating the disturbances (<italic>d1</italic> and <italic>d2</italic>) for each endogenous variable</p>
</caption>
<graphic xlink:href="10.1177_0016986211424132-fig3.tif"/>
</fig>
</sec>
<sec id="section4-0016986211424132">
<title>Assessing Model Fit</title>
<p>Consider the following research scenario. High school students complete a survey with six items: (1) “I enjoy challenging classes,” (2) “I cannot do well in challenging classes,” (3) “I look forward to classes that challenge me,” (4) “I excel in classes that are considered challenging,” (5) “I am able to succeed in challenging classes,” and (6) “I dread being in challenging classes.” Based on prior research and the literature on measuring attitudes, the research team hypothesizes several possible theoretical constructs that these items measure. Researcher A proposes a model with Items 1, 3, and 6 measuring Enjoyment of Challenging Classes and Items 2, 4, and 5 measuring Self-Beliefs Regarding Challenging Classes (see <xref ref-type="fig" rid="fig4-0016986211424132">Figure 4</xref>, Model A). Researcher B proposes a model in which Items 1, 3, 4, and 5 measure Positive Attitudes Toward Challenging Classes and Items 2 and 6 measure Negative Attitudes Toward Challenging Classes (see <xref ref-type="fig" rid="fig4-0016986211424132">Figure 4</xref>, Model B). Finally, Researcher C proposes a model in which there is only one overarching construct, Attitudes Toward Challenging Classes (see <xref ref-type="fig" rid="fig4-0016986211424132">Figure 4</xref>, Model C). After collecting data from 500 high school students, each researcher wants to determine how consistent his or her model is with the data (i.e., how well the model “fits” the data), and then the researchers want to compare how well each of these hypothesized models fits the data.</p>
<fig id="fig4-0016986211424132" position="float">
<label>Figure 4.</label>
<caption>
<p>Three hypothesized models based on prior research and literature to explain relationships among six survey items</p>
</caption>
<graphic xlink:href="10.1177_0016986211424132-fig4.tif"/>
</fig>
<p>These researchers are following the steps recommended by <xref ref-type="bibr" rid="bibr12-0016986211424132">Kline (2010)</xref>. First, they specified their models, selected measures, and collected data. Before interpreting the estimates, they need to check whether the model fit is adequate. In this case, they will check the model fit of the three models, determining if any of the models have adequate model fit without respecification.</p>
<p>In SEM, how well the model fits the data (i.e., the degree that it can reproduce the correlations between variables in the observed data) is examined through model fit indexes. The goal of SEM is to specify a model to test a theory, <italic>not to find a model that fits the data best</italic>. For instance, each member of the research team above has a theory about the constructs being measured and wants to test his or her theory. However, just because statistics would suggest a different “better” fitting model, it is not advisable for them to follow those adjustments blindly as statistics is not a substitute for theory. For instance, if the statistics suggested a model in which Item 1 caused Item 2 and Item 2 caused a latent construct indicated by Items 3 to 6, accepting that model would be poor science as the researchers did not have a theory or prior literature suggesting that model. When testing model fit, researchers have a multitude of fit indexes available to them. Following is an introduction to a few of the most commonly used indexes (for further details, see <xref ref-type="bibr" rid="bibr10-0016986211424132">Hu &amp; Bentler, 1999</xref>; <xref ref-type="bibr" rid="bibr12-0016986211424132">Kline, 2010</xref>; <xref ref-type="bibr" rid="bibr15-0016986211424132">Marsh, Hau, &amp; Wen, 2004</xref>).</p>
<p>One common measure of model fit is the model chi-square (χ<sup>2</sup>; also known as the likelihood ratio chi-square or the generalized likelihood ratio). When researchers define a model in SEM, they are implying certain relationships among variables. Some variable pairs have direct relationships, others have indirect relationships, and yet others have no correlation. These specified relationships are known as the model-implied variance–covariance matrix. The χ<sup>2</sup> statistic compares this model-implied variance–covariance matrix with the relationships that are actually observed in the data, known as the data variance–covariance matrix. If the model fits well, these two matrices should be consistent (equal), which is the null hypothesis. Therefore, failure to reject the null hypothesis indicates consistent model fit. However, the χ<sup>2</sup> test is affected by multivariate nonnormality and penalizes studies with larger sample sizes, larger correlations, and more indicators (<xref ref-type="bibr" rid="bibr12-0016986211424132">Kline, 2010</xref>). Particularly because of this sensitivity, there has been some debate about the utility of the χ<sup>2</sup> test, especially with samples sizes greater than 10,000, despite its widespread use (see the special issue of <italic>Personality and Individual Differences</italic> [<xref ref-type="bibr" rid="bibr20-0016986211424132">Vernon &amp; Eysenck, 2007]</xref> for more information on the debate in SEM about assessing model fit). Besides being commonly reported as a model fit index, the χ<sup>2</sup> statistic is also used to compare a simpler model with a more complex model (i.e., nested models; see below for more information).</p>
<p>Incremental, or comparative, fit indexes provide an indication of the relative improvement in model fit compared with a statistical baseline model, which typically is the null model and assumes no covariances between observed variables. In other words, incremental or comparative fit indexes indicate how well the model fits the data compared with the worst model possible. The Tucker–Lewis index (TLI; also known as the NNFI) and the comparative fit index (CFI) are incremental fit indexes that take into account the complexity in the model (i.e., the number of estimated parameters relative to the number of observed variances and covariances). Both types of indexes range from 0 to 1, with researchers desiring a minimum value of at least .90 (<xref ref-type="bibr" rid="bibr1-0016986211424132">Bentler &amp; Bonett, 1980</xref>; <xref ref-type="bibr" rid="bibr15-0016986211424132">Marsh et al., 2004</xref>) but oftentimes preferring a value greater than .95 (<xref ref-type="bibr" rid="bibr10-0016986211424132">Hu &amp; Bentler, 1999</xref>). When comparing two models, greater CFI and TLI values are preferred.</p>
<p>Parsimony-adjusted indexes penalize for model complexity through a built-in correction for additional parameters. If two models fit the data similarly, parsimony-adjusted indexes generally favor the simpler model (e.g., the one with more degrees of freedom, or less paths). The root mean square error of approximation (RMSEA) is a commonly used parsimony-adjusted index that both estimates the amount of error of approximation per model degree of freedom and takes into account the sample size. Whereas the TLI and CFI may be considered “goodness-of-fit” indexes, with greater values indicating better model fit, the RMSEA may be considered a “badness-of-fit” index, with greater values indicating worse model fit. An RMSEA of 0 indicates the best fit, and there is no upper limit to the RMSEA index. The RMSEA performs particularly well with larger numbers of indicators. Ideally, researchers desire an RMSEA of 0 with values less than .05 being considered good. RMSEA values from .05 to .08 are generally considered okay, and some researchers (e.g., <xref ref-type="bibr" rid="bibr13-0016986211424132">MacCallum, Browne, &amp; Sugawara, 1996</xref>) consider values of .08 to .10 to be marginal. In general, RMSEA values greater than .10 are considered to indicate bad model fit (<xref ref-type="bibr" rid="bibr3-0016986211424132">Browne &amp; Cudeck, 1993</xref>).</p>
<sec id="section5-0016986211424132">
<title>Comparing Models</title>
<p>Besides examining the fit of a single model, another common use of the χ<sup>2</sup> statistic is to compare nested models using the χ<sup>2</sup> difference test. Two models are nested if one is a more complicated version of another (assuming same sample and variables), that is, one model can be created by only adding (not adding <italic>and</italic> subtracting) paths<sup><xref ref-type="fn" rid="fn1-0016986211424132">1</xref></sup> to the other model. For instance, <xref ref-type="bibr" rid="bibr7-0016986211424132">Gridley (2002)</xref> used confirmatory factor analysis, a procedure used to determine how well indicators measure constructs, to reexamine previously published data of measures drawn from Gardner’s theory of multiple intelligences. Among the models she compared were a previously investigated model with four constructs (linguistic verbal intelligence, logical–mathematical intelligence, spatial-general intelligence, and spatial-tangrams intelligence) that were not correlated with one another and a model that allowed those four constructs to be correlated. To compare the relative fit of the two models, Gridley subtracted the smaller χ<sup>2</sup> (821.11) and its degrees of freedom (60) from the larger χ<sup>2</sup> (3190.55) and degrees of freedom (66), resulting in a change in χ<sup>2</sup> of 2,369.44 with 6 degrees of freedom, which was statistically significant, indicating that the more complex model—the one with the correlated constructs—is preferred.</p>
<p>However, the χ<sup>2</sup> difference test can only be done with nested models. <xref ref-type="bibr" rid="bibr7-0016986211424132">Gridley (2002)</xref> could not use the same test to compare the hypothesized model with a theoretical model suggesting four different constructs (spatial intelligences, logical–mathematical intelligences, linguistic intelligence, and interpersonal intelligence) as one model is not a more complex version of the other, created by only adding additional paths. One option for comparing nonnested models is to compare information criteria, such as the Akaike information criterion (AIC) or the Bayesian information criterion (BIC). Information criteria can only be used to indicate <italic>relative</italic> goodness (or badness) of fit, that is, to compare two models. The formulas for the AIC and BIC not only include the χ<sup>2</sup> statistic but also account for the number of parameters in the case of the AIC and the number of parameters and the sample size in the case of the BIC. Whichever model has the smaller AIC or BIC is the preferred model (<xref ref-type="bibr" rid="bibr12-0016986211424132">Kline, 2010</xref>; <xref ref-type="bibr" rid="bibr18-0016986211424132">Raftery, 1995</xref>). <xref ref-type="bibr" rid="bibr18-0016986211424132">Raftery (1995)</xref> suggests the following guidelines for interpreting the BIC difference regarding evidence favoring the more complex model: 0 to 2 = weak evidence, 2 to 6 = positive evidence, 6 to 10 = strong evidence, and &gt;10 = very strong evidence.</p>
</sec>
</sec>
<sec id="section6-0016986211424132">
<title>Analyzing a Path Model</title>
<p>Following are examples using data from the Early Childhood Longitudinal Study–Kindergarten Class of 1998-1999 (ECLS-K). These analyses are for pedagogical purposes, and readers should not make substantive inferences based on the results as considerations such as sampling weights and missing data are not taken into account and only a small number of the survey items are included. Data for 10,944 students who were observed in both Grade 3 and Grade 5 are used in this example. The variables in the model are achievement test scores for reading and mathematics that were scaled using item response theory and four items measuring students’ perceived competence in mathematics (taken from the ECLS-K adapted version of <xref ref-type="bibr" rid="bibr14-0016986211424132">Marsh’s [1992]</xref> Self-Description Questionnaire [SDQ]–I Perceived Interest/Competence in Mathematics). For the path models, the four items were summed together to create a perceived mathematics competence scale score.</p>
<p><xref ref-type="fig" rid="fig5-0016986211424132">Figure 5</xref> is an example of a path diagram, which includes only observed variables. Path analysis is similar to a traditional multiple regression; however, path diagrams are not limited to only one outcome. For instance, in <xref ref-type="fig" rid="fig5-0016986211424132">Figure 5</xref>, both Grade 5 math and Grade 5 math perceived competence are outcomes, with all the equations being estimated simultaneously. Grade 5 math is an observed variable as it is represented by a rectangle. Furthermore, it is an exogenous variable as it causes another variable but is not an effect itself. Similarly, Grade 3 reading and Grade 3 math perceived competence (the sum of scores on the four items) are observed exogenous variables. As in traditional multiple regression analyses, these three variables are correlated with one another, as indicated by the curved double-headed arrows. Single-headed arrows go from these exogenous variables to their effects, Grade 5 math and Grade 5 math perceived competence, which are endogenous observed variables. The two circles (d1 and d2) represent disturbances, the unexplained variance in the endogenous variables, Grade 5 math and Grade 5 math perceived competence, respectively. The unexplained variance in these variables may be because of variables that were not included in the model (such as parental support) or because of measurement error.</p>
<fig id="fig5-0016986211424132" position="float">
<label>Figure 5.</label>
<caption>
<p>Path model with three observed exogenous variables (Grade 3 math, Grade 3 math perceived competence, Grade 3 reading) and two observed endogenous variables (Grade 5 math and Grade 5 math perceived competence)</p>
<p><italic>Note</italic>. <italic>d1</italic> and <italic>d2</italic> represent both the unexplained variance and the measurement error variance in the endogenous variables. Standardized estimates are shown (correlations for double-headed errors, and standardized regression weights for single-headed arrows).</p>
<p><italic>**p</italic> &lt; .01. ***<italic>p</italic> &lt; .001.</p>
</caption>
<graphic xlink:href="10.1177_0016986211424132-fig5.tif"/>
</fig>
<p>The numbers presented in <xref ref-type="fig" rid="fig5-0016986211424132">Figure 5</xref> are the standardized estimates for this path model. For the double-headed arrows, standardized estimates are correlations. The strongest relationship is between Grade 3 math and Grade 3 reading scores (<italic>r</italic> = .73). There is a small correlation between Grade 3 math and Grade 3 math perceived competence scores (<italic>r</italic> = .22), and a very small correlation between Grade 3 reading and Grade 3 math perceived competence (<italic>r</italic> = .03). The standardized estimates on the single-headed arrows are standardized regression weights, similar to beta weights in traditional multiple regression. For instance, after accounting for the other variables in the model, for a 1 standard deviation increase on the Grade 3 math assessment, students are predicted to have a 0.77 standard deviation increase on the Grade 5 math assessment. In other words, students with higher achievement in Grade 3 tend to have higher achievement in Grade 5 as well. Although Grade 3 achievement has a small effect on perceived competence in Grade 5 (0.28), we find that perceived competence in Grade 3 has almost no effect on Grade 5 achievement (0.03), after controlling for other variables in the model.</p>
<p>Because there are no latent constructs in a path model, many researchers do not report model fit indexes for path analysis; however, they are reported here for pedagogical reasons. The χ<sup>2</sup> value for this model was 322.79, with 2 degrees of freedom, which is statistically significant (<italic>p</italic> &lt; .001). Given the large sample size, it is not unusual to reject the null hypothesis. The CFI for this model was .99, which is above the ideal of .95, and the TLI was .94, which is less than ideal although acceptable. Finally, the RMSEA is .12 with a 90% confidence interval from 0.11 to 0.13, which indicates poor model fit. This illustrates the need to report multiple fit indexes to get a better overall picture of the goodness (or badness) of fit of the model. Although there is some positive indication of model fit, the RMSEA in particular might suggest that the researcher consider an alternative model based on theory to explain the relationships among these variables. In fact, researchers should ideally consider at least one alternative model in addition to the hypothesized based on theory (<xref ref-type="bibr" rid="bibr12-0016986211424132">Kline, 2010</xref>; <xref ref-type="bibr" rid="bibr19-0016986211424132">Robert &amp; Pashler, 2000</xref>). The lack of clarity in this situation highlights the need to test multiple models.</p>
</sec>
<sec id="section7-0016986211424132">
<title>Analyzing a Latent Variable Model</title>
<p>As previously mentioned, the ECLS-K data set includes each student’s responses for the four items indicating perceived competence in mathematics. Rather than including the sum of the items as a measure of attitudes toward math (as typically is done in multiple regression), ignoring the measurement error inherent in each observation, we can include a latent variable representing perceived competence and use the four items as indicators. By doing so, we separate out the measurement error in the items, that is, the variance not explained by the common factor. Moreover, this allows the items to relate differentially to the factor. Rather than all items having a weight of 1 as we do when we create sum scores, items will have different weights on the latent construct.</p>
<p>As shown in <xref ref-type="fig" rid="fig6-0016986211424132">Figure 6</xref>, the rectangles for Grade 3 and Grade 5 math perceived competence have been replaced with circles. Now, these are latent, or unobserved, constructs. They are measured by the four items from the adapted SDQ, as indicated by the four single-headed arrows pointing to the SDQ rectangles, indicating the four observed items. Note that the arrows go from the latent constructs to the measured items. This indicates that one’s level of math perceived competence “causes” the response on the items. There are two unobserved “pieces” that explain each item: the math perceived competence factor and measurement error, which are indicated by the small circle with a single-headed arrow. The rest of the model remains the same as in the path model (<xref ref-type="fig" rid="fig5-0016986211424132">Figure 5</xref>). Because Grade 5 math perceived competence is an endogenous variable, caused by Grade 3 math score, reading score, and math perceived competence, it still has a latent construct for the unexplained variance (u1). This is different from the disturbance term in <xref ref-type="fig" rid="fig5-0016986211424132">Figure 5</xref>, the path diagram, as the measurement error has now been separated out from the measurement of the construct, as indicated by the errors for the eight items, meaning that this circle represents <italic>only</italic> the unexplained variance remaining in Grade 5 math perceived competence. As can be seen by the standardized estimates in <xref ref-type="fig" rid="fig5-0016986211424132">Figures 5</xref> and <xref ref-type="fig" rid="fig6-0016986211424132">6</xref>, for these models, the relationships are similar with latent and observed variables. Perhaps the most marked difference is the relationship between the two latent variables, Grade 3 math perceived competence and Grade 5 math perceived competence. Because of measurement error, the standardized regression weight in the path analysis was only .36. However, once measurement error was modeled and taken into account, the regression weight was estimated to be .43 in the structural equation model. The fit of this model is significantly better than the fit of the path model. The χ<sup>2</sup> (1363.08 with 39 degrees of freedom) is still statistically significant (<italic>p</italic> &lt; .001), as expected given the sample size. However, the CFI (.98) and the TLI (.97) both indicate good model fit, and the RMSEA is acceptable (.06 with a 90% confidence interval from 0.05 to 0.06). This model seems to fit the data reasonably well, although there may be other models that fit the data equally well or better.</p>
<fig id="fig6-0016986211424132" position="float">
<label>Figure 6.</label>
<caption>
<p>Structural equation model with two observed exogenous variables (Grade 3 math and Grade 3 reading), one latent exogenous variable (Grade 3 math perceived competence) that is measured by four observed items, one observed endogenous variables (Grade 5 math), and one latent endogenous variable (Grade 5 math perceived competence) that is measured by four observed items</p>
<p><italic>Note</italic>. Standardized estimates are shown (correlations for double-headed errors, and standardized regression weights for single-headed arrows). <italic>e1</italic> through <italic>e8</italic> represent the measurement error variance in the observed items, <italic>u1</italic> represents the unexplained variance in the latent construct, and <italic>d1</italic> represents both the unexplained variance and the error variance in the observed endogenous variable.</p>
<p>***<italic>p</italic> &lt; .001.</p>
</caption>
<graphic xlink:href="10.1177_0016986211424132-fig6.tif"/>
</fig>
</sec>
<sec id="section8-0016986211424132">
<title>Conclusions</title>
<p>Over the past decade, several articles in <italic>Gifted Child Quarterly</italic> have used SEM. For example, <xref ref-type="bibr" rid="bibr16-0016986211424132">Peters and Gentry (2010)</xref> used SEM for multiple purposes, focusing on the measurement model (i.e., how the theoretical constructs are measured by the observed indicators) and on latent means (group means on latent constructs). <xref ref-type="bibr" rid="bibr9-0016986211424132">Hoekman, McCormick, and Barnett (2005)</xref> used SEM to examine the pattern of relationships among motivational and affective variables, commitment to schoolwork, and satisfaction with school. Similarly, <xref ref-type="bibr" rid="bibr6-0016986211424132">Cramond, Matthews-Morgan, Bandalos, and Zuo (2005)</xref> examined the relationships between three latent constructs: performance on the Torrance Tests of Creative Thinking, intelligence, and creative achievement.</p>
<p>Ultimately, SEM has many uses in the research of giftedness. It allows the researcher to use multiple indicators of constructs of interest, such as intelligence, giftedness, motivation, and creativity, and to explicitly model measurement error in observations. Additionally, SEM allows the researcher to model interactions, correlated error terms, more than one dependent variable, and other complex modeling considerations.</p>
</sec>
<sec id="section9-0016986211424132">
<title>Further Reading</title>
<p>For an overview of SEM, see <xref ref-type="bibr" rid="bibr12-0016986211424132">Kline (2010)</xref>. For readers interested in a text that explains SEM analysis using specific software, Byrne has a series of books including one on using Amos (<xref ref-type="bibr" rid="bibr4-0016986211424132">Byrne, 2010</xref>) and one on using Mplus (<xref ref-type="bibr" rid="bibr5-0016986211424132">Byrne, 2011</xref>). <xref ref-type="bibr" rid="bibr2-0016986211424132">Bollen (1989)</xref> and <xref ref-type="bibr" rid="bibr8-0016986211424132">Hancock and Mueller (2006)</xref> both provide more advanced information about SEM.</p>
</sec>
</body>
<back>
<ack>
<p>The author would like to thank Dr. Jesse Owen, Timothy Sauer, and Emily Dickinson at the University of Louisville for feedback on this article.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0016986211424132">
<label>1.</label>
<p>Paths that can be added include causal paths (single-headed arrows indicating one variable causes another) or correlations (double-headed arrows indicating a noncausal relationship between two variables).</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
<name><surname>Bonett</surname><given-names>D. G.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Significance tests and goodness of fit in the analysis of covariance structures</article-title>. <source>Psychological Bulletin</source>, <volume>88</volume>, <fpage>588</fpage>-<lpage>606</lpage>.</citation>
</ref>
<ref id="bibr2-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bollen</surname><given-names>K. A.</given-names></name>
</person-group> (<year>1989</year>). <source>Structural equations with latent variables</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley Interscience</publisher-name>.</citation>
</ref>
<ref id="bibr3-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Browne</surname><given-names>M. W.</given-names></name>
<name><surname>Cudeck</surname><given-names>R.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Alternative ways of assessing model fit</article-title>. In <person-group person-group-type="editor">
<name><surname>Bollen</surname><given-names>K. A.</given-names></name>
<name><surname>Long</surname><given-names>J. S.</given-names></name>
</person-group> (Eds.), <source>Testing structural equation models</source> (pp. <fpage>136</fpage>-<lpage>162</lpage>). <publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr4-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Byrne</surname><given-names>B. M.</given-names></name>
</person-group> (<year>2010</year>). <source>Structural equation modeling with AMOS: Basic concepts, applications, and programming</source> (<edition>2nd ed.</edition>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr5-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Byrne</surname><given-names>B. M.</given-names></name>
</person-group> (<year>2011</year>). <source>Structural equation modeling with Mplus: Basic concepts, applications, and programming</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr6-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cramond</surname><given-names>B.</given-names></name>
<name><surname>Matthews-Morgan</surname><given-names>J.</given-names></name>
<name><surname>Bandalos</surname><given-names>D.</given-names></name>
<name><surname>Zuo</surname><given-names>L.</given-names></name>
</person-group> (<year>2005</year>). <article-title>A report on the 40-year follow-up of the Torrance Tests of Creative Thinking</article-title>. <source>Gifted Child Quarterly</source>, <volume>49</volume>, <fpage>283</fpage>-<lpage>291</lpage>.</citation>
</ref>
<ref id="bibr7-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gridley</surname><given-names>B. E.</given-names></name>
</person-group> (<year>2002</year>). <article-title>In search of an elegant solution: Reanalysis of Plucker, Callahan, and Tomchin, with respects to Pyryt and Plucker</article-title>. <source>Gifted Child Quarterly</source>, <volume>46</volume>, <fpage>224</fpage>-<lpage>234</lpage>.</citation>
</ref>
<ref id="bibr8-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Hancock</surname><given-names>G. R.</given-names></name>
<name><surname>Mueller</surname><given-names>R. O.</given-names></name>
</person-group> (Eds.). (<year>2006</year>). <source>Structural equation modeling: A second course</source>. <publisher-loc>Greenwich, CT</publisher-loc>: <publisher-name>Information Age</publisher-name>.</citation>
</ref>
<ref id="bibr9-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hoekman</surname><given-names>K.</given-names></name>
<name><surname>McCormick</surname><given-names>J.</given-names></name>
<name><surname>Barnett</surname><given-names>K.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The important role of optimism in a motivational investigation of the education of gifted adolescents</article-title>. <source>Gifted Child Quarterly</source>, <volume>49</volume>, <fpage>99</fpage>-<lpage>110</lpage>.</citation>
</ref>
<ref id="bibr10-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hu</surname><given-names>L.</given-names></name>
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives</article-title>. <source>Structural Equation Modeling</source>, <volume>6</volume>, <fpage>1</fpage>-<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr11-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Johnsen</surname><given-names>S. K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Identification</article-title>. In <person-group person-group-type="editor">
<name><surname>Kerr</surname><given-names>B.</given-names></name>
</person-group> (Ed.), <source>Encyclopedia of giftedness, creativity, and talent</source> (<volume>Vol. 1</volume>, pp. <fpage>439</fpage>-<lpage>443</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr12-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kline</surname><given-names>R. B.</given-names></name>
</person-group> (<year>2010</year>). <source>Principles and practice of structural equation modeling</source> (<edition>3rd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>MacCallum</surname><given-names>R. C.</given-names></name>
<name><surname>Browne</surname><given-names>M. W.</given-names></name>
<name><surname>Sugawara</surname><given-names>H. M.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Power analysis and determination of sample size for covariance structure modeling</article-title>. <source>Psychological Methods</source>, <volume>1</volume>, <fpage>130</fpage>-<lpage>149</lpage>.</citation>
</ref>
<ref id="bibr14-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>H. W.</given-names></name>
</person-group> (<year>1992</year>). <source>Self-Description Questionnaire (SDQ) I: A theoretical and empirical basis for the measurement of multiple dimensions of preadolescent self-concept. An interim test manual and research monograph</source>. <publisher-loc>Macarthur, New South Wales, Australia</publisher-loc>: <publisher-name>University of Western Sydney, Faculty of Education</publisher-name>.</citation>
</ref>
<ref id="bibr15-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>H. W.</given-names></name>
<name><surname>Hau</surname><given-names>K. T.</given-names></name>
<name><surname>Wen</surname><given-names>Z. L.</given-names></name>
</person-group> (<year>2004</year>). <article-title>In search of golden rules: Comment on hypothesis testing approaches to setting cutoff values for fit indexes and dangers in overgeneralizing Hu and Bentler (1999) findings</article-title>. <source>Structural Equation Modeling</source>, <volume>11</volume>, <fpage>320</fpage>-<lpage>341</lpage>.</citation>
</ref>
<ref id="bibr16-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peters</surname><given-names>S. J.</given-names></name>
<name><surname>Gentry</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Multigroup construct validity evidence of the <italic>HOPE Scale</italic>: Instrumentation to identify low-income elementary students for gifted programs</article-title>. <source>Gifted Child Quarterly</source>, <volume>54</volume>, <fpage>298</fpage>-<lpage>313</lpage>.</citation>
</ref>
<ref id="bibr17-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pfeiffer</surname><given-names>S. I.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Identifying gifted and talented students</article-title>. <source>Journal of Applied School Psychology</source>, <volume>19</volume>, <fpage>31</fpage>-<lpage>50</lpage>.</citation>
</ref>
<ref id="bibr18-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Raftery</surname><given-names>A. E.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Bayesian model selection in social research</article-title>. <source>Sociological Methodology</source>, <volume>25</volume>, <fpage>111</fpage>-<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr19-0016986211424132">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Robert</surname><given-names>S.</given-names></name>
<name><surname>Pashler</surname><given-names>H.</given-names></name>
</person-group> (<year>2000</year>). <article-title>How persuasive is a good fit? A comment on theory testing in psychology</article-title>. <source>Psychological Review</source>, <volume>107</volume>, <fpage>358</fpage>-<lpage>367</lpage>.</citation>
</ref>
<ref id="bibr20-0016986211424132">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Vernon</surname><given-names>T.</given-names></name>
<name><surname>Eysenck</surname><given-names>S.</given-names></name>
</person-group> (Eds.). (<year>2007</year>). <article-title>Structural equation modeling</article-title> [<comment>Special issue</comment>]. <source>Personality and Individual Differences</source>, <volume>42</volume>(<issue>5</issue>).</citation>
</ref>
</ref-list>
</back>
</article>