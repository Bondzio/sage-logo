<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPM</journal-id>
<journal-id journal-id-type="hwp">spepm</journal-id>
<journal-title>Educational and Psychological Measurement</journal-title>
<issn pub-type="ppub">0013-1644</issn>
<issn pub-type="epub">1552-3888</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0013164412443963</article-id>
<article-id pub-id-type="publisher-id">10.1177_0013164412443963</article-id>
<title-group>
<article-title>Correlation Attenuation Due to Measurement Error</article-title>
<subtitle>A New Approach Using the Bootstrap Procedure</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Padilla</surname><given-names>Miguel A.</given-names></name>
<xref ref-type="aff" rid="aff1-0013164412443963">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Veprinsky</surname><given-names>Anna</given-names></name>
<xref ref-type="aff" rid="aff1-0013164412443963">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0013164412443963"><label>1</label>Old Dominion University, Norfolk, VA, USA</aff>
<author-notes>
<corresp id="corresp1-0013164412443963">Miguel A. Padilla, Department of Psychology, Old Dominion University, Mills Godwin Life Sciences Building, Room 250, Norfolk, VA 23529-0001, USA Email: <email>mapadill@odu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>72</volume>
<issue>5</issue>
<fpage>827</fpage>
<lpage>846</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Issues with correlation attenuation due to measurement error are well documented. More than a century ago, Spearman proposed a correction for attenuation. However, this correction has seen very little use since it can potentially inflate the true correlation beyond one. In addition, very little confidence interval (CI) research has been done for correction for attenuation. In the present study, the authors propose a bootstrap procedure for estimating the deattenuated correlation and corresponding CIs. The authors use Monte Carlo simulations to generate data under certain conditions and assess the performance of the bootstrapped deattenuated correlation. The authors investigate for bias and 95% CI coverage. Results indicate that the bootstrap deattenuated correlation provided adequate percentile CI coverage in all but three conditions. The bias-corrected and accelerated CI, however, provided adequate coverage under all simulation conditions.</p>
</abstract>
<kwd-group>
<kwd>bootstrap</kwd>
<kwd>confidence interval</kwd>
<kwd>deattenuated correlation</kwd>
<kwd>attenuation</kwd>
<kwd>measurement error</kwd>
<kwd>reliability</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Social/behavioral research ranges in scope and specificity, but it shares an underlying characteristic: In one way or another, researchers must work with variables measured with error. Such variables come in the form of unobservable variables such as anxiety, depression, IQ, and so on, which cannot be directly measured. Thus, each of these variables must be indirectly measured through items at which point measurement error is introduced. These types of variables are typically known as <italic>factors</italic> or <italic>latent variables.</italic> Furthermore, working with these variables frequently involves estimating relationships between them. The fundamental statistic for estimating relationships between continuous variables is the Pearson product–moment correlation coefficient (or correlation coefficient). In fact, it is the driving force behind general linear models (GLMs; e.g., regression, analysis of variance [ANOVA]) and is a benchmark measure of effect size. In general, researchers desire a strong correlation because it is a clear demonstration of a relationship. However, all statistical models assume that the variables in the model are measured without error, and none are robust to this assumption. As such, the correlation is not immune to this assumption and the issues it creates can propagate to other methodologies that are based on the correlation. Although the impact of measurement error on the correlation has been known for more than a century, to date very little work has been done to address and minimize its impact. In light of this we propose a bootstrap methodology with accompanying confidence intervals (CIs) as a viable solution to address the effect of measurement error on the correlation and investigate its properties under several simulation conditions.</p>
<sec id="section1-0013164412443963">
<title>General Overview</title>
<p>Researchers in the social/behavioral sciences are often unable to find strong empirical support for theories that otherwise appear plausible (<xref ref-type="bibr" rid="bibr3-0013164412443963">Buckley, Cote, &amp; Comstock, 1990</xref>). Failure to find empirical support may be explained from a theoretical view. Specifically, the model may not account for all factors influencing the variability on the outcome of interest. Other researchers propose that method effects and measurement error are more plausible explanations for discrepancies across research studies (<xref ref-type="bibr" rid="bibr3-0013164412443963">Buckley et al., 1990</xref>; <xref ref-type="bibr" rid="bibr19-0013164412443963">Kassarjian, 1971</xref>; <xref ref-type="bibr" rid="bibr21-0013164412443963">Lance, Dawson, Birkelbach, &amp; Hoffman, 2010</xref>). These researchers emphasize a relationship between poor validity of a measure that may be due to method effects (<xref ref-type="bibr" rid="bibr11-0013164412443963">Fiske, 1987</xref>), and measurement error that is rarely accounted for in the literature (<xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>). For example, a measure may be developed for a specific population but is then used with a general population resulting in poor correlation among variables (<xref ref-type="bibr" rid="bibr3-0013164412443963">Buckley et al., 1990</xref>; <xref ref-type="bibr" rid="bibr19-0013164412443963">Kassarjian, 1971</xref>). Such studies generally conclude a poor relationship between variables instead of investigating the validity of the measure with the population investigated and/or correcting for measurement error.</p>
<p>Unfortunately, measurement error can cause a number of serious problems in statistical models all of which lead to inaccurate inferences or conclusions. For example, when the ubiquitous correlation coefficient is calculated, measurement error in either variable will attenuate the correlation, making the relationship appear weaker than it would be without measurement error (<xref ref-type="bibr" rid="bibr1-0013164412443963">Allen &amp; Yen, 1979</xref>; <xref ref-type="bibr" rid="bibr4-0013164412443963">Carroll, Ruppert, Stefanski, &amp; Crainiceanu, 2006</xref>). In regression models, measurement error in the independent variables can result in coefficients that are smaller, larger, or even have a different sign than the coefficients that would occur if there were no measurement error. See <xref ref-type="bibr" rid="bibr15-0013164412443963">Hobfoll, Shoham, and Ritter (1991)</xref> and <xref ref-type="bibr" rid="bibr34-0013164412443963">Thomas and Williams (1991)</xref> for examples. In addition, measurement error in the dependent variable can increase the residual variance, reduce power, and decrease <italic>R</italic><sup>2</sup> (<xref ref-type="bibr" rid="bibr4-0013164412443963">Carroll et al., 2006</xref>).</p>
<p>The central statistic to GLMs is the correlation coefficient. When interest is in estimating relationships between predictor(s) and a criterion, a regression model is estimated. When interest is in the effect of an independent variable on the dependent variable, an ANOVA model is estimated. Each of these models is a form of the GLM, and an underlying correlation between the variables is assumed in each case. As such, not only does the correlation determine the magnitude of the GLM parameter estimates, it can also drive a researcher’s decision on what variables to include in the model. As previously noted, however, measurement error in the variables negatively affects GLM parameter estimates and corresponding inferences.</p>
<p>An inaccurate correlation coefficient with corresponding CIs can also affect research that synthesizes other research findings such as a meta-analysis. In this type of analysis, the correlation coefficient is a benchmark measure of the effect size and is used as a data point. Even if the correlation for every study is based on a reliability of .90 for the variables, it still indicates that 10% of the variance is due to measurement error. When all these studies are synthesized through a meta-analysis, the 10% error for each correlation quickly propagates through the analysis which may result in a situation where empirical results do not support plausible theories (<xref ref-type="bibr" rid="bibr3-0013164412443963">Buckley et al., 1990</xref>). In fact, a recent meta-analytic article indicated that “for the PTSD–psychological aggression association, 98% of the variance was accounted for by methodological artifacts such as sampling and measurement error” (<xref ref-type="bibr" rid="bibr32-0013164412443963">Taft, Watkins, Stafford, Street, &amp; Monson, 2011</xref>, p. 22).</p>
<p>Thus, getting an accurate estimate of even a fundamental statistic as the correlation coefficient is essential because it is the building block to more advanced statistical models and is commonly used to synthesize research results through a meta-analysis. If the correlation coefficient with corresponding CIs is inaccurate because of measurement error, it will negatively affect the parameter estimates and inferences of statistical models based on the correlation coefficient and meta-analytic research in which it is used as a data point.</p>
</sec>
<sec id="section2-0013164412443963">
<title>Correlation Attenuation</title>
<p>The correlation coefficient is biased as a result of measurement error (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>; <xref ref-type="bibr" rid="bibr10-0013164412443963">Fan, 2003</xref>; <xref ref-type="bibr" rid="bibr25-0013164412443963">Mutch &amp; Tisak, 2005</xref>; <xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>; <xref ref-type="bibr" rid="bibr33-0013164412443963">Tarkkonen &amp; Vehkalahti, 2005</xref>; <xref ref-type="bibr" rid="bibr37-0013164412443963">You &amp; Chen, 2006</xref>). The magnitude of the bias depends on the reliabilities of the measurement instruments used to represent the variables: Poor reliability estimates attenuate the correlation and, consequently, the effect size (<xref ref-type="bibr" rid="bibr10-0013164412443963">Fan, 2003</xref>).</p>
<p>The lack of consistency in measuring variables (i.e., low reliability) results in obtaining a weaker (or attenuated) relationship between the variables than may be true in the population (<xref ref-type="bibr" rid="bibr10-0013164412443963">Fan, 2003</xref>; <xref ref-type="bibr" rid="bibr12-0013164412443963">Fleiss &amp; Shrout, 1977</xref>; <xref ref-type="bibr" rid="bibr17-0013164412443963">H. G. Johnson, 1944</xref>; <xref ref-type="bibr" rid="bibr20-0013164412443963">Kirkpatrick, 1997</xref>; <xref ref-type="bibr" rid="bibr24-0013164412443963">Murphy, 2008</xref>; <xref ref-type="bibr" rid="bibr25-0013164412443963">Mutch &amp; Tisak, 2005</xref>; <xref ref-type="bibr" rid="bibr27-0013164412443963">Pedhazur, 1997</xref>; <xref ref-type="bibr" rid="bibr36-0013164412443963">Winne &amp; Belfry, 1982</xref>; <xref ref-type="bibr" rid="bibr38-0013164412443963">Zimmerman &amp; Williams, 1997</xref>). The relationship between the correlation coefficient and reliability can be seen by the equation for the deattenuated correlation coefficient (<xref ref-type="bibr" rid="bibr30-0013164412443963">Spearman, 1904</xref>):</p>
<p><disp-formula id="disp-formula1-0013164412443963">
<mml:math display="block" id="math1-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>yy</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
<mml:msqrt>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>xx</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0013164412443963" xlink:href="10.1177_0013164412443963-eq1.tif"/>
</disp-formula></p>
<p>where ρ<sub><italic>TxTy</italic></sub> is the true correlation, ρ<sub><italic>xy</italic></sub> is the observed correlation, and ρ<sub><italic>yy</italic>′</sub> and ρ<sub><italic>xx</italic>′</sub> are the reliabilities for <italic>y</italic> and <italic>x</italic>, respectively. To estimate the deattenuated correlation one just replaces the parameters with the parameter estimates as follows:</p>
<p><disp-formula id="disp-formula2-0013164412443963">
<mml:math display="block" id="math2-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>xy</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yy</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
<mml:msqrt>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>xx</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0013164412443963" xlink:href="10.1177_0013164412443963-eq2.tif"/>
</disp-formula></p>
<p>Note that <xref ref-type="disp-formula" rid="disp-formula1-0013164412443963">Equations (1)</xref> and <xref ref-type="disp-formula" rid="disp-formula2-0013164412443963">(2)</xref> are valid for continuous and ranked (<xref ref-type="bibr" rid="bibr30-0013164412443963">Spearman, 1904</xref>) variables.</p>
<p>According to <xref ref-type="disp-formula" rid="disp-formula1-0013164412443963">Equations (1)</xref> and <xref ref-type="disp-formula" rid="disp-formula2-0013164412443963">(2)</xref>, the true correlation equals the observed correlation when there is no measurement error in <italic>x</italic> and <italic>y</italic>, that is, the reliabilities of both variables equal one (ρ<sub><italic>yy</italic></sub> = ρ<sub><italic>xx</italic></sub> = 1). When this does not hold, any measurement error variance in the variables results in correlation attenuation (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>; <xref ref-type="bibr" rid="bibr38-0013164412443963">Zimmerman &amp; Williams, 1997</xref>). To correct for attenuation, accurate reliability estimates are required. According to <xref ref-type="bibr" rid="bibr36-0013164412443963">Winne and Belfry (1982)</xref>, the most common reliability coefficients are the Spearman–Brown split-half correlation and coefficient alpha (or Cronbach’s alpha). Assuming that the set of items in the measurement instrument are at least tau-equivalent or essentially tau-equivalent, coefficient alpha is equal to reliability (<xref ref-type="bibr" rid="bibr13-0013164412443963">Graham, 2006</xref>; <xref ref-type="bibr" rid="bibr22-0013164412443963">Lord, Novick, &amp; Birnbaum, 1968</xref>; <xref ref-type="bibr" rid="bibr23-0013164412443963">McDonald, 1999</xref>; <xref ref-type="bibr" rid="bibr39-0013164412443963">Zinbarg, Revelle, Yovel, &amp; Li, 2005</xref>). If the items are congeneric, coefficient alpha underestimates reliability, but coefficient omega is equal to reliability of the measurement instrument (<xref ref-type="bibr" rid="bibr23-0013164412443963">McDonald, 1999</xref>; <xref ref-type="bibr" rid="bibr39-0013164412443963">Zinbarg et al., 2005</xref>). Furthermore, both coefficients alpha and omega are equal to the reliability of the set of items when they are at least tau-equivalent. As noted by Winne and Belfry, using an underestimated reliability in <xref ref-type="disp-formula" rid="disp-formula1-0013164412443963">Equations (1)</xref> and <xref ref-type="disp-formula" rid="disp-formula2-0013164412443963">(2)</xref> results in overestimation of the correlation.</p>
<p>The two major psychometric components of a measurement instrument are validity and reliability (<xref ref-type="bibr" rid="bibr1-0013164412443963">Allen &amp; Yen, 1979</xref>; <xref ref-type="bibr" rid="bibr8-0013164412443963">Crocker &amp; Algina, 1986</xref>; <xref ref-type="bibr" rid="bibr33-0013164412443963">Tarkkonen &amp; Vehkalahti, 2005</xref>). Validity is concerned with whether the instrument measures what it purports to measure. Reliability, on the other hand, refers to the consistency or precision of the measure and is derived from the classical true score model as</p>
<p><disp-formula id="disp-formula3-0013164412443963">
<mml:math display="block" id="math3-0013164412443963">
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>τ</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0013164412443963" xlink:href="10.1177_0013164412443963-eq3.tif"/>
</disp-formula></p>
<p>where <italic>x</italic> is an observed score, τ is a true score, and <italic>u</italic> is a measurement error (<xref ref-type="bibr" rid="bibr1-0013164412443963">Allen &amp; Yen, 1979</xref>; <xref ref-type="bibr" rid="bibr8-0013164412443963">Crocker &amp; Algina, 1986</xref>; <xref ref-type="bibr" rid="bibr33-0013164412443963">Tarkkonen &amp; Vehkalahti, 2005</xref>). The true score model further assumes no correlation between the true score and the error, which allows for the separation of true score variance from the error variance,</p>
<p><disp-formula id="disp-formula4-0013164412443963">
<mml:math display="block" id="math4-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>τ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>u</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0013164412443963" xlink:href="10.1177_0013164412443963-eq4.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula1-0013164412443963">
<mml:math display="inline" id="math5-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> is the observed variance, <inline-formula id="inline-formula2-0013164412443963">
<mml:math display="inline" id="math6-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>τ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> is the true variance, and <inline-formula id="inline-formula3-0013164412443963">
<mml:math display="inline" id="math7-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>u</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> is the measurement error variance. By definition, reliability is the ratio of the true variance over the observed variance of the measurement instrument:</p>
<p><disp-formula id="disp-formula5-0013164412443963">
<mml:math display="block" id="math8-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>xx</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>τ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>τ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>τ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mtext>σ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0013164412443963" xlink:href="10.1177_0013164412443963-eq5.tif"/>
</disp-formula></p>
<p><xref ref-type="bibr" rid="bibr33-0013164412443963">Tarkkonen and Vehkalahti (2005)</xref> indicate that the majority of traditional studies focus on sampling error, often ignoring measurement error and, according to <xref ref-type="bibr" rid="bibr10-0013164412443963">Fan (2003)</xref> and <xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt and Hunter (1996)</xref>, also underreport obtained reliability estimates. Both sampling and measurement error are mutually exclusive but both have a unique effect on the outcome. To see further derivations and an explanation of the measurement error variance, the interested reader is referred to <xref ref-type="bibr" rid="bibr33-0013164412443963">Tarkkonen and Vehkalahti (2005)</xref>.</p>
<p>The issue with bias due to measurement error carries over to path models. Recognizing the effect of correlation attenuation on their proposed teaching and learning path model, <xref ref-type="bibr" rid="bibr31-0013164412443963">Stayrook and Corno (1979)</xref> corrected the path coefficients for attenuation. Unlike other discussed studies that applied the classical true score model, Stayrook and Corno followed generalizability theory, a more general extension of the classical true score model, where the true (or universe) score is “the average of all possible representative observations” (p. 229). In other words, the true score is the mean of the sampling distribution composed of representative observations. After correcting for attenuation, these researchers noted changes in their path coefficients that were more congruent with their hypotheses. Although a couple of path coefficients decreased in value, the magnitude of this change was not large and the model fit improved.</p>
<p>A clear interpretation from the discussion thus far can be made: Measurement error affects statistical results and corresponding conclusions. Despite the serious implications of measurement error, however, some studies still fail to report reliability estimates or refute the possibility of measurement error (<xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>). According to Schmidt and Hunter, there is yet to be a psychological variable that could derive an absolute value. Most psychological measures thus far developed do not account for 100% of the variability, leaving room for measurement error. Schmidt and Hunter further point out that even when reliability estimates are reported, researchers do not correct their results for measurement error, or if corrections are applied this is often done incorrectly. The researchers believe this confusion is due to lack of concrete examples as to when and how to use correction for attenuation.</p>
<p>To further illustrate their point, <xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt and Hunter (1996)</xref> present a number of scenarios depicting common misconceptions and errors in judgment. For example, in one scenario the researcher in question assumes that measurement error and sampling error are one and the same. As previously noted the two are independent and refer to different research issues. Measurement error refers to an inconsistency in assessing a psychological construct; the bias is minimized when items generated to assess one factor are highly correlated, which implies that items measure the same construct. On the other hand, sampling error refers to the difference between a sample statistic and a population parameter. Sampling bias is a possible source of sampling error: Specifically, having overrepresentation or underrepresentation of some members of the population can bias a statistic.</p>
<p>Another common mistake noted by <xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt and Hunter (1996)</xref> is the misconception associated with <italic>an adequate</italic> reliability estimate of .70 (<xref ref-type="bibr" rid="bibr26-0013164412443963">Nunnally, 1978</xref>). Even if both variables have reliability of .70, “the bias factor is <inline-formula id="inline-formula4-0013164412443963">
<mml:math display="inline" id="math9-0013164412443963">
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:mo>.</mml:mo>
<mml:mn>70</mml:mn>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>.</mml:mo>
<mml:mn>70</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msqrt>
<mml:mo>=</mml:mo>
<mml:mo>.</mml:mo>
<mml:mn>70</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>” (<xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>, p. 204). This indicates that 30% of the variance between the two variables is measurement error. Overall, the researchers point out that there is no measurement instrument free of error, at least not in the social/behavioral sciences. They also point out that in order for theory and cumulative knowledge to progress, measurement error in research must be considered and handled carefully.</p>
</sec>
<sec id="section3-0013164412443963" sec-type="methods">
<title>Methodological Studies</title>
<p>Recent methodological research has investigated correcting measurement error in the correlation coefficient. In one such study, <xref ref-type="bibr" rid="bibr38-0013164412443963">Zimmerman and Williams (1997)</xref> conducted a Monte Carlo simulation to analyze the properties of Spearman’s deattenuated correlation. The conditions of the simulation were as follows: distribution shape of the data, sample size, reliability coefficient, and population correlation. The researchers noted that the deattenuated correlation was unbiased, but only when the reliability of the variables was high (e.g., ≥.70). In contrast, if the reliability was low the deattenuated correlation greatly exceeded the true correlation. This was exacerbated with small samples (e.g., <italic>n</italic> = 20) in which case a deattenuated correlation greater than one became frequent. In addition, Zimmerman and Williams noted that the variability of corrected correlations increased as a function of poor reliability estimates, which may result in the overestimation of the association between the two variables. Zimmerman and Williams did not investigate CI coverage.</p>
<p>In another investigation, <xref ref-type="bibr" rid="bibr5-0013164412443963">Charles (2005)</xref> addressed the criticisms associated with the deattenuated correlation. As was previously discussed, correcting for attenuation when using poor reliability estimates results in overestimation of the correlation, which can result in a corrected correlation coefficient that goes beyond ±1. Instead of abandoning the attenuation correction method, Charles proposed the use of <italic>confidence sets.</italic> Unlike CIs, the idea behind confidence sets is that interest lies in finding population bounds likely to have generated the obtained sample as opposed to CIs which reflect sampled values likely to have been generated by a given population. According to Charles, corrected correlations consist of true correlations and <italic>nuisance correlations</italic> (see <xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>, for details).</p>
<p><xref ref-type="bibr" rid="bibr5-0013164412443963">Charles (2005)</xref> investigated confidence sets for correction for attenuation due to measurement error. The confidence sets were derived from regressing the sampling distribution standard deviation from the deattenuated correlation on the sample size, geometric mean of reliability, square of true-score correlation, and their two- and three-way interactions. The regression equation accounted for 99.6% of the deattenuated correlation variability. The method performed reasonably well under the investigated conditions. However, it has seen little use in the applied literature. One reason may be that the method is counterintuitive to what researchers are used to in that statistics are used to estimate population parameters as opposed to finding a range of populations that generate the sample data.</p>
<p>The purpose of the current study is to assess the performance of the bootstrapped deattenuated correlation and corresponding CIs based on Spearman’s original correlation correction. In particular, interest lies in simulation conditions similar across earlier studies. The bootstrapped deattenuated correlation was assessed for bias and interval estimation. We start with the bootstrapped deattenuated correlation.</p>
</sec>
<sec id="section4-0013164412443963">
<title>Bootstrapped Deattenuated Correlation</title>
<p>The bootstrapped deattenuated correlation for a pair of variables <italic>x</italic> and <italic>y</italic> can be summarized in three steps. Suppose <bold>X</bold> = (<bold>x</bold><sub>1</sub>, <bold>x</bold><sub>2</sub>, . . ., <bold>x</bold><sub><italic>n</italic></sub>) is the observed sample where each <bold>x</bold><sub><italic>i</italic></sub> = (<italic>y</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>i</italic></sub>) is a 1 × 2 vector. First, obtain a bootstrap sample <inline-formula id="inline-formula5-0013164412443963">
<mml:math display="inline" id="math10-0013164412443963">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi mathvariant="bold">x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi mathvariant="bold">x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi mathvariant="bold">x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, which is a <italic>b</italic>th random resample from <bold>X</bold> with replacement. Note that <bold>X</bold> and <bold>X</bold><sup>(<italic>b</italic>)</sup> have the same sample size. Second, compute the <italic>b</italic>th bootstrap estimate of the deattenuated correlation as</p>
<p><disp-formula id="disp-formula6-0013164412443963">
<mml:math display="block" id="math11-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>yy</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
<mml:msqrt>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>xx</mml:mi>
<mml:mo>′</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0013164412443963" xlink:href="10.1177_0013164412443963-eq6.tif"/>
</disp-formula></p>
<p>from <bold>X</bold><sup>(<italic>b</italic>)</sup>. Last, <inline-formula id="inline-formula6-0013164412443963">
<mml:math display="inline" id="math12-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> represents the empirical sampling distribution (ESD) for <inline-formula id="inline-formula7-0013164412443963">
<mml:math display="inline" id="math13-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> for <italic>b</italic> = 1, 2, . . ., <italic>B</italic> bootstrap samples. The ESD can then be summarized to obtain statistical quantities associated with <inline-formula id="inline-formula8-0013164412443963">
<mml:math display="inline" id="math14-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> for statistical inference.</p>
<p>The bootstrap estimate of standard error (<italic>SE</italic>) for the deattenuated correlation is</p>
<p><disp-formula id="disp-formula7-0013164412443963">
<mml:math display="block" id="math15-0013164412443963">
<mml:mrow>
<mml:mi>SE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>B</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>b</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0013164412443963" xlink:href="10.1177_0013164412443963-eq7.tif"/>
</disp-formula></p>
<p>where <italic>b</italic> is the bootstrap replicate, <inline-formula id="inline-formula9-0013164412443963">
<mml:math display="inline" id="math16-0013164412443963">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> is the estimated deattenuated correlation for the <italic>b</italic>th bootstrap replicate, and</p>
<p><disp-formula id="disp-formula8-0013164412443963">
<mml:math display="block" id="math17-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>b</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0013164412443963" xlink:href="10.1177_0013164412443963-eq8.tif"/>
</disp-formula></p>
<p>There are several types of bootstrap CIs that can be constructed, but here we will focus on the percentile bootstrap (PB) and the bias-corrected and accelerated bootstrap (BCa) CIs because the sampling distribution of the correlation coefficient is not normal (<xref ref-type="bibr" rid="bibr18-0013164412443963">N. C. Johnson, Kotz, &amp; Balakrishnan, 1995</xref>). The PB CI can be constructed by computing the α/2 and 1 −α/2 percentiles from the <inline-formula id="inline-formula10-0013164412443963">
<mml:math display="inline" id="math18-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> ESD where α is the significance level. For further technical and theoretical details about the BCa CI or the bootstrap in general, see <xref ref-type="bibr" rid="bibr9-0013164412443963">Efron and Tibshirani (1993)</xref>.</p>
<p>In the current study, these methods were used to estimate 100(1 –α)% CIs for the deattenuated correlation under several simulation conditions, where α = .05. In addition, all corresponding bootstrap quantities were estimated from a total of 1,000 bootstrap samples.</p>
</sec>
<sec id="section5-0013164412443963" sec-type="methods">
<title>Method</title>
<sec id="section6-0013164412443963">
<title>Simulation</title>
<p>A Monte Carlo simulation was used to investigate the properties of the bootstrapped deattenuated correlation CIs. Specifically, the impact of three simulation factors was investigated in a 5 (correlation magnitude) × 5 (reliability) × 6 (sample size) simulation design. All data were simulated assuming multivariate normality. To increase the generality of the results, data were simulated under similar scenarios investigated in earlier studies (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>; <xref ref-type="bibr" rid="bibr38-0013164412443963">Zimmerman &amp; Williams, 1997</xref>). In this study, 1,000 replications were obtained for each combination of the Monte Carlo simulation.</p>
<p>Data were simulated as follows. First, generate an <italic>n</italic>×<italic>k</italic> multivariate true variable data <bold>T</bold> = (τ<sub><italic>i</italic>1</sub>,τ<sub><italic>i</italic>2</sub>) such that <bold>T</bold>~<italic>N</italic>(<bold>0</bold>, <bold>P</bold>), where <italic>i</italic> = 1, 2, . . ., <italic>n, j</italic> = 1, 2, . . ., <italic>k</italic>, and <bold>P</bold> is the <italic>k</italic>×<italic>k</italic> true correlation matrix. Note that <italic>k</italic> = 2. Second, the observed variables were generated as</p>
<p><disp-formula id="disp-formula9-0013164412443963">
<mml:math display="block" id="math19-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>τ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>u</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0013164412443963" xlink:href="10.1177_0013164412443963-eq9.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula11-0013164412443963">
<mml:math display="inline" id="math20-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>u</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>jj</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. The variance of <italic>u</italic><sub><italic>ij</italic></sub> is defined as</p>
<p><disp-formula id="disp-formula10-0013164412443963">
<mml:math display="block" id="math21-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>jj</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mrow>
<mml:mtext>var</mml:mtext>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>τ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>jj</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>jj</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0013164412443963" xlink:href="10.1177_0013164412443963-eq10.tif"/>
</disp-formula></p>
<p>where ρ<sub><italic>ij</italic></sub> is the reliability of <italic>j</italic>th variable. The following simulation conditions were investigated.</p>
<sec id="section7-0013164412443963">
<title>Correlation (ρ)</title>
<p>Small, medium, and large correlations, as defined by (<xref ref-type="bibr" rid="bibr6-0013164412443963">Cohen, 1988</xref>), were investigated. The Pearson product–moment correlation (ρ) measures the magnitude of a relationship between the two continuous variables and can be interpreted as an effect size (ρ<sup>2</sup>). Cohen recommends the following interpretation of the correlation coefficient: ρ = .10, .30, .50 represents a small, moderate, and strong correlation, respectively. To broaden the investigation, we focused on the correlation coefficients ranging from .10 to .50 in increments of .10.</p>
</sec>
<sec id="section8-0013164412443963">
<title>Reliability (ρ<sub><italic>ij</italic></sub>)</title>
<p>The reliability of both variables in the correlation was manipulated. The rule of thumb in the behavioral sciences is to consider a reliability coefficient of .70 as an adequate reliability estimate (<xref ref-type="bibr" rid="bibr26-0013164412443963">Nunnally, 1978</xref>). Nonetheless, we investigated reliability estimates ranging from .50 to .90 in increments of .10, which mimic scenarios similar to what is often seen in applied research.</p>
</sec>
<sec id="section9-0013164412443963">
<title>Sample size (<italic>n</italic>)</title>
<p>The following sample sizes were investigated: <italic>n</italic> = 50, 100, 150, 200, 250, 300. These are typical sample sizes found in social/behavioral research.</p>
</sec>
</sec>
<sec id="section10-0013164412443963">
<title>Procedure</title>
<p>In each replication, the deattenuated correlation was computed along with the corresponding bootstrap 95% CIs. Relative bias for the deattenuated correlation was computed as</p>
<p><disp-formula id="disp-formula11-0013164412443963">
<mml:math display="block" id="math22-0013164412443963">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>bias</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>TyTx</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0013164412443963" xlink:href="10.1177_0013164412443963-eq11.tif"/>
</disp-formula></p>
<p>where ρ is the true population correlation. The average of the estimated <italic>SE</italic> was computed as</p>
<p><disp-formula id="disp-formula12-0013164412443963">
<mml:math display="block" id="math23-0013164412443963">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>SE</mml:mi>
</mml:mrow>
<mml:mo stretchy="true">¯</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>rep</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mi>SE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>rep</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0013164412443963" xlink:href="10.1177_0013164412443963-eq12.tif"/>
</disp-formula></p>
<p>where <italic>rep</italic> is the number of replications and <inline-formula id="inline-formula12-0013164412443963">
<mml:math display="inline" id="math24-0013164412443963">
<mml:mrow>
<mml:mi>SE</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mtext>ρ</mml:mtext>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> is the bootstrap <italic>SE</italic> for the bootstrapped deattenuated correlation for each replication.</p>
<p>CI coverage was assessed using <xref ref-type="bibr" rid="bibr2-0013164412443963">Bradley’s (1978)</xref> liberal criterion, which is defined as 1 − 1.5α≤ 1 −ρ≤ 1 − 0.5α (<xref ref-type="bibr" rid="bibr28-0013164412443963">Romano, Kromrey, &amp; Hibbard, 2010</xref>). Coverage is defined as the proportion of estimated CIs that contain the true population correlation. Thus, with α = .05 acceptable coverage falls within the interval [.925, .975].</p>
</sec>
</sec>
<sec id="section11-0013164412443963" sec-type="results">
<title>Results</title>
<sec id="section12-0013164412443963">
<title>Point Estimate Bias</title>
<p>The focus of the study is the bootstrapped deattenuated correlation CIs; however, parameter estimate bias was also investigated since it can have an effect on the CIs. <xref ref-type="table" rid="table1-0013164412443963">Tables 1</xref> through <xref ref-type="table" rid="table5-0013164412443963">5</xref> display the results and there is no observable bias. In fact, the magnitude of the bias was .00 ± .07. However, the quantities for bias behave in the anticipated manner: Bias decreases as sample size and/or reliability increases.</p>
<table-wrap id="table1-0013164412443963" position="float">
<label>Table 1.</label>
<caption><p>95% CI Coverage for Reliability by Sample Size at .10 Correlation</p></caption>
<graphic alternate-form-of="table1-0013164412443963" xlink:href="10.1177_0013164412443963-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Reliability</th>
<th align="center"><italic>n</italic></th>
<th align="center">Relative bias</th>
<th align="center">RMSE</th>
<th align="center">Percentile CI</th>
<th align="center">BCa CI</th>
</tr>
</thead>
<tbody>
<tr>
<td>.50</td>
<td>50</td>
<td>−.0260 (.2865)</td>
<td>.2865</td>
<td>.9300</td>
<td>.9330</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0739 (.1984)</td>
<td>.1986</td>
<td>.9450</td>
<td>.9470</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0059 (.1626)</td>
<td>.1626</td>
<td>.9460</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0003 (.1378)</td>
<td>.1378</td>
<td>.9530</td>
<td>.9560</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0365 (.1301)</td>
<td>.1301</td>
<td>.9490</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0004 (.1132)</td>
<td>.1132</td>
<td>.9490</td>
<td>.9480</td>
</tr>
<tr>
<td>.60</td>
<td>50</td>
<td>−.0032 (.2430)</td>
<td>.2430</td>
<td>.<bold>9210</bold></td>
<td>.9250</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0751 (.1677)</td>
<td>.1679</td>
<td>.9410</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0403 (.1363)</td>
<td>.1364</td>
<td>.9330</td>
<td>.9350</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0061 (.1194)</td>
<td>.1194</td>
<td>.9490</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0095 (.1027)</td>
<td>.1027</td>
<td>.9470</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0026 (.0963)</td>
<td>.0963</td>
<td>.9460</td>
<td>.9480</td>
</tr>
<tr>
<td>.70</td>
<td>50</td>
<td>−.0303 (.2018)</td>
<td>.2018</td>
<td>.9380</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0237 (.1421)</td>
<td>.1421</td>
<td>.9410</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0140 (.1231)</td>
<td>.1231</td>
<td>.9310</td>
<td>.9370</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0221 (.0980)</td>
<td>.0980</td>
<td>.9490</td>
<td>.9490</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0016 (.0883)</td>
<td>.0883</td>
<td>.9590</td>
<td>.9610</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0499 (.0827)</td>
<td>.0829</td>
<td>.9460</td>
<td>.9470</td>
</tr>
<tr>
<td>.80</td>
<td>50</td>
<td>.0216 (.1809)</td>
<td>.1810</td>
<td>.9340</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0189 (.1291)</td>
<td>.1291</td>
<td>.9370</td>
<td>.9360</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0398 (.1050)</td>
<td>.1051</td>
<td>.9420</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0250 (.0878)</td>
<td>.0878</td>
<td>.9450</td>
<td>.9410</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0340 (.0777)</td>
<td>.0778</td>
<td>.9440</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0185 (.0714)</td>
<td>.0714</td>
<td>.9520</td>
<td>.9550</td>
</tr>
<tr>
<td>.90</td>
<td>50</td>
<td>−.0713 (.1527)</td>
<td>.1529</td>
<td>.9430</td>
<td>.9390</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0092 (.1152)</td>
<td>.1152</td>
<td>.9280</td>
<td>.9340</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0311 (.0891)</td>
<td>.0892</td>
<td>.9480</td>
<td>.9470</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0343 (.0766)</td>
<td>.0767</td>
<td>.9530</td>
<td>.9500</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0287 (.0693)</td>
<td>.0694</td>
<td>.9510</td>
<td>.9520</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0033 (.0628)</td>
<td>.0628</td>
<td>.9460</td>
<td>.9480</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0013164412443963">
<p>Note: CI = confidence interval; RMSE = root mean square error; BCa = bias-corrected and accelerated bootstrap. Numbers in parentheses are standard errors; CIs in boldface fall outside the interval [.925, .975]. All CIs are based on 1,000 bootstrap samples.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table2-0013164412443963" position="float">
<label>Table 2.</label>
<caption><p>95% CI Coverage for Reliability by Sample Size at .20 Correlation</p></caption>
<graphic alternate-form-of="table2-0013164412443963" xlink:href="10.1177_0013164412443963-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Reliability</th>
<th align="center"><italic>n</italic></th>
<th align="center">Relative bias</th>
<th align="center">RMSE</th>
<th align="center">Percentile CI</th>
<th align="center">BCa CI</th>
</tr>
</thead>
<tbody>
<tr>
<td>.50</td>
<td>50</td>
<td>−.0037 (.2824)</td>
<td>.2824</td>
<td>.9350</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0183 (.1943)</td>
<td>.1943</td>
<td>.9490</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0075 (.1674)</td>
<td>.1674</td>
<td>.9290</td>
<td>.9320</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0059 (.1388)</td>
<td>.1388</td>
<td>.9490</td>
<td>.9490</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0178 (.1286)</td>
<td>.1286</td>
<td>.9410</td>
<td>.9390</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0034 (.1207)</td>
<td>.1207</td>
<td>.9350</td>
<td>.9380</td>
</tr>
<tr>
<td>.60</td>
<td>50</td>
<td>−.0479 (.2404)</td>
<td>.2406</td>
<td>.9280</td>
<td>.9350</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0074 (.1660)</td>
<td>.1660</td>
<td>.9380</td>
<td>.9380</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0190 (.1323)</td>
<td>.1324</td>
<td>.9460</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0224 (.1176)</td>
<td>.1177</td>
<td>.9440</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0083 (.1057)</td>
<td>.1057</td>
<td>.9470</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0137 (.0934)</td>
<td>.0935</td>
<td>.9490</td>
<td>.9520</td>
</tr>
<tr>
<td>.70</td>
<td>50</td>
<td>−.0599 (.2055)</td>
<td>.2059</td>
<td>.9280</td>
<td>.9310</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0108 (.1386)</td>
<td>.1386</td>
<td>.9430</td>
<td>.9500</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0031 (.1123)</td>
<td>.1123</td>
<td>.9480</td>
<td>.9470</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0223 (.0969)</td>
<td>.0970</td>
<td>.9510</td>
<td>.9490</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0304 (.0901)</td>
<td>.0903</td>
<td>.9440</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0099 (.0832)</td>
<td>.0832</td>
<td>.9410</td>
<td>.9410</td>
</tr>
<tr>
<td>.80</td>
<td>50</td>
<td>.0198 (.1710)</td>
<td>.1710</td>
<td>.9340</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0022 (.1220)</td>
<td>.1220</td>
<td>.9400</td>
<td>.9410</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0064 (.0982)</td>
<td>.0982</td>
<td>.9540</td>
<td>.9530</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0116 (.0831)</td>
<td>.0831</td>
<td>.9480</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0031 (.0755)</td>
<td>.0755</td>
<td>.9470</td>
<td>.9510</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0042 (.0683)</td>
<td>.0683</td>
<td>.9460</td>
<td>.9500</td>
</tr>
<tr>
<td>.90</td>
<td>50</td>
<td>.0164 (.1534)</td>
<td>.1534</td>
<td>.9380</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0179 (.1104)</td>
<td>.1105</td>
<td>.9300</td>
<td>.9330</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0150 (.0879)</td>
<td>.0879</td>
<td>.9470</td>
<td>.9500</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0092 (.0770)</td>
<td>.0770</td>
<td>.9430</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0026 (.0678)</td>
<td>.0678</td>
<td>.9440</td>
<td>.9470</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0123 (.0631)</td>
<td>.0631</td>
<td>.9470</td>
<td>.9420</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0013164412443963">
<p>Note: CI = confidence interval; RMSE = root mean square error; BCa = bias-corrected and accelerated bootstrap. Numbers in parentheses are standard errors; CIs in boldface fall outside the interval [.925, .975]. All CIs are based on 1,000 bootstrap samples.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table3-0013164412443963" position="float">
<label>Table 3.</label>
<caption><p>95% CI Coverage for Reliability by Sample Size at .30 Correlation</p></caption>
<graphic alternate-form-of="table3-0013164412443963" xlink:href="10.1177_0013164412443963-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Reliability</th>
<th align="center"><italic>n</italic></th>
<th align="center">Relative bias</th>
<th align="center">RMSE</th>
<th align="center">Percentile CI</th>
<th align="center">BCa CI</th>
</tr>
</thead>
<tbody>
<tr>
<td>.50</td>
<td>50</td>
<td>−.0411 (.2861)</td>
<td>.2863</td>
<td>.<bold>9240</bold></td>
<td>.9270</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0139 (.1938)</td>
<td>.1939</td>
<td>.9460</td>
<td>.9470</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0121 (.1578)</td>
<td>.1578</td>
<td>.9480</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0021 (.1391)</td>
<td>.1391</td>
<td>.9440</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0152 (.1221)</td>
<td>.1222</td>
<td>.9520</td>
<td>.9530</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0030 (.1146)</td>
<td>.1146</td>
<td>.9510</td>
<td>.9510</td>
</tr>
<tr>
<td>.60</td>
<td>50</td>
<td>.0150 (.2276)</td>
<td>.2277</td>
<td>.9350</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0041 (.1641)</td>
<td>.1641</td>
<td>.9430</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0219 (.1272)</td>
<td>.1274</td>
<td>.9460</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0054 (.1116)</td>
<td>.1117</td>
<td>.9540</td>
<td>.9560</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0025 (.1015)</td>
<td>.1015</td>
<td>.9440</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0026 (.0963)</td>
<td>.0963</td>
<td>.9450</td>
<td>.9420</td>
</tr>
<tr>
<td>.70</td>
<td>50</td>
<td>−.0236 (.2040)</td>
<td>.2041</td>
<td>.<bold>9240</bold></td>
<td>.9290</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0009 (.1387)</td>
<td>.1387</td>
<td>.9360</td>
<td>.9680</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0025 (.1124)</td>
<td>.1124</td>
<td>.9480</td>
<td>.9530</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0090 (.0954)</td>
<td>.0954</td>
<td>.9470</td>
<td>.9410</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0058 (.0856)</td>
<td>.0857</td>
<td>.9480</td>
<td>.9490</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0062 (.0754)</td>
<td>.0754</td>
<td>.9610</td>
<td>.9620</td>
</tr>
<tr>
<td>.80</td>
<td>50</td>
<td>−.0151 (.1690)</td>
<td>.1691</td>
<td>.9470</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0193 (.1125)</td>
<td>.1126</td>
<td>.9580</td>
<td>.9610</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0126 (.0979)</td>
<td>.0980</td>
<td>.9430</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0008 (.0835)</td>
<td>.0835</td>
<td>.9380</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0103 (.0734)</td>
<td>.0735</td>
<td>.9500</td>
<td>.9530</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0023 (.0687)</td>
<td>.0687</td>
<td>.9490</td>
<td>.9480</td>
</tr>
<tr>
<td>.90</td>
<td>50</td>
<td>−.0249 (.1449)</td>
<td>.1451</td>
<td>.9470</td>
<td>.9510</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0343 (.1052)</td>
<td>.1057</td>
<td>.9400</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0073 (.0844)</td>
<td>.0844</td>
<td>.9450</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0030 (.0717)</td>
<td>.0717</td>
<td>.9600</td>
<td>.9580</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0023 (.0664)</td>
<td>.0664</td>
<td>.9460</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0065 (.0592)</td>
<td>.0593</td>
<td>.9520</td>
<td>.9500</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0013164412443963">
<p>Note: CI = confidence interval; RMSE = root mean square error; BCa = bias-corrected and accelerated bootstrap. Numbers in parentheses are standard errors; CIs in boldface fall outside the interval [.925, .975]. All CIs are based on 1,000 bootstrap samples.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table4-0013164412443963" position="float">
<label>Table 4.</label>
<caption><p>95% CI Coverage for Reliability by Sample Size at .40 Correlation</p></caption>
<graphic alternate-form-of="table4-0013164412443963" xlink:href="10.1177_0013164412443963-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Reliability</th>
<th align="center"><italic>n</italic></th>
<th align="center">Relative bias</th>
<th align="center">RMSE</th>
<th align="center">Percentile CI</th>
<th align="center">BCa CI</th>
</tr>
</thead>
<tbody>
<tr>
<td>.50</td>
<td>50</td>
<td>−.0270 (.2812)</td>
<td>.2814</td>
<td>.9330</td>
<td>.9390</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0009 (.1946)</td>
<td>.1946</td>
<td>.9410</td>
<td>.9390</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0097 (.1533)</td>
<td>.1533</td>
<td>.9520</td>
<td>.9530</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0148 (.1326)</td>
<td>.1327</td>
<td>.9550</td>
<td>.9520</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0025 (.1154)</td>
<td>.1154</td>
<td>.9570</td>
<td>.9580</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0043 (.1116)</td>
<td>.1116</td>
<td>.9520</td>
<td>.9510</td>
</tr>
<tr>
<td>.60</td>
<td>50</td>
<td>−.0130 (.2181)</td>
<td>.2181</td>
<td>.9380</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0102 (.1554)</td>
<td>.1555</td>
<td>.9430</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0036 (.1260)</td>
<td>.1260</td>
<td>.9520</td>
<td>.9520</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0067 (.1131)</td>
<td>.1132</td>
<td>.9410</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0128 (.1010)</td>
<td>.1012</td>
<td>.9360</td>
<td>.9350</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0005 (.0884)</td>
<td>.0884</td>
<td>.9480</td>
<td>.9530</td>
</tr>
<tr>
<td>.70</td>
<td>50</td>
<td>−.0091 (.1960)</td>
<td>.1961</td>
<td>.9270</td>
<td>.9260</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0127 (.1293)</td>
<td>.1264</td>
<td>.9560</td>
<td>.9550</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0087 (.1085)</td>
<td>.1085</td>
<td>.9440</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>.0021 (.0917)</td>
<td>.0917</td>
<td>.9480</td>
<td>.9490</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0049 (.0841)</td>
<td>.0841</td>
<td>.9500</td>
<td>.9510</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0135 (.0747)</td>
<td>.0749</td>
<td>.9620</td>
<td>.9610</td>
</tr>
<tr>
<td>.80</td>
<td>50</td>
<td>−.0099 (.1636)</td>
<td>.1637</td>
<td>.9320</td>
<td>.9410</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0034 (.1124)</td>
<td>.1124</td>
<td>.9450</td>
<td>.9490</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0067 (.0923)</td>
<td>.0923</td>
<td>.9480</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0151 (.0773)</td>
<td>.0776</td>
<td>.9510</td>
<td>.9510</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0088 (.0712)</td>
<td>.0713</td>
<td>.9440</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0033 (.0651)</td>
<td>.0651</td>
<td>.9440</td>
<td>.9450</td>
</tr>
<tr>
<td>.90</td>
<td>50</td>
<td>−.0161 (.1407)</td>
<td>.1407</td>
<td>.9280</td>
<td>.9340</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0132 (.0971)</td>
<td>.0972</td>
<td>.9400</td>
<td>.9420</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0107 (.0774)</td>
<td>.0775</td>
<td>.9480</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0074 (.0691)</td>
<td>.0691</td>
<td>.9450</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0033 (.0619)</td>
<td>.0619</td>
<td>.9400</td>
<td>.9410</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0042 (.0573)</td>
<td>.0573</td>
<td>.9460</td>
<td>.9470</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0013164412443963">
<p>Note: CI = confidence interval; RMSE = root mean square error; BCa = bias-corrected and accelerated bootstrap. Numbers in parentheses are standard errors; CIs in boldface fall outside the interval [.925, .975]. All CIs based on 1,000 bootstrap samples.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table5-0013164412443963" position="float">
<label>Table 5.</label>
<caption><p>95% CI Coverage for Reliability by Sample Size at .50 Correlation</p></caption>
<graphic alternate-form-of="table5-0013164412443963" xlink:href="10.1177_0013164412443963-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Reliability</th>
<th align="center"><italic>n</italic></th>
<th align="center">Relative bias</th>
<th align="center">RMSE</th>
<th align="center">Percentile CI</th>
<th align="center">BCa CI</th>
</tr>
</thead>
<tbody>
<tr>
<td>.50</td>
<td>50</td>
<td>−.0028 (.2637)</td>
<td>.2637</td>
<td>.9350</td>
<td>.9370</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>.0010 (.1787)</td>
<td>.1787</td>
<td>.9600</td>
<td>.9580</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0112 (.1529)</td>
<td>.1530</td>
<td>.9420</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0067 (.1288)</td>
<td>.1289</td>
<td>.9530</td>
<td>.9580</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0005 (.1227)</td>
<td>.1227</td>
<td>.9340</td>
<td>.9380</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0103 (.1085)</td>
<td>.1086</td>
<td>.9550</td>
<td>.9530</td>
</tr>
<tr>
<td>.60</td>
<td>50</td>
<td>−.0162 (.2182)</td>
<td>.2184</td>
<td>.9360</td>
<td>.9390</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0192 (.1505)</td>
<td>.1508</td>
<td>.9460</td>
<td>.9500</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0057 (.1266)</td>
<td>.1266</td>
<td>.9400</td>
<td>.9400</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0018 (.1066)</td>
<td>.1067</td>
<td>.9380</td>
<td>.9420</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0013 (.0957)</td>
<td>.0957</td>
<td>.9530</td>
<td>.9560</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>.0029 (.0866)</td>
<td>.0866</td>
<td>.9450</td>
<td>.9440</td>
</tr>
<tr>
<td>.70</td>
<td>50</td>
<td>−.0226 (.1806)</td>
<td>.1810</td>
<td>.9330</td>
<td>.9380</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0019 (.1252)</td>
<td>.1252</td>
<td>.9430</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0031 (.1025)</td>
<td>.1025</td>
<td>.9370</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0028 (.0878)</td>
<td>.0878</td>
<td>.9450</td>
<td>.9450</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0069 (.0813)</td>
<td>.0814</td>
<td>.9400</td>
<td>.9410</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0043 (.0723)</td>
<td>.0724</td>
<td>.9550</td>
<td>.9540</td>
</tr>
<tr>
<td>.80</td>
<td>50</td>
<td>−.0090 (.1479)</td>
<td>.1480</td>
<td>.9390</td>
<td>.9430</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0062 (.1032)</td>
<td>.1032</td>
<td>.9420</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>.0016 (.0837)</td>
<td>.0837</td>
<td>.9410</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0080 (.0742)</td>
<td>.0743</td>
<td>.9430</td>
<td>.9460</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>.0051 (.0669)</td>
<td>.0667</td>
<td>.9440</td>
<td>.9440</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0015 (.0613)</td>
<td>.0613</td>
<td>.9430</td>
<td>.9440</td>
</tr>
<tr>
<td>.90</td>
<td>50</td>
<td>−.0197 (.1304)</td>
<td>.1308</td>
<td>.9290</td>
<td>.9320</td>
</tr>
<tr>
<td/>
<td>100</td>
<td>−.0014 (.0873)</td>
<td>.0873</td>
<td>.9460</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>150</td>
<td>−.0005 (.0746)</td>
<td>.0746</td>
<td>.9350</td>
<td>.9380</td>
</tr>
<tr>
<td/>
<td>200</td>
<td>−.0035 (.0641)</td>
<td>.0641</td>
<td>.9400</td>
<td>.9420</td>
</tr>
<tr>
<td/>
<td>250</td>
<td>−.0000 (.0563)</td>
<td>.0563</td>
<td>.9500</td>
<td>.9480</td>
</tr>
<tr>
<td/>
<td>300</td>
<td>−.0006 (.0529)</td>
<td>.0529</td>
<td>.9490</td>
<td>.9500</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0013164412443963">
<p>Note: CI = confidence interval; RMSE = root mean square error; BCa = bias-corrected and accelerated bootstrap. Numbers in parentheses are standard errors; CIs in boldface fall outside the interval [.925, .975]. All CIs are based on 1,000 bootstrap samples.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section13-0013164412443963">
<title>Standard Error and Root Mean Squared Error</title>
<p>Although the <italic>SE</italic> is not technically required for the PB or BCa CI, it gives an indication of the precision of the deattenuated correlation. The results in <xref ref-type="table" rid="table1-0013164412443963">Tables 1</xref> through <xref ref-type="table" rid="table5-0013164412443963">5</xref> indicate that the deattenuated correlation has very little variability. In addition, the <italic>SE</italic> becomes smaller as the sample size and reliability increase, that is, the deattenuated correlation becomes more precise. The root mean square error (RMSE) is similar to the <italic>SE</italic> in magnitude and behaves in a similar manner, that is, the RMSE becomes smaller as the sample size and reliability increase.</p>
</sec>
<sec id="section14-0013164412443963">
<title>Confidence Intervals</title>
<p>For the majority of simulation conditions, both the PB and BCa CIs met Bradley’s criteria (<xref ref-type="bibr" rid="bibr2-0013164412443963">Bradley, 1978</xref>). Results are shown in <xref ref-type="table" rid="table1-0013164412443963">Tables 1</xref> through <xref ref-type="table" rid="table5-0013164412443963">5</xref>. In only the following three instances with a sample size of 50, the PB CIs fell slightly below the lower bound of Bradley’s criteria: (a) when the correlation was .10 and reliability was .60 and (b) when the correlation was .30 and the reliability was .50 or .70. However, the BCa CIs met Bradley’s criteria in all conditions. The slight underestimation of the PB CIs in the three conditions indicated above could be due to the PB CI requiring a sample size larger than 50 and/or could be due to simulation (or sampling) error.</p>
<p><xref ref-type="fig" rid="fig1-0013164412443963">Figures 1</xref> and <xref ref-type="fig" rid="fig2-0013164412443963">2</xref> display the 95% CI coverage for each method over sample size. As can be seen, both the PB and BCa CIs had similar coverage probabilities. However, the BCa CIs had more consistent estimation in that they had less variability and thus were narrower.</p>
<fig id="fig1-0013164412443963" position="float">
<label>Figure 1.</label>
<caption><p>Percentile bootstrap 95% confidence interval coverage over sample size</p></caption>
<graphic xlink:href="10.1177_0013164412443963-fig1.tif"/>
</fig>
<fig id="fig2-0013164412443963" position="float">
<label>Figure 2.</label>
<caption><p>Bias-corrected and accelerated 95% confidence interval coverage over sample size</p></caption>
<graphic xlink:href="10.1177_0013164412443963-fig2.tif"/>
</fig>
</sec>
</sec>
<sec id="section15-0013164412443963" sec-type="discussion">
<title>Discussion</title>
<p>Measurement error in the social/behavioral sciences is common because of the nature of the latent variables of interest in these fields such as anxiety, depression, IQ, and so on. These types of variables exist in potential but cannot be directly measured. Thus, they must be indirectly measured through items in a measurement instrument at which point the measurement error is introduced. However, measurement error in these types of variables can hinder the correlation between them which can propagate to other statistics and methodologies that are based on the correlation such as GLMs and meta-analysis (<xref ref-type="bibr" rid="bibr3-0013164412443963">Buckley et al., 1990</xref>; <xref ref-type="bibr" rid="bibr4-0013164412443963">Carroll et al., 2006</xref>; <xref ref-type="bibr" rid="bibr19-0013164412443963">Kassarjian, 1971</xref>; <xref ref-type="bibr" rid="bibr21-0013164412443963">Lance et al., 2010</xref>; <xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>; <xref ref-type="bibr" rid="bibr32-0013164412443963">Taft et al., 2011</xref>). Thus, it is important to get an accurate correlation estimate and accompanying CIs when there is measurement error in the variables.</p>
<p>Although the effects of measurement error on the correlation coefficient, and potential solution by way of the deattenuated correlation, have been known for over a century (<xref ref-type="bibr" rid="bibr30-0013164412443963">Spearman, 1904</xref>), to date very little of it is used in applied work (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>; <xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>). The main issues hindering its use are that CIs for it have been difficult to develop and that the deattenuated correlation can potentially be greater than one. Several recent studies have been conducted to investigate these issues further (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>; <xref ref-type="bibr" rid="bibr38-0013164412443963">Zimmerman &amp; Williams, 1997</xref>). Although the first study had promising results when reliability and sample size were .70 and 100 or greater, respectively, it did not investigate CIs. The second study investigated confidence sets as opposed to CIs for the deattenuated correlation. This method also showed promise; however, the lower bound had accuracy issues with high correlations (e.g., <italic>r</italic>≥ .70) and small sample sizes (e.g., <italic>n</italic>≤ 100). Even so, the methodology has seen little use in applied research.</p>
<p>Here we introduce a bootstrapped deattenuated correlation coefficient with corresponding CIs and assessed its statistical properties through simulation. Simulation conditions investigated included true population correlation, sample size, and reliability of both variables. According to the results, the BCa CIs were acceptable under all 150 conditions of the simulation. The PB CIs had unacceptable coverage in three simulation conditions: The conditions included a sample size of 50, reliability of .70 or less, and correlation between .10 and .30. For the conditions investigated, the BCa method showed excellent promise whereas some caution is warranted for the PB method with sample size of 50 or less and reliability of .70 or less. Thus, the bootstrapped deattenuated correlation is an adequate method for correcting the attenuated correlation due to measurement error and provides good estimates of corresponding CIs.</p>
<p>Bootstrap methodology is a flexible technique that can be used to solve a variety of statistical problems, but to our knowledge it has not been used to address measurement error in the correlation coefficient. In this capacity, the bootstrap holds much promise with three advantages. First, within this investigation, the bootstrap remained relatively unbiased and did not exceed the correlation bounds (±1), which was the primary criticism in earlier studies. Second, the bootstrap provided the ESD for the deattenuated correlation, which was recommended by <xref ref-type="bibr" rid="bibr5-0013164412443963">Charles (2005)</xref> and “. . . difficult, if not impossible . . .” according to <xref ref-type="bibr" rid="bibr14-0013164412443963">Hakstian, Schroeder, and Rogers (1988</xref>, p. 27). As such, the bootstrapped deattenuated correlation did not have any lower and/or upper bound accuracy issues. Third, the bootstrap deattenuated correlation can be extended to GLMs. The parameter estimates of any GLM can be obtained through the covariance (correlation) matrix and mean vector for a set of variables (for details, see <xref ref-type="bibr" rid="bibr35-0013164412443963">Timm, 2002</xref>). In this respect, one replaces the covariance matrix with the deattenuated covariance matrix at each <italic>b</italic>th step from which the GLM parameter estimates are obtained. From here, the ESD for each GLM parameter estimate is generated and can be used to make inferences.</p>
<p>A limitation here is that the bootstrapped deattenuated correlation’s performance was assessed using normally distributed data. Although the normality assumption dominates research in social/behavioral sciences, there is no indication that any proposed CI for the deattenuated correlation, including the one here, is robust to the normality assumption (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>; <xref ref-type="bibr" rid="bibr38-0013164412443963">Zimmerman &amp; Williams, 1997</xref>). Zimmerman and Williams did not investigate the CI for the deattenuated correlation; however, they indicated that the deattenuated estimate of the correlation is unbiased under a variety of distributions when the reliability is high (e.g., .70). This suggests that the bootstrapped deattenuated correlation may hold promise under nonnormality given that the procedure only requires an unbiased estimate to generate the correct CIs. Even so, future research should investigate the performance of the bootstrapped deattenuated correlation under nonnormality.</p>
<p>While other studies about the deattenuated correlation investigated a larger range for reliability, here we only focused on reliability that ranged from .50 to .90. This decision was made as a matter of practicality. It is difficult to imagine a researcher using a measurement instrument with reliability less than .70. A measurement instrument with a reliability estimate of .70 indicates that 30% of the instrument’s variance is error variance; a reliability estimate of .50 indicates that 50% of the instrument’s variance is error variance. Thus, we did not investigate as wide a range of reliability as previous studies; however, the range that was investigated is sufficient for applied research. In addition, the reality is that in applied research a measurement instrument with more than 30% of its variance being error variance should probably not be used (<xref ref-type="bibr" rid="bibr26-0013164412443963">Nunnally, 1978</xref>). In this case, the researcher should find or create a more adequate measurement instrument.</p>
<p>As previously mentioned, the deattenuated correlation has seen very little use in the social/behavioral sciences since its inception more than 100 years ago (<xref ref-type="bibr" rid="bibr5-0013164412443963">Charles, 2005</xref>). Although several reasons have been discussed, the most likely reason is the vast popularity of coefficient alpha (<xref ref-type="bibr" rid="bibr7-0013164412443963">Cortina, 1993</xref>; <xref ref-type="bibr" rid="bibr16-0013164412443963">Hogan, Benjamin, &amp; Brezinski, 2000</xref>). It is widely known that coefficient alpha is a lower bound estimate of reliability, and therefore it is used to provide a conservative estimate of reliability. Given that the deattenuated correlation, including the one proposed here, assumes that the reliability estimate is accurate, researchers most likely worry that using coefficient alpha will inflate the estimated deattenuated correlation and possibly make it larger than one. This is a valid concern. However, researchers should be reminded that coefficient alpha is not the only measure of reliability.</p>
<p>As discussed earlier, an alternative to coefficient alpha is coefficient omega (<xref ref-type="bibr" rid="bibr23-0013164412443963">McDonald, 1999</xref>; <xref ref-type="bibr" rid="bibr39-0013164412443963">Zinbarg et al., 2005</xref>). Coefficient omega provides a comparable form of reliability to coefficient alpha but does not have the strict assumption that the items have to be tau-equivalent or essentially tau-equivalent. When this assumption is not met, coefficient alpha will underestimate the reliability whereas coefficient omega will not. Hence, there is an option to using coefficient alpha. See <xref ref-type="bibr" rid="bibr23-0013164412443963">McDonald (1999)</xref> and <xref ref-type="bibr" rid="bibr39-0013164412443963">Zinbarg et al. (2005)</xref> for further details.</p>
<p>As noted by <xref ref-type="bibr" rid="bibr5-0013164412443963">Charles (2005)</xref>, arguing that the deattenuated correlation is imperfect indicates that the attenuated correlation is even more imperfect. If attenuation due to measurement error continues to be ignored, researchers will continue to have a difficult time finding a true relationship (or effect) that may exist. Furthermore, it automatically implies that variables are measured without error, which is not the case in the social/behavioral sciences (<xref ref-type="bibr" rid="bibr29-0013164412443963">Schmidt &amp; Hunter, 1996</xref>). Although attenuated correlations continue to be used, it is mostly out of a defensive position in that it is better to be conservative than overoptimistic. In addition, Schmidt and Hunter suggest that such a position is emotional as opposed to rational, and that failure to correct for attenuation is the second worst methodological error in the literature—second only to declaring significance when a <italic>p</italic> value is less than .05.</p>
<p>In conclusion, this preliminary study has illustrated the increase in accuracy when combining the deattenuated correlation with the bootstrap procedure. According to the results, the bootstrapped deattenuated correlation is an adequate method for correcting the attenuated correlation due to measurement error and provides equally adequate CIs. Given the controversy over the deattenuated correlation, it is hoped that the presentation here, at the very least, is a good start at revisiting this century-old problem.</p>
<p>Interested researchers can obtain an easy-to-use R function for the bootstrapped deattenuated correlation with example data free of charge by contacting the corresponding author.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Allen</surname><given-names>M. J.</given-names></name>
<name><surname>Yen</surname><given-names>W. M.</given-names></name>
</person-group> (<year>1979</year>). <source>Introduction to measurement theory</source>. <publisher-loc>Monterey, CA</publisher-loc>: <publisher-name>Brooks/Cole</publisher-name>.</citation>
</ref>
<ref id="bibr2-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradley</surname><given-names>J. V.</given-names></name>
</person-group> (<year>1978</year>). <article-title>Robustness?</article-title> <source>British Journal of Mathematics and Statistical Psychology</source>, <volume>31</volume>, <fpage>144</fpage>-<lpage>152</lpage>.</citation>
</ref>
<ref id="bibr3-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Buckley</surname><given-names>M. R.</given-names></name>
<name><surname>Cote</surname><given-names>J. A.</given-names></name>
<name><surname>Comstock</surname><given-names>S. M.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Measurement errors in the behavioral sciences: The case of personality/attitude research</article-title>. <source>Educational and Psychological Measurement</source>, <volume>50</volume>, <fpage>447</fpage>-<lpage>474</lpage>. doi:10.1177/0013164490503001<pub-id pub-id-type="doi">10.1177/0013164490503001</pub-id></citation>
</ref>
<ref id="bibr4-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Carroll</surname><given-names>R. J.</given-names></name>
<name><surname>Ruppert</surname><given-names>D.</given-names></name>
<name><surname>Stefanski</surname><given-names>L. A.</given-names></name>
<name><surname>Crainiceanu</surname><given-names>C. M.</given-names></name>
</person-group> (<year>2006</year>). <source>Measurement error in nonlinear models: A modern perspective</source> (<edition>2nd ed.</edition>). <publisher-loc>Boca Raton, FL</publisher-loc>: <publisher-name>Chapman &amp; Hall/CRC</publisher-name>.</citation>
</ref>
<ref id="bibr5-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Charles</surname><given-names>E. P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The correction for attenuation due to measurement error: Clarifying concepts and creating confidence sets</article-title>. <source>Psychological Methods</source>, <volume>10</volume>, <fpage>206</fpage>-<lpage>226</lpage>. doi:10.1037/1082-989X.10.2.206<pub-id pub-id-type="doi">10.1037/1082-989X.10.2.206</pub-id></citation>
</ref>
<ref id="bibr6-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cohen</surname><given-names>J.</given-names></name>
</person-group> (<year>1988</year>). <source>Statistical power analysis for the behavioral sciences</source> (<edition>2nd ed.</edition>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr7-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cortina</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1993</year>). <article-title>What is coefficient alpha? An examination of theory and applications</article-title>. <source>Journal of Applied Psychology</source>, <volume>78</volume>, <fpage>98</fpage>-<lpage>104</lpage>. doi:10.1037/0021-9010.78.1.98<pub-id pub-id-type="doi">10.1037/0021-9010.78.1.98</pub-id></citation>
</ref>
<ref id="bibr8-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Crocker</surname><given-names>L. M.</given-names></name>
<name><surname>Algina</surname><given-names>J.</given-names></name>
</person-group> (<year>1986</year>). <source>Introduction to classical and modern test theory</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Holt, Rinehart &amp; Winston</publisher-name>.</citation>
</ref>
<ref id="bibr9-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Efron</surname><given-names>B.</given-names></name>
<name><surname>Tibshirani</surname><given-names>R.</given-names></name>
</person-group> (<year>1993</year>). <source>An introduction to the bootstrap</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Chapman &amp; Hall</publisher-name>.</citation>
</ref>
<ref id="bibr10-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fan</surname><given-names>X.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Two approaches for correcting correlation attenuation caused by measurement error: Implications for research practice</article-title>. <source>Educational and Psychological Measurement</source>, <volume>63</volume>, <fpage>915</fpage>-<lpage>930</lpage>. doi:10.1177/0013164403251319<pub-id pub-id-type="doi">10.1177/0013164403251319</pub-id></citation>
</ref>
<ref id="bibr11-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fiske</surname><given-names>D. W.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Construct invalidity comes from method effects</article-title>. <source>Educational and Psychological Measurement</source>, <volume>47</volume>, <fpage>285</fpage>-<lpage>307</lpage>. doi:10.1177/0013164487472001<pub-id pub-id-type="doi">10.1177/0013164487472001</pub-id></citation>
</ref>
<ref id="bibr12-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fleiss</surname><given-names>J. L.</given-names></name>
<name><surname>Shrout</surname><given-names>P. E.</given-names></name>
</person-group> (<year>1977</year>). <article-title>The effects of measurement errors on some multivariate procedures</article-title>. <source>American Journal of Public Health</source>, <volume>67</volume>, <fpage>1188</fpage>-<lpage>1191</lpage>. doi:10.2105/ajph.67.12.1188<pub-id pub-id-type="doi">10.2105/ajph.67.12.1188</pub-id></citation>
</ref>
<ref id="bibr13-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Graham</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Congeneric and (essentially) tau-equivalent estimates of score reliability</article-title>. <source>Educational and Psychological Measurement</source>, <volume>66</volume>, <fpage>930</fpage>-<lpage>944</lpage>. doi:10.1177/0013164406288165<pub-id pub-id-type="doi">10.1177/0013164406288165</pub-id></citation>
</ref>
<ref id="bibr14-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hakstian</surname><given-names>A. R.</given-names></name>
<name><surname>Schroeder</surname><given-names>M. L.</given-names></name>
<name><surname>Rogers</surname><given-names>W. T.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Inferential procedures for correlation coefficients corrected for attenuation</article-title>. <source>Psychometrika</source>, <volume>53</volume>, <fpage>27</fpage>-<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr15-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hobfoll</surname><given-names>S. E.</given-names></name>
<name><surname>Shoham</surname><given-names>S. B.</given-names></name>
<name><surname>Ritter</surname><given-names>C.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Women’s satisfaction with social support and their receipt of aid</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>61</volume>, <fpage>332</fpage>-<lpage>341</lpage>. doi:10.1037/0022-3514.61.2.332<pub-id pub-id-type="doi">10.1037/0022-3514.61.2.332</pub-id></citation>
</ref>
<ref id="bibr16-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hogan</surname><given-names>T. P.</given-names></name>
<name><surname>Benjamin</surname><given-names>A.</given-names></name>
<name><surname>Brezinski</surname><given-names>K. L.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Reliability methods: A note on the frequency of use of various types</article-title>. <source>Educational and Psychological Measurement</source>, <volume>60</volume>, <fpage>523</fpage>-<lpage>531</lpage>. doi:10.1177/00131640021970691<pub-id pub-id-type="doi">10.1177/00131640021970691</pub-id></citation>
</ref>
<ref id="bibr17-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>H. G.</given-names></name>
</person-group> (<year>1944</year>). <article-title>An empirical study of the influence of errors of measurement upon correlation</article-title>. <source>American Journal of Psychology</source>, <volume>57</volume>, <fpage>521</fpage>-<lpage>536</lpage>. doi:10.2307/1417247<pub-id pub-id-type="doi">10.2307/1417247</pub-id></citation>
</ref>
<ref id="bibr18-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>N. C.</given-names></name>
<name><surname>Kotz</surname><given-names>S.</given-names></name>
<name><surname>Balakrishnan</surname><given-names>N.</given-names></name>
</person-group> (<year>1995</year>). <source>Continuous univariate distributions</source> (<volume>Vol. 2</volume>, <edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr19-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kassarjian</surname><given-names>H. H.</given-names></name>
</person-group> (<year>1971</year>). <article-title>Personality and consumer behavior: A review</article-title>. <source>Journal of Marketing Research</source>, <volume>8</volume>, <fpage>409</fpage>-<lpage>418</lpage>.</citation>
</ref>
<ref id="bibr20-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kirkpatrick</surname><given-names>L. A.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Effects of multiple determinacy and measurement error on trait-behavior and behavior-behavior relations: An integrated conceptual model</article-title>. <source>Personality and Social Psychology Bulletin</source>, <volume>23</volume>, <fpage>199</fpage>-<lpage>209</lpage>. doi:10.1177/0146167297232008<pub-id pub-id-type="doi">10.1177/0146167297232008</pub-id></citation>
</ref>
<ref id="bibr21-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lance</surname><given-names>C. E.</given-names></name>
<name><surname>Dawson</surname><given-names>B.</given-names></name>
<name><surname>Birkelbach</surname><given-names>D.</given-names></name>
<name><surname>Hoffman</surname><given-names>B. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Method effects, measurement error, and substantive conclusions</article-title>. <source>Organizational Research Methods</source>, <volume>13</volume>, <fpage>435</fpage>-<lpage>455</lpage>. doi:10.1177/1094428109352528<pub-id pub-id-type="doi">10.1177/1094428109352528</pub-id></citation>
</ref>
<ref id="bibr22-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lord</surname><given-names>F.</given-names></name>
<name><surname>Novick</surname><given-names>M.</given-names></name>
<name><surname>Birnbaum</surname><given-names>A.</given-names></name>
</person-group> (<year>1968</year>). <source>Statistical theories of mental test scores</source>. <publisher-loc>Oxford, England</publisher-loc>: <publisher-name>Addison-Wesley</publisher-name>.</citation>
</ref>
<ref id="bibr23-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McDonald</surname><given-names>R. P.</given-names></name>
</person-group> (<year>1999</year>). <source>Test theory: A unified treatment</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr24-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Murphy</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Explaining the weak relationship between job performance and ratings of job performance</article-title>. <source>Industrial and Organizational Psychology</source>, <volume>1</volume>, <fpage>148</fpage>-<lpage>160</lpage>. doi:10.1111/j.1754-9434.2008.00030.x<pub-id pub-id-type="doi">10.1111/j.1754-9434.2008.00030.x</pub-id></citation>
</ref>
<ref id="bibr25-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mutch</surname><given-names>C.</given-names></name>
<name><surname>Tisak</surname><given-names>J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Measurement error and the correlation between positive and negative affect: Spearman (1904, 1907) revisited</article-title>. <source>Psychological Reports</source>, <volume>96</volume>(<issue>1</issue>), <fpage>43</fpage>-<lpage>46</lpage>. doi:10.2466/pr0.96.1.43-46<pub-id pub-id-type="doi">10.2466/pr0.96.1.43-46</pub-id></citation>
</ref>
<ref id="bibr26-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nunnally</surname><given-names>J. C.</given-names></name>
</person-group> (<year>1978</year>). <source>Psychometric theory</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</citation>
</ref>
<ref id="bibr27-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Pedhazur</surname><given-names>E. J.</given-names></name>
</person-group> (<year>1997</year>). <source>Multiple regression in behavioral research: Explanation and prediction</source> (<edition>3rd ed.</edition>). <publisher-loc>Orlando, FL</publisher-loc>: <publisher-name>Harcourt Brace</publisher-name>.</citation>
</ref>
<ref id="bibr28-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Romano</surname><given-names>J. L.</given-names></name>
<name><surname>Kromrey</surname><given-names>J. D.</given-names></name>
<name><surname>Hibbard</surname><given-names>S. T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A Monte Carlo study of eight confidence interval methods for coefficient alpha</article-title>. <source>Educational and Psychological Measurement</source>, <volume>70</volume>, <fpage>376</fpage>-<lpage>393</lpage>. doi:10.1177/0013164409355690<pub-id pub-id-type="doi">10.1177/0013164409355690</pub-id></citation>
</ref>
<ref id="bibr29-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schmidt</surname><given-names>F. L.</given-names></name>
<name><surname>Hunter</surname><given-names>J. E.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Measurement error in psychological research: Lessons from 26 research scenarios</article-title>. <source>Psychological Methods</source>, <volume>1</volume>, <fpage>199</fpage>-<lpage>223</lpage>. doi:10.1037/1082-989X.1.2.199<pub-id pub-id-type="doi">10.1037/1082-989X.1.2.199</pub-id></citation>
</ref>
<ref id="bibr30-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Spearman</surname><given-names>C.</given-names></name>
</person-group> (<year>1904</year>). <article-title>The proof and measurement of association between two things</article-title>. <source>American Journal of Psychology</source>, <volume>15</volume>, <fpage>72</fpage>-<lpage>101</lpage>.</citation>
</ref>
<ref id="bibr31-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stayrook</surname><given-names>N.</given-names></name>
<name><surname>Corno</surname><given-names>L. Y. N.</given-names></name>
</person-group> (<year>1979</year>). <article-title>An application of generalizability theory in disattenuating a path model of teaching and learning</article-title>. <source>Journal of Educational Measurement</source>, <volume>16</volume>, <fpage>227</fpage>-<lpage>237</lpage>. doi:10.1111/j.1745-3984.1979.tb00104.x<pub-id pub-id-type="doi">10.1111/j.1745-3984.1979.tb00104.x</pub-id></citation>
</ref>
<ref id="bibr32-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Taft</surname><given-names>C. T.</given-names></name>
<name><surname>Watkins</surname><given-names>L. E.</given-names></name>
<name><surname>Stafford</surname><given-names>J.</given-names></name>
<name><surname>Street</surname><given-names>A. E.</given-names></name>
<name><surname>Monson</surname><given-names>C. M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Posttraumatic stress disorder and intimate relationship problems: A meta-analysis</article-title>. <source>Journal of Consulting and Clinical Psychology</source>, <volume>79</volume>, <fpage>22</fpage>-<lpage>33</lpage>. doi:10.1037/a0022196<pub-id pub-id-type="doi">10.1037/a0022196</pub-id></citation>
</ref>
<ref id="bibr33-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tarkkonen</surname><given-names>L.</given-names></name>
<name><surname>Vehkalahti</surname><given-names>K.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Measurement errors in multivariate measurement scales</article-title>. <source>Journal of Multivariate Analysis</source>, <volume>96</volume>, <fpage>172</fpage>-<lpage>189</lpage>. doi:10.1016/j.jmva.2004.09.007<pub-id pub-id-type="doi">10.1016/j.jmva.2004.09.007</pub-id></citation>
</ref>
<ref id="bibr34-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thomas</surname><given-names>S. P.</given-names></name>
<name><surname>Williams</surname><given-names>R. L.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Perceived stress, trait anger, modes of anger expression, and health status of college men and women</article-title>. <source>Nursing Research</source>, <volume>40</volume>, <fpage>303</fpage>-<lpage>307</lpage>.</citation>
</ref>
<ref id="bibr35-0013164412443963">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Timm</surname><given-names>N. H.</given-names></name>
</person-group> (<year>2002</year>). <source>Applied multivariate analysis</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr36-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Winne</surname><given-names>P. H.</given-names></name>
<name><surname>Belfry</surname><given-names>M. J.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Interpretive problems when correcting for attenuation</article-title>. <source>Journal of Educational Measurement</source>, <volume>19</volume>, <fpage>125</fpage>-<lpage>134</lpage>. doi:10.1111/j.1745-3984.1982.tb00121.x<pub-id pub-id-type="doi">10.1111/j.1745-3984.1982.tb00121.x</pub-id></citation>
</ref>
<ref id="bibr37-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>You</surname><given-names>J.</given-names></name>
<name><surname>Chen</surname><given-names>G.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Estimation of a semiparametric varying-coefficient partially linear errors-in-variables model</article-title>. <source>Journal of Multivariate Analysis</source>, <volume>97</volume>, <fpage>324</fpage>-<lpage>341</lpage>. doi:10.1016/j.jmva.2005.03.002<pub-id pub-id-type="doi">10.1016/j.jmva.2005.03.002</pub-id></citation>
</ref>
<ref id="bibr38-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zimmerman</surname><given-names>D. W.</given-names></name>
<name><surname>Williams</surname><given-names>R. H.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Properties of the Spearman correction for attenuation for normal and realistic non-normal distributions</article-title>. <source>Applied Psychological Measurement</source>, <volume>21</volume>, <fpage>253</fpage>-<lpage>270</lpage>. doi:10.1177/01466216970213005<pub-id pub-id-type="doi">10.1177/01466216970213005</pub-id></citation>
</ref>
<ref id="bibr39-0013164412443963">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zinbarg</surname><given-names>R. E.</given-names></name>
<name><surname>Revelle</surname><given-names>W.</given-names></name>
<name><surname>Yovel</surname><given-names>I.</given-names></name>
<name><surname>Li</surname><given-names>W.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Cronbach’s α, Revelle’s β, and Mcdonald’s ω<sub>H</sub>: Their relations with each other and two alternative conceptualizations of reliability</article-title>. <source>Psychometrika</source>, <volume>70</volume>, <fpage>123</fpage>-<lpage>133</lpage>. doi:10.1007/s11336-003-0974-7<pub-id pub-id-type="doi">10.1007/s11336-003-0974-7</pub-id></citation>
</ref>
</ref-list>
</back>
</article>