<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">FMX</journal-id>
<journal-id journal-id-type="hwp">spfmx</journal-id>
<journal-title>Field Methods</journal-title>
<issn pub-type="ppub">1525-822X</issn>
<issn pub-type="epub">1552-3969</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1525822X11419478</article-id>
<article-id pub-id-type="publisher-id">10.1177_1525822X11419478</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Effects of Item Saliency and Question Design on Measurement Error in a Self-Administered Survey</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Stern</surname>
<given-names>Michael J.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1525822X11419478">1</xref>
<xref ref-type="corresp" rid="corresp1-1525822X11419478"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Smyth</surname>
<given-names>Jolene D.</given-names>
</name>
<xref ref-type="aff" rid="aff2-1525822X11419478">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mendez</surname>
<given-names>Jeanette</given-names>
</name>
<xref ref-type="aff" rid="aff3-1525822X11419478">3</xref>
</contrib>
</contrib-group>
<aff id="aff1-1525822X11419478"><label>1</label> Department of Sociology and Anthropology, College of Charleston, Charleston, SC, USA</aff>
<aff id="aff2-1525822X11419478"><label>2</label> Department of Sociology, UNL Gallup Research Center, University of Nebraska–Lincoln, Lincoln, NE, USA</aff>
<aff id="aff3-1525822X11419478"><label>3</label> Department of Political Science, Oklahoma State University, Stillwater, OK, USA</aff>
<author-notes>
<corresp id="corresp1-1525822X11419478">Michael J. Stern, Department of Sociology and Anthropology, College of Charleston, 66 George St. Charleston, SC 29424, USA Email: <email>sternm@cofc.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2012</year>
</pub-date>
<volume>24</volume>
<issue>1</issue>
<fpage>3</fpage>
<lpage>27</lpage>
<permissions>
<copyright-statement>© SAGE Publications 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Recent survey design research has shown that small changes in the structure and visual layout of questions can affect respondents’ answers, but the results are not always consistent across studies. One possible reason for some of the inconsistency may be differences in the item saliency of the questions used in the experiments. In this article, the authors examine how item saliency might influence visual design effects. The authors report the results of three experimental alterations in question format and visual design using data from a 2005 random sample mail survey of 1,315 households. The results suggest that the saliency of the questions has effects both independent of and in concert with the layout of the questions. The implications for survey design are discussed.</p>
</abstract>
<kwd-group>
<kwd>survey</kwd>
<kwd>saliency</kwd>
<kwd>visual design</kwd>
<kwd>measurement error</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1525822X11419478">
<title>Introduction</title>
<p>Over the past decade, research on the design of survey items has shown that even the most minor changes can have a tremendous influence on respondents’ answers. The reason for these response effects seems to lie in the way respondents use both verbal (i.e., words) and visual questionnaire stimuli to comprehend and answer items (<xref ref-type="bibr" rid="bibr15-1525822X11419478">Jenkins and Dillman 1997</xref>) and in their predisposed expectations during the answering process. To the latter point, <xref ref-type="bibr" rid="bibr36-1525822X11419478">Tourangeau et al. (2004)</xref> explain that respondents expect more positive response options to appear at the top of lists (an “expected order”), and when survey questions violate this expectation it can cause some measure of confusion. Thus, both the design features of a question and its consistency with a respondent’s expectations can affect the answers provided across a variety of question formats (<xref ref-type="bibr" rid="bibr3-1525822X11419478">Christian and Dillman 2004</xref>) and modes (<xref ref-type="bibr" rid="bibr6-1525822X11419478">Dillman and Christian 2005</xref>). However, there has been some discussion as to why certain questions show response effects while others do not (<xref ref-type="bibr" rid="bibr7-1525822X11419478">Dillman et al. 1996</xref>; <xref ref-type="bibr" rid="bibr24-1525822X11419478">Schuman and Presser 1981</xref>). One plausible explanation is item saliency—that is, the degree to which the topic of any given survey question resonates with the respondent.</p>
<p>Survey research addressing the effects of saliency has largely focused on its implications for response rates (see <xref ref-type="bibr" rid="bibr13-1525822X11419478">Groves et al. 2000</xref>). In short, the theory and empirical research suggests that respondents are more likely to respond to questionnaires with more salient topics. However, while it has been suggested that both question topic (i.e., saliency) and design features of individual questions affect respondent processing (<xref ref-type="bibr" rid="bibr8-1525822X11419478">Dillman et al. 2009</xref>), the ways in which saliency might affect the answering process at the level of individual questions is absent within current discussions of saliency. Also absent from consideration is whether item saliency and visual design have mutually exclusive or combined effects on how respondents answer questions. In addition, the interaction between visual layout and item saliency may be further complicated by respondents’ personal characteristics. In this article, we report the results of three visual design experiments, taking into account item saliency and respondents’ demographic characteristics. The experiments were embedded in two versions of a questionnaire concerning community satisfaction and civic participation. While these three experiments do not provide a large number of replications, they offer a beginning for expanding our understanding of saliency to individual questions and for disentangling the independent and mutual effects of item saliency and visual layout.</p>
</sec>
<sec id="section2-1525822X11419478">
<title>Theoretical Background</title>
<sec id="section3-1525822X11419478">
<title>Understanding the Response Process</title>
<p>Survey researchers have made significant progress toward explicating the mental processes respondents undergo when interpreting and answering survey questions. For example, <xref ref-type="bibr" rid="bibr35-1525822X11419478">Tourangeau (1984)</xref> and <xref ref-type="bibr" rid="bibr15-1525822X11419478">Jenkins and Dillman (1997)</xref> have articulated a multistep progression to explain the response process. Respondents start in a perception stage where they assess a question’s format or design and the item’s topic and move to comprehending the question, recalling relevant information, deciding on an answer, and providing a response. <xref ref-type="bibr" rid="bibr25-1525822X11419478">Schwarz (1996)</xref> argues that respondents work through this response process as cooperative communicators, meaning that they follow and expect that the researcher also follows communication norms requiring all information exchanged to be useful, understandable, and relevant to the task at hand. Thus, respondents assume that both the words and the more formal design elements used are relevant to the response task.</p>
<p>Respondents do not always do the cognitive work necessary to adequately answer a survey item; this shortcutting of the response process is most often referred to as “satisficing” (<xref ref-type="bibr" rid="bibr18-1525822X11419478">Krosnick and Alwin 1987</xref>). Most of the research on satisficing in self-administered surveys has focused on scalar questions, but it also occurs in mark-all-that-apply questions (<xref ref-type="bibr" rid="bibr27-1525822X11419478">Smyth et al. 2006</xref>), ranking questions (<xref ref-type="bibr" rid="bibr30-1525822X11419478">Stern et al. 2007</xref>), and questions that include a nonqualifier (<xref ref-type="bibr" rid="bibr5-1525822X11419478">Converse 1964</xref>). Although there are many respondent-driven reasons for satisficing, there are two plausible reasons that are the direct results of a study’s features: an item’s substantive appeal (or salience) and an item’s visual layout.</p>
</sec>
<sec id="section4-1525822X11419478">
<title>Saliency</title>
<p>
<xref ref-type="bibr" rid="bibr31-1525822X11419478">Sudman and Bradburn (1974)</xref> argue that there are three elements that can increase the saliency of a survey: (1) the survey’s uniqueness; (2) high economic or social benefits and low costs; and (3) the potential for positive long-term consequences. Under ideal circumstances, at least one of these elements will be present and will motivate completion of the survey using optimal processing behavior. If these features are not present, respondents are more likely to end the survey conversation. Thus, saliency, as a motivating factor, can influence data quality.</p>
<p>Much of the research on saliency focuses on response rates to the overall survey and strongly supports the notion that topic interest encourages response (<xref ref-type="bibr" rid="bibr13-1525822X11419478">Groves et al. 2000</xref>; <xref ref-type="bibr" rid="bibr12-1525822X11419478">Groves et al. 2004</xref>; <xref ref-type="bibr" rid="bibr21-1525822X11419478">Marcus et al. 2007</xref>). In fact, <xref ref-type="bibr" rid="bibr12-1525822X11419478">Groves et al. (2004)</xref> find a 40% increase in response rates when individuals are interested in the survey topic. However, in their work on open-ended questions, <xref ref-type="bibr" rid="bibr14-1525822X11419478">Holland and Christian (2009)</xref> extend leverage saliency theory to individual questions and find that topic interest also affects completion of individual items as well as the quality of the responses given. Thus, topic interest and the resulting saliency of a given item play a role in the answering process, yet we have little research on how respondents who have low levels of salience may answer in similar or different ways than people for whom the question topic is of interest. Even if surveyors get respondents who are low in saliency to answer, we may not be getting the same quality of data. There is some support for this assertion. For example, <xref ref-type="bibr" rid="bibr9-1525822X11419478">Eisenhower et al. (1991)</xref> suggest that saliency influences the answers respondents provide (i.e., measurement error) by affecting the respondent’s motivation and ability to comprehensively proceed through the “recall” stage of the answering process.</p>
</sec>
<sec id="section5-1525822X11419478">
<title>Visual Design Theory</title>
<p>Another direct influence on the answering process in self-administered surveys comes from the design of the questions. Early empirical observations by Tom Smith about how small changes in survey items affect the answering process gave rise to the work of <xref ref-type="bibr" rid="bibr15-1525822X11419478">Jenkins and Dillman (1997)</xref>, who address how visual and spatial cues affect the way respondents interpret information in a survey. The major insight of visual design theory is that even the formal visual elements of a self-administered questionnaire are assumed by respondents to be meaningful and important information and thus are used in the response process. These formal features might include the numbers in the queries and answer categories, the graphical elements on the questionnaire, and any symbols such as arrows. In addition, the properties applied to these visual elements such as size, spacing, location, font, contrast, brightness, and color communicate meaning to respondents.</p>
<p>A number of studies have established the importance of visual design in various types of questions. For example, <xref ref-type="bibr" rid="bibr4-1525822X11419478">Christian et al. (2007)</xref> were able to use visual design manipulations to increase the percentage of respondents formatting a date correctly from 45% to 96%. Likewise, <xref ref-type="bibr" rid="bibr3-1525822X11419478">Christian and Dillman (2004)</xref> and <xref ref-type="bibr" rid="bibr26-1525822X11419478">Smyth et al. (2009</xref>) have shown that providing larger answer boxes can increase the amount of information respondents provide in open-ended questions in both mail and web surveys. The visual layout of response options in rows and columns versus one single column in scalar questions has also been shown to affect responses (<xref ref-type="bibr" rid="bibr3-1525822X11419478">Christian and Dillman 2004</xref>; <xref ref-type="bibr" rid="bibr33-1525822X11419478">Toepoel 2008</xref>), as has the placement of nonsubstantive response options in bipolar scalar questions (<xref ref-type="bibr" rid="bibr36-1525822X11419478">Tourangeau et al. 2004</xref>). In other words, the effects of visual design occur across question types (see <xref ref-type="bibr" rid="bibr8-1525822X11419478">Dillman et al. 2009</xref> for a review).</p>
</sec>
<sec id="section6-1525822X11419478">
<title>The Interaction of Item Saliency and Question Design</title>
<p>As the above review shows, both decreased saliency and poor visual design can independently affect responses. However, another possibility is that saliency and visual design might have interacting effects such that those for whom the question topic is least interesting or salient might be most affected when the visual design does not conform to expectations. In their elaboration likelihood model, <xref ref-type="bibr" rid="bibr22-1525822X11419478">Petty and Cacioppo (1986)</xref> develop two cognitive processing routes to explain attitude formation and change. The first, the <italic>central route</italic>, requires a great amount of effort and thought, or high elaboration. Those processing along this route thoroughly think through the merits of the argument, resulting in a decision that is a function of the positive and negative thoughts generated. When positive thoughts are generated and the topic is considered, the message is accepted. On the other hand, if the elaboration produces negative responses, the message will be rejected. The second, the <italic>peripheral route</italic>, does not involve intensive scrutiny of the message itself. Rather, individuals consider peripheral cues and heuristics (e.g., perceived source credibility) when arriving at a decision.</p>
<p>Applying <xref ref-type="bibr" rid="bibr22-1525822X11419478">Petty and Cacioppo’s (1986)</xref> model to visual design of survey questions suggests that those with higher interest will engage in thorough cognitive processing of tasks, focusing strongly on the direct verbal cues, while those with lower interest will rely on peripheral cues such as visual design elements; that is, people may rely on visual design differently in the answering process because of differences in item saliency. Recent research supports this assertion. For example, <xref ref-type="bibr" rid="bibr34-1525822X11419478">Toepol et al (2009)</xref> apply an “information-processing perspective” to examine how question item saliency impacts responses to web survey scalar questions with a variety of different response option formats ranging from “regular” or expected to “irregular” or unexpected. Their research suggests that people for whom the questions were the least salient relied on peripheral cues more so than people who were interested in the question topic. Thus, we would expect to see differences in the effects of visual design alterations across those with high and low topic interest. More specifically, we would expect the responses of those with low topic interest to be more strongly affected by changes in visual design.</p>
</sec>
<sec id="section7-1525822X11419478">
<title>The Influence of Respondent Characteristics</title>
<p>A respondent’s personal characteristics can have a bearing on both the saliency and visual design influences on responses to an item. With regard to saliency, certain question domains might hold a different appeal depending on gender, level of education, or age. An emerging literature also suggests that there are at least subtle differential effects of survey item design on people with varying demographic characteristics. For example, <xref ref-type="bibr" rid="bibr19-1525822X11419478">Krosnick et al. (1996)</xref> find that response order effects are more prevalent among people with lower levels of education. Likewise, <xref ref-type="bibr" rid="bibr16-1525822X11419478">Knäuper (1999)</xref> and <xref ref-type="bibr" rid="bibr17-1525822X11419478">Knäuper et al. (1998)</xref> argue that individuals over 60 years of age are more impacted by visual layout than younger individuals. Recently, <xref ref-type="bibr" rid="bibr30-1525822X11419478">Stern et al. (2007)</xref> found that the visual layout of questions affected respondents across education levels, ages, and genders in similar directions, but that the size of the effects varied across these demographic groups, suggesting that some demographic groups are more influenced by visual design than others.</p>
</sec>
<sec id="section8-1525822X11419478">
<title>Summary</title>
<p>The research on the answering process has begun to address the impact of survey question design on respondent behavior but has failed to account for the influence of item saliency. Likewise, research on saliency has largely focused on unit nonresponse, ignoring the effects of saliency on individual items. What is more, there are theoretical reasons to suspect that there may be an interaction between visual design and item saliency that may affect the way respondents answer individual survey questions. Finally, some of the variation in response behavior due to visual design and/or saliency may be the result of the respondents’ personal characteristics. In the analyses that follow, we assess the relative effect of these factors—independently and in concert—on the way respondents answer survey questions.</p>
</sec>
</sec>
<sec id="section9-1525822X11419478">
<title>Methods and Procedures</title>
<p>The experiments reported here were embedded in two versions of a 2005 self-administered mail survey about community satisfaction and civic participation (<xref ref-type="bibr" rid="bibr28-1525822X11419478">Stern 2006</xref>). Respondents were randomly assigned to one of the two versions. The overall design of the two versions was very similar with only a slight paper color difference (white and off-white) between them. The 10-page questionnaire with 75 queries for the average respondent was sent to a random sample of 2,000 households, 1,315 of which completed and returned it, culminating in a response rate of 65.75% (American Association for Public Opinion Research [<xref ref-type="bibr" rid="bibr1-1525822X11419478">AAPOR] 2008</xref>, RR1).</p>
<p>The implementation design used three mail contacts: an initial invitation and questionnaire with a $2 token incentive, a post card follow-up sent 2 weeks later, and a replacement questionnaire and letter sent to nonresponding households about 2 weeks after the postcard. In all contacts, respondents with the most recent birthday were asked to respond in order to achieve a gender balance.</p>
<sec id="section10-1525822X11419478">
<title>Visual Design Experiments</title>
<p>The experiments were designed to replicate previous work in the area of visual design with the substantive topics of the questions written to assess the effects of item saliency. The result is a diverse set of question format experiments including: (1) polar point versus number boxes in a scalar question; (2) check-all-that-apply versus forced choice formats; and (3) small versus large answer spaces in an open-ended question.</p>
</sec>
<sec id="section11-1525822X11419478">
<title>Measuring Item Saliency</title>
<p>While measuring saliency is difficult, proxies for saliency have been developed and used effectively (e.g., <xref ref-type="bibr" rid="bibr11-1525822X11419478">Goyder 1987</xref>; <xref ref-type="bibr" rid="bibr12-1525822X11419478">Groves et al. 2004</xref>). <xref ref-type="bibr" rid="bibr13-1525822X11419478">Groves et al. (2000)</xref> explain that behaviors such as volunteering in community groups, local political activism, and other forms of localized civic engagement are linked to survey participation because these activities indicate an individual’s sense of responsibility as well as their localized attention. In addition to the personal characteristics of a respondent, for example, volunteer or nonvolunteer, the actual topic of the survey or survey item matters. Therefore, community volunteers and people who assume local leadership roles will find questions about the community more salient, their predisposition to answer all types of questions notwithstanding. <xref ref-type="table" rid="table1-1525822X11419478">Table 1</xref>
 shows our measures of item saliency by the question topic along with the experimental design tests. We expect questions about community to be more highly salient for those high in community involvement, thus making community involvement our proxy for item saliency.</p>
<table-wrap id="table1-1525822X11419478" position="float">
<label>Table 1.</label>
<caption>
<p>Measures of Item-Saliency by Question Topic and Experimental Design Tests</p>
</caption>
<graphic alternate-form-of="table1-1525822X11419478" xlink:href="10.1177_1525822X11419478-table1.tif"/>
<table>
<thead>
<tr>
<th>Survey Item Number</th>
<th>Measures of Item Saliency</th>
<th>Question Stem</th>
<th>Experimental Design Tests</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q20</td>
<td>Community Participation and Local Leadership Roles</td>
<td>“On a scale from 1 to 5, how much do you think the organizations, clubs, or local groups that exist in the Lewiston/Clarkston area contribute to the quality of life of local residents?”</td>
<td>Polar Point with versus number box both with a “don’t know” response option</td>
</tr>
<tr>
<td>Q10</td>
<td>Community Participation and Local Leadership Roles</td>
<td>“Have you ever engaged in any of the following activities in order to influence a decision concerning your community?”</td>
<td>Check-all-that-apply versus forced-choice with a “none of the above”</td>
</tr>
<tr>
<td>Q6</td>
<td>Community Participation and Local Leadership Roles</td>
<td>“Is there any particular change that you think would make this area a better place for you to live?”</td>
<td>Size of answer box</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Our three measures of saliency are the number of local groups to which one is a member, the number of local events they attended over the last year, and the number of local leadership roles taken on over the past year. To measure the local groups to which one is a member and the number of local events they attended over the last year, we organized a long list of community groups by type into nine different categories (religious, fraternal, service, arts and cultural, business, union and professional, civic and community, family-orientated, hobby and sport, and “other groups”). The resulting variable is the cumulative number of groups and events they participated in over the last year. For the leadership variable, we asked how many local groups or organizations for which the respondent served as a leader over the past year.</p>
</sec>
<sec id="section12-1525822X11419478">
<title>Respondent Characteristics</title>
<p>Consistent with the previously mentioned research on respondent characteristics and response effects, we focus on educational level, age (including age-squared), and sex of the respondent. Education was measured in categories ranging from one (having less than a high school diploma) to eight (having earned a postbaccalaureate degree). Age was measured in years. Sex was measured as male or female. In the analyses that include respondent characteristics, demographic differences could influence our main effects for saliency, the interactions of saliency with design or both, but they cannot possibly explain design effects due to the random assignment of experimental questionnaires.</p>
</sec>
<sec id="section13-1525822X11419478">
<title>Analytic Strategy</title>
<p>The results are framed around our three guiding questions:<list list-type="order">
<list-item>
<p>Does item saliency affect the answering process?</p>
</list-item>
<list-item>
<p>If so, does saliency interact with item design?</p>
</list-item>
<list-item>
<p>Do a respondent’s personal characteristics explain away any of these effects?</p>
</list-item>
</list>Thus, for each experiment, we begin with an analysis of the differences by questionnaire version alone followed by analyses addressing whether questionnaire version or item saliency play independent roles in the answering process (while controlling for respondent characteristics), and finally, whether they interact. Given our diverse question structures and the substance of our research question, we use a number of different analytic approaches including chi-square tests, negative binomial regressions (when the Poisson models are overdispersed), logistic regressions, and proportional odds models.</p>
</sec>
</sec>
<sec id="section14-1525822X11419478">
<title>Results</title>
<sec id="section15-1525822X11419478">
<title>Polar Point versus Number Box with a “Don’t Know” Option</title>
<p>The treatments comparing a polar point scalar question to a number box format are shown in <xref ref-type="fig" rid="fig1-1525822X11419478">Figure 1</xref>
. The number box format has been suggested as a possible solution for mixed mode surveys because it supposedly more closely mimics a telephone survey than a list of scale points (<xref ref-type="bibr" rid="bibr8-1525822X11419478">Dillman et al. 2009</xref>). However, a number of recent studies have suggested that respondents have difficulty applying the information from the question stem to the answering space; they are more likely to become confused about which end of the scale is represented by large or small numbers (<xref ref-type="bibr" rid="bibr2-1525822X11419478">Christian 2003</xref>; <xref ref-type="bibr" rid="bibr3-1525822X11419478">Christian and Dillman 2004</xref>). Indeed, <xref ref-type="bibr" rid="bibr29-1525822X11419478">Stern (2008)</xref> has shown that respondents make more mistakes when using the number box format, as evidenced by changing their responses more in this format than in others.</p>
<fig id="fig1-1525822X11419478" position="float">
<label>Figure 1.</label>
<caption>
<p>Polar point versus number box with a “don’t know” option.</p>
</caption>
<graphic alternate-form-of="fig1-1525822X11419478" xlink:href="10.1177_1525822X11419478-fig1.tif"/>
</fig>
<p>In addition, there are several issues surrounding the use of nonopinion categories such as the “don’t know” option offered in our experiment. First, some people may provide a nonopinion when they actually have one, leading to what <xref ref-type="bibr" rid="bibr10-1525822X11419478">Gilljam and Granberg (1993)</xref> term “false negatives,” and the tendency to do this may be affected by the visual prominence of the category. <xref ref-type="bibr" rid="bibr20-1525822X11419478">Lam et al. (2002)</xref> found that the placement of the “don’t know” response option in a list had little effect on its use; however, <xref ref-type="bibr" rid="bibr30-1525822X11419478">Stern et al. (2007)</xref> found just the opposite. Second, although it has not yet been explored, item saliency should play a role because respondents who are more invested in a question’s topic should spend more time answering and may have more concrete opinions making them less likely to select nonopinion categories. Finally, women are more likely to provide a nonopinion than are men (see <xref ref-type="bibr" rid="bibr23-1525822X11419478">Rapoport 1982</xref> for a review).</p>
<p>Our preliminary examination (<xref ref-type="table" rid="table2-1525822X11419478">Table 2</xref>
) seems to confirm previous studies; question format has significant effects on the results both with and without the “don’t know” response option in the analysis. Respondents receiving the number box provide substantially different values and are significantly more likely to select “don’t know.”</p>
<table-wrap id="table2-1525822X11419478" position="float">
<label>Table 2.</label>
<caption>
<p>Response Distributions for Polar Point versus Number Box Formats with and without the “Don’t Know” Option Included<sup><xref ref-type="table-fn" rid="table-fn1-1525822X11419478">a</xref></sup>
</p>
</caption>
<graphic alternate-form-of="table2-1525822X11419478" xlink:href="10.1177_1525822X11419478-table2.tif"/>
<table>
<thead>
<tr>
<th rowspan="3">
</th>
<th colspan="3">Without the “Don’t Know” Option</th>
<th colspan="3">With the “Don’t Know” Option</th>
</tr>
<tr>
<th>Polar Point</th>
<th>Number Box</th>
<th>
</th>
<th>Polar Point</th>
<th>Number Box</th>
<th>
</th>
</tr>
<tr>
<th>%</th>
<th>%</th>
<th>Overall Chi-Square</th>
<th>%</th>
<th>%</th>
<th>Overall Chi-Square</th>
</tr>
</thead>
<tbody>
<tr>
<td>1) A lot</td>
<td>34.4</td>
<td>31.4</td>
<td rowspan="5">χ<sup>2</sup> = 36.44, <italic>p</italic> &lt; .000</td>
<td>30.5</td>
<td>23.9</td>
<td rowspan="5">χ<sup>2</sup> = 71.18, <italic>p</italic> &lt; .000</td>
</tr>
<tr>
<td>2)</td>
<td>27.3</td>
<td>21.3</td>
<td>24.2</td>
<td>16.2</td>
</tr>
<tr>
<td>3)</td>
<td>28.5</td>
<td>24.4</td>
<td>25.3</td>
<td>18.6</td>
</tr>
<tr>
<td>4)</td>
<td>7.0</td>
<td>14.1</td>
<td>6.2</td>
<td>10.8</td>
</tr>
<tr>
<td>5) Not at all</td>
<td>2.8</td>
<td>8.8</td>
<td>2.5</td>
<td>6.7</td>
</tr>
<tr>
<td>Don’t know</td>
<td align="center">—</td>
<td align="center">—</td>
<td>
</td>
<td>11.3</td>
<td>23.9</td>
<td>
</td>
</tr>
<tr>
<td>Total</td>
<td align="center">100</td>
<td align="center">100</td>
<td>
</td>
<td align="center">100</td>
<td align="center">100</td>
<td>
</td>
</tr>
<tr>
<td>
<italic>N</italic>
</td>
<td align="center">572</td>
<td align="center">488</td>
<td>
</td>
<td align="center">645</td>
<td align="center">641</td>
<td>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1525822X11419478">
<p>Note: <sup>a</sup>Responses are from question 20, shown in <xref ref-type="fig" rid="fig1-1525822X11419478">Figure 1</xref>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<sec id="section16-1525822X11419478">
<title>Does Item Saliency Play a Role in the Answering Process?</title>
<p>In <xref ref-type="table" rid="table3-1525822X11419478">Table 3</xref>
, we add the measures of saliency. In this case, we use two sets of dichotomous variables: (1) participating in more than the mean number of groups and events; and (2) taking on more than the mean number of local leadership roles.<xref ref-type="fn" rid="fn1-1525822X11419478">1</xref></p>
<table-wrap id="table3-1525822X11419478" position="float">
<label>Table 3.</label>
<caption>
<p>Response Distributions for Polar Point versus Number Box Formats With and Without the “Don’t Know” Response Option by Local Community Participation and Leadership<sup><xref ref-type="table-fn" rid="table-fn28-1525822X11419478">a</xref></sup>
</p>
</caption>
<graphic alternate-form-of="table3-1525822X11419478" xlink:href="10.1177_1525822X11419478-table3.tif"/>
<table>
<thead>
<tr>
<th rowspan="3">
</th>
<th colspan="2">Low Community Participation</th>
<th colspan="2">High Community Participation</th>
<th colspan="2">Low in Leadership Roles</th>
<th colspan="2">High in Leadership Roles</th>
</tr>
<tr>
<th># Box</th>
<th>Polar Point</th>
<th># Box</th>
<th>Polar Point</th>
<th># Box</th>
<th>Polar Point</th>
<th># Box</th>
<th>Polar Point</th>
</tr>
<tr>
<th>%</th>
<th>%</th>
<th>%</th>
<th>%</th>
<th>%</th>
<th>%</th>
<th>%</th>
<th>%</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="9">Response distributions without the “don’t know” response option</td>
</tr>
<tr>
<td>1) A lot</td>
<td>26.6</td>
<td>26.6</td>
<td>37.6</td>
<td>41.4</td>
<td>23.5</td>
<td>29.1</td>
<td>43.2</td>
<td>42.0</td>
</tr>
<tr>
<td>2)</td>
<td>16.5</td>
<td>25.4</td>
<td>22.9</td>
<td>28.5</td>
<td>21.7</td>
<td>23.1</td>
<td>17.9</td>
<td>33.5</td>
</tr>
<tr>
<td>3)</td>
<td>30.4</td>
<td>33.7</td>
<td>21.1</td>
<td>23.0</td>
<td>29.6</td>
<td>35.0</td>
<td>18.9</td>
<td>18.8</td>
</tr>
<tr>
<td>4)</td>
<td>21.5</td>
<td>9.5</td>
<td>13.8</td>
<td>6.3</td>
<td>18.3</td>
<td>8.8</td>
<td>15.8</td>
<td>4.5</td>
</tr>
<tr>
<td>5) Not at all</td>
<td>5.1</td>
<td>4.8</td>
<td>4.6</td>
<td>0.8</td>
<td>7.0</td>
<td>4.1</td>
<td>4.2</td>
<td>1.3</td>
</tr>
<tr>
<td>Total</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">100</td>
</tr>
<tr>
<td>
<italic>N</italic>
</td>
<td align="center">79</td>
<td align="center">152</td>
<td align="center">109</td>
<td align="center">256</td>
<td align="center">115</td>
<td align="center">320</td>
<td align="center">95</td>
<td align="center">224</td>
</tr>
<tr>
<td>Overall Chi-square</td>
<td align="center" colspan="2">χ<sup>2</sup> = 9.27, <italic>p</italic> = .055</td>
<td align="center" colspan="2">χ<sup>2</sup> = 12.14, <italic>p</italic> = .016</td>
<td align="center" colspan="2">χ<sup>2</sup> = 10.03, <italic>p</italic> = .040</td>
<td align="center" colspan="2">χ<sup>2</sup> = 19.07, <italic>p</italic> = .001</td>
</tr>
<tr>
<td colspan="9">Selection of the “don’t know” response option</td>
</tr>
<tr>
<td>Don’t know</td>
<td>38.3</td>
<td>16.0</td>
<td>15.5</td>
<td>5.9</td>
<td>36.1</td>
<td>15.0</td>
<td>5.9</td>
<td>3.0</td>
</tr>
<tr>
<td>
<italic>N</italic>
</td>
<td align="center">128</td>
<td align="center">300</td>
<td align="center">129</td>
<td align="center">272</td>
<td align="center">180</td>
<td align="center">380</td>
<td align="center">101</td>
<td align="center">231</td>
</tr>
<tr>
<td>Chi-square</td>
<td align="center" colspan="2">χ<sup>2</sup> = 24.41, <italic>p</italic> = .000</td>
<td align="center" colspan="2">χ<sup>2</sup> = 9.91, <italic>p</italic> = .002</td>
<td align="center" colspan="2">χ<sup>2</sup> = 29.09, <italic>p</italic> = .000</td>
<td align="center" colspan="2">χ<sup>2</sup> = 1.58, <italic>p</italic> = .208</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1525822X11419478">
<p>Note:</p></fn>
<fn id="table-fn28-1525822X11419478">
<p><sup>a</sup>Responses are from question 20, shown in <xref ref-type="fig" rid="fig1-1525822X11419478">Figure 1</xref>. Low participation and leadership refers to those who reported participating in or taking leadership roles in less than the mean number of events and groups, while high participation and leadership refers to those who reported participating in or taking leadership roles in more than the mean number of events and groups.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>When our measure of saliency is community participation (top half of the first panel), it has an effect, but not in a way that we would anticipate. For example, <italic>if</italic> people who are more interested in the topic (i.e., those who participate in their local communities at higher levels) spend more time on the question, optimize, and are thus less affected by the visual design, we should not see effects by questionnaire version for them. However, we find more design effects among this group, including large differences in the use of the “not at all” category across versions (number box = 4.6%; polar point = 0.8%) compared to less pronounced differences among those who participate at lower levels (number box = 5.1%; polar point = 4.8%).</p>
<p>We see a very similar, yet less vivid, result with leadership roles (top half of the second panel). Interestingly, the opposite is true when examining the use of the “don’t know” response (shown in the bottom of <xref ref-type="table" rid="table3-1525822X11419478">Table 3</xref>). People who received the number box are more likely to use the “don’t know” response, and the differences by version are more pronounced for people with low community participation and leadership than for those with high participation and leadership.</p>
</sec>
<sec id="section18-1525822X11419478">
<title>Does Saliency Interact with Question-Item Design and Do a Respondent’s Personal Characteristics Explain away Any of These Effects?</title>
<p>To answer these questions, we turn to the multivariate models. In the left half of <xref ref-type="table" rid="table4-1525822X11419478">Table 4</xref>
, we examine the distribution of the substantive responses without the “don’t know” response, using a proportional odds approach.<xref ref-type="fn" rid="fn2-1525822X11419478">2</xref> The right half of the table shows the results of a logistic regression model predicting selection of the “don’t know” response. The first three columns indicate that being high in community participation (saliency), community leadership (saliency), and receiving the polar point version of the questionnaire (visual design) are all significantly related to the values respondents provided. Those for whom we would expect the questions to be more salient were more likely to give more positive answers than those for whom we would expect the questions to be less salient. What is more, those who received the polar point version of the question provided significantly different responses than those who had received the number box version. In the fourth column, we enter all three of the previous measures into the model along with the respondent characteristics.</p>
<table-wrap id="table4-1525822X11419478" position="float">
<label>Table 4.</label>
<caption>
<p>Proportional Odds and Logistic Regression Models for the Effects of Local Community Participation, Leadership, Question Format, and Demographics Characteristics on Responses</p>
</caption>
<graphic alternate-form-of="table4-1525822X11419478" xlink:href="10.1177_1525822X11419478-table4.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th colspan="5">Response Distributions without the “Don’t Know” Response Option<sup><xref ref-type="table-fn" rid="table-fn29-1525822X11419478">a</xref></sup>
</th>
<th colspan="5">Selection of the “Don’t Know” Response Option<sup><xref ref-type="table-fn" rid="table-fn4-1525822X11419478">b</xref></sup>
</th>
</tr>
<tr>
<th>
</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn5-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn5-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn5-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn5-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Community participation</td>
<td>0.86<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.03)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.85<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.04)</td>
<td>0.86<sup><xref ref-type="table-fn" rid="table-fn8-1525822X11419478">**</xref></sup> 	(0.06)</td>
<td>0.75<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.03)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.83<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.05)</td>
<td>0.85<sup><xref ref-type="table-fn" rid="table-fn9-1525822X11419478">*</xref></sup> 	(0.07)</td>
</tr>
<tr>
<td>Local leadership roles</td>
<td align="center">—</td>
<td>0.87<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.04)</td>
<td align="center">—</td>
<td>0.94 	(0.05)</td>
<td>0.99 	(0.09)</td>
<td align="center">—</td>
<td>0.29<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.07)</td>
<td align="center">—</td>
<td>0.41<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.11)</td>
<td>0.27<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.11)</td>
</tr>
<tr>
<td>Questionnaire version (1 = <italic>Polar point</italic>)<sup><xref ref-type="table-fn" rid="table-fn6-1525822X11419478">d</xref></sup>
</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.67<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.11)</td>
<td>0.75<xref ref-type="table-fn" rid="table-fn10-1525822X11419478">†</xref> 	(0.17)</td>
<td>0.87 	(0.37)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.41<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.18)</td>
<td>0.33<sup><xref ref-type="table-fn" rid="table-fn7-1525822X11419478">***</xref></sup> 	(0.17)</td>
<td>0.37<sup><xref ref-type="table-fn" rid="table-fn9-1525822X11419478">*</xref></sup> 	(0.17)</td>
</tr>
<tr>
<td>Community Participation × Questionnaire Version</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.99 	(0.07)</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.94 	(0.11)</td>
</tr>
<tr>
<td>Local Leadership Roles × Questionnaire Version</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.93 	(0.09)</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>1.92<sup><xref ref-type="table-fn" rid="table-fn9-1525822X11419478">*</xref></sup> 	(0.55)</td>
</tr>
<tr>
<td>Log likelihood</td>
<td>−970.09</td>
<td>−1061.92</td>
<td>−1538.55</td>
<td>−771.43</td>
<td>−770.99</td>
<td>−580.03</td>
<td>−344.51</td>
<td>−580.03</td>
<td>−206.04</td>
<td>−204.79</td>
</tr>
<tr>
<td>Pseudo <italic>R</italic>
<sup>2</sup>
</td>
<td>.02</td>
<td>.01</td>
<td>.01</td>
<td>.03</td>
<td>.03</td>
<td>.10</td>
<td>.10</td>
<td>.03</td>
<td>.18</td>
<td>0.19</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1525822X11419478">
<p>Note:</p></fn>
<fn id="table-fn29-1525822X11419478">
<p><sup>a</sup>Responses are from question 20, shown in <xref ref-type="fig" rid="fig1-1525822X11419478">Figure 1</xref>. Large values equate to more negative responses. As a result of the scaling, we use a proportional odds approach to model the outcomes.</p>
</fn>
<fn id="table-fn4-1525822X11419478">
<p>
<sup>b</sup>Question included a “don’t know” option. For this analysis, we use logistic regression because the outcome is dichotomous based on whether the respondent chose the “don’t know” response option.</p>
</fn>
<fn id="table-fn5-1525822X11419478">
<p>
<sup>c</sup>Models include age, age-squared, education, and sex. Full tables are available on request.</p>
</fn>
<fn id="table-fn6-1525822X11419478">
<p>
<sup>d</sup>Questionnaire version is a dichotomous variable where 1 indicates the polar point version and 0 represents the number box. Expected order refers to response options that start with the most positive option (e.g., very beneficial) and end with the first option’s opposite (e.g., very bad).</p>
</fn>
<fn id="table-fn7-1525822X11419478">
<p><sup>***</sup> <italic>p</italic> ≤ .001.</p>
</fn>
<fn id="table-fn8-1525822X11419478">
<p><sup>**</sup> <italic>p</italic> ≤ .01.</p>
</fn>
<fn id="table-fn9-1525822X11419478">
<p><sup>*</sup> <italic>p</italic> ≤ .05.</p>
</fn>
<fn id="table-fn10-1525822X11419478">
<p>†<italic>p</italic> ≤ .10.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The only saliency measure that stays significant at conventionally accepted probability levels is community participation (Exp(<italic>b</italic>) = 0.85; <italic>p</italic> &lt; .001); the questionnaire version approaches significance (Exp(<italic>b</italic>) = 0.75; <italic>p</italic> &lt; .10). For the “don’t know” response, we see that both measures of saliency and questionnaire version have significant independent effects on respondents’ answers. In the full model, we find that these relationships are affected to some degree by the inclusion of the interaction term; therefore, we use predicted probabilities to graphically show the interaction between community participation and questionnaire design while controlling for respondent characteristics (<xref ref-type="fig" rid="fig2-1525822X11419478">Figure 2</xref>
).</p>
<fig id="fig2-1525822X11419478" position="float">
<label>Figure 2.</label>
<caption>
<p>Predicted probabilities for the interactions between community participation and question format on responses net of demographics characteristics.</p>
</caption>
<graphic alternate-form-of="fig2-1525822X11419478" xlink:href="10.1177_1525822X11419478-fig2.tif"/>
</fig>
<p>As the findings for community participation are significant in both tests and it is a more widely used measure in previous research, we enter that variable into the interaction instead of leadership roles, here and throughout the results. <xref ref-type="fig" rid="fig2-1525822X11419478">Figure 2</xref> shows that people for whom the question is salient and received the polar point version of the question are the most likely to strongly agree and the least likely to strongly disagree with the statement. Similarly, people for whom the question is salient but received the number box version of the question are very likely to strongly agree with the statement, but the probabilities tend to stay a bit lower for these respondents than for people who received the polar point version of the questionnaire. There is a lot more variability among individuals who are low in saliency. Although these respondents start and end in roughly the same place regardless of questionnaire version, there is a spike in the middle of the scale for people with the polar point version and a dip for people who received the number box. This variation could indicate neutrality or confusion.</p>
</sec>
</sec>
</sec>
<sec id="section19-1525822X11419478">
<title>Forced Choice versus Check-All-That-Apply Formats</title>
<p>Our second experiment compares two versions of a multiple answer or “mark-all-that-apply” question (<xref ref-type="fig" rid="fig3-1525822X11419478">Figure 3</xref>
). Recent research has shown that respondents tend to provide more affirmative responses to formats in which they are asked to provide an affirmative or negative response (e.g., yes or no) for each item compared to simply being asked to check-all-that-apply (see <xref ref-type="bibr" rid="bibr27-1525822X11419478">Smyth et al. 2006</xref>, 2008; Thomas and Klein 2008). We find the same in our experiment (forced-choice = 3.20 and check-all-that-apply = 3.01; <italic>t</italic> = 2.48, <italic>p</italic> = .013). What is particularly interesting are the differences in the “none of the above” category; it was chosen significantly more often by respondents who received the check-all-that-apply version of the question (forced-choice = 1.8% and check-all-that-apply = 6.3; χ<sup>2</sup> = 16.35, <italic>p</italic> &lt; .000).</p>
<fig id="fig3-1525822X11419478" position="float">
<label>Figure 3.</label>
<caption>
<p>Forced Choice versus Check-All-That-Apply Formats</p>
</caption>
<graphic alternate-form-of="fig3-1525822X11419478" xlink:href="10.1177_1525822X11419478-fig3.tif"/>
</fig>
<sec id="section20-1525822X11419478">
<title>Does Item Saliency Play a Role in the Answering Process? Does Saliency Interact with Question-Item Design and Do a Respondent’s Personal Characteristics Explain away Any of These Effects?</title>
<p>In the first set of models (left-hand side of <xref ref-type="table" rid="table5-1525822X11419478">Table 5</xref>
), we see saliency is positively related to the number of items endorsed, while receiving the check-all-that-apply version of the question is negatively associated with the number of items selected. In the full models, we see that the relationship holds for our measures of saliency, but not for question format, although it approaches significance (<italic>p</italic> &lt; .10). We see a different story in the right side of the table, which examines use of the “none of the above” option. The check-all-that-apply version of the question is positively and significantly related to choosing this response option. At the same time, in the full model, only general community participation maintains its negative relationship to choosing this option. <xref ref-type="fig" rid="fig4-1525822X11419478">Figure 4</xref>
 shows that people who received the check-all-that-apply version and are low in community participation are almost 80% more likely to choose the “none of the above” option than any other group. These results suggest that saliency is most important for the substantive items, but that format is a bit more important for the nonsubstantive items.</p>
<table-wrap id="table5-1525822X11419478" position="float">
<label>Table 5.</label>
<caption>
<p>Negative Binomial and Logistic Regression Models for the Effects of Local Community Participation, Leadership, Question Format, and Demographics Characteristics on Responses</p>
</caption>
<graphic alternate-form-of="table5-1525822X11419478" xlink:href="10.1177_1525822X11419478-table5.tif"/>
<table>
<thead>
<tr>
<th rowspan="2">
</th>
<th colspan="5">Number of Affirmative Responses<sup><xref ref-type="table-fn" rid="table-fn30-1525822X11419478">a</xref></sup>
</th>
<th colspan="5">Selection of the “None of the Above” Response Option<sup><xref ref-type="table-fn" rid="table-fn12-1525822X11419478">b</xref></sup>
</th>
</tr>
<tr>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn13-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn13-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn13-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn13-1525822X11419478">c</xref></sup> (<italic>SE</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Community participation</td>
<td>1.07<sup><xref ref-type="table-fn" rid="table-fn15-1525822X11419478">***</xref></sup> 	(0.01)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>1.05<sup><xref ref-type="table-fn" rid="table-fn15-1525822X11419478">***</xref></sup> 	(0.01)</td>
<td>1.06<sup><xref ref-type="table-fn" rid="table-fn15-1525822X11419478">***</xref></sup> 	(0.02)</td>
<td>0.72<sup><xref ref-type="table-fn" rid="table-fn15-1525822X11419478">***</xref></sup> 	(0.05)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.82<sup><xref ref-type="table-fn" rid="table-fn17-1525822X11419478">*</xref></sup> 	(0.08)</td>
<td>1.51 	(0.55)</td>
</tr>
<tr>
<td>Local leadership roles</td>
<td align="center">—</td>
<td>1.07<sup><xref ref-type="table-fn" rid="table-fn15-1525822X11419478">***</xref></sup> 	(0.01)</td>
<td align="center">—</td>
<td>1.03<sup><xref ref-type="table-fn" rid="table-fn16-1525822X11419478">**</xref></sup> 	(0.01)</td>
<td>1.02 	(0.02)</td>
<td align="center">—</td>
<td>0.67<sup><xref ref-type="table-fn" rid="table-fn17-1525822X11419478">*</xref></sup> 	(0.12)</td>
<td align="center">—</td>
<td>0.65 	(0.20)</td>
<td>0.44 	(0.35)</td>
</tr>
<tr>
<td>Questionnaire version<sup><xref ref-type="table-fn" rid="table-fn14-1525822X11419478">d</xref></sup> (1 = <italic>Check-all</italic>)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.94<sup><xref ref-type="table-fn" rid="table-fn17-1525822X11419478">*</xref></sup> 	(0.03)</td>
<td>0.92<xref ref-type="table-fn" rid="table-fn18-1525822X11419478">†</xref> 	(0.05)</td>
<td>0.96 	(0.10)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>3.56<sup><xref ref-type="table-fn" rid="table-fn15-1525822X11419478">***</xref></sup> 	(1.18)</td>
<td>22.46<sup><xref ref-type="table-fn" rid="table-fn16-1525822X11419478">**</xref></sup> 	(23.59)</td>
<td>300.58<sup><xref ref-type="table-fn" rid="table-fn17-1525822X11419478">*</xref></sup> 	(36.40)</td>
</tr>
<tr>
<td>Community Participation × Questionnaire Version</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.99 	(0.02)</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.51 	(0.20)</td>
</tr>
<tr>
<td>Local Leadership Roles × Questionnaire Version</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>1.02 	(0.16)</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>1.49<sup><xref ref-type="table-fn" rid="table-fn17-1525822X11419478">*</xref></sup> 	(0.96)</td>
</tr>
<tr>
<td>Log-Likelihood</td>
<td>−1456.76</td>
<td>−1582.44</td>
<td>−2348.40</td>
<td>−1113.52</td>
<td>−1113.00</td>
<td>−174.15</td>
<td>−213.20</td>
<td>−99.73</td>
<td>−90.44</td>
<td>−89.11</td>
</tr>
<tr>
<td>Pseudo <italic>R</italic>
<sup>2</sup>
</td>
<td>.03</td>
<td>.02</td>
<td>.00</td>
<td>.05</td>
<td>.05</td>
<td>.03</td>
<td>.04</td>
<td>.18</td>
<td>.24</td>
<td>.25</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn11-1525822X11419478">
<p>Note:</p></fn>
<fn id="table-fn30-1525822X11419478">
<p>
<sup>a</sup>Negative binomial models are used due to the positive skewness of the dependent variable and the significant levels of overdispersion.</p>
</fn>
<fn id="table-fn12-1525822X11419478">
<p>
<sup>b</sup>Logistic regression models are used here due to the binary outcome variable (1 = <italic>selection of the none of the above</italic>).</p>
</fn>
<fn id="table-fn13-1525822X11419478">
<p>
<sup>c</sup>Models include age, age-squared, education, and sex. Full tables are available on request.</p>
</fn>
<fn id="table-fn14-1525822X11419478">
<p>
<sup>d</sup> Questionnaire version is a dichotomous variable where 1 indicates the respondent received the check all that apply version of the questionnaire and 0 means that respondent received forced choice version.</p>
</fn>
<fn id="table-fn15-1525822X11419478">
<p><sup>***</sup> <italic>p</italic> ≤ .001.</p>
</fn>
<fn id="table-fn16-1525822X11419478">
<p><sup>**</sup> <italic>p</italic> ≤ .01.</p>
</fn>
<fn id="table-fn17-1525822X11419478">
<p><sup>*</sup> <italic>p</italic> ≤ .05.</p>
</fn>
<fn id="table-fn18-1525822X11419478">
<p>†<italic>p</italic> ≤ .10.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig4-1525822X11419478" position="float">
<label>Figure 4.</label>
<caption>
<p>Predicted probabilities for the interactions between community participation and question format on the use of none of the above net of demographics characteristics.</p>
</caption>
<graphic alternate-form-of="fig4-1525822X11419478" xlink:href="10.1177_1525822X11419478-fig4.tif"/>
</fig>
</sec>
</sec>
<sec id="section22-1525822X11419478">
<title>Answer Box Sizes for Open-Ended Responses</title>
<p>In theory, the size of an answer space serves as a graphical indication of how much information a respondent is expected to provide (<xref ref-type="bibr" rid="bibr3-1525822X11419478">Christian and Dillman 2004</xref>; Holland and Christian 2008). Here we compared results from two versions of an open-ended question. In one version, the box is 1.0′′ high × 6.5′′ wide and in the other it is 2.0′′ high × 6.5′′ wide. The question is: “Is there any particular change that you think would make this area a better place for you to live?” We initially found an overall difference in the number of words provided, such that respondents supplied more words in the larger answer space (mean = 17.17), as compared to the smaller one (mean = 14.95) but not at statistically significant levels (<italic>t</italic> = 1.82; <italic>p</italic> = .07) after we applied a Bonferroni correction.</p>
<sec id="section23-1525822X11419478">
<title>Does Item Saliency Play a Role in the Answering Process? Does Saliency Interact with Question-Item Design and Do a Respondent’s Personal Characteristics Explain away Any of These Effects?</title>
<p>When we turn to our measures of saliency (<xref ref-type="table" rid="table6-1525822X11419478">Table 6</xref>
), we find that the differences in the mean number of words provided by those low in community participation are in the same direction as in the overall findings (i.e., more words in the larger box) but unlike the overall findings, the difference for this group reaches significance (<italic>p</italic> = .04). In the multivariate analysis (<xref ref-type="table" rid="table7-1525822X11419478">Table 7</xref>
), we find that people for whom the question was more salient provided more words as did those who received the larger answer space (Exp(<italic>b</italic>) = 1.04; <italic>p</italic> &lt; .05 and Exp(<italic>b</italic>) = 0.87; <italic>p</italic> &lt; .05, respectively). However, in the full model, the only marginally significant effect is the positive relationship between general community participation (saliency) and the number of words provided. The effects for size of the box are not significant. Based on these results, we can conclude that the size of the box was less important than the saliency of the item.</p>
<table-wrap id="table6-1525822X11419478" position="float">
<label>Table 6.</label>
<caption>
<p>Mean Differences in the Number of Words Provided for the Entire Sample and by Measure of Local Community Participation and Leadership Based on the Size of the Answer Box</p>
</caption>
<graphic alternate-form-of="table6-1525822X11419478" xlink:href="10.1177_1525822X11419478-table6.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>Format</th>
<th>
<italic>n</italic>
</th>
<th>Mean</th>
<th>Diff.</th>
<th>
<italic>t</italic>-Test</th>
<th>
<italic>p</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="2">Overall</td>
<td>Big Box</td>
<td>456</td>
<td>17.17</td>
<td rowspan="2">2.22</td>
<td rowspan="2">1.82</td>
<td rowspan="2">0.07</td>
</tr>
<tr>
<td>Small Box</td>
<td>466</td>
<td>14.95</td>
</tr>
<tr>
<td rowspan="2">Low community participation</td>
<td>Big Box</td>
<td>87</td>
<td>18.03</td>
<td rowspan="2">4.66</td>
<td rowspan="2">2.08</td>
<td rowspan="2">0.04</td>
</tr>
<tr>
<td>Small Box</td>
<td>197</td>
<td>13.37</td>
</tr>
<tr>
<td rowspan="2">High community participation</td>
<td>Big Box</td>
<td>92</td>
<td>18.34</td>
<td rowspan="2">2.11</td>
<td rowspan="2">0.87</td>
<td rowspan="2">0.38</td>
</tr>
<tr>
<td>Small Box</td>
<td>212</td>
<td>16.23</td>
</tr>
<tr>
<td rowspan="2">Low in leadership roles</td>
<td>Big Box</td>
<td>117</td>
<td>18.15</td>
<td rowspan="2">3.28</td>
<td rowspan="2">1.57</td>
<td rowspan="2">0.12</td>
</tr>
<tr>
<td>Small Box</td>
<td>262</td>
<td>14.87</td>
</tr>
<tr>
<td rowspan="2">High in leadership roles</td>
<td>Big Box</td>
<td>80</td>
<td>18.04</td>
<td rowspan="2">1.47</td>
<td rowspan="2">1.47</td>
<td rowspan="2">0.14</td>
</tr>
<tr>
<td>Small Box</td>
<td>175</td>
<td>14.58</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn19-1525822X11419478">
<p>Note: Low participation and leadership refers to those who reported participating in or taking leadership roles in less than the mean number of events and groups while high participation and leadership refers to those who reported participating in or taking leadership roles in more than the mean number of events and groups.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table7-1525822X11419478" position="float">
<label>Table 7.</label>
<caption>
<p>Negative Binominal Regression Models for the Effects of Local Community Participation, Leadership, Question Format, and Demographics Characteristics on Open-Ended Responses<sup><xref ref-type="table-fn" rid="table-fn21-1525822X11419478">a</xref></sup>
</p>
</caption>
<graphic alternate-form-of="table7-1525822X11419478" xlink:href="10.1177_1525822X11419478-table7.tif"/>
<table>
<thead>
<tr>
<th rowspan="2">
</th>
<th colspan="5">Number of Words</th>
</tr>
<tr>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>) (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn22-1525822X11419478">b</xref></sup> (<italic>SE</italic>)</th>
<th>Exp(<italic>b</italic>)<sup><xref ref-type="table-fn" rid="table-fn22-1525822X11419478">b</xref></sup> (<italic>SE</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Community participation</td>
<td>1.04<sup><xref ref-type="table-fn" rid="table-fn26-1525822X11419478">*</xref></sup> (0.02)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>1.05<sup><xref ref-type="table-fn" rid="table-fn26-1525822X11419478">*</xref></sup> (0.02)</td>
<td>1.05<sup>†</sup>(0.03)</td>
</tr>
<tr>
<td>Local leadership roles</td>
<td align="center">—</td>
<td>1.01 (0.02)</td>
<td align="center">—</td>
<td>0.97 (0.02)</td>
<td>0.99 (0.04)</td>
</tr>
<tr>
<td>Questionnaire version<sup><xref ref-type="table-fn" rid="table-fn23-1525822X11419478">c</xref></sup> (1 = <italic>Small Box</italic>)</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.87<sup><xref ref-type="table-fn" rid="table-fn26-1525822X11419478">*</xref></sup> (0.11)</td>
<td>0.85 (0.09)</td>
<td>0.88 (0.19)</td>
</tr>
<tr>
<td>Community participation × Questionnaire Version</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>1.00 (0.04)</td>
</tr>
<tr>
<td>Local Leadership Roles × Questionnaire Version</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.98 (0.05)</td>
</tr>
<tr>
<td>Log likelihood</td>
<td>−2223.94</td>
<td>−2395.51</td>
<td>−3492.42</td>
<td>−1783.99</td>
<td>−1783.81</td>
</tr>
<tr>
<td>Pseudo <italic>R</italic>
<sup>2</sup>
</td>
<td>.01</td>
<td>.00</td>
<td>.00</td>
<td>.01</td>
<td>.01</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn20-1525822X11419478">
<p>Note:</p>
</fn>
<fn id="table-fn21-1525822X11419478">
<p>
<sup>a</sup>Negative binomial models are used due to the positive skewness of the dependent variable and the significant levels of overdispersion.</p>
</fn>
<fn id="table-fn22-1525822X11419478">
<p>
<sup>b</sup>Models include age, age-squared, education, and sex. Full tables are available on request.</p>
</fn>
<fn id="table-fn23-1525822X11419478">
<p>
<sup>c</sup>Questionnaire version is a dichotomous variable where 1 indicates the respondent received the questionnaire version with the 2′′ × 6.5′′ answer box, whereas a 0 indicates the respondent received the 1′′ × 6.5′′ answer box.</p>
</fn>
<fn id="table-fn24-1525822X11419478">
<p><sup>***</sup> <italic>p</italic> ≤ .001.</p>
</fn>
<fn id="table-fn25-1525822X11419478">
<p><sup>**</sup> <italic>p</italic> ≤ .01.</p>
</fn>
<fn id="table-fn26-1525822X11419478">
<p><sup>*</sup> <italic>p</italic> ≤ .05.</p>
</fn>
<fn id="table-fn27-1525822X11419478">
<p>†<italic>p</italic> ≤ .10.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section25-1525822X11419478">
<title>Conclusions</title>
<p>Does item saliency play a role in the answering process? If so, does saliency interact with question-item design? Do a respondent’s personal characteristics explain away any of these effects? These are the three questions that have guided this research. This article shows clearly that item saliency plays an independent role in how respondents answer questions. What is more, item saliency does interact in some cases with question design. Finally, respondent characteristics seemed to have little effect on this relationship. There were several other interesting findings upon which we elaborate below.</p>
<p>First, there were some mixed effects throughout. For example, in the size of answer box experiment, question saliency had greater impact on the way respondents answered than the visual design, while the reverse was true with respect to the use of the “none of the above” option in the check-all-that-apply question. With the other experiment (number box versus polar-point with a “don’t know” response), there was clearly an interaction whereby respondents for whom the question was less salient were more affected by the visual design. Thus, item saliency was important; however, this was especially true on certain visual design modifications. What was clear is that when respondents were given the option of providing a “don’t know” response, those for whom the question topic was not salient were influenced much more by the presence and placement of this option. The findings, therefore, provide support for the <italic>elaboration likelihood model</italic> in that those with lower saliency seemed to rely more on peripheral cues (i.e., design features) than those with higher saliency.</p>
<p>A second interesting finding to emerge from our data is that although question saliency matters, not all types of interest are equal. Previous research suggested that community involvement and volunteering were good indicators of how likely a person was to respond to a survey request because both are volunteer actions. However, we found that nominal levels of community involvement seemed to matter more than leadership roles, a result that contradicts notions of these two indicators working similarly and is counter to arguments that those people who spend the most time in groups (i.e., leaders and organizers), should be least affected by the question design. However, we cannot speak here as to whether leaders and organizers actually responded at equal or higher levels to the survey request.</p>
<p>Third, the respondent characteristics were rarely influential in our models. While there is reason to believe they might play a role, they do not in this study. There was no case where the effects of item saliency and visual design were reduced to a nonsignificant level as a result of personal characteristics. However, more research needs to be done that specifically focuses on the role of personal characteristics before any comprehensive statements can be made on this topic. <italic>Leverage saliency theory</italic> suggests that we can increase the odds of a person responding to a survey through incentives, even when they are not interested in the survey’s topic. However, we previously knew little about whether those for whom the topic was not salient answered differently from others. Using these experimental manipulations, we show that indeed they do answer differently and can be more dramatically affected by the design of the question. Thus, their increased, incentivized participation may come at the cost of increased measurement error.</p>
<p>The implications of these results are important for how we think about designing questions. For example, where we find the greatest influence on people with low levels of saliency is in the use of nonqualifiers. Therefore, survey researchers should probably be careful in their use of “don’t know” response options in cases where their topic may not appeal widely to respondents. In addition, it is clear that “nontraditional” designs, such as the use of a number box for a scalar question, can result in higher levels of measurement error when the topic is not of great interest to the respondent. Although we need more research in this area with a greater number of replications, our results suggest that item saliency contributes to the answering process, interacts with the visual design, and, as a result, can impact our degree of measurement error.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict" id="fn3-1525822X11419478">
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn4-1525822X11419478">
<p>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: Support for conducting this research was provided by the Department of Community and Rural Sociology and the Social and Economic Sciences Research Center at Washington State University, Pullman. Additional support was provided by the USDA–National Agricultural Statistics Service and the National Science Foundation Division of Science Resource Statistics under Cooperative Agreement #43-3AEU-1-80055 with the Washington State University Social and Economic Sciences Research Center, Don A. Dillman, Principal Investigator.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<title>Notes</title>
<fn fn-type="other" id="fn1-1525822X11419478">
<label>1.</label>
<p>Group members/event goers are distinguished from leaders/organizers because one can participate in their local communities nominally or actively. Nominal participation includes membership or attendance such as joining the local PTA or attending a PTA meeting. Active participation refers to taking a role in or making an investment in the success of the group through leadership and/or organizing actions such as chairing the local PTA or organizing a fundraising event.</p>
</fn>
<fn fn-type="other" id="fn2-1525822X11419478">
<label>2.</label>
<p>The coefficients are exponentiated and presented in odds ratios; therefore, all values over 1 are positive and those less than 1 are negative. For example, the value 1.04 for community participation means that for every one-unit increase in community participation, there is a concomitant 4% increase in the odds that a person will answer in a given manner.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1525822X11419478">
<citation citation-type="book">
<collab collab-type="author">American Association for Public Opinion Research (AAPOR)</collab>. <year>2008</year>. <source>Standard definitions: Final dispositions of case codes and outcome rates for surveys</source>. <edition>5th ed</edition>. <publisher-loc>Lenexa, KS</publisher-loc>: <publisher-name>AAPOR</publisher-name>.</citation>
</ref>
<ref id="bibr2-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>2003</year>. <article-title>The influence of visual layout on scalar questions in web surveys</article-title>. <comment>Master’s thesis</comment>, <publisher-name>Washington State University</publisher-name>.
</citation>
</ref>
<ref id="bibr3-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>The influence of graphical and symbolic language manipulations on responses to self-administered questions</article-title>. <source>Public Opinion Quarterly</source>, <volume>68</volume>, <fpage>58</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr4-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Smyth</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>Helping respondents get it right the first time: The relative influence of words, symbols, and graphics in web and telephone surveys</article-title>. <source>Public Opinion Quarterly</source>, <volume>71</volume>, <fpage>113</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr5-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Converse</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>1964</year>. <article-title>The nature of belief systems in mass publics</article-title>. In <source>Ideology and discontent</source>, ed. <person-group person-group-type="editor"><name><surname>Apter</surname><given-names>D.</given-names></name></person-group> <fpage>206</fpage>–<lpage>61</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>The Free Press</publisher-name>.</citation>
</ref>
<ref id="bibr6-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>2005</year>. <article-title>Survey mode as a source of instability in responses across surveys</article-title>. <source>Field Methods</source>, <volume>17</volume>, <fpage>30</fpage>–<lpage>52</lpage>.</citation>
</ref>
<ref id="bibr7-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Sangster</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Tarnai</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rockwood</surname>
<given-names>T.</given-names>
</name>
</person-group> <year>1996</year>. <article-title>Understanding differences in people’s answers to telephone and mail surveys</article-title>. <source>New Directions for Evaluation</source>, <volume>70</volume>, <fpage>45</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr8-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Smyth</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>2009</year>. <source>Internet, mail and mixed-mode surveys: The tailored design method</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr9-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Eisenhower</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Mathiowetz</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Morganstein</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>1991</year>. <article-title>Recall error: Sources and bias reduction techniques</article-title>. In <source>Measurement errors in surveys</source>, eds. <person-group person-group-type="editor">
<name>
<surname>Biemer</surname>
<given-names>P. P.</given-names>
</name>
<name>
<surname>Groves</surname>
<given-names>R. M.</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>L. E.</given-names>
</name>
<name>
<surname>Mathiowetz</surname>
<given-names>N. A.</given-names>
</name>
<name>
<surname>Sudman</surname>
<given-names>S.</given-names>
</name>
</person-group> <fpage>127</fpage>–<lpage>44</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr10-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gilljam</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Granberg</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>1993</year>. <article-title>Should we take don’t know for an answer?</article-title> <source>Public Opinion Quarterly</source>, <volume>57</volume>, <fpage>348</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr11-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Goyder</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>1987</year>. <source>The silent minority: Nonrespondents on sample surveys</source>. <publisher-loc>Boulder, CO</publisher-loc>: <publisher-name>Westview</publisher-name>.</citation>
</ref>
<ref id="bibr12-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Presser</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Dipko</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>The role of topic interest in survey participation decisions</article-title>. <source>Public Opinion Quarterly</source>, <volume>68</volume>, <fpage>2</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr13-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Singer</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Corning</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>2000</year>. <article-title>Leverage-salience theory of survey participation: Description and an illustration</article-title>. <source>Public Opinion Quarterly</source>, <volume>64</volume>, <fpage>299</fpage>–<lpage>308</lpage>.</citation>
</ref>
<ref id="bibr14-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Holland</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>The influence of topic interest and interactive probing on responses to open-ended questions in web surveys</article-title>. <source>Social Science Computer Review</source>, <volume>27</volume>, <fpage>196</fpage>–<lpage>212</lpage>.</citation>
</ref>
<ref id="bibr15-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Jenkins</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>1997</year>. <article-title>Towards a theory of self-administered questionnaire design</article-title>. In <source>Survey measurement and process quality</source>, eds. <person-group person-group-type="editor">
<name>
<surname>Lyberg</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Biemer</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Collins</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Leeuw</surname>
<given-names>E. de</given-names>
</name>
<name>
<surname>Dippo</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Schwarz</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Trewin</surname>
<given-names>D.</given-names>
</name>
</person-group> <fpage>165</fpage>–<lpage>96</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr16-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Knäuper</surname>
<given-names>B.</given-names>
</name>
</person-group> <year>1999</year>. <article-title>The impact of age and education on response order effects in attitude measurement</article-title>. <source>Public Opinion Quarterly</source>, <volume>63</volume>, <fpage>347</fpage>–<lpage>70</lpage>.</citation>
</ref>
<ref id="bibr17-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Knäuper</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Belli</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Herzog</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>1998</year>. <article-title>Question difficulty and respondents’ characteristics: Effects on data quality</article-title>. <source>Journal of Official Statistics</source>, <volume>13</volume>, <fpage>181</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr18-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krosnick</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Alwin</surname>
<given-names>D.</given-names>
</name>
</person-group> <year>1987</year>. <article-title>An evaluation of a cognitive theory of response-order effects in survey measurement</article-title>. <source>Public Opinion Quarterly</source>, <volume>51</volume>, <fpage>201</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr19-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krosnick</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Narayan</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Smith</surname>
<given-names>W.</given-names>
</name>
</person-group> <year>1996</year>. <article-title>Satisficing in surveys: Initial evidence</article-title>. <source>New Directions for Evaluation</source>, <volume>70</volume>, <fpage>29</fpage>–<lpage>44</lpage>.</citation>
</ref>
<ref id="bibr20-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lam</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Bordingnon</surname>
<given-names>C.</given-names>
</name>
</person-group> <year>2002</year>. <article-title>Effects of item grouping and position of the “don’t know” questionnaire response</article-title>. <source>Field Methods</source>, <volume>14</volume>, <fpage>418</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr21-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Marcus</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Bosjnak</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Lindner</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Pilischenko</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Shutz</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>Compensating for low topic interest and long surveys: A field experiment on nonresponse in web surveys</article-title>. <source>Social Science Computer Review</source>, <volume>25</volume>, <fpage>372</fpage>–<lpage>83</lpage>.</citation>
</ref>
<ref id="bibr22-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Petty</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Cacioppo</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>1986</year>. <source>Communication and persuasion: Central and peripheral routes to attitude change</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr23-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rapoport</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>1982</year>. <article-title>Sex differences in attitude expression: A generational explanation</article-title>. <source>Public Opinion Quarterly</source>, <volume>46</volume>, <fpage>86</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr24-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Schuman</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Presser</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>1981</year>. <source>Questions and answers in attitude surveys experiments on question form, wording, and context</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr25-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Schwarz</surname>
<given-names>N.</given-names>
</name>
</person-group> <year>1996</year>. <source>Cognition and communication: Judgmental biases, research methods, and the logic of conversation</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr26-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smyth</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>McBride</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>Open-ended questions in web surveys: Can increasing the size of answer boxes and providing extra verbal instructions improve response quality?</article-title> <source>Public Opinion Quarterly</source>, <volume>73</volume>, <fpage>325</fpage>–<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr27-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smyth</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Christian</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Stern</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2006</year>. <article-title>Comparing check-all and forced-choice question formats in web surveys</article-title>. <source>Public Opinion Quarterly</source>, <volume>70</volume>, <fpage>66</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr28-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Stern</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2006</year>. <article-title>How use of the Internet impacts community participation and the maintenance of core social ties: An empirical study</article-title>. <comment>PhD diss., Department of Sociology</comment>, <publisher-name>Washington State University</publisher-name>.</citation>
</ref>
<ref id="bibr29-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stern</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>The use of client-side paradata in analyzing the effects of visual layout on changing responses in web surveys</article-title>. <source>Field Methods</source>, <volume>20</volume>, <fpage>377</fpage>–<lpage>98</lpage>.</citation>
</ref>
<ref id="bibr30-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stern</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Smyth</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>Visual design, order effects and respondent characteristics in a self-administered survey</article-title>. <source>Survey Research Methods</source>, <volume>1</volume>, <fpage>121</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr31-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sudman</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Bradburn</surname>
<given-names>N.</given-names>
</name>
</person-group> <year>1974</year>. <source>Response effects in surveys</source>. <publisher-loc>Chicago</publisher-loc>: <publisher-name>Aldine</publisher-name>.</citation>
</ref>
<ref id="bibr32-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Thomas</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Klein</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>2006</year>. <article-title>Merely incidental? Effects of response format on self-reported behavior</article-title>. <source>Journal of Official Statistics</source>, <volume>22</volume>, <fpage>221</fpage>–<lpage>44</lpage>.</citation>
</ref>
<ref id="bibr33-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Toepoel</surname>
<given-names>V.</given-names>
</name>
</person-group> <year>2008</year>. <source>A closer look at web questionnaire design</source>. <comment>Tillburg, The Netherlands Center for Economic Research Dissertation Series No. 220.</comment>: <publisher-name>Tillburg University</publisher-name>.</citation>
</ref>
<ref id="bibr34-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Toepoel</surname>
<given-names>V.</given-names>
</name>
<name>
<surname>Vis</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Das</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>van Soest</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>Design of web questionnaires: An information-processing perspective for the effect of response categories</article-title>. <source>Sociological Methods &amp; Research</source>, <volume>37</volume>, <fpage>371</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr35-1525822X11419478">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Tourangeau</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>1984</year>. <article-title>Cognitive science and survey methods</article-title>. In <source>Cognitive aspect of survey methodology: Building a bridge between disciplines</source>, eds. <person-group person-group-type="editor">
<name>
<surname>Jabine</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Straf</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Tanur</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Tourangeau</surname>
<given-names>R.</given-names>
</name>
</person-group> <fpage>73</fpage>–<lpage>100</lpage>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academy Press</publisher-name>.</citation>
</ref>
<ref id="bibr36-1525822X11419478">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tourangeau</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Couper</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Conrad</surname>
<given-names>F.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>Spacing, position, and order: Interpretive heuristics for visual features of survey questions</article-title>. <source>Public Opinion Quarterly</source>, <volume>68</volume>, <fpage>368</fpage>–<lpage>93</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>