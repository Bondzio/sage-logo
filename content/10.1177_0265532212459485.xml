<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">LTJ</journal-id>
<journal-id journal-id-type="hwp">spltj</journal-id>
<journal-title>Language Testing</journal-title>
<issn pub-type="ppub">0265-5322</issn>
<issn pub-type="epub">1477-0946</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0265532212459485</article-id>
<article-id pub-id-type="publisher-id">10.1177_0265532212459485</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Test review</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Ten years on: The Hong Kong Language Proficiency Assessment for Teachers of English (LPATE)</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Coniam</surname><given-names>David</given-names></name>
<aff id="aff1-0265532212459485">The Hong Kong Institute of Education, Hong Kong</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Falvey</surname><given-names>Peter</given-names></name>
<aff id="aff2-0265532212459485">The Chinese University of Hong Kong, Hong Kong</aff>
</contrib>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>30</volume>
<issue>1</issue>
<fpage>147</fpage>
<lpage>155</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<sec id="section1-0265532212459485">
<title>Purpose</title>
<p>The <italic>Language Proficiency Assessment for Teachers of English</italic> (LPATE) is a test of standards of English language ability for Hong Kong primary and secondary school teachers of English.</p>
</sec>
<sec id="section2-0265532212459485">
<title>Background to the initiative for setting minimum standards for English language teachers</title>
<p>The impetus for the creation of the LPATE arose, in 1996, because of concerns in business and education communities over falling English language standards among teachers in Hong Kong, supported by evidence from <xref ref-type="bibr" rid="bibr14-0265532212459485">Tsui, Coniam, Sengupta and Wu (1994)</xref> that less than 20% of English language teachers were both subject and professionally trained. With a view to upgrading teacher language standards, the Hong Kong Government thus decided, in 1996, to investigate the establishment of language ‘benchmarks’ – minimum standards of competence in English language – for all teachers in Hong Kong (of 42,000 primary and secondary school teachers, approximately 12,500 were English language teachers) and initiated the process by commissioning a consultancy study for the LPATE.</p>
<p>A representative committee was established in late 1997 to agree on assessment constructs, establish specifications, create exemplar tasks, assemble scales and descriptors for criterion-referenced task assessment and monitor the piloting of the assessment instruments. It was agreed that the target model for English would not be a native speaker but an ‘educated Hong Kong speaker of English’. It was also agreed that the assessment should consist of a battery of ‘formal’ tests (i.e. Reading, Writing, Listening and Speaking), and a live performance test of Classroom Language. The Reading and Listening Tests were to be analytically marked. The composition element in the Writing Test, the Speaking Test and Classroom Language Assessment (CLA) components were to be scale-based with descriptors specifying levels of achievement on different scales. Failure to reach accepted standards would result in retraining and possible dismissal from the profession of current teachers and a bar to entry to the profession for new entrants. This condition was particularly threatening for non-graduate primary school teachers of English whose standards were lower than those of graduate entrants to the profession.</p>
<p>The Committee agreed that in such a high-stakes assessment exercise, assessment procedures and tasks should be as authentic, credible and transparent as possible; for example assessment of the teacher’s language in a live classroom context was viewed as an essential component of the benchmarking battery of tasks in spite of claims that it would be difficult to administer, threatening to teachers and costly.</p>
<p>The model of language assessment that was used parallels the elements of the model laid out in <xref ref-type="bibr" rid="bibr12-0265532212459485">MacNamara (1996)</xref>. That means that in the context of assessing English language teachers’ language ability, a performance assessment model of communicative competence was followed where tasks were as authentic as possible. In addition, care was taken to delineate the practical boundaries of what can be assessed. For the non-performance elements of the test, it was decided to use tests for reading and listening that were to be amenable to statistical analysis.</p>
<p>The piloting of the assessment framework, the Pilot Benchmark Assessment (English) [PBAE], was administered in 1999 to determine how well lower secondary English language teachers coped with the prototype benchmark levels of language ability. The examination syllabus and specifications for the LPATE test were published in 2001 (<xref ref-type="bibr" rid="bibr11-0265532212459485">Government of the Hong Kong Special Administrative Region, 2000</xref>), with the first live administration in March 2001.</p>
<p>The LPATE’s initial life was five years, until September 2006 (see <xref ref-type="bibr" rid="bibr15-0265532212459485">Urmston, 2002</xref>), to ensure that all serving teachers met the minimum standard in all test components. After 2006, the test was to be revisited and revised, and only offered to new teachers. During the first five years, no charge to sit the test was levied but, in 2007, a charge equivalent to US$300 was introduced for new teachers (<xref ref-type="bibr" rid="bibr8-0265532212459485">Education Bureau of Hong Kong, 2007</xref>).</p>
<p>Despite initial reservations, the Hong Kong Government, after considerable debate, granted full exemption to teachers holding both a relevant degree and a professional teaching qualification and, furthermore, set aside US$30 million so that approximately half the whole teacher cohort of 42,000 primary and secondary school teachers might attend enhancement courses and prove they met the specified standard.</p>
</sec>
<sec id="section3-0265532212459485">
<title>The 2007 revision</title>
<p>A revision to the LPATE was commissioned in 2005 and completed in 2007. The revised version was broadly similar to the 2000 version, with some minor amendments. <xref ref-type="table" rid="table1-0265532212459485">Table 1</xref> lays out the five components of the test.</p>
<table-wrap id="table1-0265532212459485" position="float">
<label>Table 1.</label>
<caption>
<p>Overview of the LPATE (after 2007 revision)</p>
</caption>
<graphic alternate-form-of="table1-0265532212459485" xlink:href="10.1177_0265532212459485-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
</colgroup>
<tbody>
<tr>
<td><bold>Classroom Language Assessment</bold></td>
</tr>
<tr>
<td><italic>Purpose</italic>: Demonstrate the ability to deliver an English lesson to students in a primary or secondary class</td>
</tr>
<tr>
<td><italic>Input and output characteristics</italic>: Two separate assessments in a candidate’s school of a single-period (40 minute) lesson.</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic>:</td>
</tr>
<tr>
<td>Scale 1: Grammatical and Lexical Accuracy and Range</td>
</tr>
<tr>
<td>Scale 2: Pronunciation, Stress and Intonation</td>
</tr>
<tr>
<td>Scale 3: The Language of Interaction</td>
</tr>
<tr>
<td>Scale 4: The Language of Instruction</td>
</tr>
<tr>
<td><italic>Passing criteria</italic>: A minimum of Level 3 (one 2.5 allowed) must be obtained on all 4 scales to pass.</td>
</tr>
<tr>
<td><bold>Reading Test</bold></td>
</tr>
<tr>
<td><italic>Purpose</italic>: Demonstrate the ability to read and understand texts of the type that an English teacher might read for both teaching and professional development purposes.</td>
</tr>
<tr>
<td><italic>Input and output characteristics</italic>: Three sections (with a combined word length of 1,500–2,000 words), each consisting of questions on texts of various types: narratives, arguments, descriptions, etc.</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic>: Analytical scoring approach: No. of questions 40–50</td>
</tr>
<tr>
<td><italic>Passing criteria</italic>: Raw scores converted to 5 levels of proficiency, with final scores determined via expert judgement procedures. A minimum of Level 3 must be obtained to pass.</td>
</tr>
<tr>
<td><bold>Listening Test</bold></td>
</tr>
<tr>
<td><italic>Purpose</italic>: Demonstrate the ability to understand spoken texts of the type that an English teacher would listen to for both teaching and professional development purposes.</td>
</tr>
<tr>
<td><italic>Input and output characteristics</italic>: Three or four recordings of spoken discourse (heard once only) of various types: radio news, interviews, chat shows, current affairs shows, etc.</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic>: Analytical scoring approach: No. of questions 30–40</td>
</tr>
<tr>
<td><italic>Passing criteria</italic>: Raw scores converted to 5 levels of proficiency, with final scores determined via expert judgement procedures. A minimum of Level 3 must be obtained to pass.</td>
</tr>
<tr>
<td><bold>Writing Test</bold></td>
</tr>
<tr>
<td><italic>Purpose</italic>: Demonstrate the ability to 1) write a coherent text; 2) correct errors in a student composition; 3) provide a written explanation of errors in a student composition.</td>
</tr>
<tr>
<td><bold>Part 1</bold> – <italic>Input and output characteristics</italic>: Candidates to write one text of 400 words (e.g. expository, narrative, descriptive, etc.) around a topic familiar to Hong Kong teachers.</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic>:</td>
</tr>
<tr>
<td>Scale 1: Organization and Coherence</td>
</tr>
<tr>
<td>Scale 2: Grammatical and Lexical Accuracy and Range</td>
</tr>
<tr>
<td>Scale 3: Task Completion</td>
</tr>
<tr>
<td><bold>Part 2</bold> (two tasks) – <italic>Input and output characteristics</italic>: limited-response blank-filling tasks</td>
</tr>
<tr>
<td>Task 2A: Detection and correction of errors or problems in a piece of writing</td>
</tr>
<tr>
<td>Task 2B: Explanation of (different) errors or problems in the same piece of writing</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic> – Tasks 2A and 2B each carry 20 points, with raw scores converted to 5 levels of proficiency on 2 scales of performance:</td>
</tr>
<tr>
<td>Scale 4: Correcting errors/problems in a student’s composition</td>
</tr>
<tr>
<td>Scale 5: Explaining errors/problems in a student composition</td>
</tr>
<tr>
<td><italic>Passing criteria</italic>: A minimum of Level 3 (one 2.5 allowed) must be obtained on all 5 scales to pass.</td>
</tr>
<tr>
<td><bold>Speaking Test</bold></td>
</tr>
<tr>
<td><italic>Purpose</italic>: Demonstrate the ability to 1) read aloud an English language teaching-type prose passage; 2) recount an experience/present arguments; 3) participate in a discussion on an education-related topic</td>
</tr>
<tr>
<td><bold>Part 1</bold> (two tasks)</td>
</tr>
<tr>
<td>Task 1A: Reading Aloud – <italic>Input and output characteristics</italic>: Reading aloud a prose passage</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic> (Task 1A)</td>
</tr>
<tr>
<td>Scale 1: Pronunciation, Stress and Intonation; Scale 2: Reading Aloud with Meaning</td>
</tr>
<tr>
<td>Task 1B: Recounting an experience / Presenting an argument – <italic>Input and output characteristics</italic>: Responding to a prompt</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic> (Task 1B)</td>
</tr>
<tr>
<td>Scale 3: Grammatical and Lexical Accuracy and Range; Scale 4: Organization and Cohesion</td>
</tr>
<tr>
<td><bold>Part 2</bold>: Group Interaction: Participating in a group discussion related to an English language issue</td>
</tr>
<tr>
<td><italic>Input and output characteristics –</italic> Responding to a prompt</td>
</tr>
<tr>
<td><italic>Assessment criteria</italic> (Part 2)</td>
</tr>
<tr>
<td>Scale 5: Interacting with Peers; Scale 6: Discussing Educational Matters with Peers</td>
</tr>
<tr>
<td><italic>Passing criteria</italic>: A minimum of Level 3 (one 2.5 allowed) must be obtained on all 6 scales to pass.</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section4-0265532212459485">
<title>Implementation of LPATE and results</title>
<p>The LPATE was administered first in 2001, again in 2002 and 2003, twice yearly from 2004 to 2005 and once a year thereafter. In the first two years (i.e. 2001–2003), the number of applications to sit the LPATE was low, as teachers wondered whether the examination was a government initiative which might fizzle out. When this did not occur, and the deadline of 2006 for getting ‘benchmarked’ approached, the candidature for the test began to rise.</p>
<p><xref ref-type="table" rid="table2-0265532212459485">Table 2</xref> presents the candidature for the various administrations and test results from 2001 to 2011. Note particularly the lower scores for Speaking and Writing. As all five components of the test <italic>must</italic> be passed, the overall pass rate was, consequently, very low even though scores on the other three components were reasonably high. The results from the first administration in 2001 produced an outcry in the local media because of the apparently low pass rates – considerably lower than the 33% who passed the writing test (see, e.g., <xref ref-type="bibr" rid="bibr13-0265532212459485"><italic>South China Morning Post</italic>, 2001</xref>).</p>
<table-wrap id="table2-0265532212459485" position="float">
<label>Table 2.</label>
<caption>
<p>LPATE results</p>
</caption>
<graphic alternate-form-of="table2-0265532212459485" xlink:href="10.1177_0265532212459485-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Year</th>
<th align="left">2001</th>
<th align="left">2002</th>
<th align="left">2003</th>
<th align="left">2004</th>
<th align="left">2004</th>
<th align="left">2005</th>
<th align="left">2005</th>
<th align="left">2006</th>
<th align="left">2007</th>
<th align="left">2008</th>
<th align="left">2009</th>
<th align="left">2010</th>
<th align="left">2011</th>
</tr>
<tr>
<th align="left">Candidature</th>
<th align="left">396</th>
<th align="left">708</th>
<th align="left">1968</th>
<th align="left">2177</th>
<th align="left">1494</th>
<th align="left">1115</th>
<th align="left">1445</th>
<th align="left">953</th>
<th align="left">1836</th>
<th align="left">1285</th>
<th align="left">1298</th>
<th align="left">2058</th>
<th align="left">1867</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reading</td>
<td>86%</td>
<td>55%</td>
<td>63%</td>
<td>71%</td>
<td>66%</td>
<td>71%</td>
<td>59%</td>
<td>86%</td>
<td>79%</td>
<td>83%</td>
<td>80%</td>
<td>66%</td>
<td>89%</td>
</tr>
<tr>
<td>Writing</td>
<td>33%</td>
<td>29%</td>
<td>41%</td>
<td>40%</td>
<td>28%</td>
<td>41%</td>
<td>30%</td>
<td>46%</td>
<td>40%</td>
<td>42%</td>
<td>46%</td>
<td>43%</td>
<td>37%</td>
</tr>
<tr>
<td>Listening</td>
<td>68%</td>
<td>39%</td>
<td>72%</td>
<td>49%</td>
<td>71%</td>
<td>62%</td>
<td>64%</td>
<td>74%</td>
<td>80%</td>
<td>72%</td>
<td>70%</td>
<td>72%</td>
<td>83%</td>
</tr>
<tr>
<td>Speaking</td>
<td>51%</td>
<td>58%</td>
<td>45%</td>
<td>47%</td>
<td>43%</td>
<td>45%</td>
<td>39%</td>
<td>37%</td>
<td>48%</td>
<td>62%</td>
<td>51%</td>
<td>44%</td>
<td>50%</td>
</tr>
<tr>
<td>CLA</td>
<td>89%</td>
<td>91%</td>
<td>89%</td>
<td>88%</td>
<td>90%</td>
<td>89%</td>
<td>93%</td>
<td>93%</td>
<td>93%</td>
<td>95%</td>
<td>97%</td>
<td>94%</td>
<td>96%</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0265532212459485"><p><italic>Source</italic>: <ext-link ext-link-type="uri" xlink:href="http://www.edb.gov.hk/index.aspx?langno=1&amp;nodeid=1365">www.edb.gov.hk/index.aspx?langno=1&amp;nodeid=1365</ext-link></p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section5-0265532212459485">
<title>Test quality analysis: Reliability, validity, fairness</title>
<p>The LPATE is created and administered by the Hong Kong Examinations and Assessment Authority (HKEAA) except for the Classroom Language component which is administered by the Government’s Education Bureau.</p>
<p>During the initial phases of development, analyses and validation reports were conducted for all LPATE test components, although not all were made public. Research was reported for CLA (<xref ref-type="bibr" rid="bibr3-0265532212459485">Coniam &amp; Falvey, 1999a</xref>); the development of the Writing Test (<xref ref-type="bibr" rid="bibr9-0265532212459485">Falvey &amp; Coniam, 2000</xref>), assessor training for the Speaking Test (<xref ref-type="bibr" rid="bibr4-0265532212459485">Coniam &amp; Falvey, 1999b</xref>), and the cloze component of the Reading Test (<xref ref-type="bibr" rid="bibr5-0265532212459485">Coniam &amp; Falvey, 2000</xref>).</p>
</sec>
<sec id="section6-0265532212459485">
<title>Reliability</title>
<p>The HKEAA is rigorous in the quality control of all its examinations and strives for high reliability in all them. The objective Reading, Listening and Writing (error correction) Tests go through a rigorous development process. Before being administered as live tests, they are pretested, refined and equated against anchor tests. These components of the LPATE are marked, and administratively checked for consistency. Although not published, confidential access to analyses of administered live tests reveals reliability indices to be in the region of 0.8 for the Reading and Listening Tests, and 0.7 for the Writing (error correction) Test.</p>
<p>For the performance test components of the LPATE, thorough and repeated training exercises and standardization procedures are compulsory for all markers. The Speaking Test and Writing (composition) Tests are double marked while CLA is either double marked or assessed on two separate occasions by assessors from the Hong Kong Education Bureau. CLA charges are approximately US$120, well below the actual cost of administering that component.</p>
<p>In the case of the Writing (composition) Test, the three scales, after marking, are converted to Rasch Fair Average scores to take account of marker severity. Rasch Fair Averaging is not possible for the Speaking Test (there is insufficient overlap possible with the 70 markers marking across three different centres on various occasions); however, all performances are video-recorded, and potential ‘fail’ scores (any level ‘2’, see below) are reviewed for accuracy.</p>
<p>There is an equitable appeals procedure in place. While this varies from year to year, in 2011, the appeal rate was 8.6% of the candidature. Unsurprisingly, few appeals succeed on the objective papers although rather more succeed on the Speaking and Writing (composition) Tests. Further, under government data access laws, candidates can request access to any of their marked scripts.</p>
<p>The HKEAA’s Chief Examiners’ reports are available through the Education Bureau’s website. While – as mentioned – item analyses are conducted for the Reading, Listening and Writing (error correction) Tests, these are not reported to the public; they have, however, been made available to the authors for the current review. The reports highlight the strength and weaknesses of candidates, as well as problematic items. With regard to reliability and consistency, <xref ref-type="bibr" rid="bibr7-0265532212459485">Drave (2010)</xref> asserts that the various assessment processes gives rise to ‘standards which are quite stable from year to year’ (p. 6).</p>
</sec>
<sec id="section7-0265532212459485">
<title>Validity</title>
<p>In terms of validity, test types were originally developed that would, as far as possible, reflect tasks that an English language teacher might face – and have, for the most part, remained so. However, it should be noted that there was a range of relevance in the task types that were accepted for the actual test. For example, CLA has high validity while the Speaking Test requires candidates to read aloud and to discuss student written work. The Listening and Reading Tests require candidates to respond to the type of texts that they might come across in the context of their work. The composition task on the Writing Test requires candidates to produce a piece of expository writing related to teaching.</p>
<p>During its short life, two test types have been singled out for criticism regarding their validity. The first concerns the inclusion, in 2001, of a multiple-choice cloze test in the Reading Test. There was initially resistance to the inclusion of this test type on two grounds. First, that it contravened the more modern paradigm of assessment which eschews large-scale multiple-choice testing; and second, that the material should be authentic. However, after much discussion, it was finally agreed to include a multiple-choice cloze test because of the reliability such a test might afford as an anchor against the other test components. However, the multiple-choice cloze test was removed in the 2007 revision on grounds of poor validity.</p>
<p>The second validity issue was the inclusion in the Writing Test of a task requiring candidates to identify and explain errors in a student text. <xref ref-type="bibr" rid="bibr10-0265532212459485">Glenright (2002)</xref> criticizes the error-correction section of the Writing Test, asserting that it produces detrimental washback for teachers preparing for the examination. Nonetheless, in the 2007 revision, it was decided that this element would remain, although slightly refocused by the inclusion of more objective items into the second part – explaining errors. The decision may have been influenced by <xref ref-type="bibr" rid="bibr1-0265532212459485">Andrews (2001)</xref> who, in the context of teacher language awareness, concludes that ‘when teaching grammar, teachers who know it better, and can explain and reflect on it better may teach it better’ and by Chief Examiner Reports (CERs) in the early years which regularly commented on candidates’ inability to recognize, correct and explain sentence level errors (see, e.g., CERs 2001, p. 3; 2002, p. 4; <ext-link ext-link-type="uri" xlink:href="http://www.edb.gov.hk/index.aspx?nodeid=1365&amp;langno=1">www.edb.gov.hk/index.aspx?nodeid=1365&amp;langno=1</ext-link>).</p>
</sec>
<sec id="section8-0265532212459485">
<title>Fairness</title>
<p>A further issue is fairness: how a pass is determined on each test component and the test as a whole. A pass on the LPATE is obtained via a ‘conjunctive’ scoring method (<xref ref-type="bibr" rid="bibr16-0265532212459485">Zieky &amp; Perie, 2006</xref>). That is, a pass (Level 3) has to be obtained on all scales in all test components. This is in contrast to the ‘compensatory’ scoring method of tests such as IELTS, where a higher score on one scale may compensate for a lower score on another.</p>
<p>The test types developed for the LPATE were all criterion-referenced (‘standards-referenced’ in HKEAA terms) in that the percentage of test takers who might pass was not predetermined. It is important to consider, however, how pass marks are arrived at for the different test types. As explained earlier, the Reading Test, Listening Test, and the Writing (error correction) Test are analytically marked. Pass marks for these tests are determined through a modified Angoff-based expert-judgment approach (<xref ref-type="bibr" rid="bibr2-0265532212459485">Angoff, 1971</xref>) supported by Rasch analysis related to an anchor test (see <xref ref-type="bibr" rid="bibr7-0265532212459485">Drave, 2010</xref>). The Angoff method typically assigns an expected passing percentage (after the experts consider what score a minimally adequate test taker would achieve) for each question on a test, with an overall cut score determined from the mean passing rate for all questions combined. In contrast to the analytically marked test components, the Writing (composition) Test, Speaking Test and CLA are assessed using scales and descriptors. A cogent discussion of standard setting for the Reading and Listening Tests is presented in <xref ref-type="bibr" rid="bibr7-0265532212459485">Drave (2010)</xref>.</p>
<p>While a pass on the Reading and Listening Tests is determined globally by an overall test score, it was decided that a pass on the scale-based tests should be contingent upon test takers passing every scale. Consider the Writing Test, for example, which consists of five scales. Not reaching the benchmark level (Level 3) in any one of these levels results in a fail on that test component. (Note, however, that a dispensation of one ‘Level 2.5’ score is permitted on one scale only.)</p>
<p>The issue of allowing one fail at Level 2.5 on one scale only is probably worth revisiting when the next revision occurs. This criterion for success is there because an insistence on achieving a benchmark level in all components of the scale-based tests is considered, by the authorities, as a non-negotiable condition for passing the examination. The downside is that it leads to a comparatively large number of failures. Although it could be argued that this method militates against test takers in ways which examinations such as IELTS which average scores do not, it can also be argued that in a high-stakes test of teacher competence it is necessary that candidates pass every component.</p>
</sec>
<sec id="section9-0265532212459485">
<title>How far has the LPATE achieved its objective?</title>
<p>The purpose of the LPATE was to meet the requirement that in order to deliver any form of communicative curriculum, teachers would need to operate in English at a reasonably high level. The minimum standard (Level 3) equates (impressionistically) with IELTS 6.5, indicative of a level needed to operate at tertiary level. This would appear to be a defensible standard for a non-native speaking teacher of English.</p>
<p>Although there is no hard evidence yet that English language teachers standards have risen (<xref ref-type="bibr" rid="bibr6-0265532212459485">Drave, 2006</xref>), it is likely that LPATE has had some effect in part, because of the necessity for non-English majors to establish their competency, in part because of the requirement for <italic>all</italic> teachers of English to be degree holders and reach required minimum standards (which has had a substantial, positive effect on the primary sector in particular), and also in part through the loss to the profession (through attrition, retirement, personal decision, etc.) of teachers whose English may have been less than optimal.</p>
<p>The question of how far teacher competency equates with improved levels of English in students in the English language teaching context, is, however, still an empirical question that deserves further investigation.</p>
</sec>
</body>
<back>
<ack><p>We would like to thank the Hong Kong Examinations and Assessment Authority – and in particular Christina Lee, General Manager of the Assessment Development Office, and Neil Drave, the Manager for Assessment Development of the LPATE – for access to confidential data and for support in putting the review together.</p></ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p></fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0265532212459485">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Andrews</surname><given-names>S.</given-names></name>
</person-group> (<year>2001</year>). <article-title>The language awareness of the L2 teacher: Its impact upon pedagogical practice</article-title>. <source>Language Awareness</source>, <volume>10</volume>(<issue>2&amp;3</issue>), <fpage>73</fpage>–<lpage>90</lpage>.</citation>
</ref>
<ref id="bibr2-0265532212459485">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Angoff</surname><given-names>W. H.</given-names></name>
</person-group> (<year>1971</year>). <article-title>Scales, norms and equivalent scores</article-title>. In <person-group person-group-type="editor">
<name><surname>Thorndike</surname><given-names>R. L.</given-names></name>
</person-group> (Ed.), <source>Educational measurement</source>, <edition>2nd ed.</edition> (pp. <fpage>508</fpage>–<lpage>600</lpage>). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Council on Education</publisher-name>.</citation>
</ref>
<ref id="bibr3-0265532212459485">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Coniam</surname><given-names>D.</given-names></name>
<name><surname>Falvey</surname><given-names>P.</given-names></name>
</person-group> (<year>1999a</year>). <article-title>Assessor training in a high-stakes test of speaking: The Hong Kong English language benchmarking initiative</article-title>. <source>Melbourne Papers in Language Testing</source>, <volume>8</volume>(<issue>2</issue>), <fpage>1</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr4-0265532212459485">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Coniam</surname><given-names>D.</given-names></name>
<name><surname>Falvey</surname><given-names>P.</given-names></name>
</person-group> (<year>1999b</year>). <article-title>The English language benchmarking initiative: A validation study of the Classroom Language Assessment component</article-title>. <source>Asia Pacific Journal of Language in Education</source>, <volume>2</volume>(<issue>2</issue>), <fpage>1</fpage>–<lpage>35</lpage>.</citation>
</ref>
<ref id="bibr5-0265532212459485">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Coniam</surname><given-names>D.</given-names></name>
<name><surname>Falvey</surname><given-names>P.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The relevance and applicability of cloze in English language benchmarking in Hong Kong</article-title>. <source>New Horizons in Education</source>, <volume>42</volume>, <fpage>1</fpage>–<lpage>10</lpage>.</citation>
</ref>
<ref id="bibr6-0265532212459485">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Drave</surname><given-names>N.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The Language Proficiency Assessment for Teachers of English (LPATE) as an instrument of educational change</article-title>. In <conf-name>Assessment and Society: Proceedings of the Academic Forum on English Language Testing in Asia (AFELTA)</conf-name>, <conf-loc>Taipei</conf-loc>, <conf-date>November 2006</conf-date>.</citation>
</ref>
<ref id="bibr7-0265532212459485">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Drave</surname><given-names>N.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Keeping up appearances: Maintaining standards in Hong Kong’s Language Proficiency Assessment for teachers of English (LPATE)</article-title>. <conf-name>36th International Association for Education Assessment conference</conf-name>, <conf-loc>Bangkok, Thailand</conf-loc>, <conf-date>August 2010</conf-date>.</citation>
</ref>
<ref id="bibr8-0265532212459485">
<citation citation-type="gov">
<collab>Education Bureau of Hong Kong</collab>. (<year>2007</year>). <article-title>Language Proficiency Assessment for Teachers (English Language) Handbook</article-title>. <access-date>Retrieved December 12, 2011</access-date>, from <ext-link ext-link-type="uri" xlink:href="http://www.edb.gov.hk/index.aspx?nodeid=1368&amp;langno=1">http://www.edb.gov.hk/index.aspx?nodeid=1368&amp;langno=1</ext-link>.</citation>
</ref>
<ref id="bibr9-0265532212459485">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Falvey</surname><given-names>P.</given-names></name>
<name><surname>Coniam</surname><given-names>D.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Establishing English language writing benchmarks for primary and secondary teachers of English language in Hong Kong</article-title>. <source>Hong Kong Journal of Applied Linguistics</source>, <volume>5</volume>(<issue>1</issue>), <fpage>128</fpage>–<lpage>159</lpage>.</citation>
</ref>
<ref id="bibr10-0265532212459485">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Glenright</surname><given-names>P.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Language proficiency assessment for teachers: The effects of benchmarking on writing assessment in Hong Kong schools</article-title>. <source>Assessing Writing</source>, <volume>8</volume>, <fpage>84</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr11-0265532212459485">
<citation citation-type="book">
<collab>Government of the Hong Kong Special Administrative Region</collab>. (<year>2000</year>). <article-title>Language Benchmark Assessment for Teachers – English Language: Syllabus specifications, explanatory notes, specimen questions with suggested answers, scales and descriptors</article-title>. <publisher-loc>Hong Kong</publisher-loc>: <publisher-name>Government Printer</publisher-name>.</citation>
</ref>
<ref id="bibr12-0265532212459485">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>MacNamara</surname><given-names>T.</given-names></name>
</person-group> (<year>1996</year>). <source>Measuring second language performance</source>. <publisher-loc>Harlow, Essex</publisher-loc>: <publisher-name>Addison Wesley Longman</publisher-name>.</citation>
</ref>
<ref id="bibr13-0265532212459485">
<citation citation-type="journal">
<collab>South China Morning Post</collab>. (<year>2001</year>, <month>June</month> <day>9</day>). <article-title>Teachers flunk English test</article-title>. <source>South China Morning Post</source>.</citation>
</ref>
<ref id="bibr14-0265532212459485">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tsui</surname><given-names>A. B. M.</given-names></name>
<name><surname>Coniam</surname><given-names>D.</given-names></name>
<name><surname>Sengupta</surname><given-names>S.</given-names></name>
<name><surname>Wu</surname><given-names>K.Y.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Computer-mediated communication and teacher education: The case of TELENEX</article-title>. In <person-group person-group-type="editor">
<name><surname>Bird</surname><given-names>N.</given-names></name>
<name><surname>Falvey</surname><given-names>P.</given-names></name>
<name><surname>Tsui</surname><given-names>A. B. M.</given-names></name>
<name><surname>McNeill</surname><given-names>A.</given-names></name>
</person-group> (Eds.). <source>Language and Learning</source> (pp. <fpage>352</fpage>–<lpage>369</lpage>). <publisher-loc>Hong Kong</publisher-loc>: <publisher-name>Government Printer</publisher-name>.</citation>
</ref>
<ref id="bibr15-0265532212459485">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Urmston</surname><given-names>A.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The Language Proficiency Assessment for teachers of English in Hong Kong: The first steps towards a fully qualified profession</article-title>. <conf-name>Paper presented at the 5th Asian Forum on English Language Testing</conf-name>, <conf-loc>Tokyo, Japan</conf-loc>, <conf-date>October 2002</conf-date>.</citation>
</ref>
<ref id="bibr16-0265532212459485">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Zieky</surname><given-names>M.</given-names></name>
<name><surname>Perie</surname><given-names>M.</given-names></name>
</person-group> (<year>2006</year>). <source>A primer on setting cut scores on tests of educational achievement</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Educational Testing Service</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>