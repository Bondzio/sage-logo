<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BMS</journal-id>
<journal-id journal-id-type="hwp">spbms</journal-id>
<journal-title>Bulletin de Méthodologie Sociologique</journal-title>
<issn pub-type="ppub">0759-1063</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0759106311426987</article-id>
<article-id pub-id-type="publisher-id">10.1177_0759106311426987</article-id>
<title-group>
<article-title>Nonresponse versus Measurement Error</article-title>
<subtitle>Are Reluctant Respondents Worth Pursuing?</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Hox</surname>
<given-names>Joop J.</given-names>
</name>
<xref ref-type="aff" rid="aff1-0759106311426987"/>
<xref ref-type="corresp" rid="corresp1-0759106311426987"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>de Leeuw</surname>
<given-names>Edith D.</given-names>
</name>
<aff id="aff1-0759106311426987">Department of Methodology and Statistics, Utrecht University</aff>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chang</surname>
<given-names>Hsuan-Tzu</given-names>
</name>
<aff id="aff2-0759106311426987">Department of Psychology, National Taiwan University</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0759106311426987">Joop Hox, Department of Methodology and Statistics, Utrecht University, the Netherlands. P.O.B. 80140, NL-3508 TC, Utrecht, the Netherlands Email: <email>j.hox@uu.nl</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>113</volume>
<issue>1</issue>
<fpage>5</fpage>
<lpage>19</lpage>
<permissions>
<copyright-statement>The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE/ Association Internationale de Méthodologie Sociologique</copyright-holder>
</permissions>
<abstract>
<p>
<bold>Non-réponse versus erreur de mesure – Doit-on insister auprès des répondants réticents ?</bold> : Pour augmenter les taux de réponse, les enquêteurs intensifient leurs efforts pour amener les personnes échantillonnées parmi les répondants. La question est de savoir si les répondants « réticents » fournissent des réponses de qualité moindre que les répondants « impatients ». Nous définissons les répondants impatients comme des personnes qui répondent au premier envoi d'une enquête postale, et les répondants réticents comme des personnes qui répondent plus tardivement. Nous avons utilisé une analyse multitrait-multiméthode (MTMM) qui permet la séparation statistique de la variance de fond ou de trait, la variance de méthode et la variance d'erreur. Les résultats montrent que la structure de mesure ne diffère pas entre les répondants impatients et réticents. Il n'y avait également aucune différence systématique dans les estimations de la fiabilité et la validité des deux groupes.</p>
<p>To increase response rates, survey researchers intensify their efforts to bring sampled persons into the respondent pool. The question is whether or not “reluctant” survey respondents provide answers of lower quality than “eager” respondents. We define eager respondents as persons who respond to the first round of a mail survey, and reluctant respondents as persons who respond in later rounds. We used a multitrait-multimethod (MTMM) design, which allows statistical separation of substantive or trait variance, method variance, and error variance. The results show that the measurement structure does not differ between eager and reluctant respondents. There was also no systematic difference in the reliability and validity estimates for both groups.</p>
</abstract>
<kwd-group>
<kwd>Qualité des données</kwd>
<kwd>Erreurs de mesure</kwd>
<kwd>Multitrait-Multiméthode</kwd>
<kwd>(MTMM)</kwd>
<kwd>Biais de non-réponse</kwd>
<kwd>Répondants réticents</kwd>
<kwd>Erreur d'enquête totale</kwd>
</kwd-group>
<kwd-group>
<kwd>Data Quality</kwd>
<kwd>Measurement Error</kwd>
<kwd>Multitrait-MultiMethod (MTMM)</kwd>
<kwd>Nonresponse Bias</kwd>
<kwd>Reluctant Respondents</kwd>
<kwd>Total Survey Error</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0759106311426987">
<title>Introduction</title>
<p>Participation in surveys has been declining over time (<xref ref-type="bibr" rid="bibr14-0759106311426987">De Leeuw and De Heer, 2002</xref>), and this trend is visible in all sectors of the survey industry (<xref ref-type="bibr" rid="bibr8-0759106311426987">Brehm, 1994</xref>; <xref ref-type="bibr" rid="bibr19-0759106311426987">Goyder, 1987</xref>), and for all survey modes (<xref ref-type="bibr" rid="bibr28-0759106311426987">Hox and De Leeuw, 1994</xref>). In survey methodology, a high response rate is commonly viewed as indicating a “good” survey, and in the last three decades survey researchers have devoted much time and effort to counteract the downward trend in response rates (<xref ref-type="bibr" rid="bibr16-0759106311426987">Dillman, 1978</xref>; <xref ref-type="bibr" rid="bibr13-0759106311426987">De Leeuw, 1999</xref>; <xref ref-type="bibr" rid="bibr19-0759106311426987">Goyder, 1987</xref>; <xref ref-type="bibr" rid="bibr23-0759106311426987">Groves and Couper, 1998</xref>; <xref ref-type="bibr" rid="bibr22-0759106311426987">Groves et al., 2002</xref>; <xref ref-type="bibr" rid="bibr32-0759106311426987">Morton-Williams, 1993</xref>; <xref ref-type="bibr" rid="bibr43-0759106311426987">Singer, 2006</xref>; <xref ref-type="bibr" rid="bibr44-0759106311426987">Stoop, 2005</xref>). However, in recent years there is a growing concern that achieving a high response rate may not always lead to higher quality data, and although nonresponse should not be taken lightly, survey researchers should regard the totality of survey quality indicators (<xref ref-type="bibr" rid="bibr6-0759106311426987">Biemer, 2010</xref>; <xref ref-type="bibr" rid="bibr7-0759106311426987">Biemer and Lyberg, 2003</xref>: 95; <xref ref-type="bibr" rid="bibr25-0759106311426987">Groves and Lyberg, 2010</xref>; see also pp. 133 and 147 in <xref ref-type="bibr" rid="bibr21-0759106311426987">Groves, 1989</xref>).</p>
<p>The quality of survey data can be threatened by sample composition bias, due to nonresponse and self-selection of respondents and by response bias from several sources. Increasing the response rate diminishes the potential impact of selection bias. For example, research has shown that reminders and increased fieldwork effort, not only bring in more respondents, but also can bring in those respondents that are underrepresented, such as the elderly, lower educated, and lower income groups (<xref ref-type="bibr" rid="bibr16-0759106311426987">Dillman, 1978</xref>; <xref ref-type="bibr" rid="bibr44-0759106311426987">Stoop, 2005</xref>). However, this could be purely cosmetic. As nonresponse error is a function of the nonresponse rate and the difference between respondents and nonrespondents on a particular variable of interest (for an overview, see <xref ref-type="bibr" rid="bibr12-0759106311426987">Couper and De Leeuw, 2003</xref>), nonresponse error will only be reduced by drawing in those specific respondents that narrow this gap. That this is not always the case is shown by <xref ref-type="bibr" rid="bibr24-0759106311426987">Groves and Peytcheva (2008)</xref>, who in a meta-analysis of 59 methodological studies, found only a weak relationship between the response rate achieved and the nonresponse bias.</p>
<p>But, even if increasing the response rate does reduce nonresponse errors, by convincing special subpopulations to respond, the question remains whether it decreases the total survey error. Increasing the response rate by increasing the level of effort to bring a sampled person in the respondent pool and drawing in reluctant respondents may actually increase the measurement error (<xref ref-type="bibr" rid="bibr23-0759106311426987">Groves and Couper, 1998</xref>); in other words, it is feared that reluctance to respond may be related to data quality. Two theoretical models can be discerned to describe this situation: an <italic>independence</italic> model and a <italic>common cause</italic> model (see <xref ref-type="bibr" rid="bibr45-0759106311426987">Tourangeau et al., 2008</xref>). In the independence model, nonresponse error and measurement error are uncorrelated and have different sources. Nonresponse is caused by situational factors (time, opportunity, at home patterns) and motivational factors (altruism, low cost compared to benefits, high saliency). Measurement error, on the other hand, is largely cognitive and related to the question-answer process (poor comprehension of question, memory and retrieval difficulties).</p>
<p>In the common cause model, respondents that are difficult to persuade also answer less thoroughly, and the underlying cause of survey non-participation and measurement error is the same. The common cause model states that there is indeed a relationship between reluctance to respond and data quality. Two different mechanisms can be posed for this common cause relationship between response propensity and measurement error. First, there is evidence that reluctant respondents tend to be older, have a lower education and a lower social economic status (SES); see for instance <xref ref-type="bibr" rid="bibr16-0759106311426987">Dillman (1978)</xref>, <xref ref-type="bibr" rid="bibr19-0759106311426987">Goyder (1987)</xref>, <xref ref-type="bibr" rid="bibr21-0759106311426987">Groves (1989)</xref> and <xref ref-type="bibr" rid="bibr44-0759106311426987">Stoop (2005)</xref>. To obtain a representative sample of the population, extra survey effort is often exercised to get these reluctant respondents included. As a consequence, there will be small but replicable socio-demographic differences between eager and reluctant respondents, which in turn can give rise to differences in the amount of measurement error. Respondents with lower education or language problems are expected to produce more measurement errors because they are less capable to go optimally through all phases of the survey question-answer process. Such correlates of measurement error are denoted <italic>extrinsic</italic> error sources, because they derive from a different composition of the response groups, and are not related to the survey process itself. In other words, a relationship between reluctance to respond and data quality is indeed present, but this relationship is spurious and can be explained by differences on background variables (such as age and education) between eager and reluctant respondents.</p>
<p>The second mechanism depends on <italic>intrinsic</italic> error sources, which are related to the survey itself. Intrinsic error sources include respondent motivation, interest in the study, or degree of suspicion if sensitive questions are involved. For instance, highly motivated sample persons or people highly interested in the study will be more prone to respond and will be also more prone to invest effort to go carefully through the question-answer process. Lesser motivated sample members will more easily refuse to cooperate with the survey request or when persuaded will fall back on easy, suboptimal response strategies, such as satisficing, rather than using an optimal response strategy (<xref ref-type="bibr" rid="bibr31-0759106311426987">Krosnick, 1991</xref>). Therefore, the lesser motivated will not only refuse more often, but also produce more measurement errors when persuaded to respond. If indeed intrinsic errors play a major role in the common cause model, there will be a relationship between reluctance to respond and data quality, which cannot be explained away by socio-demographic differences between reluctant and eager respondents.</p>
<p>The purpose of this study is to investigate whether or not reluctant respondents produce larger measurement errors, and whether this is the result of self-selection or of intrinsic differences. Using confirmatory factor analysis of multitrait-multimethod data from a mail survey, we explore the relationship between reluctance and data quality. Furthermore, we investigate whether differences in sample composition on background variables between eager and reluctant respondents (extrinsic factors) may explain differences in data quality.</p>
</sec>
<sec id="section2-0759106311426987">
<title>Review of Earlier Studies</title>
<p>There is some evidence that supports the hypothesis that reluctant sample persons, which are brought into the respondent pool through increasingly persuasive efforts, may provide data with more measurement error than sample persons who respond immediately. As early as 1963, <xref ref-type="bibr" rid="bibr10-0759106311426987">Cannell and Fowler (1963)</xref> found that respondents who reacted immediately to a mail survey provided more accurate responses regarding hospital episodes than more reluctant respondents who reacted to the second mailing, while respondents who had to be prompted a third time by telephone or personal visit gave the least accurate answers. However, <xref ref-type="bibr" rid="bibr34-0759106311426987">Olsen (2006)</xref>, using record checks for divorce and marriage data, finds only few and small associations between response propensity and measurement error, while <xref ref-type="bibr" rid="bibr35-0759106311426987">Olsen and Kennedy (2006)</xref>, who compare survey results on donations and academic performance with administrative records on university alumni, find no support for the hypothesis that respondents who are more difficult to recruit gave less useful data than more amenable respondents. <xref ref-type="bibr" rid="bibr33-0759106311426987">Muller, Krauter and Trappman (2009)</xref> did find a relationship between contactibility and conversion of soft refusals with measurement error on employment data, but the relationships between contactibility and underreporting became non significant when variables related to task difficulty were added to the regression model. Finally, <xref ref-type="bibr" rid="bibr36-0759106311426987">Olsen, Feng, and Witt (2008)</xref> summarize seven studies that look into differences in response accuracy between high and low recruitment effort respondents on such diverse topics as medical history, voting, delinquency and academic performance. They report that findings differ dramatically by type of effort and that when follow-up call attempts are made, small but significant effects are found between immediate respondents and reluctant respondents who needed more follow-ups, with less accuracy for the latter. However, hardly any effect was found for refusal conversion.</p>
<p>All studies cited above investigated behavioural data and could use hard validating information (records) to investigate response accuracy. However, the situation that hard criteria for data quality by means of validating data are available is rare. Furthermore, when subjective phenomena, such as attitudes, are investigated, hard validating data do not exist. In the absence of validation data, a variety of proxy indicators for measurement error are used; a commonly used proxy is item nonresponse. In their meta-analysis, <xref ref-type="bibr" rid="bibr36-0759106311426987">Olsen et al. (2008)</xref> summarize the results of 15 studies with a total of 178 questions for which question-level item nonresponse rates were available. They find that respondents recruited with more effort have higher item nonresponse rates than those recruited easily; they also find that this effect is larger for refusal conversion studies than for other studies.</p>
<p>When attitudinal data are investigated, no consistent evidence is found that more effort to get sample persons into the respondent pool leads to worse data. For instance, <xref ref-type="bibr" rid="bibr48-0759106311426987">Yan et al. (2004)</xref> find hardly any relationships between nonresponse propensity and various indicators of response bias, such as acquiescence, extremeness, and non-differentiation; however, they do find some effect for no-opinion responses with later respondents producing more no-opinion answers. When multiple-item attitude scales are used, it is possible to calculate the psychometric reliability of measurements. <xref ref-type="bibr" rid="bibr20-0759106311426987">Green (1991)</xref> found small, non significant, and inconsistent effects of follow-ups on scale reliability, but did find that late respondents score lower on several attitude scales. <xref ref-type="bibr" rid="bibr15-0759106311426987">De Leeuw and Hox (1988)</xref> find similar results: small differences between eager and reluctant respondents in four scales indicating attitude towards surveys: faithfulness, apprehension, suspiciousness, and perceived question threat, with reluctant respondents indicating less positive attitudes on all scales, but they find no differences in psychometric quality. Finally, <xref ref-type="bibr" rid="bibr11-0759106311426987">Chen et al. (2003)</xref> show that although poor response is associated with biographical background variables, there is no clear association between delayed response and psychographical variables, such as personality traits. A similar result was reported by <xref ref-type="bibr" rid="bibr29-0759106311426987">Hox et al. (1996)</xref>.</p>
<p>
<xref ref-type="bibr" rid="bibr37-0759106311426987">Petchev and Petcheva (2007)</xref> are among the first who go beyond proxy indicators and apply a more complicated model-based definition of measurement error when no validating data are available. Based on mean-variance models, they show that although older and less educated respondents do provide more measurement error, but there is no association between response propensity and measurement error. Finally, <xref ref-type="bibr" rid="bibr30-0759106311426987">Kaminska et al. (2010)</xref> use latent class analysis and structural equation modelling to explore satisficing among reluctant respondents in a cross-national context. Their findings suggest a relationship between reluctance and response quality, but this relationship could be explained away by differences in cognitive ability. For the present study, we reanalyzed a data set, which included the rare combination of information on the nonresponse process and a multitrait-multimethod matrix, to investigate response quality. This enabled us to use a very strong model (<xref ref-type="bibr" rid="bibr40-0759106311426987">Saris and Gallhofer, 2007</xref>) to explore the relationship between reluctance and data quality.</p>
</sec>
<sec id="section3-0759106311426987">
<title>Measurement Error</title>
<p>Measurement error is operationalised in different ways in different studies. Ideally, the true value is known and this true value is then compared with the reported value. Some studies do have access to a validation criterion and therefore can carry out a record check. But when subjective phenomena are studied, hard validation data are <italic> by definition</italic> not available, and researchers have to rely on various proxy indicators of data quality. <xref ref-type="bibr" rid="bibr5-0759106311426987">Biemer (2001)</xref> points out that these often rely on assumptions on the direction of the biases (for example, under-reporting of sensitive information) and argues in favour of a model-based approach instead. <xref ref-type="bibr" rid="bibr37-0759106311426987">Petchev and Petcheva (2007)</xref> also plead for a model-based approach.</p>
<p>A direct model-based approach to the analysis of measurement error in surveys on subjective phenomena is the multitrait-multimethod (MTMM) design that allows separation of substantive or trait variance, method variance, and error variance (<xref ref-type="bibr" rid="bibr9-0759106311426987">Campbell and Fiske, 1959</xref>; <xref ref-type="bibr" rid="bibr2-0759106311426987">Alwin, 1974</xref>; <xref ref-type="bibr" rid="bibr39-0759106311426987">Saris and Andrews, 1991</xref>).</p>
<p>The most common approach to evaluating the measurement model in MTMM designs is confirmatory factor analysis, which defines both the substantive traits and the measurement methods as latent factors. See <xref ref-type="bibr" rid="bibr27-0759106311426987">Hox (1995)</xref> for an application using different software packages. To investigate if eager and reluctant respondents produce different measurement errors, we have to compare the measurement model for both groups.</p>
<p>Three questions can be addressed when groups are compared using confirmatory factor analysis. First, the question is whether or not the eager and reluctant respondents share the same factor structure. This is the weakest form of measurement invariance, in comparative research this is often denoted as factorial or <italic>functional equivalence</italic> (<xref ref-type="bibr" rid="bibr47-0759106311426987">Vandenberg and Lance, 2000</xref>). If functional equivalence holds, the <italic>same constructs</italic> are measured in both groups. The second question is whether the constructs are measured equivalently in both groups. If the factor loadings for eager and reluctant respondents are identical, we have a form of equivalence that is referred to as <italic>metric equivalence</italic> (<xref ref-type="bibr" rid="bibr47-0759106311426987">Vandenberg and Lance, 2000</xref>): the same constructs are measured in the <italic>same way</italic> for both groups. The third question is if the intercepts for the observed variables are identical for both groups. If these intercepts can be considered invariant across groups, this is called <italic>scalar</italic> equivalence (<xref ref-type="bibr" rid="bibr47-0759106311426987">Vandenberg and Lance, 2000</xref>), and the actual scores can be compared across groups. When scalar equivalence holds, the same constructs are measured in the same way and on the <italic>same scale</italic> for both eager and reluctant respondents. Finally, a fourth question is whether or not both groups contribute equal amounts of measurement error, as indicated by the error variances of the responses.</p>
<p>If differences are found between eager and reluctant respondents, this may be because the reluctant respondents, who did not respond initially, are different on background characteristics due to initial selective nonresponse (extrinsic factors). It may also be because reluctant respondents produce more measurement error for intrinsic reasons, for instance, because they are less motivated and tend to satisfice more. Thus, the final step is to analyze which part of the difference is due to differences between the two groups in socio-demographic characteristics because of selective nonresponse in the reluctant group, and which part is due to cognitive aspects in the question-answer process. This question can be addressed by comparing measurement models with and without propensity score adjustment for differences in socio-demographic background variables (see <xref ref-type="bibr" rid="bibr38-0759106311426987">Rubin and Thomas, 1996</xref>).</p>
<p>In this study, we use this model-based MTMM approach to investigate whether or not reluctant respondents, who are pressured to comply with the survey request, produce data of lower quality than eager respondents who immediately respond to the survey request. Furthermore, we investigate if differences are caused by extrinsic causes; that is, by mere differences in background variables, or by intrinsic causes, which are related to the survey and question-answer process itself.</p>
</sec>
<sec id="section4-0759106311426987">
<title>Method</title>
<sec id="section5-0759106311426987">
<title>Sample and Survey Procedure</title>
<p>A secondary analysis was performed on data collected for a survey on well-being in The Netherlands (<xref ref-type="bibr" rid="bibr26-0759106311426987">Hox, 1986</xref>). These data have the advantage that both a careful record of the (non) response was kept and that an MTMM approach was used, giving us the rare opportunity to use a model-based approach to investigate the relationship between nonresponse and measurement error.</p>
<p>The data were collected with a mail survey using <xref ref-type="bibr" rid="bibr16-0759106311426987">Dillman’s (1978)</xref> TDM approach (see also <xref ref-type="bibr" rid="bibr17-0759106311426987">Dillman et al., 2008</xref>), including two reminders with a replacement questionnaire. The questionnaire was mailed to a sample of 1,000 addresses from the telephone directory of the Netherlands, which at the time of data collection (1984) constituted a good sampling frame for the general population. According to Dutch telecom, approximately 90 percent of the private households at that time had a listed landline telephone (see also <xref ref-type="bibr" rid="bibr46-0759106311426987">Trewin and Lee, 1988</xref>). The response rate is 53 percent (American Association for Public Opinion Research [<xref ref-type="bibr" rid="bibr1-0759106311426987">AAPOR], 2011</xref>, standard definitions RR3). Three returned questionnaires contained a large fraction of missing data and were discarded, leaving 498 cases for the analysis.</p>
<p>Respondents who responded to the initial mailing were classified as eager respondents; respondents who responded to the reminders were classified as reluctant respondents. There are 237 eager and 239 reluctant respondents. Compared to the eager respondents, the reluctant respondents differed on important background characteristics; they were older, lower educated, more often rented their house and were more often without a paid job. Furthermore, there were small differences in marital status and gender with more females and more married persons in the reluctant group.</p>
<p>The questionnaire included a MultiTrait-MultiMethod (MTMM) design consisting of three different aspects of well-being (traits), each measured by five question formats (methods). The three traits measuring well-being are “satisfaction with housing”, “satisfaction with income”, and “satisfaction with health”. As methods, both verbal and graphical question formats were used. The verbal question formats are a “direct question” and a “social comparison question”; the graphical question formats are “Cantril’s ladder”, “faces (smileys)”, and “circles” (<xref ref-type="bibr" rid="bibr3-0759106311426987">Andrews and Withey, 1978</xref>). An example of each question format is presented in the <xref ref-type="app" rid="app1-0759106311426987">Appendix</xref>.</p>
</sec>
<sec id="section6-0759106311426987">
<title>Analysis</title>
<p>The most common model for MTMM data is a confirmatory factor model with a factor for each trait and a factor for each method, with trait and method factors mutually uncorrelated (<xref ref-type="bibr" rid="bibr2-0759106311426987">Alwin, 1974</xref>; <xref ref-type="bibr" rid="bibr18-0759106311426987">Eid et al., 2006</xref>). In this model, the trait factors are allowed to correlate, and the method factors are usually uncorrelated. <xref ref-type="bibr" rid="bibr40-0759106311426987">Saris and Gallhofer (2007)</xref> present a confirmatory factor model for MTMM data that is formally equivalent to the classic MTMM model, but which also allows separate estimation of the reliability and the validity of each question. This model has been used by <xref ref-type="bibr" rid="bibr41-0759106311426987">Scherpenzeel and Saris (1993)</xref> to compare the quality of measurement in 10 different European countries. <xref ref-type="fig" rid="fig1-0759106311426987">Figure 1</xref>
 depicts this model for three traits and three methods. The three trait factors and the three methods define 3×3=9 survey questions labelled v1 to v9. The latent variables t1 to t9 represent the true scores for v1 to v9, and the standardised loading of v1 to v9 on the true scores t1 to t9 represent the reliabilities of the survey questions. The loadings of t1 to t9 on the corresponding trait factors (labelled tr1 to tr3) are their validities. The loadings on the method factors (labelled m1 to m3) represent systematic method effects unrelated to the traits. The latent scales for the factors are identified by constraining the variances of all trait and method factors equal to one.</p>
<fig id="fig1-0759106311426987" position="float">
<label>Figure 1.</label>
<caption>
<p>MTMM Confirmatory Factor Model According to <xref ref-type="bibr" rid="bibr40-0759106311426987">Saris and Gallhofer (2007)</xref>
</p>
</caption>
<graphic alternate-form-of="fig1-0759106311426987" xlink:href="10.1177_0759106311426987-fig1.tif"/>
</fig>
<p>Our MTMM design includes three traits (satisfaction with housing, income, and health) and five methods (direct question, social comparison, ladder, faces, and circles), which leads to 15 different questions. We estimated the MTMM model described above for the eager and reluctant respondents simultaneously using a two-group structural equation model. A series of equality constraints across the two groups is used to test for measurement equivalence. All analyses were carried out in the program Amos (<xref ref-type="bibr" rid="bibr4-0759106311426987">Arbucle, 2007</xref>).</p>
<p>To assess how much of the difference is due to socio-demographic differences (extrinsic errors), a propensity score method is used (<xref ref-type="bibr" rid="bibr38-0759106311426987">Rubin and Thomas, 1996</xref>). In the propensity score method, the propensity to be in the eager group was estimated using a logistic regression model with the background variables age, gender, marital status, education, having a job, and house ownership, variables on which the eager and reluctant respondents differed. Next, this propensity score was included in the MTMM model as a covariate, thereby statistically controlling for differences between the eager and reluctant respondents in age, gender, marital status, education, having a job, and house ownership.</p>
</sec>
</sec>
<sec id="section7-0759106311426987">
<title>Results</title>
<p>The MTMM model was first estimated on the entire sample. The fit of this model is good (<italic>χ<sup>2</sup>
</italic>=123.1, <italic>df</italic>=72, <italic>TLI</italic>=0.99, <italic>CFI</italic>=0.99, <italic>RMSEA</italic>=0.04). Subsequently, a series of nested multi-group models were fitted comparing eager and reluctant respondents. The first model imposes functional equivalence (identical factor structure) and is the model with the least restrictions which assesses the weakest form of measurement invariance. The second model adds metric equivalence (identical factor loadings); this model assesses if the constructs are measured equivalently in both groups. The third model adds scalar equivalence (identical intercepts); when this holds, it means both groups can be compared on their factor means. Finally, we test if the error variances are equal across the two groups. This tests whether or not there are differences in measurement error between the eager and the reluctant respondents. <xref ref-type="table" rid="table1-0759106311426987">Table 1</xref>
 shows the fit indices (chi-square, <italic>df</italic>, <italic>p</italic>, <italic>TLI</italic>, <italic>CFI</italic> and <italic>RMSEA</italic>) for these models. In addition, <xref ref-type="table" rid="table1-0759106311426987">Table 1</xref> shows the results of a chi-square difference test, testing the model under consideration against the previous model in the table.</p>
<table-wrap id="table1-0759106311426987" position="float">
<label>Table 1.</label>
<caption>
<p>Fit Indices for Models with Equivalence Constraints between Eager and Reluctant Respondents</p>
</caption>
<graphic alternate-form-of="table1-0759106311426987" xlink:href="10.1177_0759106311426987-table1.tif"/>
<table>
<thead>
<tr>
<th>Model</th>
<th>χ<sup>2</sup> (<italic>d.f.</italic>)</th>
<th>
<italic>p</italic>
</th>
<th>
<italic>TLI</italic>
</th>
<th>
<italic>CFI</italic>
</th>
<th>
<italic>RMSEA</italic>
</th>
<th>
<italic>Δ</italic>χ<sup>2</sup> (Δ<italic>d.f.</italic>)<sup>
<xref ref-type="table-fn" rid="table-fn1-0759106311426987">a</xref>
</sup>
</th>
<th>
<italic>p</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>No constraints</td>
<td>211.0</td>
<td>&lt;.01</td>
<td>.98</td>
<td>.99</td>
<td>.03</td>
<td align="center">–</td>
<td align="center">–</td>
</tr>
<tr>
<td>(functional equivalence)</td>
<td>(144)</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td align="center">
</td>
<td align="center">
</td>
</tr>
<tr>
<td>Equal loadings</td>
<td>240.0</td>
<td>&lt;.01</td>
<td>.99</td>
<td>1.00</td>
<td>.03</td>
<td>29.0 (22)</td>
<td>.14</td>
</tr>
<tr>
<td>(metric equivalence)</td>
<td>(166)</td>
</tr>
<tr>
<td>Equal intercepts</td>
<td>258.2</td>
<td>&lt;.01</td>
<td>.99</td>
<td>.99</td>
<td>.03</td>
<td>18.2 (15)</td>
<td>.25</td>
</tr>
<tr>
<td>(scalar equivalence)</td>
<td>(181)</td>
</tr>
<tr>
<td>Equal error variances</td>
<td>285.0</td>
<td>&lt;.01</td>
<td>.98</td>
<td>.99</td>
<td>.03</td>
<td>26.8 (15)</td>
<td>.03</td>
</tr>
<tr>
<td>(equal reliability)</td>
<td>(196)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0759106311426987">
<p>
<sup>a</sup>
<italic>Δ</italic>χ<sup>2</sup> reference is previous model</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>As <xref ref-type="table" rid="table1-0759106311426987">Table 1</xref> shows, the model that poses functional equivalence (no constraints) fits well. The models that pose metric and scalar equivalence also fit well, and do not differ significantly from the previous model or the functional equivalence model. This means that the strongest form of equivalence, scalar equivalence, holds across the eager and reluctant respondents.</p>
<p>
<xref ref-type="table" rid="table1-0759106311426987">Table 1</xref> also shows the results for a model that poses equal <italic>error variances</italic>. This model has a significantly worse fit than the scalar equivalence model. Thus, the same constructs are measured in both groups of respondents with the same factor structure and identical factor loadings and intercepts, but with different amounts of error variance. This means that eager and reluctant respondents indeed differ in the amount of random measurement error. This is also expressed in the estimates of the reliability of the nine questions reported in <xref ref-type="table" rid="table2-0759106311426987">Table 2</xref>
.</p>
<table-wrap id="table2-0759106311426987" position="float">
<label>Table 2.</label>
<caption>
<p>Parameter Estimates from MultiTrait-MultiMethod Model</p>
</caption>
<graphic alternate-form-of="table2-0759106311426987" xlink:href="10.1177_0759106311426987-table2.tif"/>
<table>
<thead>
<tr>
<th>Question</th>
<th>Trait (Validity)</th>
<th>Method</th>
<th>Reliability<sup>
<xref ref-type="table-fn" rid="table-fn2-0759106311426987">a</xref>
</sup>
</th>
<th>Error variance<sup>
<xref ref-type="table-fn" rid="table-fn2-0759106311426987">a</xref>
</sup>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>House-Direct</td>
<td>1.07</td>
<td>.28</td>
<td>.67 / .71</td>
<td>.60 / .44</td>
</tr>
<tr>
<td>House-Social</td>
<td>.69</td>
<td>.49</td>
<td>.55 / .50</td>
<td>.35 / .40</td>
</tr>
<tr>
<td>House-Ladder</td>
<td>1.17</td>
<td>.20</td>
<td>.90 / .87</td>
<td>.52 / .38</td>
</tr>
<tr>
<td>House-Faces</td>
<td>1.21</td>
<td>.39</td>
<td>.91 / .90</td>
<td>.58 / .65</td>
</tr>
<tr>
<td>House-Circles</td>
<td>1.06</td>
<td>.31</td>
<td>.88 / .90</td>
<td>.49 / .52</td>
</tr>
<tr>
<td>Income- Direct</td>
<td>1.08</td>
<td>.43</td>
<td>.79 / .80</td>
<td>.80 / .66</td>
</tr>
<tr>
<td>Income-Social</td>
<td>.85</td>
<td>.40</td>
<td>.64 / .66</td>
<td>.14 / .13</td>
</tr>
<tr>
<td>Income-Ladder</td>
<td>1.17</td>
<td>.16</td>
<td>.92 / .91</td>
<td>.16 / .09</td>
</tr>
<tr>
<td>Income-Faces</td>
<td>1.17</td>
<td>.46</td>
<td>.90 / .95</td>
<td>.19 / .11</td>
</tr>
<tr>
<td>Income-Circles</td>
<td>1.07</td>
<td>.41</td>
<td>.94 / .90</td>
<td>.12 / .20</td>
</tr>
<tr>
<td>Health-Direct</td>
<td>1.07</td>
<td>.19</td>
<td>.74 / .81</td>
<td>.15 / .17</td>
</tr>
<tr>
<td>Health-Social</td>
<td>.82</td>
<td>.39</td>
<td>.51 / .58</td>
<td>.16 / .12</td>
</tr>
<tr>
<td>Health-Ladder</td>
<td>1.27</td>
<td>.14</td>
<td>.92 / .94</td>
<td>.09 / .11</td>
</tr>
<tr>
<td>Health-Faces</td>
<td>1.30</td>
<td>.37</td>
<td>.89 / .94</td>
<td>.24 / .16</td>
</tr>
<tr>
<td>Health-Circles</td>
<td>1.07</td>
<td>.21</td>
<td>.84 / .85</td>
<td>.58 / .23</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0759106311426987">
<p>
<sup>a</sup>Reliability and error variance separate for eager/reluctant respondents</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>
<xref ref-type="table" rid="table2-0759106311426987">Table 2</xref> shows the parameter estimates for the model with equal loadings and intercepts. Using the model proposed by <xref ref-type="bibr" rid="bibr40-0759106311426987">Saris and Gallhofer (2007)</xref>, we obtain for each question in the MTMM an estimate of its validity (the trait loading), its reliability (the proportion systematic variance) and the error variance. The error variances are allowed to differ across the two groups. As <xref ref-type="table" rid="table2-0759106311426987">Table 2</xref> shows, the error variances and the reliabilities do not consistently differentiate between the two groups. So, although the groups differ in the error variances, there is no systematic tendency for the reluctant respondents to respond with more error and hence lower reliability. The validities also do not differ across the two groups, since the trait loadings can be constrained equal across the eager and reluctant respondents.</p>
<p>
<xref ref-type="table" rid="table2-0759106311426987">Table 2</xref> shows one clear difference: in general, the graphical question formats (faces, ladder, circles) perform very well compared to the verbal question formats (direct question and social comparison). This is clearly shown in <xref ref-type="table" rid="table3-0759106311426987">Table 3</xref>
, which reports the average reliability estimates for the verbal and graphical questions for both eager and reluctant respondents.</p>
<table-wrap id="table3-0759106311426987" position="float">
<label>Table 3.</label>
<caption>
<p>Average Reliability for Verbal and Graphical Questions Across Groups</p>
</caption>
<graphic alternate-form-of="table3-0759106311426987" xlink:href="10.1177_0759106311426987-table3.tif"/>
<table>
<thead>
<tr>
<th>Group</th>
<th>Verbal</th>
<th>Graphical</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>Eager</td>
<td>.65</td>
<td>.90</td>
<td>.80</td>
</tr>
<tr>
<td>Reluctant</td>
<td>.68</td>
<td>.91</td>
<td>.81</td>
</tr>
<tr>
<td>Total</td>
<td>.66</td>
<td>.90</td>
<td>
</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The same sequence of models was fitted including propensity score adjustment to account for differences between eager and reluctant respondents on age, gender, marital status, education, having a job, and house ownership. The propensity score adjustment was carried out by regressing each of the observed variables on the propensity score, effectively estimating the MTMM model on the residuals of these regressions. After propensity score adjustment, the results were essentially the same as found without propensity score adjustment: scalar equivalence holds, and the error variances are not equal. Thus, the propensity score adjustment results in very small differences, indicating that differences in background characteristics do not explain away the difference in error variances. Reliabilities differed between the eager and reluctant respondents, but not systematically. Again, the graphical question formats showed a much higher reliability than the verbal question formats for both groups.</p>
</sec>
<sec id="section8-0759106311426987">
<title>Discussion</title>
<p>The main outcome from this study is that eager and reluctant respondents differ very little in the quality of their responses to our well-being questions. Overall, the graphical scales are performing very well; both validity and reliability tend to be high for these question formats. Andrews and Withey find similar results; in their analyses, the graphical scales also performed better than the verbal scales, with especially the social comparison question performing very poorly (<xref ref-type="bibr" rid="bibr3-0759106311426987">Andrews and Withey, 1978</xref>: 204), a finding that is also replicated in our analysis.</p>
<p>A positive outcome is that all differences between eager and reluctant respondents reside in the error structure of the MTMM data, and that these differences are not systematic. On average, the reliability of the responses of the eager and the reluctant group do not differ. We did <italic>not</italic> find differences in the measurement model proper, which represents the construct validity. In other words, the same constructs are measured in the same way for both the eager and the reluctant respondents. We may therefore conclude that a second round of data collection brings in more and demographically slightly different respondents, without affecting the quality of the data.</p>
<p>The generally small effect of propensity score adjustment on the results indicates that the existing differences between eager and reluctant respondents in socio-demographic characteristics do not affect the quality of the answers.</p>
<p>We should note that the results are based on a paper-and-pen mail survey. In such a survey, the respondents can view all questions, and page back and forward in the questionnaire at will. Hence, some amount of correlated error based on memory effects can be expected. These correlated errors are not included in the MTMM models, because including correlated errors led to estimation problems (non convergence). Given that the results are very similar between the eager and reluctant respondents, we assume that these effects do not bias our results. When using modern computer-assisted interviewing methods or Internet surveys, it is preferable to present the MTMM questions randomly, or to pose different subsets of questions to different respondents, thereby reducing the redundancy in the question set. We refer to <xref ref-type="bibr" rid="bibr42-0759106311426987">Scherpenzeel and Saris (1997)</xref> for a discussion.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0759106311426987">
<title>Appendix</title>
<p>Five question formats were used: (1) a standard self-report question (direct question), (2) a social comparison question, (3) a graphical ladder scale, (4) a faces (smileys) scale, and (5) a circle scale. Three traits were measured: (1) satisfaction with house, (2) satisfaction with income, and (3) satisfaction with health. An example of each question format is given below for the domain “satisfaction with house”.
<list list-type="order">
<list-item>
<p>Direct Question<list list-type="bullet">
<list-item>
<p>How satisfied or dissatisfied are you with the house you live in?
<list list-type="order">
<list-item>
<p>Very dissatisfied</p>
</list-item>
<list-item>
<p>Dissatisfied</p>
</list-item>
<list-item>
<p>Somewhat dissatisfied</p>
</list-item>
<list-item>
<p>About equally dissatisfies as satisfied</p>
</list-item>
<list-item>
<p>Somewhat satisfied</p>
</list-item>
<list-item>
<p>Satisfied</p>
</list-item>
<list-item>
<p>Very satisfied</p>
</list-item>
</list>
</p>
</list-item>
</list>
</p>
</list-item>
<list-item>
<p>Social Comparison Question<list list-type="bullet">
<list-item>
<p>When you compare yourself to the people around you, would you say that you are more satisfied with the house you live in, about equally satisfied, or less satisfied than most people?
<list list-type="order">
<list-item>
<p>Much less satisfied</p>
</list-item>
<list-item>
<p>Less satisfied</p>
</list-item>
<list-item>
<p>A bit less satisfied</p>
</list-item>
<list-item>
<p>About equally satisfied</p>
</list-item>
<list-item>
<p>A bit more satisfied</p>
</list-item>
<list-item>
<p>More satisfied</p>
</list-item>
<list-item>
<p>Much more satisfied</p>
</list-item>
</list>
</p>
</list-item>
</list>
</p>
</list-item>
<list-item>
<p>Graphical Ladder Question<list list-type="bullet">
<list-item>
<p>Below is a drawing of a ladder. The top of the ladder represents the best that you could reasonably expect in life. The bottom represents the worst that you could expect in life.</p>
</list-item>
<list-item>
<p>If you were asked to use the ladder to illustrate how satisfied you are with the house you live in, where are you on the ladder?<fig id="fig2-0759106311426987" position="float"><graphic xlink:href="10.1177_0759106311426987-fig2.tif"/></fig></p>
</list-item>
</list>
</p>
</list-item>
<list-item>
<p>Graphical Faces Question<list list-type="bullet">
<list-item>
<p>Below are a series of faces that express different feelings. Below each face is a number.</p>
</list-item>
<list-item>
<p>Which face represents the best how satisfied you are with the house you live in?<fig id="fig3-0759106311426987" position="float"><graphic xlink:href="10.1177_0759106311426987-fig3.tif"/></fig></p>
</list-item>
</list>
</p>
</list-item>
<list-item>
<p>Graphical Circles question<list list-type="bullet">
<list-item>
<p>Below are some circles that could represent the lives of different people. Circle 1 has only minuses; this represents persons who have only bad things in their lives. Circle 7 has only pluses; this represents persons who have only good things in their lives. The other circles are in between.</p>
</list-item>
<list-item>
<p>Which circle represents the best how satisfied you are about the house you live in?<fig id="fig4-0759106311426987" position="float"><graphic xlink:href="10.1177_0759106311426987-fig4.tif"/></fig></p>
</list-item>
</list>
</p>
</list-item>
</list>
</p>
</app>
</app-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0759106311426987">
<citation citation-type="web">
<collab collab-type="author">American Association for Public Opinion Research</collab> (<year>2011</year>) <source>Standard Definitions: Final Dispositions of Case Codes and Outcome Rates for Surveys</source>.
<comment>Available at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://www.aapor.org/For_Researchers/4228.htm">http://www.aapor.org/For_Researchers/4228.htm</ext-link>
.</citation>
</ref>
<ref id="bibr2-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Alwin</surname>
<given-names>DF</given-names>
</name>
</person-group> (<year>1974</year>) <article-title>Approaches to the Interpretations of Relationships and the Multitrait-multimethod Matrix</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Costner</surname>
<given-names>HL</given-names>
</name>
</person-group> (ed.) <source>Sociological Methodology 1973-74</source>. <publisher-loc>San Francisco</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>, <fpage>79</fpage>–<lpage>105</lpage>
.</citation>
</ref>
<ref id="bibr3-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Andrews</surname>
<given-names>FM</given-names>
</name>
<name>
<surname>Withey</surname>
<given-names>SB</given-names>
</name>
</person-group> (<year>1978</year>) <source>Social Indicators of Well-being</source>.
<publisher-loc>New York</publisher-loc>: <publisher-name>Plenum</publisher-name>
.</citation>
</ref>
<ref id="bibr4-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Arbucle</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2007</year>) <source>Amos 16 User’s Guide</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>SPSS, Inc</publisher-name>
.</citation>
</ref>
<ref id="bibr5-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Biemer</surname>
<given-names>PP</given-names>
</name>
</person-group> (<year>2001</year>) <article-title> Nonresponse Bias and Measurement Bias in a Comparison of Face to Face and Telephone Interviewing</article-title>. <source>Journal of Official Statistics</source>, <volume>17</volume>(<issue>2</issue>): <fpage>295</fpage>–<lpage>320</lpage>
.</citation>
</ref>
<ref id="bibr6-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Biemer</surname>
<given-names>PP</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Total Survey Error: Design, Implementation, and Evaluation</article-title>. <source>Public Opinion Quarterly</source>, <volume>74</volume>(<issue>5</issue>): <fpage>817</fpage>–<lpage>848</lpage>
.</citation>
</ref>
<ref id="bibr7-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Biemer</surname>
<given-names>PP</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>LE</given-names>
</name>
</person-group> (<year>2003</year>) <source>Introduction to Survey Quality</source>.
<publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr8-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Brehm</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1994</year>) <source>The Phantom Respondent: Opinion Surveys and Political Representation</source>. <publisher-loc>Ann Arbor</publisher-loc>, <publisher-name>University of Michigan Press</publisher-name>
.</citation>
</ref>
<ref id="bibr9-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Campbell</surname>
<given-names>DT</given-names>
</name>
<name>
<surname>Fiske</surname>
<given-names>DW</given-names>
</name>
</person-group> (<year>1959</year>) <article-title> Convergent and Discriminant Validation by the Multimethod-multitrait Matrix</article-title>. <source>Psychological Bulletin</source>, <volume>56</volume>: <fpage>833</fpage>–<lpage>853</lpage>
.</citation>
</ref>
<ref id="bibr10-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cannell</surname>
<given-names>CF</given-names>
</name>
<name>
<surname>Fowler</surname>
<given-names>FJ</given-names>
</name>
</person-group> (<year>1963</year>) <article-title> Comparison of a Self-enumerative Procedure and a Personal Interview: A Validity Study</article-title>. <source>Public Opinion Quarterly</source>, <volume>27</volume>: <fpage>250</fpage>–<lpage>264</lpage>
.</citation>
</ref>
<ref id="bibr11-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chen</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Wei</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Syme</surname>
<given-names>PD</given-names>
</name>
</person-group> (<year>2003</year>) <article-title> Comparison of Early and Delayed Respondents to a Postal Health Survey: A Questionnaire Study of Personality Traits and Neuropsychological Symptoms</article-title>. <source>European Journal of Epidemiology</source>, <volume>18</volume>: <fpage>195</fpage>–<lpage>202</lpage>
.</citation>
</ref>
<ref id="bibr12-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Couper</surname>
<given-names>MP</given-names>
</name>
<name>
<surname>De Leeuw</surname>
<given-names>ED</given-names>
</name>
</person-group> (<year>2003</year>) <article-title> Nonresponse in Cross-cultural and Cross-national Surveys</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Harkness</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Van de Vijver</surname>
<given-names>FJR</given-names>
</name>
<name>
<surname>Mohler</surname>
<given-names>PP</given-names>
</name>
</person-group> (eds). <source>Cross-Cultural Survey Methods</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr13-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>De Leeuw</surname>
<given-names>ED</given-names>
</name>
</person-group> (<year>1999</year>) <article-title> Preface: Special Issue on Survey Nonresponse</article-title>. <source>Journal of Official Statistics</source>, <volume>15</volume>(<issue>2</issue>): <fpage>127</fpage>–<lpage>128</lpage>
.</citation>
</ref>
<ref id="bibr14-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>De Leeuw</surname>
<given-names>ED</given-names>
</name>
<name>
<surname>De Heer</surname>
<given-names>W</given-names>
</name>
</person-group> (<year>2002</year>) <article-title> Trends in Household Survey Nonresponse: A Longitudinal and International Comparison</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>DA</given-names>
</name>
<name>
<surname>Eltinge</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Little</surname>
<given-names>RJA</given-names>
</name>
</person-group> (eds) <source>Survey Nonresponse</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>, <fpage>41</fpage>–<lpage>54</lpage>
.</citation>
</ref>
<ref id="bibr15-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>De Leeuw</surname>
<given-names>ED</given-names>
</name>
<name>
<surname>Hox</surname>
<given-names>JJ</given-names>
</name>
</person-group> (<year>1988</year>) <article-title> Artifacts in Mail Surveys. The Influence of Dillman's Total Design Method on the Quality of the Responses</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Saris</surname>
<given-names>WE</given-names>
</name>
<name>
<surname>Gallhofer</surname>
<given-names>IN</given-names>
</name>
</person-group> (eds) <source>Sociometric Research. Vol. II: Data Analysis</source>,
<publisher-loc>London</publisher-loc>: <publisher-name>MacMillan</publisher-name>, <fpage>61</fpage>–<lpage>73</lpage>
.</citation>
</ref>
<ref id="bibr16-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Dillman</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1978</year>) <source>Mail and Telephone Surveys: The Total Design Method</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr17-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Dillman</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Smyth</surname>
<given-names>JD</given-names>
</name>
<name>
<surname>Christian</surname>
<given-names>LM</given-names>
</name>
</person-group> (<year>2008</year>) <source>Internet, Mail, and Mixed Mode surveys: The Tailored Design Method</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr18-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Eid</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Lischetzke</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Nussbeck</surname>
<given-names>FW</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Structural Equation Models for Multitrait-multimethod Data</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Eid</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Diener</surname>
<given-names>E</given-names>
</name>
</person-group> (eds.), <source>Handbook of Multimethod Measurement in Psychology</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>, <fpage>283</fpage>–<lpage>299</lpage>
.</citation>
</ref>
<ref id="bibr19-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Goyder</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1987</year>) <source>The Silent Minority: Nonrespondents on Sample Surveys</source>. <publisher-loc>Boulder</publisher-loc>: <publisher-name>Westview Press</publisher-name>
.</citation>
</ref>
<ref id="bibr20-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Green</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>1991</year>) <article-title>Reluctant Respondents: Differences between Early, Late, and Nonresponders to a Mail Survey</article-title>. <source>Journal of Experimental Education</source>, <volume>59</volume>(<issue>3</issue>): <fpage>268</fpage>–<lpage>276</lpage>
.</citation>
</ref>
<ref id="bibr21-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R</given-names>
</name>
</person-group> (<year>1989</year>) <source>Survey Errors and Survey Costs</source>, <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr22-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>DA</given-names>
</name>
<name>
<surname>Eltinge</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Little</surname>
<given-names>RJA</given-names>
</name>
</person-group> (<year>2002</year>) <source>Survey Nonresponse</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr23-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Couper</surname>
<given-names>MP</given-names>
</name>
</person-group> (<year>1998</year>) <source>Nonresponse in Household Interview Surveys</source>.
<publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr24-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Peytcheva</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>The Impact of Nonresponse Rates on Nonresponse Bias</article-title>. <source>Public Opinion Quarterly</source>, <volume>72</volume>: <fpage>167</fpage>–<lpage>189</lpage>
.</citation>
</ref>
<ref id="bibr25-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Total Survey Error: Past, Present, and Future</article-title>. <source>Public Opinion Quarterly</source>, <volume>74</volume>(<issue>5</issue>): <fpage>849</fpage>–<lpage>879</lpage>
.</citation>
</ref>
<ref id="bibr26-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hox</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1986</year>) <source>Het Gebruik van Hulptheorieën bij de Operationalisering. Een studie Rondom het Begrip ‘Subjectief Welbevinden’ (Using Auxiliary Theories for Operationalization)</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>University of Amsterdam</publisher-name>
<comment>(unpublished Ph Thesis)</comment>
.</citation>
</ref>
<ref id="bibr27-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hox</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1995</year>) <article-title>Covariance Structure Modeling in Windows:A Multitrait-multimethod Analysis Using Amos, Eqs, and Lisrel</article-title>. <source>Bulletin de Méthodologie Sociologique</source>, <volume>46</volume>: <fpage>71</fpage>–<lpage>87</lpage>
.</citation>
</ref>
<ref id="bibr28-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hox</surname>
<given-names>J</given-names>
</name>
<name>
<surname>De Leeuw</surname>
<given-names>ED</given-names>
</name>
</person-group> (<year>1994</year>) <article-title>A Comparison of Nonresponse in Mail, Telephone, and Face to Face Surveys: Applying Multilevel Modeling to Meta-analysis</article-title>. <source>Quality &amp; Quantity</source>, <volume>28</volume>: <fpage>329</fpage>–<lpage>344</lpage>
.</citation>
</ref>
<ref id="bibr29-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hox</surname>
<given-names>J</given-names>
</name>
<name>
<surname>De Leeuw</surname>
<given-names>ED</given-names>
</name>
<name>
<surname>Vorst</surname>
<given-names>H</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>A Reasoned Action Explanation for Survey Nonresponse</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Laaksonen</surname>
<given-names>S</given-names>
</name>
</person-group> (ed.) <source>International Perspectives on Nonresponse</source>. <publisher-loc>Helsinki</publisher-loc>: <publisher-name>Statistics Finland</publisher-name>, <fpage>101</fpage>–<lpage>110</lpage>
.</citation>
</ref>
<ref id="bibr30-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kaminska</surname>
<given-names>O</given-names>
</name>
<name>
<surname>McCutcheon</surname>
<given-names>AL</given-names>
</name>
<name>
<surname>Billiet</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Satisficing among Reluctant Respondents in a Cross-national Context</article-title>. <source>Public Opinion Quarterly</source>, <volume>74</volume>(<issue>5</issue>): <fpage>956</fpage>–<lpage>984</lpage>
.</citation>
</ref>
<ref id="bibr31-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krosnick</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1991</year>) <article-title>Response Strategies for Coping with the Cognitive Demands of Attitude Measures in Surveys</article-title>. <source>Applied Cognitive Psychology</source>, <source>5</source>: <fpage>213</fpage>–<lpage>236</lpage>
.</citation>
</ref>
<ref id="bibr32-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Morton-Williams</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1993</year>) <source>Interviewer Approaches</source>.
<publisher-loc>Aldershot</publisher-loc>: <publisher-name>Darthmouth</publisher-name>
.</citation>
</ref>
<ref id="bibr33-0759106311426987">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Muller</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Kreuter</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Trappmann</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2009</year>) <source>Nonresponse and Measurement Error in Employment Research</source>.
<conf-name>Paper presented at the International Total Survey Error Workshop</conf-name>, <conf-loc>Tallberg, Sweden</conf-loc>
<comment>2009. Available at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://niss.org/node/703">http://niss.org/node/703</ext-link>, <comment>and also at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://niss.org/content/nonresponse-and-measurement-error-employment-research">http://niss.org/content/nonresponse-and-measurement-error-employment-research</ext-link>
.</citation>
</ref>
<ref id="bibr34-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Olsen</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Survey Participation, Nonresponse Bias, Measurement Error Bias, and Total Bias</article-title>. <source>Public Opinion Quarterly</source>, <volume>70</volume>: <fpage>737</fpage>–<lpage>758</lpage>
.</citation>
</ref>
<ref id="bibr35-0759106311426987">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Olsen</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Kennedy</surname>
<given-names>C</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Examination of the Relationship between Nonresponse and Measurement Error in a Validation Study of Alumni</article-title>. In <source>Proceedings of the Annual Meetings of the American Statistical Association</source>, <comment>Toronto 2006, 4181-88</comment>. <comment>Available at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://www.amstat.org/sections/srms/proceedings/y2006/Files/JSM2006-000229.pdf">http://www.amstat.org/sections/srms/proceedings/y2006/Files/JSM2006-000229.pdf</ext-link>
.</citation>
</ref>
<ref id="bibr36-0759106311426987">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Olsen</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Feng</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Witt</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>When Do Nonresponse Follow-ups Improve or Reduce Data Quality?: A Meta-analysis and Review of the Existing Literature</article-title>. <conf-name>Paper presented at the International Total Survey Error Workshop</conf-name>, <conf-loc>Research Triangle Park, NC</conf-loc>
<comment>June 2008. Available at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://niss.org/event/itsew-2008-multiple-sources-error-and-their-interaction">http://niss.org/event/itsew-2008-multiple-sources-error-and-their-interaction</ext-link>
.</citation>
</ref>
<ref id="bibr37-0759106311426987">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name>
<surname>Petchev</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Petcheva</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Relationship between Measurement Error and Unit Nonresponse in Household Surveys: An Approach in the Absence of Validation Data</article-title>. <conf-name>Paper presented at the International Workshop on Household Survey Nonresponse</conf-name>, <conf-loc>Southampton</conf-loc>, <comment>September 2007</comment>
.</citation>
</ref>
<ref id="bibr38-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Thomas</surname>
<given-names>N</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>Matching Using Estimated Propensity Scores: Relating Theory to Practice</article-title>. <source>Biometrics</source>, <volume>52</volume>: <fpage>254</fpage>–<lpage>268</lpage>
.</citation>
</ref>
<ref id="bibr39-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Saris</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Andrews</surname>
<given-names>FM</given-names>
</name>
</person-group> (<year>1991</year>) <article-title>Evaluation of Measurement Instruments Using a Structural Modelling Approach</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Biemer</surname>
<given-names>PP</given-names>
</name>
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>LE</given-names>
</name>
<name>
<surname>Mathiowetz</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Sudman</surname>
<given-names>S</given-names>
</name>
</person-group> (eds) <source>Measurement Errors in Surveys</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>, <fpage>575</fpage>–<lpage>599</lpage>
.</citation>
</ref>
<ref id="bibr40-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Saris</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Gallhofer</surname>
<given-names>IN</given-names>
</name>
</person-group> (<year>2007</year>) <source>Design, Evaluation, and Analysis of Questionnaires for Survey Research</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>
.</citation>
</ref>
<ref id="bibr41-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Scherpenzeel</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Saris</surname>
<given-names>WE</given-names>
</name>
</person-group> (<year>1993</year>) <article-title>The Evaluation of Measurement Instruments by Meta-analysis of MTMM Studies</article-title>. <source>Bulletin de Méthodologie Sociologique</source>, <volume>39</volume>: <fpage>3</fpage>–<lpage>19</lpage>
.</citation>
</ref>
<ref id="bibr42-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Scherpenzeel</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Saris</surname>
<given-names>WE</given-names>
</name>
</person-group> (<year>1997</year>) <article-title>The Validity and Reliability of Survey Questions: A Meta-analysis of MTMM Studies</article-title>. <source>Sociological Methods and Research</source>, <volume>25</volume>: <fpage>341</fpage>–<lpage>383</lpage>
.</citation>
</ref>
<ref id="bibr43-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Singer</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Special Issue: Nonresponse Bias in Household Surveys</article-title>. <source>Public Opinion Quarterly</source>, <volume>70</volume>: <fpage>5</fpage>
.</citation>
</ref>
<ref id="bibr44-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Stoop</surname>
<given-names>IAL</given-names>
</name>
</person-group> (<year>2005</year>). <source>Nonresponse in Sample Surveys: The Hunt for the Last Respondent</source>.
<publisher-loc>The Hague</publisher-loc>: <publisher-name>Social and Cultural Planning office</publisher-name>
.</citation>
</ref>
<ref id="bibr45-0759106311426987">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Tourangeau</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Presser</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Toppe</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Kennedy</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Yan</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>2008</year>) <source>Experiments Exploring the Relationship (or Lack Thereof) Between Nonresponse Error and Measurement Error</source>. <conf-name>Paper presented at the International Total Survey Error Workshop</conf-name>, <conf-loc>Research Triangle Park, NC</conf-loc>
<comment>June 2008. Available at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://niss.org/event/itsew-2008-multiple-sources-error-and-their-interaction">http://niss.org/event/itsew-2008-multiple-sources-error-and-their-interaction</ext-link>
.</citation>
</ref>
<ref id="bibr46-0759106311426987">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Trewin</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>G</given-names>
</name>
</person-group> (<year>1988</year>) <article-title>International Comparison of Telephone Coverage</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Biemer</surname>
<given-names>PP</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>LE</given-names>
</name>
<name>
<surname>Massey</surname>
<given-names>JT</given-names>
</name>
<name>
<surname>Nicholls</surname>
<given-names>WL</given-names>
</name>
<name>
<surname>Waksberg</surname>
<given-names>J</given-names>
</name>
</person-group> (eds) <source>Telephone Survey Methodology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>, <fpage>9</fpage>–<lpage>24</lpage>
.</citation>
</ref>
<ref id="bibr47-0759106311426987">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vandenberg</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Lance</surname>
<given-names>CE</given-names>
</name>
</person-group> (<year>2000</year>) <article-title>A Review and Synthesis of the Measurement Invariance Literature: Suggestions, Practices, and Recommendations for Organizational Research</article-title>. <source>Organizational Research Methods</source>
<volume>2</volume>: <fpage>4</fpage>–<lpage>69</lpage>
.</citation>
</ref>
<ref id="bibr48-0759106311426987">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Yan</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Tourangeau</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Arens</surname>
<given-names>Z</given-names>
</name>
</person-group> (<year>2004</year>) <article-title>When Less is More: Are Reluctant Respondents Poor Reporters?</article-title> In <source>Proceedings of the Annual Meetings of the American Statistical Association</source>, <comment>Toronto. 2004, 4632-4651. Available at:</comment>
<ext-link ext-link-type="uri" xlink:href="http://www.amstat.org/sections/srms/proceedings/y2004/Files/Jsm2004-000169.pdf">http://www.amstat.org/sections/srms/proceedings/y2004/Files/Jsm2004-000169.pdf</ext-link>
.</citation>
</ref>
</ref-list>
</back>
</article>