<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JVC</journal-id>
<journal-id journal-id-type="hwp">spjvc</journal-id>
<journal-title>Journal of Vibration and Control</journal-title>
<issn pub-type="ppub">1077-5463</issn>
<issn pub-type="epub">1741-2986</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1077546310371349</article-id>
<article-id pub-id-type="publisher-id">10.1177_1077546310371349</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The development of autonomous low-cost biped mobile surveillance robot by intelligent bricks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Chen</surname><given-names>Chen-Yuan</given-names></name>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Shih</surname><given-names>Bih-Yaw</given-names></name>
<xref ref-type="corresp" rid="corresp1-1077546310371349"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Shih</surname><given-names>Chia-Hung</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Chou</surname><given-names>Wei-Chung</given-names></name>
</contrib>
</contrib-group>
<aff id="aff1-1077546310371349">Department of Computer Science, National Pingtung University of Education, Pingtung, Taiwan, Republic of China</aff>
<author-notes>
<corresp id="corresp1-1077546310371349">Bih-Yaw Shih, Department of Computer Science, National Pingtung University of Education No. 4–18, Ming Shen Rd., Pingtung 90003, Taiwan, Republic of China Email: <email>byshih@mail.npue.edu.tw</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2012</year>
</pub-date>
<volume>18</volume>
<issue>5</issue>
<fpage>577</fpage>
<lpage>586</lpage>
<history>
<date date-type="received"><day>28</day><month>3</month><year>2010</year></date>
<date date-type="accepted"><day>8</day><month>4</month><year>2010</year></date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2011 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>An intelligent surveillance robot is required in many military and civilian activities, such as enemy attacks in a city environment and civilian rescue missions. These special applications require a kind of low-cost biped mobile robot that can function covertly in highly confined environments. However, biped robots necessitate high costs. In the past, biped robots have been hard to build and very expensive. The current study provides a contribution describing the mechanical construction of a low-cost bipedal mechanism, as well as the path record system of a biped surveillance robot for indoor reconnaissance tasks. Our experiments show that proposed autonomous biped robot is both reliable and can meet the goal of low cost construction.</p>
</abstract>
<kwd-group>
<kwd>Biped mobile robot</kwd>
<kwd>intelligence robot</kwd>
<kwd>low cost building mechanism</kwd>
<kwd>path record system</kwd>
<kwd>surveillance robot</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="sec1-1077546310371349"><title>1. Introduction</title>
<p>Reconnaissance and surveillance are crucial activities for both military and civilian organizations. Detection in crucial hot spots, hostage and survivor rescue, illicit drug raids and responses to nuclear or chemical or toxic waste contamination are situations demanding reconnaissance. These special tasks require a kind of robot that could move about in the region and record the necessary information. Biped robots are usually ideal for these situations as it is easier for them to move about in spatially-confined areas and evade detection than other kinds of robots (<xref ref-type="bibr" rid="bibr5-1077546310371349">Drenner et al., 2002</xref>, <xref ref-type="bibr" rid="bibr6-1077546310371349">2004</xref>; <xref ref-type="bibr" rid="bibr14-1077546310371349">Stoeter et al., 2002</xref>; <xref ref-type="bibr" rid="bibr11-1077546310371349">Kratochvil et al., 2003</xref>).</p>
<p>A mobile biped robot can provide short-range remote eyes and ears for urban surveillance. Their mobility allows them to be transported easily and deployed extensively (<xref ref-type="bibr" rid="bibr1-1077546310371349">Arkin, 1991</xref>; <xref ref-type="bibr" rid="bibr4-1077546310371349">Chemel et al., 1999</xref>; <xref ref-type="bibr" rid="bibr7-1077546310371349">Grabowski and Khosla, 2001</xref>; <xref ref-type="bibr" rid="bibr12-1077546310371349">Kratochvil, 2003</xref>; <xref ref-type="bibr" rid="bibr2-1077546310371349">Burion, 2004</xref>). Also, mobile robots can allow for flexible deployment, such as by being placed in advance, being deployed by human beings or even by larger robots (<xref ref-type="bibr" rid="bibr3-1077546310371349">Burt et al., 2006</xref>; <xref ref-type="bibr" rid="bibr16-1077546310371349">Zheng et al., 2007</xref>; <xref ref-type="bibr" rid="bibr17-1077546310371349">Zheng, 2009</xref>). In addition, the low cost of mobile robots means that large quantities can be used in one operation. Individual robots could be expendable without influencing the overall mission. The mobility of biped robots makes them adaptable to changing environments.</p>
<p>However, the small size of bipedal robots creates great challenges. The crucial problem resulting from the small size is difficulty of locomotion (<xref ref-type="bibr" rid="bibr15-1077546310371349">Sugahara et al., 2003</xref>; <xref ref-type="bibr" rid="bibr10-1077546310371349">Kim and Oh, 2004</xref>; <xref ref-type="bibr" rid="bibr8-1077546310371349">Hashimoto et al., 2006</xref>) and how to package sensing, computing and power subsystems into a limited space. In our design, we reasonably utilize the tightly-constrained space, make efficient use of batteries and choose components carefully ensuring that individual parts are small enough, and that we limit power consumption. The small volume of biped robots limits the available space for on-board computation, communication and sensing resources.</p>
<p>In order to accomplish indoor secret surveillance tasks effectively, there are several design requirements to be met. The robot must be as mobile as possible, so as to function in confined spots and permit easy deployment. Moreover, the robot must be able to survey the surroundings and record key details about surveillance spots by sensor data.</p>
<p>In this study, we present a kind of low-cost biped mobile surveillance robot—ARSR. The mechanical design is discussed in <xref ref-type="sec" rid="sec2-1077546310371349">Section 2</xref>, system implementation is discussed in <xref ref-type="sec" rid="sec3-1077546310371349">Section 3</xref>, experiments and results are discussed in <xref ref-type="sec" rid="sec6-1077546310371349">Section 4</xref>. Finally, we make some conclusions in <xref ref-type="sec" rid="sec7-1077546310371349">Section 5</xref>.</p>
</sec>
<sec id="sec2-1077546310371349"><title>2. Mechanical design</title>
<p>Each standard locomotion choice has its advantages and disadvantages. However, in order to meet the goal of being low cost (<xref ref-type="bibr" rid="bibr9-1077546310371349">Hirai et al., 1998</xref>; <xref ref-type="bibr" rid="bibr13-1077546310371349">Park et al., 2005</xref>), the framework of the biped ARSR robot is built using Lego Mindstorms NXT Alpha Rex Model (<xref ref-type="fig" rid="fig1-1077546310371349">Figure 1</xref>). The ARSR is built with Lego NXT Intelligent Bricks as the brain of the device. It also equipped with three Servo Motors (<xref ref-type="fig" rid="fig2-1077546310371349">Figure 2</xref>) and an Ultrasonic Sensor (<xref ref-type="fig" rid="fig3-1077546310371349">Figure 3</xref>). Two Servo Motors are used for locomotion (<xref ref-type="fig" rid="fig4-1077546310371349">Figure 4</xref>), one is used to rotate the Ultrasonic Sensor to acquire the environment information.
<fig id="fig1-1077546310371349" position="float"><label>Figure 1.</label><caption><p>NXT Alpha Rex.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig1.tif"/></fig>
<fig id="fig2-1077546310371349" position="float"><label>Figure 2.</label><caption><p>Servo Motor.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig2.tif"/></fig>
<fig id="fig3-1077546310371349" position="float"><label>Figure 3.</label><caption><p>Ultrasonic Sensor.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig3.tif"/></fig>
<fig id="fig4-1077546310371349" position="float"><label>Figure 4.</label><caption><p>Servo Motors for locomotion.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig4.tif"/></fig></p>
<p>The Intelligent Brick controls the Ultrasonic Sensor and three Servo Motors. The Brick sends commands to the two Servo Motors, for walking control and turning direction controls. It also receives information from the Ultrasonic Sensor to make decisions about the ARSR’s movement: forward, making turns and stopping. The Intelligent Brick records environmental information, such as counting forward steps and keeping track of turning direction while the ARSR is in movement. The information is recorded in two txt format files. These two txt documents’ data are used to support the surveillance function and draw routes.</p>
</sec>
<sec id="sec3-1077546310371349"><title>3. System implementation</title>
<p>To implement the biped robot’s surveillance function, we use LEGO MINDSTORMS Education NXT Software also called NXT-G to develop the ARSR’s action control ability. The interface of the software is shown in <xref ref-type="fig" rid="fig5-1077546310371349">Figure 5</xref>.
<fig id="fig5-1077546310371349" position="float"><label>Figure 5.</label><caption><p>The interface of NXT-G software.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig5.tif"/></fig></p>
<p>The surveillance program serves as the central controlling unit commanding the two Servo Motors through the Intelligent Brick. The flow chart of the surveillance algorithm is shown in <xref ref-type="fig" rid="fig6-1077546310371349">Figure 6</xref>. The surveillance program instructs the Intelligent Brick when the robot moves, executes a turn (<xref ref-type="fig" rid="fig7-1077546310371349">Figure 7</xref>) or stops (<xref ref-type="fig" rid="fig8-1077546310371349">Figure 8</xref>). This program makes decisions based on input from the Ultrasonic Sensor.
<fig id="fig6-1077546310371349" position="float"><label>Figure 6.</label><caption><p>The flow chart of the surveillance algorithm.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig6.tif"/></fig>
<fig id="fig7-1077546310371349" position="float"><label>Figure 7.</label><caption><p>Forward control program.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig7.tif"/></fig>
<fig id="fig8-1077546310371349" position="float"><label>Figure 8.</label><caption><p>Turning control program.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig8.tif"/></fig></p>
<sec id="sec4-1077546310371349"><title>3.1. Forward control and step record</title>
<p>When the program begins executing, the ARSR will continue forward until it moves too close to an obstacle. When the ARSR meets an obstacle, it stops and records how many steps it has walked. Then the program writes the value in a txt format file named forwards (<xref ref-type="fig" rid="fig9-1077546310371349">Figure 9</xref>).
<fig id="fig9-1077546310371349" position="float"><label>Figure 9.</label><caption><p>Recording forward steps.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig9.tif"/></fig></p>
</sec>
<sec id="sec5-1077546310371349"><title>3.2. Making turn and recording direction</title>
<p>After the step value is recorded, the program controls another Servo Motor to rotate the Ultrasonic Sensor. The Servo Motor rotates the Ultrasonic Sensor from center to left, reads the left side’s distance, then saves the value as a variable named LeftRead. The Servo Motor then rotates the Ultrasonic Sensor from left to center. When the Ultrasonic Sensor returns to the center, the Servo Motor rotates it from center to right, reads the right side’s distance, then saves the value as a variable named RightRead.</p>
<p>The Servo Motor then rotates the Ultrasonic Sensor from right to center (<xref ref-type="fig" rid="fig10-1077546310371349">Figure 10</xref>).
<fig id="fig10-1077546310371349" position="float"><label>Figure 10.</label><caption><p>Reading left side and right side distance.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig10.tif"/></fig></p>
<p>When the two variables are acquired, the program will make an if-else decision.</p>
<p>When the LeftRead variable is greater than the RightRead variable, then program directs the ARSR to make a left turn and writes the value 1 in a txt format file named turns. If the RightRead variable is greater than the LeftRead variable, then the program directs the ARSR to make a right turn and writes the value 2 in the same txt format file, the turns.txt file (<xref ref-type="fig" rid="fig11-1077546310371349">Figures 11</xref> and <xref ref-type="fig" rid="fig12-1077546310371349">12</xref>). If the LeftRead variable and RightRead variable are equal to each other or too little, it means the distance of both sides to the ARSR are the same or too close. The program will direct the ARSR to make a right turn and write the value 2 in the turns.txt file. After the process of turning, the ARSR will again move forward until it moves too close to an obstacle, when the turning decision is again made. The program will continue doing these processes after the surveillance task is done. Information about the steps walked and turning directions are acquired. This data will be used in the experiments described in next section.
<fig id="fig11-1077546310371349" position="float"><label>Figure 11.</label><caption><p>Determine turning direction.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig11.tif"/></fig>
<fig id="fig12-1077546310371349" position="float"><label>Figure 12.</label><caption><p>Record turning directions.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig12.tif"/></fig></p>
</sec>
</sec>
<sec id="sec6-1077546310371349"><title>4. Experiment results</title>
<p>In order to verify the feasibility of the ARSR described in this article, we conducted a field test. The experimental environment was a closed area in our laboratory building. The experimental processes are shown in <xref ref-type="fig" rid="fig13-1077546310371349">Figure 13</xref>. This figure shows the ARSR’s actual performance. Information of forward steps and turning directions during the field test was recorded. This data was used draw a map using the MATLAB® application.
<fig id="fig13-1077546310371349" position="float"><label>Figure 13.</label><caption><p>ARSR surveillance experiment.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig13.tif"/></fig></p>
<p>All information about the number of forward steps and turning directions was input into the map drawing program. The program uses two matrixes to store forward steps and turning directions. The surveillance information map is plotted using trigonometric functions. If we know the present coordinates x<sub>i</sub> and y<sub>i</sub>, then the next coordinates can be described as x<sub>i+1</sub> = x<sub>i</sub> + a<sub>i+1</sub>*cos(θ) and y<sub>i+1</sub> = y<sub>i</sub> + a<sub>i+1</sub>*sin(θ). When the ARSR made a right-angle left turn, the program would add pi/2 to θ. On the other hand, when the ARSR make a right-angle right turn, the program would subtract pi/2 from θ. The partial program codes are shown in <xref ref-type="fig" rid="fig14-1077546310371349">Figure 14</xref>. After the completing the above computing process, the program plots the whole surveillance information map (see <xref ref-type="fig" rid="fig15-1077546310371349">Figure 15</xref>).
<fig id="fig14-1077546310371349" position="float"><label>Figure 14.</label><caption><p>Partial program code.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig14.tif"/></fig>
<fig id="fig15-1077546310371349" position="float"><label>Figure 15.</label><caption><p>Surveillance information map.</p></caption><graphic xlink:href="10.1177_1077546310371349-fig15.tif"/></fig></p>
<p>When the experiment begins, the ARSR starts forward locomotion until it meets an obstacle. After the ARSR stops, the Servo Motor rotates the Ultrasonic Sensor to acquire the left and right side distance. Since the right side distance is longer than the left side distance, the ARSR makes a right-angle right turn to avoid the obstacle. Then the ARSR starts forward locomotion. Because the experimental environment is a square area, the ARSR’s path should show the form of a square. A comparison of <xref ref-type="fig" rid="fig13-1077546310371349">Figure 13</xref> and <xref ref-type="fig" rid="fig15-1077546310371349">Figure 15</xref>, confirms that the ARSR achieved the purpose of its design as a low-cost bipedal mobile surveillance robot.</p>
</sec>
<sec id="sec7-1077546310371349"><title>5. Conclusions</title>
<p>In this paper a low-cost mobile surveillance biped robot is described. The ARSR has been specifically designed to operate in indoor areas. The ARSR is able to move around the indoor environment and to record surveillance information. The hardware used to build the ARSR is inexpensive and easy to obtain. Using Lego Mindstorms NXT Alpha Rex Model, the ARSR structure allows users to add more sensors when additional surveillance functions are required.</p>
<p>Several experiments of indoor sequences have demonstrated that the proposed ARSR performs a robust detection of the surveillance information. To achieve the goal of a low-cost biped surveillance robot, the MATLAB program is used to draw maps of the environment. The experimental result shows the good performance of the map drawing. Although the results appear promising, the ARSR has some limits. In particular, the environment does not guarantee optimal performance, especially when an obstacle may interfere with the ultrasonic sensor’s detection ability. Moreover, the slippery floor also interferes with the ARSR’s walking. When the floor is slippery, the ARSR may not walk in a straight line.</p>
<p>There remains a lot of work to be completed. To do instant surveillance tasks, the ARSR needs real time map drawing ability. Hence, future work could be done using wireless data transmission devices to give the ARSR the ability to do real time surveillance and map drawing tasks.</p>
</sec>
</body>
<back><ack>
<title>Acknowledgements</title>
<p>The authors are most grateful for the kind assistance of Professor Ali Nayfeh, Editor of JVC, and for the constructive suggestions from the anonymous reviewers, all of which has led to the making of several corrections and have greatly aided us to improve the presentation of this paper.</p>
</ack>
<sec id="sec8-1077546310371349"><title>Funding</title>
<p>The authors are appreciative of the financial support in the form of research grants to Dr. Chen-Yuan Chen from the National Science Council, Republic of China under Grant Nos. NSC 98-2221-E-153-004 and NSC 99-2628-E-153-001MY2.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="bibr1-1077546310371349"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Arkin</surname><given-names>RC</given-names></name></person-group> (<year>1991</year>) <article-title>Reactive control as a substrate for telerobotic systems</article-title>. <source>IEEE Aerospace and Electronic Systems Magazine</source> <volume>6</volume>: <fpage>24</fpage>–<lpage>31</lpage>.</citation></ref>
<ref id="bibr2-1077546310371349"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Burion</surname><given-names>S</given-names></name></person-group>, <year>2004</year>, <article-title>“Human detection for robotic urban search and rescue,” Diploma work</article-title>, <publisher-name>Carnegie Mellon University</publisher-name>.</citation></ref>
<ref id="bibr3-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>I</given-names></name><name><surname>Drenner</surname><given-names>A</given-names></name><name><surname>Carlson</surname><given-names>C</given-names></name><name><surname>Kottas</surname><given-names>AD</given-names></name><name><surname>Papanikolopoulos</surname><given-names>N</given-names></name></person-group> (<year>2006</year>) <article-title>Impact orientation invariant robot design: an approach to projectile deployed robotic platforms</article-title>. In <source>Proceedings of IEEE International Conference on Robotics and Automation</source> <conf-loc>Orlando, FL</conf-loc>, <comment>May 15–19</comment>, pp. <fpage>2298</fpage>–<lpage>2303</lpage>.</citation></ref>
<ref id="bibr4-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Chemel</surname><given-names>B</given-names></name><name><surname>Mutschler</surname><given-names>E</given-names></name><name><surname>Schempf</surname><given-names>H</given-names></name></person-group> (<year>1999</year>) <article-title>Cyclops: miniature robotic reconnaissance system</article-title>. In <source>Proceedings of IEEE International Conference on Robotics and Automation</source> <conf-loc>Detroit, MI</conf-loc>, <comment>May 10–15</comment>, pp. <fpage>2298</fpage>–<lpage>2303</lpage>.</citation></ref>
<ref id="bibr5-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Drenner</surname><given-names>A</given-names></name><name><surname>Burt</surname><given-names>I</given-names></name><name><surname>Kratochvil</surname><given-names>B</given-names></name><name><surname>Nelson</surname><given-names>BJ</given-names></name><name><surname>Papanikolopoulos</surname><given-names>N</given-names></name><name><surname>Yesom</surname><given-names>KB</given-names></name></person-group> (<year>2002</year>) <article-title>Communication and mobility enhancements to the scout robot</article-title>. In <source>Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems</source> <conf-loc>Lausanne, Switzerland</conf-loc>, <comment>Sept. 30–Oct. 4</comment>, pp. <fpage>865</fpage>–<lpage>870</lpage>.</citation></ref>
<ref id="bibr6-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Drenner</surname><given-names>A</given-names></name><name><surname>LaPoint</surname><given-names>MA</given-names></name><name><surname>Burt</surname><given-names>I</given-names></name><name><surname>Cannon</surname><given-names>K</given-names></name><name><surname>Hays</surname><given-names>C</given-names></name><name><surname>Kottas</surname><given-names>AD</given-names></name><etal/></person-group> (<year>2004</year>) <article-title>Increasing the scout’s effectiveness through local sensing and ruggedization</article-title>. In <source>Proceedings of IEEE International Conference on Robotics and Automation</source> <conf-loc>New Orleans, LA</conf-loc>, <comment>April 26–May 1</comment>, pp. <fpage>1406</fpage>–<lpage>1411</lpage>.</citation></ref>
<ref id="bibr7-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Grabowski</surname><given-names>R</given-names></name><name><surname>Khosla</surname><given-names>P</given-names></name></person-group> (<year>2001</year>) <article-title>Localization technique for a team of small robots</article-title>. In <source>Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems</source> <conf-loc>Maui, HI</conf-loc>, <comment>Oct. 29–Nov. 6</comment>, pp. <fpage>1067</fpage>–<lpage>1072</lpage>.</citation></ref>
<ref id="bibr8-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Hashimoto</surname><given-names>K</given-names></name><name><surname>Sugahara</surname><given-names>Y</given-names></name><name><surname>Lim</surname><given-names>HO</given-names></name><name><surname>Takanishi</surname><given-names>A</given-names></name></person-group> (<year>2006</year>) <article-title>Realization of stable walking on public road with new biped foot system adaptable to uneven terrain</article-title>. In <source>Proceedings of IEEE/RAS-EMBS International Conference on Biomedical Robotics and Biomechatronics, <italic>Pisa, Italy</italic></source> <comment>Feb. 20–22</comment>, pp. <fpage>20</fpage>–<lpage>22</lpage>.</citation></ref>
<ref id="bibr9-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Hirai</surname><given-names>K</given-names></name><name><surname>Hirose</surname><given-names>M</given-names></name><name><surname>Takenaka</surname><given-names>T</given-names></name></person-group> (<year>1998</year>) <article-title>The development of Honda humanoid robot</article-title>. In <source>Proceedings of IEEE International Conference on Robotics and Automation</source> <conf-loc>Leuven, Belgium</conf-loc>, <comment>May 16–20</comment>, pp. <fpage>16</fpage>–<lpage>20</lpage>.</citation></ref>
<ref id="bibr10-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JH</given-names></name><name><surname>Oh</surname><given-names>JH</given-names></name></person-group> (<year>2004</year>) <article-title>Walking control of the humanoid platform KHR-1 based on torque feedback control</article-title>. In <source>Proceedings of IEEE International Conference on Robotics and Automation</source> <conf-loc>New Orleans, LA</conf-loc>, <comment>April 26–May 1</comment>, pp. <fpage>623</fpage>–<lpage>628</lpage>.</citation></ref>
<ref id="bibr11-1077546310371349"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Kratochvil</surname><given-names>B</given-names></name></person-group> (<year>2003</year>) <article-title>Implementation of scout behaviors using analog sensing methods</article-title>, <source>University of Minnesota, Computer Science Department, Technical Report</source>, pp. <fpage>3</fpage>–<lpage>44</lpage>.</citation></ref>
<ref id="bibr12-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Kratochvil</surname><given-names>BE</given-names></name><name><surname>Burt</surname><given-names>IT</given-names></name><name><surname>Drenner</surname><given-names>A</given-names></name><name><surname>Goerke</surname><given-names>D</given-names></name><name><surname>Jackson</surname><given-names>B</given-names></name><name><surname>McMillen</surname><given-names>C</given-names></name><etal/></person-group> (<year>2003</year>) <article-title>Heterogeneous implementation of an adaptive robotic sensing team</article-title>. In <source>Proceedings of IEEE International Conference on Robotics and Automation</source> <conf-loc>Taipei, Taiwan</conf-loc>, <comment>Sept. 14–19</comment>, pp. <fpage>4264</fpage>–<lpage>4269</lpage>.</citation></ref>
<ref id="bibr13-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Park</surname><given-names>IW</given-names></name><name><surname>Kim</surname><given-names>JY</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Oh</surname><given-names>JH</given-names></name></person-group> (<year>2005</year>) <article-title>Mechanical design of humanoid robot platform KHR-3(KAIST Humanoid Robot-3:HUBO)</article-title>. In <source>Proceedings of IEEE/RAS International Conference on Humanoid Robots</source> <conf-loc>Tsukuba, Japan</conf-loc>, <comment>Dec. 5–7</comment>, pp. <fpage>321</fpage>–<lpage>326</lpage>.</citation></ref>
<ref id="bibr14-1077546310371349"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Stoeter</surname><given-names>SA</given-names></name><name><surname>Rybski</surname><given-names>PE</given-names></name><name><surname>Stubbs</surname><given-names>KN</given-names></name><name><surname>McMillen</surname><given-names>CP</given-names></name><name><surname>Gini</surname><given-names>M</given-names></name><name><surname>Hougen</surname><given-names>DF</given-names></name><etal/></person-group> (<year>2002</year>) <article-title>A robot team for surveillance tasks: design and architecture</article-title>. <source>Robotics and Autonomous Systems, Elsevier</source> <volume>40</volume>: <fpage>173</fpage>–<lpage>183</lpage>.</citation></ref>
<ref id="bibr15-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Sugahara</surname><given-names>Y</given-names></name><name><surname>Hosobata</surname><given-names>T</given-names></name><name><surname>Mikuriya</surname><given-names>Y</given-names></name><name><surname>Lim</surname><given-names>HO</given-names></name><name><surname>Takanishi</surname><given-names>A</given-names></name></person-group> (<year>2003</year>) <article-title>Realization of stable dynamic walking by a parallel bipedal locomotor on uneven terrain using a virtual compliance control</article-title>. In <source>Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems</source> <conf-loc>Las Vegas, NV</conf-loc>, <comment>Oct. 27–31</comment>, pp. <fpage>595</fpage>–<lpage>600</lpage>.</citation></ref>
<ref id="bibr16-1077546310371349"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Sang</surname><given-names>W</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name></person-group> (<year>2007</year>) <article-title>Mechanical design and control system of a miniature autonomous surveillance robot</article-title>. In <source>Proceedings of IEEE International Conference on Mechatronics and Automation</source> <conf-loc>Harbin, China</conf-loc>, <comment>Aug. 5–9</comment>, pp. <fpage>1752</fpage>–<lpage>1757</lpage>.</citation></ref>
<ref id="bibr17-1077546310371349"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>C</given-names></name></person-group> (<year>2009</year>) <article-title>Implementation of Reactive Control for a Miniature Surveillance Robot</article-title>. In <source>Proceedings of International Conference on Information Technology and Computer Science, <italic>Kiev</italic> Ukraine</source>, <volume>vol. 2</volume>, pp. <fpage>510</fpage>–<lpage>513</lpage>.</citation></ref>
</ref-list>
</back>
</article>