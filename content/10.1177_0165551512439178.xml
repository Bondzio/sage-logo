<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JIS</journal-id>
<journal-id journal-id-type="hwp">spjis</journal-id>
<journal-title>Journal of Information Science</journal-title>
<issn pub-type="ppub">0165-5515</issn>
<issn pub-type="epub">1741-6485</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0165551512439178</article-id>
<article-id pub-id-type="publisher-id">10.1177_0165551512439178</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Methods for evaluating information sources: An annotated catalogue</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Hjørland</surname><given-names>Birger</given-names></name>
</contrib>
<aff id="aff1-0165551512439178">Royal School of Library and Information Science, Denmark</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0165551512439178">Birger Hjørland, Royal School of Library and Information Science, 6 Birketinget, DK-2300 Copenhagen S, Denmark. Email: <email>bh@iva.dk</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>6</month>
<year>2012</year>
</pub-date>
<volume>38</volume>
<issue>3</issue>
<fpage>258</fpage>
<lpage>268</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Chartered Institute of Library and Information Professionals</copyright-holder>
</permissions>
<abstract>
<p>The article briefly presents and discusses 12 different approaches to the evaluation of information sources (for example a Wikipedia entry or a journal article): (1) the checklist approach; (2) classical peer review; (3) modified peer review; (4) evaluation based on examining the coverage of controversial views; (5) evidence-based evaluation; (6) comparative studies; (7) author credentials; (8) publisher reputation; (9) journal impact factor; (10) sponsoring: tracing the influence of economic, political, and ideological interests; (11) book reviews and book reviewing; and (12) broader criteria. Reading a text is often not a simple process. All the methods discussed here are steps on the way on learning how to read, understand, and criticize texts. According to hermeneutics it involves the subjectivity of the reader, and that subjectivity is influenced, more or less, by different theoretical perspectives. Good, scholarly reading is to be aware of different perspectives, and to situate oneself among them.</p>
</abstract>
<kwd-group>
<kwd>critical research assessment</kwd>
<kwd>evaluation of information sources</kwd>
<kwd>source criticism</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0165551512439178" sec-type="intro">
<title>1. Introduction</title>
<p>Evaluation of information sources (or ‘critical research assessment’ or ‘source criticism’) is becoming a focus in library and information science (LIS), because users have easy access to overwhelming amounts of documents. From being relatively scarce, ‘information’ is becoming abundant. In schools of LIS, courses in ‘information competency’ and ‘source criticism’ are becoming common, and much research on evaluating Wikipedia and other kinds of information source is also being carried out, as well as more general research about conceptualizations and methodologies in these fields.</p>
<p>The focus of evaluation in this context is on whether or not a given source is reliable for use in a scholarly argument. Information specialists should consider themselves as a kind of consumer adviser, who provides guidance to users of information sources (the users being mainly students). In this connection it is important to consider ‘the ‘functional view of information sources’, which states that a source is not in itself good or bad, but just more or less fruitful or relevant in relation to a given question.</p>
<p>Research and practice related to the evaluation of information sources are not independent of general approaches or ‘paradigms’ in LIS. In other articles I have argued that LIS should be based on a social, epistemological approach rather than on an individual, cognitive view. The present article is first of all inspired by Marc Meola’s criticism [<xref ref-type="bibr" rid="bibr1-0165551512439178">1</xref>] that the popular checklist approach is based on a ‘mechanistic way of evaluating that is at odds with critical thinking’, and his attempt to provide alternative ways of evaluation. Second, the present paper is inspired by Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>], who based their evaluation very much on real-life examples from the scholarly literature, and like myself are much concerned with ‘paradigm theory’.</p>
<p>In the following, 12 different approaches to evaluating information sources are presented and discussed, together with the core literature and criticism of each approach. It is not an in-depth treatment of each approach but – as stated in the subtitle – an annotated catalogue of different approaches meant to serve students as well as teachers and researchers in this field. A similar overview has not been published before, and the different approaches are mostly used without considering each other.</p>
</sec>
<sec id="section2-0165551512439178">
<title>2. The checklist approach</title>
<p>In this approach a list of relevant points to be examined is constructed. They often include issues such as authority, accuracy, objectivity, currency, and coverage of a document. The points may or may not be ranked. The list is then applied to a given information source to be evaluated.</p>
<p>Examples from the literature include Beck [<xref ref-type="bibr" rid="bibr3-0165551512439178">3</xref>], Cooke [<xref ref-type="bibr" rid="bibr4-0165551512439178">4</xref>], and Skov [<xref ref-type="bibr" rid="bibr5-0165551512439178">5</xref>] (the last one is in Danish). Skov’s list was translated into English in [<xref ref-type="bibr" rid="bibr6-0165551512439178">6</xref>]. (See <xref ref-type="table" rid="table1-0165551512439178">Table 1</xref>.)</p>
<table-wrap id="table1-0165551512439178" position="float">
<label>Table 1.</label>
<caption><p>Checklist for evaluating a web resource</p></caption>
<graphic alternate-form-of="table1-0165551512439178" xlink:href="10.1177_0165551512439178-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<tbody>
<tr>
<td>• Fitness for purpose</td>
<td>• Updating</td>
</tr>
<tr>
<td> – Does the source contain information about the purpose and target group?</td>
<td> – Are updating and maintenance done regularly?</td>
</tr>
<tr>
<td> – Does the page fulfil its purpose?</td>
<td> – Are dates of construction and updating provided?</td>
</tr>
<tr>
<td/>
<td> – Does the source contain a news section?</td>
</tr>
<tr>
<td/>
<td> – Does the source contain dead links?</td>
</tr>
<tr>
<td>• Authority/trustworthiness</td>
<td>• Navigation</td>
</tr>
<tr>
<td> – Is it possible to identify the author/originator?</td>
<td> – Are there clear logical structures and good order?</td>
</tr>
<tr>
<td> – What are the qualifications of the originator?</td>
<td> – Is it easy to navigate between sections?</td>
</tr>
<tr>
<td> – What is the publishing institution/organization?</td>
<td> – Is there a table of contents or a site map?</td>
</tr>
<tr>
<td> – Is there a contact address?</td>
<td> – Are there buttons for up, down, and home?</td>
</tr>
<tr>
<td> – Does the source contain opinions or facts?</td>
<td> – Is there a standardized, recognizable design?</td>
</tr>
<tr>
<td> – Does the source contain special pleading?</td>
<td> – Is there an internal search engine?</td>
</tr>
<tr>
<td> – Is there advertising? Is any sponsor named?</td>
<td/>
</tr>
<tr>
<td> – Are there references to sources or to literature?</td>
<td/>
</tr>
<tr>
<td> – How is the quality control maintained?</td>
<td/>
</tr>
<tr>
<td>• Content</td>
<td>• Design/style</td>
</tr>
<tr>
<td> – Does the source contain unique information?</td>
<td> – Are there relevant graphics?</td>
</tr>
<tr>
<td> – What is the coverage like (depth and comprehensiveness)?</td>
<td> – What are the readability and the legibility of the text like? Is the text worth reading?</td>
</tr>
<tr>
<td> – Is the information relevant? Are there annotated links to other pages?</td>
<td> – Is it of sufficiently good quality to create enthusiasm?</td>
</tr>
<tr>
<td> – Is the information correct?</td>
<td/>
</tr>
<tr>
<td> – Are there misspellings and signs of botched work?</td>
<td/>
</tr>
<tr>
<td> – Does the source contain unfinished sections?</td>
<td/>
</tr>
<tr>
<td/>
<td>• Availability</td>
</tr>
<tr>
<td/>
<td> – Is the server busy?</td>
</tr>
<tr>
<td/>
<td> – Is there toll access or free access?</td>
</tr>
<tr>
<td/>
<td> – Does the source require registration? Does it use cookies?</td>
</tr>
<tr>
<td/>
<td>• Performance</td>
</tr>
<tr>
<td/>
<td> – Are there heavy graphics?</td>
</tr>
<tr>
<td/>
<td> – Is ‘text-only’ a possibility?</td>
</tr>
<tr>
<td/>
<td> – Is the site suitable for the disabled?</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0165551512439178">
<p>Source: from [<xref ref-type="bibr" rid="bibr6-0165551512439178">6</xref>], p. 1893.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<sec id="section3-0165551512439178">
<title>Criticism</title>
<p>Criticism points out that checklists have a built-in tendency to mix more or less essential criteria, and that there is no necessary relation between the quality of formal attributes (e.g. spelling) that are easy to check, and more central qualities (such as the validity of claims made in the source). If an information source is screened out because of poor spelling and graphics, we may talk of a ‘false negative’ if the conclusions in the source are valid: the source is deemed bad although it might be fruitful. It is the central qualities that are most important for the user to check, and in this respect the checklist often fails (cf. [<xref ref-type="bibr" rid="bibr6-0165551512439178">6</xref>]). Marc Meola writes:</p>
<disp-quote>
<p>The checklist model rests on faulty assumptions about the nature of information available through the web, mistaken beliefs about student evaluation skills, and an exaggerated sense of librarian expertise in evaluating information. The checklist model is difficult to implement in practice and encourages a mechanistic way of evaluating that is at odds with critical thinking [1, p. 331].</p>
</disp-quote>
<p>A serious problem with the checklist approach is also that many pseudoscientific web pages (for example those that attempt to disprove evolution, claim that the Holocaust did not take place, or misrepresent historical figures like Martin Luther King on hate sites) often fulfil all the formal requirements put forward in checklists. This means that applying a checklist to such sites often results in a failure to identify false evidence. Here the problem is ‘false positive’: something is found to be fine although it is wrong.</p>
</sec>
</sec>
<sec id="section4-0165551512439178">
<title>3. Classical peer review</title>
<p>In this approach, usually two or three subject experts evaluate an information source. The subject experts are supposed to be experts at the same level as the author of the source to be evaluated (hence the term ‘peer’). The reviews may be blind or double blind (as opposed to so-called ‘open reviews’). In blind reviews the author does not know who the reviewers are. In double-blind reviews the reviewers are not informed about the identity of the author. In both cases a formal evaluation form may or may not be used. The evaluations are not published.</p>
<p>Peer review is usually regarded as a ‘gold standard’ in academia. In some bibliographic databases it is possible to limit the search to peer-reviewed journals only. (So far, there are no investigations of whether non-peer reviewed journals, such as <italic>Library Trends</italic>, have lower citation rates than peer-reviewed journals; it should be expected that a complex set of different factors are interacting.)</p>
<sec id="section5-0165551512439178">
<title>Criticism</title>
<p>Peer review is heavily discussed and criticized, and experiments such as [<xref ref-type="bibr" rid="bibr7-0165551512439178">7</xref><xref ref-type="bibr" rid="bibr8-0165551512439178"/><xref ref-type="bibr" rid="bibr9-0165551512439178"/><xref ref-type="bibr" rid="bibr10-0165551512439178"/><xref ref-type="bibr" rid="bibr11-0165551512439178"/>–<xref ref-type="bibr" rid="bibr12-0165551512439178">12</xref>] indicate that the reliability of the evaluations is low. Chubin and Hackett [<xref ref-type="bibr" rid="bibr13-0165551512439178">13</xref>] found in a survey of members of the Scientific Research Society that only 8% agreed that ‘peer review works well as it is’ (p. 192). These criticisms are indeed serious, but the problem is that nobody has yet been able to suggest a better evaluation process that has won broad consent. Other important criticisms are that peer review has a built-in conservatism, and tends to suppress innovative ideas ([<xref ref-type="bibr" rid="bibr14-0165551512439178">14</xref>]), and that ‘peers’ are not just peers, but are often competing individuals in the same narrow field; there are therefore also social-psychological issues involved. An empirical study by Mahoney [<xref ref-type="bibr" rid="bibr15-0165551512439178">15</xref>] found that reviewers are strongly biased against manuscripts that report results contrary to their theoretical perspective. Also, reviewers are influenced by criteria connected to a certain approach or ‘paradigm’, and may be indisposed to see the quality of papers written from other perspectives. Studies have also found that reviewers often do not identify factual errors in the manuscripts they review.</p>
<p>There is a comprehensive body of scholarly writings about peer reviews. In addition to the literature mentioned above, the following deserve to be considered: Weller [<xref ref-type="bibr" rid="bibr16-0165551512439178">16</xref>] is a monograph written in the context of information science; Shatz [<xref ref-type="bibr" rid="bibr17-0165551512439178">17</xref>] is a critical inquiry with emphasis on, among other issues, ethical aspects of the review process; Hamermesh [<xref ref-type="bibr" rid="bibr18-0165551512439178">18</xref>] examined who the referees are, how they are appointed, whether the assignment is done fairly, and how much time referees spend on the reviews; [<xref ref-type="bibr" rid="bibr19-0165551512439178">19</xref>] is a special issue of the <italic>JAMA</italic> (<italic>Journal of the American Medical Association</italic>) publishing papers from the First International Congress on Peer Review in Biomedical Publication.</p>
</sec>
</sec>
<sec id="section6-0165551512439178">
<title>4. Modified peer review</title>
<p>Here we are talking about modifications of the classical peer review. The journal <italic>Nature</italic>, for example, used its referees to compare two anonymous sources each (one from Wikipedia and one from <italic>Encyclopedia Britannica</italic>). The reviews were published [<xref ref-type="bibr" rid="bibr20-0165551512439178">20</xref>], and this study is today the most cited one about Wikipedia.</p>
<p>Another alternative is to create other groups to carry out the reviews. Miller et al. [<xref ref-type="bibr" rid="bibr21-0165551512439178">21</xref>], for example, asked librarians to evaluate Wikipedia.</p>
<sec id="section7-0165551512439178">
<title>Criticism</title>
<p>Basically this method has the same inherent problems as classical peer review. <italic>Encyclopedia Britannica</italic> [<xref ref-type="bibr" rid="bibr22-0165551512439178">22</xref>] made a criticism of [<xref ref-type="bibr" rid="bibr20-0165551512439178">20</xref>], but <italic>Nature</italic> answered this criticism [<xref ref-type="bibr" rid="bibr23-0165551512439178">23</xref>] (see also [<xref ref-type="bibr" rid="bibr24-0165551512439178">24</xref>]) and <italic>Britannica</italic> did not present new important principal arguments against the peer review method as such.</p>
<p>Hjørland [<xref ref-type="bibr" rid="bibr6-0165551512439178">6</xref>] criticized the method used by <italic>Nature</italic> [<xref ref-type="bibr" rid="bibr20-0165551512439178">20</xref>], arguing that many scientific issues are controversial; the position of the reviewers is therefore important for the outcome of the review. He therefore suggested an alternative method: examination of how a given source treats controversial views (see below).</p>
</sec>
</sec>
<sec id="section8-0165551512439178">
<title>5. Evaluation based on examining the coverage of controversial views</title>
<p>A controversy in a given field is identified, and the most important references or spokespersons from each side of the controversy are also identified. How this controversy is covered in the information source to be evaluated is then checked. Does the source mention the controversy? Does it provide references to each side? Examples of the application of this method are [<xref ref-type="bibr" rid="bibr6-0165551512439178">6</xref>] and [<xref ref-type="bibr" rid="bibr25-0165551512439178">25</xref>].</p>
<sec id="section9-0165551512439178">
<title>Criticism</title>
<p>There are some forms of ‘established knowledge’ that are not controversial (e.g. the melting point of lead); in such cases no controversies can be found, but it is still important to check for error. There is also a principal problem in determining when a point of view is serious enough to be taken into consideration. Finally, the usefulness of the method depends on the identification of controversies, which presupposes good knowledge of the subject literature in the field. It is time consuming, but the time might be well spent.</p>
</sec>
</sec>
<sec id="section10-0165551512439178">
<title>6. Evidence-based evaluation</title>
<p>This type of evaluation is based on the principles of evidence-based practice (EBP), which is an interdisciplinary movement that started as evidence-based medicine (EBM) in about 1992. Sackett et al. [<xref ref-type="bibr" rid="bibr26-0165551512439178">26</xref>] give the following definition: ‘Evidence based medicine is the conscientious, explicit, and judicious use of current best evidence in making decisions about the care of individual patients.’ Such a definition is, however, impossible to differentiate from other forms of scientifically based medicine. It has therefore been claimed [<xref ref-type="bibr" rid="bibr27-0165551512439178">27</xref>] that EBM – as well as evidence-based practice in general – is based on certain ideas of what counts as the best evidence, and here the movement is generally interpreted as a movement with a strong affiliation to positivist ideals of science competing with other views about what counts as the best evidence [<xref ref-type="bibr" rid="bibr27-0165551512439178">27</xref>]. The most characteristic ideal in EBP is the administration of a hierarchy of research methods that is independent of the questions being answered. It is basically characterized by the neglect of theoretical and qualitative research.</p>
<p>Applied to the evaluation of information sources, this means that evidence-based evaluation examines the evidence on which the conclusions of a given source are based. If it is a primary source (e.g. a research article), emphasis is put on evaluation of the research method applied (mostly from a version of the evidence hierarchy). If it is a secondary or tertiary information source (e.g. a systematic review or a Wikipedia article), it is evaluated by the principles of meta-reviews – that is, from an examination of its sources and the principles of synthesizing research results.</p>
<p>This approach is essentially based on the use of research methodology to evaluate documents. Textbooks on research methodology are written in order to train students to do research. They may, however, just as well be used in order to evaluate research. Some books are explicitly written for this purpose. For example:</p>
<list list-type="bullet">
<list-item><p><italic>Studying a study and testing a test: How to read the medical evidence</italic> [<xref ref-type="bibr" rid="bibr28-0165551512439178">28</xref>];</p></list-item>
<list-item><p><italic>Evaluating research articles: From start to finish</italic> [<xref ref-type="bibr" rid="bibr29-0165551512439178">29</xref>];</p></list-item>
<list-item><p><italic>How to read a paper: The basics of evidence-based medicine</italic> [<xref ref-type="bibr" rid="bibr30-0165551512439178">30</xref>];</p></list-item>
<list-item><p><italic>Evaluating information: A guide for users of social science research</italic> [<xref ref-type="bibr" rid="bibr31-0165551512439178">31</xref>];</p></list-item>
<list-item><p><italic>Questioning numbers: How to read and critique research</italic> [<xref ref-type="bibr" rid="bibr32-0165551512439178">32</xref>]; and</p></list-item>
<list-item><p><italic>Reasoning with statistics: How to read quantitative research</italic> [<xref ref-type="bibr" rid="bibr33-0165551512439178">33</xref>].</p></list-item>
</list>
<p>Whereas many such books deal with narrow empirical methods, some include also theoretical, ideological, and critical aspects:</p>
<list list-type="bullet">
<list-item><p><italic>What’s behind the research? Discovering hidden assumptions in the behavioral sciences</italic> [<xref ref-type="bibr" rid="bibr34-0165551512439178">34</xref>];</p></list-item>
<list-item><p><italic>Sociological theory – A contemporary view: How to read, criticize and do theory</italic> [<xref ref-type="bibr" rid="bibr35-0165551512439178">35</xref>]; and</p></list-item>
<list-item><p><italic>How to Read Karl Marx</italic> [<xref ref-type="bibr" rid="bibr36-0165551512439178">36</xref>].</p></list-item>
</list>
<p>This last example makes it obvious that any prescription of how to read depends on the theoretical stance taken by the author of that prescription (which is also demonstrated by the overwhelming number of guides on how to read the Bible). In the end, the criteria for evaluation of research are a matter of theories in the philosophy of science. Critical debates on these issues are taking place in the epistemological discourses.</p>
<sec id="section11-0165551512439178">
<title>Criticism</title>
<p>Evidence-based evaluation is criticized as being too narrow, too mechanical, and too formalist [<xref ref-type="bibr" rid="bibr27-0165551512439178">27</xref>]. It is acknowledged that practice should always be based on the best evidence, and on relevant scientific knowledge. Non-positivist epistemologies such as some versions of pragmatism, hermeneutics and critical theory provide a broader and less mechanical way to evaluate information sources – not just in the humanities and social sciences, but also in sciences such as medicine. When such broader epistemological questions are taken into account, we should speak of research-based evaluation (rather than evidence-based evaluation), which is the core of scholarly criticism.</p>
</sec>
</sec>
<sec id="section12-0165551512439178">
<title>7. Comparative studies</title>
<p>The coverage of a given subject in a document may be compared with the coverage of the same subject in a small number of ‘authoritative works’ in the field. Based on these works, a comprehensive table of content of subtopics and a scheme in which the table of contents appears for each of the works may be made (see examples in [<xref ref-type="bibr" rid="bibr37-0165551512439178">37</xref>] comparing information about major philosophers). For each of the sources a checkmark is made in order to indicate whether the subtopic is covered in that work.</p>
<p>Subtopics that are covered by all the authoritative sources are considered mandatory, and the work under examination is evaluated by counting the percentage of mandatory subtopics it includes. In the example in <xref ref-type="table" rid="table2-0165551512439178">Table 2</xref>, subtopics 2, 3 and 4 are covered by all the authoritative sources, and the work to be examined covers one of these subtopics, or 33%. Alternatively – or additionally – the sources may be examined by counting the numbers of errors they contain (see for example [<xref ref-type="bibr" rid="bibr38-0165551512439178">38</xref>]).</p>
<table-wrap id="table2-0165551512439178" position="float">
<label>Table 2.</label>
<caption><p>Scheme for comparing coverage in different information sources</p></caption>
<graphic alternate-form-of="table2-0165551512439178" xlink:href="10.1177_0165551512439178-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Work 1</th>
<th align="left">Work 2</th>
<th align="left">Work 3</th>
<th align="left">Work 4 (to be examined)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Subtopic 1</td>
<td/>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
<tr>
<td>Subtopic 2</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>Subtopic 3</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
<tr>
<td>…</td>
<td/>
<td>×</td>
<td/>
<td/>
</tr>
<tr>
<td>Subtopic <italic>N</italic></td>
<td>×</td>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<p>Meola [<xref ref-type="bibr" rid="bibr1-0165551512439178">1</xref>] also contains important arguments and examples on how to evaluate information sources by using other sources for comparison and fact-checking.</p>
<sec id="section13-0165551512439178">
<title>Criticism</title>
<p>There is a problem in determining which works to recognize as being ‘authoritative’ (and thus suitable for comparison), which demands a good working knowledge of the sources in the field. The fact that works are seldom independent, but are used by authors of new works, should also not be underestimated. The method is most suitable in research fields that are not too dynamic (after a scientific breakthrough the concept of ‘authoritative work’ is problematic).</p>
</sec>
</sec>
<sec id="section14-0165551512439178">
<title>8. Author credentials</title>
<p>Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>] consider the study of author credentials to be one of three gold standards in research assessment (the other two are peer review and publisher reputation). It is not enough for an author to have a high academic degree (e.g. a PhD) or affiliations with a university; rather the author’s credentials should normally be in the specific field of the document to be evaluated. Even receivers of the highest academic recognition (e.g. Nobel Prize winners) may speak or write about matters outside their competence.</p>
<p>Ways of examining author credentials include:</p>
<list list-type="order">
<list-item><p>looking up the author’s CV on his or her home page;</p></list-item>
<list-item><p>considering the biographies often provided in books or in conference presentations; and</p></list-item>
<list-item><p>considering his or her bibliometric data (publications as well as citations).</p></list-item>
</list>
<p>The criteria for author credentials are by principle the same as the criteria used in selecting reviewers for peer review: the author should be <italic>active</italic> in the research field in question, possibly a senior researcher, and should have no conflicts of interest. Even when these criteria are fulfilled, there still remains the question of the author’s theoretical orientation.</p>
<p>Sometimes different factors, such as sex, ethnicity or religion, have been considered. Some feminist researchers may, for example, consider it important that the author be a woman. In evaluating single information sources this is generally a very bad idea, because the best publications may be deselected (i.e., ‘false negatives’). However, in research policy it is relevant to consider whether there is a broad representation of different views among researchers, including a balanced representation of sexes, ages, ethnic groups, and so on. This is obviously more important in the case of, for example, history compared with chemistry.</p>
<sec id="section15-0165551512439178">
<title>Criticism</title>
<p>First, to evaluate a document by considering the credentials of its author is only an indirect evaluation. After all, it is the properties of the document itself that matter. Qualified authors sometimes write bad papers, and the converse. Second, new scientific breakthroughs are often made by ‘outsiders’ (see, for example, [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>], [<xref ref-type="bibr" rid="bibr39-0165551512439178">39</xref>] and [<xref ref-type="bibr" rid="bibr40-0165551512439178">40</xref>]). Third, researchers in a field may also attempt to make the impression that consensus is stronger than it is; they may have an interest in not questioning their own field as much as is necessary – depending on the culture in that field.</p>
<p>Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>] present and discuss the case of hormone replacement therapy (HRT) for women. The research first suggested that HRT was beneficial, but later research suggested that, in addition to the benefits, HRT poses serious dangers. Nevertheless, the research was published by researchers with appropriate credentials.</p>
</sec>
</sec>
<sec id="section16-0165551512439178">
<title>9. Publisher reputation</title>
<p>Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>] also consider publisher reputation as one of the three gold standards in research assessment. Journals and monographs as well as ‘grey literature’ may be evaluated according to the status of their publishers. In the case of journals three aspects may be considered:</p>
<list list-type="order">
<list-item><p>Is the journal published by a publisher with a fine reputation?</p></list-item>
<list-item><p>Is the journal itself well respected?</p></list-item>
<list-item><p>What is the journal’s impact factor (JIF)?</p></list-item>
</list>
<p>Question 2 is more important than question 1: if we know that a journal is, for example, considered a leading one in its field, we need not ask more. The question of JIF is considered separately below. Two issues in particular are important to consider . First, journals are often considered to form a prestige hierarchy: some journals are top quality, some are low quality, and some are in the middle. Papers not accepted by top journals are usually accepted elsewhere. Second, it is a mistake to believe that all journals in an academic discipline form a single hierarchy; they are often specialized and do <italic>not</italic> compete for the same articles as journals representing other subfields. Also, as shown empirically by Heine Andersen [<xref ref-type="bibr" rid="bibr41-0165551512439178">41</xref>], researchers have different perceptions of those hierarchies – that is, of what constitutes the most important journals. ‘Paradigms’ again play an important role in this respect.</p>
<p>In relation to the evaluation of monographs (and anthologies), publishers play a more direct role. Vanity presses are often considered to be a sign of bad quality, while highly respected publishers are considered to be an indicator of good quality. University presses are generally considered to be a sign of quality, and they have mostly adopted a peer review process, because they know that their authors are mostly under pressure to publish in peer-reviewed sources.</p>
<p>It is possible to rank publishers by bibliometric indicators, but this is less important in disciplines that are dominated by journal publications (in which case the JIF may be used as a better alternative). Concerning grey literature, bibliometric data indicating the status of the departments issuing the documents are a hypothetical possibility.</p>
<p>Publishers may have special economic, ideological or disciplinary interests or profiles. This aspect is discussed in the section about sponsoring below.</p>
<sec id="section17-0165551512439178">
<title>Criticism</title>
<p>As with author credentials, evaluation of a document by evaluating its publisher is an indirect kind of evaluation. The same publisher may publish individual documents with varying degrees of quality: that a document is published by a publisher with a fine reputation is never a guarantee of quality. As already stated, Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>] present and discuss the case of HRT for women. The research first suggested that HRT was beneficial, but later research suggested that, in addition to the benefits, HRT poses serious dangers. Nevertheless, the research was published in very respectable publications.</p>
</sec>
</sec>
<sec id="section18-0165551512439178">
<title>10. Journal impact factor</title>
<p>Journal impact factor is one kind of impact factor (IF); another kind is web impact factor (WIF). JIF is a statistical measure of trenchancy, measured by citations received in other journals. It is calculated each year by Thomson Reuters (formerly the Institute for Scientific Information, ISI) and is termed the Thomson Reuters Impact Factor and published in its <italic>Journal Citation Reports</italic> [<xref ref-type="bibr" rid="bibr42-0165551512439178">42</xref>]. The JIF of a given journal is calculated by dividing the number of citations received in the current year by the number of source items published in that journal during the previous two years. The JIF is a tool for ranking <italic>journals</italic>, but it is also marketed as a tool for evaluating single <italic>articles</italic>:</p>
<disp-quote>
<p>Perhaps the most important and recent use of impact is in the process of academic evaluation. The impact factor can be used to provide a gross approximation of the prestige of journals in which individuals have been published. This is best done in conjunction with other considerations such as peer review, productivity, and subject specialty citation rates. [<xref ref-type="bibr" rid="bibr43-0165551512439178">43</xref>]</p>
</disp-quote>
<p>And:</p>
<disp-quote>
<p>Impact factor is not a perfect tool to measure the quality of articles but there is nothing better and it has the advantage of already being in existence and is, therefore, a good technique for scientific evaluation. Experience has shown that in each specialty the best journals are those in which it is most difficult to have an article accepted, and these are the journals that have a high impact factor. Most of these journals existed long before the impact factor was devised. The use of impact factor as a measure of quality is widespread because it fits well with the opinion we have in each field of the best journals in our specialty. [<xref ref-type="bibr" rid="bibr44-0165551512439178">44</xref>], cited in [<xref ref-type="bibr" rid="bibr45-0165551512439178">45</xref>]</p>
</disp-quote>
<p>There is therefore a tendency to use JIF as an indicator of journal quality, and also as an indicator of the quality of each article published in a given journal.</p>
<sec id="section19-0165551512439178">
<title>Criticism</title>
<p>There is a comprehensive literature criticizing the JIF – especially its use as an indicator of the quality of articles and/or their authors. The Norwegian cancer researcher Per Ottar Seglen is one of the main critics of this measure. Research by his team was pioneering in the field of autophagy, and thanks to their contributions the Norwegian Radium Hospital has the opportunity to stay at the forefront of this research field. This was not, however, the picture shown by bibliometric indicators. Therefore Professor Seglen decided to examine the nature of and mechanisms behind the bibliometric indicators, and he became one of the leading critical bibliometricians, in particular in relation to the JIF. Among his papers in this field are [<xref ref-type="bibr" rid="bibr46-0165551512439178">46</xref>], [<xref ref-type="bibr" rid="bibr47-0165551512439178">47</xref>] and [<xref ref-type="bibr" rid="bibr48-0165551512439178">48</xref>]. In his article ‘Why the impact factor of journals should not be used for evaluating research’, Seglen concludes:</p>
<disp-quote>
<p>Summary points:</p>
</disp-quote>
<list list-type="bullet">
<list-item><p>Use of journal impact factors conceals the difference in article citation rates (articles in the most cited half of articles in a journal are cited 10 times as often as the least cited half)</p></list-item>
<list-item><p>Journals’ impact factors are determined by technicalities unrelated to the scientific quality of their articles</p></list-item>
<list-item><p>Journal impact factors depend on the research field: high impact factors are likely in journals covering large areas of basic research with a rapidly expanding but short lived literature that use many references per article</p></list-item>
<list-item><p>Article citation rates determine the journal impact factor, not vice versa [<xref ref-type="bibr" rid="bibr48-0165551512439178">48</xref>].</p></list-item>
</list>
<p>Another medical researcher conducted a review of studies on JIF and concluded:</p>
<disp-quote>
<p>In sum, the impact factor is ill conceived, intellectually and technically flawed, and [a] misleading effort to assess the academic worth of a paper [Walter et al., 2003] [<xref ref-type="bibr" rid="bibr49-0165551512439178">49</xref>]. And, if that’s not enough, Walter and colleagues (2003) point out that the impact factor (IF) has now ‘… spawned a range of flawed offspring, including “Scope-adjusted IF”, “Discipline-specific IF”, “Journal-specific influence factor”, “Immediacy index” and “Cited half-life”’. Exercise physiologists should reflect critically on the issues presented in this article. This article is by no means complete in its analysis, it is nonetheless reasonably complete to help with the decision to make a clean break from the use of impact factors. [<xref ref-type="bibr" rid="bibr50-0165551512439178">50</xref>]</p>
</disp-quote>
<p>A historical review of the development of the JIF is ‘Garfield and the impact factor’ [<xref ref-type="bibr" rid="bibr51-0165551512439178">51</xref>]. The debates about JIF continue, and a recent contribution from the field of organizational studies is [<xref ref-type="bibr" rid="bibr52-0165551512439178">52</xref>].</p>
</sec>
</sec>
<sec id="section20-0165551512439178">
<title>11. Sponsoring: tracing the influence of economic, political and ideological interests</title>
<p>Bailin and Grafstein [2, p. 38] write: ‘Research is generally dependent on financial support, what gets funded to some degree determines what gets researched and thus what research questions are asked. Underlying any research question are certain assumptions about the nature of the phenomena being examined.’ The book provides three examples of how funding has influenced research:</p>
<list list-type="bullet">
<list-item><p>Case 1: hormone replacement therapy (HRT);</p></list-item>
<list-item><p>Case 2: Enron;</p></list-item>
<list-item><p>Case 3: <italic>The bell curve</italic>.</p></list-item>
</list>
<p>In all three cases the book argues that the sponsoring behind the research has hindered the establishment of the truth. In the HRT case the pharmaceutical industry supported research that suppressed findings of serious side effects. In the Enron case the auditing firm (Arthur Andersen) had a conflict of interest, because it was dependent on major income from Enron (of which the smallest part was for the audit itself). Therefore nobody at Arthur Andersen ‘blew the whistle’ when Enron carried out fraudulent trading. In the case of <italic>The bell curve</italic> it was shown that the authors (Richard J Herrnstein and Charles Murray) received financial support from the American Enterprise Institute, which is conservative, and has an ideological interest in favour of the book’s findings. ‘The research findings in <italic>The bell curve</italic>’, Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>] write, ‘were not based on disinterested scientific inquiry, but … on the contrary, the book was written with a clear political agenda in mind’ (p. 36).</p>
<sec id="section21-0165551512439178">
<title>Criticism</title>
<p>As with author credentials and publisher reputation, to evaluate a document by tracing its sponsorships is an <italic>indirect kind of evaluation</italic>. If it should have any implications it should be made probable that the sponsorship has influenced the conclusions in a negative way. The evaluation of a work by examining its dependence on sponsors, although it is an indirect method, is, however, an important part of the critical work. Although there are no necessary relations between sponsoring and conclusions, conflicts of interest should always be carefully examined.</p>
</sec>
</sec>
<sec id="section22-0165551512439178">
<title>12. Book reviews</title>
<p>Book reviews can, depending on their quality, be used to evaluate books as information sources. Also, the method used to write good book reviews may serve as a valuable evaluation method (cf., [17, pp. 109–120]). Book reviews have been termed ‘published peer reviews’ [<xref ref-type="bibr" rid="bibr53-0165551512439178">53</xref>], and George Sarton [<xref ref-type="bibr" rid="bibr54-0165551512439178">54</xref>], a historian of science, summarized the qualities of a good book review: a review should describe and characterize not only the book in question, but also the subject with which it is dealing. It should furthermore answer the question ‘Is the book a real addition to our knowledge, and if so, what exactly has been added?’</p>
<p>The Danish historian Svend Ellehøj [<xref ref-type="bibr" rid="bibr55-0165551512439178">55</xref>] wrote about the criteria that are relevant in the review of historical monographs. The review should not just consider the research problem and structure of the argumentation, and its relation to the relevant primary sources and literature in the field; as far as possible it should also inform about the author, his or her environment, and his or her relation to more general theories. Ellehøj also emphasizes that, although the set of criteria that are active in book reviews is extremely complicated, it is nonetheless possible to produce evaluations of historical research results that have a satisfactory level of validity.</p>
<p>Good book reviews (although not the average book review) may cause the reader to completely change his or her opinion of a specific book. A good review informs about the strong and weak aspects of a book compared with other books on the same subject. It evaluates the sources used: are they the most important ones available? It also evaluates the interpretation of the sources, the scholarly perspective, and the validity of the conclusions. In the best book reviews, the evaluation of the details and of the metatheoretical perspective may be mutually supportive.</p>
<sec id="section23-0165551512439178">
<title>Criticism</title>
<p>It is hard to find any objections in principle to the book review as a method of information evaluation. It is easy, however, to criticize the level of most book reviews; they have even been branded a second-class citizen of scientific literature [<xref ref-type="bibr" rid="bibr56-0165551512439178">56</xref>]. Book reviews are, moreover, regularly charged with merely reflecting individual opinions, which, according to their critics, disqualifies them entirely as scholarly contributions [<xref ref-type="bibr" rid="bibr57-0165551512439178">57</xref>]. However, none of this criticism detracts from the conclusion that, when done properly and qualified, book reviews and the methodology of book reviewing are a first-class scholarly tool.</p>
</sec>
</sec>
<sec id="section24-0165551512439178">
<title>13. Broader criteria</title>
<p>A single document to be evaluated is always part of broader contexts. It needs to be seen in a historical and social perspective. The understanding of the single document should (according to the hermeneutical circle) be supplemented by understanding of the culture or domain in which the document is produced (and vice versa).</p>
<p>Again, the example in which Bailin and Grafstein [<xref ref-type="bibr" rid="bibr2-0165551512439178">2</xref>] present and discuss the case of hormone replacement therapy (HRT) for women should be mentioned. In spite of its problematic findings, all of the research met the gold standards: it was peer-reviewed, the research was published in very respectable publications, and the researchers had appropriate credentials. This indicates that the criteria used are influenced by background knowledge and theory, and when this changes then former evaluations are no longer valid. This is an argument for the hermeneutic philosophy of science, and against the positivist philosophy of science.</p>
<p>In the humanities, <italic>reception studies</italic> are the study of the influence of a given work or a given author (e.g. the influence and reception of Friedrich Nietzsche). Reception studies work from the premise that all texts are historically situated, and acquire new meanings in new contexts; they demonstrate that the influence of a work is dependent not just on the internal properties of that work but also on the different cultures, social groups and disciplines in which it has been used, ignored, or rejected. It is often the case that something that has formerly been refused may be re-evaluated and receiving new attention. This is for example the case with the field of classical rhetoric, which was broadly rejected in the age of logical positivism, but which since then has again become a highly respected and influential field. The lesson for the present article is again that individuals evaluating sources always do so from a perspective or ‘paradigm’, and that it is not enough to focus on narrow criteria for evaluating evaluation sources.</p>
</sec>
<sec id="section25-0165551512439178" sec-type="conclusions">
<title>14. Conclusion</title>
<p>After receiving tuition in source criticism, a student wrote: ‘I now know that to evaluate a text is not “just” to read it, understand it, and to criticize its content. More professional methods are needed.’</p>
<p>This sentence made me a little worried about the consequences of teaching the methods discussed in this article. I do not believe that any of these methods can do the job, alone or in combination. I think the goal is to teach students to read texts, to understand them, and to be able to provide a relevant criticism of them. That is the end goal, and that should be sufficient. All the methods are ‘just’ steps on our way in learning how to read, understand, and criticize texts. But as such they may represent valuable or indeed necessary steps that counteract the use of narrow and one-sided approaches. To read a text is often not a simple process. It involves considering a text in relation to other texts, in relation to the methods used and the social interests it serves and counteracts, and in relation to its public reception as indicated by, for example, bibliometric measures. In other words, it involves the subjectivity of the reader, and that subjectivity is influenced – more or less – by different theoretical perspectives. Good, scholarly reading is to be aware of different perspectives, and to situate oneself among them.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="bibr1-0165551512439178">
<label>[1]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Meola</surname><given-names>M</given-names></name>
</person-group>. <article-title>Chucking the checklist: a contextual approach to teaching undergraduates web-site evaluation</article-title>. <source>Portal: Libraries and the Academy</source> <year>2004</year>; <volume>4</volume>(<issue>3</issue>), <fpage>331</fpage>–<lpage>344</lpage>.</citation>
</ref>
<ref id="bibr2-0165551512439178">
<label>[2]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bailin</surname><given-names>A</given-names></name>
<name><surname>Grafstein</surname><given-names>A</given-names></name>
</person-group>. <source>The critical assessment of research: Traditional and new methods of evaluation</source>. <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Chandos</publisher-name>, <year>2010</year>.</citation>
</ref>
<ref id="bibr3-0165551512439178">
<label>[3]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Beck</surname><given-names>SE</given-names></name>
</person-group> <article-title>The good, the bad and the ugly, or, why it’s a good idea to evaluate web sources</article-title>. <comment>Web-page developed at New Mexico State University Library</comment> <year>1997</year> (Retrieved <day>10</day> <month>December</month> <year>2011</year> <comment>from <ext-link ext-link-type="uri" xlink:href="http://lib.nmsu.edu/instruction/eval.html">http://lib.nmsu.edu/instruction/eval.html</ext-link></comment>)</citation>
</ref>
<ref id="bibr4-0165551512439178">
<label>[4]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cooke</surname><given-names>A</given-names></name>
</person-group>. <source>A guide to finding quality information on the internet: Selection and evaluation strategies</source>. <edition>2nd ed.</edition> <publisher-loc>London, UK</publisher-loc>: <publisher-name>Library Association</publisher-name>, <year>2001</year>.</citation>
</ref>
<ref id="bibr5-0165551512439178">
<label>[5]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Skov</surname><given-names>A</given-names></name>
</person-group>. <article-title>Criteria for evaluating web-resource 2000 (translated from the Danish by Birger Hjørland from ‘Kvalitetsvurdering af web-sider’)</article-title>. (Retrieved <day>10</day> <month>December</month> <year>2011</year> <comment>from <ext-link ext-link-type="uri" xlink:href="http://www.iva.dk/jni/lifeboat/info.asp?subjectid=308">http://www.iva.dk/jni/lifeboat/info.asp?subjectid=308</ext-link></comment>; <comment>original Danish version retrieved from <ext-link ext-link-type="uri" xlink:href="http://vip.iva.dk/tutorials/kvalitet/ny_side_2.htm">http://vip.iva.dk/tutorials/kvalitet/ny_side_2.htm</ext-link></comment>)</citation>
</ref>
<ref id="bibr6-0165551512439178">
<label>[6]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hjørland</surname><given-names>B</given-names></name>
</person-group>. <article-title>Evaluation of an information source illustrated by a case study: effect of screening for breast cancer</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <year>2011</year>; <volume>62</volume>(<issue>10</issue>): <fpage>1892</fpage>–<lpage>1898</lpage>.</citation>
</ref>
<ref id="bibr7-0165551512439178">
<label>[7]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cicchetti</surname><given-names>DV</given-names></name>
</person-group>. <article-title>The reliability of peer review for manuscript and grant submissions: A cross-disciplinary investigation</article-title>. <source>Behavioral and Brain Sciences</source> <year>1991</year>; <volume>14</volume>(<issue>1</issue>): <fpage>119</fpage>–<lpage>135</lpage>.</citation>
</ref>
<ref id="bibr8-0165551512439178">
<label>[8]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cole</surname><given-names>S</given-names></name>
<name><surname>Cole</surname><given-names>JR</given-names></name>
<name><surname>Simon</surname><given-names>GA</given-names></name>
</person-group>. <article-title>Chance and consensus in peer review</article-title>. <source>Science</source> <year>1981</year>; <volume>214</volume>(<issue>4523</issue>): <fpage>881</fpage>–<lpage>886</lpage>.</citation>
</ref>
<ref id="bibr9-0165551512439178">
<label>[9]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garfunkel</surname><given-names>JM</given-names></name>
<name><surname>Ulshen</surname><given-names>MH</given-names></name>
<name><surname>Hamrick</surname><given-names>HJ</given-names></name>
<name><surname>Lawson</surname><given-names>EE</given-names></name>
</person-group>. <article-title>Problems Identified by Secondary Review of Accepted Manuscripts</article-title>. <source>JAMA (Journal of the American Medical Association)</source> <year>1990</year>; <volume>263</volume>(<issue>10</issue>): <fpage>1369</fpage>–<lpage>1371</lpage>.</citation>
</ref>
<ref id="bibr10-0165551512439178">
<label>[10]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peters</surname><given-names>DP</given-names></name>
<name><surname>Ceci</surname><given-names>SJ</given-names></name>
</person-group> <article-title>Peer-review practices of psychological journals: the fate of published articles, submitted again</article-title>. <source>Behavioral and Brain Sciences</source> <year>1982</year>; <volume>5</volume>(<issue>2</issue>): <fpage>187</fpage>–<lpage>255</lpage>.</citation>
</ref>
<ref id="bibr11-0165551512439178">
<label>[11]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rothwell</surname><given-names>PM</given-names></name>
<name><surname>Martyn</surname><given-names>CN</given-names></name>
</person-group>. <article-title>Reproducibility of peer review in clinical neuroscience. Is agreement between reviewers any greater than would be expected by chance alone?</article-title> <source>Brain</source> <year>2000</year>; <volume>123</volume>(<issue>9</issue>): <fpage>361</fpage>–<lpage>376</lpage>.</citation>
</ref>
<ref id="bibr12-0165551512439178">
<label>[12]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Starbuck</surname><given-names>WH</given-names></name>
</person-group>. <article-title>How much better are the most prestigious journals? The statistics of academic publication</article-title>. <source>Organization Science</source> <year>2005</year>; <volume>16</volume>(<issue>2</issue>): <fpage>180</fpage>–<lpage>200</lpage>.</citation>
</ref>
<ref id="bibr13-0165551512439178">
<label>[13]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chubin</surname><given-names>M</given-names></name>
<name><surname>Hackett</surname><given-names>E</given-names></name>
</person-group>. <source>Peerless science: Peer review and US science policy</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>State University of New York Press</publisher-name>, <year>1990</year>.</citation>
</ref>
<ref id="bibr14-0165551512439178">
<label>[14]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Horrobin</surname><given-names>DF</given-names></name>
</person-group>. <article-title>The philosophical basis of peer review and the suppression of innovation</article-title>. <source>JAMA (Journal of the American Medical Association)</source> <year>1990</year>; <volume>263</volume>(<issue>10</issue>): <fpage>1438</fpage>–<lpage>1441</lpage>.</citation>
</ref>
<ref id="bibr15-0165551512439178">
<label>[15]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mahoney</surname><given-names>MJ</given-names></name>
</person-group>. <article-title>Publication prejudices: an experimental study of confirmatory bias in the peer review system</article-title>. <source>Cognitive Therapy and Research</source> <year>1977</year>; <volume>1</volume>(<issue>2</issue>): <fpage>161</fpage>–<lpage>175</lpage>.</citation>
</ref>
<ref id="bibr16-0165551512439178">
<label>[16]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Weller</surname><given-names>AC</given-names></name>
</person-group>. <source>Editorial peer review: Its strengths and weaknesses</source>. <publisher-loc>Medford, NJ, USA</publisher-loc>: <publisher-name>Information Today</publisher-name>, <year>2001</year> (<comment>ASIS&amp;T Monograph Series</comment>).</citation>
</ref>
<ref id="bibr17-0165551512439178">
<label>[17]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Shatz</surname><given-names>D</given-names></name>
</person-group>. <source>Peer review: A critical inquiry</source>. <publisher-loc>Lanham, MD, USA</publisher-loc>: <publisher-name>Rowman and Littlefield Publishers</publisher-name>, <year>2004</year> (<comment>Issues in Academic Ethics</comment>).</citation>
</ref>
<ref id="bibr18-0165551512439178">
<label>[18]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hamermesh</surname><given-names>DS</given-names></name>
</person-group>. <article-title>Facts and myths about refereeing</article-title>. <source>Journal of Economic Perspectives</source> <year>1994</year>; <volume>8</volume>(<issue>1</issue>): <fpage>153</fpage>–<lpage>163</lpage>.</citation>
</ref>
<ref id="bibr19-0165551512439178">
<label>[19]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rennie</surname><given-names>D</given-names></name>
</person-group>. <article-title>Editorial peer review in biomedical publication: the first international congress</article-title>. <source>JAMA (Journal of the American Medical Association)</source> <year>1990</year>; <volume>263</volume>(<issue>10</issue>): <year>1317</year> (<comment>Thematic issue: ‘Guarding the Guardians’ about research in editorial ‘Peer Review’</comment>).</citation>
</ref>
<ref id="bibr20-0165551512439178">
<label>[20]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Giles</surname><given-names>J</given-names></name>
</person-group>. <article-title>Special report: Internet encyclopaedias go head to head</article-title>. <source>Nature</source> <year>2005</year>; <volume>438</volume>: <fpage>900</fpage>–<lpage>901</lpage> (Retrieved <day>8</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www2.stat.unibo.it/mazzocchi/macroeconomia/documenti/Nature%202006%20wikipedia.pdf">http://www2.stat.unibo.it/mazzocchi/macroeconomia/documenti/Nature%202006%20wikipedia.pdf</ext-link></comment>).</citation>
</ref>
<ref id="bibr21-0165551512439178">
<label>[21]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Miller</surname><given-names>BX</given-names></name>
<name><surname>Helicher</surname><given-names>K</given-names></name>
<name><surname>Berry</surname><given-names>T</given-names></name>
</person-group>. <article-title>I want My Wikipedia!</article-title> <source>Library Journal</source> <year>2006</year>; <volume>131</volume>(<issue>6</issue>): <fpage>122</fpage>–<lpage>124</lpage> (Retrieved <day>8</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www.libraryjournal.com/article/CA6317246.html">http://www.libraryjournal.com/article/CA6317246.html</ext-link></comment>).</citation>
</ref>
<ref id="bibr22-0165551512439178">
<label>[22]</label>
<citation citation-type="web">
<collab>Encyclopedia Britannica</collab>. <article-title>Fatally flawed. Refuting the recent study on encyclopedic accuracy by the journal</article-title> <source>Nature</source>. <year>2006</year> (Retrieved <day>8</day> <month>December</month> <year>2011</year> <comment>from <ext-link ext-link-type="uri" xlink:href="http://corporate.britannica.com/britannica_nature_response.pdf">http://corporate.britannica.com/britannica_nature_response.pdf</ext-link></comment>).</citation>
</ref>
<ref id="bibr23-0165551512439178">
<label>[23]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Giles</surname><given-names>J</given-names></name>
</person-group>. <article-title>Supplementary information to accompany</article-title> <source>Nature</source> <comment>news article ‘Internet encyclopaedias go head to head’</comment>. <year>2005</year> (Retrieved <day>8</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nature/journal/v438/n7070/extref/438900a-s1.doc">http://www.nature.com/nature/journal/v438/n7070/extref/438900a-s1.doc</ext-link></comment>).</citation>
</ref>
<ref id="bibr24-0165551512439178">
<label>[24]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Lubick</surname><given-names>N.</given-names></name>
<name><surname>Wikipedia</surname><given-names>v</given-names></name>
</person-group>. <article-title>Britannica: Reader beware</article-title>. <source>Geotimes</source> <year>2006</year>; <volume>51</volume>(<issue>4</issue>): <fpage>46</fpage> (Retrieved <day>8</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www.agiweb.org/geotimes/apr06/geomedia.html#FIRST">http://www.agiweb.org/geotimes/apr06/geomedia.html#FIRST</ext-link></comment>).</citation>
</ref>
<ref id="bibr25-0165551512439178">
<label>[25]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Luyt</surname><given-names>B</given-names></name>
</person-group>. <article-title>The nature of historical representation on Wikipedia: dominant or alternative historiography?</article-title> <source>Journal of the American Society for Information Science and Technology</source> <year>2011</year>; <volume>62</volume>(<issue>6</issue>): <fpage>1058</fpage>–<lpage>1065</lpage>.</citation>
</ref>
<ref id="bibr26-0165551512439178">
<label>[26]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Sackett</surname><given-names>DL</given-names></name>
<name><surname>Rosenberg</surname><given-names>WMC</given-names></name>
<name><surname>Gray</surname><given-names>JAM</given-names></name>
<name><surname>Haynes</surname><given-names>RB</given-names></name>
<name><surname>Richardson</surname><given-names>WS</given-names></name>
</person-group>. <article-title>Evidence based medicine: what it is and what it isn’t</article-title>. <source>British Medical Journal (BMJ)</source>; <year>1996</year>; <volume>312</volume>(<issue>7023</issue>): <fpage>71</fpage>–<lpage>72</lpage> (Retrieved <day>8</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www.bmj.com/content/312/7023/71.full">http://www.bmj.com/content/312/7023/71.full</ext-link></comment>).</citation>
</ref>
<ref id="bibr27-0165551512439178">
<label>[27]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hjørland</surname><given-names>B</given-names></name>
</person-group>. <article-title>Evidence-based practice: an analysis based on the philosophy of science</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <year>2011</year>; <volume>62</volume>(<issue>7</issue>): <fpage>1301</fpage>–<lpage>1310</lpage>.</citation>
</ref>
<ref id="bibr28-0165551512439178">
<label>[28]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Riegelman</surname><given-names>RK</given-names></name>
</person-group>. <source>Studying a study and testing a test: How to read the medical evidence</source>. <edition>5th ed.</edition> <publisher-loc>Philadelphia, PA, USA</publisher-loc>: <publisher-name>Lippincott Williams and Wilkins</publisher-name>, <year>2004</year>.</citation>
</ref>
<ref id="bibr29-0165551512439178">
<label>[29]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Girden</surname><given-names>ER</given-names></name>
</person-group>. <source>Evaluating research articles: From start to finish</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>SAGE Publications</publisher-name>, <year>1996</year>.</citation>
</ref>
<ref id="bibr30-0165551512439178">
<label>[30]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Greenhalgh</surname><given-names>T</given-names></name>
</person-group>. <source>How to read a paper: The basics of evidence-based medicine</source>. <edition>4th ed.</edition> <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>BMJ Books</publisher-name>, <year>2010</year>.</citation>
</ref>
<ref id="bibr31-0165551512439178">
<label>[31]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Katzer</surname><given-names>J</given-names></name>
<name><surname>Cook</surname><given-names>KH</given-names></name>
<name><surname>Crouch</surname><given-names>WW</given-names></name>
</person-group>. <source>Evaluating information: A guide for users of social science research</source>. <edition>4th ed.</edition> <publisher-loc>Boston, MA, USA</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>, <year>1998</year>.</citation>
</ref>
<ref id="bibr32-0165551512439178">
<label>[32]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wilkins</surname><given-names>KG</given-names></name>
</person-group> <source>Questioning numbers: How to read and critique research</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>, <year>2010</year>.</citation>
</ref>
<ref id="bibr33-0165551512439178">
<label>[33]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Williams</surname><given-names>F</given-names></name>
<name><surname>Monge</surname><given-names>PR</given-names></name>
</person-group>. <source>Reasoning with statistics: How to read quantitative research</source>. <edition>5th ed.</edition> <publisher-loc>Florence, KY, USA</publisher-loc>: <publisher-name>Wadsworth Publishing Company</publisher-name>, <year>2000</year>.</citation>
</ref>
<ref id="bibr34-0165551512439178">
<label>[34]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Slife</surname><given-names>BD</given-names></name>
<name><surname>Williams</surname><given-names>RN</given-names></name>
</person-group>. <source>What’s behind the research? Discovering hidden assumptions in the behavioral sciences</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>SAGE Publications</publisher-name>, <year>1995</year>.</citation>
</ref>
<ref id="bibr35-0165551512439178">
<label>[35]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Smelser</surname><given-names>NJ</given-names></name>
</person-group>. <source>Sociological theory – a contemporary view: How to read, criticize and do theory</source>. <publisher-loc>New Orleans, LA, USA</publisher-loc>: <publisher-name>Quid Pro Books</publisher-name>, <year>2011</year> (<edition>1st ed</edition>. <year>1971</year>).</citation>
</ref>
<ref id="bibr36-0165551512439178">
<label>[36]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fischer</surname><given-names>E</given-names></name>
<name><surname>Marek</surname><given-names>F</given-names></name>
</person-group>. <source>How to read Karl Marx</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Monthly Review Press</publisher-name>, <year>1996</year>.</citation>
</ref>
<ref id="bibr37-0165551512439178">
<label>[37]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bragues</surname><given-names>G</given-names></name>
</person-group>. <article-title>Wiki-philosophizing in a marketplace of ideas: evaluating Wikipedia’s entries on seven great minds</article-title>. <source>MediaTropes eJournal</source> <year>2009</year>; <volume>2</volume>(<issue>1</issue>): <fpage>117</fpage>–<lpage>158</lpage>.</citation>
</ref>
<ref id="bibr38-0165551512439178">
<label>[38]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rector</surname><given-names>LH</given-names></name>
</person-group>. <article-title>Comparison of Wikipedia and other encyclopedia for accuracy, breadth, and depth in historical articles</article-title>. <source>Reference Services Review</source> <year>2008</year>; <volume>36</volume>(<issue>1</issue>): <fpage>7</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr39-0165551512439178">
<label>[39]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fleck</surname><given-names>L</given-names></name>
</person-group>. <source>Genesis and development of a scientific fact</source>. <publisher-loc>Chicago, IL, USA</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>, <year>1979</year> (<comment>German original 1935</comment>).</citation>
</ref>
<ref id="bibr40-0165551512439178">
<label>[40]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Hjørland</surname><given-names>B</given-names></name>
<name><surname>Nicolaisen</surname><given-names>J</given-names></name>
</person-group>. <article-title>The social psychology of information use: seeking ‘friends’, avoiding ‘enemies’</article-title>. <source>Information Research</source> <year>2010</year>; <volume>15</volume>(<issue>3</issue>) <fpage>colis706</fpage> (<comment>Available at <ext-link ext-link-type="uri" xlink:href="http://InformationR.net/ir/15-3/colis7/colis706.html">http://InformationR.net/ir/15-3/colis7/colis706.html</ext-link></comment>).</citation>
</ref>
<ref id="bibr41-0165551512439178">
<label>[41]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Andersen</surname><given-names>H</given-names></name>
</person-group>. <article-title>Influence and reputation in the social sciences: how much do researchers agree?</article-title> <source>Journal of Documentation</source> <year>2000</year>; <volume>56</volume>(<issue>6</issue>): <fpage>674</fpage>–<lpage>692</lpage>.</citation>
</ref>
<ref id="bibr42-0165551512439178">
<label>[42]</label>
<citation citation-type="web">
<source>Journal Citation Reports</source>. <publisher-loc>Philadelphia, PA, USA</publisher-loc>: <publisher-name>Thomson Reuters</publisher-name> <comment>(annual). Official website: <ext-link ext-link-type="uri" xlink:href="http://thomsonreuters.com/products_services/science/science_products/a-z/journal_citation_reports/">http://thomsonreuters.com/products_services/science/science_products/a-z/journal_citation_reports/</ext-link></comment></citation>
</ref>
<ref id="bibr43-0165551512439178">
<label>[43]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Garfield</surname><given-names>E</given-names></name>
</person-group>. <article-title>The impact factor. Current Contents print editions June 20, 1994</article-title>. <comment>Here cited</comment> <day>8</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://thomsonreuters.com/products_services/science/free/essays/impact_factor/">http://thomsonreuters.com/products_services/science/free/essays/impact_factor/</ext-link></comment></citation>
</ref>
<ref id="bibr44-0165551512439178">
<label>[44]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hoeffel</surname><given-names>C</given-names></name>
</person-group>. <article-title>Journal impact factors</article-title>. <source>Allergy</source> <year>1998</year>; <volume>53</volume>(<issue>12</issue>): <year>1225</year>.</citation>
</ref>
<ref id="bibr45-0165551512439178">
<label>[45]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Garfield</surname><given-names>E</given-names></name>
</person-group>. <article-title>The agony and the ecstasy: the history and meaning of the journal impact factor</article-title>. <conf-name>Presented at the 5th International Congress on Peer Review and Biomedical Publication</conf-name>, <conf-loc>Chicago, IL, USA</conf-loc>, <day>16</day> <month>September</month> <year>2005</year> (Retrieved <day>9</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www.garfield.library.upenn.edu/papers/jifchicago2005.pdf">http://www.garfield.library.upenn.edu/papers/jifchicago2005.pdf</ext-link></comment>).</citation>
</ref>
<ref id="bibr46-0165551512439178">
<label>[46]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Seglen</surname><given-names>PO</given-names></name>
</person-group>. <article-title>How representative is the journal impact factor?</article-title> <source>Research Evaluation</source> <year>1993</year>; <volume>2</volume>(<issue>3</issue>): <fpage>143</fpage>–<lpage>149</lpage>.</citation>
</ref>
<ref id="bibr47-0165551512439178">
<label>[47]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Seglen</surname><given-names>PO</given-names></name>
</person-group>. <article-title>Bruk av siteringer og tidsskriftimpaktfaktor til forskningsevaluering</article-title>. <source>Biblioteksarbejde</source> <year>1996</year>; <volume>17</volume>(<issue>48</issue>): <fpage>27</fpage>–<lpage>34</lpage> (Retrieved <day>9</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://biblioteksarbejde.dk/art/BA48/seglen(1996).pdf">http://biblioteksarbejde.dk/art/BA48/seglen(1996).pdf</ext-link></comment>).</citation>
</ref>
<ref id="bibr48-0165551512439178">
<label>[48]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Seglen</surname><given-names>PO</given-names></name>
</person-group>. <article-title>Why the impact factor of journals should not be used for evaluating research</article-title>. <source>British Medical Journal</source> <year>1997</year>; <volume>314</volume>(<issue>7079</issue>): <fpage>498</fpage>–<lpage>502</lpage> (Retrieved <day>10</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://www.bmj.com/content/314/7079/497.1?tab=full">http://www.bmj.com/content/314/7079/497.1?tab=full</ext-link></comment>).</citation>
</ref>
<ref id="bibr49-0165551512439178">
<label>[49]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walter</surname><given-names>G</given-names></name>
<name><surname>Bloch</surname><given-names>S</given-names></name>
<name><surname>Hunt</surname><given-names>G</given-names></name>
<name><surname>Fisher</surname><given-names>K</given-names></name>
</person-group>. <article-title>Counting on citations: a flawed way to measure quality</article-title>. <source>Medical Journal of Australia</source> <year>2003</year>; <volume>178</volume>(<issue>6</issue>): <fpage>280</fpage>–<lpage>281</lpage>.</citation>
</ref>
<ref id="bibr50-0165551512439178">
<label>[50]</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Boone</surname><given-names>T</given-names></name>
</person-group>. <article-title>Journal impact factor: a critical review</article-title>. <source>Professionalization of Exercise Physiology</source> [<comment>online journal</comment>] <year>2004</year>; <volume>7</volume>(<issue>1</issue>) (Retrieved <day>10</day> <month>December</month> <year>2011</year> <comment>from: <ext-link ext-link-type="uri" xlink:href="http://faculty.css.edu/tboone2/asep/journalIMPACTfactor.html">http://faculty.css.edu/tboone2/asep/journalIMPACTfactor.html</ext-link></comment>).</citation>
</ref>
<ref id="bibr51-0165551512439178">
<label>[51]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bensman</surname><given-names>SJ</given-names></name>
</person-group>. <article-title>Garfield and the impact factor</article-title>. <source>Annual Review of Information Science and Technology</source> <year>2007</year>; <volume>41</volume>: <fpage>93</fpage>–<lpage>155</lpage>.</citation>
</ref>
<ref id="bibr52-0165551512439178">
<label>[52]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Baum</surname><given-names>JAC</given-names></name>
</person-group>. <article-title>Free-riding on power laws: questioning the validity of the impact factor as a measure of research quality in organization studies</article-title>. <source>Organization</source> <year>2011</year>; <volume>18</volume>(<issue>4</issue>): <fpage>449</fpage>–<lpage>466</lpage>.</citation>
</ref>
<ref id="bibr53-0165551512439178">
<label>[53]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hyland</surname><given-names>K</given-names></name>
</person-group>. <source>Disciplinary discourses: Social interactions in academic writing</source>. <publisher-loc>Harlow, UK</publisher-loc>: <publisher-name>Longman</publisher-name>, <year>2000</year>.</citation>
</ref>
<ref id="bibr54-0165551512439178">
<label>[54]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sarton</surname><given-names>G</given-names></name>
</person-group>. <article-title>Notes on the reviewing of learned books</article-title>. <source>Science</source> <year>1960</year>; <volume>131</volume>(<day>22</day> <month>April</month>): <fpage>1182</fpage>–<lpage>1187</lpage>.</citation>
</ref>
<ref id="bibr55-0165551512439178">
<label>[55]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ellehøj</surname><given-names>S</given-names></name>
</person-group>. <article-title>Faglige kriterier for vurdering af historiske forskningsresultater i: Problemvurdering og prioritering i historie</article-title>. <source>Studier i historisk metode V</source> <year>1970</year>: <fpage>72</fpage>–<lpage>80</lpage> (<comment>in Danish</comment>).</citation>
</ref>
<ref id="bibr56-0165551512439178">
<label>[56]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Riley</surname><given-names>LE</given-names></name>
<name><surname>Spreitzer</surname><given-names>EA</given-names></name>
</person-group>. <article-title>Book reviewing in the social sciences</article-title>. <source>The American Sociologist</source> <year>1970</year>; <volume>5</volume>(<month>November</month>): <fpage>358</fpage>–<lpage>363</lpage>.</citation>
</ref>
<ref id="bibr57-0165551512439178">
<label>[57]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sabosik</surname><given-names>PE</given-names></name>
</person-group>. <article-title>Scholarly reviewing and the role of choice in the postpublication review process</article-title>. <source>Book Research Quarterly</source> <year>1988</year>; <volume>4</volume>(<issue>2</issue>): <fpage>10</fpage>–<lpage>18</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>