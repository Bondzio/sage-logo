<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ERG</journal-id>
<journal-id journal-id-type="hwp">sperg</journal-id>
<journal-title>Ergonomics in Design: The Quarterly of Human Factors Applications</journal-title>
<issn pub-type="ppub">1064-8046</issn>
<issn pub-type="epub">XXXX-XXXX</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1064804612444786</article-id>
<article-id pub-id-type="publisher-id">10.1177_1064804612444786</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Features</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Accessible In-Flight Entertainment Systems for Blind and Deaf Passengers</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Eghtesadi</surname><given-names>Caesar</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Goldberg</surname><given-names>Larry</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Botkin</surname><given-names>Bradley</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>O’Connell</surname><given-names>Trisha</given-names></name>
</contrib>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2012</year>
</pub-date>
<volume>20</volume>
<issue>3</issue>
<fpage>7</fpage>
<lpage>13</lpage>
<permissions>
<copyright-statement>© 2012 Human Factors and Ergonomics Society</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Human Factors and Ergonomics Society</copyright-holder>
</permissions>
<abstract>
<p>This article describes the development of a prototype accessible in-flight entertainment (IFE) system for people with sensory disabilities. For passengers who are deaf or hard of hearing, the system provides access to content through user-selectable caption display of audio information. Those who are blind or have low vision can find content via talking menus and audio description of key visual content. Findings support the feasibility of project solutions and informed development of recommendations for accessible designs within industry IFE standards. Results are under review by the U.S. Department of Transportation in support of a proposed supplemental rulemaking on requirements for accessible IFE systems.</p>
</abstract>
<kwd-group>
<kwd>disability</kwd>
<kwd>accessible communications</kwd>
<kwd>inclusive travel</kwd>
<kwd>airlines</kwd>
<kwd>accommodation</kwd>
<kwd>deaf passengers</kwd>
<kwd>blind passengers</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>A prototype entertainment system could help stimulate the development and adoption of accessibility standards.</p>
<p>Airlines offer in-flight entertainment (IFE) systems that enable passengers to access movies, music libraries, television broadcasts, and up-to-date flight information such as arrival times, connecting flights, and gate changes. However, people with sensory disabilities cannot benefit from these services. A traveler who is deaf or hard of hearing can find and understand text-based information but is unable to enjoy a movie or television program because IFE systems do not carry or display caption data. A traveler who is blind or has low vision cannot independently navigate among any of the current IFE systems to access entertainment or information.</p>
<p>The user interface models in IFE systems rely on one’s ability to see and interact with graphics. Systems are operated via seat arm or handheld controls or touch-screen menus. Interface designs and behaviors include the presentation of choices through icons, multicolumn tables, or rotating images and the use of flashing lights or changes in color for alerts or confirmation of selection. In the project described in this article, we created prototype interface solutions that enabled independent access to captioned or described movies, music, and information within seat-back in-flight systems.</p>
<sec id="section1-1064804612444786">
<title>Equal Access to Ife Systems and Information</title>
<p>The proliferation of inaccessible IFE systems creates yet another area of daily life in which people with sensory disabilities cannot equally participate and are placed at a disadvantage compared with the rest of population. An estimated 28 million Americans are deaf or hard of hearing (<xref ref-type="bibr" rid="bibr7-1064804612444786">Lucas, Schiller, &amp; Benson, 2004</xref>), and up to 20 million Americans report visual impairments (<xref ref-type="bibr" rid="bibr10-1064804612444786">Pleis &amp; Lethbridge-Çejku, 2007</xref>). As the population ages, more and more people will experience sensory disabilities.</p>
<p>Captions and video description, pioneered by WGBH, are widely used by people with sensory disabilities to understand media on television, on the Web, and in theaters (<xref ref-type="bibr" rid="bibr9-1064804612444786">O’Connell &amp; Goldberg, 2010</xref>). Users who are blind also require talking menus to find programming and video descriptions, which can be provided through text-to-speech (TTS) solutions. Many of these features have become popular among general users as well. Some people prefer reading captions while listening to audio, and some users who struggle with reading or want hands-free options prefer navigating via a speech interface, illustrating the benefits of universal design.</p>
<p>Almost all IFE media content has already been captioned. Similarly, most first-run movies have already been audio described to play in hundreds of theaters around the country that use WGBH’s Motion Picture Access (MoPix) systems (<ext-link ext-link-type="uri" xlink:href="http://ncam.wgbh.org/mopix/">http://ncam.wgbh.org/mopix/</ext-link>). Yet these captions and descriptions are not generally available within IFE systems, and none of the menus and text-based information is accessible to people with vision impairments.</p>
</sec>
<sec id="section2-1064804612444786">
<title>Goals: Influence Industry Implementation and Inform Accessibility Requirements</title>
<p>As of this writing, there were no requirements for accessible IFE systems. Under the Air Carrier Access Act of 1986 (ACAA; Title 49, Section 41705 of the U.S. Code), the U.S. Department of Transportation establishes accessibility requirements for people with disabilities related to air travel. The ACAA rulemakings do not correspond directly to requirements established by the Americans With Disabilities Act (ADA; <ext-link ext-link-type="uri" xlink:href="http://www.ada.gov/index.html">http://www.ada.gov/index.html</ext-link>), which addresses places of public accommodation. In fact, even under the ADA, public and commercial entities are not expressly required to add captioning or describe the content they offer via the Internet or to make their Web sites or other digital delivery accessible to people with disabilities. Section 508 of the Accessibility Standards of the Rehabilitation Act Amendments of 1998 (<ext-link ext-link-type="uri" xlink:href="http://www.section508.gov">http://www.section508.gov</ext-link>) apply only to federal procurements of information and communication technologies. On aircraft, only safety information must be made accessible, and alternative methods of providing information, such as printed cards, are acceptable.</p>
<p>This lack of accessibility to IFE content for people with sensory disabilities may soon change, as the Department of Transportation has stated its intention to address accessible IFE systems in the future. The agency specifically noted the progress made in our project in a related 2009 department rulemaking that amends the ACAA on nondiscrimination on the basis of disability in air travel (73 FR 27614).</p>
<p>In September 2011, the department proposed that airlines make automated airport kiosks at U.S. airports accessible to passengers with disabilities. Under the proposed rule, airlines also would be required, over a two-year period, to make their Web sites accessible to persons with disabilities. A final decision and recommendations for implementing this proposal are expected toward the end of 2012 (<ext-link ext-link-type="uri" xlink:href="http://www.dot.gov/affairs/2011/dot12611.html">http://www.dot.gov/affairs/2011/dot12611.html</ext-link>).</p>
<p>Significant advances in accessibility are forthcoming on a number of fronts that also may advance the issue. The 2010 passage of the 21st Century Communications and Video Accessibility Act (21st CVAA; <ext-link ext-link-type="uri" xlink:href="http://www.nad.org/issues/civil-rights/communications-act/21st-century-act">http://www.nad.org/issues/civil-rights/communications-act/21st-century-act</ext-link>) establishes new requirements for Internet and broadcast services, including requirements for the provision of audio description on selected television programming and accessible user interfaces on television and video display devices.</p>
<p>Aware that federal regulations are not keeping pace with many new technologies, in 2010, the U.S Department of Justice issued notices of proposed rulemaking to collect input on possible ADA revisions that specifically addresses Web services, movie captioning, and video description, among other issues. Aircraft accessibility requirements will continue to be regulated by the Department of Transportation under the ACAA. However, they are likely to be influenced by ADA revisions as well as by the greater availability of accessible digital programming and user interface models for set-top boxes.</p>
</sec>
<sec id="section3-1064804612444786">
<title>Prototype Development</title>
<p>We developed the prototype in Visual Basic on a Windows PC platform. The prototype was based on Panasonic’s IFE system (eFX) and followed the eFX user interface design paradigm. It emulated an 800 × 480-pixel seat-back touch-screen display, used an off-the-shelf TTS engine (Microsoft SAPI), and included an external input device to emulate a potential tactile button controller in the seat arm. The prototype offered the same functionality as the eFX system, with the addition of an accessibility menu that enabled captioning or audio description for movies and TV programs, a low-vision navigation mode with large fonts and high-contrast screens, and a talking menu navigation mode.</p>
<p><xref ref-type="fig" rid="fig1-1064804612444786">Figure 1</xref> shows the Home/Main Menu page of the eFX with a dedicated “Accessibility” button added at the bottom of the menu bar on the left.</p>
<fig id="fig1-1064804612444786" position="float">
<label>Figure 1.</label>
<caption><p>Home/Main Menu screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig1.tif"/>
</fig>
<p>Talking menus provided consistent audio information about user positioning within all levels of the hierarchical menus and automatically announced the name or function of a menu, button, or key press as the user navigated through the user interface. As with many IFE systems, the eFX is designed to be operated via a visually based touch screen, so an alternative mechanism was required for operation by blind and low-vision users. The prototype’s touch-screen solution involved the Trace Research and Development Center’s EZ Access® approach (<xref ref-type="bibr" rid="bibr5-1064804612444786">Law &amp; Vanderheiden, 2000</xref>) and offered navigation and control via an external five-button device, which could be replicated easily in a seat arm or handheld device. EZ Access controls are relatively familiar to most blind and low-vision users, as the controls are widely available in the United States in kiosks at banks, airports, and Amtrak stations. <xref ref-type="fig" rid="fig2-1064804612444786">Figure 2</xref> (next page) shows the EZ Access device.</p>
<fig id="fig2-1064804612444786" position="float">
<label>Figure 2.</label>
<caption><p>Five-button EZ Access keypad as input device.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig2.tif"/>
</fig>
<p>We identified the functional requirements and preferred features of an accessible IFE for navigation, control, and access to content and provided access to them within the prototype via an Accessibility Options page. This included (a) large font mode, (b) EZ Access support for alternative input device, (c) TTS support for controls and on-screen text, (d) on-demand caption support, and (e) on-demand video description support.</p>
<p>Via the Accessibility Options page, a user could select features that met his or her needs. Each feature can be enabled individually or in any combination.</p>
<p><xref ref-type="fig" rid="fig3-1064804612444786">Figure 3</xref> shows the Accessibility Home/Main Menu screen after a user activated the large-font mode.</p>
<fig id="fig3-1064804612444786" position="float">
<label>Figure 3.</label>
<caption><p>Accessible Home/Main Menu screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig3.tif"/>
</fig>
<p>Hearing- and vision-impaired expert users at WGBH and the American Foundation for the Blind conducted assessments of the system during its development. They applied functional recommendations derived from the <xref ref-type="bibr" rid="bibr12-1064804612444786">World Wide Web Consortium’s (2008)</xref> <italic>Web Content Accessibility Guidelines</italic> and outlined in <italic>Developer’s Guide to Creating Talking Menus for Set-top Boxes and DVDs</italic> (<xref ref-type="bibr" rid="bibr4-1064804612444786">Goldberg, Wlodkowski, &amp; Schmidt, 2003</xref>) and Accessible Digital Media Guidelines (<xref ref-type="bibr" rid="bibr2-1064804612444786">Freed &amp; Rothberg, 2006</xref>), produced by the WGBH National Center for Accessible Media. Users with a hearing impairment were easily able to use all the accessibility features and understand and operate the caption controls. Expert blind and low-vision users suggested iterative refinements to the screen design, color, contrast ratio, font size, button size, and location, as well as to audio quality and navigation controls.</p>
</sec>
<sec id="section4-1064804612444786">
<title>Prototype Evaluation: Two Rounds of User Testing</title>
<p>Two rounds (Phase 1 and Phase 2) of accessibility and usability testing of the product concept were conducted to gather information and refine the prototype:</p>
<list id="list1-1064804612444786" list-type="bullet">
<list-item><p><italic>Phase 1</italic> combined one-on-one interviews and usability tests utilizing an accessible IFE system prototype. This phase has two parts: pilot testing with two participants at the Media Access Group of WGBH, and testing with six participants at the AFB Tech of the American Foundation for the Blind.</p></list-item>
<list-item><p><italic>Phase 2</italic> utilized 80 volunteers in usability field testing of an accessible IFE system prototype at the American Council of the Blind Convention.</p></list-item>
</list>
<sec id="section5-1064804612444786">
<title>Phase 1 testing: Eight users.</title>
<p>The final prototype was subjected to evaluation by eight technologically adept adult users with sensory disabilities: one deaf, three low-vision, and four blind evaluators. Evaluation was weighted toward users with visual impairments, given that interface solutions required for travelers with hearing impairments related only to on–off controls for captions.</p>
<p>Interaction with different caption control configurations on televisions and Web videos is a daily occurrence for hearing-impaired users, so our formative evaluation revealed no problems with the system among this population. Conversely, the user interface challenges and solutions designed for blind and low-vision users are more complex, and the addition of talking menus and controls does not guarantee successful operation of the system.</p>
<p>Blind users are regularly required to develop a mental model of digital content that is formatted for visual display; they use TTS software that announces item characteristics and provides supplemental audio information. Blind users vary in how they explore on-screen content, but they are all affected by the original design. Effective navigation and comprehension of content can be positively or negatively influenced by the complexity and organization of the visual design and by the clarity of the supplemental audio.</p>
<p>Web sites offer structured content with headings, but IFE systems have unstructured content with idiosyncratic designs and hierarchies. Moreover, not all people who are visually impaired use TTS software or magnification technologies, and those who do can choose among a host of native and external technologies that do not always share common interface designs.</p>
<p>Similarly, there is wide variability in how blind and low-vision users familiarize themselves with new devices, and control mechanisms and orientation strategies vary depending on personal preferences. Regardless of the approach they use to develop a mental model, all blind and low-vision technology users – regardless of age or experience – consistently require greater time on task to orient themselves to different navigation schemes, as they must experience content via listening to audio in a linear sequence (<xref ref-type="bibr" rid="bibr1-1064804612444786">Bigham, Cavender, Brudvik, Wobbrock, &amp; Ladner, 2007</xref>; <xref ref-type="bibr" rid="bibr6-1064804612444786">Lazar, Allen, Kleinman, &amp; Malarkey, 2007</xref>; <xref ref-type="bibr" rid="bibr8-1064804612444786">Neilsen, 2003</xref>). Consequently, visually impaired users were the primary target participants for the usability evaluation.</p>
<p>It is also important to note that an inclusive user interface design would mitigate the time on task for audio-only exploration; however, this prototype was built around a visual design, so our evaluation focused primarily on successful task completion.</p>
<p>Evaluations were performed in individual hands-on, task-centered sessions preceded by questions about IFE and technology use. Of the eight participants, five were familiar with airline in-flight entertainment systems, and three (one low-vision and two blind users) had used one. Two of these three had listened to audio programs, and one played a trivia game aided by a sighted friend. Their experience with these systems, though limited, was generally positive. One vision-impaired participant reported having trouble with confusing armrest satellite radio buttons.</p>
<p>A moderator observed each user as he or she attempted a scripted set of tasks and noted ease of use, areas of confusion, task completion, and user comments and recommendations. Blind and low-vision participants were provided with the five-button EZ Access controller to navigate the system and were allowed time to become familiar with its use. The participant who was deaf used the touch screen.</p>
<p><xref ref-type="table" rid="table1-1064804612444786">Table 1</xref> lists all the tasks that we asked participants to complete and an associated screenshot of the related user interface screen (<xref ref-type="fig" rid="fig4-1064804612444786">Figures 4</xref> to <xref ref-type="fig" rid="fig8-1064804612444786">8</xref>, next page). All participants began the evaluation at the Home/Main Menu screen (<xref ref-type="fig" rid="fig1-1064804612444786">Figure 1</xref>, page X), and all navigated from task to task from whatever screen they were on at the close of the prior task.</p>
<table-wrap id="table1-1064804612444786" position="float">
<label>Table 1.</label>
<caption><p>Evaluation Tasks With the Associated User Interface (UI) Accessibility Screens</p></caption>
<graphic alternate-form-of="table1-1064804612444786" xlink:href="10.1177_1064804612444786-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Evaluation Task</th>
<th align="left">Screenshot of Associated User Interface</th>
</tr>
</thead>
<tbody>
<tr>
<td>Navigate to Accessibility Options screen. Enable different accessibility features.</td>
<td>Accessibility Options screen with large fonts enabled (<xref ref-type="fig" rid="fig4-1064804612444786">Figure 4</xref>)</td>
</tr>
<tr>
<td>Navigate to Music screen. Find a specific album. Find and play a specific song within the album. Pause and then resume listening to the selected song. Stop the song and select a different album. Select a different song.</td>
<td>Music Selection and Tracking (<xref ref-type="fig" rid="fig5-1064804612444786">Figures 5</xref> and <xref ref-type="fig" rid="fig6-1064804612444786">6</xref>)</td>
</tr>
<tr>
<td>Navigate to Movie screen. Find and play a specific movie. Pause and resume playing the movie. Pause mid-movie and turn descriptions (or captions) off and on and resume playing the movie.</td>
<td>Movie Selection (<xref ref-type="fig" rid="fig7-1064804612444786">Figure 7</xref>)</td>
</tr>
<tr>
<td>Navigate to Flight Information screen. Find gate assignment and arrival times for a specific flight. Find gate assignment and on-time or delayed status of a specific connecting flight.</td>
<td>Flight Information (<xref ref-type="fig" rid="fig8-1064804612444786">Figure 8</xref>)</td>
</tr>
</tbody>
</table>
</table-wrap>
<fig id="fig4-1064804612444786" position="float">
<label>Figure 4.</label>
<caption><p>Accessibility options screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig4.tif"/>
</fig>
<fig id="fig5-1064804612444786" position="float">
<label>Figure 5.</label>
<caption><p>Music menu screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig5.tif"/>
</fig>
<fig id="fig6-1064804612444786" position="float">
<label>Figure 6.</label>
<caption><p>Music tracks screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig6.tif"/>
</fig>
<fig id="fig7-1064804612444786" position="float">
<label>Figure 7.</label>
<caption><p>Movie menu screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig7.tif"/>
</fig>
<fig id="fig8-1064804612444786" position="float">
<label>Figure 8.</label>
<caption><p>Connecting gates screen.</p></caption>
<graphic xlink:href="10.1177_1064804612444786-fig8.tif"/>
</fig>
<p>Participants accomplished these tasks with varying degrees of ease. The most challenging tasks were rewinding or resuming playback of content. We recommend the following with regard to the accessibility features:</p>
<list id="list2-1064804612444786" list-type="bullet">
<list-item><p>Provide more comprehensive “help” options specific to using the accessibility features.</p></list-item>
<list-item><p>Make suggestions for enhancements of the high-contrast mode.</p></list-item>
<list-item><p>Use less computer-based nomenclature in navigation options (“captions: check box checked” vs. “captions: on” or “captions: off”).</p></list-item>
</list>
<p>Other problems mentioned by participants stemmed from the eFX user interface design. First, users were confused by two differently labeled screens (Main Menu and Home) that offered the same options. This duplication made it particularly difficult for blind users to develop a working mental model of the hierarchy of the various screens. Some stopped exploring, announcing that they were lost, and simply needed to be told that these screens were duplicative to proceed.</p>
<p>Second, movie and TV controls were hidden and popped up on the screen only when the focus (controlled either via touch screen or via EZ Access device) was moved to the outer edge of the screen.</p>
<p>In addition, users who were unfamiliar with the EZ Access navigation device were somewhat confused by the option either to go back one screen using the “Up Arrow” button or to go back to the Home or Main Menu page by using the round “Back” button. Blind and low-vision users also noted personal preferences for certain TTS voices, and a few commented on the weight of the EZ Access device.</p>
<p>The prototype was generally well received, despite these issues, and participants were able to complete each of the tasks.</p>
</sec>
<sec id="section6-1064804612444786">
<title>Phase 2 testing: 80 users</title>
<p>We refined the prototype to incorporate recommendations related to the accessibility features. The user interface was also revised to make nomenclature consistent and was submitted for further testing at the American Council for the Blind’s annual convention.</p>
<p>We made the system available for individual exploration for 3 days on two identical testing platforms. Eighty consumers (52 blind and 28 low vision) participated in this evaluation. Two moderators worked with participants to introduce the eFX interface and EZ Access device, observed participants at each workstation in independent exploration (15 to 20 minutes per person), and then asked summary questions. Information about these participants and their experience with the prototype is summarized below.</p>
<list id="list3-1064804612444786" list-type="bullet">
<list-item><p>Ninety percent use a speech interface on their computer.</p></list-item>
<list-item><p>Fifty-nine percent have used a speech interface to navigate a commercial service on a kiosk.</p></list-item>
<list-item><p>Eighty-seven percent said it was very easy (69%) or somewhat easy (18%) to navigate the IFE using the speech interface on a 5-point Likert-type scale of effort (<italic>very easy, somewhat easy, average, somewhat difficult</italic>, or <italic>very difficult</italic>).</p></list-item>
<list-item><p>Ninety-five percent said it was very important (69%) or somewhat important (26%) to have independent access to an IFE on a 5-point Likert-type scale of importance.</p></list-item>
</list>
<p>We also asked participants which services they would be most likely to use and to rank those services (music listings, TV listings, movies with description, and flight information). They rated flight information as the most likely service to be used, followed by an even split between music listings and movies with description. TV was chosen as the least likely service. This rating is no doubt affected by the fact that blind viewers are well aware that most television programming is not described, with the exception of a handful of programs and selected PBS programs.</p>
</sec>
</sec>
<sec id="section7-1064804612444786">
<title>Lessons Learned</title>
<p>Overall, user testing confirmed consumers’ ability to use accessibility features to find, enable, and enjoy IFE services and generated great enthusiasm within the community of travelers with disabilities. Usability testing of accessibility features is complicated when accessibility solutions are added after the fact to an existing user interface that relies on visual designs rather than integrated into a new design that accommodates multiple modes of interactions.</p>
<p>In this case, meeting the needs of deaf viewers for captions and caption controls was easily accomplished. However, accessibility enhancements for blind and low-vision users revealed hierarchical navigation contradictions in the Home/Main Menu screens and required workaround solutions for pop-up movie and TV controls, which added to these users’ time on task. Given that increased time on task is already a daily challenge for those who are blind and have low vision, our results support the greater benefit of a universal design approach in the initial development of a user interface.</p>
</sec>
<sec id="section8-1064804612444786">
<title>Looking Forward: Industry Implementation and Recommendations</title>
<p>This project provided policy developers and disability organizations with a model of an accessible IFE system and informed industry about functional requirements as well as user interface design. During the life of the project, two IFE systems offered by Panasonic and the IMS Company implemented captions within their systems. To date, there has been no implementation of an accessible interface for blind users.</p>
<p>Findings also provided recommendations for handling captions and descriptions within technical standards maintained by the World Airlines Entertainment Association (WAEA). These recommendations were published as an accessibility addendum to the <italic>WAEA Specification 0403: Digital Content Delivery Methodology for Airline Inflight Entertainment Systems</italic> (<xref ref-type="bibr" rid="bibr11-1064804612444786">WAEA, 2007</xref>).</p>
<p>We shared the prototype and results of our user testing with the Department of Transportation through demonstrations and formal filings (<xref ref-type="bibr" rid="bibr3-1064804612444786">Goldberg, 2006</xref>). However, the department has yet to issue the long-awaited supplemental notice of proposed rulemaking on accessible IFE systems that was referenced in its 2009 rule. Potential revisions to the ADA to explicitly address access requirements for digital information and services will likely affect this proposed rulemaking. Furthermore, the Federal Communications Commission has established an advisory committee to analyze and make recommendations on implementation requirements and timetables for accessible content, services, and products required by the 21st CVAA. The committee’s working group on set-top box accessibility is cochaired by this project’s principal investigator, Larry Goldberg, who is sharing lessons learned about accessible designs for menu navigation drawn from a number of models, including the IFE prototype described in this article.</p>
<p>If federal accessibility requirements for IFE systems are enacted, our findings will contribute to inclusive designs that will increase the system capacity of the nation’s airlines to better serve travelers with disabilities. Air travel for people with sensory disabilities will include equal access to entertainment and information and will minimize requests for information from other passengers and staff. Access to in-flight information technologies for people with disabilities will promote their full inclusion in society, improve their ability to travel independently, and provide important information during air travel.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other">
<p>This article summarizes usability research and outcomes of a field-initiated development project (#H133G050254) led by Larry Goldberg and funded by the U.S. Department of Education’s National Institute on Disability and Rehabilitation Research aimed at conducting research on barriers and developing solutions that can make in-flight communication and entertainment systems accessible to people with sensory disabilities. The project team extends its appreciation for the expertise of project supporters, including Kate Hunter-Zaworski, director of the National Center for Accessible Transportation at Oregon State University; Mark Uslan, director of AFB Tech; and Amy Salmon, Steven Kaye, and Michael O’Hare, universal design consultants of Tech For All.</p></fn>
</fn-group>
<bio>
<p><bold>Caesar Eghtesadi</bold>, PhD, is founder and president of Tech For All, Inc. (TFA, <ext-link ext-link-type="uri" xlink:href="http://www.TFAConsulting.com">http://www.TFAConsulting.com</ext-link>). TFA is an accessibility and universal design consulting firm providing services to corporations, educational institutions, and government agencies striving to ensure the accessibility and usability of their information and communication technologies. For more than 15 years, he has provided leadership on numerous access technology projects, which include software, Web, and multimedia applications; office equipment; kiosks; medical devices; and telecommunications products. He holds a PhD in applied acoustics from the University of London, United Kingdom. He may be reached at <email>keghtesadi@TFAConsulting.com</email>.</p>
<p><bold>Larry Goldberg</bold> is founding director of the WGBH National Center for Accessible Media (NCAM) and a nationally recognized expert in accessibility solutions for people with disabilities. He led the development of closed-captioning standards now required by the Federal Communications Commission and chaired subcommittees for the Federal Access Board, drafting recommendations for updates of the Section 508 standard. He regularly briefs congressional and regulatory committees on access barriers and opportunities within new media, most recently testifying as an expert witness at hearings before the Subcommittee on Telecommunications and the Internet on the 21st Century Communications and Video Accessibility Act. He may be reached at <email>larry_goldberg@wgbh.org</email>.</p>
<p><bold>Bradley Botkin</bold> is director of technology at the WGBH National Center for Accessible Media. Many of the software solutions and specifications he has developed have resulted in new capabilities within mainstream media technologies that are specifically designed to meet the needs of people with disabilities. He is an active participant in industry groups, working to ensure accessible navigation schemes and standard approaches for carriage and display of captions and description in digital media technologies of all types.</p>
<p><bold>Trisha O’Connell</bold> is director of research and development at the WGBH-Shapiro National Center for Accessible Media (NCAM, <ext-link ext-link-type="uri" xlink:href="http://ncam.wgbh.org/">http://ncam.wgbh.org/</ext-link>) and works to identify access barriers and opportunities in the convergence of technology, media, disability, and education. She has developed and managed numerous projects, prototyping access solutions to mainstream technologies and exploring technology-based educational practices, including a seminal study on the impact of extended description on visually impaired students’ comprehension. She holds an MBA from the Simmons Graduate School of Management.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1064804612444786">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bigham</surname><given-names>J. P.</given-names></name>
<name><surname>Cavender</surname><given-names>A. C.</given-names></name>
<name><surname>Brudvik</surname><given-names>J. T.</given-names></name>
<name><surname>Wobbrock</surname><given-names>J. O.</given-names></name>
<name><surname>Ladner</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2007</year>). <article-title>WebinSitu: A comparative analysis of blind and sighted browsing behavior</article-title>. In <source>Proceedings of the 9th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2007)</source> (pp. <fpage>51</fpage>–<lpage>58</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>.</citation>
</ref>
<ref id="bibr2-1064804612444786">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Freed</surname><given-names>F.</given-names></name>
<name><surname>Rothberg</surname><given-names>M.</given-names></name>
</person-group> (<year>2006</year>). <source>Accessible digital media</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>WGBH National Center for Accessible Media</publisher-name>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://ncam.wgbh.org/invent_build/web_multimedia/accessible-digital-media-guide/">http://ncam.wgbh.org/invent_build/web_multimedia/accessible-digital-media-guide/</ext-link></comment></citation>
</ref>
<ref id="bibr3-1064804612444786">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Goldberg</surname><given-names>L.</given-names></name>
</person-group> (<year>2006</year>). <source>Comments on proposed amendments to rules implementing the Air Carrier Access Act before the Department of Transportation</source> (<comment>Ost Docket No. 2006-23999</comment>). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>WGBH National Center for Accessible Media</publisher-name>.</citation>
</ref>
<ref id="bibr4-1064804612444786">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Goldberg</surname><given-names>L.</given-names></name>
<name><surname>Wlodkowski</surname><given-names>T.</given-names></name>
<name><surname>Schmidt</surname><given-names>C.</given-names></name>
</person-group> (<year>2003</year>). <source>Developer’s guide to creating talking menus for set-top boxes and DVDs</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>WGBH National Center for Accessible Media</publisher-name>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://ncam.wgbh.org/invent_build/analog/talkingmenus/">http://ncam.wgbh.org/invent_build/analog/talkingmenus/</ext-link></comment></citation>
</ref>
<ref id="bibr5-1064804612444786">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Law</surname><given-names>C. M.</given-names></name>
<name><surname>Vanderheiden</surname><given-names>G. C.</given-names></name>
</person-group> (<year>2000</year>). <source>EZ Access for Electronic Devices Version 2.0 implementation guide</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://trace.wisc.edu/world/ez/">http://trace.wisc.edu/world/ez/</ext-link></comment></citation>
</ref>
<ref id="bibr6-1064804612444786">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lazar</surname><given-names>J.</given-names></name>
<name><surname>Allen</surname><given-names>A.</given-names></name>
<name><surname>Kleinman</surname><given-names>J.</given-names></name>
<name><surname>Malarkey</surname><given-names>C.</given-names></name>
</person-group> (<year>2007</year>). <article-title>What frustrates screen reader users on the web: A study of 100 blind users</article-title>. <source>International Journal of HCI</source>, <volume>22</volume>, <fpage>247</fpage>–<lpage>269</lpage>.</citation>
</ref>
<ref id="bibr7-1064804612444786">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lucas</surname><given-names>J. W.</given-names></name>
<name><surname>Schiller</surname><given-names>J. S.</given-names></name>
<name><surname>Benson</surname><given-names>V.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Summary health statistics for U.S. adults: National Health Interview Survey, 2001</article-title>. <source>Vital Health Statistics</source>, <volume>10</volume>(<issue>218</issue>), <fpage>1</fpage>–<lpage>134</lpage>.</citation>
</ref>
<ref id="bibr8-1064804612444786">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Neilsen</surname><given-names>J.</given-names></name>
</person-group> (<year>2003</year>). <source>Alternative interfaces for accessibility</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.useit.com/alertbox/20030407.html">http://www.useit.com/alertbox/20030407.html</ext-link></comment></citation>
</ref>
<ref id="bibr9-1064804612444786">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>O’Connell</surname><given-names>T.</given-names></name>
<name><surname>Goldberg</surname><given-names>L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Universal design in media</article-title>. In <person-group person-group-type="editor">
<name><surname>Preiser</surname><given-names>W. F. E.</given-names></name>
<name><surname>Smith</surname><given-names>K. H.</given-names></name>
<name><surname>Ostroff</surname><given-names>E.</given-names></name>
</person-group> (Eds.), <source>Universal design handbook</source> (<edition>2nd ed.</edition>, chapter 34, pp. 1–9). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</citation>
</ref>
<ref id="bibr10-1064804612444786">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pleis</surname><given-names>J. R.</given-names></name>
<name><surname>Lethbridge-Çejku</surname><given-names>M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Summary health statistics for U.S. adults: National Health Interview Survey</article-title>, <year>2006</year>. <source>Vital Health Statistics</source>, <volume>10</volume>(<issue>235</issue>), <fpage>120</fpage>.</citation>
</ref>
<ref id="bibr11-1064804612444786">
<citation citation-type="book">
<collab>World Airline Entertainment Association</collab>. (<year>2007</year>). <source>WAEA Specification 0403: Digital content delivery methodology for airline inflight entertainment systems. Version 1.0</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr12-1064804612444786">
<citation citation-type="web">
<collab>World Wide Web Consortium</collab>. (<year>2008</year>). <source>Web Content Accessibility Guidelines (WCAG) 2.0: W3C recommendation 11 December 2008</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.w3.org/TR/WCAG20/">http://www.w3.org/TR/WCAG20/</ext-link></comment></citation>
</ref>
</ref-list>
</back>
</article>