<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">LDX</journal-id>
<journal-id journal-id-type="hwp">spldx</journal-id>
<journal-id journal-id-type="nlm-ta">J Learn Disabil</journal-id>
<journal-title>Journal of Learning Disabilities</journal-title>
<issn pub-type="ppub">0022-2194</issn>
<issn pub-type="epub">1538-4780</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0022219409355484</article-id>
<article-id pub-id-type="publisher-id">10.1177_0022219409355484</article-id>
<title-group>
<article-title>Meta-analysis on the Effectiveness of Extra time as a Test Accommodation for Transitioning Adolescents With Learning Disabilities</article-title>
<subtitle>More Questions Than Answers</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Gregg</surname><given-names>Noel</given-names></name>
<xref ref-type="aff" rid="aff1-0022219409355484">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Nelson</surname><given-names>Jason M.</given-names></name>
<xref ref-type="aff" rid="aff2-0022219409355484">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0022219409355484"><label>1</label>University of Georgia, Athens, GA, USA</aff>
<aff id="aff2-0022219409355484"><label>2</label>University of Georgia Regents’ Center for Learning Disorders, Athens, GA, USA</aff>
<author-notes>
<corresp id="corresp1-0022219409355484">Noel Gregg, 331 Milledge Hall, Athens, GA 30602, USA Email: <email>ngregg@uga.edu</email></corresp>
<fn fn-type="other" id="bio1-0022219409355484">
<p>Noel Gregg, PhD, is a Distinguished Research Professor at the University of Georgia, and she is currently serving as the associate dean of research in the College of Education. She is a faculty member in the Department of Communication Sciences and Special Education, and an adjunct professor in psychology (Franklin College of Arts and Sciences) and school psychology (College of Education). Her areas of specialization include adolescents and adults with learning disabilities and AD/HD, accommodations, alternative media, assessment, and written language disorders.</p>
</fn>
<fn fn-type="other" id="bio2-0022219409355484">
<p>Jason M. Nelson, PhD, is head of research and a licensed psychologist at the Regents’ Center for Learning Disorders at the University of Georgia. He is currently interested in issues related to the assessment of college students with learning disabilities and attention-deficit/hyperactivity disorder.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2012</year>
</pub-date>
<volume>45</volume>
<issue>2</issue>
<fpage>128</fpage>
<lpage>138</lpage>
<permissions>
<copyright-statement>© Hammill Institute on Disabilities 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Hammill Institute on Disabilities</copyright-holder>
</permissions>
<abstract>
<p>The accommodation of students with learning disabilities (LD) on mandatory high stakes tests continues to heighten concern over the equity and effectiveness of current practices. As students transition from high school, they are required to complete timed graduation tests and postsecondary entrance examinations. The most common accommodation accessed by transitioning adolescents with LD is extended time. In order to inform test accommodation practices, a meta-analysis was conducted to address whether test scores from accommodated (i.e., extended time only) and standard test administrations are comparable for transitioning adolescents with LD as compared to their normally achieving peers. The results of the meta-analyses raised more questions than answers and highlighted the need for future research in this area.</p>
</abstract>
<kwd-group>
<kwd>accommodations</kwd>
<kwd>transition</kwd>
</kwd-group>
<custom-meta-wrap>
<custom-meta>
<meta-name>cover-date</meta-name>
<meta-value>March/April 2012</meta-value>
</custom-meta>
</custom-meta-wrap>
</article-meta>
</front>
<body>
<p>Standards-based reform and professional licensing has led to an increase in large-scale assessments as the gatekeeper for promotion, graduation, and career attainment. These high-stakes tests are increasingly central to accountability across the life span. The accommodation of students with learning disabilities (LD) on mandatory high-stakes tests continues to heighten concern over the equity and effectiveness of specific types of accommodations. As students transition from high school, they are often required to complete timed graduation exit tests and postsecondary entrance examinations. The most common accommodation accessed by these transitioning adolescents with LD is extended time (<xref ref-type="bibr" rid="bibr13-0022219409355484">Gregg, 2009</xref>; <xref ref-type="bibr" rid="bibr24-0022219409355484">Ofiesh, Hughes, &amp; Scott, 2004</xref>).</p>
<p>Testing agencies report an ever increasing number of students with LD requesting the accommodation of extended time. Between 1998 and 2003, requests for extra time on the <italic>Scholastic Aptitude Test</italic> (SAT) grew about 26% (<xref ref-type="bibr" rid="bibr6-0022219409355484">Bridgeman, Trapani, &amp; Curley, 2003</xref>). This pattern of an increase in the request by students with LD to access extended time on standardized tests has also been observed across graduate and licensure examinations (e.g., GRE, GMAT, LSAT, MCAT). Recently, the Educational Testing Service (ETS) received over 10,000 requests for accommodations on its graduate examinations (<xref ref-type="bibr" rid="bibr7-0022219409355484">Brinckerhoff &amp; Banerjee, 2007</xref>).</p>
<sec id="section1-0022219409355484">
<title>Effectiveness of Accommodations</title>
<p>Accommodations are assumed to have a beneficial influence on the test scores of examinees receiving them, but not to provide accommodated individuals with an advantage (<xref ref-type="bibr" rid="bibr30-0022219409355484">Sireci &amp; Parker, 2005</xref>). Some researchers propose the <italic>interaction hypothesis</italic> be used to interpret score comparability. This hypothesis purports that an accommodation should only benefit the test scores for examinees who need the accommodation, but not for those individuals who do not need the accommodation (<xref ref-type="bibr" rid="bibr33-0022219409355484">Zuriff, 2000</xref>). Therefore, advocates of the hypothesis claim that any improvement by examinees without disabilities taking a test with accommodations challenges the validity of accommodated tests. Rather than using such a restricted criterion, <xref ref-type="bibr" rid="bibr12-0022219409355484">Fuchs and Fuchs (1999)</xref> suggested applying the <italic>differential boost hypothesis</italic> to address the validity of test accommodations. According to this hypothesis, accommodations should improve the performance of students with disabilities to a “significantly greater extent” than it improves the performance of students without disabilities (<xref ref-type="bibr" rid="bibr12-0022219409355484">Fuchs &amp; Fuchs, 1999</xref>).</p>
</sec>
<sec id="section2-0022219409355484">
<title>Specificity of Population</title>
<p>A major limitation of many studies pertaining to the effectiveness of extended time on the test performance of examinees is that the participants investigated are often defined as “students with disabilities.” The moderating effect for type of disability on test performance under timed and untimed conditions has received very little research attention (<xref ref-type="bibr" rid="bibr29-0022219409355484">Sireci, 2004</xref>; <xref ref-type="bibr" rid="bibr32-0022219409355484">Tindal &amp; Ketterlin-Geller, 2004</xref>). In addition, information pertaining to examinees’ severity of disability, cognitive and achievement profiles, and educational background is often not reported or controlled for by authors (<xref ref-type="bibr" rid="bibr13-0022219409355484">Gregg, 2009</xref>).</p>
</sec>
<sec id="section3-0022219409355484">
<title>Purpose of Study and Research Questions</title>
<p>The primary purpose of this meta-analysis was to evaluate the empirical-based literature on the effectiveness of extended time during testing specific to the transitioning population of adolescents with LD. Though previous narrative reviews of this literature have been conducted (e.g., <xref ref-type="bibr" rid="bibr31-0022219409355484">Sireci, Scarpati, &amp; Li, 2005</xref>; <xref ref-type="bibr" rid="bibr33-0022219409355484">Zuriff, 2000</xref>), this study is the first to use meta-analytic techniques to quantify the magnitude of the differences in test performance, if any, as a result of extended time between transitioning students with LD and typically achieving students. Meta-analysis allows for a more thorough understanding of the practical significance of findings in the extant literature than narrative review through its use of effect size (ES) to quantify the magnitude of potential differences (<xref ref-type="bibr" rid="bibr17-0022219409355484">Kavale, 1984</xref>).</p>
<p>In order to inform test accommodation practices for transitioning adolescents with LD, we sought to answer the following question: Are test scores from accommodated (i.e., extended time only) and standard test administrations comparable for transitioning adolescents with LD and their typically achieving peers? To answer this question, we made five comparisons, including comparing the performance of: (a) students with LD given an extended time administration to typically achieving students given a standard administration, (b) students with LD given an extended time administration to typically achieving students given an extended time administration, (c) students with LD given a standard administration to typically achieving students given a standard administration, (d) students with LD given both standard and extended time administrations, and (e) typically achieving students given both standard and extended time administrations. Secondary research questions included: (a) Does the type of test content (i.e., reading or mathematics) affect the test performance of transitioning adolescents with and without LD on accommodated (i.e., extended time only) and standard administrations? and (b) Does the type of test (e.g., entrance or diagnostic) affect test performance of transitioning adolescents with and without LD on accommodated (i.e., extended time only) and standard administrations?</p>
</sec>
<sec id="section4-0022219409355484" sec-type="methods">
<title>Method</title>
<sec id="section5-0022219409355484">
<title>Identification of Studies</title>
<p>First, a computer search of the PsychINFO database was conducted. The search located over 2,300 studies. The descriptors used included: LD and accommodations (approximately 10 hits), LD filtered by adolescent age group (approximately 1,200 hits), and LD filtered by adult age group (approximately 1,100 hits). In addition, to ensure articles were not overlooked, searches were conducted on MEDLine and ERIC databases. Next, a search was conducted of journals where the majority of the articles were found and in journals related to any of the following topics: adolescent and adult learners; literacy; adolescents or adults with LD; learning disabilities; testing; accommodations; and measurement (see <xref ref-type="app" rid="app1-0022219409355484">Appendix</xref>). A hand search of the past 10 years of these journals was conducted. In addition, a review of specific Web sites determined to be related to accommodation policies and practices was completed to identify any research not found in the database searches (see <xref ref-type="app" rid="app1-0022219409355484">Appendix</xref>). Finally, published literature reviews specific to the accommodation of individuals with disabilities were identified (nine) and the research articles in these reviews were compared to the list from the database searches. All studies must have been published in peer-reviewed journals or a technical research document of one of the major test publishers. No dissertations or ERIC documents were included in the analysis.</p>
</sec>
<sec id="section6-0022219409355484">
<title>Criteria for Inclusion</title>
<p>For the first review, 132 studies were determined relevant. These 132 studies were then evaluated to determine if they met the following specific inclusion criteria: (a) The participants were in ninth grade and higher or their age ranges were 14 or older in years, (b) the participants with disabilities must have received the diagnosis of LD, and (c) the sample size for participants with or without LD had to be greater than nine. While single-participant designs were reviewed, they were not part of the meta-analyses; (d) the only types of academic skills investigated were reading, written expression, or mathematics. No studies related to foreign language accommodations were included in the study; (e) the study investigated extended time in isolation of any other accommodations provided examinees; (f) the study was published in a refereed journal or technical manual or report of a testing company; and (g) necessary statistics were available for calculating effect size.</p>
</sec>
<sec id="section7-0022219409355484">
<title>Coding Procedure</title>
<p>Using these criteria, only 9 studies were identified for the next stage of analysis after reviewing all of the 132 articles. Several studies met some but not all of these criteria and could not be included in the meta-analysis. For instance, in the literature, a study by <xref ref-type="bibr" rid="bibr28-0022219409355484">Runyan (1991)</xref> is often used to provide evidence for the effectiveness of extended time on the performance of college students with LD. However, Runyan reported average percentile scores. Because percentile scores should not be averaged, calculating an effect size from these results is also impermissible. The following information for each of the 9 studies was coded:</p>
<list id="list1-0022219409355484" list-type="order">
<list-item><p>Attributes of the study: Each study was coded for (a) the year of the study, (b) the name of the authors, and (c) the title of the study.</p></list-item>
<list-item><p>Attributes of the academic skill investigated: Each study was coded into one of the following categories: (a) reading, (b) math, and (c) written language. The Verbal section of the SAT was coded as a reading measure.</p></list-item>
<list-item><p>Attributes of the population: Each study was first coded as to what type of institution or situation best described the participants: (a) secondary, (b) postsecondary entrance exams, (c) adult basic education or GED, (d) community or technical college, (e) higher education undergraduate, (f) higher education graduate, and (g) postgraduate. Second, the age categories of the participants were coded. Third, the number and gender of participants with and without LD were coded. Finally, information pertaining to the educational and language background of participants was coded.</p></list-item>
<list-item><p>Each study was coded as to the type of LD that participants demonstrated, including: (a) general (no type identified), (b) reading, (c) math, (d) written language, and (e) other. In addition, the study was coded as to whether current functioning was provided about the participants: (a) none, (b) cognitive, (c) achievement, (d) social/emotional, and (e) other.</p></list-item>
<list-item><p>Attributes of the eligibility criteria: Each study was coded as to whether the specific type of eligibility criteria used to identify the population with LD was provided in the article. The codes included: (a) Individuals with Disabilities Education Act (IDEA) with no criteria, (b) discrepancy, (c) cutoff, (d) clinical, and (e) none.</p></list-item>
<list-item><p>Attributes of the methodology and design: Each study was coded as to the type of research design used, including: (a) experimental, (b) quasi-experimental, (c) nonexperimental, and (d) other. Second, the type of methodology used was coded in the following categories: (a) AVOVA, (b) MANOVA, (c) regression, (d) confirmatory factory analysis (CFA), (e) differential item response (DIF), (f) meta-analysis, and (g) other.</p></list-item>
</list>
</sec>
<sec id="section8-0022219409355484">
<title>Interrater Agreement</title>
<p>Two raters coded the studies. The interrater agreement for article inclusion in the analysis was 100%. The interrater agreement across all attributes described previously yielded a reliable percentage of greater than 90% agreement.</p>
</sec>
<sec id="section9-0022219409355484">
<title>Analyses of Effect Sizes</title>
<p>The comprehensive meta-analysis (<xref ref-type="bibr" rid="bibr5-0022219409355484">Biostat, 2000</xref>) computer program was used to conduct all analyses. Effect sizes were computed using the mean test scores and standard deviations of the groups. If means and standard deviations were not reported in the studies, other data (e.g., <italic>t</italic>-test statistics) were used to estimate effect sizes. Cohen’s <italic>d</italic> was calculated for each analysis. Hedge’s <italic>g</italic> was also calculated because it corrects for bias of <italic>d</italic> when small samples are used (<xref ref-type="bibr" rid="bibr15-0022219409355484">Hedges, 1981</xref>). Because these effect sizes were virtually identical in the current study, only <italic>d</italic> is reported due to its customary use in other meta-analyses. Confidence intervals (95%) were calculated to determine the statistical significance of effect sizes. Confidence intervals that do not include zero indicate statistical significance.</p>
<p>When more than one effect size could be calculated per study, each effect size was calculated; the mean of the effect sizes for each study was then computed, and the overall effect size was included in the analysis. This procedure prevented violation of the assumption of independent data points. Violating this assumption results in the allotment of undue weight to those studies with multiple effect sizes (<xref ref-type="bibr" rid="bibr21-0022219409355484">Lipsey &amp; Wilson, 2001</xref>).</p>
<p>Analyses were also investigated for homogeneity. The <italic>Q</italic><sub>w</sub> statistic indicated whether the effect sizes used to compute a mean effect size for each of the current study’s analyses was representative of the same population distribution. Analyses of potential moderator variables were conducted for those analyses in which a statistically significant <italic>Q</italic><sub>w</sub> was found and enough effect sizes were available to reliably examine the moderating effect. When these conditions were met, <italic>Q</italic><sub>b</sub> was computed using a mixed effects model. A significant <italic>Q</italic><sub>b</sub> indicates that some of the heterogeneity is explained by the moderating variable. A mixed effects model instead of a fixed effects model was used because the former has been found to be superior when heterogeneity exists within an effect size distribution (<xref ref-type="bibr" rid="bibr26-0022219409355484">Overton, 1998</xref>). Within a mixed effects model, the effect size variance that is not explained by the moderating variable and sampling error is appropriately apportioned into the weighting function of the analysis (<xref ref-type="bibr" rid="bibr21-0022219409355484">Lipsey &amp; Wilson, 2001</xref>). The current study examined the potential moderating variables of type of test (i.e., SAT vs. non-SAT) and academic skill area (i.e., reading/writing vs. math). Before conducting the analyses, the effect size distributions were examined for potential outliers by calculating standardized residuals. Values greater than three were determined to be outliers because standardized residuals of this magnitude are rare (<xref ref-type="bibr" rid="bibr16-0022219409355484">Hedges &amp; Olkin, 1985</xref>). No outliers were detected.</p>
</sec>
</sec>
<sec id="section10-0022219409355484" sec-type="results">
<title>Results</title>
<p>The first part of our study included the coding of descriptive information about the studies as a means of placing the meta-analysis in context and allowing for a better understanding of our results. While only transitioning students with LD were included in the meta-analysis, we were interested in the degree of specificity provided to describe these populations. For instance, what degree of descriptive information (i.e., nonexperimental data) was provided by the authors of the studies?</p>
<sec id="section11-0022219409355484">
<title>Population Specificity</title>
<p>To address the influence of population specificity, two approaches were taken in this study. First, only adolescents and adults with LD were included in our investigation to control for the influence of disability on outcomes. Second, we coded each study for the degree of specificity provided by authors pertaining to the examinees studied (see <xref ref-type="table" rid="table1-0022219409355484">Table 1</xref>). Concern over inadequacies in research reporting has long been a concern in the field of LD. In an extensive review of the literature, <xref ref-type="bibr" rid="bibr18-0022219409355484">Keogh, Major, Omori, Gandar, and Reid (1980)</xref> identified three categories of descriptive information that they suggest be reported in empirical-based studies including populations with LD. The findings of this landmark study are still relevant today. Keogh et al. labeled their categories <italic>marker variables</italic> and included the following types: subject, substantive, and topical markers. The subject markers they suggest researchers always report about participants include: number, gender, socioeconomic status (SES), setting of the study, language and educational background, and eligibility criteria used for identification of LD. Substantive markers refer to the ability and achievement scores documenting current functioning of populations investigated. Topical markers provide the current cognitive and linguistic processing abilities of the populations studied.</p>
<table-wrap id="table1-0022219409355484" position="float">
<label>Table 1.</label>
<caption>
<p>Descriptive Variables Reported in Studies</p>
</caption>
<graphic alternate-form-of="table1-0022219409355484" xlink:href="10.1177_0022219409355484-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Study</th>
<th align="center">Age</th>
<th align="center">Gender</th>
<th align="center">Ethnicity</th>
<th align="center">Socioeconomic status</th>
<th align="center">Cognitive/achievement (nonexperimental)</th>
<th align="center">Behavioral/emotional (nonexperimental)</th>
<th align="center">Learning disability eligibility criteria</th>
</tr>
</thead>
<tbody>
<tr>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr3-0022219409355484">Braun, Rogosta, and Kaplan (1986)</xref></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr8-0022219409355484">Cahalan, Mandinach, and Camara (2002)</xref></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr9-0022219409355484">Camara, Copeland, and Rothchild (1998)</xref></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr10-0022219409355484">A. Cohen, Gregg, and Deng (2005)</xref></td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux, Pearson, and Siegel (2006)</xref></td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr20-0022219409355484">Lindstrom and Gregg (2007)</xref></td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh, Mather, and Russell (2005)</xref></td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><xref ref-type="bibr" rid="bibr27-0022219409355484">Ragosta, Braun, and Kaplan (1991)</xref></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Our coding system, described previously, provided information about the studies used in the meta-analysis on many of the marker variables suggested by <xref ref-type="bibr" rid="bibr18-0022219409355484">Keogh et al. (1980)</xref> as essential to include when reporting research. The marker variables we coded included: subject markers (number, age, gender, grade, year of study, setting, and eligibility criteria), substantive markers (current general ability, academic abilities, and social/emotional characteristics), and topical markers (current cognitive and linguistic processing abilities). Of the nine studies included in our meta-analysis, only one reported any substantive or topical marker variables. Two studies included substantive and topical information, but this information was used to answer research questions. Most disturbing, just three studies clearly identified the eligibility criteria used to identify the population with LD. Five of the nine studies investigated the performance of examinees with and without LD using extended time on the <italic>Scholastic Aptitude Test</italic> or the current revised <italic>SAT Reasoning Test</italic> college entrance examination.</p>
</sec>
<sec id="section12-0022219409355484">
<title>Meta-Analysis Comparisons</title>
<p>Five meta-analytic comparisons were made to investigate the current study’s research questions. Three comparisons were between groups, including comparing (a) the scores of students with LD provided accommodations to those of typically achieving students administered a standard version of the test, (b) the test scores of students with LD provided accommodations to the scores of typically achieving students provided accommodations, and (c) the test scores of students with LD administered a standard version of the test to those of typically achieving students administered a standard version of the test. Two within-group comparisons were conducted, including comparing (a) the scores of students with LD administered a standard version of a test compared to their scores on an accommodated version of the test and (b) the scores of typically achieving students administered a standard version of a test compared to their scores on an accommodated version of the test. <xref ref-type="table" rid="table2-0022219409355484">Table 2</xref> displays the effect sizes and other characteristics of each of these analyses. For the between-groups comparison, a negative effect size indicated that the typically achieving students outperformed the students with LD. For the within-group analyses, a positive effect size indicated that the groups scored higher on the accommodated version of the test. Effect sizes are interpreted in accordance with <xref ref-type="bibr" rid="bibr11-0022219409355484">J. Cohen’s (1988)</xref> guidelines that those ranging from .20 to .49, .50 to .79, and .80 and above should be regarded as small, medium, and large, respectively.</p>
<table-wrap id="table2-0022219409355484" position="float">
<label>Table 2.</label>
<caption>
<p>Summary of Effect Sizes</p>
</caption>
<graphic alternate-form-of="table2-0022219409355484" xlink:href="10.1177_0022219409355484-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Comparison</th>
<th align="center"><italic>N</italic></th>
<th align="center"><italic>k</italic></th>
<th align="center">ES</th>
<th align="center">95% confidence interval lower</th>
<th align="center">95% confidence interval upper</th>
<th align="center"><italic>Q</italic><sub>w</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>LD Accomm./Typical Stand.<sup><xref ref-type="table-fn" rid="table-fn2-0022219409355484">a</xref></sup></td>
<td>9</td>
<td>21</td>
<td>−.41</td>
<td>−0.61</td>
<td>−0.21</td>
<td>298.95<xref ref-type="table-fn" rid="table-fn7-0022219409355484">*</xref></td>
</tr>
<tr>
<td>LD Accom./Typical Accom.<sup><xref ref-type="table-fn" rid="table-fn3-0022219409355484">b</xref></sup></td>
<td>3</td>
<td>3</td>
<td>−.69</td>
<td>−1.11</td>
<td>−0.27</td>
<td>4.47</td>
</tr>
<tr>
<td>LD Stand./Typical Stand.<sup><xref ref-type="table-fn" rid="table-fn4-0022219409355484">c</xref></sup></td>
<td>6</td>
<td>11</td>
<td>−.86</td>
<td>−1.09</td>
<td>−0.64</td>
<td>29.54<xref ref-type="table-fn" rid="table-fn7-0022219409355484">*</xref></td>
</tr>
<tr>
<td>LD Stand./LD Accom.<sup><xref ref-type="table-fn" rid="table-fn5-0022219409355484">d</xref></sup></td>
<td>3</td>
<td>4</td>
<td>.90</td>
<td>0.29</td>
<td>1.52</td>
<td>27.15<xref ref-type="table-fn" rid="table-fn7-0022219409355484">*</xref></td>
</tr>
<tr>
<td>Typical Stand./Typical Accom.<sup><xref ref-type="table-fn" rid="table-fn6-0022219409355484">e</xref></sup></td>
<td>2</td>
<td>2</td>
<td>.66</td>
<td>0.16</td>
<td>1.16</td>
<td>3.02</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0022219409355484">
<p>Note: <italic>N</italic> = total studies; <italic>k</italic> = total effect sizes; ES = mean effect size (Cohen’s <italic>d</italic>); <italic>Q</italic><sub>w</sub> = statistic of test of homogeneity.</p>
</fn>
<fn id="table-fn2-0022219409355484">
<label>a</label>
<p>Scores of students with learning disabilities (LD) given accommodations compared to the scores of typically achieving students given standardized administration.</p>
</fn>
<fn id="table-fn3-0022219409355484">
<label>b</label>
<p>Scores of students with LD given accommodations compared to the scores of typically achieving students given accommodations.</p>
</fn>
<fn id="table-fn4-0022219409355484">
<label>c</label>
<p>Scores of students with LD given standardized administration compared to typically achieving students given standardized administration.</p>
</fn>
<fn id="table-fn5-0022219409355484">
<label>d</label>
<p>Scores of students with learning disabilities given standardized administration compared to scores when given accommodations.</p>
</fn>
<fn id="table-fn6-0022219409355484">
<label>e</label>
<p>Scores of typically achieving students given standardized administration compared to scores when given accommodations.</p>
</fn>
<fn id="table-fn7-0022219409355484">
<label>*</label>
<p><italic>p</italic> &lt; .01.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<sec id="section13-0022219409355484">
<title>LD accommodated versus typical standard</title>
<p>As shown in <xref ref-type="table" rid="table2-0022219409355484">Table 2</xref>, results of this comparison indicated a small effect size. The confidence interval does not include 0 and therefore indicates statistical significance. Typically achieving students administered standard versions of the test outperformed students with LD who were provided accommodations on the same tests. <xref ref-type="table" rid="table3-0022219409355484">Table 3</xref> displays each of the studies included in this analysis and indicates that eight of nine studies resulted in effect sizes in a negative direction. Also apparent in <xref ref-type="table" rid="table3-0022219409355484">Table 3</xref> is a wide range of effect sizes (−.96 to .04). Not surprisingly, the <italic>Q</italic><sub>w</sub> statistic for this analysis was found to be significant (see <xref ref-type="table" rid="table2-0022219409355484">Table 2</xref>), indicating heterogeneous results and need for the examination of potential moderating variables.</p>
<table-wrap id="table3-0022219409355484" position="float">
<label>Table 3.</label>
<caption>
<p>Effects Sizes for Each Study Included in Each Comparison</p>
</caption>
<graphic alternate-form-of="table3-0022219409355484" xlink:href="10.1177_0022219409355484-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Comparison</th>
<th align="center">Study</th>
<th align="center">ES</th>
<th align="center">Measure</th>
<th align="center">LD <italic>N</italic></th>
<th align="center">Typical <italic>N</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>LD Accomm./Typical Stand.<sup><xref ref-type="table-fn" rid="table-fn9-0022219409355484">a</xref></sup></td>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>−0.02</td>
<td>Algebra</td>
<td>44</td>
<td>44</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr3-0022219409355484">Braun, Ragosta, and Kaplan (1986)</xref></td>
<td>−0.37</td>
<td>SAT</td>
<td>574</td>
<td>6,448</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr8-0022219409355484">Cahalan, Mandinach, and Camara (2002)</xref></td>
<td>−0.39</td>
<td>SAT</td>
<td>241</td>
<td>33,771</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr9-0022219409355484">Camara, Copeland, and Rothchild (1998)</xref></td>
<td>−0.48</td>
<td>SAT</td>
<td>9,099</td>
<td>70,6537</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr10-0022219409355484">A. Cohen, Gregg, and Deng (2005)</xref></td>
<td>−0.96</td>
<td>State Math</td>
<td>1,250</td>
<td>1,250</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux, Pearson, and Siegel (2006)</xref></td>
<td>0.04</td>
<td>NDRT</td>
<td>22</td>
<td>22</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr20-0022219409355484">Lindstrom and Gregg (2007)</xref></td>
<td>−0.13</td>
<td>SAT</td>
<td>2,476</td>
<td>2,476</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh, Mather, and Russell (2005)</xref></td>
<td>−0.70</td>
<td>NDRT</td>
<td>43</td>
<td>41</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr27-0022219409355484">Ragosta, Braun, and Kaplan (1991)</xref></td>
<td>−0.36</td>
<td>SAT</td>
<td>411</td>
<td>4,801</td>
</tr>
<tr>
<td>LD Accom./Typical Accom.<sup><xref ref-type="table-fn" rid="table-fn10-0022219409355484">b</xref></sup></td>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>−0.32</td>
<td>Algebra</td>
<td>44</td>
<td>44</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al. (2006)</xref></td>
<td>−0.88</td>
<td>NDRT</td>
<td>22</td>
<td>22</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh et al. (2005)</xref></td>
<td>−0.94</td>
<td>NDRT</td>
<td>43</td>
<td>41</td>
</tr>
<tr>
<td>LD Stand./Typical Stand.<sup><xref ref-type="table-fn" rid="table-fn11-0022219409355484">c</xref></sup></td>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>−1.13</td>
<td>Algebra</td>
<td>44</td>
<td>44</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr3-0022219409355484">Braun et al. (1986)</xref></td>
<td>−0.51</td>
<td>SAT</td>
<td>574</td>
<td>6,448</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr9-0022219409355484">Camara et al. (1998)</xref></td>
<td>−0.78</td>
<td>SAT</td>
<td>9,099</td>
<td>706,537</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al. (2006)</xref></td>
<td>−1.69</td>
<td>NDRT</td>
<td>22</td>
<td>22</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr27-0022219409355484">Ragosta et al. (1991)</xref></td>
<td>−0.56</td>
<td>SAT</td>
<td>411</td>
<td>4,801</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh et al. (2005)</xref></td>
<td>−1.45</td>
<td>NDRT</td>
<td>43</td>
<td>41</td>
</tr>
<tr>
<td>LD Stand./LD Accom.<sup><xref ref-type="table-fn" rid="table-fn12-0022219409355484">d</xref></sup></td>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>0.85</td>
<td>Algebra</td>
<td>44</td>
<td>n/a</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr9-0022219409355484">Camara et al. (1998)</xref></td>
<td>0.41</td>
<td>SAT</td>
<td>9,099</td>
<td>n/a</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al. (2006)</xref></td>
<td>1.57</td>
<td>NDRT</td>
<td>22</td>
<td>n/a</td>
</tr>
<tr>
<td>Typical Stand./Typical Accom.<sup><xref ref-type="table-fn" rid="table-fn13-0022219409355484">e</xref></sup></td>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>0.44</td>
<td>Algebra</td>
<td>n/a</td>
<td>44</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al. (2006)</xref></td>
<td>0.95</td>
<td>NDRT</td>
<td>n/a</td>
<td>22</td>
</tr>
<tr>
<td>SAT versus Non-SAT</td>
<td><xref ref-type="bibr" rid="bibr3-0022219409355484">Braun et al. (1986)</xref></td>
<td>−0.37</td>
<td>SAT</td>
<td>574</td>
<td>6,448</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr8-0022219409355484">Cahalan et al. (2002)</xref></td>
<td>−0.39</td>
<td>SAT</td>
<td>241</td>
<td>33,771</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr9-0022219409355484">Camara et al. (1998)</xref></td>
<td>−0.48</td>
<td>SAT</td>
<td>9,099</td>
<td>706,537</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr20-0022219409355484">Lindstrom and Gregg (2007)</xref></td>
<td>−0.13</td>
<td>SAT</td>
<td>2,476</td>
<td>2,476</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr27-0022219409355484">Ragosta et al. (1991)</xref></td>
<td>−0.36</td>
<td>SAT</td>
<td>411</td>
<td>4,801</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>−0.02</td>
<td>Non-SAT</td>
<td>44</td>
<td>44</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr10-0022219409355484">A. Cohen et al. (2005)</xref></td>
<td>−0.96</td>
<td>Non-SAT</td>
<td>1,250</td>
<td>1,250</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al. (2006)</xref></td>
<td>0.04</td>
<td>Non-SAT</td>
<td>22</td>
<td>22</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh et al. (2005)</xref></td>
<td>−0.70</td>
<td>Non-SAT</td>
<td>43</td>
<td>41</td>
</tr>
<tr>
<td>Reading versus Math</td>
<td><xref ref-type="bibr" rid="bibr1-0022219409355484">Alster (1997)</xref></td>
<td>−0.02</td>
<td>Math</td>
<td>44</td>
<td>44</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr3-0022219409355484">Braun et al. (1986)</xref></td>
<td>−0.24</td>
<td>Math</td>
<td>574</td>
<td>6,448</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr8-0022219409355484">Cahalan et al. (2002)</xref></td>
<td>−0.42</td>
<td>Math</td>
<td>241</td>
<td>33,771</td>
</tr>
<tr>
<td/>
<td>Camara et al. (2002)</td>
<td>−0.53</td>
<td>Math</td>
<td>9,099</td>
<td>706,537</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr10-0022219409355484">A. Cohen et al. (2005)</xref></td>
<td>−0.96</td>
<td>Math</td>
<td>1,250</td>
<td>1,250</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr20-0022219409355484">Lindstrom and Gregg (2007)</xref></td>
<td>−0.10</td>
<td>Math</td>
<td>2,476</td>
<td>2,476</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr27-0022219409355484">Ragosta et al. (1991)</xref></td>
<td>−0.23</td>
<td>Math</td>
<td>411</td>
<td>4,801</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr3-0022219409355484">Braun et al. (1986)</xref></td>
<td>−0.49</td>
<td>Reading</td>
<td>574</td>
<td>6,448</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr8-0022219409355484">Cahalan et al. (2002)</xref></td>
<td>−0.36</td>
<td>Reading</td>
<td>241</td>
<td>33,771</td>
</tr>
<tr>
<td/>
<td>Camara et al. (2002)</td>
<td>−0.43</td>
<td>Reading</td>
<td>9,099</td>
<td>706,537</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr20-0022219409355484">Lindstrom and Gregg (2007)</xref></td>
<td>−0.15</td>
<td>Reading</td>
<td>2,476</td>
<td>2,476</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh et al. (2005)</xref></td>
<td>−0.70</td>
<td>Reading</td>
<td>43</td>
<td>41</td>
</tr>
<tr>
<td/>
<td><xref ref-type="bibr" rid="bibr27-0022219409355484">Ragosta et al. (1991)</xref></td>
<td>−0.49</td>
<td>Reading</td>
<td>411</td>
<td>4,801</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn8-0022219409355484">
<p>Note: ES = effect size (Cohen’s <italic>d</italic>); SAT = <italic>Scholastic Aptitude Test</italic>; State Math = state-mandated mathematics test; NDRT = <italic>Nelson-Denny Reading Test.</italic></p>
</fn>
<fn id="table-fn9-0022219409355484">
<label>a</label>
<p>Scores of students with learning disabilities (LD) given accommodations compared to the scores of typically achieving students given standardized administration.</p>
</fn>
<fn id="table-fn10-0022219409355484">
<label>b</label>
<p>Scores of students with LD given accommodations compared to the scores of typically achieving students given accommodations.</p>
</fn>
<fn id="table-fn11-0022219409355484">
<label>c</label>
<p>Scores of students with LD given standardized administration compared to typically achieving students given standardized administration.</p>
</fn>
<fn id="table-fn12-0022219409355484">
<label>d</label>
<p>Scores of students with learning disabilities given standardized administration compared to scores when given accommodations.</p>
</fn>
<fn id="table-fn13-0022219409355484">
<label>e</label>
<p>Scores of typically achieving students given standardized administration compared to scores when given accommodations.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Two moderator variables were examined: (a) type of test and (b) academic skill area. For the first analysis, the effect size distributions of studies using the SAT as a dependent variable were compared to those of studies that incorporated other tests (e.g., the <italic>Nelson-Denny Reading Test</italic>). The second analysis compared those studies investigating performance on reading/writing tests to those that incorporated math tests. <xref ref-type="table" rid="table4-0022219409355484">Table 4</xref> displays the results of these analyses.</p>
<table-wrap id="table4-0022219409355484" position="float">
<label>Table 4.</label>
<caption>
<p>Analysis of Moderator Variables</p>
</caption>
<graphic alternate-form-of="table4-0022219409355484" xlink:href="10.1177_0022219409355484-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Moderator variable</th>
<th align="center">Subgroup</th>
<th align="center">ES</th>
<th align="center"><italic>Q</italic><sub>b</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td>Type of test</td>
<td>SAT</td>
<td>−.34</td>
<td/>
</tr>
<tr>
<td/>
<td>Non-SAT</td>
<td>−.56</td>
<td>1.76</td>
</tr>
<tr>
<td>Academic skill area</td>
<td>Reading/writing</td>
<td>−.38</td>
<td/>
</tr>
<tr>
<td/>
<td>Math</td>
<td>−.38</td>
<td>0.00</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn14-0022219409355484">
<p>Note: Moderator effects computed using a random effects model.</p>
</fn>
<fn id="table-fn15-0022219409355484">
<p>ES = effect size (Cohen’s <italic>d</italic>); <italic>Q</italic><sub>b</sub> = statistic for between-class effect; SAT = <italic>Scholastic Aptitude Test</italic>; non-SAT = tests used in included studies that were not the SAT.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The <italic>Q</italic><sub>b</sub> statistics for both analyses were not statistically significant, indicating the hypothesized moderating variables did not reliably explain the heterogeneity found in the initial analysis. As shown in <xref ref-type="table" rid="table4-0022219409355484">Table 4</xref>, the effect size was small when comparing the scores of students with LD provided accommodations on the SAT compared to typically achieving students who took a standard version of the SAT. Results indicated that the effect size was medium when non−SAT tests were examined. The effect sizes for both reading/writing and math were small.</p>
</sec>
<sec id="section14-0022219409355484">
<title>LD accommodated versus typical accommodated</title>
<p><xref ref-type="table" rid="table2-0022219409355484">Table 2</xref> shows that only three studies were identified that allowed for this comparison. Results indicated that typically achieving students provided test accommodations outperformed students with LD provided the same accommodations. The effect size was medium and the difference between the groups was statistically significant. As displayed in <xref ref-type="table" rid="table2-0022219409355484">Table 2</xref>, the <italic>Q</italic><sub>w</sub> statistic was statistically significant. Potential moderator effects were not examined because of an insufficient number of effect sizes.</p>
</sec>
<sec id="section15-0022219409355484">
<title>LD standard versus typical standard</title>
<p>A large effect size was found for the comparison of the scores of students with LD and typically achieving students taking standard versions of tests. As expected, typically achieving students significantly outperformed students with LD. As shown in <xref ref-type="table" rid="table2-0022219409355484">Table 2</xref>, the <italic>Q</italic><sub>w</sub> statistic was statistically significant, but potential moderator effects were not examined because of an insufficient number of effect sizes.</p>
</sec>
<sec id="section16-0022219409355484">
<title>LD standard versus LD accommodated and typical standard versus typical accommodated</title>
<p>Few studies permitting within group comparisons were identified (see <xref ref-type="table" rid="table2-0022219409355484">Table 2</xref>). The small number of studies that were identified indicated that both students with LD and typically achieving students improved test scores when provided accommodations. The magnitude of improvement was large for students with LD and medium for typically achieving students. As shown in <xref ref-type="table" rid="table3-0022219409355484">Table 3</xref>, the effects sizes for these few studies were variable.</p>
</sec>
</sec>
</sec>
<sec id="section17-0022219409355484" sec-type="discussion">
<title>Discussion</title>
<p>To understand the role of extended time on standardized test scores requires one to utilize a multidimensional framework that draws upon scientific, psychometric, educational, sociological, and political perspectives (<xref ref-type="bibr" rid="bibr14-0022219409355484">Gregg, Mather, Shaywitz, &amp; Sireci, 2002</xref>). The purpose of one’s inquiry pertaining to the use of extended time will dictate the influence of one perspective over another. However, all perspectives form an intertwined network of knowledge—one not more important than another to decision making.</p>
<p>The purpose of using a test accommodation is to adjust conditions with the goal of equalizing the opportunity for an individual to demonstrate knowledge. Unfortunately, many standardized tests introduce construct irrelevant variables that discriminate against certain examinees. An accommodation like extended time may itself introduce construct irrelevant variance if the accommodation changes the construct being measured. Therefore, with the use of a testing accommodation, a potential threat to the construct validity of a measure can arise. The degree to which an accommodation strengthens or weakens validity is directly related to its impact on the construct being measured (<xref ref-type="bibr" rid="bibr31-0022219409355484">Sireci et al., 2005</xref>).</p>
<p>Investigating score comparability of standardized tests taken with and without extended time is critical for making reliable and valid assumptions pertaining to the population with LD. As extended time is the most frequently accessed accommodation on standardized tests for transitioning adolescents and adults with LD, investigating the literature pertaining to its effectiveness is relevant and necessary. However, <xref ref-type="bibr" rid="bibr23-0022219409355484">Lu and Sireci (2007)</xref> suggested that a great deal more research focusing on the validity issues surrounding test speededness is needed. As they note, “To support the validity of inferences derived from test scores, the time limits associated with tests should be defended through empirical research” (p. 36). Far too often, time limits are set mainly for practical administrative purposes.</p>
<p>As a result of our meta-analysis, we found that the body of research we examined is not adequate to address many of the questions pertaining to the comparability of scores with and without this accommodation. The literature is lacking in quantity of studies, restricted in types of design methodologies, and underrepresentative of the diversity of individuals demonstrating the disorder. After a thorough review of the literature, only <italic>nine</italic> studies were identified as specifically addressing the effect of extended test-taking time for transitioning adolescents with LD. Unfortunately, there are more court cases challenging the validity of extended time on standardized assessments for individuals with LD than there are empirically based studies to provide evidence as to the effect of this accommodation on performance.</p>
<p>The lack of detailed descriptive information about the participants in these studies was even more discouraging (see <xref ref-type="table" rid="table1-0022219409355484">Table 1</xref>). As mentioned previously, only one of the nine studies reported any substantive (i.e., ability and achievement current functioning) or topical marker variables (i.e., cognitive processing current functioning) for the populations investigated. In addition, just three studies reported the type of eligibility criteria used to operationalize LD. Without concise information about the populations studied, generalizability of findings is questionable.</p>
<p>The investigation of transitioning adolescence with LD taking the SAT college entrance examination with and without extended time represent the largest groups of studies informing our understanding of the effectiveness of this accommodation. The generalizability of this body of research to the broad range of abilities represented by the transitioning population with LD is highly questionable. The restricted range of abilities and educational backgrounds represented by students taking college entrance examinations do not adequately inform us about many subgroups within the population of LD (e.g., ability levels, age, educational experience, SES, language background, etc.).</p>
<sec id="section18-0022219409355484">
<title>Effectiveness of Extended Time as an Accommodation</title>
<p>The results of our meta-analysis of transitioning adolescents with and without LD provided extended time or standard administrations of tests leave professionals with a great deal more questions than answers as to the effectiveness of this accommodation. However, the one outcome consistent across all of the comparisons was that the typically achieving students outperformed the students with LD regardless of the type of test administration.</p>
<p>All of the studies included in our meta-analysis examined the performance of transitioning adolescents with LD taking a standardized test with extended time as compared to their typically achieving peers taking the same test without extended time. This comparison resulted in a small effect size (−.41), indicating that typically achieving students continue to outperform students with LD, even when the latter are provided extended time and the former are not. This finding challenges the assumption that provision of extended time on standardized tests provides an unfair advantage to transitioning students with LD. As with all of the comparisons we investigated, the effect size range across the studies was very broad, indicating differences in number and type of examinees (see <xref ref-type="table" rid="table3-0022219409355484">Table 3</xref>). It should be noted that none of the nine studies reported effect sizes.</p>
<p>Interestingly, the two studies (i.e., <xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux, Pearson, &amp; Siegel, 2006</xref>; <xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh, Mather, &amp; Russell, 2005</xref>) investigating the reading comprehension performance of examinees taking the <italic>Nelson Denny Reading Test</italic> (<xref ref-type="bibr" rid="bibr4-0022219409355484">Brown, Fischco, &amp; Hanna, 1993</xref>) provided different findings when comparing individuals with LD provided extended time compared to typically achieving students who were provided standard test procedures. <xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al. (2006)</xref> studied a broad age range of examinees (17−61) and a smaller number of participants (reading disordered = 22, average achieving control = 22) with very heterogeneous educational backgrounds and ability levels. In addition, their reading disordered group appeared to be more severe in reading abilities than in many of the studies in this meta-analysis. The results of the Lesaux et al. study indicate a small effect size between the performances of individuals with LD provided extended time as compared to typically achieving students taking the test under standard administration (.04). In contrast, <xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh et al. (2005)</xref> used a more homogenous population of transitioning adolescents in both age (18−25) and educational background (all attending college). Their participant sample was also twice the size of the Lesaux study. The effect size between the Ofiesh groups administered the <italic>Nelson Denny Reading Comprehension</italic> test with and without extended time was moderate (−.70). This raises the possibility that extended time has different effects based on the severity of achievement deficits of students with LD. However, additional research is needed to investigate this possibility.</p>
<p>Because the nine studies provided such mixed results, we examined two potential moderating variables (i.e., type of test and academic skill area). As the majority of the studies (five of the nine) in our meta-analysis investigated examinee performance on the SAT, we used it as a dependent variable as compared to other types of measures (e.g., reading comprehension, math). The secondary analysis compared those studies investigating performance on reading/writing tests to those that incorporated math tests. However, neither moderating variable (i.e., type of test or academic skill area) explained the heterogeneity found in the initial analysis. The difference may be the result of the heterogeneity in the populations studied (e.g., ability, type of LD, age range). It should also be highlighted that the small sample of studies resulted in minimal power to detect statistically significant differences.</p>
</sec>
<sec id="section19-0022219409355484">
<title>Interaction or Differential Boost Hypotheses</title>
<p>Only two studies provided information to investigate the <italic>interaction</italic> or <italic>differential boost hypotheses</italic> (i.e., <xref ref-type="bibr" rid="bibr1-0022219409355484">Alster, 1997</xref>; <xref ref-type="bibr" rid="bibr19-0022219409355484">Lesaux et al., 2006</xref>). Both studies found that students with LD when provided both extended time and standard administrations of tests demonstrated significant gains (Alster ES =.85, Lesaux ES = 1.57). However, the performance of the typically achieving students when given both extended and standard administrations of tests demonstrated large effect sizes in the Lesaux study (ES = .95), but a small effect size was found in the Alster study (ES = .44). Again, as with the <xref ref-type="bibr" rid="bibr25-0022219409355484">Ofiesh et al. (2005)</xref> study, the Alster participants across groups were more homogenous in educational background, age, and ability. The findings from these two studies support the conclusions drawn by Sireci et al.’s (2005) review of the literature that “all student groups (SWD and their general education peers) had score gains under accommodation conditions” (p. 481). However, as they note, the “students with disabilities” demonstrated “significantly greater gains” when provided the accommodation of extended time. A great deal more research is needed to validate either the <italic>interaction</italic> or <italic>differential boost hypotheses</italic>.</p>
</sec>
<sec id="section20-0022219409355484">
<title>Summary</title>
<p>Extended time is an accommodation frequently provided on standardized tests to individuals with disabilities. The implicit assumption by some professionals is that extended time is effective for all individuals with disabilities. However, concern that extended time provides an unfair advantage to examinees not provided the accommodation has led others to suggest that everyone would significantly benefit from extended time. The results of this meta-analysis raise concerns about both of these perspectives.</p>
<p>The most significant finding of our meta-analysis is that transitioning students with LD still underperform academically as compared to their normally achieving peers whether provided extended time or not on standardized tests. While students with LD perform significantly better when provided extended time, the accommodation does not erase the disability. As noted by <xref ref-type="bibr" rid="bibr10-0022219409355484">A. Cohen, Gregg, and Deng (2005)</xref>, “Accommodations are not the source of differential performance, in other words, they simply mediate learning” (p. 233). While cognitive and linguistic processes continue to make learning difficult for many students with LD, their poor academic performance might also speak to a lack of effective instruction at the elementary and secondary levels. Again, A. Cohen et al. observed “that pointing the accusatory finger at accommodations is possibly inappropriate and redirects the needed attention of professionals on the failure of many students to attain curriculum goals” (p. 321).</p>
<p>The results of this meta-analysis underscore the lack of research available to make conclusions about the comparability of scores for transitioning students with LD taking tests with extended time to their normally achieving peers. Two of the most disturbing findings were the omission by researchers of descriptive information defining the participants studied and the overrepresentation of studies investigating performance of students on postsecondary entrance examinations (i.e., SAT). One must be very cautious in generalizing the findings from this meta-analysis to the heterogeneous population of transitioning students with LD.</p>
</sec>
<sec id="section21-0022219409355484">
<title>Future Research</title>
<p>Based on our findings, we offer three recommendations for future research on test accommodations for students with LD. First, and most importantly, future studies are needed in which <italic>both</italic> students with LD and typically achieving students are administered <italic>both</italic> standardized and accommodated versions of tests. This type of design is necessary to more adequately understand the impact of test accommodations in relation to the interaction and differential boost hypotheses. The majority of studies in the current investigation only allowed comparison of the performance of students with LD taking an accommodated version of a test to typically achieving students taking a standard version of a test. Such a comparison does not permit interpretation of results within the framework of the interaction and differential boost hypotheses.</p>
<p>Second, including detailed descriptive information about the LD sample used in future studies is paramount for interpretation of future research results. The studies included in our investigation lacked specificity in their sample descriptions. Most samples were referred to as “LD,” without specification of the type of LD or associated cognitive and linguistic process deficits that might be important to know in order to make reasonable conclusions about the impact of test accommodations on students with LD. Future studies should be designed in which the test accommodations of the LD group are justified by the specific type of LD and, as much as reasonably possible, by the specific cognitive and linguistic process deficits that are associated with the specific LD.</p>
<p>Finally, the impact of test accommodations on the validity of test scores should be investigated more thoroughly by future researchers. The <italic>Standards for Educational and Psychological Testing</italic> (<xref ref-type="bibr" rid="bibr2-0022219409355484">American Educational Research Association, American Psychological Association, &amp; National Council on Measurement in Education, 1999</xref>) define validity as the “degree to which accumulated evidence and theory support specific interpretations of test scores entailed by proposed uses of a test” (p. 184). There is no single, definitive test of construct validity (<xref ref-type="bibr" rid="bibr22-0022219409355484">Lissitz &amp; Samuelsen, 2007</xref>). The most common types of validity evidence pertaining to test accommodations include (a) predictive validity, (b) construct (factorial) equivalence, (c) social considerations (consequential validity), and (d) differential item functioning analyses (<xref ref-type="bibr" rid="bibr31-0022219409355484">Sireci et al., 2005</xref>). Our review indicated that the vast majority of studies in this area of inquiry were predictive validity studies. Future studies investigating other dimensions of validity are needed to more adequately understand the impact of test accommodations on the validity of test scores.</p>
</sec>
</sec>
</body>
<back>
<app-group>
<app id="app1-0022219409355484">
<title>Appendix</title>
<sec id="section22-0022219409355484">
<title>Journals Hand Searched 1996–2007</title>
<list id="list2-0022219409355484" list-type="simple">
<list-item><p><italic>Journal of Learning Disabilities</italic></p></list-item>
<list-item><p><italic>Learning Disability Quarterly</italic></p></list-item>
<list-item><p><italic>Learning Disabilities Research and Practice</italic></p></list-item>
<list-item><p><italic>Learning Disabilities: A Contemporary Journal</italic></p></list-item>
<list-item><p><italic>Annals of Dyslexia</italic></p></list-item>
<list-item><p><italic>Exceptional Children</italic></p></list-item>
<list-item><p><italic>Journal of Psychoeducational Assessment</italic></p></list-item>
<list-item><p><italic>School Psychology Review</italic></p></list-item>
<list-item><p><italic>Journal of Educational Measurement</italic></p></list-item>
<list-item><p><italic>Educational Measurement: Issues and Practice</italic></p></list-item>
<list-item><p><italic>American Educational Research Journal</italic></p></list-item>
<list-item><p><italic>Educational Evaluation and Policy Analysis</italic></p></list-item>
<list-item><p><italic>(continued)</italic></p></list-item>
<list-item><p><italic>Educational Researcher</italic></p></list-item>
<list-item><p><italic>Review of Educational Research</italic></p></list-item>
<list-item><p><italic>Applied Measurement in Education</italic></p></list-item>
<list-item><p><italic>Adult Basic Education and Literacy Journal</italic></p></list-item>
<list-item><p><italic>Adult Education Quarterly</italic></p></list-item>
<list-item><p><italic>Journal of Adolescent and Adult Literacy</italic></p></list-item>
<list-item><p><italic>Journal of Literacy Research</italic></p></list-item>
<list-item><p><italic>Reading Research Quarterly</italic></p></list-item>
<list-item><p><italic>Review of Adult Learning and Literacy</italic></p></list-item>
</list>
</sec>
<sec id="section23-0022219409355484">
<title>Web Sites Hand Searched for References</title>
<list id="list3-0022219409355484" list-type="simple">
<list-item><p>Center for Research on Evaluation, Standards, and Student Testing</p></list-item>
<list-item><p>National Center on Educational Outcomes</p></list-item>
<list-item><p>Behavior Research and Training National Center for Research and Evaluation</p></list-item>
<list-item><p>Student Testing Center for Assessment Validity and Evaluation</p></list-item>
<list-item><p>Wisconsin Center for Educational Research</p></list-item>
<list-item><p>Educational Testing Center (ETS)</p></list-item>
<list-item><p>General Educational Development Testing Service of American Council on Education</p></list-item>
<list-item><p>National Assessment of Educational Progress</p></list-item>
</list>
</sec>
</app>
</app-group>
<fn-group>
<fn fn-type="conflict">
<p>The authors declared no conflicts of interest with respect to the authorship and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The authors received no financial support for the research and/or authorship of this article. The first author would like to thank the National Institute for Literacy, Washington, DC.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Alster</surname><given-names>E. H.</given-names></name>
</person-group> (<year>1997</year>). <article-title>The effects of extended time on algebra test scores for college students with and without learning disabilities</article-title>. <source>Journal of Learning Disabilities</source>, <volume>30</volume>, <fpage>222</fpage>–<lpage>227</lpage>.</citation>
</ref>
<ref id="bibr2-0022219409355484">
<citation citation-type="book">
<collab>American Educational Research Association, American Psychological Association, &amp; National Council on Measurement in Education</collab>. (<year>1999</year>). <source>Standards for education and psychological testing</source> (<edition>2nd ed.</edition>). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>.</citation>
</ref>
<ref id="bibr3-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Braun</surname><given-names>H.</given-names></name>
<name><surname>Ragosta</surname><given-names>M.</given-names></name>
<name><surname>Kaplan</surname><given-names>B.</given-names></name>
</person-group> (<year>1986</year>). <source>The predictive validity of the Scholastic Aptitude Test for disabled students</source> (<comment>ETS Research Report 86-38</comment>). <publisher-loc>New York</publisher-loc>: <publisher-name>College Board</publisher-name>.</citation>
</ref>
<ref id="bibr4-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brown</surname><given-names>J. I.</given-names></name>
<name><surname>Fischco</surname><given-names>V. V.</given-names></name>
<name><surname>Hanna</surname><given-names>G.</given-names></name>
</person-group> (<year>1993</year>). <source>Nelson-Denny Reading Test</source>. <publisher-loc>Itasca, IL</publisher-loc>: <publisher-name>Riverside Publishing Company</publisher-name>.</citation>
</ref>
<ref id="bibr5-0022219409355484">
<citation citation-type="book">
<collab>Biostat</collab>. (<year>2000</year>). <source>Comprehensive meta-analysis: A computer program for research synthesis</source>. <publisher-loc>Englewood, NJ</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr6-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bridgeman</surname><given-names>B.</given-names></name>
<name><surname>Trapani</surname><given-names>C.</given-names></name>
<name><surname>Curley</surname><given-names>E.</given-names></name>
</person-group> (<year>2003</year>). <source>Impact of fewer questions per section on SAT 1 scores</source> (<comment>College Board Research Report No. 2003-2</comment>). <publisher-loc>New York</publisher-loc>: <publisher-name>College Board</publisher-name>.</citation>
</ref>
<ref id="bibr7-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brinckerhoff</surname><given-names>L. C.</given-names></name>
<name><surname>Banerjee</surname><given-names>M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Misconceptions regarding accommodations on high-stakes tests: Recommendations for preparing disability documentation for test takers with learning disabilities</article-title>. <source>Learning Disabilities Research and Practice</source>, <volume>22</volume>, <fpage>246</fpage>–<lpage>256</lpage>.</citation>
</ref>
<ref id="bibr8-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cahalan</surname><given-names>C.</given-names></name>
<name><surname>Mandinach</surname><given-names>E.</given-names></name>
<name><surname>Camara</surname><given-names>W.</given-names></name>
</person-group> (<year>2002</year>). <source>Predictive validity of SAT I: Reasoning tests for test takers with learning disabilities and extended time accommodations</source> (<comment>College Board Research Report No. 2002-05</comment>). <publisher-loc>New York</publisher-loc>: <publisher-name>College Board</publisher-name>.</citation>
</ref>
<ref id="bibr9-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Camara</surname><given-names>W.</given-names></name>
<name><surname>Copeland</surname><given-names>T.</given-names></name>
<name><surname>Rothchild</surname><given-names>B.</given-names></name>
</person-group> (<year>1998</year>). <source>Effects of extended time on the SAT I: Reasoning Test: Score growth for students with learning disabilities</source> (<comment>College Board Research Report 98-7</comment>). <publisher-loc>New York</publisher-loc>: <publisher-name>College Board</publisher-name>.</citation>
</ref>
<ref id="bibr10-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cohen</surname><given-names>A.</given-names></name>
<name><surname>Gregg</surname><given-names>N.</given-names></name>
<name><surname>Deng</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The role of extended time and item content on a high-stakes mathematics test</article-title>. <source>Learning Disabilities Research and Practice</source>, <volume>20</volume>, <fpage>225</fpage>–<lpage>233</lpage>.</citation>
</ref>
<ref id="bibr11-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cohen</surname><given-names>J.</given-names></name>
</person-group> (<year>1988</year>). <source>Statistical power analysis for the behavioral sciences</source> (<edition>2nd ed.</edition>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr12-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fuchs</surname><given-names>L. S.</given-names></name>
<name><surname>Fuchs</surname><given-names>D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Fair and unfair testing accommodations</article-title>. <source>School Administrator</source>, <volume>56</volume>, <fpage>24</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr13-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gregg</surname><given-names>N.</given-names></name>
</person-group> (<year>2009</year>). <source>Assessment and accommodation of adolescents and adults with learning disabilities and attention-deficit/hyperactivity disorder</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Guilford</publisher-name>.</citation>
</ref>
<ref id="bibr14-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gregg</surname><given-names>N.</given-names></name>
<name><surname>Mather</surname><given-names>N.</given-names></name>
<name><surname>Shaywitz</surname><given-names>S.</given-names></name>
<name><surname>Sireci</surname><given-names>S.</given-names></name>
</person-group> (<year>2002</year>). <source>The flagging of test scores of individuals with disabilities who are granted the accommodation of extended time: A report of the majority opinion of the Blue Ribbon Panel of Flagging</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Educational Testing Service</publisher-name>.</citation>
</ref>
<ref id="bibr15-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hedges</surname><given-names>L. V.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Distribution theory for Glass’s estimator of effect size and related estimators</article-title>. <source>Journal of Educational Statistics</source>, <volume>6</volume>, <fpage>107</fpage>–<lpage>128</lpage>.</citation>
</ref>
<ref id="bibr16-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hedges</surname><given-names>L. V.</given-names></name>
<name><surname>Olkin</surname><given-names>I.</given-names></name>
</person-group> (<year>1985</year>). <source>Statistical methods for meta-analysis</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr17-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kavale</surname><given-names>K. A.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Potential advantages of the meta-analysis technique for research in special education</article-title>. <source>The Journal of Special Education</source>, <volume>18</volume>, <fpage>61</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr18-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Keogh</surname><given-names>B. K.</given-names></name>
<name><surname>Major</surname><given-names>S. M.</given-names></name>
<name><surname>Omori</surname><given-names>H.</given-names></name>
<name><surname>Gandar</surname><given-names>P.</given-names></name>
<name><surname>Reid</surname><given-names>H. P.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Proposed markers in learning disabilities research</article-title>. <source>Journal of Abnormal Child Psychology</source>, <volume>8</volume>, <fpage>21</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr19-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lesaux</surname><given-names>N. K.</given-names></name>
<name><surname>Pearson</surname><given-names>M. R.</given-names></name>
<name><surname>Siegel</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The effects of timed and untimed testing conditions on the reading comprehension of adults with reading disabilities</article-title>. <source>Reading and Writing</source>, <volume>19</volume>, <fpage>21</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr20-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lindstrom</surname><given-names>J.</given-names></name>
<name><surname>Gregg</surname><given-names>N.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The role of extended time on the SAT reasoning test for students with disabilities</article-title>. <source>Learning Disabilities Research and Practice</source>, <volume>22</volume>, <fpage>85</fpage>–<lpage>95</lpage>.</citation>
</ref>
<ref id="bibr21-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lipsey</surname><given-names>M. W.</given-names></name>
<name><surname>Wilson</surname><given-names>D. B.</given-names></name>
</person-group> (<year>2001</year>). <source>Practical meta-analysis</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr22-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lissitz</surname><given-names>R. W.</given-names></name>
<name><surname>Samuelsen</surname><given-names>K.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A suggested change in terminology and emphasis regarding validity and education</article-title>. <source>Educational Researcher</source>, <volume>36</volume>, <fpage>437</fpage>–<lpage>448</lpage>.</citation>
</ref>
<ref id="bibr23-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lu</surname><given-names>Y.</given-names></name>
<name><surname>Sireci</surname><given-names>S. G.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Validity issues in test speededness</article-title>. <source>Educational Measurement: Issues and Practice</source>, <volume>6</volume>, <fpage>29</fpage>–<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr24-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ofiesh</surname><given-names>N.</given-names></name>
<name><surname>Hughes</surname><given-names>C.</given-names></name>
<name><surname>Scott</surname><given-names>S.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Extended test time and postsecondary students with learning disabilities: A model for decision making</article-title>. <source>Learning Disabilities Research and Practice</source>, <volume>19</volume>, <fpage>57</fpage>–<lpage>90</lpage>.</citation>
</ref>
<ref id="bibr25-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ofiesh</surname><given-names>N.</given-names></name>
<name><surname>Mather</surname><given-names>N.</given-names></name>
<name><surname>Russell</surname><given-names>A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Using speeded cognitive, reading, and academic measures to determine the need for extended test time among university students with learning disabilities</article-title>. <source>Journal of Psychoeducational Assessment</source>, <volume>23</volume>, <fpage>35</fpage>–<lpage>52</lpage>.</citation>
</ref>
<ref id="bibr26-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Overton</surname><given-names>R. C.</given-names></name>
</person-group> (<year>1998</year>). <article-title>A comparison of fixed-effects and mixed (random-effects) models for meta-analysis tests of moderator variable effects</article-title>. <source>Psychological Methods</source>, <volume>3</volume>, <fpage>134</fpage>–<lpage>147</lpage>.</citation>
</ref>
<ref id="bibr27-0022219409355484">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ragosta</surname><given-names>M.</given-names></name>
<name><surname>Braun</surname><given-names>H.</given-names></name>
<name><surname>Kaplan</surname><given-names>B.</given-names></name>
</person-group> (<year>1991</year>). <source>Performance and persistence: A validity study of the SAT for students with disabilities</source> (<comment>College Board Research Report 91-3; ETS Research Report 91-41</comment>). <publisher-loc>New York</publisher-loc>: <publisher-name>College Board</publisher-name>.</citation>
</ref>
<ref id="bibr28-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Runyan</surname><given-names>K.</given-names></name>
</person-group> (<year>1991</year>). <article-title>The effect of extra time on reading comprehension scores for university students with and without learning disabilities</article-title>. <source>Journal of Learning Disabilities</source>, <volume>24</volume>, <fpage>104</fpage>–<lpage>108</lpage>.</citation>
</ref>
<ref id="bibr29-0022219409355484">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Sireci</surname><given-names>S. G.</given-names></name>
</person-group> (<year>2004</year>). <source>Validity issues in accommodating NAEP reading tests</source>. <access-date>Retrieved July 25, 2006</access-date>, <comment>from <ext-link ext-link-type="uri" xlink:href="http://www.nagb.org/pubs/conferences/sierci.co">www.nagb.org/pubs/conferences/sierci.co</ext-link></comment></citation>
</ref>
<ref id="bibr30-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sireci</surname><given-names>S. G.</given-names></name>
<name><surname>Parker</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Validity on trial: Psychometric and legal conceptualizations of validity</article-title>. <source>Educational Measurement: Issues and Practice</source>, <volume>25</volume>, <fpage>27</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr31-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sireci</surname><given-names>S. G.</given-names></name>
<name><surname>Scarpati</surname><given-names>S. E.</given-names></name>
<name><surname>Li</surname><given-names>S.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Test accommodations for students with disabilities: An analysis of the interaction hypothesis</article-title>. <source>Review of Educational Research</source>, <volume>75</volume>, <fpage>457</fpage>–<lpage>490</lpage>.</citation>
</ref>
<ref id="bibr32-0022219409355484">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Tindal</surname><given-names>G.</given-names></name>
<name><surname>Ketterlin-Geller</surname><given-names>L. R.</given-names></name>
</person-group> (<year>2004</year>). <source>Research on mathematics test accommodations relevant to NAEP testing</source>. <access-date>Retrieved July 2006</access-date> <comment>from <ext-link ext-link-type="uri" xlink:href="http://www.nagb.org/pubs/conferences/tindal">www.nagb.org/pubs/conferences/tindal</ext-link></comment></citation>
</ref>
<ref id="bibr33-0022219409355484">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zuriff</surname><given-names>G. E.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Extra examination time for students with learning disabilities: An examination of the maximum potential thesis</article-title>. <source>Applied Measurement in Education</source>, <volume>13</volume>, <fpage>99</fpage>–<lpage>117</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>