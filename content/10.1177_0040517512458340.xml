<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="EN">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TRJ</journal-id>
<journal-id journal-id-type="hwp">sptrj</journal-id>
<journal-title>Textile Research Journal</journal-title>
<issn pub-type="ppub">0040-5175</issn>
<issn pub-type="epub">1746-7748</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0040517512458340</article-id>
<article-id pub-id-type="publisher-id">10.1177_0040517512458340</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Optimization of automated online fabric inspection by fast Fourier transform (FFT) and cross-correlation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Malek</surname><given-names>Abdel Salam</given-names></name>
<xref ref-type="aff" rid="aff1-0040517512458340">1</xref>
<xref ref-type="aff" rid="aff2-0040517512458340">2</xref>
<xref ref-type="corresp" rid="corresp1-0040517512458340"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Drean</surname><given-names>Jean-Yves</given-names></name>
<xref ref-type="aff" rid="aff1-0040517512458340">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Bigue</surname><given-names>Laurent</given-names></name>
<xref ref-type="aff" rid="aff3-0040517512458340">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Osselin</surname><given-names>Jean-François</given-names></name>
<xref ref-type="aff" rid="aff1-0040517512458340">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0040517512458340"><label>1</label>Laboratoire Physique et Mécanique Textiles (LPMT) EAC, <institution>Université de Haute Alsace (UHA)</institution>, Mulhouse, France</aff>
<aff id="aff2-0040517512458340"><label>2</label>Faculty of Industrial Education, <institution>Suez Canal University</institution>, Egypt</aff>
<aff id="aff3-0040517512458340"><label>3</label>Laboratoire Modélisation, Intelligence, Processus et Système (MIPS), <institution>Université de Haute Alsace (UHA)</institution>, Mulhouse, France</aff>
<author-notes>
<corresp id="corresp1-0040517512458340">Abdel Salam Malek, Laboratoire Physique et Mécanique Textiles (LPMT) EAC, <institution>Université de Haute Alsace (UHA)</institution>, 11 Rue Alfred Werner, Mulhouse 68093, France. Email: <email>abdelsalammalek@yahoo.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2013</year>
</pub-date>
<volume>83</volume>
<issue>3</issue>
<fpage>256</fpage>
<lpage>268</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Fabric inspection has an importance to prevent the risk of delivering inferior quality product. Until recently, the process was still undertaken offline and manually by humans, which has many drawbacks. The continuous development in computer technology introduces the automated fabric inspection as an effective alternative. In our work, Fast Fourier Transform and Cross-correlation techniques, i.e. linear operations, are first implemented to examine the structure regularity features of the fabric image in the spatial domain. To improve the efficiency of the technique and overcome the problem of detection errors, further thresholding operation is implemented using a level selection filter. Through this filter, the technique is able to detect only the actual or real defects and highlight its exact dimensions. A software package such as Matlab or Scilab is used for this procedure. It is implemented firstly on a simulated plain fabric to determine the most important parameters during the process of defect detection and then to optimize each of them even considering noise. To verify the success of the technique, it is implemented on real plain fabric samples with different colors containing various defects. Several results of the proposed technique for the simulated and real plain fabric structures with the most common defects are presented. Finally, a vision-based fabric inspection prototype that could be accomplished on-loom to inspect the fabric under construction with 100% coverage is proposed.</p>
</abstract>
<kwd-group>
<kwd>Fabric inspection</kwd>
<kwd>fabric defects</kwd>
<kwd>fast Fourier transforms</kwd>
<kwd>cross-correlation</kwd>
<kwd>defect detection parameters</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Generally, all companies promote quality as the central customer value and the critical success factor for achieving competitiveness. In the textile industry, it is very difficult to achieve 100% first quality products while in the weaving process it is an impossible task. Moreover, it is found that fabric defects are responsible for nearly 85% of the second quality items found in the garment industry which represents a loss in revenue for manufacturers since the second quality product will sell for only 45–65% of the price of first quality fabric.<sup><xref ref-type="bibr" rid="bibr1-0040517512458340">1</xref></sup> Therefore, fabric inspection is an utmost priority to prevent delivering inferior quality production. Mainly, such objects have two distinct possibilities. The first one is the product or end (offline) inspection in which the manufactured fabric has to be inspected by a human using inspection machines. The second possibility is the process inspection (online) in which the weaving process, or its parameters, can be constantly monitored for the occurrence of defects. Until recently, fabric inspection is still undertaken offline and manually by skilled staff with a maximum accuracy of only 70–80%.</p>
<p>Because production speeds are faster than ever, manufacturers must be able to identify defects, locate their source, and make the necessary corrections in less time so as to reduce the amount of second quality fabric. This in turn places a greater strain on the inspection departments of the manufacturers. In addition, due to factors such as tiredness, boredom, and inattentiveness, the staff performance is often unreliable.<sup><xref ref-type="bibr" rid="bibr2-0040517512458340">2</xref></sup> Therefore, the best possibility for objective and consistent evaluation is through the application of an online automated inspection system. The wider application of online automated fabric inspection would seem to offer a number of potential advantages including improved safety, reduced labor costs, the elimination of human error and/or subjective judgment, and the creation of timely statistical product data. Moreover, because they are computer-based, these systems do not suffer the drawbacks of human visual inspection.</p>
<p>In the two past decades, interesting research work relevant to automated fabric inspection has been reported. All researchers interpreted this task as a texture analysis problem. Based on the algorithm used, texture analysis is categorized into six approaches.<sup><xref ref-type="bibr" rid="bibr1-0040517512458340">1</xref></sup> Each one of them has some advantages and, unfortunately, some drawbacks. In our research work, we chose to implement a Fourier-based technique. On the one hand, Fourier analysis is simple, fast, and simulates the human visual inspection. While on the other hand, it has a low computational complexity and is less sensitivity to noise. Moreover, it corresponds to fabric’s high degree of periodicity and the speed of the weaving machine, as well.</p>
<sec id="sec1-0040517512458340"><title>Goals</title>
<p>The main goals of our work can be summarized as follows:
<list id="list1-0040517512458340" list-type="bullet">
<list-item><p>Improving fabric quality by detecting all fabric defects immediately during the production to reduce the cost and meet the manufacturers’ needs.</p></list-item>
<list-item><p>Creating timely, statistical product data that enables the manufacturers to design and improve the future plans of the factory.</p></list-item>
<list-item><p>Developing a methodology to extract defect features from various fabrics using fast Fourier transform (FFT) and cross-correlation techniques (CCTs).</p></list-item>
<list-item><p>Developing a methodology to optimize the main important detection parameters.</p></list-item>
<list-item><p>Designing a full laboratory prototype to demonstrate the utility of the combined hardware/software capabilities as a proof-of-concept.</p></list-item>
</list></p>
</sec>
<sec id="sec2-0040517512458340"><title>Technical implementation</title>
<sec id="sec3-0040517512458340"><title>Fourier transform</title>
<p>According to the Fourier theorem, any signal can be represented by the sum of sine and cosine waves with various amplitudes and frequencies. The tool to do that is well known as a Fourier transform (FT). The input of the transformation represents the image spatial domain while the output of the transformation represents the image in the Fourier or frequency domain where each point represents a particular frequency contained in the spatial domain image. The important property is that regular spatial pattern information becomes obvious in Fourier-transformed images.</p>
<p>FT transforms the image encoded as luminance values of pixels. Because such values are spatially sampled, we use discrete Fourier transform (DFT), the digital implementation of Fourier transform. The sampled image does not contain all frequencies forming the original image before its acquisition. Therefore, to lose as little information as possible, the Shannon theorem must be fulfilled as follows: the sample frequency must be twice as much as the higher frequency of interest.</p>
<p>DFT transforms an <italic>M × N</italic> image into another <italic>M × N</italic> image. Without loss of generality, we will consider square images, of size <italic>N × N</italic>. In our application, <italic>ƒ</italic>(<italic>x</italic>,<italic>y</italic>) is the gray level at pixel coordinates (<italic>x</italic>,<italic>y</italic>) in the original image of size <italic>N × N</italic> (spatial domain). For frequency variables <italic>a</italic>,<italic>b</italic> = 0, 1, … … . , <italic>N</italic> − 2, <italic>N</italic> − 1, the DFT <italic>F</italic>(<italic>a</italic>,<italic>b</italic>) is expressed by
<disp-formula id="disp-formula1-0040517512458340"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math1-0040517512458340"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mi>f</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>ax</mml:mi><mml:mo>+</mml:mo><mml:mi>by</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula1-0040517512458340" xlink:href="10.1177_0040517512458340-eq1.tif"/></disp-formula>
</p>
<p>where the exponential term is the basis function corresponding to each point <italic>F</italic>(<italic>a</italic>,<italic>b</italic>) in the Fourier frequency domain. In the frequency domain, the digital image is described as a periodic function where its DC component is defined as the mean value of the waveform. Moreover, the DC component of an image is the average value of all pixels (the center of the spectrum). Thus, 1/<italic>N</italic><sup>2</sup> <italic>F</italic>(<italic>0</italic>,<italic>0</italic>) represents the DC-component of the image which corresponds to the average luminance while <italic>F</italic>(<italic>N</italic>-1,<italic>N</italic>-1) represents the transform at the highest frequency. It is shown that <italic>F</italic>(<italic>a</italic>,<italic>b</italic>) is periodic, with period <italic>N × N</italic>.</p>
<p>An important property of two-dimensional FT is its ability to restore the processed image from the frequency domain to its spatial domain. This is usually done using inverse discrete Fourier transform (IDFT). Thus, in a similar way to the previous equation, the Fourier image can be re-transformed to the spatial domain using IDFT as follows
<disp-formula id="disp-formula2-0040517512458340"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math2-0040517512458340"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mi>F</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>j</mml:mi><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ax</mml:mi><mml:mo>+</mml:mo><mml:mi>by</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula2-0040517512458340" xlink:href="10.1177_0040517512458340-eq2.tif"/></disp-formula>
</p>
<p>Despite its numerous advantages, the long computational time of DFT is an important drawback. In fact, one-dimensional DFT has <italic>N<sup>2</sup></italic> complexity which can be reduced to <italic>N log</italic><sub>2</sub> <italic>N</italic> if we employ FFT. FFT is a DFT with some reorganization that can reduce the complexity of the DFT and save an enormous amount of time. Similarly, the complexity of two-dimensional DFT is proportional to 2<italic>N<sup>3</sup></italic> while using FFT reduces it to 2<italic>N</italic><sup>2</sup><italic> log</italic><sub>2</sub> <italic>N</italic>. Therefore, during our application, we will implement FFT. <xref ref-type="fig" rid="fig1-0040517512458340">Figures 1(a) and 1(b)</xref> present the images of the defect-free simulated and real plain fabric in the spatial domain, while <xref ref-type="fig" rid="fig1-0040517512458340">Figures 1(c) and 1(d)</xref> show its Fourier frequency spectrum as intensity functions, respectively. As it is anticipated, the value of each point in the frequency spectrum determines the amplitude of the corresponding frequency. In addition, the vertical and horizontal lines corresponding to the warp and weft threads in the original images can be identified.
<fig id="fig1-0040517512458340" position="float"><label>Figure 1.</label><caption><p>FFT implementation on simulated and real plain fabric images.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig1.tif"/></fig></p>
</sec>
<sec id="sec4-0040517512458340"><title>Cross-correlation technique (CCT)</title>
<p>As mentioned previously, by considering the periodic nature of woven fabric, it is possible to monitor and describe the relationship between the regular structure of the fabric in the spatial domain and its Fourier spectrum in the frequency domain. Presence of a defect over the periodical structure of woven fabric causes changes in its Fourier spectrum. By comparing the power spectrum of an image containing a defect with that of a defect-free image, the shifts in the normalized intensity between one spectrum and the other could signify the presence of a defect.</p>
<p>In our work, the basic principle is to compute a set of seven textural features in a sliding window (sub-image). Then, we search for the significant local deviations in the feature values from the entire image. Such textural features are extracted from the weft and warp diagrams of the Fourier frequency spectrum of the sub-image.<sup><xref ref-type="bibr" rid="bibr3-0040517512458340">3</xref>–<xref ref-type="bibr" rid="bibr5-0040517512458340">5</xref></sup></p>
<p>As the information about weft yarns appears in the vertical direction <italic>f<sub>y</sub></italic> while the information about warp yarns appears in the horizontal direction <italic>f<sub>x</sub></italic>, the seven features are extracted as follows
<disp-formula id="disp-formula3-0040517512458340"><label>(3, 4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math3-0040517512458340"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula3-0040517512458340" xlink:href="10.1177_0040517512458340-eq3.tif"/></disp-formula>
<disp-formula id="disp-formula4-0040517512458340"><label>(5, 6)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math4-0040517512458340"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic alternate-form-of="disp-formula4-0040517512458340" xlink:href="10.1177_0040517512458340-eq4.tif"/></disp-formula>
<disp-formula id="disp-formula5-0040517512458340"><label>(7, 8)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math5-0040517512458340"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula5-0040517512458340" xlink:href="10.1177_0040517512458340-eq5.tif"/></disp-formula>
<disp-formula id="disp-formula6-0040517512458340"><label>(9)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math6-0040517512458340"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>yi</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>yi</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo/><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula6-0040517512458340" xlink:href="10.1177_0040517512458340-eq6.tif"/></disp-formula>
where feature <italic>P<sub>1</sub></italic> represents the image average light intensity that characterizes the fabric structure (density) irregularity. Features <italic>P<sub>2</sub></italic>, <italic>P<sub>3</sub></italic>, and <italic>P<sub>4</sub></italic> detect changes in the vertical or warp direction, whereas <italic>P<sub>5</sub></italic>, <italic>P<sub>6</sub></italic>, and <italic>P<sub>7</sub></italic> detect changes in the horizontal or weft direction. The features <italic>P<sub>4</sub></italic> and <italic>P</italic><bold><italic><sub>7</sub></italic></bold> analyze the region between the central peak, the first harmonic frequency, and the first peak because higher harmonic frequency components are significantly distorted in the real environment.</p>
<p>To obtain the reference figures, the average feature correlation coefficient of a fabric image free of defects is calculated. After that, a possibly defective image is scanned or sampled in sub-images of determined size and step. Again, the average feature correlation coefficient of each sub-image is also calculated. If the calculated value of the sub-image feature correlation coefficient is smaller than that of the defect-free image, it means that such sub-image has a defect. For instance, we can represent it on the original image with a red overlay.</p>
<p>An image of the simulated fabric containing a defect, a stain, is chosen to illustrate the variation in the coefficient of feature correlation as shown in <xref ref-type="fig" rid="fig2-0040517512458340">Figure 2(a)</xref>. In addition, <xref ref-type="fig" rid="fig2-0040517512458340">Figure 2(b)</xref> shows the defective area inside the image while it is surrounded by red squares. Each one represents a sub-image of a smaller average correlation coefficient than that of the defect-free image.
<fig id="fig2-0040517512458340" position="float"><label>Figure 2.</label><caption><p>The implementation of the technique on a simulated plain image exhibiting a stain.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig2.tif"/></fig></p>
</sec>
<sec id="sec5-0040517512458340"><title>Important modification</title>
<p>The implementation of all researchers using FFT and cross-correlation (sliding window) to detect woven fabric defects was found to be very similar. Throughout the research, the obtained results were usually poor with various detection errors. Also, the images of the real fabric were always of poor quality. In addition, there are fuzziness and confusion during the mathematical calculations of some important detection factors such as the coefficient of feature correlation. Moreover, there was no answer to different important questions related to the parameters which should be considered during defect detection. For instance, what are these parameters? Is it possible to optimize them? What about noise?</p>
<p>In our work, the major improvement or modification is that we introduce a comprehensive study for fabric defect detection using FFT and cross-correlation to obtain robust detection results, remove any confusion, and answer the questions raised above. To do that, we first determine the most important parameters during the process of defect detection and then optimize each of them, including noise. Also, a level selection filter is developed to minimize as much as possible the detection errors.</p>
</sec>
<sec id="sec6-0040517512458340"><title>Fabric images</title>
<p>As much as possible, good quality images must be used. Such quality facilitates a correct feature extraction, which consequently enhances the analysis stage. Therefore, the acquired images should have high resolution, be of a suitable format, and have a high contrast. Moreover, they should be focused with minimum noise and/or rotation. In addition, it is useful to implement the detection technique firstly on synthetic (simulated) images to determine and optimize the most important detection parameters.<sup><xref ref-type="bibr" rid="bibr3-0040517512458340">3</xref>,<xref ref-type="bibr" rid="bibr4-0040517512458340">4</xref></sup> The simulated image we use first is an image free of defects as illustrated in <xref ref-type="fig" rid="fig1-0040517512458340">Figure 1(a)</xref>. From this image, we generate the other images which contain the most major defects. The chosen major defects are as follows: hole, oil stain, float, coarse-end, coarse-pick, double-end, double-pick, irregular-weft density, miss-end, and miss-pick. These defects represent all possibilities regarding the expected defect type, size, and direction i.e. warp direction, weft direction, and/or both (area).</p>
<p>Obviously, after applying the proposed procedure on simulated fabric images, we should examine it on different images of real plain fabric. Thus, a flat scanner is used to capture various plain fabric samples containing different types of defects. As our object is to automate the visual inspection, the minimum level of resolution during our work is set to 300 dpi (the actual resolution limit of human vision).<sup><xref ref-type="bibr" rid="bibr6-0040517512458340">6</xref></sup> Then, it was increased gradually by a step of 200 dpi to 1300 dpi. Finally, the acquired images are stored in 256 gray levels through matrices of size 500 × 500 pixels.</p>
</sec>
<sec id="sec7-0040517512458340"><title>Strategy of implementation</title>
<p>The procedure of performing our proposed technique passes through three stages or phases to ensure robust final results. Within the first (training) stage, an inspection of the simulated fabric image free of defects takes place. The main objective here is to calculate the feature important parameters, for instance, the extreme values or peaks. Then, these values are used to choose the first threshold. During the second (testing) stage, several fabric images having pre-determined defects are used. The purpose is to highlight the well-known existing defects. In addition, only the features of interest (the seven features) are calculated. The amount by which these features lie below the value of the chosen threshold in the training stage is considered as a defect measurement. Then, these optimized values are used (with another fine tuning) for real fabric images to show the success of the technique. In these two stages, we use images containing pre-determined defects. It means that the severity, the dimension, and the orientation of all defects are well known. But as fabric defects are distributed randomly and dynamically, a perfect robust automation of the visual inspection process requires unsupervised defect detection. It refers to the detection of unknown class of defects for which there is no training. Therefore, the objective of third stage is to detect all types of defects regardless their size or position inside the fabric. Moreover, the technique will be examined with plain fabrics of different colors. Finally, our proposed algorithm, technique, and all associated optimizations were accomplished by implementing several Matlab and Scilab scripts.</p>
</sec>
</sec>
<sec id="sec8-0040517512458340"><title>Defect detection parameters</title>
<p>This part of our research work helps us to develop an appropriate method for choosing parameter settings and fine tuning the performance of the used algorithm. Such parameters along with their optimization methods are demonstrated as follows:</p>
<sec id="sec9-0040517512458340"><title>Acquisition resolution</title>
<p>It is well known that we cannot obtain high quality products from poor raw material. The digital image of the fabric is to be considered as the raw material of our work. The importance of this parameter stems from:
<list id="list2-0040517512458340" list-type="bullet">
<list-item><p>It is responsible for demonstrating the statistical features differences.</p></list-item>
<list-item><p>It determines also the minimum defect size that could be detected.</p></list-item>
<list-item><p>This item with fabric width determines the number of cameras required for online detection systems.</p></list-item>
</list></p>
</sec>
<sec id="sec10-0040517512458340"><title>Sub-image size</title>
<p>This parameter may be considered as the most important one because it represents the segmentation stage in our image processing procedure. The next criteria present some critical considerations during optimization of this parameter:
<list id="list3-0040517512458340" list-type="bullet">
<list-item><p>Both minimum and maximum size (in pixels).</p></list-item>
<list-item><p>The relationship between the size in the warp direction and the size in the weft direction.</p></list-item>
<list-item><p>How can we move between the minimum and maximum sizes?</p></list-item>
<list-item><p>What about defect type?</p></list-item>
</list></p>
<p>In the beginning, we had to start from where others ended. In Tunák and Linka,<sup><xref ref-type="bibr" rid="bibr4-0040517512458340">4</xref></sup> the size of 50 × 50 pixels was determined to detect fabric defects. Therefore, it is estimated that this value could be considered as an average for the sub-image size. In addition, the average equals (<italic>N</italic>/10), where <italic>N</italic> equals 500 pixels. Consequently, both minimum and maximum values could be considered as functions of <italic>N</italic> so that the maximum value is <italic>N</italic>/5 and the minimum is <italic>N</italic>/15. The decision has been made based on approximately doubling and halving the average value. Also, when the sub-window size is out of those selected limits, the performance of defect detection is very poor.</p>
<p>The relation between the size in the warp direction and the size in the weft direction is another important factor. In fact, there are two possibilities: either they are equal or not. During our first trials, we implemented different sizes in both directions but we obtained many detection errors rather than a large number of images with no errors. In addition, the main image should be sub-imaged so that the difference between sizes is an equal integer in both the weft and the warp directions. Finally, the suitable sub-image size will be optimized for each defect type and then for all types simultaneously. <xref ref-type="fig" rid="fig3-0040517512458340">Figures 3(a) and 3(b)</xref> illustrate the optimization results (a stain has always been chosen).
<fig id="fig3-0040517512458340" position="float"><label>Figure 3.</label><caption><p>Optimization of sub-window size for a simulated image exhibiting a stain.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig3.tif"/></fig></p>
</sec>
<sec id="sec11-0040517512458340"><title>Scanning step</title>
<p>Our objective during the scanning of the main fabric image is to cover the whole area of the image. This could be achieved for all step values from 1 × 1 pixel to those values when the scanning step is equal to the sub-image size. Logically, optimization in this case means the choice of the higher step value to minimize the total detection time and the intensive overlapping as well. In addition, the step limits during the optimization are related to the limits of sub-window size. Therefore, for each defect type, the scanning step and the sub-image size will be optimized simultaneously. In addition, we will study the relationship between the two parameters to determine mathematically the shape of this correlation, if possible.</p>
</sec>
<sec id="sec12-0040517512458340"><title>Noise level</title>
<p>In the weaving process, it is expected that during the running of the weaving machines vibrations will result in slightly defocus images. It means that the captured images will be rather noisy and this situation influences the detection reliability. Thus, the simulation of such real circumstances (noisy images) increases the credibility of our implemented technique. Such simulation is obtained through adding four different levels of Gaussian noise to all (simulated and real) fabric images. Consequently, defect detection is implemented on the noisy images. It is absolutely reasonable to optimize the higher level of noise which has no effect on the detection results. This optimization helps us to adjust the actual situation during the weaving process.</p>
</sec>
<sec id="sec13-0040517512458340"><title>Feature correlation coefficient value</title>
<p>This parameter assesses how good a set of features is for implementing our technique. It is estimated that the maximum used value should be smaller than 1.0 (the case of exact correlation). Thus, different coefficient correlation values (0.7, 0.75, 0.8, 0.85, 0.9, 0.95, and 0.99) are used during the optimization of this parameter. As it is found that very fine tuning has no effect on detection credibility, the step between each two used coefficient values is 0.05. Our object is to define only one or two values suitable for all detection circumstances.</p>
</sec>
<sec id="sec14-0040517512458340"><title>Detection time</title>
<p>Feasibility of the considered technique depends on the time it requires. Although we will implement the technique for online inspection where fabric production speeds are slow when compared with those of offline inspection, detection time still represents an important parameter in our study. Certainly, the detection time for each case study is different and depends also on the computer that is used. Studying the influence of each detection parameter on the total detection time helps us to choose one optimum value if several values are available.</p>
</sec>
</sec>
<sec id="sec15-0040517512458340"><title>Technique reliability</title>
<p>Technique reliability is very important as it determines its performance or efficiency. In this work, we will use the false alarm rate to characterize such reliability. A false alarm (false positive) occurs when our technique highlights an image area as a defect when it is not a defect. Moreover, the false negative occurs when the technique fails to highlight an existing defect. False detection rate is calculated as the total number of images containing false results divided by the total number of processed images. As it is found that most detection errors are positive (to reduce false negatives, we lower the threshold), we developed a level selection filter to avoid this drawback. For the sake of clarity, implementation of such a filter will be described considering the actual graphical output of our program. During the process of defect detection, as explained before, if there is a defect, it will be highlighted by overlapping red square overlays. Each square corresponds to the test of one sub-image. In addition, we are supposed to get redundant information, provided that original images are sampled with overlapping sub-windows. With a proper choice of the sample step, each pixel appears in four sub-images. Our level selection filter counts in how many defective sub-windows the pixel appears. It can appear from zero times to four times.</p>
<p>Therefore, we can obtain four levels as follows:
<list id="list4-0040517512458340" list-type="bullet">
<list-item><p>Level 1: an area is scanned and consequently counted one time.</p></list-item>
<list-item><p>Level 2: an area is scanned and consequently counted two times.</p></list-item>
<list-item><p>Level 3: an area is scanned and consequently counted three times.</p></list-item>
<list-item><p>Level 4: an area is scanned and consequently counted four times.</p></list-item>
</list></p>
<p>Based on the filter, fine tuning takes place to determine the degree of accuracy for defect detection. For instance, if level 4 is considered, we are sure that the area has a defect while level 1 could be considered as a false alarm. The area in level 3 is to be considered also as a defect whereas the area in level 2 needs more training to decide if it will be considered as a defect or not. <xref ref-type="fig" rid="fig4-0040517512458340">Figure 4(a)</xref> shows the implementation of the filter on a simulated fabric image containing a stain while <xref ref-type="fig" rid="fig4-0040517512458340">Figure 4(b)</xref> illustrates the color map of the filter result. Each sub-image has a different color. The overlapping between two or more sub-images results in another different color (usually darker). From <xref ref-type="fig" rid="fig4-0040517512458340">Figure 4(c)</xref>, the exact highlighting of the defect is obvious.
<fig id="fig4-0040517512458340" position="float"><label>Figure 4.</label><caption><p>The filter applied on a simulated fabric exhibiting a stain.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig4.tif"/></fig></p>
</sec>
<sec id="sec16-0040517512458340" sec-type="results"><title>Results and discussion</title>
<sec id="sec17-0040517512458340"><title>Defect detection for simulated fabric</title>
<p>Due to the various factors affecting the results when implementing our detection technique, a large number of images are obtained. From these results and during the optimization of the procedure when using the simulated images, it is found that the sub-window size and the scanning step are the most important detection parameters. In fact, for each defect type, it is found that many values are suitable to detect the defect. What is important here is to find only one or two values for each parameter suitable to detect all defect types. It is found that the detection errors are increased if low and/or high values of sub-window size and scanning step are used. Moreover, the suitable values of the these two parameters are between a 50 × 50 to 65 × 65 pixel sub-window size and a 20 × 20 to 30 × 30 pixel scanning step. The value of the feature correlation coefficient threshold plays an important role in the success of the implemented technique. The use of lower coefficient values increases the detection errors especially in the case of low scanning values. Finally, our technique is able to detect all defects even with noise. Therefore, to ensure optimum defect detection for all defect types, the size of the sliding window is set to 60 × 60 with a 30 × 30 pixel scanning step while the correlation coefficient is set to a value 0.8. In addition, level 3 is found as the optimum level when the level selection filter is implemented. <xref ref-type="fig" rid="fig5-0040517512458340">Figure 5</xref> shows the success of the technique in detecting all defect types in the case of a simulated plain structure.
<fig id="fig5-0040517512458340" position="float"><label>Figure 5.</label><caption><p>The implementation of the detection technique on various simulated fabric images contain defects.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig5.tif"/></fig></p>
</sec>
<sec id="sec18-0040517512458340"><title>Defect detection for real fabrics</title>
<p>The optimization results in the previous step are used here during the implementation of the technique on real fabric images. It is found that the image acquisition resolution is another important detection parameter. The best detection results are obtained at 1000 dpi resolution. The pre-optimized detection parameters are fine tuned for the real plain structure. It is found that to obtain the optimum detection results, the size of the sliding window needs to be set to 50 × 50 with a 25 × 25 pixel scanning step for some defects and 60 × 60 with a 28 × 28 pixel scanning step for the other defects whereas the correlation coefficient value needs to be set to 0.75 and 0.8. Also, the different added noise levels have a subtle effect on the detection results especially in the case of higher levels of noise. During the implementation of the level selection filter, it is found that level 3 is the optimum one. Through these results, our defect detection technique is able to detect each fabric defect of a 1.5 mm size with a 100% detection rate. <xref ref-type="fig" rid="fig6-0040517512458340">Figure 6</xref> shows the success of the technique in detecting all defect types in the case of real white plain fabric whereas <xref ref-type="fig" rid="fig7-0040517512458340">Figure 7</xref> shows the implementation of the level selection filter at level 3 on the same fabric images.
<fig id="fig6-0040517512458340" position="float"><label>Figure 6.</label><caption><p>The implementation of the detection technique on real fabric images.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig6.tif"/></fig>
<fig id="fig7-0040517512458340" position="float"><label>Figure 7.</label><caption><p>The implementation of the third level selection filter on real fabric images.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig7.tif"/></fig></p>
</sec>
<sec id="sec19-0040517512458340"><title>Defect detection for real colored fabrics</title>
<p>Rationally, the white plain fabric is chosen in our study because, on the one hand, the vast part of raw woven fabric exists in this form. On the other hand, the real fabric images should resemble the real images. To prove the utility of the procedure used and as one step in the unsupervised stage of fabric defect detection, colored (black) fabric images acquired under the same optimized resolution (1000 dpi) are used. <xref ref-type="fig" rid="fig8-0040517512458340">Figure 8</xref> illustrates the success of the technique to detect all defects.
<fig id="fig8-0040517512458340" position="float"><label>Figure 8.</label><caption><p>The implementation of the detection technique and the filter on real black fabric images.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig8.tif"/></fig></p>
</sec>
<sec id="sec20-0040517512458340"><title>Detection time</title>
<p>After the optimization of all the detection parameters as illustrated above, the detection time is measured as shown in <xref ref-type="fig" rid="fig9-0040517512458340">Figure 9</xref>. During the measurement, the maximum optimized value for each detection parameter is considered. It is found that the measured time is approximately 0.7 seconds for all defect types. During this time, an image of 500 × 500 pixel acquired at 1000 dpi is scanned which is equivalent to 1.27 cm of fabric (the available cameras acquire up to 30 cm of fabric width at such resolution). Consequently, the detection technique is able to inspect at least one meter of fabric each minute. Industrially, high speed weaving machines run at 1000 picks/min while most plain fabrics are produced at 25–30 picks/cm weft density. This means that the productivity of the weaving machine is 33–40 cm/min. Therefore, the speed of the technique is two to three times the machine productivity.
<fig id="fig9-0040517512458340" position="float"><label>Figure 9.</label><caption><p>Measured detection time.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig9.tif"/></fig></p>
</sec>
</sec>
<sec id="sec21-0040517512458340"><title>The proposed prototype</title>
<p>A prototype is proposed to examine the technique in real-time (on the weaving machine). The fabric images are acquired under a source of sufficient illumination by one or more cameras. The camera is synchronized to the fabric motion and used to acquire high-resolution, vibration-free images of the fabric under construction. A central processing unit (computer) is employed for processing the acquired images using our software. The results of the processing are used to detect fabric defects. Also, it is used to take actions for reporting and correcting these defects to replace or remove these parts from the production line. The prototype has to be robust. Thus, it should adapt automatically and achieve consistently high performance despite irregularities in illumination and accommodate uncertainties in angles, positions, etc. <xref ref-type="fig" rid="fig10-0040517512458340">Figure 10</xref> shows the schematic of the proposed vision prototype. It takes fabric images continuously using one line-scan camera that, with the provided optics, has an ability to acquire a 0.3 meter wide image at 1000 dpi resolution. In addition, all detection parameters are set to their optimized values. Again, it is found that our online automated fabric inspection prototype is capable of identifying the existing fabric defects.
<fig id="fig10-0040517512458340" position="float"><label>Figure 10.</label><caption><p>Schematic of the vision prototype.</p></caption><graphic xlink:href="10.1177_0040517512458340-fig10.tif"/></fig></p>
</sec>
<sec id="sec22-0040517512458340" sec-type="conclusions"><title>Conclusions</title>
<p>This research work introduces a comprehensive study using FFT and CCTs to detect the structural defects of plain weaves in gray levels. To obtain robust detection results, we first use simulated fabric images to determine the most important parameters during the process of defect detection and then optimize each one, even in the case when there is noise. In addition, a level selection filter with four different accuracy levels is developed to minimize as much as possible the detection errors and to obtain acceptable results for the process. Several results of the proposed technique for the simulated and real plain fabric structures with the most common defects are presented. It is found that for simulated and real fabric images, the optimum defect detection for all defect types is obtained when each detection parameter is set to only one or two values. Such values are approximately the same for both simulated and real fabric images. Also it is found during the implementation of the level selection filter that level 3 is the optimum level for both simulated and real fabric images. Moreover, our proposed detection technique is able to detect each fabric defect of a 1.5 mm size with a 100% detection rate even with the deferent added noise levels. Finally, as the technique is fast and corresponds to the speed of the weaving machine, it could be used for online fabric defect detection. To verify the success of the technique in real-time, a vision-based fabric inspection prototype that could be accomplished on-loom to inspect the fabric under construction with 100% coverage is proposed.</p>
</sec>
</body>
<back>
<sec id="sec23-0040517512458340"><title>Funding</title>
<p>This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="bibr1-0040517512458340"><label>1</label><citation citation-type="journal"><comment>Malek A, Drean J-Y, Bigue L, et al. Automatic fabric inspection: invention or innovation. In: <italic>International conference on intelligent textiles and mass customization</italic>, Casablanca, Morocco, 27–29 October 2011</comment>.</citation></ref>
<ref id="bibr2-0040517512458340"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Behera</surname><given-names>BK</given-names></name><name><surname>Text</surname><given-names>B</given-names></name><name><surname>Tech</surname><given-names>M</given-names></name></person-group>. <article-title>Image processing in textiles, a critical appreciation of recent developments</article-title>. <source>Textile Progress</source> <year>2004</year>; <volume>35</volume>: <fpage>127</fpage>–<lpage>137</lpage>.</citation></ref>
<ref id="bibr3-0040517512458340"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>C</given-names></name><name><surname>Pang</surname><given-names>G</given-names></name></person-group>. <article-title>Fabric defect detection by Fourier analysis</article-title>. <source>IEEE Trans Indust Appl</source> <year>2000</year>; <volume>36</volume>: <fpage>1267</fpage>–<lpage>1276</lpage>.</citation></ref>
<ref id="bibr4-0040517512458340"><label>4</label><citation citation-type="journal"><comment>Tunák M and Linka A. Simulation and recognition of common fabric defects. In: <italic>13th International conference on structure and structural mechanics of textiles (STRUTEX)</italic>, Liberec, Czech Republic, 27–29 November 2006; 363--370</comment>.</citation></ref>
<ref id="bibr5-0040517512458340"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sengottuvelan</surname><given-names>P</given-names></name><name><surname>Wahi</surname><given-names>A</given-names></name><name><surname>Shanmugam</surname><given-names>A</given-names></name></person-group>. <article-title>Automatic fault analysis of textile fabric using imaging systems</article-title>. <source>Res J Appl Sci</source> <year>2008</year>; <volume>3</volume>: <fpage>26</fpage>–<lpage>31</lpage>.</citation></ref>
<ref id="bibr6-0040517512458340"><label>6</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Roger</surname><given-names>B</given-names></name></person-group>. <source>Fundamentals of digital imaging in medicine</source>, <edition>1st ed</edition>. <publisher-loc>London</publisher-loc>: <publisher-name>Springer</publisher-name>, <year>2010</year>, pp. <fpage>110</fpage>–<lpage>110</lpage>.</citation></ref>
</ref-list>
</back>
</article>