<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AJE</journal-id>
<journal-id journal-id-type="hwp">spaje</journal-id>
<journal-title>American Journal of Evaluation</journal-title>
<issn pub-type="ppub">1098-2140</issn>
<issn pub-type="epub">1557-0878</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1098214012464300</article-id>
<article-id pub-id-type="publisher-id">10.1177_1098214012464300</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Oral History</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Oral History of Evaluation</article-title>
<subtitle>The Professional Development of Joseph Wholey</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Miller</surname>
<given-names>Robin Lin</given-names>
</name>
<xref ref-type="corresp" rid="corresp1-1098214012464300"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Caracelli</surname>
<given-names>Valerie</given-names>
</name>
</contrib>
<contrib contrib-type="author">
<collab>The Oral History Project Team</collab>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-1098214012464300">Robin Lin Miller, Michigan State University, Department of Psychology, East Lansing, MI 48824, USA. Email: <email>mill1493@msu.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>34</volume>
<issue>1</issue>
<fpage>120</fpage>
<lpage>131</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">American Evaluation Association</copyright-holder>
</permissions>
<kwd-group>
<kwd>evaluation history</kwd>
<kwd>professional development</kwd>
<kwd>Joseph Wholey</kwd>
<kwd>Urban Institute</kwd>
<kwd>Department of Health and Human Services</kwd>
<kwd>GPRA</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Since 2003, the Oral History Project Team has conducted interviews with individuals who have made signal contributions to evaluation theory and practice. In 2011, Valerie Caracelli and Robin Miller traveled to Virginia to meet with Joseph S. Wholey. We conducted an interview with Wholey lasting 1 hr and 25 min, which we then transcribed verbatim. Working with Wholey, we edited the transcript for clarity and length. The final product was reviewed and approved by Wholey prior to submission to <italic>AJE</italic>.</p>
<p>Joseph S. Wholey is Professor Emeritus in the University of Southern California’s (USC) School of Public Policy, Planning, and Development. He received his BA from Catholic University, Phi Beta Kappa and his MA in mathematics and PhD in philosophy from Harvard University. His work focuses on the use of strategic planning, performance measurement, and evaluation to improve the performance and the accountability of public and nonprofit organizations. During the Johnson Administration, he served as Special Assistant to the Deputy Assistant Secretary for Program Analysis and as Director of Program Evaluation at the Department of Health, Education, and Welfare, now the U.S. Department of Health and Human Services. From 1968 to 1978 he was Director of Program Evaluation Studies and senior staff member at the Urban Institute. From 1971 to 1978, he was a member of the County Board of Arlington, Virginia. He returned for 2 years to HHS as Deputy Assistant Secretary for Evaluation. In 1980, Wholey was appointed Professor of Public Administration at USC, based at USC’s Washington, DC, Public Affairs Center. In conjunction with teaching, Wholey served as Senior Advisor to the Deputy Director for Management at the U.S. Office of Management and Budget (1994–1996) and as Senior Advisor for Evaluation Methodology and Senior Advisor for Performance and Accountability (1996–2002) at the U.S. Government Accountability Office. He was instrumental in assisting Congress and executive branch agencies in the development and implementation of the Government Performance and Results Act (1993) and other performance-related initiatives. Wholey is a fellow of the National Academy of Public Administration and cofounder of the American Evaluation Association. In 1979, he received the Alva and Gunnar Myrdal Government Evaluation Award from the Evaluation Research Society and in 1983 he received the Elmer B. Staats Award from the American Society for Public Administration. In 1999, the American Society for Public Administration inaugurated a distinguished scholar award in Joe’s name and honored him as the award’s first recipient. He is the author of many journal articles and is the author, coauthor, editor, or coeditor of eight books, including the <italic>Handbook of Practical Program Evaluation</italic> (now in its third edition, coedited with Harry Hatry and Kathryn Newcomer).</p>
<p>Theorist, evaluator, educator, author, in this oral history, Joseph Wholey shares his work and views on fostering good government. Wholey’s lifework focuses on how evaluators can constructively help federal policy makers and program managers make program theory manifest, clarify program objectives, and deliver relevant and useful performance information for program improvement. Wholey began to popularize the various tools that could benefit program management in timely and useful ways in the early 1970s. In <italic>Foundations of Program Evaluation</italic>, <xref ref-type="bibr" rid="bibr2-1098214012464300">William Shadish, Thomas Cook, and Laura Leviton (1991</xref>) note that Wholey may be the most influential theorist covered in their book. But it was his instrumental role in the passage and implementation of the Government Performance and Results Act in 1993, recently modified as the GPRA Modernization Act of 2010 (GPRAMA), that makes Wholey’s drum beat as loudly today as it did then. His ideas maintain currency and importance with government’s emphasis on evidence-based policy and practice. Pursuing the goal of social betterment depends on efficient and effective programs that serve society’s needs. Today, as evaluators take issue with performance information and the emphasis placed on favoring either performance measurement or evaluation, we see that Wholey has always emphasized the importance and complementarity of both. His promotion of what he termed the <italic>sequential purchase of information</italic> for decision making has become part of our profession’s lexicon, including evaluability assessment, performed when there is a need is to determine whether a program meets preconditions for designing an evaluation that can lead to program improvement, rapid feedback evaluation, performance monitoring, and periodic evaluations. In the edited transcript of our interview that follows, he uses the analogy of an apple to remind us that each bite of performance information has a role in providing policy makers and program managers with relevant and useful information for improving government performance and results.</p>
<sec id="section1-1098214012464300">
<title>Interview with Joseph Wholey</title>
<speech>
<speaker>Valerie:</speaker>
<p>How did you move from a master’s degree in mathematics and a doctorate in mathematical philosophy to government?</p>
<p>Joe: I was actually in the Harvard philosophy department . . . got a PhD in philosophy. I was teaching at Rutgers, next I was in the Pentagon working on operations research in the field of general nuclear war and how we would not bomb everything in the Soviet Union. I was working on civil rights and social action evenings and weekends, and general nuclear war by day, and a friend of mine suggested that I might go over into HEW.<sup><xref ref-type="fn" rid="fn1-1098214012464300">1</xref></sup> They were getting into the planning–program–budgeting system, which came from McNamara’s Defense Department and then was being spread by the Johnson Administration to the other departments as well. My friend suggested, “put your name in over there,” so the next thing I was working for Alice [Rivlin].<sup><xref ref-type="fn" rid="fn2-1098214012464300">2</xref></sup></p>
<p>This was the time of the Civil Rights Act, the Economic Opportunity Act, and so forth.<sup><xref ref-type="fn" rid="fn3-1098214012464300">3</xref></sup> I was in the March on Washington.<sup><xref ref-type="fn" rid="fn4-1098214012464300">4</xref></sup> I was right up against the statue when Martin Luther King was speaking.<sup><xref ref-type="fn" rid="fn5-1098214012464300">5</xref></sup> I couldn’t see him. I could only hear him because he was right up above me.</p>
</speech>
<speech>
<speaker>Robin:</speaker>
<p>So the move was in part a way to reconcile your nightlife with your daytime activities, yes? Create more synergies than conflicts?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Yes. This McNamara idea, as opposed to the massive retaliation under President Eisenhower, was a big step forward. If they don’t bomb our cities, we won’t bomb theirs. I was working on how you keep track of which weapons have been used and so forth. The theory was you’d maintain civilian control of the nuclear forces during a nuclear war, which was probably a romantic idea.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>Describe the early influences that led you toward the path of federal evaluator and evaluation theorist.</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Well, I guess to become an evaluator one certainly important influence is being a policy analyst. I was in the Johnson Administration and working in what now is called ASPE<sup><xref ref-type="fn" rid="fn6-1098214012464300">6</xref></sup>—planning and evaluation—it had a different name then. We were doing policy analysis in the maternal and child health field and other fields. Alice Rivlin was my boss and Bill Gorham<sup><xref ref-type="fn" rid="fn7-1098214012464300">7</xref></sup> was her boss, Deputy Assistant Secretary and Assistant Secretary. This was back in the days of planning–program–budgeting. You do policy analysis to figure out the most cost-effective things to do and you notice that you don’t know what the existing programs are accomplishing. So, we got into evaluation then. In fact, we wrote that into some legislation, the Maternal and Child Health Act and the Public Health Service Act, set-asides for evaluation. It helped to fuel a whole evaluation industry inside HEW, now the Department of Health and Human Services. So that’s an early influence on getting into evaluation.</p>
<p>Now as far as being a theorist, I didn’t know I was one! I think at the Urban Institute<sup><xref ref-type="fn" rid="fn8-1098214012464300">8</xref></sup> and other places I wrote things and published them. I suppose we were creating the field of evaluation at the federal level. I was actually interested in evaluation for helping improve programs. When we got into it originally, it was after all to help do policy analysis. Very few programs ever end, at least at the federal level, so the idea of trying to improve the programs we have, that would be one of the main purposes for evaluation. That was, I guess what got me into helping develop evaluation theory.</p>
<p>[The first time I was] in HEW [during the Johnson Administration], I was a political appointee. I was only there 2 years, but I went from being Alice’s assistant to being the head of evaluation in HEW. ASPE had a very small staff, maybe 20 people. When I came back [to HEW in 1978], there were about 200! It had inherited a big research program from the old Office of Economic Opportunity. The whole Office of the Secretary had grown. When I came back, I was Deputy Assistant Secretary for Evaluation. That was when Jimmy Carter was President and Califano<sup><xref ref-type="fn" rid="fn9-1098214012464300">9</xref></sup> was the Secretary.</p>
</speech>
<speech>
<speaker>Robin:</speaker>
<p>How would you compare and contrast where evaluation was in that first office with the larger landscape of evaluation in the federal government at that time?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I had a chance a few years later to write about that. My first book was Federal Evaluation Policy [The Urban Institute, 1970]. In the Office of Economic Opportunity they were trying new things and they were trying to figure out if they worked or not. Things like the Job Corps and the legal services program. They were trying lots of different things. There was a lot of evaluation there. Also, in the training programs, the Labor Department had a lot of evaluation going. Then both in the education arena and in the health arena a lot of evaluation started going in HEW. The fourth area was the Department of Housing and Urban Development (HUD). Those were the four leaders in evaluation in those days. The Department of Housing and Urban Development had a sort of policy research arm that did a lot of evaluation as well. I think Donna Shalala headed that at one point.<sup><xref ref-type="fn" rid="fn10-1098214012464300">10</xref></sup></p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>You mentioned improvement.</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I was at the Urban Institute. We had the evaluation office there from when the Urban Institute was created.<sup>
<xref ref-type="fn" rid="fn11-1098214012464300">11</xref>
</sup> It was at the end of the Johnson Administration. The Ford Foundation put money in and they took money from the Department of Housing and Urban Development. There was 10 million dollars to start, 5 million from HUD and 5 million from the Ford Foundation. We could generate some of our own projects rather than have to look for grants and contracts. We were getting grants and contracts. We were doing—must have had 25 evaluators at one point, and six secretaries back in the days of secretaries. We made some of them into research secretaries so they could help do the studies as well. At a certain point, we decided to evaluate our own work. It wasn’t the most scientific thing but you try to see how these studies were done and what happened. We found that quite often the studies were not getting much use. Then we had to decide what to do about that.</p>
<p>One thing we decided to do was to build into each study a little evaluation of that study—the results of that study. We called them case studies of the work and what happened after the work was done. This led us into wondering if we could focus the studies better at the start so they would be used when they were finished. And that got us into this whole arena of so-called evaluability assessment. It’s really the front end work that you do—GAO does a lot of this too, to make sure (a) you can get the data you’re going to need and (b) that people will use it when you turn it in. [Would it help] the program get any better?</p>
<p>You have to see what is the range of feasible action, the range of feasible response to the studies because often times the people closer to the program, who you might call the managers, don’t have the authority to make the changes that are needed. We thought of management going upward quite a bit from the people that are called the program managers to bureau chiefs and people even higher. In our view, and even in the Budget Bureau and other places, they were helping manage the program. We called them “those in charge.” Because you are not going to get new legislation, there were a finite number of people who really cared about the program and could influence it. Sometimes they’d be staff people on the Hill. In this evaluability assessment, we would work to do a certain small number of interviews and read whatever we could to see what questions people were interested in and what they might do if they had the answers to them and then help focus the evaluations. It was kind of like you were trying to see if you could find a user out there who would make it worthwhile to do the study. Otherwise the idea was to do the smallest study possible, if it wasn’t going to be used by anybody, and get on to the next job.</p>
<p>People in the evaluation office over there at the Urban Institute were inventing this stuff and I was writing about it so then I was thought of as the person who was doing all these studies. Actually I was benefitting from the work of a very good staff. And letting it be known that we really contrasted evaluation with research. Research was to build knowledge and, from our point of view, mainly evaluation was to improve programs. It was different. There were things to write about in that vein. I think I had a fairly traditional view of evaluation when I started at the Urban Institute and then later on got much more interested in this. In fact, we invented a second sort of mini-evaluation. In evaluability assessment, you figured out how to aim the study and whether you were going to be able to get the data. The second [bite], we called rapid feedback evaluation. When I went over to HEW the second time, we called it short-term evaluation. But the idea was to quickly do a study to help you aim the bigger study. You had two [bites of] the apple up front. We were calling that the sequential purchase of information: You do the micro-study, then the mini-study, and then maybe you do the bigger study or maybe you didn’t even need to do the bigger study.</p>
<p>I remember the first rapid feedback evaluation because the Department of Housing and Urban Development wanted the terms of reference for a bigger study to be developed by somebody. We said we’d just invented rapid feedback evaluation but we’ve never done it. We’d like to use that as the process to help you write the job description for what later would be put out on contract to somebody else. And the great thing about it, it was rapid feedback evaluation of what was called Operation Breakthrough. Governor Romney<sup><xref ref-type="fn" rid="fn12-1098214012464300">12</xref></sup>—the first Governor Romney—had run an automobile company and he was fascinated by the idea of housing low-income people with industrialized housing production. You might call it prefabricated housing. It was a very difficult thing to get building codes changed so it was a big demonstration project. The Congress had wanted an evaluation of it. We did our rapid feedback evaluation; gave our answers. Then they let the bigger contract and did the bigger study. We had people saying that everything that could be learned was learned already from the rapid feedback evaluation. One reason for that is a lot of programs are poorly structured for evaluation. Maybe it’s not too surprising that in 6 months you could learn what could be known about the effectiveness of a program. Anyhow evaluability assessment caught on somewhat, but rapid feedback evaluation never did. We had two inventions and one more famous than the other.</p>
</speech>
<speech>
<speaker>Robin:</speaker>
<p>Why do you think one caught on and one didn’t catch on?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I remember Len Rutman the Canadian wrote a book on evaluability assessment (<xref ref-type="bibr" rid="bibr1-1098214012464300">Rutman, 1980</xref>). He captured it quite early. Later on, evaluability assessment had much more to do with looking into the actual program during the design phase for a bigger study. That was not in the early version of evaluability assessment. I think different people kind of liked the idea of this micro-study to help you aim a bigger study. We said it doesn’t have to be a separate thing. It could just be called “here is how we do the design phase” of an evaluation. Here is one way. There are other ways, but you could just say “Here’s how we do our studies.” Say you had a contract or somebody told you to evaluate something. You could use evaluability assessment to help you aim the study. There is more design work needed once the actual evaluation is starting. You want to design it so you’ll have measures that’ll work and some kinds of comparisons that you can make that’ll help you to see if the program is producing something. [And then you want] some ways of conveying the information in usable form so that some specific people will make some use of it. It was kind of a sensible idea. We were doing training in evaluability assessment in the early days one time down in South Carolina. They said, “This is just common sense.” We said, “Oh, we’re accused of common sense. Oh how terrible!” We didn’t mind. As I say, it was different from the idea of staying quite far away from decision makers and doing your best “research” job of designing an evaluation. The [evaluability assessment versus research approach] was something [of] a matter for debate. You’d go to conferences. This way is better than that way and so forth. We were developing evaluation theory, even though I didn’t know it.</p>
<p>Later on I became a university professor [at USC]. I published a book about work done during the Carter years. I had a chance to talk about not just the work we were doing ourselves but . . . I remember Mike Hendricks was involved with what was called service delivery assessment. Those were quick studies done by an Inspector General’s staff. Mike was helping aim those. I was kind of an outside advisor being in a sister part of the Office of the Secretary. Hale Champion was Califano’s Undersecretary.<sup><xref ref-type="fn" rid="fn13-1098214012464300">13</xref></sup> They didn’t have a Deputy Secretary in those days. He was quoted years later as saying that Joe Wholey was trying to take the spirit out of service delivery assessment, making it a little too researchy because from my point of view if you’re going to do a sample, why not make it a stratified random sample, but not from Hale Champion’s point of view. It wasn’t rapid feedback evaluation but it showed that you can get an awful lot of useful information quite quickly. It was quite exciting too because Califano or Champion would be briefed and they would make decisions right in front of your eyes, you know, as to what we were going to try to do to make the program better.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>It was like a briefing?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Yes, it was a briefing. They would have a 20-page report. The funny thing was that these people had been in regional offices as evaluators and they knew that reports weren’t 20 pages long, so they would write a 200-page technical appendix. Nobody wanted it but they knew that was what evaluations were supposed to be like. It was quite exciting that the people who did the studies were people from out in the field. They would get to brief the Secretary or the Undersecretary themselves. Mike Hendricks taught them how to give briefings. You never sit down because you are the most junior person in the room but while you’re still on your feet, you can then re-enter the conversation if you need to. Never sit down!</p>
</speech>
<speech>
<speaker>Robin:</speaker>
<p>Was there a particular evaluation that provides a good example this brief report, doing the briefing, and seeing use right there in front of you?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I think the first one that was briefed was a service delivery assessment of the Head Start Program and out of it came Califano wanting to have what we now call a performance measurement system so you could see what Head Start was doing. I was put to work on that and came back to Califano with a system based on classroom observation. No. He wanted outcome information, like do the kids flunk kindergarten or something of that nature as the measurement system. I thought that the Head Start Program was itself a very interesting example. Most Head Start programs are really terrible and still to this day are really terrible. The evaluations show that. And yet politically it’s in such an unassailable position that people just keep putting more money in and every now and then try to fix it somewhat. It is sort of a discouraging example of nonuse of evaluation. Not that we’re against little children, but it doesn’t lead to program improvement.</p>
</speech>
<speech>
<speaker>Robin:</speaker>
<p>When you and your colleagues were trying to think about this notion of sequential purchase of information, how were you thinking about the very political nature of decision making?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Well, we were up close to politics. We were right there in Washington getting to see some studies ignored entirely. There was a program called Health Start, I think, which was just like the health piece of Head Start. We did a little evaluation of that, turned it in, and the audience didn’t like it, so they just tried to bury it . . . successfully. They couldn’t make us change our conclusions. But they didn’t like the ones that were finally in there. That didn’t mean they had to publicize them very widely.</p>
<p>The third [bite] of the apple was going to be either an evaluation study or a performance measurement system or outcome monitoring system or whatever you might want to call it. I think that there were enough examples of people deciding to do something constructive that we were just encouraged that this idea of evaluation for use really was the right way to go and evaluation that typically wasn’t going to result in grand policy decisions was a helpful way to go.</p>
<p>One other little piece though, that came out, was during the Carter Presidency when I was back in there as Deputy Assistant Secretary,<sup><xref ref-type="fn" rid="fn14-1098214012464300">14</xref></sup> and the Senate Appropriations Committee was very down on evaluation. They said that year after year, the same programs get reevaluated, yet never change. I had this functional manager responsibility for, I think, 20 different evaluation offices sprinkled throughout the Department. We collected all these examples of evaluations done and programs changed. We packaged it up into a report for the Senate Appropriations Committee. The Secretary sent it over there. And we did it a second year. This was great! You know, we were getting a pulse and we were socializing these different evaluation offices that they shouldn’t just fund their own policy research: they should fund evaluation for use. Here are examples after examples. Let’s keep doing this!</p>
<p>But the Senate Appropriations Committee said we get all these reports all the time and no one looks at them, and so they weren’t the customer any longer. It was kind of discouraging in that way because it was really going well and helping us to move the evaluators in the Department in a good direction. I remember that Jim Moran, who is now a Congressman,<sup><xref ref-type="fn" rid="fn15-1098214012464300">15</xref></sup> was the staff person we were often reporting to over there. When the Senate Appropriations Committee says something, people in the Department pay a lot of attention. It was helping us aim the evaluations done in the Department in a good direction. Our way of doing evaluations wasn’t the only good way. There are other good ways to do evaluation.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>You said once something that I thought was very interesting. You were speaking with students about the criticism in Shadish, Cook, and Leviton (1991) that you pay too much attention to managers. And your response was that you must be the humble evaluator who surrenders some of his or her sovereignty to others in the interest of relevance.</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Yes. We were kind of misinterpreted because people thought we meant the people who were the program manager or maybe the bureau chief. But we meant the people who have the greatest influence on the program. And so we wanted to surrender some of our sovereignty in what would be the focus of the work to people who were likely to use the information to influence and, we hope, improve the program. That didn’t mean you had to keep every last little tiny program but if we are trying to help in a certain area of responsibility of the government, we want the best job to be done that could be done. We would be humble [in the sense that we were] not going to be the ones to choose the goals, the measures, the comparisons, you know, the analytical framework. We’re going to let other people have a chance at that partly by [letting those responsible for programs] know what each other was saying, partly by letting them know how the program seems to be working, what sort of information could be obtained at reasonable cost [and in a reasonable time frame], and so forth. Focusing on intermediate outcome variables is often where a piece of evaluation work or a performance measurement system should be aimed. You want intermediate outcome data [because they are connected closely] enough to the program that the program [managers] can influence those variables. And, if you’re lucky, [the intermediate outcomes] are connected [to impacts] by some body of research: you know that if you don’t have too much low birth weight that you’re not going to have too much infant mortality. That’s an easy example. But the evaluation doesn’t have to recreate all of the research. If there’s enough research that you can rely on, then you can get back to the intermediate outcome variables that are more likely to be perceptibly influenced by the program. That would be a contribution.</p>
<p>Often you have to find those variables during the evaluation design process. They’re not in the rhetoric of the program and they’re not in the existing performance measurement system but at some place along the causal chain that either the evaluation or the new performance measurement system is going to focus. It was like Califano saying, you know, we should see whether they flunk kindergarten or not. That would be a good intermediate outcome variable that isn’t being captured in any existing system because you’d have to have a way of tracing children into the schools and maybe some comparison children as well if you want to do evaluation studies.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>Did you ever think of entering politics yourself?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Oh, I did enter politics. I was on the County Board here in Arlington for 8 years. I could, from my experience as a local elected official, say that I didn’t read anything. It was only when we got into strategic planning or long-range planning that I was an eager audience for evaluations. But for day-to-day decision making, there just wasn’t time. You worked through briefings. You might arrange to have more different people from different points of view give the briefings. We created all these different citizen advisory committees to help us so we wouldn’t just be a captive of the city or county manager. In that sense we had a lot more information. They might read evaluations but we were doing it mostly verbally. Most of government decision making is verbal.</p>
<p>Those were interesting times. Having the evaluation staff when I was over at the Urban Institute, and most of that time I was on the County Board here in Arlington. We did strategic planning:Metro<sup><xref ref-type="fn" rid="fn16-1098214012464300">16</xref></sup> was coming. How should Arlington respond? It became known later throughout the country or world as smart growth. We concentrated development as you can just look out the window here near the subway station. Most of Arlington was left just as it was. We did evaluation and policy analysis that changed our political supporters from being no growth people to controlled growth people. Their taxes would be a lot higher if we didn’t take advantage of the economic development possibilities of bringing Metro through Arlington.</p>
<p>I might have thought of going further in politics but I think it was very good that I just served the two terms and voluntarily stepped aside. It was a wise former city manager of Miami-Dade County, who was staffing one of the commissions here in Northern Virginia. He said people stay in local government too long. There’s so much input that you develop a shell and that’s not good. I told him, “Irv,<sup><xref ref-type="fn" rid="fn17-1098214012464300">17</xref></sup> I’m going to not run for re-election.” He said, “You should serve one more term.” I said, “Irv, you told me 8 years is enough!” It was good to do it. I was defeated the first time I ran and then 2 years later I was elected, then I was re-elected, and then chose to step aside. I went back in as Deputy Assistant Secretary [at HEW] as I was just finishing my 8th year on the County Board.</p>
</speech>
<speech>
<speaker>Robin:</speaker>
<p>Did sitting in the position of an elected official change the way you thought about your approach to evaluation when you stepped back into. . .</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I think it was all grist for the mill. We did something that used evaluation while I was on the County Board here. I was also on the Metro subway and bus company Board of Directors and so both here in Arlington and then later in Metro we did some zero-base budgeting, which really means multiple-level budgeting, [that can help] you see what difference it’ll make if you make reductions in proposed expenditures. Often evaluation information is brought forward in that decision arena because people were trying to show that this particular program does some good and shouldn’t be cut. People mine whatever information they have. They might mine evaluation studies or at least performance measurement systems to produce the information to try to convince you not to make these reductions. The head of community relations at Metro said “Well, if we had to make a [I think it was 15%] cut, the first thing is the head of the office would resign”. We went back and asked them “what difference would it make if it was a 30% cut or a 50% cut?” and wound up cutting that off. That’s a lot. Zero-base budgeting was invented originally as a way to hold down staff offices, not operating programs, because staff offices always grow. Jimmy Carter was quite enthused about zero-base budgeting and they were trying to use it for all the programs but I think it makes maybe the biggest sense if you’re trying to hold down the size of the staff offices.</p>
<p>The Defense Department still uses a planning–program–budgeting system I think to this day though it has gone away from the rest of the government. I was impressed when Ken Kizer came in as head of the Veteran’s Health Administration. From his point of view it was sort of a quality management approach. It was developing the right performance measurement systems to help you to create incentives for program improvement. That’s what he did. Stan Divorski<sup><xref ref-type="fn" rid="fn18-1098214012464300">18</xref></sup> was in the GAO at the time I was there and I showed him some of these graphs on improvement of care for chronic diseases in the Veteran’s Health Administration and he couldn’t believe the huge improvements brought about when you created the right incentives.</p>
<p>We got into in performance measurement and wrote about other people’s development of performance measurement systems while I was still at the Urban Institute. At first it was controversial in the evaluation community. You know, it’s kind of like performance measurement systems are being put forward as an alternative to and somehow better than evaluation studies. From my point of view, they’re all evaluation. You’re trying to see if a program has met its goals or not and you might use a performance measurement system and you might use an evaluation study. You know, in randomized control trials, the goal is to exceed how the control group is doing and you think the program is good if it’s beating what otherwise would have occurred. But, there are other ways to evaluate a program. Do they reach higher and higher goals, which can just be set by edict or by finding out what the best performers are accomplishing, so everybody should move up that way.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>Isn’t there some difficulty about what goals to set?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>You need other things from outside besides performance measurement systems. Certainly you need the evaluation studies and you need sometimes experiments or demonstration projects and policy research; a lot of different ways to learn about how you might improve programs. The performance measurement systems could never be the only thing. Plus you always have to worry about creaming and cheating and all this that you see in the elementary and secondary education arenas. So you have to have the other studies too, I mean the evaluation studies, the research studies, and so forth. On the other hand, you know the evaluation studies and policy research can be very, very expensive and take a long time to do and by the time they’re done maybe there is not going to be any audience for them. I like the combination of the two.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>And that really started way back in the Urban Institute days, the performance measurement systems?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>We certainly wrote about it. We found out that some people had used them to good effect, the Labor Department as an example. If you have a performance measurement system you look kind of businesslike. That’s a good thing politically. And, of course, later we had the Government Performance and Results Act (GPRA) pushing everybody to do it. It was a little bit of over-reaction. I remember when I was in the Budget Bureau<sup><xref ref-type="fn" rid="fn19-1098214012464300">19</xref></sup> for some time when we were implementing the Government Performance and Results Act. We got the science community to see that they could use the so-called alternative form of measurement, which was really qualitative, you know qualitative descriptions of what was good performance and what was excellent performance. Then you matched what actually happened to it. Might be a 3-point scale: research was tragically poor, pretty good, or path-breaking. I remember the National Science Foundation quite eagerly said we’ll do it that way. It was still implementing the Government Performance and Results Act but it wasn’t doing it with numerical measurement systems unless you count a 3-point scale as numerical measurement. And then, they said we’re never going to fund bad research so they went to a 2-point scale: either its good stuff or its path-breaking stuff. They would bring in their outside advisory committees and evaluate how the National Science Foundation was doing with math, astronomy, and other areas of scientific research.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>You were really instrumental in getting the Government Performance and Results Act passed.</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Well, I testified a couple of times. I wasn’t like lead testimony, but I did testify for it, probably through the National Academy of Public Administration. I was having sabbatical coming up and had written to Alice [Rivlin], “Could I do my sabbatical over there at OMB?” Before John Koskinen had come in as the Deputy Director for Management, I was already hired to be his assistant. I stayed 2 years on my 1-year sabbatical. They wanted me to stay a 3rd year, but I said 2 years on a 1-year sabbatical is enough. I was part time at OMB and part time at my university, the University of Southern California.</p>
<p>The Government Performance and Results Act was just coming in. I had had a little consulting firm, so I was helping in the early implementation phases, as Harry Hatry was over at the Urban Institute, helping the government learn how to do this stuff:the goal setting, the performance measurement, the performance reporting, and so forth. My job then with Jonathan Bruel<sup><xref ref-type="fn" rid="fn20-1098214012464300">20</xref></sup> and Walter Groszyk<sup><xref ref-type="fn" rid="fn21-1098214012464300">21</xref></sup> at OMB was to teach the branches about all this Government Performance and Results Act stuff so that they could then teach the agencies, you might say. Use it themselves and teach the agencies. Belle Sawhill<sup><xref ref-type="fn" rid="fn22-1098214012464300">22</xref></sup> was there as one of the top political appointees and she would laugh when she would see this little performance cadre coming along, the three of us. But the main idea was to get the branches to take ownership and so that they would then socialize the agencies. And then at GAO<sup><xref ref-type="fn" rid="fn23-1098214012464300">23</xref></sup> we got into the later phases when you were actually going government-wide, not just pilot projects, and getting into strategic planning. Chris Mihm<sup><xref ref-type="fn" rid="fn24-1098214012464300">24</xref></sup> knew about this stuff. We would teach the different pieces of GAO about it so that they could then tell the agencies how to do a good job in the strategic planning, performance measurement, and performance reporting. And then comes in David Walker<sup><xref ref-type="fn" rid="fn25-1098214012464300">25</xref></sup> and he wants us to apply this new law to ourselves at GAO. We’re going to have the best strategic plan in the whole government. We’ll lead by example. Gene Dodaro<sup><xref ref-type="fn" rid="fn26-1098214012464300">26</xref></sup> quickly got to be smarter than Chris and Joe. In one weekend he said, “Well, they’re not 5-year plans, they’re 6-year plans”. He read the statute better than we had! In any case, for a brief shining moment we tried to get and did get GAO to use this qualitative goal setting and measurement but they quickly switched back. You don’t want to set goals that you know you won’t achieve.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>You had come as a senior advisor for evaluation methodology at GAO in 1996 and then later became the senior advisor for performance and accountability in 2001. Stephanie Shipman said that you had helped with the evaluator’s guide for reviewing the agency performance plans and that you had remarked at the time that you were impressed by seeing the entire federal government pass before your eyes.</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Well, it did. GAO was impressed too because they thought they knew these departments and the GAO people found out they only knew certain pieces of the departments because that’s where they were doing the repetitive work. The departments had many more responsibilities. So, yes I was seeing the whole government pass before my eyes both at OMB and at GAO. A lot of people were getting much more broad gauge because they had to see the whole arena of responsibilities the agencies had: Were they setting appropriate short-term and long-term goals? Were they making good progress? I was just leaving OMB and then they [GAO] asked me to come over there—this other responsibility. They said you can be fulltime at GAO, part time at USC, or if you want it the other way around, or part time at both—and I chose part time at both. You can have senior executive level rank and don’t have to supervise anybody. I hadn’t been there 3 months when they offered me the evaluation staff and I said, “That’s not the deal. No.” I could advise anyone in the organization. It was great. From the top of the organization to the newest hire, I was the advisor.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>You mainly worked closely with Chris Mihm and he said that you were instrumental not just in the review of the performance plans but to the design and implementation of GAO’s entire approach to the Government Performance and Results Act.</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Well, he and I were the ones who knew about it. Gene Dodaro had to work on everything. He couldn’t just work on this. We did search around and look in the academic literature and find what looked like a good way to do strategic planning. And then Chris and some others and I helped adapt it to GAO’s purposes. And then Dave Walker<sup><xref ref-type="fn" rid="fn27-1098214012464300">27</xref></sup> was very good. He knew that government is verbal—here is the head of an organization that is going to be churning out reports, and he wants people to pay attention to them, and he got a draft of the strategic plan down to one page, which he could then show to different members of Congress, the Senate, and so forth, whenever he happened to come across them. He said that he knew a third of the members when he came because he been a political appointee before, and one of his goals was to meet a new member every day so he would know them. He wanted to have GAO doing studies that they would think valuable to them. And so he wanted a way to brief them, some miniature version of these are the goals we’re thinking of setting for the evaluations and other studies that GAO is going to do, the bodies of work you might say. Is that what’s going to meet your needs or not? And Dodaro was good too. He said the statute says every 3 years we have to update the plan but there’s a new Congress every 2 years so GAO will revise its strategic plan every 2 years. Dave and Gene were bringing a lot to making this a meaningful strategic planning and reporting process. It wasn’t just teaching the different pieces of GAO how to review the federal agencies but also showing GAO how to do what the head of the agency wanted it to be: the exemplar for the government.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>You defined the best and then it became the best. Did the impact of GPRA turn out as you imagined or hoped?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Never. You don’t achieve what you hoped you’d achieve. In particular you aren’t achieving much use of all that overhead. I mean, it’s all overhead and it’s all producing a lot of paper. When the new administration came in this time around, the Obama administration, there were a lot of studies out there saying it [GPRA] has done some good but for all the effort that’s going in, it is not doing as much good as it should be doing. It is not very sensible to put the same amount of effort into trivial programs and bureaus as you would in to the main important things that the government is trying to accomplish or even the administration is trying to accomplish. We need to refocus somehow. Paul Posner<sup><xref ref-type="fn" rid="fn28-1098214012464300">28</xref></sup> is very good. He says all of these things have come along—planning–program–budgeting, policy analysis, zero-base budgeting, and GPRA—and they all kind of help things a bit. They move, he might say, the sophistication and the dialogue up somewhat. And when people say they didn’t achieve all they claim they were going to, that’s true, but they helped. They do help rational decision making to be a little bit more likely.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>Given all the effort over the years, what are the most important things we could do now to foster a results orientation across the federal government and in how the federal government works with states, locals, and nonprofits?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I like very much the idea of collaborative goal setting: executive branch and legislative branch working together and when you have federal-state or federal-local working together too to try to see whether we can have sensible goals and keep the pulse on what’s happening. That’s been done quite nicely I thought with Healthy People<sup><xref ref-type="fn" rid="fn29-1098214012464300">29</xref></sup> over the years. It’s been a good example of bringing in the academy, universities, and so forth. What are realistic goals for health promotion and disease prevention? Can we push things in a somewhat good direction? Can we get them to go a little bit better by the things that we would do? That’s what Healthy People has been all about. There have been other areas too, like drug control policy. Sometimes there’s been a sensible effort to try to figure out what the big goals are in a collaborative way and then to figure out how we would assess progress. Often different agencies of the government have to work together to achieve the results. In the Obama administration, the Department of Housing and Urban Development, the Department of Veterans Affairs, and maybe the Defense Department, said “We’re going to cut down the number of homeless veterans dramatically.” It seemed like a stretch goal to me. I think they had some success, but these departments are not going to house homeless veterans, so that means you’re rippling out into states, localities, non-profits and so forth getting people enthused about the idea that we can push beyond what’s likely to happen to what’s better. I think you can’t do that with too many things. Walter Groszyk<sup><xref ref-type="fn" rid="fn30-1098214012464300">30</xref></sup> said one time, with too many cross cuts, you can’t put analytical staff on all of them and try to set realistic goals and stretch goals and all that, so you have to decide what the important priorities are and then say we’re going to work on those. Different leaders have tried to agree on national indicators. . .. You’ve got the unemployment rate and a few other things: you know, is the gross national product rising or falling? But we don’t have them. There have been efforts to develop them and they haven’t gotten too far. I think we need things like that. I would feel good if we had. I think there’d have to be some political leadership heading in those directions. Sometimes maybe at the level of governors you can make progress, and sometimes governors get promoted. Mark Warner<sup><xref ref-type="fn" rid="fn31-1098214012464300">31</xref></sup> is one person that I’ve been enthused about over the years. When he was governor he helped improve goal-setting for the Commonwealth of Virginia. I think you need political leaders who are sophisticated about some of this stuff to make good progress. You have to pick priority areas, put people on them to try to figure out good ways to go, but you’d be doing it in a collaborative way with the other important people whose help would be needed later to achieve the goals. So I don’t know if it’s just a pointy-headed intellectual romantic idea.</p>
<p>One problem with the strategic planning the federal government has done is it hasn’t done so much on looking at alternative scenarios or alternative assumptions as to how the future might unfold and what we might need to do in those alternative futures. An awful lot of the strategic planning is just about the programs and policies we have now where we are going to try to get with them. But the world is changing all the time. I do remember that the Department of Veterans Affairs was having to look at alternative futures as part of its strategic planning because it depends a lot on which wars you’re going to have and how damaged people are going to be, physically and mentally.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>When you reflect on your own work and your contributions, what is the idea that you hold in the greatest esteem?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>Well, I don’t know if you would go along with this, but I’ve often said I take a zero-base approach to evaluation. I’m willing to do little or no evaluation unless it’s going to be useful. I’m not interested, you might say, in doing elegant studies for their own contribution to building knowledge. I’m just much more pragmatic in my approach. Unless it is going to be useful, and that means instrumental use, you know, and program improvement use, then I’m counseling that we take our scarce analytical resources and put them elsewhere. So that’d be something I’m kind of proud of being an evaluator who’s willing not to do an evaluation.</p>
</speech>
<speech>
<speaker>Valerie:</speaker>
<p>What do you think are the most pressing issues that future evaluation scholars and practitioners need to address?</p>
</speech>
<speech>
<speaker>Joe:</speaker>
<p>I think that the issue of efficiency in our evaluation work needs to be a focus. I don’t remember it being a focus and I think that would be a good focus. We want to be effective in a constrained resource environment and we should pay attention to what are efficient ways to do useful evaluation work.</p>
</speech>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict" id="fn1a-1098214012464300"><label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn2a-1098214012464300"><label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="other" id="fn2b-1098214012464300"><label>Authors' Note</label>
<p>The Oral History Project Team consists of Robin Lin Miller (Michigan State University), Jean King (University of Minnesota), Melvin Mark (The Pennsylvania State University), and Valerie Caracelli (United States Government Accountability Office). Correspondence concerning this article should be addressed to Robin Lin Miller, Michigan State University, Department of Psychology, 316 Physics Road, East Lansing, MI 48824; e-mail: mill1493@msu.edu</p>
</fn></fn-group>
<notes>
<title>Notes</title>
<fn-group>
<fn fn-type="other" id="fn1-1098214012464300">
<label>1.</label>
<p>The Department of Health, Education, and Welfare was renamed the Department of Health and Human Services in 1979.</p>
</fn>
<fn fn-type="other" id="fn2-1098214012464300">
<label>2.</label>
<p>Dr. Rivlin is founding director of the Congressional Budget Office and former Director of the White House Office of Management and Budget. She is currently a Senior Fellow at the Brookings Institution.</p>
</fn>
<fn fn-type="other" id="fn3-1098214012464300">
<label>3.</label>
<p>1964.</p>
</fn>
<fn fn-type="other" id="fn4-1098214012464300">
<label>4.</label>
<p>August 28, 1963.</p>
</fn>
<fn fn-type="other" id="fn5-1098214012464300">
<label>5.</label>
<p>King delivered his speech, now known as the “I have a dream” speech, from the Lincoln Memorial.</p>
</fn>
<fn fn-type="other" id="fn6-1098214012464300">
<label>6.</label>
<p>Office of the Assistant Secretary for Planning and Evaluation, U.S. Department of Health and Human Services, then the U.S. Department of Health, Education, and Welfare.</p>
</fn>
<fn fn-type="other" id="fn7-1098214012464300">
<label>7.</label>
<p>Mr. Gorham is the founding president of the Urban Institute and former Assistant Secretary of Health, Education, and Welfare and Deputy Assistant Secretary of Defense.</p>
</fn>
<fn fn-type="other" id="fn8-1098214012464300">
<label>8.</label>
<p>1968–1978.</p>
</fn>
<fn fn-type="other" id="fn9-1098214012464300">
<label>9.</label>
<p>Joseph Califano was appointed Secretary of HEW in 1977.</p>
</fn>
<fn fn-type="other" id="fn10-1098214012464300">
<label>10.</label>
<p>Shalala served as Assistant Secretary for Policy Development and Research at the U.S. Department for Housing and Urban Development from 1977 to 1980.</p>
</fn>
<fn fn-type="other" id="fn11-1098214012464300">
<label>10.</label>
<p>1968.</p>
</fn>
<fn fn-type="other" id="fn12-1098214012464300">
<label>11.</label>
<p>George W. Romney, Governor of Michigan, 1963–1969, and U.S. Secretary of Housing and Urban Development, 1969–1972.</p>
</fn>
<fn fn-type="other" id="fn13-1098214012464300">
<label>12.</label>
<p>At HEW.</p>
</fn>
<fn fn-type="other" id="fn14-1098214012464300">
<label>13.</label>
<p>At HEW in 1978 after 10 years at the Urban Institute.</p>
</fn>
<fn fn-type="other" id="fn15-1098214012464300">
<label>14.</label>
<p>Democrat, Virginia, 8th Congressional District.</p>
</fn>
<fn fn-type="other" id="fn16-1098214012464300">
<label>15.</label>
<p>The Washington Metropolitan Area Transit system linked Arlington to its rail system in 1976.</p>
</fn>
<fn fn-type="other" id="fn17-1098214012464300">
<label>16.</label>
<p>Irv McNayr.</p>
</fn>
<fn fn-type="other" id="fn18-1098214012464300">
<label>17.</label>
<p>Divorski was with the Office of the Auditor General of Canada; he was on special assignment at the Government Accountability Office in the late 1990s.</p>
</fn>
<fn fn-type="other" id="fn19-1098214012464300">
<label>18.</label>
<p>1994–1996.</p>
</fn>
<fn fn-type="other" id="fn20-1098214012464300">
<label>19.</label>
<p>Now Executive Director, IBM Center for the Business of Government.</p>
</fn>
<fn fn-type="other" id="fn21-1098214012464300">
<label>20.</label>
<p>Senior Advisor for Performance Management, Budget Review and Concepts Division, Office of Management and Budget.</p>
</fn>
<fn fn-type="other" id="fn22-1098214012464300">
<label>21.</label>
<p>Isabel V. Sawhill is currently senior fellow at the Brookings Institute.</p>
</fn>
<fn fn-type="other" id="fn23-1098214012464300">
<label>22.</label>
<p>1996–2002.</p>
</fn>
<fn fn-type="other" id="fn24-1098214012464300">
<label>23.</label>
<p>Managing Director, Strategic Issues, Government Accountability Office.</p>
</fn>
<fn fn-type="other" id="fn25-1098214012464300">
<label>24.</label>
<p>U.S. Comptroller General, 1998–2008.</p>
</fn>
<fn fn-type="other" id="fn26-1098214012464300">
<label>25.</label>
<p>Currently Comptroller General of the United States.</p>
</fn>
<fn fn-type="other" id="fn27-1098214012464300">
<label>26.</label>
<p>Comptroller General of the United States, 1998–2008.</p>
</fn>
<fn fn-type="other" id="fn28-1098214012464300">
<label>27.</label>
<p>Former Director of Federal Budget and Intergovernmental Relations at the Government Accountability Office.</p>
</fn>
<fn fn-type="other" id="fn29-1098214012464300">
<label>28.</label>
<p>For information on the history of Healthy People, see http://www.healthypeople.gov/2020/about/history.aspx.</p>
</fn>
<fn fn-type="other" id="fn30-1098214012464300">
<label>29.</label>
<p>Former Senior Adviser for Performance Management, Budget Review and Concepts Division, Office of Management and Budget.</p>
</fn>
<fn fn-type="other" id="fn31-1098214012464300">
<label>30.</label>
<p>Mark Warner, U.S. Senator representing Virginia.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1098214012464300">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rutman</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>1980</year>). <source>Planning useful evaluations: Evaluability assessment</source>. <publisher-loc>Beverly Hills, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr2-1098214012464300">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Shadish</surname>
<given-names>W. R.</given-names>
</name>
<name>
<surname>Cook</surname>
<given-names>T. D.</given-names>
</name>
<name>
<surname>Leviton</surname>
<given-names>L. C.</given-names>
</name>
</person-group> (<year>1991</year>). <source>Foundations of program evaluation: Theories of practice</source>. <publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr3-1098214012464300">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wholey</surname>
<given-names>J. S.</given-names>
</name>
</person-group> (<year>1970</year>). <source>Federal evaluation policy</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>The Urban Institute</publisher-name>.</citation>
</ref>
<ref id="bibr4-1098214012464300">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wholey</surname>
<given-names>J. S.</given-names>
</name>
</person-group> (<year>1979</year>). <source>Evaluation—Promise and performance</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>The Urban Institute</publisher-name>.</citation>
</ref>
<ref id="bibr5-1098214012464300">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wholey</surname>
<given-names>J. S.</given-names>
</name>
<name>
<surname>Hatry</surname>
<given-names>H. P.</given-names>
</name>
<name>
<surname>Newcomer</surname>
<given-names>K. E.</given-names>
</name>
</person-group> (Eds.). (<year>2010</year>). <source>Handbook of practical program evaluation (Essential text for non-profit and public leadership and management)</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>