<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">SAG</journal-id>
<journal-id journal-id-type="hwp">spsag</journal-id>
<journal-title>Simulation &amp; Gaming</journal-title>
<issn pub-type="ppub">1046-8781</issn>
<issn pub-type="epub">1552-826X</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1046878111431868</article-id>
<article-id pub-id-type="publisher-id">10.1177_1046878111431868</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Validity and Effectiveness of a Business Game Beta Test</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Gold</surname><given-names>Steven C.</given-names></name>
<xref ref-type="aff" rid="aff1-1046878111431868">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wolfe</surname><given-names>Joseph</given-names></name>
<xref ref-type="aff" rid="aff2-1046878111431868">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-1046878111431868"><label>1</label>Rochester Institute of Technology, Rochester, NY, USA</aff>
<aff id="aff2-1046878111431868"><label>2</label>Experiential Adventures LLC, Bainbridge Island, WA, USA</aff>
<author-notes>
<corresp id="corresp1-1046878111431868">Steven C. Gold, Saunders College of Business, Rochester Institute of Technology, 106 Lomb Memorial Drive, Rochester, NY 14623-5603 Email: <email>stevengold@saunders.rit.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2012</year>
</pub-date>
<volume>43</volume>
<issue>4</issue>
<fpage>481</fpage>
<lpage>505</lpage>
<permissions>
<copyright-statement>© 2012 SAGE Publications</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>New gaming software must undergo a series of tests before its general release. The objective of these tests is to ensure that the simulation is appropriate for its intended audience, plays well, possesses the requisite level of fidelity to the system being modeled, and is free from programming errors. This article first catalogs the design parameters associated with a good beta test. It then compares this ideal against the beta test created for a first-generation online business game released by a major online game publisher. It then examines the actual behaviors and results produced by the study’s beta testers to determine the degree the publisher and authors could be confident that the game met the criteria of targeted audience propriety, playability, model fidelity, and algorithmic accuracy. In this instance, this well-designed beta test could not guarantee the release of error-free software, and the likely reasons for this outcome are identified.</p>
</abstract>
<kwd-group>
<kwd>algorithmic accuracy</kwd>
<kwd>audience propriety</kwd>
<kwd>beta testing</kwd>
<kwd>beta-test procedure</kwd>
<kwd>business simulation development</kwd>
<kwd>business simulation testing</kwd>
<kwd>defect analysis</kwd>
<kwd>model fidelity</kwd>
<kwd>playability</kwd>
<kwd>release conditions</kwd>
<kwd>software development</kwd>
<kwd>software testing</kwd>
<kwd>test design</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Software bugs have almost become a modern way of life. All of us have come across accounting errors in our bank account statements or have been billed for services not rendered. These are annoyances, but they are minor and inconsequential compared with some of the world’s worst disasters caused by program bugs. Program errors in the Therac-25 radiation therapy machine killed three of six persons given massive radium overdoses (<xref ref-type="bibr" rid="bibr9-1046878111431868">Levenson &amp; Turner, 1993</xref>). An onboard program error caused the destruction of the Ariane 5 prototype 1 min into its flight on June 4, 1996, at the cost of more than US$1.0 billion (<xref ref-type="bibr" rid="bibr4-1046878111431868">Dowson, 1997</xref>), and a software bug in a Royal Air Force Chinook helicopter’s engine control computer caused its crash, killing 29 in the process (<xref ref-type="bibr" rid="bibr13-1046878111431868">Rogerson, 2002</xref>). While these are large-scale events, the phenomena of bug-ridden or poorly tested business game software is something known to all who have used or created the field’s teaching simulation games.</p>
<p>The ability to encode and then release bug-free software is a problem that will not go away. This is especially true when a typical business game’s source code, which was once only a few hundred lines, can now encompass thousands of lines. The programming demands for online business games are even higher because they not only include source code for the game, but for the active interface as well. This interface must be attractive, be “open,” and anticipate every false move made by its players. In addition, the cost of detecting bugs is extremely high and the efficacy of code testing efforts is questionable. Given the limited resources possessed by a business game’s developer, the bug-finding and debugging task is daunting. Microsoft was still embarrassed by outbreaks of Black, Red, and Blue “screens of death” after spending millions of dollars on beta testing their associated operating systems.</p>
<p>A search of both <italic>Simulation &amp; Gaming: An Interdisciplinary Journal</italic> and the <italic>Bernie Keys Library</italic>, a research archive containing a complete word-searchable compilation of all past Association for Business Simulation and Experiential Learning (ABSEL) proceedings published in <italic>Developments in Business Simulation and Experiential Learning</italic>, reveals the mechanics of conducting a valid beta test are not discussed nor has a discussion taken place of what is revealed and not revealed by conducting a beta test. When mentioned at all, game authors either state their game is being or was beta tested, or that their beta tests were encouraging (<xref ref-type="bibr" rid="bibr10-1046878111431868">Nissen, 1996</xref>; <xref ref-type="bibr" rid="bibr12-1046878111431868">Prakash et al., 2009</xref>; <xref ref-type="bibr" rid="bibr16-1046878111431868">Thorelli, 2001</xref>). <xref ref-type="bibr" rid="bibr3-1046878111431868">Byers and Cannon (2007)</xref> discuss how a beta test fits in the game design and development process, but do not discuss details concerning the effective implementation of such a test.</p>
<p>The lack of research on beta-testing methodologies with respect to the development of business simulations and games is a noteworthy deficiency owing to the key role that it plays in this process. This article attempts to direct the attention of simulation developers to this critically important area by examining the creation and conduct of an actual beta test as well as serving to open a debate on the realities of conducting effective beta tests. To do that, this article reviews the nature of the software testing cycle with a special emphasis on the beta-test phase. It then outlines the qualities that should be present to ensure that a beta-test produces bug-free software. It then presents a case example of the beta test of a newly developed Introduction to Business–level game. This case will highlight the degree to which the test achieved the qualities associated with an ideal beta test, followed by a discussion of the implementation realities of beta testing regardless of the test’s design.</p>
<sec id="section1-1046878111431868">
<title>The Beta-Testing Process</title>
<p>The literature on the beta-testing process for software development is wide and deep (<xref ref-type="bibr" rid="bibr2-1046878111431868">Beizer, 1990</xref>; <xref ref-type="bibr" rid="bibr6-1046878111431868">Gelperin &amp; Hetzel, 1988</xref>; <xref ref-type="bibr" rid="bibr15-1046878111431868">Srinivasan &amp; Gopalaswamy, 2006</xref>; <xref ref-type="bibr" rid="bibr17-1046878111431868">Whittaker, 2000</xref>). The beta test’s goal is to improve the operation and functionality of a software application before its release. <xref ref-type="bibr" rid="bibr8-1046878111431868">Kaner (2006)</xref> explains that software testing is an empirical evaluation of the quality of the product or service with respect to how it was designed to operate. The testing process will be more effective if the application’s developers can articulate and justify how the testing strategy relates to the definition of quality.</p>
<p>The first testing stage before the beta test is referred to as <italic>alpha</italic>. This is testing of software that is undergoing in-house testing. An alpha becomes a beta when software’s intended users test the program. Software testing should be done by independent and objective participants. The testing should not be limited to the process of simply finding defects, but should also focus on verifying that the application meets the purpose for which it was designed and programmed.</p>
<p>Most software passes through multiple beta stages and then arrives at release conditions. A release condition typically requires that all product features have been tested through one or more beta cycles with no known fatal flaws. A thorough beta test is essential to minimize the risks associated with releasing a software application with significant defects. The final version is commonly referred to as general availability (GA) or <italic>gold code</italic> for the gold standard expected of released software.</p>
<p><xref ref-type="bibr" rid="bibr11-1046878111431868">Pan (1999)</xref> identifies the key steps in a typical beta-testing process. These steps are the following and are discussed in detail below:</p>
<list id="list1-1046878111431868" list-type="bullet">
<list-item><p>Requirements Analysis</p></list-item>
<list-item><p>Testing Procedures</p></list-item>
<list-item><p>Reporting Systems</p></list-item>
<list-item><p>Defect Analysis and Retesting</p></list-item>
<list-item><p>Closure</p></list-item>
</list>
<sec id="section2-1046878111431868">
<title>Requirements Analysis</title>
<p>A critical step in a beta test is to develop the requirements list. This list details the software’s objectives and expected outcomes. <xref ref-type="bibr" rid="bibr1-1046878111431868">Bach (1999)</xref> points out that without such stated requirements no testing is possible because a true beta test compares the software’s actual outcomes against its expected outcomes as defined by the product’s requirements list.</p>
<p>The requirements list should be based on a clear understanding of the customer’s needs. In the case of business game software, this means understanding the targeted student’s knowledge and preparation levels and the knowledge domain of the course or business discipline targeted by the game. The development of such a list is no easy task because the ability to recognize problems in a product’s design is limited and biased by the designer’s understanding or misunderstanding of the nature and purpose of the software’s application (<xref ref-type="bibr" rid="bibr1-1046878111431868">Bach, 1999</xref>).</p>
<p>For business simulations, two significant customers are the student and the instructor or consultant. The requirements list should be developed to meet the needs of both of these customers. The requirements, however, can be general in nature to cover a broad range of objectives, as stated by <xref ref-type="bibr" rid="bibr1-1046878111431868">Bach (1999)</xref>:
<disp-quote>
<p>There is nothing in the reformulated guidelines that suggests requirements must be made absolutely clear and precise. What these guidelines emphasize is the importance of managing the relationship between risk and a shared understanding of what quality means for your product. (p. 114)</p>
</disp-quote></p>
<p>Once the requirements are finalized, the beta-test procedures can be effectively designed.</p>
</sec>
<sec id="section3-1046878111431868">
<title>Beta-Test Procedures</title>
<p>It is important to formulate and clearly articulate the beta-test procedures. Many articles have been written on this subject. For the purposes of this article, we have abstracted what we believe are a beta test’s most relevant components. The test process will be more effective if its requirements are specified in terms that communicate the essence of what is desired, along with an idea of risks, benefits, and the relative importance of each requirement (Harmesh, 2009; <xref ref-type="bibr" rid="bibr8-1046878111431868">Kaner, 2006</xref>; <xref ref-type="bibr" rid="bibr14-1046878111431868">Shea, 2006</xref>).</p>
<list id="list2-1046878111431868" list-type="order">
<list-item><p><italic>Select qualified participants.</italic></p></list-item>
</list>
<p>A critical component of the beta-test procedure, and perhaps the most important component, is the selection of the participants or subjects. <xref ref-type="bibr" rid="bibr8-1046878111431868">Kaner (2006)</xref> highlights the importance of selecting independent participants who are managed by objective test administrators. Equally important is that the participants (testers) be characteristic of the game’s target population (users).To achieve objectivity in the test’s administration, no incentives, direct or indirect, should be given to the testers or administrators. It is also important that no participants should be penalized for failure of the beta test’s results. The participants also need to have the background and skills necessary to fulfill the tasks in the beta-test requirements list. This would be best accomplished by randomly drawing the test’s participants from the application’s target population (<xref ref-type="bibr" rid="bibr14-1046878111431868">Shea, 2006</xref>). If random selection cannot be achieved, a statistically controlled overt selection process should be employed. A mistake would be to use “friends” of the authors. Even though they may provide a serious and responsible review of the simulation game, they would not meet the critical conditions of objectivity and being characteristic of the end user (customer). However, during alpha testing stage, this would be a useful source of feedback to the developers of the game.</p>
<list id="list3-1046878111431868" list-type="simple">
<list-item><p><italic>2. Specify test procedures and schedules.</italic></p></list-item>
</list>
<p>The test procedures should specify how the testers would exercise the test scenarios, including the number of game iterations that will occur and the time schedule involved. It is recommended that the game be run under alternative scenarios if the simulation itself provides flexible applications. When possible, the test procedures should cover a wide range of cases, including extreme scenarios and extreme data entry values.</p>
<list id="list4-1046878111431868" list-type="simple">
<list-item><p><italic>3. Plan and clarify specific roles for testers.</italic></p></list-item>
</list>
<p>Schedule each tester to focus on a specific test scenario. For critical tests, include more than one tester for each scenario as each tester will approach each task differently.</p>
<list id="list5-1046878111431868" list-type="simple">
<list-item><p><italic>4. Determine expected results based on requirements list.</italic></p></list-item>
</list>
<p><xref ref-type="bibr" rid="bibr1-1046878111431868">Bach (1999)</xref> specifies that all test cases should be traceable to one or more stated requirements and that these requirements be stated in testable terms. If the software application stores values in a database, predetermine the expected outcomes so that these outcomes can be compared with the application’s actual results. For example, in a business simulation, one can compare the decisions made by the students to the expected and actual outcomes with respect to the income statement or balance sheet values and expected ranges.</p>
<list id="list6-1046878111431868" list-type="simple">
<list-item><p><italic>5. Plan a reward for a job well done.</italic></p></list-item>
</list>
<p><xref ref-type="bibr" rid="bibr14-1046878111431868">Shea (2006)</xref> points out that a good beta tester shows sincere interest, participation, and engagement. To facilitate this goal, <xref ref-type="bibr" rid="bibr5-1046878111431868">Fine (2002)</xref> recommends that a special incentive be provided to help promote their involvement. This does not have to be a big reward, and items like T-shirts and mugs have been used as effective incentives (<xref ref-type="bibr" rid="bibr5-1046878111431868">Fine, 2002</xref>).</p>
</sec>
<sec id="section4-1046878111431868">
<title>Reporting Systems</title>
<p>It is important to provide an effective and convenient reporting system for the testers to record defects and other findings. An efficient reporting system will increase the feedback’s volume and quality. Several options are suggested, including designing an online form, a database entry system, an email messaging system, an online discussion board, or any combination of these methods. It is advisable to have testers report problems in real time, as soon as they are discovered. Reporting in real time is more accurate and timely, and minimizes the probability of not receiving relevant information.</p>
</sec>
<sec id="section5-1046878111431868">
<title>Defect Analysis and Retesting</title>
<p>Compare expected with actual outcomes from the beta test. Defects reported by the testers must be carefully evaluated for Type I and Type II errors. A Type I error occurs if a tester reports an outcome that is a defect when in fact it is not. A Type II error occurs if a defect exists, but is not found by the testers. Instituting an effective test procedure as described above will help minimize the probability of Type I and Type II errors.</p>
<p>If a defect is found and corrected, based on the severity of the defect and nature of the change in the program, it is advisable to perform a new round of testing. This requires that the complete test procedure be repeated after each round of fixes. It is highly recommended that this step not be skipped. Each time a software program is revised, even when the change seems to be small, it can break something else that is even more significant to the program’s operation. The only way to be sure a software program is bug-free is to stop the cycles of testing only when no defects are found.</p>
</sec>
<sec id="section6-1046878111431868">
<title>Closure</title>
<p>A difficult issue for the entire beta-testing process is determining when to stop testing and to release the product. It is typically not economically feasible to continue testing until all defects are found and corrected. Yet, the risks could be very high and costly if a product is released with known defects. As pointed out by <xref ref-type="bibr" rid="bibr19-1046878111431868">Yang and Chao (1995)</xref>, testing is a balance between budget considerations, quality, and time. The decision to release a product that does not meet all the design and development features, or has some defects, should be based on a careful analysis of the expected benefits versus the risks and potential costs. The standard economic rule is to stop testing when the expected benefits from continued testing no longer exceeds the expected costs.</p>
<p>A closure meeting between vendors and beta testers is recommended as a final step, with a final report coming from this meeting. This is an effective venue to raise broad questions about the application’s learning outcomes, user expectations, and go-to-market or further testing recommendations.</p>
</sec>
<sec id="section7-1046878111431868">
<title>Summary of Key Beta-Test Design Process Components</title>
<p>Based on a review of the recommended beta-testing process, <xref ref-type="table" rid="table1-1046878111431868">Table 1</xref> summarizes the key components required for a thorough and complete test that we have found in the literature. The requirements list is the first critical step and is needed to verify that the application meets its intended purpose, and to help determine the qualifications of the participants, including the testers, administrators, and the target population. The procedures must clearly specify the test scenarios and schedules, the role of the testers, the expected outcomes, and the incentives provided for the testers. The reporting system needs to provide an effective method of communication and feedback from the participants. The final steps are a careful defect analysis and the closure decision to move forward, continue testing, or even cancel the entire release.</p>
<table-wrap id="table1-1046878111431868" position="float">
<label>Table 1.</label>
<caption><p>Ideal Beta-Test Design Components</p></caption>
<graphic alternate-form-of="table1-1046878111431868" xlink:href="10.1177_1046878111431868-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
</colgroup>
<tbody>
<tr>
<td>Requirements list</td>
</tr>
<tr>
<td> Verify the application meets its intended purpose</td>
</tr>
<tr>
<td>Qualifications of participants</td>
</tr>
<tr>
<td> Conducted by independent testers</td>
</tr>
<tr>
<td> Conducted by an objective administrator</td>
</tr>
<tr>
<td> Played by the application’s target population</td>
</tr>
<tr>
<td>Procedures</td>
</tr>
<tr>
<td> Specify test scenarios and schedules</td>
</tr>
<tr>
<td> Clarify the tester’s role</td>
</tr>
<tr>
<td> Determine the simulation’s expected values</td>
</tr>
<tr>
<td> Provide incentives for beta testers</td>
</tr>
<tr>
<td>Reporting system</td>
</tr>
<tr>
<td> Provide an effective reporting system for defects and suggestions</td>
</tr>
<tr>
<td>Defect analysis</td>
</tr>
<tr>
<td> Compare expected outcomes against actual outcomes</td>
</tr>
<tr>
<td>Closure</td>
</tr>
<tr>
<td> Decision to go or not go to market recognizing the risks associated with making this decision with imperfect information</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section8-1046878111431868">
<title>Setting Up the Beta Test: Process and Method</title>
<p>The game being tested was <italic>THE GLOBAL BUSINESS GAME: BUSINESS BASICS EDITION</italic> (<xref ref-type="bibr" rid="bibr7-1046878111431868">Wolfe, n.d.</xref>). It is a simplified version of <italic>THE GLOBAL BUSINESS GAME: WORLD EDITION</italic>. Its original source code has been used since its December 2000 release. Because the game’s source code was the same as that used by its mature progenitors, the test was still a verification test to see whether</p>
<list id="list7-1046878111431868" list-type="bullet">
<list-item><p>its inherited source code was error free,</p></list-item>
<list-item><p>the author had written the right software for its intended audience, and</p></list-item>
<list-item><p>the author had revised its text screens and player support materials in an appropriate manner.</p></list-item>
</list>
<p>The game’s breadth and depth was dictated by the topics and tools presented in seven of the field’s Introduction to Business–type textbooks. The following summarizes the games major appearance and playing features:</p>
<list id="list8-1046878111431868" list-type="order">
<list-item><p>the manufacture of motor scooters in one, two-shift factory</p></list-item>
<list-item><p>scooters made from one subassembly kit imported from Asia</p></list-item>
<list-item><p>two continental markets operating under stable economic conditions</p></list-item>
<list-item><p>financing via stock issues and loans</p></list-item>
<list-item><p>on-screen call-outs and Help topics</p></list-item>
<list-item><p>automated cash flow report</p></list-item>
<list-item><p>a simple, illustrated 24-page step-by-step <italic>Player’s Guide</italic></p></list-item>
<list-item><p>Excel workbooks and tutorials</p></list-item>
<list-item><p>game played via the Internet</p></list-item></list>
<p>The beta test was set up to follow the best practices identified in the literature review and was not constrained by time or resources. The beta test consisted of the six steps identified in the literature.</p>
<sec id="section9-1046878111431868">
<title>Step 1: Specifying the requirements list</title>
<p>The requirements list details the key objectives and desired outcomes of the beta test. The primary objectives of this beta test were to find out whether the game was viewed, by students, as suitable for an Introduction to Business class and how easy it was for them to play and enjoy the game while engaged in its subtle learning process. <xref ref-type="table" rid="table2-1046878111431868">Table 2A</xref> presents the six questions the testers were asked to answer. Based on the nature of the questions posed, the publisher was primarily conducting a software validation study where the question was “Has the right software been written?” rather than one of verification where the question is “Have we written the software right?” It is important to note that the reference to the game’s software includes the game’s interface and the code that was written to enhance the user interface. The requirement’s list also dealt with the software’s stability, performance, and market/customer reach given its intended audience. Given these objectives, the following questions were posed to the beta testers.</p>
<table-wrap id="table2-1046878111431868" position="float">
<label>Table 2A.</label>
<caption><p>Requirements List—Respondent’s Questions</p></caption>
<graphic alternate-form-of="table2-1046878111431868" xlink:href="10.1177_1046878111431868-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Number</th>
<th align="center">Question</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>How suitable is the game for an Introduction to Business class?</td>
</tr>
<tr>
<td>2</td>
<td>How easy is it to know what you need to do?</td>
</tr>
<tr>
<td>3</td>
<td>How easy is it to make decisions?</td>
</tr>
<tr>
<td>4</td>
<td>How easy is it to understand the results?</td>
</tr>
<tr>
<td>5</td>
<td>How easy is it to understand how to win?</td>
</tr>
<tr>
<td>6</td>
<td>Did you enjoy playing the game?</td>
</tr>
</tbody>
</table></table-wrap>
<table-wrap id="table3-1046878111431868" position="float">
<label>Table 2B.</label>
<caption><p>Requirements List and Verification of Objectives—Ideal Versus Actual</p></caption>
<graphic alternate-form-of="table3-1046878111431868" xlink:href="10.1177_1046878111431868-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Ideal</th>
<th align="center">Actual</th>
<th align="center">Conformity to the ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Develop a list of detailed requirements of the application and how it will meet its intended purpose</td>
<td>Testers were asked a set of questions on whether they felt the game was appropriate for an Introduction to Business course and the ease of use</td>
<td>High conformity</td>
</tr>
</tbody>
</table>
</table-wrap>
<p><xref ref-type="table" rid="table3-1046878111431868">Table 3</xref> summarizes the ideal versus actual characteristics of the requirements list and the conformity to the ideal. This step in the procedure was considered to have high conformity to the ideal beta test.</p>
<table-wrap id="table4-1046878111431868" position="float">
<label>Table 3.</label>
<caption><p>Participants in Beta Test—Ideal Versus Actual</p></caption>
<graphic alternate-form-of="table4-1046878111431868" xlink:href="10.1177_1046878111431868-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Ideal</th>
<th align="center">Actual</th>
<th align="center">Conformity to the ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Conducted by independent participants</td>
<td>The participants were paid players not under the direct employment of the game’s publisher.</td>
<td>Perfect conformity for the game’s testers.</td>
</tr>
<tr>
<td>Played by the application’s target population</td>
<td><list id="list9-1046878111431868" list-type="order">
<list-item><p>Testers were business school sophomores rather than the game’s targeted freshmen.</p></list-item>
<list-item><p>Testers were naïve game players like the game’s targeted population.</p></list-item>
<list-item><p>Most testers were sophomores with a small number being juniors.</p></list-item>
<list-item><p>Testers were not randomly obtained from the university’s student population within its business school.</p></list-item>
<list-item><p>The majority of the testers were members of a collegewide International Business Honors program.</p></list-item></list></td>
<td><list id="list10-1046878111431868" list-type="order">
<list-item><p>Testers were business school students that mirrored the game’s target population.</p></list-item>
<list-item><p>Testers were naïve game players that mirrored the game’s target population.</p></list-item>
<list-item><p>More than 50.0% of the testers where enrolled in an honors program that required a grade point average (GPA) equal to or greater than 3.25 which is not the GPAs expected of entry-level Freshmen.</p></list-item>
<list-item><p>Participants were interested in international business. This agrees with the game’s orientation that is international in its scope.</p></list-item>
<list-item><p>Participants were not academically naïve as none were incoming freshmen.</p>
<p>Verdict—Moderate conformity, but nonconformity in a crucial area (Item 5).</p></list-item></list></td>
</tr>
<tr>
<td>Conducted by knowledgeable administrators</td>
<td><list id="list11-1046878111431868" list-type="order">
<list-item><p>The test’s administrator was a consultant who specialized in conducting beta tests. This administrator also monitored turn-in conformance and emailed laggard participants and teams. No coaching was provided by this administrator.</p></list-item>
<list-item><p>The game’s author acted as a team coach as a substitute for the normal role taken by an instructor using the game. The author provided active coaching for the game’s first three rounds and coaching on request for the test’s final three rounds.</p></list-item></list></td>
<td><list id="list12-1046878111431868" list-type="order">
<list-item><p>The consultant’s responsibility was to enable a good test, but was appropriately disinterested about its outcome.</p></list-item>
<list-item><p>The game’s author wanted the test to be successful so that useful feedback could be obtained.</p></list-item>
<list-item><p>The game’s author served as a proxy for the role expected of any instructor using the game.</p>
<p>Verdict—High conformity.</p></list-item></list></td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section10-1046878111431868">
<title>Step 2: Selecting qualified participants (players and administrators)</title>
<p>The beta test involves the selection of participants (players) and the game administrator, and as much as possible duplicating the environment under which the game will be played, that is, the classroom and its target player audience. In all, 18 business school sophomores at a large southern university served as the study’s beta testers. Eighteen students is a reasonable number for a test, but is smaller than the target market for an Introduction to Business class. The “ideal” beta test should be with a class size as close as possible to the target market environment. This group-test size was selected, however, because it was comparable with those previously used by the publisher of similar games in the firm’s portfolio of simulations.</p>
<p>To be a part of the test, student participants had to meet two important criteria: (a) independent of the publisher of the game and (b) characteristic of the game’s target population (users). The administrators of the game should be knowledgeable of the mechanics of using the game and the beta-testing procedure. To simulate a classroom environment, it is recommended that an administrator would also play the role of the instructor.</p>
<p><xref ref-type="table" rid="table3-1046878111431868">Table 3</xref> summarizes the ideal versus actual characteristics of the participants and administrators, and the conformity to the ideal. The selection of the participants and administrators are described in the table and shows a high conformity with the ideal beta-test conditions. The participants consisted of business school students and inexperienced game players which mirrors the target market. Experienced beta testers or game players were specifically not chosen even though they may be more adept at finding defects, but would not represent the target market. However, the students used in the study were not freshman, but were relatively naïve regarding the entire range of business and accounting concepts associated with the game. This does represent a variance from the ideal selection of beta-test participants because the target market is Introduction to Business and typically has a large percentage of freshman students.</p>
</sec>
<sec id="section11-1046878111431868">
<title>Step 3: Establishing procedures</title>
<p>Before play began, the testers were told the expectations for their role in the beta test and received a copy of the game’s 10-page <italic>Player’s Guide</italic>, an introduction email from the game’s administrator with instructions on how to access the game at its web address, the study’s questionnaire with instructions for its completion, their license number and game password, and the name and email address of their company’s partner.</p>
<p>The procedure for the beta test involved the participants in the following ways:</p>
<list id="list13-1046878111431868" list-type="bullet">
<list-item><p>dedicating four consecutive weeks to play six decision rounds of a relatively simple online business game</p></list-item>
<list-item><p>being one member of a two-member company</p></list-item>
<list-item><p>submitting team decisions twice a week, by 8:00 p.m. every Monday and Thursday in a 3-week period</p></list-item>
<list-item><p>providing endgame feedback via a structured questionnaire</p></list-item>
<list-item><p>accepting and receiving the beta test’s remuneration terms</p></list-item>
</list>
<p>The length of time of 4 weeks was selected because Introduction to Business classes would probably only devote a month of a semester course to the game, perhaps the closing month. In this sense, the beta test meets the condition of modeling the expected classroom scenario. The team size of two is within the range of the standard team size of two to four students, but three or four students per team may have been a more representative choice. Given the smaller number of students, it was decided that having smaller teams would allow for more competition, which would better reflect the typical class game environment. Submitting two decisions per week is representative of the suggested time frame for the game.</p>
<p>Student testers were given monetary incentives to play the game seriously and meet their responsibilities, as recommended for an effective beta test. Yet, the amount of the incentive is not well described in the literature. Because of this, determining the incentive scheme is challenging and appears to be a judgment call. In this beta test, participants received compensation at .25 cents for every spelling and grammar error cited and US$5.00 for every math error reported. The testers were also given a staggered hourly budget at US$10.00 per hour. This budget allowed more billable hours for the game’s opening rounds and fewer for its ending rounds. As an indication of the payout schedule’s motivational properties, the state’s minimum wage is US$7.25 per hour with part-time retail sales clerks earning an average wage of $7.82 in the test’s previous year. The authors are aware that some developers give extra credit points to students in a classroom setting as an incentive to participate, but we have not found research on this approach and its effectiveness.</p>
<p><xref ref-type="table" rid="table4-1046878111431868">Table 4</xref> summarizes the ideal procedural components in a beta test compared with the actual components. The qualitative assessment showed high conformity in the first two criteria, but only moderate conformity with respect to the remunerations given to the participants. The assessment of moderate is owing to the lack of adequate guidelines in the literature and the fact that the incentives were close to the state’s minimum wage, which is not a significant incentive.</p>
<table-wrap id="table5-1046878111431868" position="float">
<label>Table 4.</label>
<caption><p>Procedure in Beta Test—Ideal Versus Actual</p></caption>
<graphic alternate-form-of="table5-1046878111431868" xlink:href="10.1177_1046878111431868-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Ideal</th>
<th align="center">Actual</th>
<th align="center">Conformity to the ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Determine and state the tester’s role</td>
<td>Players were informed about what the beta test was to accomplish and their role was in bringing about those accomplishments.</td>
<td>High conformity.</td>
</tr>
<tr>
<td>Specify test procedures and schedules</td>
<td>Testers were provided a welcoming letter, a Player’s Guide that indicated how a company could make its decisions, a statement of the beta test’s purpose, its schedule of events, and company assignments.</td>
<td>High conformity.</td>
</tr>
<tr>
<td>Model test procedures to reflect the target market experience.</td>
<td>The length of time to play the game was 1 month, with two students per team. Two decisions were required per week.</td>
<td>This scenario meets the typical class environment.Verdict—High conformity.</td>
</tr>
<tr>
<td>Beta testers receive remuneration</td>
<td>Testers were paid a staggered hourly rate and paid for every spelling and grammatical error cited and a larger rate for every math error found.</td>
<td>Not known whether the total and cumulative monetary rewards provided high incentives for active participation. Testers were paid for every grammatical and spelling error found. An amount that was 20 times larger was awarded for each math or calculating error found.</td>
</tr>
<tr>
<td/>
<td/>
<td>Verdict—Moderate conformity for the rates paid.</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section12-1046878111431868">
<title>Step 4: Providing an effective reporting system</title>
<p>In the beta test, participants could communicate and record their findings in two ways. The first was directly through the game’s website interface. The second approach was through email. The testers were informed with respect to the procedures to use the website interface and email, the importance of fully and quickly reporting all defects or issues, and communication etiquette. Both methods of communication were convenient and allowed for real-time reporting of problems. As summarized in <xref ref-type="table" rid="table5-1046878111431868">Table 5</xref>, we assessed the reporting system as having high conformity with the ideal. The students raised no questions or issues with respect to communicating their findings. Almost all testers filed their required reports, although some were slower at doing it and some were less detailed than others.</p>
<table-wrap id="table6-1046878111431868" position="float">
<label>Table 5.</label>
<caption><p>Reporting System—Ideal Versus Actual</p></caption>
<graphic alternate-form-of="table6-1046878111431868" xlink:href="10.1177_1046878111431868-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Ideal</th>
<th align="center">Actual</th>
<th align="center">Conformity to the ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Provide an effective and convenient reporting system for defects and suggestions</td>
<td><list id="list14-1046878111431868" list-type="order">
<list-item><p>Players interfaced via the game’s website as well as reporting results via emails.</p></list-item>
<list-item><p>All testers thoroughly familiar with online etiquette and procedures.</p></list-item></list></td>
<td>High conformity.</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section13-1046878111431868">
<title>Step 5: Evaluating results—Defect analysis</title>
<p>Evaluating results first requires that the game’s expected values be known. The expected values in the beta test were well known as the game being tested was <italic>THE GLOBAL BUSINESS GAME: BUSINESS BASICS EDITION</italic>, which is a simplified version of <italic>THE GLOBAL BUSINESS GAME: WORLD EDITION</italic>, now in its fourth edition. The source code used in the beta test was the same as that used by the game in its earliest iterations. Next, the expected values can be compared with the actual outcomes from the study. It is important that the defects reported by the testers are not just accepted when evaluating the success of the beta test. It is required, in the ideal beta test, to carefully evaluate the reported defects for both Type I and Type II errors to confirm their accuracy (<xref ref-type="table" rid="table6-1046878111431868">Table 6</xref>).</p>
<table-wrap id="table7-1046878111431868" position="float">
<label>Table 6.</label>
<caption><p>Defect Analysis—Ideal Versus Actual</p></caption>
<graphic alternate-form-of="table7-1046878111431868" xlink:href="10.1177_1046878111431868-table7.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Ideal</th>
<th align="center">Actual</th>
<th align="center">Conformity to the ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Determine the simulation’s expected values</td>
<td>The simulation’s accounting and operations are known as well as the form those results should take.</td>
<td>This beta test was more a test of the game’s new interface rather than its source program that was in its fourth generation.</td>
</tr>
<tr>
<td/>
<td/>
<td>Verdict—High conformity.</td>
</tr>
<tr>
<td>Compare expected with actual values and evaluate for Type I and Type II errors</td>
<td>All reported defects were compared with expected values and evaluated for Type I and Type II errors as illustrated in <xref ref-type="table" rid="table7-1046878111431868">Tables 7</xref> and <xref ref-type="table" rid="table8-1046878111431868">8</xref>.</td>
<td>Verdict—High conformity.</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>In a statistical test, a Type I error is one where it is stated that the condition is True when it is actually False. In this study’s beta test, it means the testers did not find an error when an error was ultimately found to exist. A Type II error is one where it is stated that the condition is False when it is actually True.</p>
<p>The evaluation of Type I and II errors were classified and the results are detailed in <xref ref-type="table" rid="table7-1046878111431868">Tables 7</xref> and <xref ref-type="table" rid="table8-1046878111431868">8</xref>. It was found that the testers (student participants) who filed their reports made 126 Type I errors and 3 Type II errors. The testers were very good at pointing out what they felt were grammatical errors although none of them discovered any of the simulation’s mathematical errors even though the reward structure for doing so was much greater than that for detecting spelling and grammar errors. We were surprised and concerned to find the significant number of Type I errors. This clearly highlights the extreme importance of checking for these types of errors and not just accepting the defects reported by the testers. Suggestions on how to minimize these types of errors are discussed later in the article.</p>
<table-wrap id="table8-1046878111431868" position="float">
<label>Table 7.</label>
<caption><p>Tester Type I Errors</p></caption>
<graphic alternate-form-of="table8-1046878111431868" xlink:href="10.1177_1046878111431868-table8.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th align="left">Error</th>
<th align="center">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>• Did not note the column label for South America read “Mexico.”</td>
<td>18</td>
</tr>
<tr>
<td>• Did not see the Earnings/Deficit in the Accounting window did not match the Net Income reported for that period.</td>
<td>18</td>
</tr>
<tr>
<td>• Did not detect the Prior Period’s Retained Earnings/Deficit was not reported correctly.</td>
<td>18</td>
</tr>
<tr>
<td>• No players noticed in the game’s Newspaper the current quarter’s results were not being reported, but instead were showing their firm’s Year-To-Date Performance Index.</td>
<td>18</td>
</tr>
<tr>
<td>• No firm noted the Help topic for “Market Demand” was labeled “Country Demand.” Only continents or markets are there rather than the countries in the game.</td>
<td>18</td>
</tr>
<tr>
<td>• Did not notice Help mislabeled Market Area decisions as Country Market Decisions.</td>
<td>18</td>
</tr>
<tr>
<td>• Did not note Help mislabeled their company’s financial center by country rather than by market.</td>
<td>18</td>
</tr>
<tr>
<td>• Did not notice that the Player’s Guide displayed six continents even though only two are available.</td>
<td>18</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="table9-1046878111431868" position="float">
<label>Table 8.</label>
<caption><p>Tester Type II Errors</p></caption>
<graphic alternate-form-of="table9-1046878111431868" xlink:href="10.1177_1046878111431868-table9.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th align="left">Error</th>
<th align="center">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>Firm 6 states it would be good if the simulation allowed players to juggle windows. This feature exists under “Click here to open a new window” in the game’s tool bar. It is also explained in the Help topic “Screen View.”</td>
<td>1</td>
</tr>
<tr>
<td>Firm 1 states the Income Statement’s shipping expense is incorrect. The player is overlooking the shipping costs associated with importing the factory’s raw materials. This information could have been obtained by retrieving the entry’s Accounting Window by clicking on the account in the Income Statement.</td>
<td>1</td>
</tr>
<tr>
<td>Firm 1 claims the unit sales forecast for scooters in North America is too high when compared with the output generated by the game’s demand forecasting tool. The player is confusing total North American demand versus the demand for the firm’s specific set of scooters.</td>
<td>1</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section14-1046878111431868">
<title>Step 6: Determining closure</title>
<p>Given the imperfections found here with respect to Type I and II errors, and those that probably are associated with any beta test, what criteria should be used by a publisher to determine when to test more or go to market? No matter how thorough the beta test, problems probably lurk in the game’s software waiting to be discovered. Unfortunately, it is typically not economically feasible to continue testing until all defects are found and corrected.</p>
<p>One possible solution as to when to close the beta test and release the software product may be determined by the economic and finance literature’s net present value calculation (NPV). Nevertheless, because the information from any beta test is imperfect, the NPV methodology cannot be accurately applied, as it requires the expected costs and benefits to be identified and the assignment of associated expected costs to each possible outcome. Below is a list of possible scenarios and potential costs that may occur after a business simulation game is released to illustrate the problems of applying NPV solutions to the release dilemma. These examples are taken from the experiences known by this article’s authors. Given all these imponderables, the NPV rule was found to be difficult to utilize confidently to any of the scenarios presented in <xref ref-type="table" rid="table9-1046878111431868">Table 9</xref>.</p>
<table-wrap id="table10-1046878111431868" position="float">
<label>Table 9.</label>
<caption><p>Potential Costs Associated With Releasing an Imperfect Game</p></caption>
<graphic alternate-form-of="table10-1046878111431868" xlink:href="10.1177_1046878111431868-table10.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Case</th>
<th align="center">Scenario</th>
<th align="center">Monetary Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td><list id="list15-1046878111431868" list-type="order">
<list-item><p>Instructor asks for a “work around” for the problem</p></list-item>
<list-item><p>Instructor continues to use the game as long as a pizza party is provided to the class as an apology</p></list-item></list></td>
<td><list id="list16-1046878111431868" list-type="order">
<list-item><p>No cost for the work around</p></list-item>
<list-item><p>Low cost at US$90.00 for the pizza party, but future revenues undetermined</p></list-item></list></td>
</tr>
<tr>
<td>B</td>
<td><list id="list17-1046878111431868" list-type="order">
<list-item><p>Instructor demands a refund of all student game licenses</p></list-item>
<list-item><p>Instructor uses the game again</p></list-item></list></td>
<td><list id="list18-1046878111431868" list-type="order">
<list-item><p>Refund cost high in the current semester—US$540.00</p></list-item>
<list-item><p>Undetermined revenues for future adoptions</p></list-item></list></td>
</tr>
<tr>
<td>C</td>
<td><list id="list19-1046878111431868" list-type="order">
<list-item><p>Instructor demands a refund of all student game licenses</p></list-item>
<list-item><p>Instructor never uses the game again</p></list-item></list></td>
<td><list id="list20-1046878111431868" list-type="order">
<list-item><p>Refund cost high in the current semester—US$540.00</p></list-item>
<list-item><p>Sales revenue loss high in future semesters, but loss undetermined</p></list-item></list></td>
</tr>
<tr>
<td>D</td>
<td><list id="list21-1046878111431868" list-type="order">
<list-item><p>Bug is fixed within three to five business days and patch installed. Game suspended for this one user while fix is created</p></list-item>
<list-item><p>This bug and its delay cause students to begin to suspect the game experience’s validity</p></list-item>
<list-item><p>The instructor never uses the game again</p></list-item></list></td>
<td><list id="list22-1046878111431868" list-type="order">
<list-item><p>Bug fix cost relatively high in the current run—US$240.00]</p></list-item>
<list-item><p>Negative effect on learning potential moderate, but undetermined</p></list-item>
<list-item><p>High cost in future semesters, but total revenue loss undetermined</p></list-item></list></td>
</tr>
<tr>
<td>E</td>
<td><list id="list23-1046878111431868" list-type="order">
<list-item><p>Bug fixed overnight and patch installed</p></list-item>
<list-item><p>Students suspect the game’s validity as a learning method</p></list-item>
<list-item><p>The instructor never uses the game again</p></list-item>
<list-item><p>Instructor tells many colleagues the game “has problems”</p></list-item></list></td>
<td><list id="list24-1046878111431868" list-type="order">
<list-item><p>Bug fix relatively low for the current run—US$120.00</p></list-item>
<list-item><p>Negative effect on learning potential moderate, but cost undetermined</p></list-item>
<list-item><p>High cost in future semesters, but total revenue loss undetermined</p></list-item>
<list-item><p>Cost of instructor’s opinion voiced to colleagues undetermined, but conditioned by contacts and reputation in the field</p></list-item></list></td>
</tr>
</tbody>
</table>
</table-wrap>
<p>What else is available to the well-meaning game publisher? Other common approaches include payoff tables, decision trees, and simulation models. The use of a payoff table requires a specification of the possible states of nature and the alternative actions that could be taken by the software publisher. A simple example would be the decision to release or not to release a software product. The states of nature could be the product is completely successful, the product has minor flaws, and the product has major defects. The expected net benefits and probability of occurrence of each state of nature for each decision would then be assigned, and the resulting payoff in each of the cells in the payoff matrix determined. The decision with the highest expected net benefit would be selected, but this would be a futile exercise and the decision maker does not know a priori the probabilities of the states of nature.</p>
<p>The decision-tree method comes across the same specification problems, but in different forms at different junctures. Again, the expected net benefits and the probabilities associated with each sequence of events must be assigned. The simulation approach is probably the most involved and requires the set of possible scenarios to be simulated and the outcomes calculated. A sophisticated simulation would allow the cash flows to be calculated for numerous alternatives, but only if the cash flows could be accurately calculated and predicted. Thus, a software “go-to-market” decision is basically a “best feeling” situation with some supporting quantitative analysis. As we see it, it’s a judgment call on the part of the developer.</p>
</sec>
</sec>
</sec>
<sec id="section15-1046878111431868">
<title>The Quality of the Beta Test</title>
<p>Given high conformity of the beta-testing process to the ideal, we expected high reliability and quality with respect to the “responsible” participation of the testers (student players). The following hypotheses were tested to determine the reliability and quality of the beta test’s results, and to try to uncover the reasons for the high level of Type I errors by the participants (testers).</p>
<sec id="section16-1046878111431868">
<title>Hypotheses</title>
<list id="list25-1046878111431868" list-type="simple">
<list-item><p><italic>Hypothesis 1</italic>: All testers will actively participate in playing the game.</p></list-item>
<list-item><p><italic>Hypothesis 2</italic>: All testers will be disciplined in their approach to the game.</p></list-item>
<list-item><p><italic>Hypothesis 3</italic>: All testers will provide full and complete answers to the study’s feedback questions.</p></list-item>
<list-item><p><italic>Hypothesis 4</italic>: A high correlation will be found between tester participation and the amount of feedback given.</p></list-item>
<list-item><p><italic>Hypothesis 5</italic>: A high correlation will be found between participation and the number of hours billed by the testers.</p></list-item>
</list>
<p>The first two hypotheses were tested using a game administrator feature that records the on-screen time players devote to their game. This feature compiles the start and entry times by player and activity such as print, edit, view, save, and submit. The second hypothesis was further examined by retaining all emails associated with the game administrator’s activities and summarizing those messages that pertained to the game’s conduct and orderly processing.</p>
<p>The remaining hypotheses were tested via a content analysis of the responses made to the questions the testers were asked to answer, the information they provided about their experiences, and their suggestions for improving the game.</p>
<list id="list26-1046878111431868" list-type="order"><list-item><p>All testers will actively participate in playing the game.</p></list-item></list>
<p>This study’s first hypothesis stated that all the game’s testers would actively participate in playing the game they were evaluating. <xref ref-type="fig" rid="fig1-1046878111431868">Figure 1</xref> presents a graph of the range of screen time minutes spent by decision period.</p>
<fig id="fig1-1046878111431868" position="float">
<label>Figure 1.</label>
<caption>
<p>Screen time minutes by period</p>
</caption>
<graphic xlink:href="10.1177_1046878111431868-fig1.tif"/></fig>
<p>This graph indicates that in every period, at least one tester spent no time on the period’s decision as the range minutes run from zero in every period. The graph also shows that the mean participation rate varied by period, as indicated by the horizontal line intersecting the range line. The greatest time spent on the game was in its first period, with the least amount of time in the last period. <xref ref-type="fig" rid="fig2-1046878111431868">Figure 2</xref> further indicates the amount of total within-team participation for all periods.</p>
<fig id="fig2-1046878111431868" position="float">
<label>Figure 2.</label>
<caption>
<p>Total and individual screen time by team</p>
</caption>
<graphic xlink:href="10.1177_1046878111431868-fig2.tif"/></fig>
<p>The amount of within-team participation equality was the greatest for Teams 1 and 3. Firm 5 had the least amount of partnering with 97.5% of company’s screen time by one of its members. Other companies, such as Teams 2, 4, and 9, one player dominated the other. Based on these two observations, Hypothesis 1 is rejected. All players did not actively participate in the game, at least as measured by the amount of time they spent online in an online-based game. In fact, 35.1% of the time, certain participants spent less than 5 min on that round’s decisions.</p>
<list id="list27-1046878111431868" list-type="simple">
<list-item><p>2. All testers will be disciplined in their approach to the game.</p></list-item>
</list>
<p>The study’s second hypothesis stated that the testers would be disciplined or systematic in their conduct within the test’s requirements. All email messages associated with the game were retained. <xref ref-type="table" rid="table10-1046878111431868">Table 10</xref> presents a log of what could be defined as discipline failures.</p>
<table-wrap id="table11-1046878111431868" position="float">
<label>Table 10.</label>
<caption><p>Poor Discipline Incidents</p></caption>
<graphic alternate-form-of="table11-1046878111431868" xlink:href="10.1177_1046878111431868-table11.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Period</th>
<th align="center">Incident</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pregame</td>
<td>A player from Firm 1 emails the Game Coach that he is not playing the game seriously.</td>
</tr>
<tr>
<td>Pregame</td>
<td>A player from Firm 4 indicates he is unaware there is a Player’s Guide to the game even though it was supplied as part of the study’s start-up package.</td>
</tr>
<tr>
<td>1</td>
<td>Two teams have signed on only one player.</td>
</tr>
<tr>
<td>1</td>
<td>Five companies failed to turn-in their first decision set on time.</td>
</tr>
<tr>
<td>1</td>
<td>Firm 5 never turns in its decision set. A dummy decision is entered for them by the Game Administrator.</td>
</tr>
<tr>
<td>2</td>
<td>The Game Coach sends extensive comments to Firms 5 and 7. None of the teams logon to change their decision sets.</td>
</tr>
<tr>
<td>2</td>
<td>The Game Coach suggests to Firm 1 that it look again at its production schedule. The team does not logon to correct this error.</td>
</tr>
<tr>
<td>3</td>
<td>Firms 2, 5, and 8 miss the game’s turn-in time. Firm 2 never opens its results until after the game’s turn-in time.</td>
</tr>
<tr>
<td>3</td>
<td>One member of Firm 2 did not know it had a partner in the game. The partner, however, had submitted the team’s decision set without the other members’ knowledge or approval.</td>
</tr>
<tr>
<td>4</td>
<td>Firm 4 submits its decision set 2½ days late thereby holding up the entire game.</td>
</tr>
<tr>
<td>5</td>
<td>One player on Firm 9 states a lack of knowledge that the game had begun and therefore had not been participating in the test.</td>
</tr>
<tr>
<td>5</td>
<td>Four firms miss the game’s turn-in deadline.</td>
</tr>
<tr>
<td>5</td>
<td>Firm 5 submits its decision set 2¾ days late.</td>
</tr>
<tr>
<td>5</td>
<td>Firm 9 submits its decision set 3 days late.</td>
</tr>
<tr>
<td>6</td>
<td>Firm 1 submits its decision set 1½ days late.</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Based on the incidents noted above, it could be reasoned the players lacked discipline in a number of areas. They often were unable to submit their decisions on time. This meant they did not begin to work on their next period’s decision set early enough even though (a) the test’s pacing had been announced in advance and (b) 3 to 4 days occurred between each decision set. Others did not know they had partners or that the game had begun until after a number of periods had elapsed. Based on these observations, the second hypothesis is rejected.</p>
<p>The third hypothesis stated that the testers would give full and complete responses to the study’s questionnaire. This hypothesis was tested by two methods. <xref ref-type="table" rid="table11-1046878111431868">Table 11</xref> shows the number of times each question was answered based on the 11 testers who responded and not on the 18 testers that <italic>should</italic> have responded.</p>
<table-wrap id="table12-1046878111431868" position="float">
<label>Table 11.</label>
<caption><p>Responses by Question</p></caption>
<graphic alternate-form-of="table12-1046878111431868" xlink:href="10.1177_1046878111431868-table12.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th align="left">Question</th>
<th align="center">Count</th>
<th align="center">%</th>
</tr>
</thead>
<tbody>
<tr>
<td>How suitable is the game for an Introduction to Business class?</td>
<td>7</td>
<td>63.6</td>
</tr>
<tr>
<td>How easy is it to know what you need to do?</td>
<td>4</td>
<td>36.4</td>
</tr>
<tr>
<td>How easy is it to make decisions?</td>
<td>6</td>
<td>54.5</td>
</tr>
<tr>
<td>How easy is it to understand the results?</td>
<td>4</td>
<td>36.4</td>
</tr>
<tr>
<td>How easy is it to understand how to win?</td>
<td>5</td>
<td>45.5</td>
</tr>
<tr>
<td>Did you enjoy playing the game?</td>
<td>3</td>
<td>27.3</td>
</tr>
</tbody>
</table>
</table-wrap>
<list id="list28-1046878111431868" list-type="simple">
<list-item><p>3. All testers will provide full and complete answers to the study’s feedback questions.</p></list-item>
</list>
<p>Based on these responses, the testers answered the questions about the game’s suitability for freshmen students and the ease with which decisions could be made. Relatively few answered the questions about enjoying the game or understanding how to win or understanding their results. <xref ref-type="table" rid="table12-1046878111431868">Table 12</xref> indicates how complete each responding tester’s answers were given the questionnaire asked six questions.</p>
<table-wrap id="table13-1046878111431868" position="float">
<label>Table 12.</label>
<caption><p>Answers by Responding Tester</p></caption>
<graphic alternate-form-of="table13-1046878111431868" xlink:href="10.1177_1046878111431868-table13.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th align="left">Tester</th>
<th align="center">Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>6/6</td>
</tr>
<tr>
<td>2</td>
<td>5/6</td>
</tr>
<tr>
<td>3</td>
<td>1/6</td>
</tr>
<tr>
<td>4</td>
<td>0/6</td>
</tr>
<tr>
<td>5</td>
<td>0/6</td>
</tr>
<tr>
<td>6</td>
<td>2/6</td>
</tr>
<tr>
<td>7</td>
<td>6/6</td>
</tr>
<tr>
<td>8</td>
<td>4/6</td>
</tr>
<tr>
<td>9</td>
<td>2/6</td>
</tr>
<tr>
<td>10</td>
<td>1/6</td>
</tr>
<tr>
<td>11</td>
<td>2/6</td>
</tr>
<tr>
<td>Total</td>
<td>2.64/6.00</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Taken in total, this hypothesis regarding complete responses must be rejected. Of the 18 testers, 9 either did not answer any question or did not respond to the questionnaire. Of those who <italic>did</italic> respond, only 3 testers answered all questions or nearly all the questions. These partial responses resulted in a 44.0% question response rate. Accordingly, this hypothesis of response completeness was rejected.</p>
<p>It should be noted, however, that some of the testers were very diligent and businesslike with the responses they provided. The questionnaire asked them to document all grammatical errors with screen captures, quotes, and links to the errors. They responded by presenting 50 screen captures, 113 suggested sentence rewordings, and 35 links to the sources of errant texts.</p>
<list id="list29-1046878111431868" list-type="simple">
<list-item><p>4. Tester participation will correlate highly with the amount of feedback given.</p></list-item>
</list>
<p>The fourth hypothesis looked to see whether a high ratio existed between the amount of time the testers put into playing the game and the amount of information they provided. It was assumed that those who put in the most time viewing and interacting with the game would also have the most to state about the game. This hypothesis was mildly accepted. The correlation between the amounts of screen time devoted the game, and the number of words found in their reports was low, but statistically significant with an <italic>r</italic><sup>2</sup> of .182 and a <italic>p</italic> value of .04 in a one-tail test. This weak correlation means that 81.8% of the variation in the size of their reports was associated with other factors.</p>
<list id="list30-1046878111431868" list-type="simple">
<list-item><p>5. Participation will correlate highly with the number of hours billed by the testers.</p></list-item>
</list>
<p>The fifth hypothesis tested whether the game publisher’s dollar payout reflected the number of hours of tester game time and the feedback game play was supposed to produce. It would be assumed that those who spent the greatest amount of game time would provide the greatest amount of feedback. They should also bill the greater number of hours as their reward for their efforts. A positive, but weak relationship has already been determined between the amount of time the testers spent playing the game and the size of their reports. <xref ref-type="table" rid="table13-1046878111431868">Table 13</xref> shows the actual hourly rate the testers were paid based on the amount of time they spent online with the game and the pay per report word. The game pay rate per hour ranged from US$0.00 to US$20.31 with an average hourly rate of US$10.75. The cost per report word is more problematical because eight testers received pay for play even though they did not file a report. If a report was filed, the pay per report word ranged from US$0.04 to US$0.73 per word or an average of US$0.27 per word. A regression analysis of the testers who filed a report, after constraining the intercept value to zero, shows that Report Size is positively related to the Pay Rate. It is statistically significant with a <italic>p</italic> value less than 5.0% and an adjusted <italic>r</italic><sup>2</sup> equal to 32.9%. Clearly, some testers were better values for the publisher both in the number of hours they devoted to the game and the amount of words they produced per billed hour.</p>
<table-wrap id="table14-1046878111431868" position="float">
<label>Table 13.</label>
<caption><p>Pay Per Online Game Time and Report Size</p></caption>
<graphic alternate-form-of="table14-1046878111431868" xlink:href="10.1177_1046878111431868-table14.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">Game<hr/></th>
</tr>
<tr>
<th align="center">Tester</th>
<th align="center">Pay per hour (US$)</th>
<th align="center">Pay per word</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>11.42</td>
<td>N/R</td>
</tr>
<tr>
<td>2</td>
<td>15.22</td>
<td>N/R</td>
</tr>
<tr>
<td>3</td>
<td>10.06</td>
<td>US$0.17</td>
</tr>
<tr>
<td>4</td>
<td>8.53</td>
<td>US$0.10</td>
</tr>
<tr>
<td>5</td>
<td>16.18</td>
<td>US$0.28</td>
</tr>
<tr>
<td>6</td>
<td>20.31</td>
<td>US$0.07</td>
</tr>
<tr>
<td>7</td>
<td>10.00</td>
<td>N/R</td>
</tr>
<tr>
<td>8</td>
<td>11.81</td>
<td>US$0.53</td>
</tr>
<tr>
<td>9</td>
<td>10.00</td>
<td>US$0.73</td>
</tr>
<tr>
<td>10</td>
<td>0.00</td>
<td>N/R</td>
</tr>
<tr>
<td>11</td>
<td>8.99</td>
<td>US$0.60</td>
</tr>
<tr>
<td>12</td>
<td>13.79</td>
<td>N/R</td>
</tr>
<tr>
<td>13</td>
<td>12.57</td>
<td>US$0.04</td>
</tr>
<tr>
<td>14</td>
<td>10.23</td>
<td>N/R</td>
</tr>
<tr>
<td>15</td>
<td>9.84</td>
<td>N/R</td>
</tr>
<tr>
<td>16</td>
<td>10.00</td>
<td>N/R</td>
</tr>
<tr>
<td>17</td>
<td>10.11</td>
<td>US$0.04</td>
</tr>
<tr>
<td>18</td>
<td>4.45</td>
<td>US$0.16</td>
</tr>
<tr>
<td>Average</td>
<td>10.75</td>
<td>US$0.27</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1046878111431868">
<p><italic>Note.</italic> N/R = no report.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>A further analysis was conducted to determine what factors might have led to the testers failing to submit their game write-ups. This is an important analysis, as this was actually the beta test’s objective. A multiple regression analysis on the submission of a report was conducted using as predictor variables, time spent with the game online, gender, company performance, and class standing. The predictive value of this combination of potential predictors was nonsignificant after adjusting its <italic>r</italic><sup>2</sup> of .40 for the test’s small sample size (adjusted <italic>r</italic><sup>2</sup> = .22, <italic>F</italic> statistic = 2.18). Accordingly, other factors are associated with the nonfiling of reports and they should be investigated and corrective measures taken.</p>
</sec>
</sec>
<sec id="section17-1046878111431868">
<title>Discussion</title>
<p>An effective beta test is necessary before any software application is released to the market. A publisher should not knowingly distribute untested or poorly tested software. An effective beta test should help a software developer meet the important market release conditions of audience propriety, playability, model fidelity, and algorithmic accuracy. Because of these conditions, it is critical for software developers to fully comprehend the beta-testing process.</p>
<p>To better understand the nature and challenges of implementing this ideal, the beta test used by a major game publisher was examined for a first-generation online business game. The example beta test presented in this article was designed to meet the ideal beta-test criteria comprising qualifications of the participants, the requirements list of the application, the test procedures, reporting systems, and the defect analysis.</p>
<p>Many of the indicators of an effective beta-test process were followed. However, problems arose with respect to the nature and participation levels of the testers used for the test. Not all testers contributed equally regarding their involvement with the game or with providing adequate written feedback. This occurred despite the fact that the testers were provided financial incentives to do so. Possible reasons for this deficient behavior were examined. None could be found that related to the testers’ game performance, gender, or class standing. Perhaps greater incentives or different incentives are needed to promote tester involvement, including greater involvement and encouragement by the test game administrators. This problem of uneven, within-team participation is not, however, unique to this study. Participation in group projects is rarely equal. A similar participation counting method for a similar game found equally low participation rates (<xref ref-type="bibr" rid="bibr18-1046878111431868">Wolfe &amp; McCoy, 2008</xref>). Other, nonmonetary incentives might have been effective. A study by <xref ref-type="bibr" rid="bibr5-1046878111431868">Fine (2002)</xref> recommends simple gifts such as T-shirts or coffee mugs whereas this beta test used a financial reward system. An examination of a priori tester rewards and incentives important to tester candidates is warranted and should be subjected to their objective usefulness toward obtaining more-active tester involvement.</p>
<p>Another issue concerns the quality of the tester’s feedback. A review of their feedback indicated a high degree of Type I and Type II errors. This problem was not due to the qualifications of the testers in our study. These testers had the background and capabilities necessary to evaluate the business simulation game as they had been exposed to its knowledge domain through prior coursework. One possible explanation could be that the data gathering instruments were not well utilized by the participants (testers). This, however, does not seem to be the likely cause based on their use of the online data gathering tools they had been exposed to in their training session. It is believed that the test’s reporting problem is most likely related to the lack of motivation by several of the testers. This was demonstrated by their inadequate written feedback. Again, a revised incentive system might help here. This is a serious concern that may exist with many beta-testing situations and clearly warrants further research.</p>
<p>The final stage of the beta-testing cycle, which entails closure or release conditions, was also a contentious issue. In a practical sense, it is impossible to continue testing until all the new software’s defects are found and corrected. No matter how much testing is done, we will always find errors at the extreme or in extreme cases. Thus, a conscientious publisher needs some type of standard or decision rule regarding when such testing should end. To help make the closure decision, the economic paradigm of applying techniques such as NPV, payoff tables, decision trees analysis, and even simulation was reviewed. Unfortunately, it has been found that these techniques are difficult to apply accurately given the imponderables associated with measuring the expected benefits, expected costs, and the probabilities of the various outcomes. It would be good to be able to assign costs or benefits so that the publisher could determine how many more beta tests should be performed to eliminate all possible costly errors. The true, long-term costs to the publisher of releasing bad software might be the user dropping the game thereby losing future royalties and earnings. Another cost could be the publisher earning a negative reputation for releasing faulty software. Another cost might be the extra cost or burden on the publisher’s support group to help users deal with glitches and negative player reactions. However, software glitches and bugs, known as Schroedinbugs, can lie dormant in software and never come to the surface, or are never recognized by adopters until the simulation is used beyond its normal limits.</p>
</sec>
<sec id="section18-1046878111431868">
<title>Conclusion</title>
<p>This study examined the beta-testing program used by a major game developer and publisher. A number of problems arose that compromised the publisher’s ideal method. Because problems will always be associated with even a perfect beta-test design, our study shows that further research is needed on the implementation process, especially in the area of effective tester performance. It is further suggested this research investigate the use of economic tools to determine the practical limits of conducting beta tests of analysis for better quantifying release conditions. With respect to closure, we recommend a final meeting take place with the stakeholders to address the beta test’s results; review lessons learned, and discuss the advantages and disadvantages of releasing the product at that time. The decision to release or retest a product needs to be based on a careful balance between budget considerations, quality issues, risk assessments, and time availability given the uncertainties associated with the entire process.</p>
<p>Simulation development may benefit from future research in the area of beta testing and release conditions. It is hoped that this article will serve as a catalyst for future research on beta testing owing to the paucity of research on this topic and its importance with respect to the effective development of business games.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared the following potential conflicts of interest with respect to the research, authorship, and/or publication of this article: This article’s second writer was the author of the game tested. Neither authors of this article had or have a personal or financial interest in the firm that conducted the beta test. The beta-testing firm had a contractual obligation to the game’s publisher and neither of this article’s two authors.</p></fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors received no financial support for the research and/or authorship of this article.</p></fn>
</fn-group>
<bio>
<title>Bios</title>
<p><bold>Steven C. Gold</bold> is a professor of economics in the Saunders College of Business at the Rochester Institute of Technology. He is a fellow and past president of ABSEL, and has authored four computerized simulation games with such notable publishers as McGraw-Hill and Macmillan. His most recent simulation is designed to teach economics, called Beat the Market, and published with Gold Simulations.</p>
<p>Contact: <email>stevengold@saunders.rit.edu</email></p>
<p><bold>Joseph Wolfe</bold>, PhD, Stern School of Business, New York University. He is a past ABSEL president and is an ABSEL fellow. He is the author of more than 45 case studies and a family of online business games.</p>
<p>Contact: <email>Jwolfe8125@aol.com</email></p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bach</surname><given-names>J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Risk and requirements-based testing</article-title>. <source>Computer</source>, <volume>32</volume>(<issue>6</issue>), <fpage>113</fpage>-<lpage>114</lpage>.</citation>
</ref>
<ref id="bibr2-1046878111431868">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Beizer</surname><given-names>B.</given-names></name>
</person-group> (<year>1990</year>). <source>Software testing techniques</source>. <publisher-loc>Boston MA</publisher-loc>: <publisher-name>International Thomson Computer Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Byers</surname><given-names>C.</given-names></name>
<name><surname>Cannon</surname><given-names>H. M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The programming game: An exploratory collaboration between business simulation and instructional design</article-title>. <source>Developments in Business Simulation and Experiential Learning</source>, <volume>34</volume>, <fpage>259</fpage>-<lpage>265</lpage>.</citation>
</ref>
<ref id="bibr4-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dowson</surname><given-names>M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>The Ariane 5 software failure</article-title>. <source>Software Engineering Notes</source>, <volume>22</volume>(<issue>2</issue>), <fpage>84</fpage>.</citation>
</ref>
<ref id="bibr5-1046878111431868">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fine</surname><given-names>M.</given-names></name>
</person-group> (<year>2002</year>). <source>Beta testing for better software</source>. <publisher-loc>Indianapolis, IN</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr6-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gelperin</surname><given-names>D.</given-names></name>
<name><surname>Hetzel</surname><given-names>B.</given-names></name>
</person-group> (<year>1988</year>). <article-title>The growth of software testing</article-title>. <source>Communications of the ACM</source>, <volume>31</volume>, <fpage>687</fpage>-<lpage>695</lpage>.</citation>
</ref>
<ref id="bibr7-1046878111431868">
<citation citation-type="web">
<collab>THE GLOBAL BUSINESS GAME: BUSINESS BASICS EDITION</collab>. (<comment>n.d.</comment>). <article-title>[Developed by J. Wolfe.]</article-title>. <source>Innovative Learning Solutions</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://web3.onlinegbg.com">http://web3.onlinegbg.com</ext-link></comment></citation>
</ref>
<ref id="bibr8-1046878111431868">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Kaner</surname><given-names>C.</given-names></name>
</person-group> (<conf-date>2006, November</conf-date>). <source>Keynote address—Exploratory testing</source>. <conf-name>Quality Assurance Institute Worldwide Annual Software Testing Conference</conf-name>, <conf-loc>Orlando, FL</conf-loc>.</citation>
</ref>
<ref id="bibr9-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Levenson</surname><given-names>N. G.</given-names></name>
<name><surname>Turner</surname><given-names>C. S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>An investigation of the Therac-25 accidents</article-title>. <source>Computer</source>, <volume>26</volume>(<issue>7</issue>), <fpage>18</fpage>-<lpage>41</lpage>.</citation>
</ref>
<ref id="bibr10-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nissen</surname><given-names>M. E.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Designing qualitative simulation systems for business</article-title>. <source>Simulation &amp; Gaming</source>, <volume>27</volume>, <fpage>462</fpage>-<lpage>483</lpage>.</citation>
</ref>
<ref id="bibr11-1046878111431868">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Pan</surname><given-names>J.</given-names></name>
</person-group> (<year>1999</year>). <source>Software testing (18–849b Dependable Embedded Systems)</source>. <publisher-name>Topics in Dependable Embedded Systems, Electrical and Computer Engineering Department, Carnegie Mellon University</publisher-name>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ece.cmu.edu/~koopman/des_s99/sw_testing/">http://www.ece.cmu.edu/~koopman/des_s99/sw_testing/</ext-link></comment></citation>
</ref>
<ref id="bibr12-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Prakash</surname><given-names>E.</given-names></name>
<name><surname>Brindle</surname><given-names>G.</given-names></name>
<name><surname>Jones</surname><given-names>K.</given-names></name>
<name><surname>Zhou</surname><given-names>S.</given-names></name>
<name><surname>Chaudhari</surname><given-names>N. S.</given-names></name>
<name><surname>Wong</surname><given-names>K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Advances in games technology: Software, models, and intelligence</article-title>. <source>Simulation &amp; Gaming</source>, <volume>40</volume>, <fpage>752</fpage>-<lpage>801</lpage>.</citation>
</ref>
<ref id="bibr13-1046878111431868">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Rogerson</surname><given-names>S.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The Chinook helicopter disaster</article-title>. <source>IMIS Journal</source>, <volume>12</volume>(<issue>2</issue>), <comment>ETHIcol. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ccsr.cse.dmu.ac.uk/resources/general/ethicol/Ecv12no2.html">http://www.ccsr.cse.dmu.ac.uk/resources/general/ethicol/Ecv12no2.html</ext-link></comment></citation>
</ref>
<ref id="bibr14-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shea</surname><given-names>G.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Better beta: The more you know about beta testing, the more your company will gain from the experience</article-title>. <source>Computer World</source>, <volume>40</volume>(<issue>5</issue>), <fpage>43</fpage>-<lpage>44</lpage>.</citation>
</ref>
<ref id="bibr15-1046878111431868">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Srinivasan</surname><given-names>D.</given-names></name>
<name><surname>Gopalaswamy</surname><given-names>R.</given-names></name>
</person-group> (<year>2006</year>). <source>Software testing: Principles and practices</source>. <publisher-loc>New Delhi, India</publisher-loc>: <publisher-name>Pearson Education</publisher-name>.</citation>
</ref>
<ref id="bibr16-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thorelli</surname><given-names>H. B.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Ecology of international business simulation games</article-title>. <source>Simulation &amp; Gaming</source>, <volume>32</volume>, <fpage>492</fpage>-<lpage>506</lpage>.</citation>
</ref>
<ref id="bibr17-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Whittaker</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2000</year>). <article-title>What is software testing? And why is it so hard?</article-title> <source>IEEE Software</source>, <volume>17</volume>(<issue>1</issue>), <fpage>70</fpage>-<lpage>79</lpage>.</citation>
</ref>
<ref id="bibr18-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolfe</surname><given-names>J.</given-names></name>
<name><surname>McCoy</surname><given-names>R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Should business game players choose their teammates: A study with pedagogical implications</article-title>. <source>Developments in Business Simulation and Experiential Learning</source>, <volume>35</volume>, <fpage>318</fpage>-<lpage>328</lpage>.</citation>
</ref>
<ref id="bibr19-1046878111431868">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yang</surname><given-names>M. C. K.</given-names></name>
<name><surname>Chao</surname><given-names>A.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Reliability-estimation and stopping-rules for software testing based on repeated appearances of bugs</article-title>. <source>IEEE Transactions on Reliability</source>, <volume>44</volume>, <fpage>315</fpage>-<lpage>321</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>