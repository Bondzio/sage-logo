<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JPA</journal-id>
<journal-id journal-id-type="hwp">spjpa</journal-id>
<journal-title>Journal of Psychoeducational Assessment</journal-title>
<issn pub-type="ppub">0734-2829</issn>
<issn pub-type="epub">1557-5144</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0734282911435461</article-id>
<article-id pub-id-type="publisher-id">10.1177_0734282911435461</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Cross-Cultural Evaluation of Item Wording Effects on an Attitudinal Scale</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Yang</surname><given-names>Yanyun</given-names></name>
<xref ref-type="aff" rid="aff1-0734282911435461">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Chen</surname><given-names>Yi-Hsin</given-names></name>
<xref ref-type="aff" rid="aff2-0734282911435461">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Lo</surname><given-names>Wen-Juo</given-names></name>
<xref ref-type="aff" rid="aff3-0734282911435461">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Turner</surname><given-names>Jeannine E.</given-names></name>
<xref ref-type="aff" rid="aff1-0734282911435461">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0734282911435461"><label>1</label>Florida State University, Tallahassee, FL, USA</aff>
<aff id="aff2-0734282911435461"><label>2</label>University of South Florida, Tallahassee, FL, USA</aff>
<aff id="aff3-0734282911435461"><label>3</label>University of Arkansas, Tallahassee, FL, USA</aff>
<author-notes>
<corresp id="corresp1-0734282911435461">Yanyun Yang, Department of Educational Psychology and Learning Systems, Box: 306-4453, Florida State University, Tallahassee, FL, 32306, USA. Email: <email>yyang3@fsu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>30</volume>
<issue>5</issue>
<fpage>509</fpage>
<lpage>519</lpage>
<permissions>
<copyright-statement>© 2012 SAGE Publications</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Previous studies have shown that method effects associated with item wording produce artifactual factors and threaten scale validity. This study examines item wording effects on a scale of attitudes toward learning mathematics for Taiwanese and U.S. samples. Analyses from a series of CFA (confirmatory factor analysis) models support the presence of method effects for both samples. In addition, findings show that U.S. students tended to report higher means on not only the substantive factors but also the method factor, compared to Taiwanese students. The effect sizes on the mean differences are medium to large.</p>
</abstract>
<kwd-group>
<kwd>cross-cultural evaluation</kwd>
<kwd>item wording</kwd>
<kwd>attitudes toward learning mathematics</kwd>
<kwd>confirmatory factor analysis</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Self-report scales are frequently used in applied research to collect data from individual participants to assess various constructs such as personality and attitudes. Researchers have suggested that scales contain a roughly equal number of positively and negatively worded items (e.g., <xref ref-type="bibr" rid="bibr23-0734282911435461">Nunnally, 1978</xref>). The idea of including negatively worded items is to maintain respondents’ cognitive consciousness on the item contents and to avoid them establishing an automatic responding pattern due to uniformly positively worded items such that scale score is a more accurate reflection of participants’ true score on the constructs (e.g., <xref ref-type="bibr" rid="bibr24-0734282911435461">Podsakoff, MacKenzie, Lee, &amp; Podsakoff, 2003</xref>). In a review of scale development practices in the study of organizations, <xref ref-type="bibr" rid="bibr10-0734282911435461">Hinkin (1995)</xref> reported that 41% of the studies used questionnaires with negatively worded items. However, studies have repeatedly shown that including both positively and negatively worded items into a scale likely produced artifactual or method factors (e.g., <xref ref-type="bibr" rid="bibr9-0734282911435461">Harvey, Billings, &amp; Nilan, 1985</xref>). Method factors differ from substantive factors in that they are attributable to specific measurement methods (e.g., similar item wordings) rather than to the construct of interest (<xref ref-type="bibr" rid="bibr2-0734282911435461">Bagozzi &amp; Yi, 1991</xref>) and, therefore, threaten scale validity.</p>
<p>Method effects due to item wording have been found in the measure of self-esteem (e.g., <xref ref-type="bibr" rid="bibr26-0734282911435461">Tomás &amp; Oliver, 1999</xref>), physique anxiety (<xref ref-type="bibr" rid="bibr20-0734282911435461">Motl &amp; Conroy, 2000</xref>), job diagnostic survey (<xref ref-type="bibr" rid="bibr9-0734282911435461">Harvey et al., 1985</xref>), and across different groups (e.g., <xref ref-type="bibr" rid="bibr7-0734282911435461">DiStefano &amp; Motl, 2009</xref>). The majority of these studies were conducted on adults and rarely on children. Children may have difficulties in understanding negatively worded items due to their verbal abilities and cognitive development. We expected that they would respond differently to positively and negatively worded items, and item wording effects were substantial. In a study investigating the impact of item phrasing on the validity of an attitudinal scale for fourth to sixth graders in the United States, <xref ref-type="bibr" rid="bibr3-0734282911435461">Benson and Hocevar (1985)</xref> compared children’ self-rating on two sets of 15 items with same contents but with different phrasing. Items were worded positively in one set but negatively in the other set by adding “not” or “do not” to the positively worded items. Each item was rated on a scale of 1 (<italic>strong agree</italic>) to 5 (<italic>strong disagree</italic>). They found that children tended to report less favorable attitude on negatively worded items (regressed toward the scale point of 3) than positively worded items with same content. In addition, factor loadings obtained from the confirmatory factor analysis (CFA) based on the negatively worded items were generally lower than those based on the positively worded items. They argued that young children may not be able to express agreement by indicating disagreement with a negative statement or to express disagreement by indicating agreement with a negative statement.</p>
<p>This study examined method effects due to item wording on an attitudinal scale toward learning mathematics (hereafter attitudes) for fourth graders from a cross-cultural perspective, specifically, by comparing the Taiwanese and the U.S. samples using data from the <italic>Trends in International Mathematics and Science Study</italic> (TIMSS) collected in 2007. We focused on cross-cultural comparison because there have not been such endeavors. Commonly speaking, students with positive attitudes (e.g., liking mathematics) tend to achieve higher in mathematics (<xref ref-type="bibr" rid="bibr21-0734282911435461">Mullis, Martin, &amp; Foy, 2008</xref>). One may expect that students in East Asia (e.g., Taiwan) possessed more positive attitudes than their counterparts in the West (e.g., United States) because they outperformed in mathematics achievement (<xref ref-type="bibr" rid="bibr21-0734282911435461">Mullis et al., 2008</xref>). Strikingly, students in Taiwan, like those in many other Asian countries, showed relatively negative attitudes, compared to students in the United States. <xref ref-type="bibr" rid="bibr13-0734282911435461">Leung (2002)</xref> provides potential reasons to explain these findings: (a) Cultural value of modesty: Affected by the Confucian culture, students in Taiwan are taught not to boast about themselves. The Chinese saying of “Pride hurts, modesty benefits” may well articulate this cultural value. (b) The high standards along with the competitive examination systems within Asian countries: Although producing higher achievement scores than their counterparts in the West, most students in Asian countries are classified as failures under the competitive examination systems. They may, therefore, lack confidence in their ability and grow to dislike mathematics. In addition, Taiwanese teachers seldom encourage students because of fear that praise may result in students putting forth less effort and in turn becoming complacent.</p>
<sec id="section1-0734282911435461">
<title>Purpose of this Study</title>
<p>This study has two purposes. We first examined the presence of method effects due to item wording on the scale for both samples. If present, we examined which group of students tended to report higher scores on the substantive factors as well as the method factor. To answer the first research question, a series of <italic>Correlated-Trait Correlated-Method</italic> models from CFA framework (CFA-CTCM; for example, <xref ref-type="bibr" rid="bibr27-0734282911435461">Widaman, 1985</xref>) was conducted on each sample. To make cross-cultural comparison on the factor scores, multiple-group CFA-CTCM models were conducted on the combined sample. We next described in detail CFA-CTCM models.</p>
</sec>
<sec id="section2-0734282911435461">
<title>CFA-CTCM Models</title>
<p>In the past five decades, researchers have developed multiple analytic procedures to examine scale score validity (specifically, convergent and discriminant validity) and to detect method effects (e.g., <xref ref-type="bibr" rid="bibr4-0734282911435461">Campbell &amp; Fiske, 1959</xref>). A popular technique is referred to as CFA-CTCM. In a CFA-CTCM model, in addition to the substantive factors (i.e., trait factors) underlying the items measuring the construct of interest, a factor is specified among the items using same measurement methods. For example, if a scale contains both positively and negatively worded items, two method factors are specified: One underlies all negatively worded items and the other underlies all positively worded items. Typically, substantive factors and method factors are uncorrelated. CFA-CTCM models can then be compared to the models without method factors to evaluate the presence of method effects, for example, by chi-square difference test. However, CFA-CTCM models usually encounter identification problems, inadmissible solutions, and fail to provide a clear distinction between the meaning of substantive factors and method factors (<xref ref-type="bibr" rid="bibr8-0734282911435461">Eid, 2000</xref>; <xref ref-type="bibr" rid="bibr16-0734282911435461">Marsh, 1989</xref>). To overcome these limitations, <xref ref-type="bibr" rid="bibr12-0734282911435461">Kenny and Kashy (1992)</xref> and Eid revised the CFA-CTCM model such that the number of method factors is M-1 where M is the number of measurement methods and it is referred to as the CFA-CTC(M-1) model. For the example mentioned above, the number of method factor is 1 either for positively or negatively worded items but not both.</p>
<p>In a CFA-CTC(M-1) model, one of the methods should be chosen as a comparison standard. The observed score variance on the items measured by the comparison standard, for example, positively worded items, is decomposed into trait component and residual component. The observed score variance for negatively worded items includes one additional component: method-specific component. If the trait component is dominant and method-specific component is small, it suggests that two methods (positive wording and negative wording) measure the same trait consistently, which is an evidence of convergent validity. On the other hand, if method-specific component is dominant relative to trait component, then the two methods provide inconsistent measures of the construct of interest (see <xref ref-type="bibr" rid="bibr8-0734282911435461">Eid, 2000</xref>). In this study, we adopted the CFA-CTC(M-1) models and the method factor was specified for negatively worded items based on the special nature of participating children and the findings from <xref ref-type="bibr" rid="bibr3-0734282911435461">Benson and Hocevar (1985)</xref>.</p>
</sec>
<sec id="section3-0734282911435461" sec-type="methods">
<title>Method</title>
<sec id="section4-0734282911435461">
<title>Data Source</title>
<p>Data on the fourth graders’ attitudes toward learning mathematics were retrieved from the TIMSS study in 2007. The TIMSS study was chosen because it is the largest international achievement study and has been widely used to investigate cultural differences in students’ learning mathematics. A stratified systematic sampling technique was used in the TIMSS-2007 sample design, with sampling probabilities proportional to school’s size of enrollment. A sample of schools was drawn and then a sample of classrooms within schools was selected. There were 515 classes nested within 257 schools for the American sample and 174 classes within 150 schools for the Taiwanese sample. The Taiwanese sample had 4,111 fourth graders with 2,127 (51.7 %) boys and 1,984 (48.3%) girls. The American sample had 7,831 fourth graders with 3,828 (48.9%) boys and 4,003 (51.1%) girls.</p>
</sec>
<sec id="section5-0734282911435461">
<title>Instrument</title>
<p>The attitudinal scale consisted of 7 items (see <xref ref-type="table" rid="table1-0734282911435461">Table 1</xref>) intended to measure two aspects of students’ attitudes: Items 1 to 3 measured students’ positive affect toward mathematics (ATM) and Items 4 to 7 measured students’ self-confidence in learning mathematics (SCM; <xref ref-type="bibr" rid="bibr17-0734282911435461">Martin &amp; Preuschoff, 2008</xref>). Item 2, 5, and 6 were negatively worded and others were positively worded. Students were asked to respond to these items using a 4-point scale (1 = <italic>agree a lot</italic> to 4 = <italic>disagree a lot</italic>). Scores on positively worded items were reversely coded so that higher scores on all items indicated more positive attitudes. The questionnaires used in the TIMSS study were originally developed in English and then translated into various languages (e.g., traditional Chinese used in Taiwan). A strict translation-review-verification procedure was used “to create excellent quality translations that were appropriately adapted for the national context and at the same time are internationally comparable” (<xref ref-type="bibr" rid="bibr21-0734282911435461">Mullis et al., 2008</xref>, p. 63).</p>
<table-wrap id="table1-0734282911435461" position="float">
<label>Table 1.</label>
<caption>
<p>Mean, Standard Deviations, and Correlation Matrix Among Seven Items</p>
</caption>
<graphic alternate-form-of="table1-0734282911435461" xlink:href="10.1177_0734282911435461-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Item1</th>
<th align="center">Item 2</th>
<th align="center">Item 3</th>
<th align="center">Item 4</th>
<th align="center">Item 5</th>
<th align="center">Item 6</th>
<th align="center">Item 7</th>
<th align="center">United States <italic>M</italic> (<italic>SD</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Item 1. I enjoy learning mathematics</td>
<td align="center">—</td>
<td>.598</td>
<td>.753</td>
<td>.374</td>
<td>.196</td>
<td>.302</td>
<td>.350</td>
<td>3.17 (0.99)</td>
</tr>
<tr>
<td>Item 2. Mathematics is boring</td>
<td>.507</td>
<td align="center">—</td>
<td>.605</td>
<td>.283</td>
<td>.244</td>
<td>.345</td>
<td>.250</td>
<td>3.06 (1.11)</td>
</tr>
<tr>
<td>Item 3. I like mathematics</td>
<td>.791</td>
<td>.563</td>
<td align="center">—</td>
<td>.431</td>
<td>.249</td>
<td>.346</td>
<td>.377</td>
<td>3.13 (1.05)</td>
</tr>
<tr>
<td>Item 4. I usually do well in mathematics</td>
<td>.457</td>
<td>.285</td>
<td>.489</td>
<td align="center">—</td>
<td>.430</td>
<td>.485</td>
<td>.510</td>
<td>3.32 (0.75)</td>
</tr>
<tr>
<td>Item 5. Mathematics is harder for me than for many of my classmates</td>
<td>.299</td>
<td>.330</td>
<td>.329</td>
<td>.320</td>
<td align="center">—</td>
<td>.530</td>
<td>.383</td>
<td>2.96 (1.09)</td>
</tr>
<tr>
<td>Item 6. I’m just not good at mathematics</td>
<td>.288</td>
<td>.297</td>
<td>.312</td>
<td>.507</td>
<td>.465</td>
<td align="center">—</td>
<td>.389</td>
<td>3.27 (1.02)</td>
</tr>
<tr>
<td>Item 7. I learn things quickly in mathematics</td>
<td>.505</td>
<td>.292</td>
<td>.529</td>
<td>.552</td>
<td>.293</td>
<td>.405</td>
<td align="center">—</td>
<td>3.06 (0.92)</td>
</tr>
<tr>
<td>Taiwan <italic>M</italic> (<italic>SD</italic>)</td>
<td>2.70</td>
<td>2.79</td>
<td>2.69</td>
<td>2.89</td>
<td>2.27</td>
<td>2.53</td>
<td>2.74</td>
<td align="center">—</td>
</tr>
<tr>
<td/>
<td>(1.03)</td>
<td>(1.08)</td>
<td>(1.08)</td>
<td>(.87)</td>
<td>(1.01)</td>
<td>(1.08)</td>
<td>(0.95)</td>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0734282911435461">
<p>Note: Values below and above the diagonals represent the correlations for the Taiwanese and the American samples, respectively.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section6-0734282911435461">
<title>Model Specifications and Evaluations</title>
<p>Three CFA-model (<xref ref-type="fig" rid="fig1-0734282911435461">Figure 1</xref>) analyses were conducted to examine method effects associated with item wording for each sample. Model 1a was a one-factor model consisting of a general attitude factor. We did not expect this model to fit adequately to the data, but the loadings should be relatively large to ensure the scale was essentially unidimensional. Model 1b contained two correlated factors with Items 1 to 3 on ATM factor and Items 4 to 7 on SCM factor. Models 1c was a CTC(M-1) model containing two correlated factors as specified in Model 1b plus a method factor underlying three negatively worded items. A superior of Model 1c over Model 1a and 1b would suggest the presence of method effects.</p>
<fig id="fig1-0734282911435461" position="float">
<label>Figure 1.</label>
<caption>
<p>Models for the factor structures of the scale of attitudes toward learning mathematics</p>
</caption>
<graphic xlink:href="10.1177_0734282911435461-fig1.tif"/></fig>
<p>If Model 1c was chosen for both samples, a series of two-group CFA-CTC(M-1) models with increasing restricted levels of invariance (<xref ref-type="bibr" rid="bibr19-0734282911435461">Millsap &amp; Kwok, 2004</xref>) were evaluated to examine group mean difference on the latent factors (method and substantive factors) following the step procedure laid out in <xref ref-type="bibr" rid="bibr25-0734282911435461">Thompson and Green (2006)</xref>. The first step was to examine <italic>configural invariance</italic> to check whether two groups demonstrated the same factor structure (Model 2a). Model 2a was the same as Model 1c except the analysis was conducted on the combined sample with country as a grouping variable. If this model yielded adequate fit, configural invariance was supported. We then imposed equality constraints across groups on the factor loadings (<italic>metric invariance</italic>; Model 2b) and then on the item intercepts (<italic>scalar invariance</italic>; Model 2c). In this procedure, models with more constraints were nested within models with fewer constraints. If at least some of the loadings and intercepts were invariant (i.e., partial measurement invariance), we proceeded to compare group mean difference on the latent factors (<italic>latent factor mean invariance</italic>; Model 2d).</p>
<p>All CFA models were conducted using <italic>Mplus</italic> 5.21 (<xref ref-type="bibr" rid="bibr22-0734282911435461">Muthén &amp; Muthén, 1998-2009</xref>) with robust maximum likelihood (MLR) estimation. To evaluate model-data fit, the following commonly reported criteria were applied: nonsignificant model chi-square, comparative fit index (CFI) greater than 0.95, root mean square error of approximation (RMSEA) less than 0.06, and standardized root mean residual (SRMR) less than 0.08 (<xref ref-type="bibr" rid="bibr11-0734282911435461">Hu &amp; Bentler, 1999</xref>). Because the sample in this study was large, even trivial differences in model specification may result in significance of chi-square test. We thus de-emphasized the importance of chi-square test and chi-square difference test on the model-fit evaluation procedure. Instead, we used the differences in CFI, TLI (Tucker–Lewis Index), and RMSEA indices to evaluate the relative fit for nested models in measurement invariance analyses. Using simulation studies, <xref ref-type="bibr" rid="bibr5-0734282911435461">Chen (2007)</xref> suggested that if the decrease in CFI for the more constrained model is less than 0.01 and TLI and RMSEA show as good or a better fit than those for the less constrained model, the more constrained model is preferred, meaning that measurement invariance is supported.</p>
</sec>
</sec>
<sec id="section7-0734282911435461" sec-type="results">
<title>Results</title>
<sec id="section8-0734282911435461">
<title>Descriptive Statistics</title>
<p><xref ref-type="table" rid="table1-0734282911435461">Table 1</xref> provides mean and standard deviation for each item and correlation matrix among items. Students in Taiwan tended to reported lower scores on each item (i.e., less favorable attitudes) than students in the United States. The correlations among these items ranged from .20 to .80, the majority of which fell in the range of .30 to .50. Overall, the correlations were comparable between the Taiwanese and the U.S. samples. In addition, the correlations among the items measuring the same hypothesized substantive factors (i.e., ATM and SCM) were higher than the correlations among items measuring different hypothesized substantive factors.</p>
</sec>
<sec id="section9-0734282911435461">
<title>Method Effects for Each Sample</title>
<p>The three CFA-CTC(M-1) models were first analyzed for each sample. The proportion of missing data on items ranged from 0.3% to 0.5%. There was no evidence that missing values on an item were associated with other items or the country. We treated the missingness on this small proportion of data completely as random and applied the full information maximum likelihood estimation method. <xref ref-type="table" rid="table2-0734282911435461">Table 2</xref> presents model chi-square and fit indices for each model. As expected, Model 1a did not fit well for both samples but yielded reasonably large standardized loadings within a range of 0.40 to 0.90. For both samples, Model 1b demonstrated reasonable fit except for RMSEA, while Model 1c fit the data very well and substantially better than Model 1b. In addition, we analyzed a model with one general factor (across all items) and one method factor (across negatively worded items). It fit poorly. These results supported the two substantive factor structure with method factor associated with negatively worded items. Although not reported, Model 1c also fit the data very well and substantially better than Model 1b in the combined sample.</p>
<table-wrap id="table2-0734282911435461" position="float">
<label>Table 2.</label>
<caption>
<p>Fit Indexes of CFA-CTC(M-1) Models</p>
</caption>
<graphic alternate-form-of="table2-0734282911435461" xlink:href="10.1177_0734282911435461-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">χ<sup>2</sup> (MLR)</th>
<th align="center"><italic>df</italic></th>
<th align="center">CFI</th>
<th align="center">TLI</th>
<th align="center">RMSEA</th>
<th align="center">SRMR</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="7">Model 1a</td>
</tr>
<tr>
<td> Taiwan</td>
<td>1524.52<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>14</td>
<td>.808</td>
<td>.713</td>
<td>.162</td>
<td>.084</td>
</tr>
<tr>
<td> United States</td>
<td>3684.22<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>14</td>
<td>.740</td>
<td>.610</td>
<td>.183</td>
<td>.109</td>
</tr>
<tr>
<td colspan="7">Model 1b</td>
</tr>
<tr>
<td> Taiwan</td>
<td>567.48<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>13</td>
<td>.930</td>
<td>.886</td>
<td>.102</td>
<td>.047</td>
</tr>
<tr>
<td> United States</td>
<td>668.24<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>13</td>
<td>.954</td>
<td>.925</td>
<td>.080</td>
<td>.036</td>
</tr>
<tr>
<td colspan="7">Model 1c</td>
</tr>
<tr>
<td> Taiwan</td>
<td>210.05<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>10</td>
<td>.975</td>
<td>.947</td>
<td>.070</td>
<td>.028</td>
</tr>
<tr>
<td> United States</td>
<td>160.25<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>10</td>
<td>.989</td>
<td>.978</td>
<td>.044</td>
<td>.021</td>
</tr>
<tr>
<td>Model 2a: Configural invariance</td>
<td>372.01<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>20</td>
<td>.984</td>
<td>.966</td>
<td>.054</td>
<td>.024</td>
</tr>
<tr>
<td>Model 2b: Metric invariance</td>
<td>525.49<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>27</td>
<td>.977</td>
<td>.965</td>
<td>.056</td>
<td>.041</td>
</tr>
<tr>
<td colspan="7">Model 2c: Scalar invariance</td>
</tr>
<tr>
<td> 2c: All intercepts equal</td>
<td>755.41<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>31</td>
<td>.967</td>
<td>.955</td>
<td>.063</td>
<td>.047</td>
</tr>
<tr>
<td> 2c-R: All intercepts equal except Item 2</td>
<td>603.98<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>30</td>
<td>.974</td>
<td>.964</td>
<td>.057</td>
<td>.042</td>
</tr>
<tr>
<td colspan="7">Model 2d: Factor means</td>
</tr>
<tr>
<td> 2d-1: Three means equal</td>
<td>1901.84<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>33</td>
<td>.915</td>
<td>.892</td>
<td>.097</td>
<td>.102</td>
</tr>
<tr>
<td> 2d-2: Equal means on ATM and SCM</td>
<td>1262.84<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>32</td>
<td>.944</td>
<td>.927</td>
<td>.080</td>
<td>.080</td>
</tr>
<tr>
<td> 2d-3: Equal mean on negative factor</td>
<td>972.04<xref ref-type="table-fn" rid="table-fn3-0734282911435461">*</xref></td>
<td>31</td>
<td>.957</td>
<td>.942</td>
<td>.071</td>
<td>.051</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0734282911435461">
<p>Note: ATM = positive affect toward mathematics; SCM = self-confidence in learning mathematics; CFI = comparative fit index; MLR = robust maximum likelihood; RMSEA = root mean square error of approximation; SRMR = standardized root mean residual; TLI = Tucker–Lewis Index.</p>
</fn>
<fn id="table-fn3-0734282911435461">
<label>*</label>
<p><italic>p</italic> &lt; .01.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section10-0734282911435461">
<title>Latent Factor Mean Comparison Across the Taiwanese and the American Samples</title>
<p>We next examined mean differences on the latent factors between the two groups by analyzing and comparing Model 2a to 2d on the combined sample. The results were shown in <xref ref-type="table" rid="table2-0734282911435461">Table 2</xref>. Model 2a fit the data reasonably well, supporting configural invariance. In Model 2b, all freely estimated loadings were constrained to be equal. Variance of the three-factors was fixed as one in the U.S. sample while freely estimated in the Taiwanese sample. Model 2b resulted in better fit than Model 2a with a decrease in CFI value, at about 0.007 (smaller than 0.01), and similar TLI and RMSEA values, indicating that metric invariance was supported. Next, scalar invariance (Model 2c)was examined by imposing equality constraints on the intercepts. For this model, the three-factor means for the U.S. sample were arbitrarily fixed as zero but were freely estimated for the Taiwanese sample. Model 2c showed much worse fit than Model 2b. The equality constraint on the intercept of Items 2 (“Mathematics is boring”) was removed based on the values of modification indices (Model 2c-R). Compared to Model 2b, this model yielded a decrease of 0.003 in CFI value and almost identical TLI and RMSEA values. We therefore made no further modification and concluded that the two samples demonstrated partial scalar invariance (all but Item 2).</p>
<p>With partial invariance established, we then examined the mean differences on the latent factors. In this step, we analyzed three models: all factor means to be equal across groups (Model 2d-1), means of two substantive factors but not the method factor to be equal (Model 2d-2), and only the mean of the method factor to be equal (Model 2d-3). All three models demonstrated substantially worse fit compared to Model 2c-R, suggesting that the means on the three factors were not equal across groups. <xref ref-type="table" rid="table3-0734282911435461">Table 3</xref> reports standardized loading(s) for each item as well as mean and variance of factors based on Model 2c-R. On average, students in Taiwan had lower means on all three factors (i.e., less favorable attitudes). The standardized mean difference <italic>d</italic> was 0.465, 0.645, and 0.622 for the ATM, SCM, and method factor, respectively, indicating medium to large effect sizes. The <italic>R</italic><sup>2</sup> (percentage of variance explained by the factors), which was an index of item reliability, ranged from .43 to .84. The method-specific variance was computed as the ratio of squared standardized loading associated with method factor divided by <italic>R</italic><sup>2</sup>. This index represented the percentage of true score variance accounted for by the method factor. The values ranged from .10 to .45.</p>
<table-wrap id="table3-0734282911435461" position="float">
<label>Table 3.</label>
<caption>
<p>Standardized Loadings, Factor Means and Variance, and Variance Components Based on Model 2c-R</p>
</caption>
<graphic alternate-form-of="table3-0734282911435461" xlink:href="10.1177_0734282911435461-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">Factor loadings<hr/></th>
<th align="center" colspan="2">Variance components<hr/></th>
</tr>
<tr>
<th/>
<th align="center">Substantive factors</th>
<th align="center">Negative factors</th>
<th align="center"><italic>R</italic><sup>2</sup></th>
<th align="center">Method specific</th>
</tr>
</thead>
<tbody>
<tr>
<td>Item 1</td>
<td>0.86/0.86</td>
<td/>
<td>.73/.74</td>
<td/>
</tr>
<tr>
<td>Item 2</td>
<td>0.66/0.66</td>
<td>0.23/0.22</td>
<td>.49/.48</td>
<td>0.11/0.10</td>
</tr>
<tr>
<td>Item 3</td>
<td>0.89/0.92</td>
<td/>
<td>.79/.84</td>
<td/>
</tr>
<tr>
<td>Item 4</td>
<td>0.80/0.76</td>
<td/>
<td>.64/.58</td>
<td/>
</tr>
<tr>
<td>Item 5</td>
<td>0.49/0.53</td>
<td>0.44/0.44</td>
<td>.43/.48</td>
<td>0.45/0.41</td>
</tr>
<tr>
<td>Item 6</td>
<td>0.60/0.60</td>
<td>0.49/0.44</td>
<td>.60/.55</td>
<td>0.39/0.35</td>
</tr>
<tr>
<td>Item 7</td>
<td>0.66/0.71</td>
<td/>
<td>.44/.50</td>
<td/>
</tr>
<tr>
<td colspan="2">Factor mean</td>
<td colspan="3">ATM: 0/–0.50, SCM: 0/–0.63, Negative: 0/–0.74</td>
</tr>
<tr>
<td colspan="2">Factor variance</td>
<td colspan="3">ATM: 1/1.08, SCM: 1/1.16, Negative: 1/0.98</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0734282911435461">
<p>Note: ATM = positive affect toward mathematics; SCM = self-confidence in learning mathematics. Value for the U.S. sample was reported followed by the Taiwanese sample.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section11-0734282911435461" sec-type="discussion">
<title>Discussion</title>
<p>As advocated in the <italic>Standard for Educational and Psychological Testing</italic> (<xref ref-type="bibr" rid="bibr1-0734282911435461">American Educational Research Association, American Psychological Association, &amp; the National Council on Measurement in Education, 1999</xref>), researchers and practitioners need to be aware of sources of measurement errors that threaten reliability and validity when interpreting scale scores. Researchers have identified multiple sources of measurement errors, among which method effects associated with item wording have been considered as one of the main sources producing measurement errors (e.g., <xref ref-type="bibr" rid="bibr24-0734282911435461">Podsakoff et al., 2003</xref>). In this study, we applied CFA-CTC(M-1) models to a scale measuring fourth graders’ attitudes toward learning mathematics used in the TIMSS-2007 study. Our results supported the presence of method effects associated with item wording, and the method effects were generalizable across the U.S. and Taiwan samples.</p>
<p>One perspective is that the positively worded items are more prone to acquiescence and exaggeration and thus yield overestimates of children’ attitudes, and inclusion of negatively worded items counteracts some problems with positively worded items and helps produce more accurate scores. However, our analyses suggested that negatively worded items tended to yield less reliable scores. Reliabilities (<italic>R</italic><sup>2</sup>; see <xref ref-type="table" rid="table3-0734282911435461">Table 3</xref>) were relatively low for Items 2, 5, 6, and 7, three of which were worded negatively. A similar finding was obtained in <xref ref-type="bibr" rid="bibr3-0734282911435461">Benson and Hocevar (1985)</xref>. For Items 5 and 6, the standardized loadings on the substantive factor were 0.49 to 0.60, which seem to be considered as satisfactory convergent validity. However, their corresponding loadings on the method factor were also high, ranging from 0.44 to 0.49; the method factor accounted for 35% to 45% of the true score variance. In other words, they led to an inconsistent measure of trait factors with positively worded items and thus threatened convergent validity (<xref ref-type="bibr" rid="bibr8-0734282911435461">Eid, 2000</xref>).</p>
<p>Based on the parameter estimates from Model 2c-R, the percentage of variance among negatively worded items (i.e., subscale score) accounted for by the method factor could be computed; the value was 25% and 22% for the U.S. and the Taiwanese samples, respectively. In other words, about one fourth of their score variance was invalid because it was attributable to the measurement method instead of trait factors (SCM and ATM). The finding of a large method effect was consistent with what was summarized by <xref ref-type="bibr" rid="bibr6-0734282911435461">Cote and Buckley (1987)</xref> across 70 empirical studies, although different analyses were applied. In addition, internal consistency reliability for total scale scores could also be computed. Interpretation of total scale score was meaningful because these items demonstrated essential unidimensionality. Reliability concerns about the consistency of scores if a measurement is readministered under same conditions (<xref ref-type="bibr" rid="bibr14-0734282911435461">Lord &amp; Novick, 1968</xref>). Both trait and method factors lead to consistent scores and thus contribute to scale score reliability. The scale score reliability coefficient was .876 and .883 for the U.S. and the Taiwanese samples, respectively. It should be noted that reliability coefficient computed in this way is coefficient omega (<xref ref-type="bibr" rid="bibr18-0734282911435461">McDonald, 1999</xref>). It yields more accurate estimate of reliability than Cronbach’s alpha when the items do not meet restrictive assumptions such as tau-equivalency assumption (see <xref ref-type="bibr" rid="bibr28-0734282911435461">Yang &amp; Green, 2011</xref>, for discussion and demonstration of various reliability estimation methods). As a comparison to coefficient omega, Cronbach’s alpha was .821 for the U.S. sample and .837 for the Taiwanese sample.</p>
<p>It is important to note that our analyses did not lead to a conclusion that method effects were due to negative wording, and the survey developer should avoid considering this type of item in scales. For the purpose of evaluating reliability and validity of scores using CFA-CTC(M-1) models, either positively or negatively worded items could be chosen as comparison standard. The choice of comparison standard may affect model fit and yield different sets of parameter estimates but not the conclusion regarding item wording effects. To demonstrate, we analyzed all CFA-CTC(M-1) models with the method factor underlying positively worded items. Each of these models yielded slightly better fit partly due to estimating one or more parameters. The analyses led to the same conclusions on measurement invariance (e.g., partial invariance was supported) and comparable reliability estimates for both individual items and the total scale. Method factor also accounted for a large portion of variance (about 20%-35%) among the positively worded items. On the basis of our analyses, we felt comfortable to conclude that although these items were intended to measure the same latent construct (attitudes), use of different item wording led to inconsistency in scores.</p>
<p>We wish to understand why fourth-grade students perceived positively and negatively worded items regarding attitudes in different ways. As shown in <xref ref-type="table" rid="table3-0734282911435461">Table 3</xref>, the method-specific component was smallest for Item 2 (“Mathematics is boring”) but largest for Item 5 (“Mathematics is harder for me than for many of my classmates”). Item 2 has only three words, and “boring” is commonly used among younger children. It is likely that for Item 2 negative wording did create a “bump” in information-processing procedure, but it was cognitively manageable for younger children. However understanding Item 5 required wider attention span and higher level of language abilities. In fact, Item 5 also had lowest mean score in both samples (see <xref ref-type="table" rid="table1-0734282911435461">Table 1</xref>). We argue that, for younger children or some special populations, lower reliability on negatively worded items and the resulting inconsistent scores between positively and negatively worded items may be consequences of limited attention span or lack of language proficiency. For instance, a previous study found that younger students and students with poorer reading skills were not able to respond appropriately to negative items on rating scales (<xref ref-type="bibr" rid="bibr15-0734282911435461">Marsh, 1986</xref>). However, this might not hold true for older children or adults. To fully understand this issue, further studies should be conducted, for example, to correlate the method factor to the children’s reading abilities and attention span.</p>
<p>Another focus of this study was to compare mean differences on the latent factors between two samples. Commonly, group comparisons are conducted at the observed score level using statistical analyses such as <italic>t</italic> test and ANOVA (analysis of variance). These statistical procedures assume the observed scores are equally reliable and items in the scale function equally well across groups. However, this might not be true in practice and should be examined before group comparison are being made. By analyzing a series of two-group CFA-CTC(M-1) models, we established measurement invariance between the U.S. and the Taiwanese samples for this attitudinal scale. The findings from our results suggested that the 7 items functioned equally well as evidenced by the tenability of metric invariance and scalar invariance (all but one item). With this establishment, we drew a conclusion that students in the United States tended to report more positive attitudes compared to Taiwanese students, with medium to large effect sizes. This finding echoed <xref ref-type="bibr" rid="bibr13-0734282911435461">Leung’s (2002)</xref> explanations about the cultural differences between the East (e.g., Taiwan) and the West (e.g., United States).</p>
<p>In summary, this study examined method effects associated with item wording on the TIMSS 7-item attitudinal scale and found them to be generalizable across the U.S. and the Taiwanese samples. Our findings suggested that researchers and practitioners need to be aware of the item wording effects and take them into consideration in item writing, particularly for younger children. For example, test developers might consider expressing negatively worded items as simple as possible with words that children are familiar with. After data are collected, statistical analyses can be conducted to examine psychometric properties of the scale scores, to detect method effects, to investigate the relationship between method effects and other variables, to further understand what factors lead to score mean differences across cultures on not only substantive factors but also method factor, and so on.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0734282911435461">
<citation citation-type="book">
<collab>American Educational Research Association, American Psychological Association, &amp; the National Council on Measurement in Education</collab>. (<year>1999</year>). <source>Standards for educational and psychological testing</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>.</citation>
</ref>
<ref id="bibr2-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bagozzi</surname><given-names>R. P.</given-names></name>
<name><surname>Yi</surname><given-names>Y.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Multitrait-multimethod matrices in consumer research</article-title>. <source>Journal of Consumer Research</source>, <volume>17</volume>, <fpage>426</fpage>-<lpage>439</lpage>.</citation>
</ref>
<ref id="bibr3-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Benson</surname><given-names>J.</given-names></name>
<name><surname>Hocevar</surname><given-names>D.</given-names></name>
</person-group> (<year>1985</year>). <article-title>The impact of item phrasing on the validity of attitude scales for elementary school children</article-title>. <source>Journal of Educational Measurement</source>, <volume>22</volume>(<issue>3</issue>), <fpage>231</fpage>-<lpage>240</lpage>.</citation>
</ref>
<ref id="bibr4-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Campbell</surname><given-names>D. T.</given-names></name>
<name><surname>Fiske</surname><given-names>D. W.</given-names></name>
</person-group> (<year>1959</year>). <article-title>Convergent and discriminant validation by the multitrait-multimethod matrix</article-title>. <source>Psychological Bulletin</source>, <volume>56</volume>, <fpage>81</fpage>-<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr5-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>F. F.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Sensitivity of goodness of fit indexes to lack of measurement invariance</article-title>. <source>Structural Equation Modeling</source>, <volume>14</volume>, <fpage>464</fpage>-<lpage>504</lpage>.</citation>
</ref>
<ref id="bibr6-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cote</surname><given-names>J. A.</given-names></name>
<name><surname>Buckley</surname><given-names>R.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Estimating trait, method, and error variance: Generalizing across 70 construct validation studies</article-title>. <source>Journal of Marketing Research</source>, <volume>24</volume>, <fpage>315</fpage>-<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr7-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DiStefano</surname><given-names>C.</given-names></name>
<name><surname>Motl</surname><given-names>R. W.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Self-esteem and method effects associated with negatively worded items: Investigating factorial invariance by sex</article-title>. <source>Structural Equation Modeling: A Multidisciplinary Journal</source>, <volume>16</volume>, <fpage>134</fpage>-<lpage>146</lpage>.</citation>
</ref>
<ref id="bibr8-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Eid</surname><given-names>M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>A multitrait-multimethod model with minimal assumptions</article-title>. <source>Psychometrika</source>, <volume>65</volume>, <fpage>241</fpage>-<lpage>261</lpage>.</citation>
</ref>
<ref id="bibr9-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Harvey</surname><given-names>R. J.</given-names></name>
<name><surname>Billings</surname><given-names>R. S.</given-names></name>
<name><surname>Nilan</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Confirmatory factor analysis of the job diagnostic survey: Good news and bad news</article-title>. <source>Journal of Applied Psychology</source>, <volume>70</volume>, <fpage>461</fpage>-<lpage>468</lpage>.</citation>
</ref>
<ref id="bibr10-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hinkin</surname><given-names>T. R.</given-names></name>
</person-group> (<year>1995</year>). <article-title>A review of scale development practices in the study of organizations</article-title>. <source>Journal of Management</source>, <volume>21</volume>(<issue>5</issue>), <fpage>967</fpage>-<lpage>988</lpage>.</citation>
</ref>
<ref id="bibr11-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hu</surname><given-names>L.</given-names></name>
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives</article-title>. <source>Structural Equation Modeling</source>, <volume>6</volume>, <fpage>1</fpage>-<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr12-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kenny</surname><given-names>D. A.</given-names></name>
<name><surname>Kashy</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Analysis of the multitrait–multimethod matrix by confirmatory factor analysis</article-title>. <source>Psychological Bulletin</source>, <volume>112</volume>, <fpage>165</fpage>-<lpage>172</lpage>.</citation>
</ref>
<ref id="bibr13-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Leung</surname><given-names>F. K. S.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Behind the high achievement of East Asian students</article-title>. <source>Educational Research and Evaluation</source>, <volume>8</volume>, <fpage>87</fpage>-<lpage>108</lpage>.</citation>
</ref>
<ref id="bibr14-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lord</surname><given-names>F. M.</given-names></name>
<name><surname>Novick</surname><given-names>M. R.</given-names></name>
</person-group> (<year>1968</year>). <source>Statistical theories of mental test scores</source>. <publisher-loc>Reading, MA</publisher-loc>: <publisher-name>Addison-Wesley</publisher-name>.</citation>
</ref>
<ref id="bibr15-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>H. W.</given-names></name>
</person-group> (<year>1986</year>). <article-title>The bias of negatively worded items in rating scales for young children: A cognitive-developmental phenomenon</article-title>. <source>Developmental Psychology</source>, <volume>22</volume>, <fpage>37</fpage>-<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr16-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>H. W.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Confirmatory factor analysis of multitrait-multimethod data: Many problems and a few solutions</article-title>. <source>Applied Psychological Measurement</source>, <volume>13</volume>, <fpage>335</fpage>-<lpage>361</lpage>.</citation>
</ref>
<ref id="bibr17-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Martin</surname><given-names>M. O.</given-names></name>
<name><surname>Preuschoff</surname><given-names>C.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Creating the TIMSS 2007 background indices</article-title>. In <person-group person-group-type="editor">
<name><surname>Olson</surname><given-names>J. F.</given-names></name>
<name><surname>Martin</surname><given-names>M. O.</given-names></name>
<name><surname>Mullis</surname><given-names>I. V. S.</given-names></name>
</person-group> (Eds.), <source>TIMSS 2007 Technical Report</source> (pp. <fpage>281</fpage>-<lpage>338</lpage>). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>TIMSS &amp; PIRLS International Study Center</publisher-name>.</citation>
</ref>
<ref id="bibr18-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McDonald</surname><given-names>R. P.</given-names></name>
</person-group> (<year>1999</year>). <source>Test theory: A unified treatment</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr19-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Millsap</surname><given-names>R. E.</given-names></name>
<name><surname>Kwok</surname><given-names>O.-M.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Evaluating the impact of partial factorial invariance on selection in two populations</article-title>. <source>Psychological Methods</source>, <volume>9</volume>, <fpage>93</fpage>-<lpage>115</lpage>.</citation>
</ref>
<ref id="bibr20-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Motl</surname><given-names>R. W.</given-names></name>
<name><surname>Conroy</surname><given-names>D. E.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Validity and invariance of the Social Physique Anxiety Scale</article-title>. <source>Medicine and Science in Sports and Exercise</source>, <volume>25</volume>, <fpage>1049</fpage>-<lpage>1053</lpage>.</citation>
</ref>
<ref id="bibr21-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mullis</surname><given-names>I. V. S.</given-names></name>
<name><surname>Martin</surname><given-names>M. O.</given-names></name>
<name><surname>Foy</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <source>TIMSS 2007 International Mathematics Report: Findings from IEA’s trends in international mathematics and science study at the fourth and eighth grades</source>. <publisher-loc>Chestnut Hill, MA</publisher-loc>: <publisher-name>TIMSS &amp; PIRLS International Study Center</publisher-name>.</citation>
</ref>
<ref id="bibr22-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Muthén</surname><given-names>L. K.</given-names></name>
<name><surname>Muthén</surname><given-names>B. O.</given-names></name>
</person-group> (<year>1998-2009</year>). <source>Mplus user’s guide</source> (<edition>5th ed.</edition>). <publisher-loc>Los Angeles, CA</publisher-loc>: <publisher-name>Muthén &amp; Muthén</publisher-name>.</citation>
</ref>
<ref id="bibr23-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nunnally</surname><given-names>J. C.</given-names></name>
</person-group> (<year>1978</year>). <source>Psychometric theory</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</citation>
</ref>
<ref id="bibr24-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Podsakoff</surname><given-names>P. M.</given-names></name>
<name><surname>MacKenzie</surname><given-names>S. B.</given-names></name>
<name><surname>Lee</surname><given-names>J. Y.</given-names></name>
<name><surname>Podsakoff</surname><given-names>N. P.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Common method biases in behavioral research: A critical review of the literature and recommended remedies</article-title>. <source>Journal of Applied Psychology</source>, <volume>88</volume>, <fpage>879</fpage>-<lpage>903</lpage>.</citation>
</ref>
<ref id="bibr25-0734282911435461">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>M. S.</given-names></name>
<name><surname>Green</surname><given-names>S. B.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Evaluating between-group differences in latent variable means</article-title>. In <person-group person-group-type="editor">
<name><surname>Hancock</surname><given-names>G. R.</given-names></name>
<name><surname>Mueller</surname><given-names>R. O.</given-names></name>
</person-group> (Eds.), <source>A second course in structural equation modeling</source> (pp. <fpage>119</fpage>-<lpage>169</lpage>). <publisher-loc>Greenwich, CT</publisher-loc>: <publisher-name>Information Age Publishing</publisher-name>.</citation>
</ref>
<ref id="bibr26-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tomás</surname><given-names>J. M.</given-names></name>
<name><surname>Oliver</surname><given-names>A.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Rosenberg’s self-esteem scale: Two factors or method effects</article-title>. <source>Structural Equation Modeling</source>, <volume>6</volume>, <fpage>84</fpage>-<lpage>98</lpage>.</citation>
</ref>
<ref id="bibr27-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Widaman</surname><given-names>K. F.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Hierarchically nested covariance structure models for multitrait-multimethod data</article-title>. <source>Applied Psychological Measurement</source>, <volume>9</volume>(<issue>1</issue>), <fpage>1</fpage>-<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr28-0734282911435461">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yang</surname><given-names>Y.</given-names></name>
<name><surname>Green</surname><given-names>S. B.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Coefficient alpha: A reliability coefficient for the 21st century?</article-title> <source>Journal of Psychoeducational Assessment</source>, <volume>29</volume>(<issue>4</issue>), <fpage>377</fpage>-<lpage>392</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>