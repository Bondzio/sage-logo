<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">LTJ</journal-id>
<journal-id journal-id-type="hwp">spltj</journal-id>
<journal-title>Language Testing</journal-title>
<issn pub-type="ppub">0265-5322</issn>
<issn pub-type="epub">1477-0946</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0265532213480334</article-id>
<article-id pub-id-type="publisher-id">10.1177_0265532213480334</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Defining assessment literacy: Is it different for language testers and non-language testers?</article-title>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Inbar-Lourie</surname><given-names>Ofra</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Jeong</surname><given-names>Heejeong</given-names></name>
</contrib>
<aff id="aff1-0265532213480334">Hanyang University, South Korea</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0265532213480334">Heejeong Jeong, Program Coordinator/Head Researcher, College English Education Committee, Hanyang University, 222 Wangsimni-ro, Seongdong-gu, Seoul 133-791, Korea. Email: <email>jeongheejeong@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>30</volume>
<issue>3</issue>
<issue-title>Special Issue on Language Assessment Literacy</issue-title>
<fpage>345</fpage>
<lpage>362</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Language assessment courses (LACs) are taught by professionals who have majored in the area of language testing (language testers or LTs), but also by others who come from different language-related majors (non-language testers, non-LTs). Different language assessment courses may be developed, depending on who teaches the course and the instructors’ understanding of assessment literacy. This study seeks to investigate the effect instructors bring in shaping the characteristics (i.e., content and structure) of language assessment courses. Findings from an online instructor survey (<italic>N</italic> = 140) and in-depth follow-up phone interviews (<italic>N</italic> = 13) show that there are significant differences in the content of the courses depending on the instructors’ background in six topic areas: test specifications, test theory, basic statistics, classroom assessment, rubric development, and test accommodation. Interview results confirm non-LTs are less confident in teaching technical assessment skills compared to LTs and have a tendency to focus more on classroom assessment issues. The paper ends by stressing the importance of possessing a common understanding of assessment literacy among stakeholders within the testing community, but also among non-LTs who teach language assessment courses so as to maintain course quality and to better meet student teachers’ needs.</p>
</abstract>
<kwd-group>
<kwd>Assessment culture</kwd>
<kwd>assessment literacy</kwd>
<kwd>language assessment courses</kwd>
<kwd>language assessment literacy</kwd>
<kwd>language testers</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Assessment literacy is being promoted to various groups of stakeholders (students, teachers, policy makers, administrators) who are impacted by language tests. There is an increase in the move towards sharing assessment knowledge with the stakeholders influenced by language assessment. It is vital for these stakeholders to implement actions based on appropriate assessment knowledge.</p>
<p>One of the most common and widely known ways to promote assessment literacy is through language assessment courses. These courses, which are usually offered through MA TESOL programs, have been one of the first doorways to promote and execute assessment knowledge for language teachers. In the past, there have been a few studies that looked specifically into these courses and how they are taught, but none of the studies looked precisely at the instructors who come from a non-testing background. It is important to know where these courses stand in terms of teaching language assessment to pre-service/in-service teachers and how they differ in content and quality compared to the courses taught by language testers. Student teachers who take these courses will be making important decisions based on their assessment practices informed by the content of the LACs that they have studied; therefore instructors must guarantee the courses maintain high quality.</p>
<sec id="section1-0265532213480334">
<title>Literature review</title>
<p>The review of literature on assessment literacy is based on expanding the concept of assessment literacy and the structure and format of language assessment courses. The concept of assessment literacy, introduced in general education by scholars like <xref ref-type="bibr" rid="bibr11-0265532213480334">Stiggins (1999a</xref>, <xref ref-type="bibr" rid="bibr13-0265532213480334">2001</xref>) and <xref ref-type="bibr" rid="bibr9-0265532213480334">Popham (2008)</xref>, began to appear in the language testing literature about ten years ago. The notion of educating stakeholders is strongly connected with LACs and a few empirical studies have been conducted to find out how such courses are taught.</p>
<sec id="section2-0265532213480334">
<title>Expanding assessment literacy</title>
<p><xref ref-type="bibr" rid="bibr11-0265532213480334">Stiggins (1999a)</xref> describes assessment literacy as involving teachers’ understanding of <italic>what</italic> assessment methods to use and <italic>when</italic> to use them so teachers can gather reliable information/data about students’ achievements. Assessment literacy also incorporates teachers’ ability to communicate assessment results effectively to students, parents, and other educational professionals (<xref ref-type="bibr" rid="bibr11-0265532213480334">Stiggins, 1999a</xref>). <xref ref-type="bibr" rid="bibr6-0265532213480334">Inbar-Lourie (2008</xref>, p. 389) writes of assessment literacy as ‘having the capacity to ask and answer critical questions about the purpose for assessment, about the fitness of the tool being used, about testing conditions, and about what is going to happen on the basis of the results.’</p>
<p>For language teachers, being assessment literate means possessing assessment literacy skills combined with language-specific competencies (<xref ref-type="bibr" rid="bibr6-0265532213480334">Inbar-Lourie, 2008</xref>). In order for teachers to be assessment literate in their classroom practices, it is important that they are provided with the appropriate teacher training in assessment. Recently, with the increased influence of testing, assessment literacy is being perceived as knowledge not only required for teachers but also for other stakeholders (e.g. policy makers, examination boards, parents, and the general public) within the education testing culture (<xref ref-type="bibr" rid="bibr15-0265532213480334">Taylor, 2009</xref>). Move citation to end of sentence. Despite calls for expanding the knowledge of assessment, there has been hardly any discussion about the assessment literacy of non-LTs who teach language assessment courses. It is stressed that teachers should be assessment literate to correctly implement classroom assessment, to explain the results of standardized tests to stakeholders, and to follow the standards of assessment rules. But, is there a required level of assessment literacy to teach an LAC? For example, do the instructors who teach language assessment courses have a testing background? What kind of assessment knowledge do they possess? How do they teach the course and does it meet the expectations and needs of the student teachers? Former studies of LACs focused only on the overall instructor group rather than on differentiating LTs and non-LTs though, as <xref ref-type="bibr" rid="bibr15-0265532213480334">Taylor (2009)</xref> has noted, many non-language-testing individuals work within the testing area.</p>
<p>According to a syllabi review conducted by <xref ref-type="bibr" rid="bibr7-0265532213480334">Jeong (2009)</xref>, 15 out of the 30 instructors who taught introductory language assessment courses came from a non-testing background. The purpose of this syllabi review (<italic>N</italic> = 30) was to find out the topics covered in language assessment courses and the external (department, position in the program, and geographic factors) and internal (instructor, target student population) factors that influence the content and structure of the course. It was found that the non-LTs’ diverse backgrounds in foreign languages (e.g., Spanish, French, German, etc.), special education, bilingual education, quantitative research methods, and rhetoric) translated into different course structures. Courses taught by LTs offered a variety of topics, such as computer adaptive testing, ethics in testing, statistics, and performance assessment. Courses taught by non-LTs focused more on delivering the basic theory of testing and emphasized classroom assessment. Statistics or measurement was taught by 13 instructors, 10 of whom had testing backgrounds. Only three non-language tester instructors covered statistics or measurement in their courses. Findings from this syllabi review identified the existence of two different instructor groups: language testers and non-language testers.</p>
<p>The findings from the syllabi review showed that, just as LTs can teach courses out of their disciplinary areas, such as material development and teaching methodology, non-LTs may end up teaching language assessment courses (<xref ref-type="bibr" rid="bibr7-0265532213480334">Jeong, 2009</xref>). Concerns naturally arise when instructors teach a subject area they have limited knowledge or different understandings of. It is particularly a concern for language assessment courses since assessment often involves very high stakes and raises quality concerns of how non-LTs teach the courses compared to LTs, as essential topics that should be covered for a language assessment course can vary depending on the instructor’s background.</p>
</sec>
<sec id="section3-0265532213480334">
<title>Studies in language assessment courses</title>
<p>The first study on language assessment courses was done by <xref ref-type="bibr" rid="bibr1-0265532213480334">Bailey and Brown (1996</xref>, and repeated in 2008). The purpose of the study was to ‘investigate the instructors’ backgrounds, the topics they covered, and their students’ apparent attitudes toward those courses’ (p. 351). <xref ref-type="bibr" rid="bibr2-0265532213480334">Brown and Bailey’s (2008)</xref> study was a starting point in the research of LACs. It gave information on how the courses were taught and which topics were covered and to what degree. Despite the insights gained from the study, it did not investigate is the issue of non-LTs who teach LACs. Unlike Brown and Bailey’s survey, which reported that almost all of the respondents had experience in language testing, 50% (15 out of 30) of the instructors from <xref ref-type="bibr" rid="bibr7-0265532213480334">Jeong’s (2009)</xref> syllabi review did not have experience related to the field. This difference may be due to the characteristics of the mailing list Bailey and Brown used for their study, the LTRC (Language Testing Research Colloquium) mailing list, as LTRC members are likely to come from a language-testing background.</p>
<p>Few studies about language assessment courses have been done by instructors who taught assessment courses. An important study by <xref ref-type="bibr" rid="bibr8-0265532213480334">Kleinsasser (2005)</xref> covers challenging aspects of language assessment courses from the instructor’s perspective. Kleinsasser states that one of the major difficulties in teaching a language assessment course is connecting theory with practice: ‘The bridge between the (theoretical) class discussions and the final (practical) test/assessment product, however, was not well constructed. Challenges in getting the students to move from theoretical issues to practical ones often surfaced’ (p. 82). Kleinsasser reports that students felt the time spent defining constructs, developing and piloting assessment materials, and rewriting and rethinking the various assessment tasks and items was quite burdensome, since many felt this is not the typical process they go through in a real classroom situation. However, the group work process encouraged them to include various stakeholders’ perspectives in test development and widen their views of testing.</p>
<p>In general a review of the literature points at the paucity of research studies on LAC’s and there is no currently available research on the instructor’s language testing background. This article therefore reports on a study that explores how LACs are constructed and taught in various countries depending on the course instructor, using a mixed methods approach.</p>
<p>To explore these issues, the following research questions were posed, juxtaposing language testers versus non-language testers as course instructors:</p>
<list id="list1-0265532213480334" list-type="order">
<list-item><p>Language testers vs. non-language testers: How are their language assessment courses similar?</p></list-item>
<list-item><p>Language testers vs. non-language testers: How are their language assessment courses different?</p></list-item>
</list>
</sec>
<sec id="section4-0265532213480334">
<title>The mixed methods approach</title>
<p>A mixed methods approach is used in this study for purposes of development and complementarity. The purpose of using a blend of methods is to elaborate, enhance, illustrate, and clarify the results from one method (quantitative) with the results from another method (qualitative) to increase meaningfulness (<xref ref-type="bibr" rid="bibr4-0265532213480334">Greene, 2007</xref>). In a complementarity study, two methods look into overlapping areas from different facets of a phenomenon. By collecting both qualitative and quantitative data, a more complete and contextual explanation for the research questions could be derived.</p>
<p>The type of mixed methods design employed is an integrative design (<xref ref-type="bibr" rid="bibr4-0265532213480334">Greene, 2007</xref>) with the study taking the form of an iterative design where all phases interact with each other throughout the process. Although the implementation of each phase was done separately, the analysis was closely linked to the next phase of the study.</p>
</sec>
</sec>
<sec id="section5-0265532213480334" sec-type="methods">
<title>Method</title>
<p>The participants for the study consisted of two instructor groups: language testers (LTs) and non-language testers (non-LTs). Language testers are individuals or professionals whose primary research interest is in areas of language testing. Non-language testers are defined as those whose primary interest is in other areas of language teaching (e.g. second language acquisition), but who have had experience in language-assessment-related activities (e.g., developed standardized tests, worked with a testing agency, etc.).</p>
<p>A total of 140 instructors completed the survey. The survey data was entered in SPSS v. 17 for Windows. First, it was examined using descriptive statistics to organize and summarize the data. Next, to investigate differences between groups (LTs vs. non-LTs) regarding the time spent on teaching certain topics, t-tests were conducted. More detailed demographic information regarding the instructors will be presented in the findings section.</p>
<p>The participants for the interviews (<italic>N</italic> = 13) were selected through a combination of convenient sampling and purposeful sampling. Key semi-structured interview questions are presented in <xref ref-type="app" rid="app2-0265532213480334">Appendix B</xref>. Open coding was used for the initial coding of the interview data. Transcripts were unitized and concepts were highlighted and labeled. Subsequent coding took place by comparing the current transcript with the survey data. Additional topics emerged as the coding proceeded and eight course topics that received the most attention were identified: test theory, classroom assessment, performance assessment, test specifications, rubric development, statistics, ethics, and test accommodation.</p>
<sec id="section6-0265532213480334">
<title>Data collection process and analysis</title>
<p>The online survey was first launched on July 2, 2010 and was closed August 20, 2010. The survey questions relevant to this study are presented in <xref ref-type="app" rid="app1-0265532213480334">Appendix A</xref>. The survey participants were contacted via professional ESL/EFL organizations and language testing organizations (e.g., LTEST, MwALT, ECOLT, SCALAR, TESOL, TESL-L, AAAL, CALICO, NYTESOL, CATESOL) and through personal emails. Instructors and student teachers took the survey at a time and location convenient to them. The website that provided the online survey was ‘Surveygizmo’ (<ext-link ext-link-type="uri" xlink:href="http://www.surveygizmo.com/s/282990/language-assessment-courses">www.surveygizmo.com/s/282990/language-assessment-courses</ext-link>) and consisted of a total of 29 items. Completion of the survey lasted approximately 15~20 minutes. The survey consisted of demographic information and questions that asked how much class time was devoted on teaching certain topics and which topics instructors found important for the student teachers.</p>
</sec>
</sec>
<sec id="section7-0265532213480334">
<title>Findings</title>
<p>The findings of this study will be presented in two main sections: people and courses.</p>
<sec id="section8-0265532213480334">
<title>People</title>
<p>A total of 140 self-identified LAC instructors participated in the survey (see <xref ref-type="fig" rid="fig1-0265532213480334">Figure 1</xref>). Of the instructors, 47% (<italic>n</italic> = 66) said that language testing was their primary research area, 52% (<italic>n</italic> = 73) said it was not, and one person did not provide this information. The non-LTs’ most common assessment-related experience was working with classroom teachers on testing (<italic>n</italic> = 77), having experience in developing standardized language tests (<italic>n</italic> = 47), and working as a rater (<italic>n</italic> = 46). In terms of their final degrees, there was little difference between the two groups. For both groups, applied linguistics (LT = 32, non-LT = 21) was the area most respondents reported having earned their final degrees in. The only notable difference was from the education and foreign language majors. Nine out of 10 education majors identified themselves as non-language testers, and all the foreign language majors (<italic>n</italic> = 3) were non-language testers. Education majors included education leadership, international development in education, and literacy education. Therefore, instructors’ majors cannot be an identifier in separating LTs from non-LTs.</p>
<fig id="fig1-0265532213480334" position="float">
<label>Figure 1.</label>
<caption>
<p>Survey instructors’ demographic overview.</p>
</caption>
<graphic xlink:href="10.1177_0265532213480334-fig1.tif"/>
</fig>
<p>The main target audience for the courses for both groups was student teachers (64.2%, <italic>N</italic> = 85). Some courses targeted regular undergraduates (20.44%, <italic>n</italic> = 30) and graduate students who were not student teachers (13%, <italic>n</italic> = 18). The majority (68.4%, <italic>n</italic> = 50) of the target audience of non-LTs was student teachers, a percentage higher for LTs (53.8%, <italic>n</italic> = 35). This shows that roughly two-thirds of the student teachers took language assessment courses taught by a non-LT instructor.</p>
<p>Regarding teaching experience, 70% (<italic>n</italic> = 93) of all instructor were veterans in language teaching, with more than 10 years’ experience. Looking more closely at the instructors’ teaching experience, most (80.3%, <italic>n</italic> = 106) answered that the grade level they taught was college, and 19.7% (<italic>n</italic> = 26) taught K–12. More specifically, 13% (<italic>n</italic> = 20) of the instructors had experience teaching at the secondary grade level, and only 6% (<italic>n</italic> = 6) had taught elementary school. Non-LTs had more K–12 teaching experience compared to LTs. While 24.6% (<italic>n</italic> = 18) of the non-LTs had taught K–12, only 12.3% (<italic>n</italic> = 8) of LTs had experience teaching K–12.</p>
</sec>
<sec id="section9-0265532213480334">
<title>Language assessment courses: Course structure</title>
<p>The results of the survey and interview show that the structure and organization of the courses were similar for the two groups. Both LTs and non-LTs began with an overview of the theory of the course and ended with an activity that requires student teachers to use the content learned earlier from the course. The end product of the course differed but was in similar forms. Some instructors asked STs to develop a classroom test either independently or collaboratively; others were required to pilot and report the results of the test. The differences in how many activities were done relied more on the individual instructor’s characteristics than on his or her background. Thus, structure-wise (content and format), the courses had similar features regardless of being taught by LTs or non-LTs.</p>
</sec>
<sec id="section10-0265532213480334">
<title>Topic time coverage: LTs vs. non-LTs</title>
<p>To identify the similarities and differences regarding what topics were covered in LACs and to what extent, instructors were asked to report how much time they spent on 14 commonly covered topics on a Likert-scale item (see <xref ref-type="fig" rid="fig2-0265532213480334">Figure 2</xref>). Independent t-tests were used to identify if there were significant differences between the language tester group and the non-language tester group in this respect.</p>
<fig id="fig2-0265532213480334" position="float">
<label>Figure 2.</label>
<caption>
<p>Topic time coverage: LTs vs. non-LTs.</p>
<p>Note:  The response scale was 1 = hardly any time, 2 = a little time, 3 = some time, 4 = extensive time.</p>
</caption>
<graphic xlink:href="10.1177_0265532213480334-fig2.tif"/>
</fig>
<p>The top five areas in which instructors spent the most time teaching were test theory, classroom assessment, alternative performance assessment, test specifications, and rubric development (<xref ref-type="fig" rid="fig2-0265532213480334">Figure 2</xref>; specific numbers in <xref ref-type="table" rid="table1-0265532213480334">Table 1</xref>). Topics that received similar or same time coverage by both LTs and non-LTs were test critique, history of language testing and advanced statistics. There were six areas of significant differences between the two groups with the greatest area of disagreement being test accommodation. Language testers ranked this category towards the bottom (13th out of 14 categories, <italic>M</italic> = 1.64), while non-language-testers ranked it ninth (<italic>M</italic> = 2.39) out of the categories. Thus, compared to non-LTs, LTs spend little time covering test accommodation.</p>
<table-wrap id="table1-0265532213480334" position="float">
<label>Table 1.</label>
<caption>
<p>Different topic time coverage: LT vs. non-LT.</p>
</caption>
<graphic alternate-form-of="table1-0265532213480334" xlink:href="10.1177_0265532213480334-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left" colspan="2">Language testers<hr/></th>
<th align="left" colspan="2">Non-language testers<hr/></th>
<th align="left" colspan="2">T-test<hr/></th>
</tr>
<tr>
<th/>
<th align="left"><italic>N</italic></th>
<th align="left"><italic>M</italic></th>
<th align="left"><italic>N</italic></th>
<th align="left"><italic>M</italic></th>
<th align="left"><italic>t</italic></th>
<th align="left"> <italic>p</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Test specifications</td>
<td>61</td>
<td>3.26</td>
<td>68</td>
<td>2.93</td>
<td>2.364</td>
<td>.020*</td>
</tr>
<tr>
<td>Test theory</td>
<td>63</td>
<td>3.48</td>
<td>70</td>
<td>3.19</td>
<td>2.251</td>
<td>.022*</td>
</tr>
<tr>
<td>Basic statistics</td>
<td>58</td>
<td>2.62</td>
<td>66</td>
<td>2.23</td>
<td>2.092</td>
<td>.023*</td>
</tr>
<tr>
<td>Classroom assessment</td>
<td>62</td>
<td>3.15</td>
<td>69</td>
<td>3.46</td>
<td>−2.3000</td>
<td>.024*</td>
</tr>
<tr>
<td>Rubric development</td>
<td>61</td>
<td>2.74</td>
<td>66</td>
<td>3.09</td>
<td>−2.278</td>
<td>.020*</td>
</tr>
<tr>
<td>Test accommodation</td>
<td>53</td>
<td>1.64</td>
<td>66</td>
<td>2.39</td>
<td>−4.208</td>
<td>.000*</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Out of the 14 topics, instructors spent the most time teaching test theory. For specific groups, LTs ranked this first (<italic>M</italic> = 3.48), and non-LTs ranked this third (<italic>M</italic> = 3.19). Both groups of instructors thought it was important to teach test theory, but results show that language testers value its importance more than non-LTs. Another important topic that was covered in language assessment courses was classroom assessment. From the instructor survey, classroom assessment ranked the second most covered topic (<italic>M</italic> = 3.31) in language assessment courses. Non-LTs responded that they spend the most time (<italic>M</italic> = 3.46) teaching classroom assessment above all other topics, and LTs ranked this third (<italic>M</italic> = 3.15). For test specifications, there was a significant difference (<italic>p</italic> = .020) between LTs and non-LTs. The overall ranking of this topic was fourth (<italic>M</italic> = 3.09), but for LTs, this was the second topic on which they spent the most time (<italic>M</italic> = 3.26) teaching. However, for non-LTs, it ranked sixth out of the 14 topics, with a mean of 2.93, which was significantly lower than the mean for the LTs.</p>
</sec>
<sec id="section11-0265532213480334">
<title>Important topics for classroom teachers: LTs vs. non-LTs</title>
<p>In a second set of Likert-scale items, instructors were asked to identify how important the course topics were for classroom teachers (<xref ref-type="app" rid="app2-0265532213480334">Appendix B</xref>). For all the instructors (<italic>N</italic> = 140) the five most important topics for classroom teachers are as follows: classroom assessment (<italic>m</italic> = 3.76), alternative assessment (<italic>M</italic> = 3.51), test specifications (<italic>M</italic> = 3.37), test theory (<italic>M</italic> = 3.36), and rubric development (<italic>M</italic> = 3.35).</p>
<p>Significant differences (<italic>p &lt;</italic> 0.034) between LTs and non-LTs were found in five areas: test specifications (<italic>p &lt;</italic> .012), test-taking skills and strategies (<italic>p &lt;</italic> .042), alternative assessment (<italic>p &lt;</italic> .020), rater training (<italic>p &lt;</italic> .032), and test accommodation (<italic>p &lt;</italic> .010). Out of these five, two topics (test specifications, alternative assessment) were placed among the five most important topics for classroom teachers and topics that got the most coverage in teaching. Similar to earlier results, test specifications received a significantly higher mean (<italic>M</italic> = 3.54) from language testers compared to non-LTs (<italic>M</italic> = 3.23). Language testers ranked this the second most important topic for classroom teachers while non-LTs ranked it fifth. For alternative assessment, the results were the exact opposite. Non-LTs pointed this as the second most important topic (<italic>M</italic> = 3.63), but LTs placed it as fourth (<italic>M</italic> = 3.37).</p>
</sec>
<sec id="section12-0265532213480334">
<title>Course materials: Language assessment course textbook usage</title>
<p>To obtain more insight on the courses and especially on course materials used in language assessment courses a follow-up interview was conducted with 13 instructors from the original sample (six language testers and seven non-language testers). The first topic of inquiry was the textbooks used as it was deemed that content analysis of the types of books used in language assessment courses can help in predicting the topics taught in the courses and add information on the characterizing features of the two instructor groups (LTs and non-LTs). However, the interview findings reveal that currently available textbooks regarding language assessment courses were thought to be difficult and not very useful to the student teachers or the non-LT instructors. For example Smith, who is a non-language tester and head of a TESOL MA program in the UK, in particular commented that every time she hears that a new textbook has been published, she gets very excited, but once she goes over the content, she sighs and quickly closes the book. She felt the language assessment course textbooks were targeted for large-scale assessment usage, so the content covered in these books was not directly related to language teachers’ needs.</p>
<p>Anderson, who is a non-LT, the program coordinator of a university language program, commented, ‘I’d like to see [textbooks] more in classroom assessment. Ultimately, that is for the population I work with; that’s what they’re going to need.’ She did understand the need for teachers to be aware of the issues surrounding standardized assessment but felt a lot of the content covered in standardized assessment is not applicable to the classroom context. Yet, one of the interviewees, a veteran language tester who has written several books in this field, commented that there is little difference in theory regarding large-scale or small-scale assessment. He states, ‘Validity is validity, and reliability is reliability.’ Another opinion from a non-LT instructor was that textbooks seemed to be appropriate for PhD students majoring in language testing rather than MA, undergraduate pre-service or in-service teachers.</p>
<p>The instructors reported from their teaching experience that textbooks written by language testers covered more test-oriented topics such as test specifications, ethics, and a lot more on standardized assessment compared to classroom-assessment-oriented books. However, as was stated before, these books did not seem to be used as much by non-LTs in teaching their courses. Although Anderson appreciated new books in the field, she commented that they could be over the top for her student teachers. ‘I refer to it [a textbook] a lot; I read it out loud, and students borrow it and use it, [but it is] too dense and not practical enough [for my student teachers]. I do not think it would be a useful resource [for student teachers] to have them on their shelf. It’s a great [resource] for me, but not the students.’ Anderson liked the top-selling language assessment textbook on the market, not necessarily because it was the best in terms of the content, but because it was reader friendly and accessible to non-native speakers. As Smith mentioned in regard to the same textbook, ‘This textbook sells well, but not because anyone likes it; it’s the least worst one out there.’</p>
<p>To sum up this point, from the interviews it is apparent that there was a different level of satisfaction with regard to textbooks among the instructors. It appears that non-LTs were less satisfied with the textbooks than the LTs. This could be because the majority of language assessment textbooks are written by language testers who focus more on theoretical aspects.</p>
<p>In summary, the overall structure of the course was similar for both LTs and non-LTs, but the areas LTs focused on were more technical (e.g., test specifications, test theory, statistics) compared to non-LTs who spent more time on teaching classroom related topics (e.g., alternative assessment, classroom assessment). With regard to language assessment textbooks, similar to their preference in teaching, non-LTs thought textbooks that are more focused on day-to-day classroom activities were more helpful.</p>
</sec>
</sec>
<sec id="section13-0265532213480334" sec-type="discussion">
<title>Discussion</title>
<p>The findings of this study show that language assessment courses may differ depending on the instructors’ background in the area of language testing. The following discussion considers possible reasons for this phenomenon and their implications.</p>
<sec id="section14-0265532213480334">
<title>Same name, different course: Different definition of assessment literacy?</title>
<p>As stated earlier in this paper, previous studies (<xref ref-type="bibr" rid="bibr12-0265532213480334">Stiggins, 1999b</xref>, <xref ref-type="bibr" rid="bibr14-0265532213480334">2002</xref>) in assessment literacy have focused on and attempted to define the components of assessment literacy for teachers in general and language assessment literacy for language teachers. The findings of this study, however, raise questions as to whether instructors (both LTs and non-LTs) of language assessment courses share a common definition of language assessment literacy. When teaching a course, each instructor will bring his or her own uniqueness to the courses they teach. Even within the language testers’ group, the course taught by instructor A will be different from instructor B. However, more diversity arises when the training background of the instructors shows a weak connection to the courses they teach.</p>
<p>The research findings show that LTs spend significantly more time on test theory while non-LTs focus more on classroom assessment and test accommodations. This implies that the outcomes of the course will be different depending on the instructor, even though the course is offered under similar names (e.g., language testing, language assessment). For example, if a student teacher took a course from a LT, he or she would have a better chance of learning more about test specifications and statistics compared to student teachers who took the course from a non-LT.</p>
<p>According to the survey, half of the instructors come from a non-testing background. As there seem to be more language assessment courses taught by non-LTs compared to LTs, it is important that both instructor groups share a common knowledge of what should be covered in language assessment courses in general. Since many of the non-LTs come with little training or experience in language testing, the language testing community should offer a set of objectives and guidelines or even training to the non-LTs. LTs should also check if the course content is appropriate for the target student audience. Non-LTs are often suddenly asked to teach the course with little preparation on a needs basis (e.g., Olson). Others (e.g., Smith, Ryan in this study) self-developed the course since the curriculum did not have an assessment course and were asked to teach it because there was nobody else to do so. Past experience or education in language testing was not a crucial factor in making these decisions, and none of the non-LTs interviewed received additional training after being selected to teach the course.</p>
<p>The six language testers interviewed understood the reality that many courses were taught by non-language testers. All of them said that it would be preferable if assessment courses were taught by those who majored in the field, but due to the lack of personnel it was acceptable for a non-LT to teach the course. From the follow-up interview, Goldberg, a language tester, commented, ‘Something is better than nothing. They [non-LTs] will represent a different take on the knowledge that I would have. The kind of background they [instructors] have really makes a difference [in teaching the course], [but] somebody has to do it. There is a demand. There is a need [for language assessment courses]. It would be better than nothing.’ Goldberg thinks it is better for non-LTs to teach an assessment course than not to have a course at all, but she expects that the content of the course will be more related to classroom issues, which differs from her course.</p>
<p>As shown in the findings, there are similarities and differences in the content and structure of the courses between LTs and non-LTs. The reasons lie on notions as to what constitutes assessment literacy. <xref ref-type="bibr" rid="bibr15-0265532213480334">Taylor (2009</xref>, p. 27) writes, ‘Training for assessment literacy entails an appropriate balance of technical know-how, practical skills, theoretical knowledge, and understanding of principles.’ In addition, Taylor states, (<xref ref-type="bibr" rid="bibr15-0265532213480334">2009</xref>, p. 27) ‘the level of literacy to be acquired may vary according to the context.’ However, in order to maintain course relevance, for instructors who teach language assessment courses, a common understanding of assessment literacy is needed. Then how should this be acquired and what can the language testing community do to promote sharing assessment literacy with non-LTs?</p>
</sec>
<sec id="section15-0265532213480334">
<title>Characteristics of the language assessment community</title>
<p>Prior to going into detail about ways to increase collaboration between LTs and non-LTs, it is important to think of the unique characteristics of the language assessment community. Traditionally, the testing community has been portrayed as being ‘highly technical’ (<xref ref-type="bibr" rid="bibr15-0265532213480334">Taylor, 2009</xref>, p. 21), which makes it difficult for outsiders to approach the group. This was a shared notion among the non-LTs who were interviewed in this study as well. Even though the non-LTs felt the need to expand their knowledge in the area, they expressed difficulty because, first, they did not know how to reach relevant sources, and second, they did not feel comfortable asking for guidance from the language testing community. As noted by a non-LT, Smith, attempting to gain technical knowledge, especially statistical knowledge, increased the feelings of eliteness of the LT group and the inferiority of the non-LTs. The non-LTs who expressed uneasiness and vulnerability in teaching technical topics also felt pressured by the high walls of the language testing community. This concern is aligned with <xref ref-type="bibr" rid="bibr3-0265532213480334">Davies’ (2008)</xref> and <xref ref-type="bibr" rid="bibr10-0265532213480334">Spolsky’s (2008)</xref> work on the risks of isolation of the language testing community due to its distinct nature. Although testing professionalism makes the community unique and separates it from other applied linguists, it also acts as a dividing wall. If the goal of LT is to build a ‘broader and inclusive community of good practice’ (<xref ref-type="bibr" rid="bibr15-0265532213480334">Taylor, 2009</xref>, p. 29), one of the first things that should be done is to train non-LTs to become proficient in language assessment.</p>
<p>Attempts have been made over the years and more so recently to hold workshops to promote language assessment literacy at conferences such as the Language Testing Research Colloquium (LTRC) and EALTA (European Association for Language Testing and Assessment) (<xref ref-type="bibr" rid="bibr15-0265532213480334">Taylor, 2009</xref>). However, these workshops were not well known to non-LTs. Only one of the non-LTs interviewed had attended LTRC. In addition to putting effort into widely advertising these workshops, LTs could link up with non-LTs by attending the conferences that the non-LTs are affiliated with. For example, increased workshops in TESOL or other regional conferences can be a stepping stone to enhance the literacy of non-LT instructors.</p>
<p>One practical way to do this is by offering a set of guidelines of what should be covered in language assessment courses. An array of topics that the community agrees on should be covered in an introductory course and an advanced course could be the first step towards training LT professionals. The focus of the topics can vary depending on the target audience, but there are core topics and areas that should be focused on more for particular target groups (e.g., K–12 vs. adult).</p>
</sec>
<sec id="section16-0265532213480334">
<title>Identity of a language tester</title>
<p>Unlike other stakeholders (i.e., policy makers, examination board, parents, and teachers) in the testing culture, non-LT instructors may be perceived differently depending on who the perceiver is. Within the language testing community, they may be perceived as non-language testers; however, outside this community, the non-LT instructors can be identified as language testing specialists. This is similar to the identity issue of native speaker vs. non-native English teachers stated by <xref ref-type="bibr" rid="bibr5-0265532213480334">Inbar-Lourie (2005)</xref>. A non-native speaker who identifies himself or herself as a non-native speaker can be perceived to be a native or near-native speaker if the person is positioned in a context where he or she has the most knowledge of the content. The same reasoning applies for language testers; there is no clear criterion as to who a language tester is and who is not. Then what is the signifier for a language tester? What qualities or features make them LTs? For the sake of convenience in this study I gave a simple definition of who is and who is not a language tester; however, the identity issue is more complex than I expected. Even within the group of language testers, the group can be divided into sub-groups. Similar to the native/non-native EFL teacher debate (<xref ref-type="bibr" rid="bibr5-0265532213480334">Inbar-Lourie, 2005</xref>), there are self- versus socially perceived language testers and non-language testers.</p>
<p>For language testers, the identity can begin with the meanings attributed by others. For example, expectations society has from language testers (e.g. in order to qualify as an LT, one has to have taken certain courses, should know the basics of the field and beyond). Similar to lack of clarity in the definition of what distinguishes a native speaker from a non-native speaker, the debate of who is a language tester is and what enables one to be one is ongoing.</p>
</sec>
</sec>
<sec id="section17-0265532213480334" sec-type="conclusions">
<title>Conclusion</title>
<p>This study is not only about a language assessment course, but als about the language testing community. For the future of language testing, I suggest that it is time for language testers to move towards other applied linguists. Language testers gained power in the community along with the power of language tests, but this power also brought fear to the testers of being isolated from other applied linguists as the area of expertise is too technical and specialized (<xref ref-type="bibr" rid="bibr10-0265532213480334">Spolsky, 2008</xref>). It is important for LTs to preserve their specialty, but also it is essential to share the knowledge and make it accessible to those who are part of the language assessment culture. It is the role of the LT community to make the field approachable to others.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0265532213480334">
<title>Appendix A</title>
<p><bold>Instructor survey</bold></p>
<list id="list2-0265532213480334" list-type="simple">
<list-item><p>1. What is your gender?</p></list-item>
<list-item><p>( ) Female</p></list-item>
<list-item><p>( ) Male</p></list-item>
<list-item><p>2. How many years have passed since you have received your final degree (e.g. PhD, EdD or other)?</p></list-item>
<list-item><p>( ) Less than 5 years</p></list-item>
<list-item><p>( ) 6~10 years</p></list-item>
<list-item><p>( ) 11~20 years</p></list-item>
<list-item><p>( ) more than 20 years</p></list-item>
<list-item><p>3. Which area did you receive your final degree in?</p></list-item>
<list-item><p>( ) Applied Linguistics</p></list-item>
<list-item><p>( ) Linguistics</p></list-item>
<list-item><p>( ) Curriculum and Instruction</p></list-item>
<list-item><p>( ) Educational Psychology</p></list-item>
<list-item><p>( ) TESOL</p></list-item>
<list-item><p>( ) Other ___________________</p></list-item>
<list-item><p>4. Is Language Testing your primary research area?</p></list-item>
<list-item><p>( ) Yes</p></list-item>
<list-item><p>( ) No</p></list-item>
<list-item><p>5. If Language Testing is not your primary research area, what kind of assessment related activities have you participated in? (Check all that apply.)</p></list-item>
<list-item><p>( ) Developed standardized tests</p></list-item>
<list-item><p>( ) Worked as a rater</p></list-item>
<list-item><p>( ) Worked with classroom teachers on testing</p></list-item>
<list-item><p>( ) Other</p></list-item>
<list-item><p>6. If Language Testing is not your main research area, what is your primary research area?</p></list-item>
<list-item><p>7. What is the title of the language assessment course you teach?</p></list-item>
<list-item><p>8. How many times have you taught this introductory language assessment course?</p></list-item>
<list-item><p>( ) less than 3 ( ) 4~8 ( ) 8~12 ( ) more than 12 times</p></list-item>
<list-item><p>9. Who is the main target audience (over 50%) of your course?</p></list-item>
<list-item><p>( ) Regular undergraduates</p></list-item>
<list-item><p>( ) Pre-service undergraduates</p></list-item>
<list-item><p>( ) Pre-service MA</p></list-item>
<list-item><p>( ) In-service MA</p></list-item>
<list-item><p>( ) Regular MA students (non-teachers)</p></list-item>
<list-item><p>( ) PhD students</p></list-item>
<list-item><p>( ) Other __________________</p></list-item>
<list-item><p>10. Of the following topics covered in the language assessment course, how much time did you spend teaching each topic?</p></list-item>
</list>
<table-wrap id="table2-0265532213480334" position="float">
<graphic alternate-form-of="table2-0265532213480334" xlink:href="10.1177_0265532213480334-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Extensive time</th>
<th align="left">Some time</th>
<th align="left">A little time</th>
<th align="left">Hardly any time</th>
<th align="left">N/A</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Test specifications/Item writing</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>2. Test administration</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>3. Test scoring (e.g. transform numeric scores into letter grades)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>4. Standardized testing (interpreting, analyzing)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>5. Test critiquing</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>6. Test-taking skills or strategies</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>7. Test theory (e.g. validity, reliability)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>8. Basic statistics (e.g. mean, percentile, bell curve)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>9. Advanced statistics (e.g. Item Response Theory)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>10. Test ethics</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>11. History of language testing</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>12. Classroom assessment (developing)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>13. Alternative/performance assessment</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>14. Rubric development (analytic and holistic)</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>15. Rater training</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>16. Test accommodation</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>17. Other, please specify _________</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<list id="list3-0265532213480334" list-type="simple">
<list-item><p>11. Of the topics covered in the above question, which topic do you think would be MOST helpful to classroom teachers?</p></list-item>
<list-item><p>12. Of the topics covered in the above question, which topic do you have the MOST difficulty in teaching?</p></list-item>
<list-item><p>13. How important do you think the following topics are to pre-service and in-service teachers?</p></list-item>
</list>
<table-wrap id="table3-0265532213480334" position="float">
<graphic alternate-form-of="table3-0265532213480334" xlink:href="10.1177_0265532213480334-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left">Extremely important</th>
<th align="left">Very important</th>
<th align="left">A little important</th>
<th align="left">Not important</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Test specifications/Item writing</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>2. Test administration</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>3. Test scoring (e.g. transform numeric scores into letter grades)</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>4. Standardized testing (interpreting, analyzing)</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>5. Test critiquing</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>6. Test-taking skills or strategies</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>7. Test theory (e.g. validity, reliability)</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>8. Basic statistics (e.g. mean, percentile, bell curve)</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>9. Advanced statistics (e.g. Item Response Theory)</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>10. Test ethics</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>11. History of language testing</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>12. Classroom assessment (developing )</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>13. Alternative/performance assessment</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>14. Rubric development (analytic and holistic)</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>15. Rater training</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>16. Test accommodation</td>
<td/>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<list id="list4-0265532213480334" list-type="simple">
<list-item><p>14. Do you agree or disagree with the following statement?</p></list-item>
<list-item><p>My language assessment course met the needs of my pre-service/in-service teachers.</p></list-item>
<list-item><p>( ) Strongly disagree</p></list-item>
<list-item><p>( ) Disagree</p></list-item>
<list-item><p>( ) Agree</p></list-item>
<list-item><p>( ) Strongly agree</p></list-item>
<list-item><p>15. What is the MOST important factor to make a language assessment course effective for classroom teachers?</p></list-item>
<list-item><p>( ) practicality</p></list-item>
<list-item><p>( ) theoretical knowledge</p></list-item>
<list-item><p>( ) balance between theory and practice</p></list-item>
<list-item><p>( ) Other, please specify ______________________________________________</p></list-item>
<list-item><p>16. Overall, do you think the course was helpful for your pre-service/in-service teachers?</p></list-item>
<list-item><p>( ) not at all</p></list-item>
<list-item><p>( ) a little</p></list-item>
<list-item><p>( ) somewhat helpful</p></list-item>
<list-item><p>( ) very helpful</p></list-item>
<list-item><p>17. In general, do you think your pre-service/in-service teachers find your course (check all that apply):</p></list-item>
<list-item><p>( ) interesting</p></list-item>
<list-item><p>( ) too theoretical</p></list-item>
<list-item><p>( ) easy</p></list-item>
<list-item><p>( ) useful</p></list-item>
<list-item><p>( ) too practical</p></list-item>
<list-item><p>( ) difficult</p></list-item>
<list-item><p>( ) a nice balance between theory and practice</p></list-item>
<list-item><p>18. If you were to teach this course again, or teach an advanced course in language assessment, what topics would you like to cover?</p></list-item>
<list-item><p>19. Do you have any other comments or questions you have regarding language assessment courses?</p></list-item>
</list>
</app>
<app id="app2-0265532213480334">
<title>Appendix B</title>
<p><bold>Instructor interview questions</bold></p>
<sec id="section18-0265532213480334">
<title>Language assessment course</title>
<list id="list5-0265532213480334" list-type="order">
<list-item><p>[Course Goal] What is your course goal? What do you see as the primary focus of the course you teach?</p></list-item>
<list-item><p>[Core Topics] Of the topics covered in a language assessment course, which topic do you think will be most helpful for classroom teachers?</p></list-item>
<list-item><p>[Unique Features] How is this course different from other courses (e.g. methods, seminars)? What are the unique features of the language testing course?</p></list-item>
<list-item><p>[Uncovered Areas] What are the topics you would want to cover but cannot (due to practical constraints)?</p></list-item>
<list-item><p>[Course Position] What difficulties do you have with curriculum design of the course? (e.g. Even though you feel there is a strong need, is it difficult to open an advanced course in assessment?)</p></list-item>
<list-item><p>[Challenges] What are areas you have the most difficulty teaching? What topics do your students have the hardest time understanding? How do you overcome this challenge?</p></list-item>
<list-item><p>[Training] Do you believe it is important for teacher educators to have field experience in order to teach the course?</p></list-item>
<list-item><p>[Assessment] How do you measure/assess (e.g. papers, tests, presentation, test development) students’ achievement of the course objectives?</p></list-item>
<list-item><p>[Changes and Development] How has your course changed or developed over the years? What changes have occurred in the content compared to the first time you taught the course? What would you like to do differently if you were to teach the course again?</p></list-item>
<list-item><p>[Assessment Proficiency] When students complete your course, how proficient are they in interpreting, evaluating, and developing language tests compared to when they began the course? (before and after the course)</p></list-item>
<list-item><p>In general, do you think your students find your course (1) theoretical, (2) practical, (3) easy, (4) useful, (5) difficult?</p></list-item>
<list-item><p>Is there anything else you want to know about regarding language assessment courses?</p></list-item>
</list>
</sec>
</app>
<app id="app3-0265532213480334">
<title>Appendix C</title>
<table-wrap id="table4-0265532213480334" position="float">
<label>Table A1.</label>
<caption>
<p>Important topics for classroom teachers: Instructors’ perspective.</p>
</caption>
<graphic alternate-form-of="table4-0265532213480334" xlink:href="10.1177_0265532213480334-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Topic</th>
<th align="left" colspan="4">Instructors<hr/></th>
<th align="left" colspan="4">Language testers<hr/></th>
<th align="left" colspan="6">Non-language testers<hr/></th>
</tr>
<tr>
<th/>
<th align="left"><italic>n</italic></th>
<th align="left"><italic>M</italic></th>
<th align="left"><italic>SD</italic></th>
<th align="left">Rank</th>
<th align="left"><italic>n</italic></th>
<th align="left"><italic>M</italic></th>
<th align="left"><italic>SD</italic></th>
<th align="left">Rank</th>
<th align="left"><italic>n</italic></th>
<th align="left"><italic>M</italic></th>
<th align="left"><italic>SD</italic></th>
<th align="left">Rank</th>
<th align="left"><italic>t</italic></th>
<th align="left"><italic>p</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Test specifications</td>
<td>138</td>
<td>3.37</td>
<td>.735</td>
<td>3</td>
<td>67</td>
<td>3.54</td>
<td>.611</td>
<td>2</td>
<td>71</td>
<td>3.23</td>
<td>.814</td>
<td>5</td>
<td>2.555</td>
<td>.012*</td>
</tr>
<tr>
<td>2. Test administration</td>
<td>137</td>
<td>2.93</td>
<td>.727</td>
<td>8</td>
<td>66</td>
<td>2.95</td>
<td>.711</td>
<td>9</td>
<td>71</td>
<td>2.92</td>
<td>.751</td>
<td>8</td>
<td>.312</td>
<td>.756</td>
</tr>
<tr>
<td>3. Test critiquing</td>
<td>136</td>
<td>3.18</td>
<td>.696</td>
<td>6</td>
<td>65</td>
<td>3.22</td>
<td>.718</td>
<td>6</td>
<td>71</td>
<td>3.14</td>
<td>.682</td>
<td>7</td>
<td>.621</td>
<td>.536</td>
</tr>
<tr>
<td>4. Test-taking skills or strategies</td>
<td>137</td>
<td>2.72</td>
<td>.781</td>
<td>11</td>
<td>66</td>
<td>2.58</td>
<td>.842</td>
<td>11</td>
<td>71</td>
<td>2.85</td>
<td>.690</td>
<td>10</td>
<td>−2.039</td>
<td>.042*</td>
</tr>
<tr>
<td>5. Test theory</td>
<td>136</td>
<td>3.36</td>
<td>.674</td>
<td>4</td>
<td>66</td>
<td>3.47</td>
<td>.661</td>
<td>3</td>
<td>70</td>
<td>3.27</td>
<td>.679</td>
<td>4</td>
<td>1.723</td>
<td>.087</td>
</tr>
<tr>
<td>6. Basic statistics</td>
<td>136</td>
<td>2.89</td>
<td>.863</td>
<td>9</td>
<td>66</td>
<td>2.92</td>
<td>.865</td>
<td>10</td>
<td>70</td>
<td>2.86</td>
<td>.873</td>
<td>9</td>
<td>.450</td>
<td>.653</td>
</tr>
<tr>
<td>7. Advanced statistics</td>
<td>136</td>
<td>1.74</td>
<td>.795</td>
<td>14</td>
<td>65</td>
<td>1.74</td>
<td>.853</td>
<td>14</td>
<td>71</td>
<td>1.76</td>
<td>.746</td>
<td>14</td>
<td>−.161</td>
<td>.872</td>
</tr>
<tr>
<td>8. Test ethics</td>
<td>135</td>
<td>3.12</td>
<td>.751</td>
<td>7</td>
<td>65</td>
<td>3.03</td>
<td>.684</td>
<td>7</td>
<td>70</td>
<td>3.19</td>
<td>.804</td>
<td>6</td>
<td>−.1.209</td>
<td>.229</td>
</tr>
<tr>
<td>9. History of language testing</td>
<td>136</td>
<td>2.31</td>
<td>.753</td>
<td>13</td>
<td>66</td>
<td>2.38</td>
<td>.696</td>
<td>13</td>
<td>70</td>
<td>2.26</td>
<td>.793</td>
<td>13</td>
<td>.948</td>
<td>.345</td>
</tr>
<tr>
<td>10. Classroom assessment</td>
<td>138</td>
<td>3.76</td>
<td>.494</td>
<td>1</td>
<td>67</td>
<td>3.69</td>
<td>.556</td>
<td>1</td>
<td>71</td>
<td>3.82</td>
<td>.425</td>
<td>1</td>
<td>− 1.541</td>
<td>.126</td>
</tr>
<tr>
<td>11. Alternative assessment</td>
<td>137</td>
<td>3.51</td>
<td>.642</td>
<td>2</td>
<td>67</td>
<td>3.37</td>
<td>.648</td>
<td>4</td>
<td>70</td>
<td>3.63</td>
<td>.618</td>
<td>2</td>
<td>−.2.363</td>
<td>.020*</td>
</tr>
<tr>
<td>12. Rubric development</td>
<td>137</td>
<td>3.35</td>
<td>.751</td>
<td>5</td>
<td>67</td>
<td>3.31</td>
<td>.656</td>
<td>5</td>
<td>70</td>
<td>3.40</td>
<td>.824</td>
<td>3</td>
<td>−.679</td>
<td>.499</td>
</tr>
<tr>
<td>13. Rater training</td>
<td>135</td>
<td>2.89</td>
<td>.795</td>
<td>9</td>
<td>66</td>
<td>3.03</td>
<td>.744</td>
<td>7</td>
<td>69</td>
<td>2.74</td>
<td>.816</td>
<td>12</td>
<td>2.164</td>
<td>.032*</td>
</tr>
<tr>
<td>14. Test accommodations</td>
<td>136</td>
<td>2.60</td>
<td>.781</td>
<td>12</td>
<td>65</td>
<td>2.42</td>
<td>.659</td>
<td>12</td>
<td>71</td>
<td>2.76</td>
<td>.853</td>
<td>11</td>
<td>−2.624</td>
<td>.010*</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0265532213480334">
<p><italic>Notes</italic>: (1) The response scale was as follows: 1 = hardly any time, 2 = a little time, 3 = some time, 4 = extensive time. (2) Multiple independent t-tests were used to identify significant differences between the two groups. Using the Bonferroni Adjustment required significance at the level (<italic>p</italic> &lt; .0035).</p>
</fn>
</table-wrap-foot>
</table-wrap>
</app>
</app-group>
<ack>
<p>I would like to Fred Davidson for his guidance and feedback throughout the study. I would also like to thank Hongling Sun for her thoughtful suggestions and help.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>Funding to conduct this study was provided by TOEFL Small Grants for Doctoral Research in Second or Foreign Language Assessment and the Hardie Dissertation Award from the University of Illinois at Urbana Champaign.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0265532213480334">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bailey</surname><given-names>K. M.</given-names></name>
<name><surname>Brown</surname><given-names>J. D.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Language testing courses: What are they?</article-title> In <person-group person-group-type="editor">
<name><surname>Cumming</surname><given-names>A.</given-names></name>
<name><surname>Berwick</surname><given-names>R.</given-names></name>
</person-group> (Eds.), <source>Validation in language testing</source> (pp. <fpage>236</fpage>–<lpage>256</lpage>). <publisher-loc>Philadelphia, PA</publisher-loc>: <publisher-name>Multilingual Matters</publisher-name>.</citation>
</ref>
<ref id="bibr2-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brown</surname><given-names>J. D.</given-names></name>
<name><surname>Bailey</surname><given-names>K. M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Language testing courses: What are they in 2007?</article-title> <source>Language Testing</source>, <volume>25</volume>(<issue>3</issue>), <fpage>349</fpage>–<lpage>383</lpage>.</citation>
</ref>
<ref id="bibr3-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Davies</surname><given-names>A.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Textbook trends in teaching language testing</article-title>. <source>Language Testing</source>, <volume>25</volume>(<issue>3</issue>), <fpage>327</fpage>–<lpage>347</lpage>.</citation>
</ref>
<ref id="bibr4-0265532213480334">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Greene</surname><given-names>J. C.</given-names></name>
</person-group> (<year>2007</year>). <source>Mixed methods in social inquiry</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr5-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Inbar-Lourie</surname><given-names>O.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Mind the gap: Self and perceived native speaker identities of EFL teachers</article-title>. <source>Educational Linguistics</source>, <volume>5</volume>, <fpage>265</fpage>–<lpage>281</lpage>.</citation>
</ref>
<ref id="bibr6-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Inbar-Lourie</surname><given-names>O.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Constructing a language assessment knowledge base: A focus on language assessment courses</article-title>. <source>Language Testing</source>, <volume>25</volume>(<issue>3</issue>), <fpage>385</fpage>–<lpage>402</lpage>.</citation>
</ref>
<ref id="bibr7-0265532213480334">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Jeong</surname><given-names>H.</given-names></name>
</person-group> (<year>2009</year>, <month>November</month>). <source>Syllabi review of language assessment courses</source>. <conf-name>Poster presented at the Thirty First Language Testing Research Colloquium</conf-name>, <conf-loc>Denver, Colorado</conf-loc>.</citation>
</ref>
<ref id="bibr8-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kleinsasser</surname><given-names>R. C.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Transforming a postgraduate level assessment course: A second language teacher educator’s narrative</article-title>. <source>Prospect</source>, <volume>20</volume>, <fpage>77</fpage>–<lpage>102</lpage>.</citation>
</ref>
<ref id="bibr9-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Popham</surname><given-names>W. J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Assessment literacy for teachers: Faddish or fundamental?</article-title> <source>Theory into Practice</source>, <volume>48</volume>(<issue>1</issue>), <fpage>4</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr10-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Spolsky</surname><given-names>B.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Language testing at 25: Maturity and responsibility?</article-title> <source>Language Testing</source>, <volume>25</volume>(<issue>3</issue>), <fpage>297</fpage>–<lpage>305</lpage>.</citation>
</ref>
<ref id="bibr11-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stiggins</surname><given-names>R. J.</given-names></name>
</person-group> (<year>1999a</year>). <article-title>Assessment, student confidence, and school success</article-title>. <source>Phi Delta Kappan</source>, <volume>81</volume>(<issue>3</issue>), <fpage>191</fpage>–<lpage>198</lpage>.</citation>
</ref>
<ref id="bibr12-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stiggins</surname><given-names>R. J.</given-names></name>
</person-group> (<year>1999b</year>). <article-title>Evaluating classroom assessment training in teacher education programs</article-title>. <source>Educational Measurement: Issues and Practice</source>, <volume>18</volume>(<issue>1</issue>), <fpage>23</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr13-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stiggins</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>The unfulfilled promise of classroom assessment</article-title>. <source>Educational Measurement: Issues and Practice</source>, <volume>20</volume>(<issue>3</issue>), <fpage>5</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr14-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stiggins</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Assessment crisis: The absence of assessment FOR learning</article-title>. <source>Phi Delta Kappan</source>, <volume>83</volume>(<issue>10</issue>), <fpage>758</fpage>–<lpage>766</lpage>.</citation>
</ref>
<ref id="bibr15-0265532213480334">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Taylor</surname><given-names>L.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Developing assessment literacy</article-title>. <source>Annual Review of Applied Linguistics</source> <volume>29</volume>, <fpage>21</fpage>–<lpage>36</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>