<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PIH</journal-id>
<journal-id journal-id-type="hwp">sppih</journal-id>
<journal-title>Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine</journal-title>
<issn pub-type="ppub">0954-4119</issn>
<issn pub-type="epub">2041-6518</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0954411911431664</article-id>
<article-id pub-id-type="publisher-id">10.1177_0954411911431664</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Inter-speaker speech variability assessment using statistical deformable models from 3.0 Tesla magnetic resonance images</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Vasconcelos</surname><given-names>Maria JM</given-names></name>
<xref ref-type="aff" rid="aff1-0954411911431664">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Ventura</surname><given-names>Sandra MR</given-names></name>
<xref ref-type="aff" rid="aff2-0954411911431664">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Freitas</surname><given-names>Diamantino RS</given-names></name>
<xref ref-type="aff" rid="aff3-0954411911431664">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Tavares</surname><given-names>João Manuel RS</given-names></name>
<xref ref-type="aff" rid="aff4-0954411911431664">4</xref>
</contrib>
</contrib-group>
<aff id="aff1-0954411911431664"><label>1</label>Faculty of Engineering, University of Porto/Institute of Mechanical Engineering and Industrial Management, Porto, Portugal</aff>
<aff id="aff2-0954411911431664"><label>2</label>Radiology Department, School of Allied Health Science, Porto Polytechnic Institute / Faculty of Engineering, University of Porto, Vila Nova de Gaia, Portugal</aff>
<aff id="aff3-0954411911431664"><label>3</label>Department of Electrical Engineering and Computers, Faculty of Engineering, University of Porto, Porto, Portugal</aff>
<aff id="aff4-0954411911431664"><label>4</label>Department of Mechanical Engineering, Faculty of Engineering, University of Porto/Institute of Mechanical Engineering and Industrial Management, Porto, Portugal</aff>
<author-notes>
<corresp id="corresp1-0954411911431664">João Manuel RS Tavares, Department of Mechanical Engineering, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, s/n, 4200-465 Porto, Portugal Email: <email>tavares@fe.up.pt</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2012</year>
</pub-date>
<volume>226</volume>
<issue>3</issue>
<fpage>185</fpage>
<lpage>196</lpage>
<history>
<date date-type="received">
<day>11</day>
<month>3</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>9</day>
<month>11</month>
<year>2011</year>
</date>
</history>
<permissions>
<copyright-statement>© IMechE 2011</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="society">Institution of Mechanical Engineers</copyright-holder>
</permissions>
<abstract>
<p>The morphological and dynamic characterisation of the vocal tract during speech production has been gaining greater attention due to the motivation of the latest improvements in magnetic resonance (MR) imaging; namely, with the use of higher magnetic fields, such as 3.0 Tesla. In this work, the automatic study of the vocal tract from 3.0 Tesla MR images was assessed through the application of statistical deformable models. Therefore, the primary goal focused on the analysis of the shape of the vocal tract during the articulation of European Portuguese sounds, followed by the evaluation of the results concerning the automatic segmentation, i.e. identification of the vocal tract in new MR images. In what concerns speech production, this is the first attempt to automatically characterise and reconstruct the vocal tract shape of 3.0 Tesla MR images by using deformable models; particularly, by using active and appearance shape models. The achieved results clearly evidence the adequacy and advantage of the automatic analysis of the 3.0 Tesla MR images of these deformable models in order to extract the vocal tract shape and assess the involved articulatory movements. These achievements are mostly required, for example, for a better knowledge of speech production, mainly of patients suffering from articulatory disorders, and to build enhanced speech synthesizer models.</p>
</abstract>
<kwd-group>
<kwd>Active and appearance shape models</kwd>
<kwd>image analysis</kwd>
<kwd>medical imaging</kwd>
<kwd>modelling and segmentation</kwd>
<kwd>morphological study</kwd>
<kwd>Portuguese speech language</kwd>
<kwd>vocal tract shape</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0954411911431664" sec-type="intro">
<title>Introduction</title>
<p>Since the first applications of magnetic resonance (MR) imaging to speech production assessment, in the 1980s<sup><xref ref-type="bibr" rid="bibr1-0954411911431664">1</xref>,<xref ref-type="bibr" rid="bibr2-0954411911431664">2</xref></sup> many studies have been performed, namely for French<sup><xref ref-type="bibr" rid="bibr3-0954411911431664">3</xref></sup>, English<sup><xref ref-type="bibr" rid="bibr4-0954411911431664">4</xref></sup>, Swedish<sup><xref ref-type="bibr" rid="bibr5-0954411911431664">5</xref></sup>, Japanese<sup><xref ref-type="bibr" rid="bibr6-0954411911431664">6</xref></sup> and European Portuguese (EP)<sup><xref ref-type="bibr" rid="bibr7-0954411911431664">7</xref>–<xref ref-type="bibr" rid="bibr9-0954411911431664">9</xref></sup> languages.</p>
<p>Due to the lengthy data acquisition time of the early MR imaging systems, the first studies were restricted to vowels and some consonants.<sup><xref ref-type="bibr" rid="bibr10-0954411911431664">10</xref>,<xref ref-type="bibr" rid="bibr11-0954411911431664">11</xref></sup> However, with the emerging development of rapid imaging techniques, such as synchronised sampling methods<sup><xref ref-type="bibr" rid="bibr12-0954411911431664">12</xref></sup> or tagged cine-MR<sup><xref ref-type="bibr" rid="bibr13-0954411911431664">13</xref>,<xref ref-type="bibr" rid="bibr14-0954411911431664">14</xref></sup>, the acquisition of image data regarding articulatory movements became possible. Nowadays, the acquisition of three-dimensional (3D) MR image sequences has been steady<sup><xref ref-type="bibr" rid="bibr15-0954411911431664">15</xref></sup> and, consequently, enormous expectations have been made about the attainment of image data on speech production in a more efficient and repeatable manner.</p>
<p>Various organs have important roles in the production of numerous speech sounds, functioning in an organised, i.e. articulated, manner in order to change the shape and length of a set of air cavities — the vocal tract. Most of these organs, named articulators, are soft-tissues, such as the lips, tongue and velum, that execute active movements during speech production. The tongue is a muscular organ capable of moving in nearly every direction, expanding, compressing and displaying a fine degree of articulation in the oral cavity.</p>
<p>Nonetheless, individual differences in the vocal tract morphology turn speech production into a unique motor activity. Inter-speaker variability of the acoustic speech signal can confound the process of any movement data to evaluate theories of speech movement control.<sup><xref ref-type="bibr" rid="bibr16-0954411911431664">16</xref></sup> Thus, this challenges the capability of magnetic resonance imaging for the morphological description of the acoustical inter-speaker variability.<sup><xref ref-type="bibr" rid="bibr17-0954411911431664">17</xref></sup> With the cutting-edge MR improvements, a proper 3D description on the vocal tract geometry of the speakers can be reached, both in terms of good image contrast and temporal resolution. In addition, useful and accurate morphological and dynamic information can also be attained, as to the positions and shapes of the involved articulators during speech production.<sup><xref ref-type="bibr" rid="bibr9-0954411911431664">9</xref>,<xref ref-type="bibr" rid="bibr18-0954411911431664">18</xref>–<xref ref-type="bibr" rid="bibr20-0954411911431664">20</xref></sup></p>
<p>The use of deformable models in image analysis has been generating remarkable results in innumerable and distinct applications.<sup><xref ref-type="bibr" rid="bibr8-0954411911431664">8</xref>,<xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref>,<xref ref-type="bibr" rid="bibr22-0954411911431664">22</xref></sup> Active contours, deformable templates, physical models and statistical models can be considered as the most well-known deformable models to extract object features from input images.<sup><xref ref-type="bibr" rid="bibr23-0954411911431664">23</xref></sup> Active contours were introduced<sup><xref ref-type="bibr" rid="bibr24-0954411911431664">24</xref></sup>, by considering the segmentation contour as a ‘snake’. Hence, the segmentation contour consists of an elastic set of points that are adjusted to the border of the object to be segmented, driven by the combination of internal and external forces, in order to minimize the energy of the model. On the other hand, deformable geometrical shapes (templates), built considering the shape of the object to be segmented, are parameterised by appropriated functions in order to segment the modelled object in new images based on its characteristic image features.<sup><xref ref-type="bibr" rid="bibr25-0954411911431664">25</xref></sup> Recently, enhanced physical modelling approaches integrate the previously acquired knowledge about the objects, making the models used in the image segmentation process more realistic.<sup><xref ref-type="bibr" rid="bibr26-0954411911431664">26</xref></sup> Finally, statistical models, particularly point distribution models (PDMs) are built from a set of training shapes of the object under study in order to extract its main characteristics through statistical modelling.<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref>,<xref ref-type="bibr" rid="bibr27-0954411911431664">27</xref></sup> Then, the PDMs can be used to segment the modelled object in new images by considering the image intensity information, resulting in the active shape models (ASMs)<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref>,<xref ref-type="bibr" rid="bibr28-0954411911431664">28</xref></sup>, or by considering the image texture information, resulting in the active appearance models (AAMs).<sup><xref ref-type="bibr" rid="bibr19-0954411911431664">19</xref>,<xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref>,<xref ref-type="bibr" rid="bibr29-0954411911431664">29</xref></sup></p>
<p>In this work, deformable models, in particular, PDMs, ASMs and AAMs, were applied in the automatic study of the vocal tract from 3.0 Tesla magnetic resonance images; mainly to evaluate the shape of the vocal tract during the articulation of European Portuguese (EP) sounds and later to automatically segment the vocal tract in new images.</p>
<p>This paper has been organised as follows. First, the adopted MR imaging protocol is described. Then, the focus will be on PDMs, ASMs and AAMs, alongside the data used and the assessment adopted regarding the segmentation quality. Afterwards, the models built and their application in the segmentation of the vocal tract in new images representing EP speech sounds will be presented and discussed. The paper ends by pointing out the main conclusions.</p>
</sec>
<sec id="section2-0954411911431664" sec-type="methods">
<title>Methods</title>
<p>In this section, the methodologies adopted to characterise the vocal tract during the production of EP speech sounds of 3.0 Tesla MR images are described. Thus, the used MR imaging protocol, as well the procedures adopted in the image acquisition process, are indicated. Afterwards, an explanation regarding the modelling of objects in images with PDMs is provided, as well as the building process of ASMs and AAMs that were employed to segment the shape of the vocal tract in new images. Finally, the data set used and the assessment addressed are presented.</p>
<sec id="section3-0954411911431664">
<title>Magnetic resonance imaging protocol and procedures</title>
<p>According to the safety procedures for MR, a questionnaire was performed for screening patients before any procedure. In addition, patients were previously informed and instructed about the study to be performed and informed consents were obtained.</p>
<p>The image data was acquired using a MAGNETOM Trio 3.0 Tesla MR system and two integrated coils (a 32-channel head coil and a 4-channel neck matrix coil), with the subjects in supine position. The two young volunteers (one male and one female) were trained before the MR exam to ensure the proper production of the intended sounds. The speech corpus consisted of 25 sounds of European Portuguese (EP) language, including oral and nasal vowels, and consonants.</p>
<p>Using turbo spin echo two-dimensional sequence, and adopting the following parameters: a repetition time of 400 ms, an echo time of 10 ms, an echo train length of 5, a square field-of-view of 240 cm, a matrix size of 512 × 512 pixels, a resolution of 2.133 pixels/mm and a 0.469 × 0.469 pixel size, 1 T1-weighted midsagittal slice of 3 mm thickness was acquired for each sound. In order to reduce inter-speaker variability and to ensure consistency of results, 3 measurements (i.e. 3 slices per sound) were performed during the sustained sound with an overall acquisition time of approximately 8.07 seconds, resulting in 75 images for each subject.</p>
<p>Examples of the MR images acquired are depicted in <xref ref-type="fig" rid="fig1-0954411911431664">Figure 1</xref>. From these images, one may observe different vocal tract configurations for EP vowels and consonant production, as well as for some oral and nasal sounds. Comparing the several vocal tract configurations of the subjects during the articulation of the EP sounds, individual differences of vertical length and of the morphology of the organ were revealed, although the main movements were similar.</p>
<fig id="fig1-0954411911431664" position="float">
<label>Figure 1.</label>
<caption>
<p>Midsagittal MR images of the vocal tract from a female subject (top row) and one of a male subject (bottom row) during production of EP vowels and consonants.</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig1.tif"/>
</fig>
</sec>
<sec id="section4-0954411911431664">
<title>Vocal tract modelling</title>
<p>Some of the images acquired according to the imaging protocol described in the previous section were used to statistically model the shape of the vocal tract and the remainder to evaluate the models built. Hence, in the following sections, the process adopted to label the shape of the vocal tract, i.e. to define the landmark points to be addressed by the model, is described, and then the statistical modelling techniques are introduced.</p>
<sec id="section5-0954411911431664">
<title>Shape landmark points</title>
<p>In the building process of a PDM, each shape of the vocal tract that is presented in the image training set should be described by a group of labelled landmark points conveying important anatomical aspects of the structure, as shown in <xref ref-type="fig" rid="fig2-0954411911431664">Figure 2</xref>. (In the current and subsequent images, the landmark points appear connected by fictitious line segments so as to enhance their visualisation.) Consequently, the manual identification of these points in all training images requires a comprehensive knowledge of the structure in question, as the resultant model behaviour greatly depends on the landmark points selected.</p>
<fig id="fig2-0954411911431664" position="float">
<label>Figure 2.</label>
<caption>
<p>Training image (a), chosen landmark points (b), and original image overlapped with the chosen landmark points (c).</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig2.tif"/>
</fig>
<p>The manual selection of the landmark points was carried out by one of the authors who has excellent knowledge of MR imaging and on the anatomy of the vocal tract, in addition to being cross-checked by another co-author in accordance with the following criteria.</p>
<list id="list1-0954411911431664" list-type="bullet">
<list-item><p>Four points in the lips (front and back of the lips’ margins);</p></list-item>
<list-item><p>Three points corresponding to the lingual <italic>frenulum</italic> and tongue’s tip;</p></list-item>
<list-item><p>Seven points equally spaced along the surface of the tongue;</p></list-item>
<list-item><p>Seven points along the surface of the hard palate (roof of the oral cavity) placed in symmetry with the tongue points;</p></list-item>
<list-item><p>One point at the velum (or soft palate);</p></list-item>
<list-item><p>Three points equally spaced at the posterior margin of the oropharynx (behind the oral cavity).</p></list-item>
</list>
<p>It should be noted that, during this task, the epiglottis was not taken into account. Thus, in each of the 150 acquired MR images, 25 landmark points were defined according to these criteria.</p>
</sec>
<sec id="section6-0954411911431664">
<title>Statistical modelling</title>
<p>In order to study the admissible variation of the coordinates of the landmark points of the training shapes, it is initially necessary to align them by using, for instance, dynamic programming.<sup><xref ref-type="bibr" rid="bibr30-0954411911431664">30</xref></sup> Therefore, given the co-ordinates <inline-formula id="inline-formula1-0954411911431664">
<mml:math display="inline" id="math1-0954411911431664">
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math></inline-formula> of each landmark point <inline-formula id="inline-formula2-0954411911431664">
<mml:math display="inline" id="math2-0954411911431664">
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:math></inline-formula> of the shape <inline-formula id="inline-formula3-0954411911431664">
<mml:math display="inline" id="math3-0954411911431664">
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:math></inline-formula> of the modelled structure, the shape vector is</p>
<p>
<disp-formula id="disp-formula1-0954411911431664">
<label>(1)</label>
<mml:math display="block" id="math4-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>in</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>in</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0954411911431664" xlink:href="10.1177_0954411911431664-eq1.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula4-0954411911431664">
<mml:math display="inline" id="math5-0954411911431664">
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>…</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, with <inline-formula id="inline-formula5-0954411911431664">
<mml:math display="inline" id="math6-0954411911431664">
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:math></inline-formula> representing the number of shapes in the image training set and <inline-formula id="inline-formula6-0954411911431664">
<mml:math display="inline" id="math7-0954411911431664">
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:math></inline-formula> the number of landmark points used. Once the training shapes are aligned, the mean shape and the admissible variability of the modelled structure may be found. The modes of variation characterise the manner in which the landmarks of the modelled structure tend to move together, the result of which may be obtained by applying a principal component analysis (PCA) to the deviations from the mean. Hence, it is possible to rewrite each vector <inline-formula id="inline-formula7-0954411911431664">
<mml:math display="inline" id="math8-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> as</p>
<p>
<disp-formula id="disp-formula2-0954411911431664">
<label>(2)</label>
<mml:math display="block" id="math9-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0954411911431664" xlink:href="10.1177_0954411911431664-eq2.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula8-0954411911431664">
<mml:math display="inline" id="math10-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> represents the coordinates of the <inline-formula id="inline-formula9-0954411911431664">
<mml:math display="inline" id="math11-0954411911431664">
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:math></inline-formula> landmark points of the new shape of the modelled structure, <inline-formula id="inline-formula10-0954411911431664">
<mml:math display="inline" id="math12-0954411911431664">
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math></inline-formula> are the coordinates of the landmark point <inline-formula id="inline-formula11-0954411911431664">
<mml:math display="inline" id="math13-0954411911431664">
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula12-0954411911431664">
<mml:math display="inline" id="math14-0954411911431664">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula> is the mean position of all landmark points, <inline-formula id="inline-formula13-0954411911431664">
<mml:math display="inline" id="math15-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>…</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>st</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math></inline-formula> is the matrix of the first <inline-formula id="inline-formula14-0954411911431664">
<mml:math display="inline" id="math16-0954411911431664">
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:math></inline-formula> modes of variation, <inline-formula id="inline-formula15-0954411911431664">
<mml:math display="inline" id="math17-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>si</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> corresponds to the most significant eigenvectors in a PCA applied to the coordinates of all landmark points, and <inline-formula id="inline-formula16-0954411911431664">
<mml:math display="inline" id="math18-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>…</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>st</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math></inline-formula> is a vector of weights for each variation mode of the modelled structure. Each eigenvector describes the manner in which linearly correlated <inline-formula id="inline-formula17-0954411911431664">
<mml:math display="inline" id="math19-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> move together over the training set, and due to this, is commonly known as a mode of variation. Thus, <xref ref-type="disp-formula" rid="disp-formula2-0954411911431664">equation (2)</xref> represents the PDM of the modelled structure and may be used to generate new shapes that it can undertake. Further details about the construction of PDMs can be found in previous work.<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref></sup></p>
<p>The local grey-level environment of each landmark point may also be considered in the statistical modelling of objects from images.<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref>,<xref ref-type="bibr" rid="bibr28-0954411911431664">28</xref></sup> Thus, statistical information is obtained in relation to the mean and covariance of the grey values of the image pixels around each landmark point. Additionally, this information can be used to evaluate the matching between landmark points, resulting in the ASMs, in addition to considering the information on image texture resulting in the AAMs, as explained in the following.</p>
</sec>
<sec id="section7-0954411911431664">
<title>Active shape models</title>
<p>The consideration of a PDM in addition to the grey-level profiles of each landmark point used in its building can be used to segment the modelled structure in new images through active shape models (ASMs), which are based on an iterative technique for fitting flexible models to structures represented in images.<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref>, <xref ref-type="bibr" rid="bibr27-0954411911431664">27</xref></sup> Hence, this technique is an iterative optimisation scheme that refines the mean shape, <inline-formula id="inline-formula18-0954411911431664">
<mml:math display="inline" id="math20-0954411911431664">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula>, given by the PDM built for the structure under study, according to associated modes of variation, in a new image, i.e. this refining process segments the modelled structure in the new image. The refining process adopted may be summarised by the following steps.</p>
<list id="list1-0954411911431664" list-type="order">
<list-item><p>The displacement required to dislocate the model to a more appropriate position, that is, closer to the final shape, is calculated at each landmark point.</p></list-item>
<list-item><p>The calculus of the changes in the overall shape position, orientation and scale that most adequately satisfy the local displacements found in the previous step.</p></list-item>
<list-item><p>The obtainment of the required adjustments in the parameters of the model, by analysing the residual differences between the shape of the model and the final desired shape.</p></list-item>
</list>
<p>The image segmentation process with the aid of ASMs was improved<sup><xref ref-type="bibr" rid="bibr31-0954411911431664">31</xref></sup> due to the adoption of a multi-resolution approach that may be summarised as follows: First, a multi-resolution pyramid of the input images is built by applying a Gaussian mask; following this, the grey-level profiles at the various levels of the pyramid built are studied. Consequently, the ASMs are capable of segmenting the input images in a more efficient and trustworthy manner.</p>
</sec>
<sec id="section8-0954411911431664">
<title>Active appearance models</title>
<p>The segmentation of structure in images by AAM is based on the building of texture and appearance models for the structures to be segmented.<sup><xref ref-type="bibr" rid="bibr29-0954411911431664">29</xref></sup> These models are generated by combining a shape variation model, i.e. a geometric model, with an appearance variation model in a shape-normalised framework.<sup><xref ref-type="bibr" rid="bibr19-0954411911431664">19</xref>,<xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref></sup> The geometric models integrated into the AAMs are the PDMs described by <xref ref-type="disp-formula" rid="disp-formula2-0954411911431664">equation (2)</xref>. Conversely, to build the statistical models of the grey-level appearances of the structures represented in the training images, one needs to deform each training image in order that the landmark points to match the mean shape of the structure to be modelled, using a triangulation algorithm. Then, the grey-level information, i.e. the intensity values, <inline-formula id="inline-formula19-0954411911431664">
<mml:math display="inline" id="math21-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>im</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, from the shape-normalised image over the region covered by the mean shape is sampled. In order to minimise the effect of global intensity variation in the training images, the average vector of the grey levels (<inline-formula id="inline-formula20-0954411911431664">
<mml:math display="inline" id="math22-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>im</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>) is once again normalised, thereby resulting in vector <italic>g</italic>. Following the application of a PCA to the previous vector <italic>g</italic>, a new linear model, called the texture model, is obtained.</p>
<p>
<disp-formula id="disp-formula3-0954411911431664">
<label>(3)</label>
<mml:math display="block" id="math23-0954411911431664">
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mo>=</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0954411911431664" xlink:href="10.1177_0954411911431664-eq3.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula21-0954411911431664">
<mml:math display="inline" id="math24-0954411911431664">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula> is the mean normalised grey-level vector, <inline-formula id="inline-formula22-0954411911431664">
<mml:math display="inline" id="math25-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> is a set of orthogonal modes related to the grey-level variations, and <inline-formula id="inline-formula23-0954411911431664">
<mml:math display="inline" id="math26-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> is a set parameters of the grey-level model. Therefore, the shape and appearance of any configuration of the modelled structure can be defined by vectors <inline-formula id="inline-formula24-0954411911431664">
<mml:math display="inline" id="math27-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula25-0954411911431664">
<mml:math display="inline" id="math28-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>.</p>
<p>Given that a correlation may exist between the variations of shape and of grey levels, a further PCA is applied to the data of the structure. Thus, for each training image a concatenated vector is generated</p>
<p>
<disp-formula id="disp-formula4-0954411911431664">
<label>(4)</label>
<mml:math display="block" id="math29-0954411911431664">
<mml:mrow>
<mml:mi>b</mml:mi>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>W</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>W</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msubsup>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>−</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>g</mml:mi>
<mml:mo>−</mml:mo>
<mml:mover>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0954411911431664" xlink:href="10.1177_0954411911431664-eq4.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula26-0954411911431664">
<mml:math display="inline" id="math30-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>W</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> is a diagonal matrix of weights for each parameter of the global model built, allowing for the adequate balance between the models of shape and grey levels. Next, a PCA is applied to these vectors, which results in a novel model</p>
<p>
<disp-formula id="disp-formula5-0954411911431664">
<label>(5)</label>
<mml:math display="block" id="math31-0954411911431664">
<mml:mrow>
<mml:mi>b</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>Qc</mml:mi>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0954411911431664" xlink:href="10.1177_0954411911431664-eq5.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula27-0954411911431664">
<mml:math display="inline" id="math32-0954411911431664">
<mml:mrow>
<mml:mi>Q</mml:mi>
</mml:mrow>
</mml:math></inline-formula> is the eigenvectors of <italic>b</italic> and <italic>c</italic> is the vector of the appearance parameters that control the shape in addition to the grey levels of the model built. In this manner, a new shape of the modelled structure can be obtained for a given vector <italic>c</italic> by generating the shape-free grey-level structure from vector <italic>g</italic> and then deforming it by considering the landmark points provided by <italic>x</italic>.</p>
</sec>
<sec id="section9-0954411911431664">
<title>Data set and assessment</title>
<p>A computational framework was developed in MATLAB to build statistical deformable models, namely PDMs and ASMs, which integrates the active shape models software.<sup><xref ref-type="bibr" rid="bibr32-0954411911431664">32</xref></sup> Additionally, the Modelling and Search Software<sup><xref ref-type="bibr" rid="bibr33-0954411911431664">33</xref></sup> was used to build AAMs.</p>
<p>According to the International Phonetic Alphabet (IPA), the EP speech language consists of a total of 30 sounds. In this work, 25 of these sounds have been considered in the building of the statistical models of the vocal tract by using three 3.0 Tesla MR images per sound. The considered sounds include the most representative sounds of the EP speech language. Additionally, two new 3.0 Tesla MR images for the EP speech sounds /v/, /f/, and /a/ for each subject (making a total of 12 new images) were used to evaluate the quality of the segmentations obtained by the models built. These sounds were selected because the associated sounds are easy to sustain, require slight effort for the subjects and ensure the steadiness of the vocal tract shape. They include the two classes of sounds under study (two fricative consonants, one voiced and another one voiceless, respectively, and one vowel (/a/)).</p>
<p>In order to analyse the sensibility of the ASMs in terms of the percentage of retained variance and of the dimensions of the profile adopted for the grey levels in the modelling, ASMs were built adopting 90%, 95% and 99% of retained variance and profiles of 7, 11 and 15 pixels.<sup><xref ref-type="bibr" rid="bibr20-0954411911431664">20</xref></sup> Similarly, AAMs were built adopting equal values of retained variance and the following values of 5000 and 10000 pixels were considered for building the texture model.<sup><xref ref-type="bibr" rid="bibr19-0954411911431664">19</xref></sup> These parameters were defined based on the authors’ previous experience concerning the statistical modelling of vocal tract using these models.<sup><xref ref-type="bibr" rid="bibr9-0954411911431664">9</xref>,<xref ref-type="bibr" rid="bibr19-0954411911431664">19</xref>–<xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref></sup></p>
<p>Following the building of the ASMs and AAMs from the training set constituted by 138 images, the models were then used to segment the vocal tract in 12 new images. As a stopping criterion of the segmentation process, a maximum of six iterations on each resolution level was taken into consideration. Due to the fact that five resolution levels were defined based on the dimensions of the images under study, this criterion means that from the beginning of the segmentation process to its end, a maximum of 30 iterations could occur.<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref></sup> This maximum number of iterations was chosen because in the conducted experiments this led to excellent segmentation results. In fact, it was observed that an inferior value was not always sufficient to attain satisfactory results and a superior value constantly caused similar results.</p>
<p>In order to assess the quality of the segmentations obtained for the vocal tract in new MR images by the models built, the values of the mean and standard deviation of the Euclidean distances between the landmark points of the final shape computationally obtained and the corresponding ones manually defined in the same images were calculated.</p>
</sec>
</sec>
</sec>
<sec id="section10-0954411911431664" sec-type="results|discussion">
<title>Results and discussion</title>
<p>From <xref ref-type="table" rid="table1-0954411911431664">Table 1</xref>, one may observe that the initial 11 modes of variation of the ASM built, that is, 22% of the modes of variation, are capable of explaining 90% of all variance of the vocal tract. Moreover, one may conclude that the first 17 modes, i.e. 34% of the modes of variation, provide an explanation for 95% of all variance and the initial 33 modes, which imply 66% of the modes of variation, illustrates 99% of all variance. Consequently, these findings clearly indicate the ability of the built ASM to considerably condense the data that is required to represent all configurations that the vocal tract assumes in the image training set.</p>
<table-wrap id="table1-0954411911431664" position="float">
<label>Table 1.</label>
<caption>
<p>Retained percentages along the initial first 17 modes of variation of the model built for the vocal tract.</p>
</caption>
<graphic alternate-form-of="table1-0954411911431664" xlink:href="10.1177_0954411911431664-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Mode of variation</th>
<th align="left">Retained (%)</th>
<th align="left">Cumulative retained (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<inline-formula id="inline-formula28-0954411911431664">
<mml:math display="inline" id="math33-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>40.893</td>
<td>40.893</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula29-0954411911431664">
<mml:math display="inline" id="math34-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>16.348</td>
<td>57.241</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula30-0954411911431664">
<mml:math display="inline" id="math35-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>8.065</td>
<td>65.306</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula31-0954411911431664">
<mml:math display="inline" id="math36-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>7.404</td>
<td>72.710</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula32-0954411911431664">
<mml:math display="inline" id="math37-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>4.595</td>
<td>77.305</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula33-0954411911431664">
<mml:math display="inline" id="math38-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>6</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>3.920</td>
<td>81.225</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula34-0954411911431664">
<mml:math display="inline" id="math39-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>2.515</td>
<td>83.740</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula35-0954411911431664">
<mml:math display="inline" id="math40-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>8</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>2.115</td>
<td>85.855</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula36-0954411911431664">
<mml:math display="inline" id="math41-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>9</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>1.703</td>
<td>87.558</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula37-0954411911431664">
<mml:math display="inline" id="math42-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>10</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>1.397</td>
<td>88.955</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula38-0954411911431664">
<mml:math display="inline" id="math43-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>1.296</td>
<td>90.251</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula39-0954411911431664">
<mml:math display="inline" id="math44-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>1.108</td>
<td>91.359</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula40-0954411911431664">
<mml:math display="inline" id="math45-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>13</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>1.021</td>
<td>92.380</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula41-0954411911431664">
<mml:math display="inline" id="math46-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>14</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.787</td>
<td>93.167</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula42-0954411911431664">
<mml:math display="inline" id="math47-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>15</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.677</td>
<td>93.844</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula43-0954411911431664">
<mml:math display="inline" id="math48-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>16</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.632</td>
<td>94.476</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula44-0954411911431664">
<mml:math display="inline" id="math49-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>17</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>
</td>
<td>0.562</td>
<td>95.038</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>If one takes into consideration the first seven modes of variation, it is possible to observe that a wide range of movements, including wide range ones to more refined and particular movements of the articulators, had been successfully addressed. The effects on varying the first six modes of variation of the built models are depicted in <xref ref-type="fig" rid="fig3-0954411911431664">Figure 3</xref>. From this figure, one can realise that the first mode is related to the movements of the tongue from the front to the back in the oral cavity associated with the rise of the larynx. With regard to the second mode of variation, it is possible to observe the movements of the tongue from the front-high to the back-down in the oral cavity associated with the lips opening and narrowing. The third mode of variation describes the lowering of the velum associated with the enlargement/narrowing of the pharynx cavity and the tongue’s tip movement. The vertical movement of the body of the tongue towards the palate is revealed by the fifth mode of variation. In contrast, the variations of the sixth mode illustrate the opening/closing of the lips associated with the vertical movement of the tongue. After this mode of variation, all the remaining modes represent more particular movements, such as the larynx height adjustment, the tongue’s tip movement, the opening and closing of the lips, the vertical rise of the tongue’s body towards the palate and the pharynx narrowing.</p>
<fig id="fig3-0954411911431664" position="float">
<label>Figure 3.</label>
<caption>
<p>Effect on the vocal tract by varying ( ± 2SD) each of the first six modes of variation (<inline-formula id="inline-formula45-0954411911431664">
<mml:math display="inline" id="math50-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>) of the model built.</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig3.tif"/>
</fig>
<p>After the analysis on the ability of the built statistical models to render the real behaviour of the vocal tract during the production of EP language sounds, 12 new MR images of the three distinct EP speech sounds previously selected (/f/, /v/ and /a/), i.e. of images not included in the used training image set, were automatically segmented by the same models. In <xref ref-type="fig" rid="fig4-0954411911431664">Figure 4</xref>, one MR image of each subject articulating the EP speech sound /f/ is presented as well as the evolution of the corresponding segmentation by the active shape model built: the segmentation begins with a rough estimate for the vocal tract in the input image and then deforms it towards the desired segmentation. These results were obtained considering an ASM capable of explaining 90% of all variance of the vocal tract under study and adopting a grey-level profile length of 11 pixels, that is by considering five pixels from each side of the landmark points.<sup><xref ref-type="bibr" rid="bibr21-0954411911431664">21</xref></sup> Analogously, the segmentation results obtained by using this model on another four new MR images are presented in <xref ref-type="fig" rid="fig5-0954411911431664">Figure 5</xref>, where the first two images concerns one subject and the last image concerns the other subject articulating the EP speech sounds /v/ and /a/, respectively.</p>
<fig id="fig4-0954411911431664" position="float">
<label>Figure 4.</label>
<caption>
<p>Test image of female (top row) and male (bottom row) subjects overlapped with the mean shape model built for sound /f/ and after some iterations of the segmentation process of the active shape model built</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig4.tif"/>
</fig>
<fig id="fig5-0954411911431664" position="float">
<label>Figure 5.</label>
<caption>
<p>Four test images overlapped with the mean shape model built (top row) and after the conclusion of the segmentation process by the active shape model built (bottom row). The first two images concerns one subject and the last image concerns the other subject articulating the EP speech sounds /v/ and /a/, respectively</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig5.tif"/>
</fig>
<p>In <xref ref-type="table" rid="table2-0954411911431664">Table 2</xref>, the values of the mean and standard deviation that reflect the quality of the segmentations obtained by the built ASMs in each testing MR image are indicated. (For a more comprehensive understanding of the data included in this table, the models are named as <italic>Asm_varianceretained_profiledimension</italic> and cases of segmentation failures are indicated by a dash.) The results concerning the built ASMs considering 99% of all variance were not included in this table, since the models were not able to successfully segment the modelled organ in most of the testing images. This failure is precisely due to the percentage of retained variance used, 99%, which led to an extremely rigid model and, because of that, a very low ability to be adapted to new configurations.</p>
<table-wrap id="table2-0954411911431664" position="float">
<label>Table 2.</label>
<caption>
<p>Errors (in pixels) of the shapes segmented by the deformable models built (mean and standard deviation: mean ± SD).</p>
</caption>
<graphic alternate-form-of="table2-0954411911431664" xlink:href="10.1177_0954411911431664-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="7">Female subject</th>
</tr>
<tr>
<th align="left">Model</th>
<th align="left">Image 1</th>
<th align="left">Image 2</th>
<th align="left">Image 3</th>
<th align="left">Image 4</th>
<th align="left">Image 5</th>
<th align="left">Image 6</th>
</tr>
</thead>
<tbody>
<tr>
<td>Asm_90_p7</td>
<td>8.99 ± 5.45</td>
<td>8.05 ± 4.92</td>
<td>16.02 ± 14.93</td>
<td>10.78 ± 7.23</td>
<td>13.39 ± 7.65</td>
<td>12.61 ± 7.01</td>
</tr>
<tr>
<td>Asm_95_p7</td>
<td>10.40 ± 5.77</td>
<td>9.23 ± 5.92</td>
<td>14.63 ± 8.16</td>
<td>11.07 ± 9.80</td>
<td>14.29 ± 8.70</td>
<td>13.21 ± 8.13</td>
</tr>
<tr>
<td>Asm_90_p11</td>
<td>7.50 ± 4.80</td>
<td>7.25 ± 4.42</td>
<td>16.93 ± 14.29</td>
<td>8.70 ± 4.46</td>
<td>17.29 ± 10.62</td>
<td>14.49 ± 8.33</td>
</tr>
<tr>
<td>Asm_95_p11</td>
<td>9.89 ± 6.11</td>
<td>10.42 ± 7.48</td>
<td>17.72 ± 14.40</td>
<td>8.70 ± 5.11</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>Asm_90_p15</td>
<td>8.28 ± 4.41</td>
<td>8.29 ± 3.44</td>
<td>16.77 ± 15.50</td>
<td>8.38 ± 4.68</td>
<td>16.54 ± 8.05</td>
<td>14.34 ± 8.17</td>
</tr>
<tr>
<td>Asm_95_p15</td>
<td>8.29 ± 4.56</td>
<td>8.19 ± 3.78</td>
<td>16.40 ± 15.79</td>
<td>8.67 ± 4.29</td>
<td>16.40 ± 8.73</td>
<td>14.19 ± 8.41</td>
</tr>
<tr>
<td>Aam_90_5000</td>
<td>6.75 ± 4.09</td>
<td>7.81 ± 4.74</td>
<td>13.61 ± 15.67</td>
<td>9.37 ± 6.07</td>
<td>9.54 ± 8.36</td>
<td>9.28 ± 8.59</td>
</tr>
<tr>
<td>Aam_95_5000</td>
<td align="center">-</td>
<td>6.87 ± 5.89</td>
<td>13.53 ± 15.06</td>
<td align="center">-</td>
<td>8.89 ± 6.53</td>
<td align="center">-</td>
</tr>
<tr>
<td>Aam_90_10000</td>
<td>7.04 ± 4.55</td>
<td>7.93 ± 4.76</td>
<td>13.16 ± 15.84</td>
<td>9.05 ± 5.91</td>
<td>9.54 ± 8.50</td>
<td>9.42 ± 8.67</td>
</tr>
<tr>
<td>Aam_95_10000</td>
<td>6.43 ± 5.21</td>
<td>6.92 ± 4.91</td>
<td>13.10 ± 14.72</td>
<td>9.63 ± 6.38</td>
<td>8.66 ± 5.15</td>
<td>5.34 ± 2.82</td>
</tr>
<tr>
<th align="left" colspan="7">Male subject</th>
</tr>
<tr>
<th align="left">Model</th>
<th align="left">Image 1</th>
<th align="left">Image 2</th>
<th align="left">Image 3</th>
<th align="left">Image 4</th>
<th align="left">Image 5</th>
<th align="left">Image 6</th>
</tr>
<tr>
<td>Asm_90_p7</td>
<td>9.35 ± 5.18</td>
<td>9.23 ± 7.31</td>
<td>11.11 ± 7.48</td>
<td>15.35 ± 11.34</td>
<td>7.68 ± 3.53</td>
<td>11.05 ± 6.39</td>
</tr>
<tr>
<td>Asm_95_p7</td>
<td>8.93 ± 6.21</td>
<td>10.90 ± 8.48</td>
<td>14.92 ± 8.23</td>
<td>10.20 ± 6.57</td>
<td align="center">-</td>
<td>11.02 ± 9.10</td>
</tr>
<tr>
<td>Asm_90_p11</td>
<td>6.51 ± 3.12</td>
<td>6.83 ± 4.12</td>
<td>12.81 ± 7.41</td>
<td>9.80 ± 7.50</td>
<td>7.83 ± 4.65</td>
<td>9.66 ± 4.73</td>
</tr>
<tr>
<td>Asm_95_p11</td>
<td>9.08 ± 4.55</td>
<td>8.71 ± 5.71</td>
<td>13.87 ± 7.77</td>
<td>9.65 ± 6.09</td>
<td>8.13 ± 4.53</td>
<td>10.30 ± 5.55</td>
</tr>
<tr>
<td>Asm_90_p15</td>
<td>6.53 ± 3.85</td>
<td>9.25 ± 4.54</td>
<td>11.75 ± 6.86</td>
<td>10.33 ± 5.55</td>
<td>8.56 ± 5.91</td>
<td>10.11 ± 7.01</td>
</tr>
<tr>
<td>Asm_95_p15</td>
<td>6.25 ± 4.09</td>
<td>8.84 ± 5.07</td>
<td>11.59 ± 7.05</td>
<td>10.46 ± 5.36</td>
<td>8.47 ± 6.11</td>
<td>9.94 ± 7.36</td>
</tr>
<tr>
<td>Aam_90_5000</td>
<td>6.75 ± 6.84</td>
<td>11.22 ± 7.13</td>
<td>11.61 ± 7.23</td>
<td>10.05 ± 5.65</td>
<td>7.62 ± 5.68</td>
<td>8.81 ± 5.51</td>
</tr>
<tr>
<td>Aam_95_5000</td>
<td>5.06 ± 4.40</td>
<td>10.05 ± 7.29</td>
<td>9.28 ± 6.52</td>
<td>5.32 ± 2.98</td>
<td align="center">-</td>
<td>5.32 ± 4.45</td>
</tr>
<tr>
<td>Aam_90_10000</td>
<td>6.93 ± 7.06</td>
<td>11.82 ± 7.47</td>
<td>11.99 ± 7.46</td>
<td>10.37 ± 5.93</td>
<td>7.78 ± 5.78</td>
<td>8.24 ± 5.19</td>
</tr>
<tr>
<td>Aam_95_10000</td>
<td>4.91 ± 4.19</td>
<td>11.20 ± 7.59</td>
<td>9.79 ± 6.81</td>
<td>7.96 ± 3.97</td>
<td>6.19 ± 4.81</td>
<td>4.97 ± 3.55</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>As aforementioned, active appearance models are also proficient in modelling objects in images and to segment the modelled objects into new images. Texture and appearance modes of variation are more difficult to analyse because some motion artefacts (‘blur effects’) are presented as a result of some inconsistencies of the female subject to sustain the sound, and also because of the inter-subject differences of vocal tract morphologies. The effects of varying the initial three modes of variation in terms of texture and appearance of one of the AAMs built are depicted in <xref ref-type="fig" rid="fig6-0954411911431664">Figure 6</xref>. In this figure, it is possible to observe a few slight movements, which are mostly related to the tongue. The first mode of texture depicts the movement of the lower lips and the enlargement of the tongue in the oral cavity. The second mode of variation describes the tongue’s tip movement to the alveolar region, and the same movement is observed in association with a backward movement of the tongue in the third mode of variation. On the other side, the first mode of variation of appearance describes the enlargement of the tongue in the vertical and horizontal directions in the oral cavity. Conversely, the variation of the second mode demonstrates the forward and backward movements of the tongue associated with the rise of the larynx. Finally, the third mode of variation depicts the forward and backward movements of the tongue in the direction of the palate. These results were obtained considering an AAM capable of explaining 95% of all variance of the vocal tracts under study and using 10 000 pixels in the construction of the texture model.</p>
<fig id="fig6-0954411911431664" position="float">
<label>Figure 6.</label>
<caption>
<p>Influence of the first three modes of texture (left) and appearance (right) variation (<inline-formula id="inline-formula46-0954411911431664">
<mml:math display="inline" id="math51-0954411911431664">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>λ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>) of the active appearance model built ( ± 2SD).</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig6.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig7-0954411911431664">Figure 7</xref> presents the segmentation result obtained using one of the AAMs built on one testing MR image of each subject articulating the consonant /f/. In this figure, one may observe the evolution of the segmentation process through the same active appearance model: the process begins with a rough estimate of the vocal tract in the input image and then deforms it into the final vocal tract configuration. Similarly, the segmentation results obtained by using the model on four other testing MR images are depicted in <xref ref-type="fig" rid="fig8-0954411911431664">Figure 8</xref>, where the first two images are for the female subject and the last image for the male subject during the articulation of the EP speech sounds /v/ and /a/, respectively. Additionally, the values obtained for the mean and standard deviation in order to translate the quality of the segmentation obtained in each testing MR image by the AAMs built are included in <xref ref-type="table" rid="table2-0954411911431664">Table 2</xref>. (Again, for a clearer understanding of the data indicated, the models have been named as <italic>Aam_varianceretained_npixelsused</italic> and cases of segmentation failures are indicated by a dash.) In similarity to the ASMs used, the AAMs built considering 99% of all variance were not able to successfully segment the modelled organ in most of the testing images and, hence, their results were not included in <xref ref-type="table" rid="table2-0954411911431664">Table 2</xref>.</p>
<fig id="fig7-0954411911431664" position="float">
<label>Figure 7.</label>
<caption>
<p>Segmentation process of two test images by the active appearance model built for the vocal tract for sound /f/</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig7.tif"/>
</fig>
<fig id="fig8-0954411911431664" position="float">
<label>Figure 8.</label>
<caption>
<p>Four test images overlapped with the mean shape model built (top row), final results of the segmentation process by the active appearance model built (middle row), and corresponding original images (bottom row). The first two images are for the female subject and the last image for the male subject during the articulation of the EP speech sounds /v/ and /a/, respectively</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig8.tif"/>
</fig>
<p>Through the analysis of the data presented in <xref ref-type="table" rid="table2-0954411911431664">Table 2</xref>, one may conclude that in comparison to the ASMs, the AAMs obtained better results, in other words, inferior errors of segmentation. Furthermore, it is possible to realize that the use of more modes of variation do not always assure the best results. While ASMs presented enhanced performance when 90% of all variance was addressed, AAMs addressing 95% of all variance had a superior performance when compared with the ones attaining 90% of the variance. Another significant result is that the use of 99% of modes regarding all variance translates into an extraordinary rigid model that it is not capable of being adapted to different configurations, and consequently leading to failure in the segmentation of new images.</p>
<p>The experimental findings are also depicted in <xref ref-type="fig" rid="fig9-0954411911431664">Figures 9</xref> and <xref ref-type="fig" rid="fig10-0954411911431664">10</xref>, from which one may verify that the AAMs built performed better than the ASMs used. The mean errors obtained for the female subject by the ASMs varied from 7.25 (Asm_90_p11 Image 2) to 17.72 (Asm_95_p11 Image 3) pixels, and two situations had occurred in which the segmentation failed. However, the mean errors obtained by the AAMs varied from 5.34 (Aam_95_10000 Image 6) to 13.63 (Aam_90_5000 Image 3) pixels, and three unsuccessfully segmentations had occurred. The mean errors obtained for the male subject using the ASMs varied from 6.25 (Asm_95_p15 Image 1) to 15.35 (Asm_90_p7 Image 4) pixels, and one unsuccessfully case had occurred; while using the AAMs, the mean errors varied from 4.91 (Aam_95_10000 Image 1) to 11.99 (Aam_90_10000 Image 3) pixels and the model failed to successfully segment one image.</p>
<fig id="fig9-0954411911431664" position="float">
<label>Figure 9.</label>
<caption>
<p>Mean errors (in pixels) and standard deviations of the segmentations obtained by the deformable models built for the vocal tract of the female subject.</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig9.tif"/>
</fig>
<fig id="fig10-0954411911431664" position="float">
<label>Figure 10.</label>
<caption>
<p>Mean errors (in pixels) and standard deviations of the segmentations obtained by the deformable models built for the vocal tract of the male subject.</p>
</caption>
<graphic xlink:href="10.1177_0954411911431664-fig10.tif"/>
</fig>
</sec>
<sec id="section11-0954411911431664" sec-type="conclusions">
<title>Conclusions</title>
<p>In this work, the automatic study of the vocal tract from 3.0 Tesla MR images was assessed through the application of statistical deformable models, namely active shape models (ASMs) and active appearance models (AAMs). The primary goal focused on the analysis of the vocal tract during the articulation of European Portuguese (EP) sounds, followed by the evaluation of the results concerning the automatic segmentation of the modelled vocal tract in new images.</p>
<p>While ASMs consider the information around each landmark point of the modelled structure, AAMs also use the grey-level information of the structure. Consequently, the former type of models tends to be less efficient than the latter, and this was confirmed in this work. Nevertheless, both ASMs and AAMs obtained remarkable results, both in terms of translating the movements and configurations involved in speech production, as well as in the segmentation of the vocal tract in new images.</p>
<p>One of the premises for acquiring an efficient deformable model, and consequently obtaining good results concerning the segmentation of the modelled structure, is extremely related to the quality of the images to be studied. In this work, the images studied were acquired by a 3.0 Tesla MR system and, with the higher signal-to-noise ratio and resolution, it was expected that better segmentation results can be obtained when compared to the ones achieved in 1.5 Tesla MR images.<sup><xref ref-type="bibr" rid="bibr9-0954411911431664">9</xref>,<xref ref-type="bibr" rid="bibr18-0954411911431664">18</xref>–<xref ref-type="bibr" rid="bibr20-0954411911431664">20</xref></sup> Indeed, in our previous works mean errors rounded to 10 pixels were achieved when 256 × 256 pixels 1.5 Tesla MR images were used, whilst the segmentation results using the 3.0 Tesla MR images led to similar mean errors but in double-sized images (512 × 512 pixels). Hence, the errors obtained by the same models that were built adopting the same modelling conditions were around 50% reduced with the improvement of the image quality.</p>
<p>When compared to previous works<sup><xref ref-type="bibr" rid="bibr9-0954411911431664">9</xref>,<xref ref-type="bibr" rid="bibr18-0954411911431664">18</xref>–<xref ref-type="bibr" rid="bibr20-0954411911431664">20</xref></sup>, another major contribution accomplished by this work concerns the amount of data studied. Here, 25 out of 30 possible EP speech sounds were modelled for two subjects, three measurements (slices) were used for each sound. Thus, using a training image set of 150 MR images, allowed more efficient and accurate models than the ones built so far, as was verified by the experimental findings obtained.</p>
<p>To conclude, from the work described here, one should emphasise that the recent MR imaging systems, in particular the 3.0 Tesla, and the use of the adopted statistical modelling technique have made possible the automatically and realist simulation of the vocal tract during speech production, as well as the efficient segmentation of vocal tract in new images. Therefore, the assessment of the articulators’ positions and movements can be facilitated, contributing, for example, to a better knowledge of the speech production, especially in patients with articulatory disorders, and to build improved computational speech models and devices.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure">
<p>This work was partially carried out under the scope of the project entitled “Methodologies to Analyze Organs from Complex Medical Images – Applications to the Female Pelvic Cavity”, with reference PTDC/EEA-CRO/103320/2008, financially supported by Fundação para a Ciência e Tecnologia - FCT, in Portugal. The first author would like to acknowledge the support of the PhD grant SFRH/BD/28817/2006 from FCT, and the second author would like to express her gratitude for the support of the PhD grant from the Escola Superior de Tecnologia da Saúde do Porto (ESTSP) and the Instituto Politécnico do Porto (IPP), in Portugal.</p>
</fn>
<fn fn-type="conflict">
<p>The authors declare that they do not have any conflict of interests.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0954411911431664">
<label>1.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rokkaku</surname><given-names>M</given-names></name>
<name><surname>Imaizumi</surname><given-names>S</given-names></name>
<name><surname>Niimi</surname><given-names>S</given-names></name>
<name><surname>Kiritani</surname><given-names>S</given-names></name>
</person-group> (<year>1986</year>) <article-title>Measurement of the three-dimensional shape of the vocal tract on the magnetic resonance imaging technique</article-title>. <source>Ann. Bull. RILP</source> <volume>20</volume>: <fpage>47</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr2-0954411911431664">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Baer</surname><given-names>T</given-names></name>
<name><surname>Gore</surname><given-names>JC</given-names></name>
<name><surname>Boyce</surname><given-names>S</given-names></name>
<name><surname>Nye</surname><given-names>PW</given-names></name>
</person-group> (<year>1987</year>) <article-title>Application of MRI to the analysis of speech production</article-title>. <source>Magnetic Resonance Imaging</source> <volume>5</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr3-0954411911431664">
<label>3.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Soquet</surname><given-names>A</given-names></name>
<name><surname>Lecuit</surname><given-names>V</given-names></name>
<name><surname>Metens</surname><given-names>T</given-names></name>
<name><surname>Demolin</surname><given-names>D</given-names></name>
</person-group> (<year>1996</year>) <article-title>From sagittal cut to area function: an RMI investigation</article-title>. In: <conf-name>4th International Conference on Spoken Language Processing (ICSLP 96)</conf-name>, <conf-loc>Philadelphia, USA</conf-loc>, <fpage>1205</fpage>–<lpage>1208</lpage>.</citation>
</ref>
<ref id="bibr4-0954411911431664">
<label>4.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Masaki</surname><given-names>S</given-names></name>
<name><surname>Akahane-Yamad</surname><given-names>R</given-names></name>
<name><surname>Tiede</surname><given-names>M</given-names></name>
<name><surname>Shimada</surname><given-names>Y</given-names></name>
<name><surname>Fujimoto</surname><given-names>I</given-names></name>
</person-group> (<year>1996</year>) <article-title>An MRI-based analysis of the English /r/ an /l/ articulators</article-title>. In: <conf-name>4th International Conference on Spoken Language Processing (ICSLP 96)</conf-name>, <conf-loc>Philadelphia, USA</conf-loc>, <fpage>1581</fpage>–<lpage>1584</lpage>.</citation>
</ref>
<ref id="bibr5-0954411911431664">
<label>5.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Engwall</surname><given-names>O</given-names></name>
<name><surname>Badin</surname><given-names>P</given-names></name>
</person-group> (<year>2000</year>) <article-title>An MRI study of Swedish fricatives: Coarticulatory effects</article-title>. In: <conf-name>5th Seminar On Speech Production: Models And Data</conf-name>, <conf-loc>Munchen, Germany</conf-loc>, <fpage>297</fpage>–<lpage>300</lpage>.</citation>
</ref>
<ref id="bibr6-0954411911431664">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Takemoto</surname><given-names>H</given-names></name>
<name><surname>Kitamura</surname><given-names>T</given-names></name>
<name><surname>Nishimoto</surname><given-names>H</given-names></name>
<name><surname>Honda</surname><given-names>K</given-names></name>
</person-group> (<year>2004</year>) <article-title>A method of tooth superimposition on MRI data for accurate measurement of vocal tract shape and dimensions</article-title>. <source>Acoust. Sci. &amp; Tech</source> <volume>25</volume>(<issue>6</issue>): <fpage>468</fpage>–<lpage>473</lpage>.</citation>
</ref>
<ref id="bibr7-0954411911431664">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Martins</surname><given-names>P</given-names></name>
<name><surname>Carbone</surname><given-names>IC</given-names></name>
<name><surname>Pinto</surname><given-names>A</given-names></name>
<name><surname>Silva</surname><given-names>A</given-names></name>
<name><surname>Teixeira</surname><given-names>AJ</given-names></name>
</person-group> (<year>2008</year>) <article-title>European Portuguese MRI based speech production studies</article-title>. <source>Speech Communication</source> <volume>50</volume>: <fpage>925</fpage>–<lpage>952</lpage>.</citation>
</ref>
<ref id="bibr8-0954411911431664">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ventura</surname><given-names>SR</given-names></name>
<name><surname>Freitas</surname><given-names>DR</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
</person-group> (<year>2009</year>) <article-title>Application of MRI and biomedical engineering in speech production study</article-title>. <source>Computer Methods in Biomechanics and Biomedical Engineering</source> <volume>12</volume>(<issue>6</issue>): <fpage>671</fpage>–<lpage>681</lpage>.</citation>
</ref>
<ref id="bibr9-0954411911431664">
<label>9.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ventura</surname><given-names>SR</given-names></name>
<name><surname>Vasconcelos</surname><given-names>MJM</given-names></name>
<name><surname>Freitas</surname><given-names>DR</given-names></name>
<name><surname>Ramos</surname><given-names>IMAP</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
</person-group> (<year>2011</year>) <article-title>Speaker-specific articulatory assessment and measurements during Portuguese speech production based on magnetic resonance Images</article-title>. In: <source>Language Acquisition</source>, <publisher-name>Nova Science Publishers, Inc. Leslie M. Warfelt</publisher-name>, <publisher-loc>Hauppauge NY, USA</publisher-loc>.</citation>
</ref>
<ref id="bibr10-0954411911431664">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Baer</surname><given-names>T</given-names></name>
<name><surname>Gore</surname><given-names>JC</given-names></name>
<name><surname>Gracco</surname><given-names>LW</given-names></name>
<name><surname>Nye</surname><given-names>PW</given-names></name>
</person-group> (<year>1991</year>) <article-title>Analysis of vocal tract shape and dimensions using Magnetic Resonance Imaging: Vowels</article-title>. <source>Journal of the Acoustic Society of America</source> <volume>90</volume>(<issue>2</issue>): <fpage>799</fpage>–<lpage>828</lpage>.</citation>
</ref>
<ref id="bibr11-0954411911431664">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Narayanan</surname><given-names>S</given-names></name>
<name><surname>Alwan</surname><given-names>A</given-names></name>
<name><surname>Haker</surname><given-names>K</given-names></name>
</person-group>. (<year>1995</year>) <article-title>An articulatory study of fricative consonants using Magnetic Resonance Imaging</article-title>. <source>Journal of the Acoustic Society of America</source> <volume>98</volume>(<issue>3</issue>): <fpage>1325</fpage>–<lpage>1347</lpage>.</citation>
</ref>
<ref id="bibr12-0954411911431664">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bresh</surname><given-names>E</given-names></name>
<name><surname>Nielsen</surname><given-names>J</given-names></name>
<name><surname>Nayak</surname><given-names>K</given-names></name>
<name><surname>Narayanan</surname><given-names>S</given-names></name>
</person-group> (<year>2006</year>) <article-title>Synchronized and noise-robust. audio recordings during realtime MRI scans</article-title>. <source>Journal of the Acoustic Society of America</source>, <volume>120</volume>(<issue>4</issue>): <fpage>1791</fpage>–<lpage>1794</lpage>.</citation>
</ref>
<ref id="bibr13-0954411911431664">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parthasarathy</surname><given-names>V</given-names></name>
<name><surname>Prince</surname><given-names>JL</given-names></name>
<name><surname>Stone</surname><given-names>M</given-names></name>
<name><surname>Murano</surname><given-names>EZ</given-names></name>
<name><surname>Nessaiver</surname><given-names>M</given-names></name>
</person-group> (<year>2007</year>) <article-title>Measuring tongue motion from tagged cine-MRI using harmonic phase (HARP)</article-title>. <source>Journal of the Acoustic Society of America</source> <volume>121</volume>(<issue>1</issue>): <fpage>491</fpage>–<lpage>504</lpage>.</citation>
</ref>
<ref id="bibr14-0954411911431664">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>M</given-names></name>
<name><surname>Davis</surname><given-names>E</given-names></name>
<name><surname>Douglas</surname><given-names>A</given-names></name>
<name><surname>Nessaiver</surname><given-names>M</given-names></name>
<name><surname>Gullapalli</surname><given-names>R</given-names></name>
<name><surname>Levine</surname><given-names>W</given-names></name>
<name><surname>Lundberg</surname><given-names>A</given-names></name>
</person-group> (<year>2001</year>) <article-title>Modeling tongue surface contours from Cine-MRI images</article-title>. <source>Journal of Speech, Language, and Hearing Research</source> <volume>44</volume>(<issue>5</issue>): <fpage>1026</fpage>–<lpage>1040</lpage>.</citation>
</ref>
<ref id="bibr15-0954411911431664">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Masaki</surname><given-names>S</given-names></name>
<name><surname>Nota</surname><given-names>Y</given-names></name>
<name><surname>Takano</surname><given-names>S</given-names></name>
<name><surname>Takemoto</surname><given-names>H</given-names></name>
<name><surname>Kitamura</surname><given-names>T</given-names></name>
<name><surname>Honda</surname><given-names>K</given-names></name>
</person-group> (<year>2008</year>) <article-title>Integrated magnetic resonance imaging methods for speech science and technology</article-title>. <source>The Journal of the Acoustical Society of America</source> <volume>123</volume>(<issue>5</issue>): <fpage>3734</fpage>.</citation>
</ref>
<ref id="bibr16-0954411911431664">
<label>16.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Nieto-Castanon</surname><given-names>A</given-names></name>
<name><surname>Guenther</surname><given-names>FH</given-names></name>
</person-group> (<year>1999</year>) <article-title>Constructing speaker-specific articulatory vocal tract models for testing speech motor control hypotheses</article-title>. In: <conf-name>14th International Congress of Phonetic Sciences (ICPhS 99)</conf-name>, <conf-loc>San Francisco, USA</conf-loc>, <fpage>2271</fpage>–<lpage>2274</lpage>.</citation>
</ref>
<ref id="bibr17-0954411911431664">
<label>17.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Apostol</surname><given-names>L</given-names></name>
<name><surname>Perrier</surname><given-names>P</given-names></name>
<name><surname>Raybaudi</surname><given-names>M</given-names></name>
<name><surname>Segebarth</surname><given-names>C</given-names></name>
</person-group> (<year>1999</year>) <article-title>3D geometry of the vocal tract and inter-speaker variability</article-title>. In: <conf-name>14th International Congress of Phonetic Sciences (ICPhS 99)</conf-name>, <conf-loc>San Francisco, USA</conf-loc>, <fpage>443</fpage>–<lpage>446</lpage></citation>
</ref>
<ref id="bibr18-0954411911431664">
<label>18.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ventura</surname><given-names>SR</given-names></name>
<name><surname>Freitas</surname><given-names>DR</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
</person-group> (<year>2010</year>) <article-title>Toward Dynamic Magnetic Resonance Imaging of the Vocal Tract During Speech Production</article-title>. <source>Journal of Voice</source>, <volume>25</volume>(<issue>4</issue>): <fpage>511</fpage>–<lpage>518</lpage>, <fpage>201</fpage>.</citation>
</ref>
<ref id="bibr19-0954411911431664">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vasconcelos</surname><given-names>MJM</given-names></name>
<name><surname>Ventura</surname><given-names>SR</given-names></name>
<name><surname>Freitas</surname><given-names>DR</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
</person-group>. <article-title>Towards the Automatic Study of the Vocal Tract From Magnetic Resonance Images</article-title>. <source>Journal of Voice</source>, <volume>25</volume>(<issue>6</issue>): <fpage>732</fpage>–<lpage>742</lpage>, <year>2011</year>.</citation>
</ref>
<ref id="bibr20-0954411911431664">
<label>20.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vasconcelos</surname><given-names>MJM</given-names></name>
<name><surname>Ventura</surname><given-names>SR</given-names></name>
<name><surname>Freitas</surname><given-names>DR</given-names></name>
<name><surname>Tavares</surname><given-names>JM</given-names></name>
</person-group> (<year>2010</year>) <article-title>Using statistical deformable models to reconstruct vocal tract shape from magnetic resonance images</article-title>. <source>Proc. Inst. Mechanical Engineers, Part H: J. Engineering in Medicine</source> <volume>224</volume>(<issue>10</issue>): <fpage>1153</fpage>–<lpage>1163</lpage>.</citation>
</ref>
<ref id="bibr21-0954411911431664">
<label>21.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vasconcelos</surname><given-names>MJM</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
</person-group> (<year>2008</year>) <article-title>Methods to automatically built point distribution models for objects like hand palms and faces represented in images</article-title>. <source>Computer Modeling in Engineering &amp; Sciences</source> <volume>36</volume>(<issue>3</issue>): <fpage>213</fpage>–<lpage>241</lpage>.</citation>
</ref>
<ref id="bibr22-0954411911431664">
<label>22.</label>
<citation citation-type="thesis">
<person-group person-group-type="author">
<name><surname>Schaap</surname><given-names>J</given-names></name>
</person-group> (<year>1999</year>) <article-title>3D point distribution models and their application in medical image segmentation using active shape models: A pilot study</article-title>. <comment>MSc thesis</comment>, <publisher-name>Delft University of Technology</publisher-name>, <publisher-loc>Delft</publisher-loc>.</citation>
</ref>
<ref id="bibr23-0954411911431664">
<label>23.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ma</surname><given-names>Z</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
<name><surname>Jorge</surname><given-names>RN</given-names></name>
<name><surname>Mascarenhas</surname><given-names>T</given-names></name>
</person-group>. (<year>2010</year>) <article-title>A review of algorithms for medical image segmentation and their applications to the female pelvic cavity</article-title>. <source>Computer Methods in Biomechanics and Biomedical Engineering</source> <volume>13</volume>(<issue>2</issue>): <fpage>235</fpage>–<lpage>246</lpage>.</citation>
</ref>
<ref id="bibr24-0954411911431664">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kass</surname><given-names>M</given-names></name>
<name><surname>Witkin</surname><given-names>A</given-names></name>
<name><surname>Terzopoulos</surname><given-names>D</given-names></name>
</person-group> (<year>1987</year>) <article-title>Snakes: Active Contour Models</article-title>. <source>International Journal of Computer Vision</source> <volume>1</volume>, <fpage>321</fpage>–<lpage>331</lpage>.</citation>
</ref>
<ref id="bibr25-0954411911431664">
<label>25.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yuille</surname><given-names>AL</given-names></name>
<name><surname>Cohen</surname><given-names>D</given-names></name>
<name><surname>Hallinan</surname><given-names>P</given-names></name>
</person-group> (<year>1992</year>) <article-title>Feature extraction from faces using deformable templates</article-title>. <source>International Journal of Computer Vision</source> <volume>8</volume>: <fpage>104</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr26-0954411911431664">
<label>26.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gonçalves</surname><given-names>PCT</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
<name><surname>Jorge</surname><given-names>RMN</given-names></name>
</person-group> (<year>2008</year>) <article-title>Segmentation and simulation of objects represented in images using physical principles</article-title>. <source>Computer Modeling in Engineering &amp; Sciences</source> <volume>32</volume>(<issue>1</issue>): <fpage>45</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr27-0954411911431664">
<label>27.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Cootes</surname><given-names>TF</given-names></name>
<name><surname>Taylor</surname><given-names>CJ</given-names></name>
<name><surname>Cooper</surname><given-names>DH</given-names></name>
<name><surname>Graham</surname><given-names>J</given-names></name>
</person-group> (<year>1992</year>) <article-title>Training models of shape from sets of examples</article-title>. In: <conf-name>Proceedings of the British Machine Vision Conference</conf-name>, <conf-loc>Leeds, UK</conf-loc>, <fpage>9</fpage>–<lpage>18</lpage>.</citation>
</ref>
<ref id="bibr28-0954411911431664">
<label>28.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Cootes</surname><given-names>TF</given-names></name>
<name><surname>Taylor</surname><given-names>CJ</given-names></name>
</person-group> (<year>1993</year>) <article-title>Active shape model search using local grey-level models: A quantitative evaluation</article-title>. In: <conf-name>British Machine Vision Conference</conf-name>, <conf-loc>Guildford: BMVA Press</conf-loc>, <fpage>639</fpage>–<lpage>648</lpage>.</citation>
</ref>
<ref id="bibr29-0954411911431664">
<label>29.</label>
<citation citation-type="confproc">
<person-group person-group-type="editor">
<name><surname>Cootes</surname><given-names>TF</given-names></name>
<name><surname>Edwards</surname><given-names>G</given-names></name>
</person-group> (<year>1998</year>) <article-title>Active appearance models</article-title>. In: <conf-name>European Conference on Computer Vision</conf-name>, <conf-loc>Freiburg, Germany</conf-loc>, <volume>2</volume>, <fpage>484</fpage>–<lpage>498</lpage>.</citation>
</ref>
<ref id="bibr30-0954411911431664">
<label>30.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Oliveira</surname><given-names>FPM</given-names></name>
<name><surname>Tavares</surname><given-names>JMRS</given-names></name>
</person-group> (<year>2008</year>) <article-title>Algorithm of dynamic programming for optimization of the global matching between two contours defined by ordered points</article-title>. <source>Computer Modeling in Engineering &amp; Sciences</source> <volume>31</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr31-0954411911431664">
<label>31.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Cootes</surname><given-names>TF</given-names></name>
<name><surname>Taylor</surname><given-names>CJ</given-names></name>
<name><surname>Lanitis</surname><given-names>A</given-names></name>
</person-group> (<year>1994</year>) <article-title>Active shape models: Evaluation of a multi-resolution method for improving image search</article-title>. In: <conf-name>British Machine Vision Conference</conf-name>, <year>1994</year>, <conf-loc>York, England, BMVA</conf-loc>, <volume>1</volume>, <fpage>327</fpage>–<lpage>336</lpage>.</citation>
</ref>
<ref id="bibr32-0954411911431664">
<label>32.</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Hamarneh</surname><given-names>G</given-names></name>
</person-group> (<year>1999</year>) <source>ASM (MATLAB)</source>. [<access-date>accessed in 2011</access-date>], <comment>Available from: <ext-link ext-link-type="uri" xlink:href="http://www.cs.sfu.ca/~hamarneh/software/code/asm.zip">http://www.cs.sfu.ca/~hamarneh/software/code/asm.zip</ext-link></comment> (<access-date>accessed November 2011</access-date>).</citation>
</ref>
<ref id="bibr33-0954411911431664">
<label>33.</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Cootes</surname><given-names>TF</given-names></name>
</person-group> (<year>2004</year>) <source>Build_aam</source>. [<access-date>accessed in 2011</access-date>], <comment>Available from: <ext-link ext-link-type="uri" xlink:href="http://www.wiau.man.ac.uk/~bim/software/am_tools_doc/download_win.html">http://www.wiau.man.ac.uk/~bim/software/am_tools_doc/download_win.html</ext-link></comment> (<access-date>accessed November 2011</access-date>).</citation>
</ref>
</ref-list>
</back>
</article>