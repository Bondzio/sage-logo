<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">HPC</journal-id>
<journal-id journal-id-type="hwp">sphpc</journal-id>
<journal-title>The International Journal of High Performance Computing Applications</journal-title>
<issn pub-type="ppub">1094-3420</issn>
<issn pub-type="epub">1741-2846</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1094342013495304</article-id>
<article-id pub-id-type="publisher-id">10.1177_1094342013495304</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Special Issue Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Energy efficiency in high-performance computing with and without knowledge of applications and services</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Diouri</surname>
<given-names>Mohammed EM</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013495304">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chetsa</surname>
<given-names>Ghislain L. Tsafack</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013495304">1</xref>
<xref ref-type="aff" rid="aff2-1094342013495304">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Glück</surname>
<given-names>Olivier</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013495304">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Lefèvre</surname>
<given-names>Laurent</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013495304">1</xref>
<xref ref-type="corresp" rid="corresp1-1094342013495304"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pierson</surname>
<given-names>Jean-Marc</given-names>
</name>
<xref ref-type="aff" rid="aff2-1094342013495304">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Stolf</surname>
<given-names>Patricia </given-names>
</name>
<xref ref-type="aff" rid="aff2-1094342013495304">
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Da Costa</surname>
<given-names>Georges</given-names>
</name>
<xref ref-type="aff" rid="aff2-1094342013495304">2</xref>
</contrib>
<bio>
<title>Author biographies</title>
<p>
<italic>Mohammed E.M. Diouri</italic> received both his engineering high school degree from National Institute of Applied Science in Lyon (INSA Lyon), France, and his MSc in Computer Science, specializing in Networking from INSA Lyon in 2010. He is currently a PhD student in the Department of Computer Science at Ecole Normale Superieure de Lyon. He is a member of the INRIA Avalon team (Algorithms and Software Architectures for Service Oriented Platforms) in the LIP laboratory in Lyon. His research interests are in the areas of high-performance computing, Grid and distributed computing and networking, green and energy efficient computing and networking, high-performance network protocols, and network services.</p>
<p>
<italic>Ghislain L. Tsafack Chetsa</italic> received a BS degree in mathematics and computer science from Dschang University, Cameroon, in 2006, and an MS degree from the Francophone Institute for Computer Science, Vietnam, in 2010. Prior to receiving the MS degree, he received a Maitrise in computer science from the University of Yaoundé I, Cameroon, in 2007. He has been working toward a PhD degree in computer science at Ecole Normale Superieure of Lyon, LIP lab, and Paul Sabatier University, IRIT lab. His major research interests include power-aware computing and communication in high-performance networking infrastructures, delay/disruption-tolerant networking and network services.</p>
<p>
<italic>Olivier Glück</italic> received a PhD degree in computer science from the Paris 6 University in 2002. Since 2003, he has been an Associate Professor of the Lyon 1 University and a permanent member of the LIP laboratory of Ecole Normale Superieure de Lyon, France. His research interests include high-performance computing, high-speed networks for clusters and Grids, scalable protocols and libraries for distributed computing, green networking and computing. During his PhD he designed and developed a high-performance implementation of the MPI Standard on a parallel computer made of clusters of workstations, providing a remote-write communication primitive. Between 2003 and 2012, he was a member of the INRIA RESO team. He has mainly worked on an efficient distributed file system within a Myrinet Cluster and on the interactions between MPI applications and TCP on Grids. Since 2012, he has been a member of the INRIA AVALON team.</p>
<p>
<italic>Laurent Lefèvre</italic> obtained his PhD in Computer Science in January 1997 at LIP Laboratory (Laboratoire Informatique du Parallelisme) in ENS-Lyon (Ecole Normale Superieure), France. From 1997 to 2001, he was Assistant Professor in computer science in Lyon 1 University and a member of the RESAM Laboratory (High Performance Networks and Multimedia Application Support Lab). Since 2001, he has been a Research Associate in computer science at INRIA (the French Institute for Research in Computer Science and Control). He is a member of the INRIA AVALON team (Algorithms and Software Architectures for Distributed and HPC systems) at the LIP laboratory in Lyon, France. His research interests focus on green and energy efficient computing and networking. He has organized several conferences in high-performance networking and computing and he is a member of several program committees. He has co-authored more than 100 papers published in refereed journals and conference proceedings. He participates in several national and European projects on energy efficiency. For more information, see http://perso.ens-lyon.fr/laurent.lefevre/.</p>
<p>
<italic>Jean-Marc Pierson</italic> has served as a Full Professor in Computer Science at the University of Toulouse (France) since 2006. He received his PhD from the ENS-Lyon, France in 1996. He was an Associate Professor at the University Littoral Cote-d’Opale (1997–2001) in Calais, then at INSA-Lyon (2001–2006). He is a member of the IRIT Laboratory and Chair of the SEPIA Team on distributed systems. His main interests are related to large-scale distributed systems. He serves on several PCs and editorial boards in the cloud, Grid, pervasive, and energy-aware computing areas. Recently, his researches focus on energy-aware distributed systems, in particular monitoring, job placement and scheduling, virtual machine techniques, green networking, autonomic computing, mathematical modelling. He is chairing the EU funded COST IC804 Action on ‘Energy Efficiency in Large Scale Distributed Systems’ and participates in several national and European projects on energy efficiency. For more information, see <ext-link ext-link-type="uri" xlink:href="http://www.irit.fr/∼Jean-Marc.Pierson/">http://www.irit.fr/∼Jean-Marc.Pierson/</ext-link>.</p>
<p>
<italic>Patricia Stolf</italic> has been an Assistant Professor since 2005. She teaches at the Toulouse University (France). She obtained a PhD in 2004 in the LAAS-CNRS laboratory (Toulouse, France) on tasks scheduling on clusters for remote services with quality of service. She now works in the IRIT laboratory in the SEPIA team and is currently working in the field of distributed algorithms and autonomic computing in large-scale distributed systems such as the Grid and clouds. She studies resource management, load-balancing, energy-aware autonomic systems and energy and thermal-aware task scheduling. She is involved in different research projects: in the ACTION COST IC0804 ‘Energy Efficiency in Large Scale Distributed Systems’, in the European CoolEmAll project and in the national ANR SOP project.</p>
<p>
<italic>Georges Da Costa</italic> is a permanent Assistant Professor in Computer Science at the University of Toulouse. He received his PhD from the LIG HPC research laboratory (Grenoble, France) in 2005. He is a member of the IRIT Laboratory. His main interests are related to large-scale distributed systems, algorithmic, performance evaluation and energy-aware systems. He is Work Package leader of the European project CoolEmAll which aims at providing advanced simulation, visualization and decision support tools along with blueprints of computing building blocks for modular data centre environment. He is working group chair of the European COST0804 Action on ‘Energy efficiency in large scale distributed systems’. His research currently focuses on energy aware distributed systems. He serves on several program committees in the energy-aware systems, cluster, Grid, cloud and peer-to-peer fields. His research highlights are Grid cluster and cloud computing, hybrid computing (CPU/GPU), large-scale energy aware distributed systems, performance evaluation and ambient systems.</p>
</bio>
</contrib-group>
<aff id="aff1-1094342013495304">
<label>1</label>INRIA Avalon Team, LIP Laboratory (UMR CNRS, ENS, INRIA, UCB), Ecole Normale Supérieure de Lyon, Université de Lyon, France</aff>
<aff id="aff2-1094342013495304">
<label>2</label>IRIT (UMR CNRS), University of Toulouse, Toulouse, France</aff>
<author-notes>
<corresp id="corresp1-1094342013495304">Laurent Lefèvre, INRIA Avalon Team, LIP Laboratory (UMR CNRS, ENS, INRIA, UCB), Ecole Normale Supérieure de Lyon, Université de Lyon, 69364 Lyon Cedex 07, France. Email: <email>laurent.lefevre@ens-lyon.fr</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2013</year>
</pub-date>
<volume>27</volume>
<issue>3</issue>
<issue-title>Special Issue section on CCDSC 2012 Workshop</issue-title>
<fpage>232</fpage>
<lpage>243</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The constant demand of raw performance in high-performance computing (HPC) often leads to over-provisioning in high-performance systems which in turn can result in a colossal energy waste due to workload/application variation over time. Proposing energy efficient solutions in the context of large-scale HPC is a real, unavoidable challenge. This article explores two alternative approaches (with or without knowledge of applications and services) dealing with the same goal: reducing the energy usage of large-scale infrastructures which support HPC applications. This article describes the first approach, with knowledge of applications and services, which enables users to choose the less consuming implementation of services. Based on the energy consumption estimation of the different implementations (protocols) for each service, this approach is validated on the case of fault tolerance service in HPC. The ‘without knowledge’ approach allows some intelligent framework to observe the life of HPC systems and proposes some energy reduction schemes. This framework automatically estimates the energy consumption of the HPC system in order to apply power saving schemes. Both approaches are experimentally evaluated and analysed in terms of energy efficiency.</p>
</abstract>
<kwd-group>
<kwd>energy efficiency</kwd>
<kwd>workload characterization</kwd>
<kwd>HPC applications</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1094342013495304">
<title>1. Introduction</title>
<p>High-performance computing (HPC) systems are used to run a wide range of scientific applications from various domains including car and aircraft design, prediction of severe weather phenomena and seismic waves. To enable this, there is a constant demand for raw performance in HPC systems which often leads to their over-provisioning that in turn can result in a colossal energy waste due to workload/application variation over time. Energy consumption becomes a major problem as we live now in an energy-scarce world; and HPC centres have an important role to play due to the rise of scientific needs. This is evidenced by the Green500 list,<sup>
<xref ref-type="fn" rid="fn1-1094342013495304">1</xref>
</sup> which provides a ranking of the greenest HPC systems around the world as opposed to the Top500,<sup>
<xref ref-type="fn" rid="fn2-1094342013495304">2</xref>
</sup> which emphasizes the performance of those systems. Consequently, designing energy efficient solutions in the context of large-scale HPC is a real, unavoidable challenge.</p>
<p>This article explores two approaches for supporting energy efficiency in HPC systems. The first approach assumes complete knowledge of applications and services whereas the second does not. However, they are complementary and serve the same goal: intelligently estimating resource and energy usage before applying green levers (shutdown/slowdown) in order to reduce the electricity usage of large-scale HPC infrastructures.</p>
<p>In the era of petascale and yet to come exascale infrastructures, designing scalable, reliable and energy efficient applications remains a real challenge. HPC applications along with associated services (fault tolerance, data management, visualization, etc.), can become difficult to program and optimize. Thanks to the programmer’s expertise about designed applications and services, we can avoid over provisioning of resources during the life of HPC infrastructures.</p>
<p>Designers seeking to reduce energy usage should be helped in choosing adequate protocols, services and the best implementations of their applications with regard to the targeted infrastructure. In other words, evaluating and estimating the energy impact of applications and services can help users in choosing a more energy efficient version of the application at hand. This article presents a methodology and a framework which allows energy usage estimations of a set of HPC services. Thanks to these estimations, the framework can help users to determine the least consuming version of the services depending on their application requirements. To validate our framework, real experiments on a set of protocols of the fault tolerance service are proposed and analysed.</p>
<p>Alternatively, one can suggest that designing large-scale HPC applications and services is becoming too complex and difficult. Exploring autonomous solutions able to propose and apply energy reduction solutions must be investigated. Several scientific applications, throughout their life cycle, exhibit diverse behaviours also known as phases. These phases are not only dissimilar because of their resource utilization pattern, but also because the energy consumed by the application in different phases is likely to be different as well.</p>
<p>As a second major contribution of this article, we present and implement an online methodology for phase detection and identification in HPC systems without having any knowledge of the running applications. The approach tracks phases, characterizes them and takes advantage of our partial phase recognition technique. It automatically applies power saving schemes in order to improve energy efficiency of the HPC system. Validations with a set of selected applications are presented and analysed.</p>
<p>The remainder of the article is organized as follows. Section 2 describes the considered approach when some knowledge is available on applications and services. This section focuses on the fault tolerance service in HPC. Section 3 analyses the alternative approach where energy efficiency can be obtained in an automatic external manner when no knowledge is available on the applications. Finally, Section 4 concludes this article.</p>
</sec>
<sec id="section2-1094342013495304">
<title>2. Energy efficiency in HPC with knowledge of applications and services</title>
<p>Large-scale HPC applications need to meet with several challenges (fault tolerance, data processing, etc.). In order to overcome these challenges, several services need to be run harmoniously together with extreme-scale scientific applications.</p>
<p>In our study, we identify the following services:
<list list-type="bullet">
<list-item>
<p>Checkpointing: Performed during the normal functioning of the application, it consists of storing a snapshot image of the current application state.</p>
</list-item>
<list-item>
<p>Recovery: In case of failure, it consists of restarting the execution of the application from the last checkpoint.</p>
</list-item>
<list-item>
<p>Data exchanges: Scattering data over several processes; broadcasting data to all processes; gathering data over several processes; retrieving specific data among all processes.</p>
</list-item>
<list-item>
<p>Visualizing the application logs in real time.</p>
</list-item>
<list-item>
<p>Monitoring the hardware resources that are involved in the extreme-scale system.</p>
</list-item>
</list>
</p>
<p>For each service presented above, several implementations are possible. Even if our approach aims to cover all kinds of applications and all of the services, this section focuses on the checkpointing service as an example (<xref ref-type="bibr" rid="bibr9-1094342013495304">Diouri et al., 2013a</xref>). As concerns checkpointing, applications can be run either with coordinated, uncoordinated, or hierarchical checkpointing. These protocols rely on checkpointing, and in order to obtain a coherent global state this checkpointing is associated with message logging in uncoordinated protocols (Guermouche et al.) and with process coordination in coordinated protocols (<xref ref-type="bibr" rid="bibr4-1094342013495304">Chandy and Lamport, 1985</xref>). Hybrid protocols propose to use coordinated protocol within the same cluster and message logging for messages exchanged between clusters (Ropars et al.). In uncoordinated protocols, the crashed processes are re-executed from their last checkpoint image to reach the state immediately preceding the crash in order to recover a coherent condition with non-crashed processes (<xref ref-type="bibr" rid="bibr2-1094342013495304">Bouteiller et al., 2006</xref>). In coordinated protocols, all of the processes must rollback to the previous coherent state, meaning to the last full completed coordinated checkpointing.</p>
<p>The less energy consuming fault tolerance protocol is not always the same depending on the executed application and on the execution context. Thus, to consume less energy is to let the user choose the less consuming protocol. To this end, we propose to take into account the application features and the user requirements in order to provide an energy estimation of the different implementations of the services required by the user (<xref ref-type="bibr" rid="bibr8-1094342013495304">Diouri et al., 2012</xref>).</p>
<p>Making an accurate estimation of the energy consumption due to a specific implementation of a given service is very complex as it depends on several parameters that are related not only to the protocols but also to the application features, and to the hardware used. Thus, in order to accurately estimate the energy consumption due to a specific implementation of a fault tolerance protocol, our energy estimator needs to take into consideration all of the protocol parameters (checkpointing interval, checkpointing storage destination, etc.), all of the application specifications (number of processes, number and size of exchanged messages, volume of data written/read by each process, etc.) and all of the hardware parameters (number of cores per node, memory architecture, type of hard disk drives (HDDs), etc.). We consider that a parameter is a variable of our estimator only if a variation of this parameter generates a significant variation of the energy consumption while all of the other parameters are fixed. In order to take into consideration all of the parameters, our estimator incorporates an automated calibration component.</p>
<p>
<xref ref-type="fig" rid="fig1-1094342013495304">Figure 1</xref> shows the components of our estimator framework and their interactions. As an input, the estimator component gathers information related to the execution context and to the application the user would like to run. As an output, the calibrator component provides the calibration data on which our framework relies on to estimate the energy consumption of services.</p>
<fig id="fig1-1094342013495304" position="float">
<label>Figure 1.</label>
<caption>
<p>Estimator components and interactions.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig1.tif"/>
</fig>
<p>Finally, in order to achieve important energy savings, we propose to shutdown or slowdown resources during their idle and active waiting periods. The shutdown approach is promoted only if the idle or active waiting period is long enough, that is greater than the minimum threshold from which it becomes gainful to turn off a resource and turn it on again (<xref ref-type="bibr" rid="bibr18-1094342013495304">Orgerie et al., 2008</xref>). The shutdown and slowdown approaches are proposed at the component level, meaning that we consider whether to switch off or slowdown CPU/GPU cores, network interfaces or storage medium.</p>
<sec id="section3-1094342013495304">
<title>2.1. Calibration approach</title>
<p>The goal of the calibration process is to gather energy knowledge of all of the identified operations (e.g. checkpointing, coordination, logging, etc.) according to the hardware used in the supercomputer. Indeed, the energy consumption of a fault tolerance protocol may be different depending on the hardware used. The goal of our calibration approach is to take into consideration in our energy estimations the specific hardware used.</p>
<p>A basic operation is a task <inline-formula id="inline-formula2-1094342013495304">
<mml:math id="mml-inline2-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula> which is characterized by a constant power consumption. To this end, a set of simple benchmarks extract the energy consumption <inline-formula id="inline-formula3-1094342013495304">
<mml:math id="mml-inline3-1094342013495304">
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula> of the basic operations encountered in the different versions of the same service. The energy consumption of a node <inline-formula id="inline-formula4-1094342013495304">
<mml:math id="mml-inline4-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula> performing a basic operation <inline-formula id="inline-formula5-1094342013495304">
<mml:math id="mml-inline5-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula6-1094342013495304">
<mml:math id="mml-inline6-1094342013495304">
<mml:msubsup>
<mml:mi>E</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>. Here <inline-formula id="inline-formula7-1094342013495304">
<mml:math id="mml-inline7-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the time required to perform <inline-formula id="inline-formula8-1094342013495304">
<mml:math id="mml-inline8-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula> by the node <inline-formula id="inline-formula9-1094342013495304">
<mml:math id="mml-inline9-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula>. <inline-formula id="inline-formula10-1094342013495304">
<mml:math id="mml-inline10-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the power consumption of the node <inline-formula id="inline-formula11-1094342013495304">
<mml:math id="mml-inline11-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula> during <inline-formula id="inline-formula12-1094342013495304">
<mml:math id="mml-inline12-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>. Thus, for each node <inline-formula id="inline-formula13-1094342013495304">
<mml:math id="mml-inline13-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula>, we need to get the power consumption <inline-formula id="inline-formula14-1094342013495304">
<mml:math id="mml-inline14-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>, and the execution time <inline-formula id="inline-formula15-1094342013495304">
<mml:math id="mml-inline15-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> of each basic operation.</p>
<p>The power consumption of an operation <inline-formula id="inline-formula16-1094342013495304">
<mml:math id="mml-inline16-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula17-1094342013495304">
<mml:math id="mml-inline17-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>. Here <inline-formula id="inline-formula18-1094342013495304">
<mml:math id="mml-inline18-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the power consumption when the node <inline-formula id="inline-formula19-1094342013495304">
<mml:math id="mml-inline19-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula> is idle and <inline-formula id="inline-formula20-1094342013495304">
<mml:math id="mml-inline20-1094342013495304">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is its extra power consumption due to the basic operation. In our paper (<xref ref-type="bibr" rid="bibr10-1094342013495304">Diouri et al., 2013b</xref>), we showed that <inline-formula id="inline-formula21-1094342013495304">
<mml:math id="mml-inline21-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> may be different even for identical nodes. Thus, we calibrate <inline-formula id="inline-formula22-1094342013495304">
<mml:math id="mml-inline22-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> by measuring the power consumption of each node while it is idle. In addition, we measure <inline-formula id="inline-formula23-1094342013495304">
<mml:math id="mml-inline23-1094342013495304">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> for each node <inline-formula id="inline-formula24-1094342013495304">
<mml:math id="mml-inline24-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula> and during each basic operation <inline-formula id="inline-formula25-1094342013495304">
<mml:math id="mml-inline25-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula>. In order to measure <inline-formula id="inline-formula26-1094342013495304">
<mml:math id="mml-inline26-1094342013495304">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> experimentally, we isolate each basic operation by instrumenting the implementation of each version of the service that we consider, and we use a power meter which provides power measurements with a high sampling rate (e.g. 1 measurement per second).</p>
<p>To put it into perspective, we provide the calibration results of a cluster constituted of 16 Dell R720 nodes. Each node contains: 2 Intel Xeon CPU 2.3 GHz processors, with 6 cores each; 32 GB of memory; a 10 Gigabit Ethernet network; a SCSI hard disk with a storage capacity of 598 GB. First, we measure the idle power consumption of each node (<xref ref-type="fig" rid="fig2-1094342013495304">Figure 2</xref>), then we measure the extra power consumption <inline-formula id="inline-formula27-1094342013495304">
<mml:math id="mml-inline27-1094342013495304">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> of all of the basic operations found in the fault tolerance protocols (<xref ref-type="fig" rid="fig3-1094342013495304">Figure 3</xref>). In order to collect such power measurements, we used an energy-sensing infrastructure of external power meters from the SME Omegawatt. This energy-sensing infrastructure enables us to get the instantaneous consumption in Watts, at each second for each monitored node (<xref ref-type="bibr" rid="bibr7-1094342013495304">Dias de Assuncao et al., 2010</xref>). As each node has 12 cores, we calibrated the extra power cost by assuming that 1, 4, 8 or 12 processes are running the same operation at the same time.</p>
<fig id="fig2-1094342013495304" position="float">
<label>Figure 2.</label>
<caption>
<p>Idle power measurements.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig2.tif"/>
</fig>
<fig id="fig3-1094342013495304" position="float">
<label>Figure 3.</label>
<caption>
<p>Mean extra power measurements.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig3.tif"/>
</fig>
<p>
<xref ref-type="fig" rid="fig2-1094342013495304">Figure 2</xref> confirms that <inline-formula id="inline-formula28-1094342013495304">
<mml:math id="mml-inline28-1094342013495304">
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is different for identical nodes. This highlights the need to perform such power calibration even for nodes within the same cluster. <xref ref-type="fig" rid="fig3-1094342013495304">Figure 3</xref> shows the mean extra power measurements over all of the nodes. Compared with the average values plotted in <xref ref-type="fig" rid="fig3-1094342013495304">Figure 3</xref>, the variances are very low. This suggests that <inline-formula id="inline-formula29-1094342013495304">
<mml:math id="mml-inline29-1094342013495304">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is almost the same for the nodes of the cluster that we monitored. <xref ref-type="fig" rid="fig3-1094342013495304">Figure 3</xref> also shows that the most power consuming operations are the RAM logging and the active polling that occurs during the coordination if processes are not synchronized. We also note that for these two basic operations, the extra power consumption varies with the number of cores per node that perform the same operation. This is because more cores are running intensively for these two operations.</p>
<p>For each operation <inline-formula id="inline-formula30-1094342013495304">
<mml:math id="mml-inline30-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula31-1094342013495304">
<mml:math id="mml-inline31-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> depends on different parameters. For a given node <inline-formula id="inline-formula32-1094342013495304">
<mml:math id="mml-inline32-1094342013495304">
<mml:mi>i</mml:mi>
</mml:math>
</inline-formula>, the time required for checkpointing a volume of data, of for logging a message, is<disp-formula id="disp-formula1-1094342013495304">
<label>1</label>
<mml:math id="mml-disp1-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-1094342013495304" xlink:href="10.1177_1094342013495304-eq1.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula33-1094342013495304">
<mml:math id="mml-inline33-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the time to access the storage media where the checkpoint will be stored, <inline-formula id="inline-formula34-1094342013495304">
<mml:math id="mml-inline34-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the time to write the data on a given storage media and <inline-formula id="inline-formula35-1094342013495304">
<mml:math id="mml-inline35-1094342013495304">
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the transmission rate of the storage media. Here <inline-formula id="inline-formula36-1094342013495304">
<mml:math id="mml-inline36-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula37-1094342013495304">
<mml:math id="mml-inline37-1094342013495304">
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> are almost constant when we consider volumes of data of the same order of magnitude.</p>
<p>The coordinated checkpointing at the system level requires an extra synchronization between the processes. Therefore, the time for a process coordination is<disp-formula id="disp-formula2-1094342013495304">
<label>2</label>
<mml:math id="mml-disp2-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">+</mml:mo>
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
<graphic alternate-form-of="disp-formula2-1094342013495304" xlink:href="10.1177_1094342013495304-eq2.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula38-1094342013495304">
<mml:math id="mml-inline38-1094342013495304">
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula> is the time to exchange a marker among all the processes, <inline-formula id="inline-formula39-1094342013495304">
<mml:math id="mml-inline39-1094342013495304">
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula> depends on the number of processes to synchronize and the number of processes per node and <inline-formula id="inline-formula40-1094342013495304">
<mml:math id="mml-inline40-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is the time necessary to finish transfers of inflight messages at the coordination time.</p>
<p>In order to calibrate <inline-formula id="inline-formula41-1094342013495304">
<mml:math id="mml-inline41-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>, our estimator automatically runs a simple benchmark that measures the execution time for different varying parameters, namely <inline-formula id="inline-formula42-1094342013495304">
<mml:math id="mml-inline42-1094342013495304">
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>.</p>
<p>In order to take into consideration the eventual contention that may occur on the same storage medium, we also perform this calibration for different numbers of processes per node which are running the same operation at the same time. We perform this calibration process for all the different storage media (RAM, HDD, SSD, etc.) that are available in the supercomputer.</p>
<p>
<xref ref-type="fig" rid="fig4-1094342013495304">Figures 4</xref>, <xref ref-type="fig" rid="fig5-1094342013495304">5</xref> and <xref ref-type="fig" rid="fig6-1094342013495304">6</xref> present the calibration of <inline-formula id="inline-formula43-1094342013495304">
<mml:math id="mml-inline43-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> for the 16-node cluster considering different basic operations: checkpointing on HDD, message logging on RAM and process synchronization. In <xref ref-type="fig" rid="fig4-1094342013495304">Figures 4</xref> and <xref ref-type="fig" rid="fig5-1094342013495304">5</xref> the standard deviations (error bars) due to the computation of the average values over all the nodes of our cluster are also represented. These standard deviations are invisible since the differences between the checkpointing and logging times over all the nodes are insignificant.</p>
<fig id="fig4-1094342013495304" position="float">
<label>Figure 4.</label>
<caption>
<p>Calibration of <inline-formula id="inline-formula44-1094342013495304">
<mml:math id="mml-inline44-1094342013495304">
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>k</mml:mi>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig4.tif"/>
</fig>
<fig id="fig5-1094342013495304" position="float">
<label>Figure 5.</label>
<caption>
<p>Calibration of <inline-formula id="inline-formula45-1094342013495304">
<mml:math id="mml-inline45-1094342013495304">
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>l</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>g</mml:mi>
<mml:mi>g</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig5.tif"/>
</fig>
<fig id="fig6-1094342013495304" position="float">
<label>Figure 6.</label>
<caption>
<p>Calibration of <inline-formula id="inline-formula46-1094342013495304">
<mml:math id="mml-inline46-1094342013495304">
<mml:msup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig6.tif"/>
</fig>
<p>From <xref ref-type="fig" rid="fig4-1094342013495304">Figure 4</xref>, we note that when several cores are logging at the same time, the execution time is longer: simultaneous accesses on HDD create I/O contentions. That is the reason why we need to calibrate the execution time for different numbers of processes per node. As concerns message logging on RAM, we observe in <xref ref-type="fig" rid="fig5-1094342013495304">Figure 5</xref> that logging time does not vary when the number of cores per node is changed. This is because there is no contention when several cores perform RAM access simultaneously.</p>
<p>
<xref ref-type="fig" rid="fig6-1094342013495304">Figure 6</xref> shows that the synchronization time is slightly higher when we consider more processes per node. Synchronizing processes that are on the same node requires much less time than processes on distinct nodes. This is due to the network transmission rate that is much lower than the transmission rate within the same node.</p>
</sec>
<sec id="section4-1094342013495304">
<title>2.2. Estimation methodology</title>
<p>Once this calibration is completed, our framework can estimate the energy consumption of the different versions of the studied service. For each operation <inline-formula id="inline-formula47-1094342013495304">
<mml:math id="mml-inline47-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula48-1094342013495304">
<mml:math id="mml-inline48-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> depends on different parameters related to the application and the execution context. This information is collected from the user as an input by the calibrator.</p>
<p>To estimate the energy consumption of checkpointing, the estimator component collects from the user the total memory size required by the application to run, the total number of nodes and the number of processes per node. From this information, the estimator computes the mean memory size <inline-formula id="inline-formula49-1094342013495304">
<mml:math id="mml-inline49-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> required by each node. The estimator also collects the number of checkpoints to perform during the application execution. In addition, it collects from the calibrator the checkpoint times corresponding to the calibrated checkpoint sizes. The estimator calculates the checkpoint times <inline-formula id="inline-formula50-1094342013495304">
<mml:math id="mml-inline50-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>k</mml:mi>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> corresponding to <inline-formula id="inline-formula51-1094342013495304">
<mml:math id="mml-inline51-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>. As shown in Section 2.1, most of the execution time models are linear. Therefore, if <inline-formula id="inline-formula52-1094342013495304">
<mml:math id="mml-inline52-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> is not the size recorded by the calibrator, the estimator computes the equation that gives <inline-formula id="inline-formula53-1094342013495304">
<mml:math id="mml-inline53-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>k</mml:mi>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> according to <inline-formula id="inline-formula54-1094342013495304">
<mml:math id="mml-inline54-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>, and adjusts the equation using the linear least squares method (<xref ref-type="bibr" rid="bibr19-1094342013495304">Rao et al., 1999</xref>): <inline-formula id="inline-formula55-1094342013495304">
<mml:math id="mml-inline55-1094342013495304">
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi mathvariant="italic">β</mml:mi>
</mml:math>
</inline-formula>. In the checkpointing operation, <inline-formula id="inline-formula56-1094342013495304">
<mml:math id="mml-inline56-1094342013495304">
<mml:mi mathvariant="italic">α</mml:mi>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula57-1094342013495304">
<mml:math id="mml-inline57-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> while <inline-formula id="inline-formula58-1094342013495304">
<mml:math id="mml-inline58-1094342013495304">
<mml:mi mathvariant="italic">β</mml:mi>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula59-1094342013495304">
<mml:math id="mml-inline59-1094342013495304">
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:msubsup>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
</inline-formula>. Here <inline-formula id="inline-formula60-1094342013495304">
<mml:math id="mml-inline60-1094342013495304">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula61-1094342013495304">
<mml:math id="mml-inline61-1094342013495304">
<mml:msup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula>.</p>
<p>To estimate the energy consumed by message logging, the estimator collects from the user the number of processes per node, and the total number and size of the messages sent during the application. From this information, it computes the mean volume of data <inline-formula id="inline-formula62-1094342013495304">
<mml:math id="mml-inline62-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> sent (so logged) by each node. Similarly to checkpointing, it collects from the calibrator the logging time <inline-formula id="inline-formula63-1094342013495304">
<mml:math id="mml-inline63-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>l</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>g</mml:mi>
<mml:mi>g</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
</mml:math>
</inline-formula> corresponding to <inline-formula id="inline-formula64-1094342013495304">
<mml:math id="mml-inline64-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> for each node and according to the number of processes per node.</p>
<p>To estimate the energy consumed by coordination, the estimator uses the mean message size <inline-formula id="inline-formula65-1094342013495304">
<mml:math id="mml-inline65-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>g</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula> as the total size of messages divided by the total number of messages. It also uses the number of checkpoints <inline-formula id="inline-formula66-1094342013495304">
<mml:math id="mml-inline66-1094342013495304">
<mml:mi>C</mml:mi>
</mml:math>
</inline-formula>, the total number of nodes <inline-formula id="inline-formula67-1094342013495304">
<mml:math id="mml-inline67-1094342013495304">
<mml:mi>N</mml:mi>
</mml:math>
</inline-formula> and the number of processes per node that are provided for message logging and checkpointing estimations. From the calibration output, it collects the synchronization time <inline-formula id="inline-formula68-1094342013495304">
<mml:math id="mml-inline68-1094342013495304">
<mml:msub>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> corresponding to the number of processes per node and the total number of nodes specified by the user. Here <inline-formula id="inline-formula69-1094342013495304">
<mml:math id="mml-inline69-1094342013495304">
<mml:msub>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> corresponds to one synchronization among all of the processes. Similarly to checkpointing, the estimator calculates the message transfer time <inline-formula id="inline-formula70-1094342013495304">
<mml:math id="mml-inline70-1094342013495304">
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
</mml:math>
</inline-formula> corresponding to the mean message size <inline-formula id="inline-formula71-1094342013495304">
<mml:math id="mml-inline71-1094342013495304">
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>g</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:math>
</inline-formula>.</p>
<p>The estimated energy of one basic operation <inline-formula id="inline-formula72-1094342013495304">
<mml:math id="mml-inline72-1094342013495304">
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:math>
</inline-formula> (checkpointing, logging, polling or synchronization) is<disp-formula id="disp-formula3-1094342013495304">
<mml:math id="mml-disp3-1094342013495304">
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:munderover>
<mml:mo movablelimits="false" stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
</mml:mrow>
<mml:msubsup>
<mml:mi>E</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:munderover>
<mml:mo movablelimits="false" stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
</mml:mrow>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:msubsup>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>o</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-1094342013495304" xlink:href="10.1177_1094342013495304-eq3.tif"/>
</disp-formula>
</p>
<p>The total estimated energy consumption of checkpointing is obtained by multiplying <inline-formula id="inline-formula73-1094342013495304">
<mml:math id="mml-inline73-1094342013495304">
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>k</mml:mi>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msup>
</mml:math>
</inline-formula> by the number of checkpoints <inline-formula id="inline-formula74-1094342013495304">
<mml:math id="mml-inline74-1094342013495304">
<mml:mi>C</mml:mi>
</mml:math>
</inline-formula>. The estimated energy of all coordinations is calculated as follows:<disp-formula id="disp-formula4-1094342013495304">
<mml:math id="mml-disp4-1094342013495304">
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>s</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>l</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">+</mml:mo>
<mml:msup>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>y</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>h</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>o</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula4-1094342013495304" xlink:href="10.1177_1094342013495304-eq4.tif"/>
</disp-formula>
</p>
<p>To estimate the energy consumed by hierarchical checkpointing, the estimator collects from the user the composition of each cluster (i.e. the list of processes in each cluster).</p>
<p>We can obtain the overall energy estimation of the entire checkpointing protocol from the sum of the subcomponent’s energy consumptions. Indeed, checkpointing is a common basic operation for both coordinated, uncoordinated and hierarchical protocols. If we add the energy consumed by the checkpointing to the energy consumption of message logging, we obtain the overall energy consumption of uncoordinated checkpointing. If we add the energy consumption of checkpointing to the energy consumption of coordinations, we obtain the overall energy consumption of coordinated checkpointing.</p>
</sec>
<sec id="section5-1094342013495304">
<title>2.3. Validation of the estimation framework</title>
<p>In this section, we want to compare the energy consumption obtained by our estimator once the calibration is done (but before running the application) to the real energy consumption measured by our energy sensors during the application execution. For these experiments, we use the same cluster as that described in Section 2.1.</p>
<p>We consider 4 HPC applications running over 144 processes (i.e. 12 nodes with 12 cores per node): CM1<sup>
<xref ref-type="fn" rid="fn3-1094342013495304">3</xref>
</sup> with a resolution of <inline-formula id="inline-formula75-1094342013495304">
<mml:math id="mml-inline75-1094342013495304">
<mml:mn>2400</mml:mn>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>2400</mml:mn>
<mml:mo stretchy="false">×</mml:mo>
<mml:mn>40</mml:mn>
</mml:math>
</inline-formula> and 3 NAS Parallel Benchmarks<sup>
<xref ref-type="fn" rid="fn4-1094342013495304">4</xref>
</sup> in Class D (SP, BT and EP). For each application, we measure the total energy consumption of one application execution with and without the basic operations activated in the fault tolerance protocols. To this end, we instrumented the code of fault tolerance protocols and we obtain the energy consumption of each operation. Each energy measurement is done 30 times and we compute the average value. For checkpointing measurements, we consider a checkpoint interval of 120 seconds.</p>
<p>In <xref ref-type="fig" rid="fig7-1094342013495304">Figure 7</xref>, we compare our energy estimations to real measurements. The relative differences between the estimated and the measured energy consumptions are low. Indeed, the worst relative difference that we obtain is 7.5%. This shows that our energy estimations are accurate. This estimation error may be attributed partly to the proposed estimation method but also partly to the measurement error. By providing the average values over 30 measurements, we aimed at reducing the impact of the measurement error.</p>
<fig id="fig7-1094342013495304" position="float">
<label>Figure 7.</label>
<caption>
<p>Relative difference (in %) between the estimated and the measured energy consumption.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig7.tif"/>
</fig>
<fig id="fig8-1094342013495304" position="float">
<label>Figure 8.</label>
<caption>
<p>Estimated energy consumption (in kJ) of high-level operations.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig8.tif"/>
</fig>
<p>In <xref ref-type="fig" rid="fig8-1094342013495304">Figure 8</xref>, we plot the estimated energy consumption computed by our framework for each basic operation and for each application considered. <xref ref-type="fig" rid="fig8-1094342013495304">Figure 8</xref> shows that energy consumption of one operation is not the same from one application to another. For instance, the energy consumption of RAM logging in SP is more important than in EP. In addition, HDD checkpointing in CM1 is 20 times more than in EP.</p>
</sec>
<sec id="section6-1094342013495304">
<title>2.4. Determination of the least energy consuming version of a given service</title>
<p>The results presented in Section 2.3 allow us to address the following question: how our estimator framework can help selecting the lowest energy consuming version of the considered service? To answer this question, the case of the checkpointing service is also taken as an example.</p>
<p>As mentioned before, both uncoordinated and coordinated protocols rely on checkpointing. Checkpointing is combined with message logging in uncoordinated protocols and with coordination in coordinated protocols. Therefore, to compare coordinated and uncoordinated protocols from an energy consumption standpoint, we compare the extra energy consumption of uncoordinated to message logging.</p>
<p>From one application to another the lowest energy consuming protocol is not always the same (see <xref ref-type="fig" rid="fig8-1094342013495304">Figure 8</xref>). Indeed, for BT, SP and CM1, the less energy consuming protocol is the coordinated protocol since the volume of data to log for these applications is relatively important whereas it is the uncoordinated protocol with RAM logging for EP. We also note that for the applications we considered, the uncoordinated protocol with HDD logging is always more energy consuming than the coordinated protocol. By providing such energy estimations before executing the HPC application, we can select the best fault-tolerant protocol in terms of energy consumption.</p>
</sec>
</sec>
<sec id="section7-1094342013495304">
<title>3. Energy efficiency in HPC without knowledge of the applications</title>
<p>HPC systems users generally seek better performance for their applications; consequently, any management policy that aims at reducing the energy consumption should not degrade performance. To mitigate performance degradation while improving energy performance, it is mandatory to understand the behaviour of the system at hand at runtime. Put simply, optimization proposed is closely related to the behaviour of the system. For instance, scaling the CPU frequency down to its minimum when running CPU-bound workloads may cause significant performance degradation, which is unacceptable. Thus, to efficiently optimize a HPC system at runtime, it is necessary to identify the different behaviours known as phases during execution. In this section, we discuss our phase identification approach along with management policies.</p>
<p>The rationale behind this work is that it is possible to improve energy performance of a system with nearly no performance degradation by carefully selecting power saving schemes to apply to the system at a given point in time. Several classical well-known techniques set the CPU frequency according to estimated usage of the processor over a time period (<xref ref-type="bibr" rid="bibr6-1094342013495304">Choi et al., 2006</xref>; <xref ref-type="bibr" rid="bibr13-1094342013495304">Isci et al., 2006</xref>; <xref ref-type="bibr" rid="bibr16-1094342013495304">Lim et al., 2006</xref>; <xref ref-type="bibr" rid="bibr11-1094342013495304">Freeh et al., 2008</xref>; <xref ref-type="bibr" rid="bibr21-1094342013495304">Rountree et al., 2009</xref>). We believe that actions on the system at runtime can result in energy savings provided they are carefully selected. For instance, adjusting the frequency of the processor or the speed of the network interconnect (NIC), switching off memory banks, spinning down disks, and migrating tasks among nodes of the system, are ways of adjusting the system to the actual demand (or applications’ requirements) at runtime.</p>
<p>From what precedes, choosing the appropriate lever (power saving scheme) is critical; an effective way of choosing between the different levers is to first characterize phases or the system’s behaviours so that similar phase patterns can easily be identified with each other. In so doing, a set of power saving schemes deemed efficient both in terms of energy and performance for a given phase can be used for recurring phases. This is accomplished by associating a set of levers to each characterized phase. Details with regards to phase characterization are provided in Section 3.1.</p>
<p>Once phases are characterized, the next step boils down to identifying (still at runtime) recurring phases in order to apply adequate power saving schemes. To accomplish this, we use an approach which we refer to as partial phase recognition. Instead of trying to recognize a complete phase prior to adjusting the system (which might lead to an unexpected outcome, for the phase is already finished), we decide to adjust the system when a certain fraction of a phase has been recognized. This technique is clearly giving false positives (an ongoing phase is recognized as part of a known phase in error), but we argue that the adjustment of the system is beneficial at least for a certain time. When the ongoing phase diverges too much from the recognized phase, another phase can be identified or a new phase characterized. Phase identification and partial recognition are detailed in Section 3.2.</p>
<sec id="section8-1094342013495304">
<title>3.1. Phases tracking and characterizing</title>
<p>Our methodology relies on the concept of an execution vector (EV) which is similar to power vectors (PVs) (<xref ref-type="bibr" rid="bibr14-1094342013495304">Isci and Martonosi, 2003</xref>). An EV is a column vector whose entries are system metrics including hardware performance counters, network bytes sent/received and disk read/write counts. For convenience, we will refer to these system metrics as sensors in the rest of the article. Sensors related to hardware performance counters represents the access rate to a specific hardware register over a given time interval. Likewise, network- and disk-related sensors monitor network and disk activities, respectively. We refer to the literature (Freeh et al., 2008; Lim et al., 2006; Isci et al., 2006; Choi et al., 2006) for selecting sensors related to hardware performance counters, these include: number of instructions, last level cache accesses and misses, branch misses and predictions, etc. The sampling rate corresponding to the time interval after which each sensor is read depends on the granularity. While a larger sampling rate may hide information regarding the system’s behaviour, a smaller sampling rate may incur a non-negligible overhead. In this work we collect one measurement per second. In addition, each EV is timestamped with the time at which it is sampled.</p>
<p>The Manhattan distance between two points in an <inline-formula id="inline-formula76-1094342013495304">
<mml:math id="mml-inline76-1094342013495304">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula>-dimensional space is the distance between them if a grid-like path is followed. It offers the advantage that it does not depend on the translation of the coordinate axes with respect to a coordinate axis, i.e. it weights more heavily differences in each dimension. Properties just mentioned motivate our use of the Manhattan distance as the resemblance or similarity metric between EVs. This similarity is used to cluster EVs along the execution timeline as follows: two consecutive EVs along the execution timeline belong to the same group or are similar if the Manhattan distance between them is bellow a similarity threshold (denoted as <inline-formula id="inline-formula77-1094342013495304">
<mml:math id="mml-inline77-1094342013495304">
<mml:mi>S</mml:mi>
<mml:mi>T</mml:mi>
</mml:math>
</inline-formula> in the following). We define the similarity threshold as a percentage of the maximum known distance between all consecutive EVs (along the execution timeline). For example, given a similarity threshold of 10%, two consecutive EVs belong to the same group if the Manhattan distance between them is less than 10% of the maximum existing distance between all consecutive EVs.</p>
<p>Knowing that the behaviour of the system is relatively stable during a phase and assuming that stability is translated into EVs sampled during the phase, we define a phase as any behaviour delimited by two successive Manhattan distances exceeding the similarity threshold. Therefore, let us consider the graphic of <xref ref-type="fig" rid="fig9-1094342013495304">Figure 9</xref>, where the <inline-formula id="inline-formula78-1094342013495304">
<mml:math id="mml-inline78-1094342013495304">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula>-axis represents the execution timeline; with a similarity threshold of 15%, we can observe 5 phases as indicated by the step function. Note that the threshold varies throughout the system’s lifetime since the maximum existing vector is re-initialized once a phase is detected. It can be seen in <xref ref-type="fig" rid="fig9-1094342013495304">Figure 9</xref> that a phase change is detected when the Manhattan distance between two consecutive EVs exceeds the threshold (which is 15% of the maximum distance between consecutive EVs from the moment at which the last EV of the previous phase was sampled). We can also observe that these phases correspond to variations reported in the access rate of plotted performance counters (only a few performance counters are plotted for the sake of clarity). For this experiment, the system was running a synthetic benchmark which successively runs IS and EP from NPB-3.3 (<xref ref-type="bibr" rid="bibr1-1094342013495304">Bailey et al., 1991</xref>).</p>
<fig id="fig9-1094342013495304" position="float">
<label>Figure 9.</label>
<caption>
<p>Phase identification using similarities between consecutive EVs; steps of the step function indicate phase changes.</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig9.tif"/>
</fig>
<p>The rationale behind phase tracking is the use of characteristics of known phases for optimizing similar phases. An effective phase characterization is therefore needed. To this end, once a phase is detected, we apply principal component analysis (PCA) on the dataset composed of EVs pertaining to that phase. We next keep five sensors among those contributing the least to the first principal axis (FPA) of PCA. Those five sensors serve as characteristic of the corresponding phase. PCA is a variable reduction procedure, and is used for identifying variables that shape the underlying data. In PCA, the first principal component explains the largest variance, which intuitively means that it contains the most information and the last principal component/axis the least. Therefore, we assume that the most important variables are those that contribute the most to the first principal component or axis. In other words, the most contributing variables shape the underlying data, as opposite to the least contributing variables which do not. But the fact that the least contributing variables do not shape the underlying data is also interesting because they eventually shape what is not in the underlying data. Thus, relying on this, we assume that information regarding what the system did not do during a phase can be easily retrieved from sensors contributing the least to the FPA of PCA (since they are meaningless to that phase). A phase is therefore characterized by the five sensors among those contributing the least to the FPA of PCA. These five sensors are not always the same, since the least contributing sensors depend on the activity of the system during the phase. In addition, we summarize each newly detected phase using the closest vector to the centroid of the group of vectors sampled during that phase. The closest vector to the centroid of the group of EV sampled during a phase is referred to as its reference vector.</p>
</sec>
<sec id="section9-1094342013495304">
<title>3.2. Partial phase recognition and system adaptation</title>
<p>A phase cannot be detected unless it is finished, in which case any system adaptation or optimization accordingly is no longer worthwhile. The literature (Lim et al., 2006; Choi et al., 2006) recommends phase prediction. Predicting the next phase allows adapting the system accordingly. Although phase prediction is very effective in some cases, it is not relevant in this context, for we do not have any a priori knowledge of applications sharing the platform. To overcome this limitation, we use partial phase recognition.</p>
<p>Partial phase recognition consists of identifying an ongoing phase (the phase has started and is not yet finished) <inline-formula id="inline-formula79-1094342013495304">
<mml:math id="mml-inline79-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> with a known phase <inline-formula id="inline-formula80-1094342013495304">
<mml:math id="mml-inline80-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> only considering the already executed part of <inline-formula id="inline-formula81-1094342013495304">
<mml:math id="mml-inline81-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>. The already executed part of <inline-formula id="inline-formula82-1094342013495304">
<mml:math id="mml-inline82-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> expressed as a percentage of the length (duration) of <inline-formula id="inline-formula83-1094342013495304">
<mml:math id="mml-inline83-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> is referred to as the recognition threshold <inline-formula id="inline-formula84-1094342013495304">
<mml:math id="mml-inline84-1094342013495304">
<mml:mi>R</mml:mi>
<mml:mi>T</mml:mi>
</mml:math>
</inline-formula>. Thus, with a <inline-formula id="inline-formula85-1094342013495304">
<mml:math id="mml-inline85-1094342013495304">
<mml:mi>R</mml:mi>
<mml:mi>T</mml:mi>
</mml:math>
</inline-formula>% recognition threshold, and assuming that the reference vector of <inline-formula id="inline-formula86-1094342013495304">
<mml:math id="mml-inline86-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> is <inline-formula id="inline-formula87-1094342013495304">
<mml:math id="mml-inline87-1094342013495304">
<mml:mi>E</mml:mi>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> and that its length is <inline-formula id="inline-formula88-1094342013495304">
<mml:math id="mml-inline88-1094342013495304">
<mml:msub>
<mml:mi>n</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>, an ongoing phase <inline-formula id="inline-formula89-1094342013495304">
<mml:math id="mml-inline89-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> is identified with <inline-formula id="inline-formula90-1094342013495304">
<mml:math id="mml-inline90-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> if the Manhattan distance between <inline-formula id="inline-formula91-1094342013495304">
<mml:math id="mml-inline91-1094342013495304">
<mml:mi>E</mml:mi>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> and each EV pertaining to the already executed part of <inline-formula id="inline-formula92-1094342013495304">
<mml:math id="mml-inline92-1094342013495304">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> (corresponding in length to <inline-formula id="inline-formula93-1094342013495304">
<mml:math id="mml-inline93-1094342013495304">
<mml:mi>R</mml:mi>
<mml:mi>T</mml:mi>
</mml:math>
</inline-formula>% of <inline-formula id="inline-formula94-1094342013495304">
<mml:math id="mml-inline94-1094342013495304">
<mml:msub>
<mml:mi>n</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>) are within the similarity threshold <inline-formula id="inline-formula95-1094342013495304">
<mml:math id="mml-inline95-1094342013495304">
<mml:mi>S</mml:mi>
<mml:mi>T</mml:mi>
</mml:math>
</inline-formula>.</p>
<p>As a use case of our phase tracking methodology, we use the coupling of phase tracking and partial phase recognition to guide on-the-fly system adaptation considering the processor. We define three computational levels according to the characteristics of the workload: ‘high’ for compute intensive workload, ‘medium’ for memory intensive workloads and ‘low’ for non-memory/non-compute intensive workloads.</p>
<p>As mentioned earlier in this article, PCA is applied to vectors belonging to any newly created phase for selecting five sensors which are used as phase characteristics. These characteristics are translated into system adaptation as detailed in <xref ref-type="table" rid="table1-1094342013495304">Table 1</xref>. Let us comment on a few entries of that table: workloads/applications with frequent cache references and misses are likely to be memory bound. In our case, having these sensors (cache reference and cache misses) selected from PCA indicates that the workload is not memory bound. If in addition that workload does not issue a high I/O rate (presence of I/O related sensors in the first column), then we assume that it is CPU-bound; consequently, the frequency of the processor can be scaled to its maximum, the disk sent to sleep and the speed of the interconnect scaled down. For the second line of <xref ref-type="table" rid="table1-1094342013495304">Table 1</xref>, the characteristics do not include any I/O related sensor, this implies that the system was running an I/O intensive workload; thus, the processor’s speed can be set to its minimum. Note in passing that changing the disk’s state from sleep to active does not appear in <xref ref-type="table" rid="table1-1094342013495304">Table 1</xref>, this is because the disk automatically becomes active when accessed.</p>
<table-wrap id="table1-1094342013495304" position="float">
<label>Table 1.</label>
<caption>
<p>Translation of phase characteristics into system adaptation.</p>
</caption>
<graphic alternate-form-of="table1-1094342013495304" xlink:href="10.1177_1094342013495304-table1.tif"/>
<table>
<thead>
<tr>
<th>Sensors selected from PCA for phase characterization</th>
<th>Decisions</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cache_references;</td>
<td>CPU frequency set to its maximum;</td>
</tr>
<tr>
<td>I/O related sensors;</td>
<td>Spin the disk down;</td>
</tr>
<tr>
<td>Cache_misses</td>
<td>Network speed scaled down</td>
</tr>
<tr>
<td>No I/O related sensors</td>
<td>CPU frequency scaled down;</td>
</tr>
<tr>
<td>
</td>
<td>Network speed scaled up</td>
</tr>
<tr>
<td>Instructions</td>
<td>CPU frequency set to its minimum;</td>
</tr>
<tr>
<td>Last level cache misses (llc)</td>
<td>Network speed scaled up</td>
</tr>
<tr>
<td>Instructions or llc;</td>
<td>CPU frequency set to its average value;</td>
</tr>
<tr>
<td>I/O related sensors;</td>
<td>Network speed scaled down;</td>
</tr>
<tr>
<td>I/O related sensors</td>
<td>Spin the disk down</td>
</tr>
<tr>
<td>I/O related sensors</td>
<td>CPU frequency set to its maximum;</td>
</tr>
<tr>
<td>(low computation and communication-intensive)</td>
<td>Network speed scaled up</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section10-1094342013495304">
<title>3.3. Experimental validations</title>
<p>Our evaluation support is a 15-node cluster set up on the Grid5000 (<xref ref-type="bibr" rid="bibr3-1094342013495304">Cappello et al., 2005</xref>) French large-scale experimental platform. Each node is an Intel Xeon X3440 with 4 cores and 16 GB of RAM with frequencies ranging from 1.20 to 2.53 GHz. In our experiments, low computational level always sets the CPU frequency to the lowest available (1.20 GHz), whereas high and medium computational levels set the CPU frequency to the highest available (2.53 GHz) and 2.00 GHz, respectively. Each node uses its own hard drive which supports active, ready and standby states. Infiniband-20G is used for interconnecting nodes. The Linux kernel 2.6.35 is installed on each node where perf event is used to read the hardware monitoring counters. MPICH is used as MPI library. Lower–Upper Gauss–Seidel solver (LU), Scalar Penta-diagonal solver (SP), and Block Tridiagonal solver (BT) from NPB-3.3 and a real-life application, the Advance Research WRF (WRF-ARW) (<xref ref-type="bibr" rid="bibr22-1094342013495304">Skamarock et al., 2005</xref>) model, are used for the experiments. Class C of NPB benchmarks are used (compiled with default options). WRF-ARW is a fully compressible conservative-form non-hydrostatic atmospheric model. It uses an explicit time-splitting integration technique to efficiently integrate the Euler equation. We monitored each node power usage with one sample per second using a power distribution unit.</p>
<p>To evaluate our management policy, we consider three basic configurations of the monitored cluster: (i) on-demand configuration in which Linux’s ‘on-demand’ CPU frequency scaling governor is enabled on all of the nodes of the cluster; (ii) the ‘performance’ configuration sets each node’s CPU frequency scaling governor to ‘performance’; (iii) the ‘phase-detect’ configuration corresponds to the configuration in which we detect phases, identify them using partial recognition and apply green levers accordingly. <xref ref-type="fig" rid="fig10-1094342013495304">Figure 10</xref>(a) presents the normalized average energy consumption of the overall cluster for each application under the three clusters’ configurations, whereas <xref ref-type="fig" rid="fig9-1094342013495304">Figure 9</xref> shows their execution time respectively. The results are normalized with respect to the baseline execution (on demand) and averaged over 20 executions of each workload in each configuration. <xref ref-type="fig" rid="fig10-1094342013495304">Figure 10</xref>(a) and (<xref ref-type="fig" rid="fig10-1094342013495304">b</xref>) indicate that our management policy (phase-detect) consumes on average 15% less energy than ‘performance’ and ‘on-demand’ while offering the same performance for the real life application WRF-ARW. For LU, BT and SP the average energy gain ranges from 3% to 6%. Overall, the maximum amount of possible energy savings depends on the workload at hand and was 19% for WRF-ARW. We are currently investigating whether we can do better with complete knowledge of the application.</p>
<fig id="fig10-1094342013495304" position="float">
<label>Figure 10.</label>
<caption>
<p>Phase tracking and partial recognition guided processor adaptation results. (They are averaged over 20 executions of each workload under each system configuration; they are normalized with respect to baseline execution ‘on demand’.) (a) Average energy consumed by each application under different configurations. (b) Normalized performance of each application under different configurations (less than 100% means performance degradation).</p>
</caption>
<graphic xlink:href="10.1177_1094342013495304-fig10.tif"/>
</fig>
<p>From <xref ref-type="fig" rid="fig10-1094342013495304">Figure 10</xref>(b), we notice a performance loss of less than 3% for LU and BT (performances are evaluated in terms of execution time). Bad performance with benchmarks come from the fact that some phases were wrongly identified as being memory intensive. Nevertheless, these results are similar to those observed in earlier work (<xref ref-type="bibr" rid="bibr17-1094342013495304">Lively et al., 2011</xref>). In addition, these applications do not offer many opportunities for saving energy without degrading performance. In contrast, the numerical weather forecast model (WRF-ARW) has load imbalance which can help to reduce its energy consumption without a significant impact on its performance (in terms of execution time) (<xref ref-type="bibr" rid="bibr5-1094342013495304">Chen et al., 2005</xref>; <xref ref-type="bibr" rid="bibr15-1094342013495304">Kimura et al., 2006</xref>).</p>
<p>Above results demonstrate the effectiveness of our systems’ energy management scheme based on phase detection and partial recognition. Our system performs better than Linux’s governor because Linux’s on-demand governor will not scale the CPU frequency down unless the system’s load decreases below a threshold. The problem at this point is that the CPU load generally remains very high for memory intensive workloads/phases that do not require the full computational power. In this particular scenario, network and disk bound phases are too short (from milliseconds to a few seconds) and are often considered as boundaries of memory or compute intensive phases. For this reason, we turned our focus to the processor. Therefore, the energy reduction mainly came from scaling the CPU down in phases suspected to be memory bound.</p>
</sec>
</sec>
<sec id="section11-1094342013495304">
<title>4. Conclusion</title>
<p>Energy efficiency is becoming one of the mandatory parameters that must be taken into account when operating HPC systems. In this article, we describe and analyse some approaches to reduce the energy consumed by HPC systems at runtime. HPC applications and services becoming increasingly complex and difficult to program in the era of petascale and yet to come exascale; application designers have to confront resource usage, stability, scalability and performance.</p>
<p>This article shows the importance of helping users in making the right choices in terms of energy efficient services. We present a framework that estimates the energy consumption of fault tolerance protocols. In our study, we consider the three families of fault tolerance protocols: coordinated, uncoordinated and hierarchical. To provide accurate estimations, the framework relies on an energy calibration of the execution platform and a user description of the execution settings. Thanks to our approach based on a calibration process, this framework can be used in any energy monitored supercomputer. We have shown in this article that the energy estimations provided by the framework are accurate. By estimating the energy consumption of fault tolerance protocols, such a framework allows selection of the best fault tolerant protocol in terms of energy consumption without pre-executing the application. A direct application of our energy estimating framework is the energy consumption optimization of fault tolerance protocols.</p>
<p>In addition, proposing solutions that could apply power saving schemes (shutdown or slowdown of resources) without human intervention and knowledge is a promising approach for automatic large-scale energy reduction. This article proposes an approach based on: (i) phase detection which attempts to detect system phases or behaviour changes; (ii) phase characterization which associates a characterization label to each phase (the label indicates the type of workload); (iii) finally, phase identification and system reconfiguration attempt to identify recurring phases and make reactive decisions when the identification process is successful. Such an approach allows additional energy gains.</p>
<p>Future works will cover the estimation and calibration of a larger set of services (data exchanges, visualization, monitoring). We also plan to investigate combined solutions in order to automatically improve HPC systems deploying energy efficient applications and services.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure" id="fn5-1094342013495304">
<label>Funding</label>
<p>This work is supported by the INRIA large-scale initiative Hemera focused on ‘developing large scale parallel and distributed experiments’. Experiments presented in this article were carried out using the Grid’5000 experimental testbed, being developed under the INRIA ALADDIN development action with support from CNRS, RENATER and several Universities as well as other funding bodies (see http://www.grid5000.fr).</p>
</fn>
</fn-group>
<notes>
<title>Notes</title>
<fn-group>
<fn fn-type="other" id="fn1-1094342013495304">
<label>1</label>
<p>See <ext-link ext-link-type="uri" xlink:href="http://www.green500.org">http://www.green500.org</ext-link>.</p>
</fn>
<fn fn-type="other" id="fn2-1094342013495304">
<label>2</label>
<p>See <ext-link ext-link-type="uri" xlink:href="http://www.top500.org">http://www.top500.org</ext-link>.</p>
</fn>
<fn fn-type="other" id="fn3-1094342013495304">
<label>3</label>
<p>Cloud Model 1; see <ext-link ext-link-type="uri" xlink:href="http://www.mmm.ucar.edu/people/bryan/cm1/">http://www.mmm.ucar.edu/people/bryan/cm1/</ext-link>.</p>
</fn>
<fn fn-type="other" id="fn4-1094342013495304">
<label>4</label>
<p>See <ext-link ext-link-type="uri" xlink:href="http://www.nas.nasa.gov/publications/npb.html">http://www.nas.nasa.gov/publications/npb.html</ext-link>.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bailey</surname>
<given-names>DH</given-names>
</name>
<name>
<surname>Barszcz</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Barton</surname>
<given-names>JT</given-names>
</name>
<etal/>
</person-group> (<year>1991</year>) <article-title>The NAS Parallel Benchmarks—summary and preliminary results</article-title>. In: <source>Supercomputing ‘91: Proceedings of the 1991 ACM/IEEE Conference on Supercomputing</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>, pp. <fpage>158</fpage>–<lpage>165</lpage>. <comment>DOI: 10.1145/125826.125925</comment>. </citation>
</ref>
<ref id="bibr2-1094342013495304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bouteiller</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Hérault</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Krawezik</surname>
<given-names>G</given-names>
</name>
<etal/>
</person-group> (<year>2006</year>) <article-title>MPICH-V project: A multiprotocol automatic fault-tolerant MPI</article-title>. <source>International Journal of High Performance Computing Applications</source> <volume>20</volume>(<issue>3</issue>): <fpage>319</fpage>–<lpage>333</lpage>.</citation>
</ref>
<ref id="bibr3-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cappello</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Caron</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Daydé</surname>
<given-names>MJ</given-names>
</name>
<etal/>
</person-group> (<year>2005</year>) <article-title>Grid'5000: A large scale and highly reconfigurable grid experimental testbed</article-title>. In: <source>6th IEEE/ACM International Workshop on Grid Computing, Grid’2005</source>, <publisher-loc>Seattle, WA</publisher-loc>. </citation>
</ref>
<ref id="bibr4-1094342013495304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chandy</surname>
<given-names>KM</given-names>
</name>
<name>
<surname>Lamport</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>1985</year>) <article-title>Distributed snapshots: Determining global states of distributed systems</article-title>. <source>ACM Transactions on Computer Systems</source> <volume>3</volume>(<issue>1</issue>): <fpage>63</fpage>–<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr5-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Chen</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Malkowski</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Kandemir</surname>
<given-names>MT</given-names>
</name>
<etal/>
</person-group> (<year>2005</year>) <article-title>Reducing power with performance constraints for parallel sparse applications</article-title>. In: <source>International Parallel and Distributed Processing Symposium (IPDPS)</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE Computer Society</publisher-name>.</citation>
</ref>
<ref id="bibr6-1094342013495304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Choi</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Soma</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Pedram</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Fine-grained dynamic voltage and frequency scaling for precise energy and performance tradeoff based on the ratio of off-chip access to on-chip computation times</article-title>. <source>Transactions on Computer-Aided Design of Integrated Circuits and Systems</source> <volume>24</volume>(<issue>1</issue>): <fpage>18</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr7-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Dias de Assuncao</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Gelas</surname>
<given-names>JP</given-names>
</name>
<name>
<surname>Lefèvre</surname>
<given-names>L</given-names>
</name>
<etal/>
</person-group> (<year>2010</year>) <article-title>The green Grid5000: Instrumenting a Grid with energy sensors</article-title>. In: <source>5th International Workshop on Distributed Cooperative Laboratories: Instrumenting the Grid (INGRID 2010)</source>, <publisher-loc>Poznan, Poland</publisher-loc>.</citation>
</ref>
<ref id="bibr8-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Diouri</surname>
<given-names>MEM</given-names>
</name>
<name>
<surname>Glück</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Lefèvre</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>Towards a novel smart and energy-aware service-oriented manager for extreme-scale applications</article-title>. In: <source>1st International Workshop on Power-friendly Grid Computing (PFGC), co-located with the 3rd International Green Computing Conference (IGCC 2012)</source>, <comment>San Jose, CA, 4–8 June 2012</comment>, pp. <fpage>1</fpage>–<lpage>6</lpage>.</citation>
</ref>
<ref id="bibr9-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Diouri</surname>
<given-names>MEM</given-names>
</name>
<name>
<surname>Glück</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Lefèvre</surname>
<given-names>L</given-names>
</name>
<etal/>
</person-group> (<year>2013a</year>) <article-title>ECOFIT: A framework to estimate energy consumption of fault tolerance protocols for HPC applications</article-title>. In: <source>13th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid’13)</source>, <publisher-loc>Delft, The Netherlands</publisher-loc>.</citation>
</ref>
<ref id="bibr10-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Diouri</surname>
<given-names>MEM</given-names>
</name>
<name>
<surname>Glück</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Lefèvre</surname>
<given-names>L</given-names>
</name>
<etal/>
</person-group> (<year>2013b</year>) <article-title>Your cluster is not power homogeneous: Take care when designing green schedulers!</article-title> In: <source>4th IEEE International Green Computing Conference (IGCC’13)</source>, <comment>Arlington, VA, 27–29 June 2013</comment>.</citation>
</ref>
<ref id="bibr11-1094342013495304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Freeh</surname>
<given-names>VW</given-names>
</name>
<name>
<surname>Kappiah</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Lowenthal</surname>
<given-names>DK</given-names>
</name>
<etal/>
</person-group> (<year>2008</year>) <article-title>Just-in-time dynamic voltage scaling: Exploiting inter-node slack to save energy in MPI programs</article-title>. <source>Journal of Parallel and Distributed Computing</source> <volume>68</volume>(<issue>9</issue>): <fpage>1175</fpage>–<lpage>1185</lpage>.</citation>
</ref>
<ref id="bibr12-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Guermouche</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Ropars</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Brunet</surname>
<given-names>E</given-names>
</name>
<etal/>
</person-group> (<year>2011</year>) <article-title>Uncoordinated checkpointing without domino effect for send-deterministic MPI applications</article-title>. In: <source>25th IEEE International Symposium on Parallel and Distributed Processing (IPDPS 2011)</source>, <comment>Anchorage, AK, 16–20 May 2011</comment>, pp. <fpage>989</fpage>–<lpage>1000</lpage>.</citation>
</ref>
<ref id="bibr13-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Isci</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Contreras</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Martonosi</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Live, runtime phase monitoring and prediction on real systems with application to dynamic power management</article-title>. In: <source>Proceedings of the 39th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 39)</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE Computer Society</publisher-name>, pp. <fpage>359</fpage>–<lpage>370</lpage>.</citation>
</ref>
<ref id="bibr14-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Isci</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Martonosi</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2003</year>) <article-title>Identifying program power phase behavior using power vectors</article-title>. In: <source>Workshop on Workload Characterization</source>.</citation>
</ref>
<ref id="bibr15-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kimura</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Sato</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Hotta</surname>
<given-names>Y</given-names>
</name>
<etal/>
</person-group> (<year>2006</year>) <article-title>Emprical study on reducing energy of parallel programs using slack reclamation by DVFS in a power-scalable high performance cluster</article-title>. In: <source>IEEE International Conference on Cluster Computing (CLUSTER)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>.</citation>
</ref>
<ref id="bibr16-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lim</surname>
<given-names>MY</given-names>
</name>
<name>
<surname>Freeh</surname>
<given-names>VW</given-names>
</name>
<name>
<surname>Lowenthal</surname>
<given-names>DK</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Adaptive, transparent frequency and voltage scaling of communication phases in MPI programs</article-title>. In: <source>Proceedings of the 2006 ACM/IEEE Conference on Supercomputing (SC ‘06)</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>.</citation>
</ref>
<ref id="bibr17-1094342013495304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lively</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Taylor</surname>
<given-names>V</given-names>
</name>
<etal/>
</person-group> (<year>2011</year>) <article-title>Energy and performance characteristics of different parallel implementations of scientific applications on multicore systems</article-title>. <source>International Journal High Performance Computing Applications</source> <volume>25</volume>(<issue>3</issue>): <fpage>342</fpage>–<lpage>350</lpage>. <comment>DOI: 10.1177/1094342011414749</comment>.</citation>
</ref>
<ref id="bibr18-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Orgerie</surname>
<given-names>AC</given-names>
</name>
<name>
<surname>Lefevre</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Gelas</surname>
<given-names>JP</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Save Watts in your Grid: Green strategies for energy-aware framework in large scale distributed systems</article-title>. In: <source>ICPADS 2008: The 14th IEEE International Conference on Parallel and Distributed Systems</source>, <publisher-loc>Melbourne, Australia</publisher-loc>.</citation>
</ref>
<ref id="bibr19-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rao</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Toutenburg</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Fieger</surname>
<given-names>A</given-names>
</name>
<etal/>
</person-group> (<year>1999</year>) <source>Linear models: Least squares and alternatives (Springer Series in Statistics)</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr20-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Ropars</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Guermouche</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Uçar</surname>
<given-names>B</given-names>
</name>
<etal/>
</person-group> (<year>2011</year>) <article-title>On the use of cluster-based partial message logging to improve fault tolerance for MPI HPC applications</article-title>. In: <source>17th International Conference on Parallel Processing (Euro-Par 2011)</source>, <comment>Bordeaux, France, 29 August–2 September 2011</comment>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>, pp. <fpage>567</fpage>–<lpage>578</lpage>.</citation>
</ref>
<ref id="bibr21-1094342013495304">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rountree</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Lownenthal</surname>
<given-names>DK</given-names>
</name>
<name>
<surname>de Supinski</surname>
<given-names>BR</given-names>
</name>
<etal/>
</person-group> (<year>2009</year>) <article-title>Adagio: making DVS practical for complex HPC applications</article-title>. In: <source>Proceedings of the 23rd international conference on supercomputing (ICS ‘09)</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>, pp. <fpage>460</fpage>–<lpage>469</lpage>.</citation>
</ref>
<ref id="bibr22-1094342013495304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Skamarock</surname>
<given-names>WC</given-names>
</name>
<name>
<surname>Klemp</surname>
<given-names>JB</given-names>
</name>
<name>
<surname>Dudhia</surname>
<given-names>J</given-names>
</name>
<etal/>
</person-group>. (<year>2005</year>) <article-title>A description of the Advanced Research WRF Version 2</article-title>. <source>NCAR Technical Note</source>.</citation>
</ref>
</ref-list>
</back>
</article>