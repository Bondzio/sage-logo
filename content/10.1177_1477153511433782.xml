<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="EN">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">LRT</journal-id>
<journal-id journal-id-type="hwp">splrt</journal-id>
<journal-title>Lighting Research &amp; Technology</journal-title>
<issn pub-type="ppub">1477-1535</issn>
<issn pub-type="epub">1477-0938</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1477153511433782</article-id>
<article-id pub-id-type="publisher-id">10.1177_1477153511433782</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Target visibility level and detection distance on a driving simulator</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Brémond</surname><given-names>R</given-names></name><degrees>PhD</degrees>
<xref ref-type="corresp" rid="corresp1-1477153511433782"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Bodard</surname><given-names>V</given-names></name><degrees>MSc</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Dumont</surname><given-names>E</given-names></name><degrees>PhD</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Nouailles-Mayeur</surname><given-names>A</given-names></name><degrees>PhD</degrees>
</contrib>
</contrib-group>
<aff id="aff1-1477153511433782">Université Paris Est, Institut Français des Sciences et Technologies des Transports de l’Améngament et des Réseaux, Infrastructure et Mobilité – Laboratoire Exploitation, Perception, Simulateurs et Simulations, Paris, France</aff>
<author-notes>
<corresp id="corresp1-1477153511433782">Roland Brémond, Université Paris Est, IFSTTAR, 58 Boulevard Lefebvre, 75015 Paris, France E-mail: <email>roland.bremond@ifsttar.fr</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2013</year>
</pub-date>
<volume>45</volume>
<issue>1</issue>
<fpage>76</fpage>
<lpage>89</lpage>
<history>
<date date-type="received"><day>8</day><month>8</month><year>2011</year></date>
<date date-type="rev-recd"><day>25</day><month>11</month><year>2011</year></date>
<date date-type="accepted"><day>3</day><month>12</month><year>2011</year></date>
</history>
<permissions>
<copyright-statement>© The Chartered Institution of Building Services Engineers 2011</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The visibility level (VL), a quality index in road lighting design, also serves to assess automotive lighting performance. Unlike illuminance levels, the VL provides a link between lighting design and driving performance. The reference performance of the VL is the detection of a small uniform target, standing on a uniform background (the road surface). Still, VL is subject to a number of caveats with regards to the driving task. We address the non-realistic nature of the reference target (a uniform square). A driving simulation experiment was conducted in a virtual night-time rural highway environment. The subjects drove along the road and came across different targets on the roadside. The detection distances were recorded and compared with the corresponding VL, showing rather good agreement.</p>
</abstract>
</article-meta>
</front>
<body>
<sec id="sec1-1477153511433782" sec-type="intro"><title>1. Introduction</title>
<p>The main purpose of automotive lighting is to provide highway visibility to the driver (a secondary goal is to signal the vehicle to other road users). The quantitative assessment of highway visibility is a challenging issue, in which the main theoretical background comes from psychophysics and addresses target detection.</p>
<p>For road and vehicle lighting design practitioners, Adrian’s empirical target visibility model is the prevailing alternative to illuminance and luminance levels.<sup><xref ref-type="bibr" rid="bibr1-1477153511433782">1</xref>,<xref ref-type="bibr" rid="bibr2-1477153511433782">2</xref></sup> The model is based on a set of psychophysical data<sup><xref ref-type="bibr" rid="bibr3-1477153511433782">3</xref></sup> and predicts the threshold contrast of a flat uniform target on a uniform background. The visibility level (VL) is the ratio between the actual contrast of a target and its threshold contrast. Thus, VL = 1 means that the considered target is just visible, albeit in laboratory conditions. This index is cited in several national and international standards.<sup><xref ref-type="bibr" rid="bibr4-1477153511433782">4</xref><xref ref-type="bibr" rid="bibr5-1477153511433782"/>–<xref ref-type="bibr" rid="bibr6-1477153511433782">6</xref></sup> In order to account for the fact that visibility in complex driving situations requires higher thresholds than in laboratory conditions, lighting engineers introduce a so-called field factor, which is equivalent to a threshold VL required to ensure safe driving. For instance, VL = 7 was proposed in the French recommendations for road lighting.<sup><xref ref-type="bibr" rid="bibr5-1477153511433782">5</xref></sup></p>
<p>Automotive front-lighting designers have also considered the VL as an alternative to usual indices in their field, mostly based on illuminance distributions.<sup><xref ref-type="bibr" rid="bibr7-1477153511433782">7</xref><xref ref-type="bibr" rid="bibr8-1477153511433782"/><xref ref-type="bibr" rid="bibr9-1477153511433782"/>–<xref ref-type="bibr" rid="bibr10-1477153511433782">10</xref></sup> The reason is the same: Contrary to illuminance, VL is directly related to a key visual performance in the driving task, namely detection. Assuming VL is related to visibility distance, which is in turn related to accident risk and severity,<sup><xref ref-type="bibr" rid="bibr11-1477153511433782">11</xref></sup> VL might be considered in accident scenarios to rate lighting systems in terms of safety.</p>
<p>Despite these interesting features, VL suffers from a variety of problems. First, setting a unique field factor does not address the fact that the same VL may lead to various performance levels depending on the context (e.g. speed, traffic, task demand, etc.).<sup><xref ref-type="bibr" rid="bibr12-1477153511433782">12</xref></sup> Further discussions about the relevant target shape,<sup><xref ref-type="bibr" rid="bibr13-1477153511433782">13</xref></sup> about measurement issues<sup><xref ref-type="bibr" rid="bibr14-1477153511433782">14</xref></sup> and about the impact of the driving task on target detection performance<sup><xref ref-type="bibr" rid="bibr15-1477153511433782">15</xref><xref ref-type="bibr" rid="bibr16-1477153511433782"/><xref ref-type="bibr" rid="bibr17-1477153511433782"/>–<xref ref-type="bibr" rid="bibr18-1477153511433782">18</xref></sup> have prevented its adoption in automotive lighting evaluation so far. Computer vision approaches have also been proposed<sup><xref ref-type="bibr" rid="bibr19-1477153511433782">19</xref><xref ref-type="bibr" rid="bibr20-1477153511433782"/>–<xref ref-type="bibr" rid="bibr21-1477153511433782">21</xref></sup> to address implementation issues raised by non-uniform targets and backgrounds, as well as for large targets.</p>
<p>Among the caveats with regards to the actual driving task, we address in this paper the non-realistic nature of the small uniform grey square target usually associated with the VL index. Although this standard target was initially chosen because of its key features with respect to hazard detection in terms of size and uniformity,<sup><xref ref-type="bibr" rid="bibr22-1477153511433782">22</xref></sup> it is a rather unlikely object to find on the road.</p>
<p>An experiment was conducted, in the hope of facilitating the implementation of VL for automotive lighting design. Several issues are addressed:
<list id="list1-1477153511433782" list-type="order">
<list-item><p>The first one, as we just said, is the peculiarity of the standard target. In the present study, more familiar targets were compared to the conventional grey square target.</p></list-item>
<list-item><p>The second issue is the time-varying apparent size of the target as the driver comes closer. This was solved by conducting the study in a driving simulator.</p></list-item>
<list-item><p>The third issue was to identify a straightforward link between lighting recommendations and road safety.</p></list-item>
</list></p>
<p>The aim of electric lighting is to improve drivers’ visual performance at night, given that better anticipation leads to improved road safety.<sup><xref ref-type="bibr" rid="bibr22-1477153511433782">22</xref></sup> The current belief is that using VL as a lighting index is more relevant for road safety than using illuminance. Still, it describes detection performance, not a safety index, such as accident risk. To improve the link between VL and road safety, we introduce the detection distance as an intermediate variable. We can then use the stopping distance as a safety reference for lighting design. Then, the detection distance provides an input for quantitative risk models. For instance, Gallen et al. relate detection distance to accident probability and severity.<sup><xref ref-type="bibr" rid="bibr11-1477153511433782">11</xref></sup> Their model uses driver parameters such as the detection distance and reaction time (RT), road parameters such as slope, curvature and friction, as well as vehicle speed and dynamics parameters, and computes the stopping distance. Then, the accident severity can be related to the relative speed between the driver’s car and the target at the moment of collision.</p>
<p>In the current context of energy and cost saving, this quantitative approach may impact the lighting design methodology: based on the standard obstacle collision avoidance scenario, adapting the lighting system to those characteristics of the road which affect the stopping distance regardless of the drivers visual performance would arguably increase its efficiency.</p>
<p>The driving simulation experiment was conducted with 27 subjects, in a virtual night-time highway environment illuminated with headlamps only, and devoid of traffic. A target detection performance was assessed for the standard uniform square and for objects more familiar to drivers: a road sign, a pedestrian and a car. These targets were presented either as uniform grey silhouettes, or with a more realistic texture. The subjects had to detect the various targets while driving, and the detection distance was recorded. This distance was then compared to the VL computed from the size and contrast of the target at the time of detection.</p>
<p>The next section describes the experimental material and method. Section 3 describes with more details the photometric analysis, and Section 4 gives the experimental results of the driving simulation experiment. The last section summarizes the main results and discusses how they may help improve automotive lighting design.</p>
</sec>
<sec id="sec2-1477153511433782"><title>2. Driving simulator experiment</title>
<sec id="sec3-1477153511433782"><title>2.1. Participants</title>
<p>A total of 27 subjects (5 women, 22 men), with a mean age of 35 years, participated in the experiment. They were all licensed drivers with normal or optically corrected vision (tested for night vision with Essilor Ergovision tester) without known visual or auditory impairment. The subjects scored between 10/10 and 12/10 in a binocular acuity test, except one who scored 8/10. Under these conditions, a statistical analysis using analysis of variance did not show any effect of visual acuity on visual performance.</p>
<p>Although they were recruited from IFSTTAR employees, all subjects were naive to the purpose of the experiment and were given a full explanation of the experimental procedure. A written informed consent was obtained before participation, with the option to withdraw from the study at any time.</p>
</sec>
<sec id="sec4-1477153511433782"><title>2.2. Apparatus</title>
<p>The driving simulation experiment took place in a dark room dedicated to photometrically controlled psycho-visual experiments. The driving simulator comprised a steering wheel with force feedback, a gear box and pedals, but no motion system. IFSTTAR’s own software (SIM<sup>2</sup> and DR<sup>2</sup>) served to run the simulator and to graphically render the virtual environment.<sup><xref ref-type="bibr" rid="bibr23-1477153511433782">23</xref></sup> The computer graphics images were displayed at a 60-Hz frame rate by means of a SXGA (1280 × 1024) video-projector. The subjects sat in a car seat mounted on a platform with adjustable height so as to ensure that they all had their eyes level with the centre of the projection screen. The screen was 3 m in front of the subjects. It was 2 m in width and 1.5 m in height, subtending a visual field 37° horizontally and 30° vertically.</p>
</sec>
<sec id="sec5-1477153511433782"><title>2.3. Virtual night-time highway environment</title>
<p>The geometry of the road was that of a rural four-lane freeway with central separation (see <xref ref-type="fig" rid="fig1-1477153511433782">Figure 1(a)</xref>). Vehicle headlamp illumination was simulated by means of a computer graphics special effect which involves three steps, illustrated in <xref ref-type="fig" rid="fig1-1477153511433782">Figure 1</xref>. The daytime highway environment is first rendered using photographical textures (<xref ref-type="fig" rid="fig1-1477153511433782">Figure 1(a)</xref>). A hardware accelerated black fog effect is then applied which consists of multiplying the colour <italic>C</italic><sub>0</sub> of every pixel by an exponential function of the depth <italic>Z</italic> to mimic the inverse square law of illumination:
<disp-formula id="disp-formula1-1477153511433782"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math1-1477153511433782"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula1-1477153511433782" xlink:href="10.1177_1477153511433782-eq1.tif"/></disp-formula>
<fig id="fig1-1477153511433782" position="float"><label>Figure 1</label><caption><p>Three-step special effect to simulate headlight illumination conditions: (a) daytime scene, (b) with black fog and (c) with headlamp beam pattern texture. (Available in colour in electronic version of paper.)</p></caption><graphic xlink:href="10.1177_1477153511433782-fig1.tif"/>
</fig></p>
<p>The parameter <italic>k</italic> was adjusted so that the brightest pixels in the scene would fade to black at about 200 m (<xref ref-type="fig" rid="fig1-1477153511433782">Figure 1(b)</xref>). Finally, a transparency texture built from the intensity distribution of a high-beam headlamp is applied to introduce a sense of the beam pattern, with darker areas on the sides (<xref ref-type="fig" rid="fig1-1477153511433782">Figure 1(c)</xref>). This rendering technique was designed to provide a subjective sense of headlight illumination in dynamic conditions. It does not produce an accurate luminance pattern on the road (see a luminance map <xref ref-type="fig" rid="fig2-1477153511433782">Figure 2</xref>), and thus, it cannot serve to assess headlight performance.
<fig id="fig2-1477153511433782" position="float"><label>Figure 2</label><caption><p>Left: Snapshot of the virtual environment. Right: Luminance map measured on the projection screen (logarithmic grey scale)</p></caption><graphic xlink:href="10.1177_1477153511433782-fig2.tif"/>
</fig></p>
</sec>
<sec id="sec6-1477153511433782"><title>2.4. Reaction time</title>
<p>Driving on a highway, at night, without traffic, leads to high speeds. It is even worse with driving simulators in which speeds tend to be higher than on the road.<sup><xref ref-type="bibr" rid="bibr24-1477153511433782">24</xref><xref ref-type="bibr" rid="bibr25-1477153511433782"/>–<xref ref-type="bibr" rid="bibr26-1477153511433782">26</xref></sup> Indeed, the mean speed in our experiment was 151 km/h (93.8 mph). This high speed, combined with RT, has a significant impact on the measured visibility distance.</p>
<p>In order to account for the distance run by the car between the moment the driver sees the target and the moment she or he pushes the button, the mean RT of every subject was measured prior to the driving simulation experiment. During this pre-test, the subjects were presented with a uniform grey background on which a sequence of 13 uniform gray square targets were shortly displayed, with a high contrast. The time interval between successive targets was random. The subjects were simply asked to signal the appearance of a target by pressing a button on the steering wheel (the same button as in the driving simulation experiment). The mean RT was computed for every subject (the first three targets were discarded) and was later used in order to correct the estimated target detection distance.</p>
<p>The mean RT over all subjects was 0.43 seconds (with a standard deviation of 0.015 seconds), which corresponds to 18 meters at 151 km/h. Given the inter-individual variability in terms of RT (between 0.33 seconds and 0.58 seconds), individual corrections of the detection distances were preferred to a uniform correction.</p>
</sec>
<sec id="sec7-1477153511433782"><title>2.5. Protocol</title>
<p>The independent variable was the type of target, of which there were seven: a uniform square, a uniform road sign, a uniform pedestrian, a uniform car, a textured road sign, a textured pedestrian and a textured car (see <xref ref-type="fig" rid="fig3-1477153511433782">Figure 3</xref>).
<fig id="fig3-1477153511433782" position="float"><label>Figure 3</label><caption><p>Snapshots of the seven targets presented to the participants in the driving simulator (here at 20 m). Left: Uniform targets; right: Textured targets. From top to bottom: Uniform square, road sign, pedestrian and car. (Available in colour in electronic version of paper.)</p></caption><graphic xlink:href="10.1177_1477153511433782-fig3.tif"/>
</fig></p>
<p>During the experiment, each of the seven targets was presented eight times to every subject. Targets stood next to the right-hand-side pavement marking. They were set in random order, to prevent drivers from anticipating the type of the next target, and to avoid any learning bias. They were also set at random positions along 600 m long road sections, with a minimum of 200 m between successive targets, to prevent drivers from anticipating the location of the next target. The same sequence of targets was used for all the subjects, to avoid any bias from the variations in the local target background across subjects.</p>
<p>After the RT pre-test, every participant was given an opportunity to become familiar with the simulator by driving in the same virtual environment as in the experiment until they felt comfortable with the equipment, which usually happened after a few minutes. The participants were then given the following instructions: ‘You are going to drive on a highway at night. From time to time, you will meet an object on the roadside. Each time you see one of these objects, you will tell that you have seen it by pushing the button on the steering wheel’. The complete duration of the experiment was less than half an hour for each subject, including the pre-test and the familiarization.</p>
</sec>
</sec>
<sec id="sec8-1477153511433782"><title>3. Photometric analysis</title>
<sec id="sec9-1477153511433782"><title>3.1. Luminance measurements</title>
<p>In order to estimate the photometric parameters which are needed to implement the Adrian target visibility model, luminance measurements were performed on the displayed computer graphics images, using an imaging photometer with a 980 × 980 pixel resolution (Minolta CA2000). Performing these measurements in the dynamic conditions of the experiment was not feasible, because of the exposure time required by the photometer. Therefore, snapshots of the virtual environment were used, taken every 10 m from 150 m down to 20 m for each type of target. This resulted in 14 × 7 = 90 luminance maps (see for example, <xref ref-type="fig" rid="fig2-1477153511433782">Figure 2</xref>).</p>
</sec>
<sec id="sec10-1477153511433782"><title>3.2. Computation of VLs</title>
<p>A mask was manually defined for every type of target at every distance, in order to tag target pixels in the luminance maps (<xref ref-type="fig" rid="fig4-1477153511433782">Figure 4</xref>). The luminance of a target was computed as the mean luminance of the target pixels. From the number of pixels in the mask and from the angular size of a pixel, it was also possible to estimate the equivalent angular size of each target, defined as the angular size of a square subtending the same number of pixels <italic>n</italic><sub>pix</sub>:
<disp-formula id="disp-formula2-1477153511433782"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math2-1477153511433782"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>a</mml:mi><mml:mtext>tan</mml:mtext><mml:mrow><mml:mo/><mml:mo>(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mtext>pix</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:mfrac><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mtext>pix</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mrow><mml:mo/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula2-1477153511433782" xlink:href="10.1177_1477153511433782-eq2.tif"/></disp-formula>
where <italic>a</italic><sub>pix</sub> is the size of a pixel (about 1.56 mm) and <italic>D</italic> is the distance between the subjects and the screen (3 m).
<fig id="fig4-1477153511433782" position="float"><label>Figure 4</label><caption><p>Illustration of the process to extract photometric data from a luminance map: (a) snapshot of the target (textured pedestrian), (b) corresponding mask (white for target), (c) foveal region from which data are extracted in the luminance map (pixels within the white contours contribute to object luminance; pixels within black contours contribute to background luminance; surrounding pixels contribute to adaptation luminance). (Available in colour in electronic version of paper.)</p></caption><graphic xlink:href="10.1177_1477153511433782-fig4.tif"/>
</fig></p>
<p>For the background and adaptation luminance, we followed the approach proposed by Moon and Spencer for non-uniform surrounds.<sup><xref ref-type="bibr" rid="bibr27-1477153511433782">27</xref></sup> The background is contained within the region covered by foveal vision, a disc approximately 1.5° in diameter centred in the middle of the target. So the pixels within that region, excluding target pixels, were tagged as background pixels and the background luminance <italic>L<sub>b</sub></italic> was computed as the mean of these luminance values. As for the adaptation luminance <italic>L</italic><sub><italic>a</italic></sub>, Moon and Spencer established it to be a linear combination of background luminance <italic>L</italic><sub><italic>b</italic></sub> and surround luminance:
<disp-formula id="disp-formula3-1477153511433782"><label>(3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math3-1477153511433782"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>923</mml:mn><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0096</mml:mn></mml:mrow><mml:mrow><mml:mo>π</mml:mo></mml:mrow></mml:mfrac><mml:mi>ω</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow><mml:mrow><mml:mi>ij</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>ij</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow><mml:mrow><mml:mi>ij</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>cos</mml:mi><mml:msub><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow><mml:mrow><mml:mi>ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic alternate-form-of="disp-formula3-1477153511433782" xlink:href="10.1177_1477153511433782-eq3.tif"/></disp-formula>
where ε is the solid angle subtended by a pixel from the position of the subjects, ε<italic><sub>ij</sub></italic> and <italic>L<sub>ij</sub></italic> are, respectively, the eccentricity (in arcminute) and luminance of the pixel at coordinates (<italic>i</italic>,<italic>j</italic>), and ε<italic><sub>f</sub></italic> is the foveal half angle (about 0.75°).</p>
<p>It was thus possible to extract the parameters of the Adrian model from the luminance maps, and then to compute the VL of every target at every distance, assuming a 0.2-second presentation time (a standard value for lighting design), and a 35-year-old observer (the mean age of the participants in the experiment). The results are summarized in <xref ref-type="table" rid="table1-1477153511433782">Table 1</xref>. There are a few cases in which the VL could not be computed, mostly because the target was too large (α &gt; 1°). The luminance variation inside a target is described with the luminance standard deviation (SD, in percentage, with respect to the mean luminance). ‘Uniform’ targets do not lead to SD = 0, because even though the reflectance of the object is uniform, the luminances rendered on the screen are impacted by the beam pattern texture.
<table-wrap id="table1-1477153511433782" position="float"><label>Table 1</label><caption><p>Photometric data extracted from luminance maps (e.g. <xref ref-type="fig" rid="fig2-1477153511433782">Figure 2</xref>) measured on screenshots of the seven targets at distances <italic>D</italic> between 20 m and 150 m<sup><xref ref-type="table-fn" rid="table-fn1-1477153511433782">a</xref></sup></p></caption>
<graphic alternate-form-of="table1-1477153511433782" xlink:href="10.1177_1477153511433782-table1.tif"/>
<table frame="hsides"><thead align="left">
<tr><th/>
<th><italic>D</italic> (m)</th>
<th>Size (arcmin)</th>
<th><italic>L</italic> (cd/m<sup>2</sup>)</th>
<th>SD</th>
<th><italic>L<sub>b</sub></italic> (cd/m<sup>2</sup>)</th>
<th><italic>C</italic> (cd/m<sup>2</sup>)</th>
<th><italic>L<sub>a</sub></italic> (cd/m<sup>2</sup>)</th>
<th>VL</th>
</tr></thead>
<tbody align="left">
<tr>
<td rowspan="14">Small target</td>
<td>150</td>
<td>5.4</td>
<td>0.087</td>
<td>150%</td>
<td>0.076</td>
<td>0.134</td>
<td>0.156</td>
<td>0.1</td>
</tr>
<tr>
<td>140</td>
<td>5.4</td>
<td>0.013</td>
<td>300%</td>
<td>0.074</td>
<td>−0.820</td>
<td>0.153</td>
<td>1.1</td>
</tr>
<tr>
<td>130</td>
<td>6.2</td>
<td>0.210</td>
<td>90%</td>
<td>0.101</td>
<td>1.069</td>
<td>0.182</td>
<td>1.5</td>
</tr>
<tr>
<td>120</td>
<td>6.2</td>
<td>0.511</td>
<td>22%</td>
<td>0.175</td>
<td>1.914</td>
<td>0.256</td>
<td>4.1</td>
</tr>
<tr>
<td>110</td>
<td>7.2</td>
<td>0.901</td>
<td>34%</td>
<td>0.278</td>
<td>2.242</td>
<td>0.356</td>
<td>7.9</td>
</tr>
<tr>
<td>100</td>
<td>7.2</td>
<td>1.998</td>
<td>25%</td>
<td>0.472</td>
<td>3.231</td>
<td>0.542</td>
<td>15.3</td>
</tr>
<tr>
<td>90</td>
<td>8.9</td>
<td>4.137</td>
<td>31%</td>
<td>0.833</td>
<td>3.969</td>
<td>0.882</td>
<td>34.6</td>
</tr>
<tr>
<td>80</td>
<td>9.8</td>
<td>7.972</td>
<td>25%</td>
<td>1.412</td>
<td>4.644</td>
<td>1.426</td>
<td>57.0</td>
</tr>
<tr>
<td>70</td>
<td>10.7</td>
<td>14.039</td>
<td>19%</td>
<td>2.413</td>
<td>4.819</td>
<td>2.368</td>
<td>80.0</td>
</tr>
<tr>
<td>60</td>
<td>12.5</td>
<td>23.513</td>
<td>27%</td>
<td>4.107</td>
<td>4.725</td>
<td>3.962</td>
<td>108.0</td>
</tr>
<tr>
<td>50</td>
<td>14.2</td>
<td>36.085</td>
<td>20%</td>
<td>6.048</td>
<td>4.966</td>
<td>5.779</td>
<td>140.3</td>
</tr>
<tr>
<td>40</td>
<td>17.9</td>
<td>37.199</td>
<td>24%</td>
<td>6.726</td>
<td>4.530</td>
<td>6.412</td>
<td>156.6</td>
</tr>
<tr>
<td>30</td>
<td>24.5</td>
<td>24.078</td>
<td>19%</td>
<td>4.815</td>
<td>4.001</td>
<td>4.588</td>
<td>158.2</td>
</tr>
<tr>
<td>20</td>
<td>35.6</td>
<td>9.437</td>
<td>24%</td>
<td>2.034</td>
<td>3.639</td>
<td>1.946</td>
<td>147.4</td>
</tr>
<tr>
<td rowspan="12">Uniform sign</td>
<td>150</td>
<td>12.2</td>
<td>0.000</td>
<td/>
<td>0.008</td>
<td>−1.000</td>
<td>0.079</td>
<td>0.9</td>
</tr>
<tr>
<td>140</td>
<td>12.9</td>
<td>0.000</td>
<td/>
<td>0.013</td>
<td>−1.000</td>
<td>0.086</td>
<td>1.5</td>
</tr>
<tr>
<td>130</td>
<td>14.3</td>
<td>0.143</td>
<td>113%</td>
<td>0.020</td>
<td>6.082</td>
<td>0.094</td>
<td>7.2</td>
</tr>
<tr>
<td>120</td>
<td>16.1</td>
<td>0.348</td>
<td>35%</td>
<td>0.030</td>
<td>10.524</td>
<td>0.105</td>
<td>20.4</td>
</tr>
<tr>
<td>110</td>
<td>18.0</td>
<td>0.633</td>
<td>23%</td>
<td>0.061</td>
<td>9.441</td>
<td>0.137</td>
<td>36.6</td>
</tr>
<tr>
<td>100</td>
<td>20.8</td>
<td>0.951</td>
<td>26%</td>
<td>0.112</td>
<td>7.520</td>
<td>0.191</td>
<td>52.0</td>
</tr>
<tr>
<td>90</td>
<td>23.4</td>
<td>1.746</td>
<td>24%</td>
<td>0.196</td>
<td>7.911</td>
<td>0.275</td>
<td>87.7</td>
</tr>
<tr>
<td>80</td>
<td>26.6</td>
<td>3.133</td>
<td>22%</td>
<td>0.387</td>
<td>7.101</td>
<td>0.459</td>
<td>128.9</td>
</tr>
<tr>
<td>70</td>
<td>31.2</td>
<td>5.600</td>
<td>22%</td>
<td>0.774</td>
<td>6.237</td>
<td>0.826</td>
<td>173.1</td>
</tr>
<tr>
<td>60</td>
<td>36.9</td>
<td>9.391</td>
<td>19%</td>
<td>1.556</td>
<td>5.036</td>
<td>1.559</td>
<td>189.4</td>
</tr>
<tr>
<td>50</td>
<td>44.7</td>
<td>14.779</td>
<td>17%</td>
<td>2.840</td>
<td>4.203</td>
<td>2.772</td>
<td>196.9</td>
</tr>
<tr>
<td>40</td>
<td>56.3</td>
<td>21.673</td>
<td>14%</td>
<td>5.219</td>
<td>3.152</td>
<td>5.003</td>
<td>177.8</td>
</tr>
<tr>
<td rowspan="11">Uniform pedestrian</td>
<td>150</td>
<td>16.9</td>
<td>0.000</td>
<td/>
<td>0.001</td>
<td>−1.000</td>
<td>0.063</td>
<td>0.2</td>
</tr>
<tr>
<td>140</td>
<td>18.1</td>
<td>0.000</td>
<td/>
<td>0.002</td>
<td>−1.000</td>
<td>0.063</td>
<td>0.4</td>
</tr>
<tr>
<td>130</td>
<td>19.2</td>
<td>0.046</td>
<td>235%</td>
<td>0.004</td>
<td>11.326</td>
<td>0.067</td>
<td>4.0</td>
</tr>
<tr>
<td>120</td>
<td>20.6</td>
<td>0.309</td>
<td>58%</td>
<td>0.010</td>
<td>30.478</td>
<td>0.074</td>
<td>29.0</td>
</tr>
<tr>
<td>110</td>
<td>23.2</td>
<td>0.547</td>
<td>27%</td>
<td>0.018</td>
<td>29.005</td>
<td>0.084</td>
<td>54.3</td>
</tr>
<tr>
<td>100</td>
<td>26.0</td>
<td>0.874</td>
<td>34%</td>
<td>0.045</td>
<td>18.502</td>
<td>0.111</td>
<td>81.9</td>
</tr>
<tr>
<td>90</td>
<td>29.2</td>
<td>1.605</td>
<td>32%</td>
<td>0.084</td>
<td>18.161</td>
<td>0.150</td>
<td>141.4</td>
</tr>
<tr>
<td>80</td>
<td>32.5</td>
<td>2.826</td>
<td>30%</td>
<td>0.189</td>
<td>13.977</td>
<td>0.252</td>
<td>200.0</td>
</tr>
<tr>
<td>70</td>
<td>37.1</td>
<td>4.842</td>
<td>34%</td>
<td>0.396</td>
<td>11.216</td>
<td>0.449</td>
<td>263.7</td>
</tr>
<tr>
<td>60</td>
<td>43.6</td>
<td>8.446</td>
<td>27%</td>
<td>0.690</td>
<td>11.232</td>
<td>0.729</td>
<td>369.5</td>
</tr>
<tr>
<td>50</td>
<td>52.1</td>
<td>13.674</td>
<td>27%</td>
<td>1.351</td>
<td>9.119</td>
<td>1.353</td>
<td>388.4</td>
</tr>
<tr>
<td rowspan="5">Uniform car</td>
<td>150</td>
<td>35.6</td>
<td>0.136</td>
<td>111%</td>
<td>0.002</td>
<td>61.609</td>
<td>0.065</td>
<td>21.8</td></tr>
<tr>
<td>140</td>
<td>37.9</td>
<td>0.348</td>
<td>32%</td>
<td>0.007</td>
<td>49.161</td>
<td>0.071</td>
<td>55.7</td>
</tr>
<tr>
<td>130</td>
<td>42.2</td>
<td>0.610</td>
<td>20%</td>
<td>0.028</td>
<td>20.529</td>
<td>0.092</td>
<td>89.2</td>
</tr>
<tr>
<td>120</td>
<td>46.0</td>
<td>1.048</td>
<td>19%</td>
<td>0.074</td>
<td>13.112</td>
<td>0.137</td>
<td>127.1</td>
</tr>
<tr>
<td>100</td>
<td>55.7</td>
<td>3.919</td>
<td>21%</td>
<td>0.346</td>
<td>10.320</td>
<td>0.393</td>
<td>282.2</td>
</tr>
<tr>
<td rowspan="12">Textured sign</td>
<td>150</td>
<td>11.0</td>
<td>0.000</td>
<td/>
<td>0.002</td>
<td>−1.000</td>
<td>0.069</td>
<td>0.2</td>
</tr>
<tr>
<td>140</td>
<td>11.4</td>
<td>0.000</td>
<td/>
<td>0.005</td>
<td>−1.000</td>
<td>0.073</td>
<td>0.5</td>
</tr>
<tr>
<td>130</td>
<td>13.6</td>
<td>0.000</td>
<td/>
<td>0.007</td>
<td>−1.000</td>
<td>0.076</td>
<td>1.0</td>
</tr>
<tr>
<td>120</td>
<td>15.9</td>
<td>0.011</td>
<td>510%</td>
<td>0.009</td>
<td>0.136</td>
<td>0.080</td>
<td>0.1</td>
</tr>
<tr>
<td>110</td>
<td>15.8</td>
<td>0.149</td>
<td>135%</td>
<td>0.018</td>
<td>7.284</td>
<td>0.091</td>
<td>8.8</td>
</tr>
<tr>
<td>100</td>
<td>18.6</td>
<td>0.330</td>
<td>76%</td>
<td>0.044</td>
<td>6.591</td>
<td>0.121</td>
<td>20.1</td>
</tr>
<tr>
<td>90</td>
<td>21.2</td>
<td>0.533</td>
<td>70%</td>
<td>0.071</td>
<td>6.548</td>
<td>0.149</td>
<td>33.1</td>
</tr>
<tr>
<td>80</td>
<td>25.2</td>
<td>0.848</td>
<td>74%</td>
<td>0.125</td>
<td>5.774</td>
<td>0.207</td>
<td>50.6</td>
</tr>
<tr>
<td>70</td>
<td>29.1</td>
<td>1.541</td>
<td>78%</td>
<td>0.261</td>
<td>4.901</td>
<td>0.341</td>
<td>76.0</td>
</tr>
<tr>
<td>60</td>
<td>31.8</td>
<td>3.093</td>
<td>71%</td>
<td>0.536</td>
<td>4.774</td>
<td>0.606</td>
<td>116.9</td>
</tr>
<tr>
<td>50</td>
<td>39.2</td>
<td>5.018</td>
<td>76%</td>
<td>1.134</td>
<td>3.424</td>
<td>1.172</td>
<td>121.1</td>
</tr>
<tr>
<td>40</td>
<td>49.7</td>
<td>7.987</td>
<td>80%</td>
<td>2.291</td>
<td>2.486</td>
<td>2.278</td>
<td>115.0</td>
</tr>
<tr>
<td rowspan="11">Textured pedestrian</td>
<td>150</td>
<td>16.9</td>
<td>0.000</td>
<td/>
<td>0.002</td>
<td>−1.000</td>
<td>0.064</td>
<td>0.4</td>
</tr>
<tr>
<td>140</td>
<td>18.1</td>
<td>0.000</td>
<td/>
<td>0.002</td>
<td>−1.000</td>
<td>0.063</td>
<td>0.4</td>
</tr>
<tr>
<td>130</td>
<td>19.4</td>
<td>0.000</td>
<td/>
<td>0.003</td>
<td>−1.000</td>
<td>0.067</td>
<td>0.8</td>
</tr>
<tr>
<td>120</td>
<td>20.5</td>
<td>0.116</td>
<td>137%</td>
<td>0.009</td>
<td>11.227</td>
<td>0.074</td>
<td>10.2</td>
</tr>
<tr>
<td>110</td>
<td>22.5</td>
<td>0.354</td>
<td>64%</td>
<td>0.019</td>
<td>17.796</td>
<td>0.085</td>
<td>33.2</td>
</tr>
<tr>
<td>100</td>
<td>25.9</td>
<td>0.560</td>
<td>53%</td>
<td>0.043</td>
<td>12.109</td>
<td>0.109</td>
<td>51.5</td>
</tr>
<tr>
<td>90</td>
<td>29.2</td>
<td>1.023</td>
<td>50%</td>
<td>0.088</td>
<td>10.568</td>
<td>0.155</td>
<td>85.4</td>
</tr>
<tr>
<td>80</td>
<td>32.5</td>
<td>1.798</td>
<td>64%</td>
<td>0.170</td>
<td>9.546</td>
<td>0.235</td>
<td>128.4</td>
</tr>
<tr>
<td>70</td>
<td>37.1</td>
<td>2.896</td>
<td>68%</td>
<td>0.346</td>
<td>7.380</td>
<td>0.402</td>
<td>161.4</td>
</tr>
<tr>
<td>60</td>
<td>43.6</td>
<td>5.352</td>
<td>75%</td>
<td>0.573</td>
<td>8.345</td>
<td>0.621</td>
<td>257.9</td>
</tr>
<tr>
<td>50</td>
<td>52.1</td>
<td>8.678</td>
<td>75%</td>
<td>1.200</td>
<td>6.234</td>
<td>1.213</td>
<td>257.4</td>
</tr>
<tr>
<td rowspan="6">Textured car</td>
<td>150</td>
<td>36.6</td>
<td>0.000</td>
<td/>
<td>0.003</td>
<td>−1.000</td>
<td>0.067</td>
<td>1.2</td>
</tr>
<tr>
<td>140</td>
<td>38.3</td>
<td>0.000</td>
<td/>
<td>0.004</td>
<td>−1.000</td>
<td>0.068</td>
<td>1.7</td>
</tr>
<tr>
<td>130</td>
<td>42.1</td>
<td>0.005</td>
<td>710%</td>
<td>0.006</td>
<td>−0.164</td>
<td>0.071</td>
<td>0.4</td>
</tr>
<tr>
<td>120</td>
<td>44.5</td>
<td>0.115</td>
<td>133%</td>
<td>0.011</td>
<td>9.188</td>
<td>0.077</td>
<td>18.0</td>
</tr>
<tr>
<td>110</td>
<td>49.1</td>
<td>0.282</td>
<td>67%</td>
<td>0.028</td>
<td>9.199</td>
<td>0.095</td>
<td>41.8</td>
</tr>
<tr>
<td>100</td>
<td>55.1</td>
<td>0.496</td>
<td>44%</td>
<td>0.048</td>
<td>9.372</td>
<td>0.117</td>
<td>70.1</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1477153511433782"><p><sup>a</sup>Target angular size (when smaller than 1°); mean luminance, <italic>L</italic>; standard deviation of luminance, σ<italic>L</italic>; background luminance, <italic>L<sub>b</sub></italic>; contrast, <italic>C</italic>; adaptation luminance, <italic>L<sub>a</sub></italic> and visibility level, VL (computed for a 35−year−old observer with a 0.2−second presentation time).</p></fn></table-wrap-foot>
</table-wrap></p>
</sec>
</sec>
<sec id="sec11-1477153511433782"><title>4. Results</title>
<p>Henceforth, detection distance obtained from the participants is referred to as the Experimental Detection Distance (EDD), whereas the detection distance obtained from VL values is referred to as the Computed Detection Distance (CDD).</p>
<sec id="sec12-1477153511433782"><title>4.1. Target detection performance</title>
<p>The EDD values are presented in <xref ref-type="table" rid="table2-1477153511433782">Table 2</xref> for every target. They are corrected to account for individual RT (see Section 2.4). Each value is a mean over 8 detections and 27 drivers (216 data). A few cases (5 out of 1512: 3 uniform squares, and 2 road signs) were discarded because the targets had not been detected at all. The relative visibility with respect to the reference target (the uniform square), defined as the ratio between their respective EDD, is also given in <xref ref-type="table" rid="table2-1477153511433782">Table 2</xref>. Analysis of variance showed that the ‘target’ factor is statistically significant (<italic>p</italic> &lt; 0.001).
<table-wrap id="table2-1477153511433782" position="float"><label>Table 2</label><caption><p>Mean detection distance for each target. The distance and the VL are computed at the moment of target detection, taking into account the individual reaction time</p></caption>
<graphic alternate-form-of="table2-1477153511433782" xlink:href="10.1177_1477153511433782-table2.tif"/>
<table frame="hsides"><thead align="left">
<tr><th>Target</th>
<th>Reference (uniform square)</th>
<th>Road sign</th>
<th>Road sign (uniform)</th>
<th>Pedestrian</th>
<th>Pedestrian (uniform)</th>
<th>Car</th>
<th>Car (uniform)</th>
</tr></thead>
<tbody align="left">
<tr>
<td>EDD</td>
<td>106</td>
<td>100</td>
<td>120</td>
<td>124</td>
<td>128</td>
<td>122</td>
<td>149</td>
</tr>
<tr>
<td>VL</td>
<td>9</td>
<td>18</td>
<td>13</td>
<td>6</td>
<td>9</td>
<td>14</td>
<td>26</td>
</tr>
<tr>
<td>RV ratio</td>
<td>1.00</td>
<td>0.95</td>
<td>1.20</td>
<td>1.17</td>
<td>1.22</td>
<td>1.15</td>
<td>1.41</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1477153511433782"><p>RV: relative visibility.</p></fn></table-wrap-foot>
</table-wrap></p>
<p>These results call for several comments. First, as expected, the reference target for lighting design – the uniform square – is harder to detect than most tested targets. However, the ‘road sign’ target is unexpectedly harder to detect, although the difference is small (6%). Second, the EDD of the most visible target (the uniform car) is only 40% higher than that of the reference target. This value can be interpreted as a ‘shape bias’ introduced when using the small square as a reference, instead of a big car, in terms of detection distance. Third, targets are more visible when they are uniform than when they are textured. This may be due to the high reflectance of the uniform targets, which makes them more conspicuous than the textured targets, which are darker in some parts. The small uniform target is indeed a worst-case scenario, which justifies its use as a reference for assessing the performance of lighting systems in terms of visibility.</p>
</sec>
<sec id="sec13-1477153511433782"><title>4.2. VL and detection distance</title>
<p>The first comment to be made about the VLs in <xref ref-type="table" rid="table1-1477153511433782">Table 1</xref> is that the targets are darker than their background when they appear in the distance, and then ‘vanish’ at some point before their contrast becomes positive as the driver comes closer. However, the VL before this point never reaches values much higher than 1, because of the combined effect of small angular size and low absolute contrast.</p>
<p>From the estimated VL values, we computed detection distance values corresponding to a threshold VL of 7, a field factor value recommended for road lighting.<sup><xref ref-type="bibr" rid="bibr5-1477153511433782">5</xref>,<xref ref-type="bibr" rid="bibr13-1477153511433782">13</xref>,<xref ref-type="bibr" rid="bibr28-1477153511433782">28</xref></sup> The rationale is to compute the detection distance as if the driver detects the targets at the very moment their VL reaches the threshold VL = 7. <xref ref-type="table" rid="table3-1477153511433782">Table 3</xref> shows this CDD for every target, compared to the corresponding mean EDD recorded on the driving simulator.
<table-wrap id="table3-1477153511433782" position="float"><label>Table 3</label><caption><p>Comparison between detection distance measured in a driving simulator (Experimental Detection Distance, EDD), and detection distance predicted from VL using Adrian model with a field factor of 7 (Computed Detection Distance, CDD)</p></caption>
<graphic alternate-form-of="table3-1477153511433782" xlink:href="10.1177_1477153511433782-table3.tif"/>
<table frame="hsides"><thead align="left">
<tr><th/>
<th>Reference</th>
<th>Road sign (uniform)</th>
<th>Road sign</th>
<th>Pedestrian (uniform)</th>
<th>Pedestrian</th>
<th>Car (uniform)</th>
<th>Car</th>
</tr></thead>
<tbody align="left">
<tr>
<td>EDD</td>
<td>106</td>
<td>120</td>
<td>100</td>
<td>128</td>
<td>124</td>
<td>149</td>
<td>122</td>
</tr>
<tr>
<td>CDD</td>
<td>115</td>
<td>131</td>
<td>112</td>
<td>129</td>
<td>124</td>
<td>146</td>
<td>126</td>
</tr>
<tr>
<td>Deviation</td>
<td>8%</td>
<td>9%</td>
<td>12%</td>
<td>1%</td>
<td>0%</td>
<td>−2%</td>
<td>3%</td>
</tr>
</tbody>
</table>
</table-wrap></p>
<p>In most cases, the computed visibility (CDD) is very close to the measured visibility (EDD), and the highest difference is 12% (<xref ref-type="table" rid="table3-1477153511433782">Table 3</xref>). This comes as a confirmation that the VL is a relevant index for assessing highway visibility. Setting the threshold to VL = 7 yields CDD values close enough to the EDD values so that this threshold can be considered relevant for a simple driving task, such as the one experienced by the participants on the driving simulator. However, the CDD values are most of the time higher than the EDD reference values. Given that EDD values would be even smaller if the drivers were not expecting the targets,<sup><xref ref-type="bibr" rid="bibr29-1477153511433782">29</xref></sup> this suggests that a higher VL threshold should be considered, in order to compute safer detection distance estimates.</p>
</sec>
<sec id="sec14-1477153511433782"><title>4.3. Stopping distance</title>
<p>Let us now consider the impact of the detection distance on the stopping distance, which is directly related to road safety. On a straight horizontal highway, the stopping distance <italic>D<sub>s</sub></italic> is the sum of two terms which both depend on speed <italic>V</italic> (in ms<sup>−1</sup>): the distance driven during RT <italic>t</italic>, and the braking distance on a pavement with a coefficient of friction <italic>F</italic>:
<disp-formula id="disp-formula4-1477153511433782"><label>(4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math4-1477153511433782"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>Vt</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>gF</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic alternate-form-of="disp-formula4-1477153511433782" xlink:href="10.1177_1477153511433782-eq4.tif"/></disp-formula>
with <italic>g</italic> = 9.81 m s<sup>−2</sup>. Typical values for the RT for drivers are around 2 seconds. This is much higher than the RTs measured in the experiment (less than 0.5 second), because drivers are normally unaware that they will need to brake to avoid a collision, whereas the participants in the experiment were expecting the targets. Moreover, the action of stepping on the brake pedal is physiologically a little slower than the action of pressing a button. <xref ref-type="table" rid="table4-1477153511433782">Table 4</xref> shows the stopping distance for a car running at 90 km/h, assuming a RT of 2 seconds and a coefficient of friction ranging from 0.3 (wet pavement) to 0.8 (dry concrete pavement).
<table-wrap id="table4-1477153511433782" position="float"><label>Table 4</label><caption><p>Stopping distance <italic>D<sub>s</sub></italic> for various values of the pavement coefficient of friction <italic>F</italic>, at 90 km/h, with a 2 second reaction time</p></caption>
<graphic alternate-form-of="table4-1477153511433782" xlink:href="10.1177_1477153511433782-table4.tif"/>
<table frame="hsides"><thead align="left">
<tr><th>Coefficient of friction, <italic>F</italic></th>
<th>0.3</th>
<th>0.4</th>
<th>0.5</th>
<th>0.6</th>
<th>0.7</th>
<th>0.8</th>
</tr></thead>
<tbody align="left">
<tr>
<td>Stopping distance, <italic>D<sub>S</sub></italic> (m)</td>
<td>156</td>
<td>130</td>
<td>114</td>
<td>103</td>
<td>96</td>
<td>90</td>
</tr>
</tbody>
</table>
</table-wrap></p>
<p>Previous studies about the VL have discussed the threshold needed to get a fair target detection performance,<sup><xref ref-type="bibr" rid="bibr1-1477153511433782">1</xref>,<xref ref-type="bibr" rid="bibr13-1477153511433782">13</xref>,<xref ref-type="bibr" rid="bibr30-1477153511433782">30</xref>,<xref ref-type="bibr" rid="bibr31-1477153511433782">31</xref></sup> however, recommendations do not propose practical implementations<sup><xref ref-type="bibr" rid="bibr5-1477153511433782">5</xref></sup> or do not use VL thresholds proposed in the scientific literature.<sup><xref ref-type="bibr" rid="bibr6-1477153511433782">6</xref></sup> The data collected in this study suggest some design rules for lighting systems, at least for automotive lighting, based on a ‘safe visibility distance’. Consider a driving scenario – for example, a pedestrian on a highway where the speed limit is 90 km/h. A safe stopping distance can be computed (e.g. with <xref ref-type="disp-formula" rid="disp-formula4-1477153511433782">Equation (4)</xref>) which would set a threshold detection distance (e.g. the braking distance plus 1 second at the regulatory speed). Then, the VL of the reference target (a pedestrian in the current example) could be computed as a function of the headlamp illumination, using the Adrian model and the relative visibility (RV) ratio in <xref ref-type="table" rid="table2-1477153511433782">Table 2</xref>. Based on previous studies about the relevant VL threshold, the lighting system could then be tuned so as to produce this threshold VL value, for example, VL = 7 in the Association Francaise de l'Eclairage recommendations.<sup><xref ref-type="bibr" rid="bibr5-1477153511433782">5</xref></sup> Note that this implies some knowledge about the vehicle performance and road surface characteristics to compute the stopping distance. If a local map of the infrastructure characteristics is available,<sup><xref ref-type="bibr" rid="bibr32-1477153511433782">32</xref></sup> better estimates can be expected.</p>
</sec>
</sec>
<sec id="sec15-1477153511433782" sec-type="Conclusion"><title>5. Conclusion</title>
<p>This study, conducted in controlled conditions on a driving simulator, suggests that the Adrian VL provides a fair description of a visual performance which is related to a safety index (the target detection distance). The results also suggest that the detection performance with the usual reference target (a small uniform square) is quantitatively related to the detection distance with more natural targets. Thus, the VL framework is of great interest for assessing headlight performance.</p>
<p>As expected, the VL of a target at the moment of detection depends on the nature of the target (either a reference square, or a larger target, with a semantic value) and on its texture. It would be interesting to test whether targets with equal mean reflectance and various texture patterns would produce the same VL and detection distance. However, the range of RV ratio, for the tested items, is rather limited (from 95% to 141%, see <xref ref-type="table" rid="table2-1477153511433782">Table 2</xref>), and might be dealt with as a target-dependent correction factor.</p>
<p>Setting the VL threshold at the moment of target detection to VL = 7 (based on the road lighting literature) led to a rather good fit to the data in an automotive lighting scenario. However, for design applications, this threshold value is only relevant for a very simple driving task, such as the one which was simulated in the experiment (rural environment without traffic). Field factor values for more complex situations deserve further study.</p>
<p>These results extend previous findings about visibility indices in road lighting and automotive lighting design, by tackling target visibility in dynamic conditions. In addition, we introduce a detection distance index based on the stopping distance, which allows setting the required visual performance in relation to road (e.g. friction) and vehicle parameters (e.g. speed). Such an index can be related to accident probability and severity,<sup><xref ref-type="bibr" rid="bibr11-1477153511433782">11</xref></sup> which provides a practical solution for introducing risk analysis into lighting design.</p>
<p>The present study is limited to automotive lighting, and the results cannot be extended to road lighting design directly. The relevance of the VL as a predictor of the detection distance in road lighting conditions was tackled in earlier work,<sup><xref ref-type="bibr" rid="bibr17-1477153511433782">17</xref></sup> but the data did not allow a definitive conclusion on that particular aspect, and calls for more investigations. It will also be interesting to compare the object-oriented approach (such as the VL approach described in this paper) to an edge-oriented approach based on image processing<sup><xref ref-type="bibr" rid="bibr20-1477153511433782">20</xref></sup> which makes no hypothesis about the target size or uniformity.</p>
</sec>
</body>
<back>
<sec id="sec16-1477153511433782"><title>Funding</title>
<p>This work was partially supported by the SAGILLIS FUI project.</p>
</sec>
<ack>
<title>Acknowledgement</title>
<p>We wish to thank Vincent Ledoux and Enoch Saint-Jacques who carried out the photometric measurements, and Pierre Charbonnier for helpful advice about the stopping distance computation.</p></ack>
<ref-list>
<title>References</title>
<ref id="bibr1-1477153511433782"><label>1</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adrian</surname><given-names>W</given-names></name></person-group>. <article-title>Visibility levels under night-time driving conditions</article-title>. <source>Journal of the Illuminating Engineering Society</source> <year>1987</year>; <volume>16</volume>: <fpage>3</fpage>–<lpage>12</lpage>.</citation></ref>
<ref id="bibr2-1477153511433782"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adrian</surname><given-names>W</given-names></name></person-group>. <article-title>Visibility of targets: model for calculation</article-title>. <source>Lighting Research and Technology</source> <year>1989</year>; <volume>21</volume>: <fpage>181</fpage>–<lpage>188</lpage>.</citation></ref>
<ref id="bibr3-1477153511433782"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Blackwell</surname><given-names>HR</given-names></name></person-group>. <article-title>Contrast thresholds of the human eye</article-title>. <source>Journal of the Optical Society of America</source> <year>1946</year>; <volume>36</volume>: <fpage>624</fpage>–<lpage>643</lpage>.</citation></ref>
<ref id="bibr4-1477153511433782"><label>4</label><citation citation-type="book"><collab>Commission Internationale de l'Eclairage</collab>. <source>An Analytic Model for Describing the Influence of Lighting Parameters upon Visual Performance</source>, <publisher-loc>CIE publication 19/2. Vienna</publisher-loc>: <publisher-name>CIE</publisher-name>, <year>1981</year>.</citation></ref>
<ref id="bibr5-1477153511433782"><label>5</label><citation citation-type="book"><collab>Association Française de l’Eclairage</collab>. <source>Recommendations Relatives à l’Eclairage des Voies Publiques</source>, <publisher-name>Lux éditions</publisher-name>, <year>2002</year>.</citation></ref>
<ref id="bibr6-1477153511433782"><label>6</label><citation citation-type="book"><collab>Illuminating Engineering Society of North America</collab>. <source>American National Standard Practice for Roadway Lighting, RP-8-00</source>, <publisher-loc>New York</publisher-loc>: <publisher-name>IESNA</publisher-name>, <year>2000</year>.</citation></ref>
<ref id="bibr7-1477153511433782"><label>7</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Olson</surname><given-names>P</given-names></name><name><surname>Aoki</surname><given-names>T</given-names></name><name><surname>Battle</surname><given-names>D</given-names></name><name><surname>Flannagan</surname><given-names>M</given-names></name></person-group>. <source>Development of a Headlight System Performance Evaluation Tool</source>, <publisher-loc>Ann Arbor, MI</publisher-loc>: <publisher-name>The University of Michigan Transportation Research Institute</publisher-name>, <year>1990</year>.</citation></ref>
<ref id="bibr8-1477153511433782"><label>8</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Ising</surname><given-names>K</given-names></name><name><surname>Fricker</surname><given-names>T</given-names></name><name><surname>Lawrence</surname><given-names>J</given-names></name><name><surname>Siegmund</surname><given-names>G</given-names></name></person-group>. <conf-name>Threshold visibility levels for the Adrian visibility model under night-time driving conditions: Proceedings of the Society of Automotive Engineers World Congress</conf-name>. <conf-loc>Detroit, USA, 2003. Paper no. 2003-01-0294. DOI: 10.4271/2003-01-0294</conf-loc>, <year>2003</year>.</citation></ref>
<ref id="bibr9-1477153511433782"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ising</surname><given-names>K</given-names></name></person-group>. <article-title>Threshold visibility levels required for night-time pedestrian detection in a modified Adrian/CIE visibility model</article-title>. <source>Journal of the Illuminating Engineering Society of North America</source> <year>2008</year>; <volume>5</volume>: <fpage>63</fpage>–<lpage>75</lpage>.</citation></ref>
<ref id="bibr10-1477153511433782"><label>10</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Ising</surname><given-names>K</given-names></name><name><surname>Green</surname><given-names>M</given-names></name></person-group>. <conf-name>The distribution of visibility levels at target detection in a modified Adrian/CIE visibility model: Proceedings of the Human Factors and Ergonomic Society Annual Meeting, San Antonio, Texas. October 2009</conf-name>, <year>2009</year>. <fpage>1796</fpage>–<lpage>1800</lpage>.</citation></ref>
<ref id="bibr11-1477153511433782"><label>11</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Gallen</surname><given-names>R</given-names></name><name><surname>Hautière</surname><given-names>N</given-names></name><name><surname>Glaser</surname><given-names>S</given-names></name></person-group>. <conf-name>Advisory speed for intelligent speed adaptation in adverse conditions: Proceedings of the IEEE Intelligent Vehicles Symposium</conf-name>. <conf-loc>San Diego, CA, June 2010</conf-loc>, <year>2010</year>; <fpage>107</fpage>–<lpage>114</lpage>.</citation></ref>
<ref id="bibr12-1477153511433782"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rea</surname><given-names>MS</given-names></name></person-group>. <article-title>Toward a model of visual performance: foundations and data</article-title>. <source>Journal of the Illuminating Engineering Society</source> <year>1986</year>; <volume>15</volume>: <fpage>41</fpage>–<lpage>57</lpage>.</citation></ref>
<ref id="bibr13-1477153511433782"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lecocq</surname><given-names>J</given-names></name></person-group>. <article-title>Calculation of the visibility level of spherical targets in roads</article-title>. <source>Lighting Research and Technology</source> <year>1999</year>; <volume>31</volume>: <fpage>171</fpage>–<lpage>175</lpage>.</citation></ref>
<ref id="bibr14-1477153511433782"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Brémond</surname><given-names>R</given-names></name><name><surname>Dumont</surname><given-names>E</given-names></name><name><surname>Ledoux</surname><given-names>V</given-names></name><name><surname>Mayeur</surname><given-names>A</given-names></name></person-group>. <article-title>Photometric measurements for visibility level computations</article-title>. <source>Lighting Research and Technology</source> <year>2011</year>; <volume>43</volume>: <fpage>119</fpage>–<lpage>128</lpage>.</citation></ref>
<ref id="bibr15-1477153511433782"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mayeur</surname><given-names>A</given-names></name><name><surname>Brémond</surname><given-names>R</given-names></name><name><surname>Bastien</surname><given-names>C</given-names></name></person-group>. <article-title>The effect of task and eccentricity of the target on detection thresholds in mesopic vision</article-title>. <source><italic>Implications for road lighting</italic>. Human Factors</source> <year>2008</year>; <volume>50</volume>: <fpage>712</fpage>–<lpage>721</lpage>.</citation></ref>
<ref id="bibr16-1477153511433782"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mayeur</surname><given-names>A</given-names></name><name><surname>Brémond</surname><given-names>R</given-names></name><name><surname>Bastien</surname><given-names>C</given-names></name></person-group>. <article-title>Effects of the viewing context on peripheral target detection</article-title>. <source><italic>Implications for road lighting design</italic>. Applied Ergonomics</source> <year>2010</year>; <volume>41</volume>: <fpage>461</fpage>–<lpage>468</lpage>.</citation></ref>
<ref id="bibr17-1477153511433782"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mayeur</surname><given-names>A</given-names></name><name><surname>Brémond</surname><given-names>R</given-names></name><name><surname>Bastien</surname><given-names>C</given-names></name></person-group>. <article-title>The effect of the driving activity on target detection as a function of the visibility level</article-title>. <source>Transportation Research Part F: Traffic Psychology and Behaviour</source> <year>2010</year>; <volume>13</volume>: <fpage>115</fpage>–<lpage>128</lpage>.</citation></ref>
<ref id="bibr18-1477153511433782"><label>18</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Brémond</surname><given-names>R</given-names></name><name><surname>Mayeur</surname><given-names>A</given-names></name></person-group>. <conf-name>Some drawbacks of the visibility level as an index of visual performance while driving: Proceedings of the 27th Session of the CIE</conf-name>. <conf-loc>Sun City, South Africa, Vienna: CIE, 2011</conf-loc>, <year>2011</year>; <fpage>1140</fpage>–<lpage>1143</lpage>.</citation></ref>
<ref id="bibr19-1477153511433782"><label>19</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Hautière</surname><given-names>N</given-names></name><name><surname>Dumont</surname><given-names>E</given-names></name></person-group>. <conf-name>Assessment of visibility in complex road scenes using digital imaging: Proceedings of the 26th Session of the CIE</conf-name>. <conf-loc>Beijing, China, VIenna: CIE, July 2007, D4 96–99</conf-loc>, <year>2007</year>.</citation></ref>
<ref id="bibr20-1477153511433782"><label>20</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Joulan</surname><given-names>K</given-names></name><name><surname>Hautière</surname><given-names>N</given-names></name><name><surname>Brémond</surname><given-names>R</given-names></name></person-group>. <conf-name>Contrast sensitivity functions for road visibility estimation on digital images: Proceedings of the 27th Session of the CIE</conf-name>. <conf-loc>Sun City, South Africa, Vienna: CIE, 2011</conf-loc>, <year>2011</year>; <fpage>1144</fpage>–<lpage>1149</lpage>.</citation></ref>
<ref id="bibr21-1477153511433782"><label>21</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Joulan</surname><given-names>K</given-names></name><name><surname>Hautière</surname><given-names>N</given-names></name><name><surname>Brémond</surname><given-names>R</given-names></name></person-group>. <conf-name>A unified framework for edge detection and edge visibility: Proceedings of the CVPR Workshop on Biologically-Consistent Vision</conf-name>. <conf-loc>Colorado Springs, CO: CVPR, 2011, 21–26. DOI: 10.1109/CVPRW.2011.5981679</conf-loc>, <year>2011</year>.</citation></ref>
<ref id="bibr22-1477153511433782"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rea</surname><given-names>MS</given-names></name><name><surname>Bullough</surname><given-names>JD</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name></person-group>. <article-title>A method for assessing the visibility benefits of roadway lighting</article-title>. <source>Lighting Research and Technology</source> <year>2010</year>; <volume>42</volume>: <fpage>215</fpage>–<lpage>241</lpage>.</citation></ref>
<ref id="bibr23-1477153511433782"><label>23</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rosey</surname><given-names>F</given-names></name><name><surname>Auberlet</surname><given-names>J-M</given-names></name><name><surname>Bertrand</surname><given-names>J</given-names></name><name><surname>Plainchault</surname><given-names>P</given-names></name></person-group>. <article-title>Impact of perceptual treatments on lateral control during driving on crest vertical curves: a driving simulator study</article-title>. <source>Accident Analysis and Prevention</source> <year>2008</year>; <volume>40</volume>: <fpage>1513</fpage>–<lpage>1523</lpage>.</citation></ref>
<ref id="bibr24-1477153511433782"><label>24</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Törnos</surname><given-names>J</given-names></name></person-group>. <article-title>Driving behaviour in a real and a simulated road tunnel – a validation study</article-title>. <source>Accident Analysis and Prevention</source> <year>1998</year>; <volume>30</volume>: <fpage>497</fpage>–<lpage>503</lpage>.</citation></ref>
<ref id="bibr25-1477153511433782"><label>25</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bullough</surname><given-names>JD</given-names></name><name><surname>Rea</surname><given-names>MS</given-names></name></person-group>. <article-title>Simulated driving performance and peripheral detection at mesopic and low photopic light levels</article-title>. <source>Lighting Research and Technology</source> <year>2000</year>; <volume>32</volume>: <fpage>194</fpage>–<lpage>198</lpage>.</citation></ref>
<ref id="bibr26-1477153511433782"><label>26</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bella</surname><given-names>F</given-names></name></person-group>. <article-title>Driving simulator for speed research on two-lane rural roads</article-title>. <source>Accident Analysis and Prevention</source> <year>2008</year>; <volume>40</volume>: <fpage>1078</fpage>–<lpage>1087</lpage>.</citation></ref>
<ref id="bibr27-1477153511433782"><label>27</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moon</surname><given-names>P</given-names></name><name><surname>Spencer</surname><given-names>DE</given-names></name></person-group>. <article-title>The visual effect of non-uniform surrounds</article-title>. <source>Journal of the Optical Society of America</source> <year>1945</year>; <volume>35</volume>: <fpage>233</fpage>–<lpage>247</lpage>.</citation></ref>
<ref id="bibr28-1477153511433782"><label>28</label><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Lecocq</surname><given-names>J</given-names></name></person-group>. <conf-name>Visibility level in outdoor lighting. Adrian model applied to spherical cap targets: Proceedings of the 22th Session of the CIE</conf-name>. <conf-loc>Melbourne, Australia, Vienna: CIE, 1991</conf-loc>, <year>1991</year>; <fpage>48</fpage>–<lpage>51</lpage>.</citation></ref>
<ref id="bibr29-1477153511433782"><label>29</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roper</surname><given-names>VJ</given-names></name><name><surname>Howard</surname><given-names>EA</given-names></name></person-group>. <article-title>Seeing with motor car headlamps</article-title>. <source>Transactions of the Illuminating Engineering Society</source> <year>1938</year>; <volume>30</volume>: <fpage>417</fpage>–<lpage>438</lpage>.</citation></ref>
<ref id="bibr30-1477153511433782"><label>30</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bacelar</surname><given-names>A</given-names></name><name><surname>Cariou</surname><given-names>J</given-names></name><name><surname>Hammard</surname><given-names>M</given-names></name></person-group>. <article-title>Calculational visibility model for road lighting installations</article-title>. <source>Lighting Research and Technology</source> <year>1999</year>; <volume>31</volume>: <fpage>177</fpage>–<lpage>180</lpage>.</citation></ref>
<ref id="bibr31-1477153511433782"><label>31</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Paulmier</surname><given-names>G</given-names></name><name><surname>Brusque</surname><given-names>C</given-names></name><name><surname>Carta</surname><given-names>V</given-names></name><name><surname>Nguyen</surname><given-names>V</given-names></name></person-group>. <article-title>The influence of visual complexity on the detection of targets investigated by computer generated images</article-title>. <source>Lighting Research and Technology</source> <year>2001</year>; <volume>33</volume>: <fpage>197</fpage>–<lpage>205</lpage>.</citation></ref>
<ref id="bibr32-1477153511433782"><label>32</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bartels</surname><given-names>C</given-names></name></person-group>. <source>SAFESPOT local dynamic maps – virtual world for safety applications: Proceedings ITS World Congress</source>, <publisher-loc>Beijing, China. October 2007</publisher-loc>, <year>2007</year>.</citation></ref>
</ref-list>
</back>
</article>