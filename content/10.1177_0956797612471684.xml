<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSS</journal-id>
<journal-id journal-id-type="hwp">sppss</journal-id>
<journal-id journal-id-type="nlm-ta">Psychol Sci</journal-id>
<journal-title>Psychological Science</journal-title>
<issn pub-type="ppub">0956-7976</issn>
<issn pub-type="epub">1467-9280</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0956797612471684</article-id>
<article-id pub-id-type="publisher-id">10.1177_0956797612471684</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Individual Differences in Eye Movements During Face Identification Reflect Observer-Specific Optimal Points of Fixation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Peterson</surname><given-names>Matthew F.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Eckstein</surname><given-names>Miguel P.</given-names></name>
</contrib>
<aff id="aff1-0956797612471684">University of California, Santa Barbara</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0956797612471684">Matthew F. Peterson, Department of Psychological &amp; Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA 93106 E-mail: <email>matt.peterson@psych.ucsb.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>24</volume>
<issue>7</issue>
<fpage>1216</fpage>
<lpage>1225</lpage>
<history>
<date date-type="received">
<day>17</day>
<month>4</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>11</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>In general, humans tend to first look just below the eyes when identifying another person. Does everybody look at the same place on a face during identification, and, if not, does this variability in fixation behavior lead to functional consequences? In two conditions, observers had their free eye movements recorded while they performed a face-identification task. In another condition, the same observers identified faces while their gaze was restricted to specific locations on each face. We found substantial differences, which persisted over time, in where individuals chose to first move their eyes. Observers’ systematic departure from a canonical, theoretically optimal fixation point did not correlate with performance degradation. Instead, each individual’s looking preference corresponded to an idiosyncratic performance-maximizing point of fixation: Those who looked lower on the face performed better when forced to fixate the lower part of the face. The results suggest an observer-specific synergy between the face-recognition and eye movement systems that optimizes face-identification performance.</p>
</abstract>
<kwd-group>
<kwd>eye movements</kwd>
<kwd>face perception</kwd>
<kwd>individual differences</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Identifying faces is one of the most common, socially vital visual tasks that humans perform. The combination of task difficulty and evolutionary importance has led to the creation of a network of neural modules dedicated to processing information for the recognition of individual identities, emotional valence, gender, and many other properties (<xref ref-type="bibr" rid="bibr12-0956797612471684">Haxby, Hoffman, &amp; Gobbini, 2000</xref>; <xref ref-type="bibr" rid="bibr16-0956797612471684">Kanwisher, McDermott, &amp; Chun, 1997</xref>). To quickly and accurately accomplish these tasks, the brain’s face-recognition system requires access to high-quality, task-specific visual information. The acquisition of this information is primarily determined by where on the retina the image of the face falls, which, in turn, is determined by where on the face the observer chooses to look.</p>
<p>Many researchers have examined, at the group level, where people move their eyes when looking at faces (<xref ref-type="bibr" rid="bibr2-0956797612471684">Althoff &amp; Cohen, 1999</xref>; <xref ref-type="bibr" rid="bibr5-0956797612471684">Barton, Radcliffe, Cherkasova, Edelman, &amp; Intriligator, 2006</xref>; <xref ref-type="bibr" rid="bibr21-0956797612471684">Peterson &amp; Eckstein, 2012</xref>; <xref ref-type="bibr" rid="bibr28-0956797612471684">Walker-Smith, Gale, &amp; Findlay, 1977</xref>). As a group, humans tend to direct their initial eye movements to a location just below the eyes (<xref ref-type="bibr" rid="bibr14-0956797612471684">Hsiao &amp; Cottrell, 2008</xref>; <xref ref-type="bibr" rid="bibr21-0956797612471684">Peterson &amp; Eckstein, 2012</xref>). Other researchers have focused on variations in looking behavior between well-defined groups, such as nonmembers versus members of clinical populations associated with decreased face-recognition abilities (e.g., autism: <xref ref-type="bibr" rid="bibr7-0956797612471684">Dalton et al., 2005</xref>; schizophrenia: <xref ref-type="bibr" rid="bibr30-0956797612471684">L. M. Williams, Loughland, Gordon, &amp; Davidson, 1999</xref>; prosopagnosia: <xref ref-type="bibr" rid="bibr4-0956797612471684">Barton, Radcliffe, Cherkasova, &amp; Edelman, 2007</xref>; <xref ref-type="bibr" rid="bibr31-0956797612471684">Xivry, Ramon, Lefèvre, &amp; Rossion, 2008</xref>), Western Caucasians versus East Asians (<xref ref-type="bibr" rid="bibr6-0956797612471684">Blais, Jack, Scheepers, Fiset, &amp; Caldara, 2008</xref>; <xref ref-type="bibr" rid="bibr15-0956797612471684">Jack, Blais, Scheepers, Schyns, &amp; Caldara, 2009</xref>), and older versus younger individuals (<xref ref-type="bibr" rid="bibr9-0956797612471684">Firestone, Turk-Browne, &amp; Ryan, 2007</xref>). However, few investigations have focused on differences across seemingly well-matched individuals. There are individual differences in saccade amplitudes and fixation durations, and these differences are conserved across tasks (<xref ref-type="bibr" rid="bibr22-0956797612471684">Rayner, Li, Williams, Cave, &amp; Well, 2007</xref>). In relation to the spatial distribution of saccades, <xref ref-type="bibr" rid="bibr28-0956797612471684">Walker-Smith et al. (1977)</xref> found variation between individuals, although the researchers measured only 3 observers and did not evaluate the stability of these differences across time.</p>
<p>If people do enact consistent, individualized eye movement patterns during face viewing, are these strategies correlated with recognition performance? There is a large variation in face-recognition ability within nonclinical populations (<xref ref-type="bibr" rid="bibr8-0956797612471684">Duchaine &amp; Nakayama, 2006</xref>). In a recent study, <xref ref-type="bibr" rid="bibr24-0956797612471684">Sekiguchi (2011)</xref> reported differences in specific measurements of eye movement behavior, such as time spent fixating the eyes and the number of saccadic transitions, but not in the overall distribution of fixations across internal features. Furthermore, the study showed that there are distinct fixation times on the eyes and number of saccadic transitions for high- and low-performing groups.</p>
<p>In the research reported here, we first tested for systematic individual differences in the landing point of the initial eye movement during a face-identification task. Second, we assessed the stability of these differences across time. Third, we explored the functional consequences of individual differences in face-recognition eye movement behavior. Fourth, we quantified the distance between each observer’s preferred point of fixation and that of an optimal fixation strategy based on a rational Bayesian observer that takes into account the statistical distribution of discriminating information in the faces, the task demands, and a canonical foveated visual system. Specifically, we tested two hypotheses: first, that an individual’s perceptual performance in a face-identification task can be predicted by the distance from the observer’s preferred point of fixation to the optimal point of fixation as determined by a rational, foveated Bayesian observer, and second, that individual differences in where people choose to first fixate when recognizing a face correspond to individual differences in fixation-location-dependent perceptual performance, such that perceptual performance (identification accuracy) is maximized at the preferred point of fixation.</p>
<sec id="section1-0956797612471684" sec-type="methods">
<title>Method</title>
<sec id="section2-0956797612471684">
<title>Participants</title>
<p>Thirty Caucasian undergraduate students (18 female, 12 male; age range = 19–23 years) from the University of California, Santa Barbara, participated in the study in return for course credit. All observers had normal or corrected-to-normal vision and no history of neurological disorders.</p>
</sec>
<sec id="section3-0956797612471684">
<title>Stimuli and display</title>
<p>In-house frontal-view photographs of 10 male undergraduates were cropped to remove background, hair, and clothing before being scaled so that the distance from the bottom of the hairline to the bottom of the chin was equated across the set (15.25° of visual angle). Stimuli were presented on a linearly calibrated monitor with a mean luminance of 25 cd/m<sup>2</sup>. Images were converted to 8-bit gray scale, contrast-energy normalized, and embedded in white Gaussian noise with a standard deviation of 2.75 cd/m<sup>2</sup> (see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1a</xref>).</p>
<fig id="fig1-0956797612471684" position="float">
<label>Fig. 1.</label>
<caption>
<p>Task structure and free eye movements. Observers began (a) trials in the <italic>short</italic> and <italic>long</italic> conditions (free–eye movement conditions) by fixating outside the area where the impending stimulus would appear (possible fixation points are indicated by the dashed boxes); by contrast, observers began trials in the fixed condition by gazing continuously at one of four specified locations along the vertical midline of the display (a). After fixation, a face image was displayed, followed by a Gaussian noise mask and then a display showing several faces. Observers had to select the face that had been shown earlier by clicking on it using a computer mouse, and feedback (a red square around the correct face) was shown. The illustration in (b) shows the average landing point of the first saccade for each of the 30 observers and the average landing point across the group. The white line represents the vertical midline. The illustration in panel (c) shows all saccades from 2 example observers: B. B. (an eye looker; saccades indicated by red dots, average indicated by white dot) and J. G. (a nose looker; saccades indicated by light blue dots, average indicated by black dot). The scatter plot in (d) shows the correlation between preferred saccadic end points in the <italic>short</italic> and <italic>long</italic> conditions.</p>
</caption>
<graphic xlink:href="10.1177_0956797612471684-fig1.tif"/>
</fig>
</sec>
<sec id="section4-0956797612471684">
<title>Procedure</title>
<p>Observers completed a face-identification task in three conditions—two in which free eye movements were allowed and one in which forced fixation was required. First, participants completed a 500-trial training set with a long display time (<italic>long</italic> condition: 1,500 ms). Next, they completed 500 trials with a short display time (<italic>short</italic> condition: 350 ms). Last, observers completed 1,500 trials that forced them to maintain fixation at various discrete locations (fixed condition). Eight observers returned to complete the task again in the <italic>short</italic> condition, under the same experimental conditions, after delays ranging from 90 to 525 days (<italic>M</italic> = 176 days).</p>
<sec id="section5-0956797612471684">
<title>Free eye movements</title>
<p>Each trial of the <italic>short</italic> and <italic>long</italic> conditions began with the presentation of a fixation cross at one of eight positions (randomly selected with equal probability) located outside the area where the impending face image would appear with an average distance of 13.95° of visual angle from the center of stimulus (see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1a</xref>). The peripheral starting locations were used to avoid initial fixation bias whereby task information could be accrued prior to an eye movement (<xref ref-type="bibr" rid="bibr3-0956797612471684">Arizpe, Kravitz, Yovel, &amp; Baker, 2012</xref>; <xref ref-type="bibr" rid="bibr14-0956797612471684">Hsiao &amp; Cottrell, 2008</xref>). Observers fixated the cross and pressed the space bar on a keyboard. If, before stimulus presentation, the eye position fell more than 1° from the center of the cross, an error screen would be displayed, followed by a cross at the same location. Following a 500- to 1,500-ms delay, the cross was removed and a randomly sampled face was displayed in the center of the monitor. Participants were free to move their eyes while the face image was present. The face was then replaced with a high-contrast white Gaussian noise mask for 500 ms, followed by a response screen with high-contrast, noise-free versions of the possible faces. Subjects used the mouse to select a face. Feedback was provided by framing the correct answer with a red box before beginning the next trial (see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1a</xref>).</p>
</sec>
<sec id="section6-0956797612471684">
<title>Forced fixation</title>
<p>Each trial of the fixed condition began with the presentation of a fixation cross at one of four locations (randomly selected) along the monitor’s vertical midline (3° apart, corresponding to the center of the mouth, nose tip, center of the eyes, and forehead; see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1a</xref>). The procedure was the same as in the <italic>short</italic> and <italic>long</italic> conditions except that eye movements were not allowed during the 200-ms stimulus presentation (if gaze fell more than 1° from the center of the cross, an error screen would be displayed, followed by a cross at the same location and a random resampling of a new face).</p>
</sec>
</sec>
<sec id="section7-0956797612471684">
<title>Eye tracking</title>
<p>The left eye of each participant was tracked using an SR Research EyeLink 1000 Tower Mount eye tracker sampling at 250 Hz. A nine-point calibration and validation were run before each 125-trial session with a mean error of no more than 0.5° of visual angle. Saccades were classified as events in which eye velocity was greater than 22°/s and eye acceleration exceeded 4000°/s<sup>2</sup>.</p>
</sec>
<sec id="section8-0956797612471684">
<title>Saccade-based observer classification</title>
<p>We assessed the consistency and distinctiveness with which individuals executed eye movement strategies by constructing a simple minimum-distance saccade-generator classifier. Each observer’s first fixations from the <italic>short</italic> condition were placed randomly into <italic>K</italic> groups in which <italic>K</italic> ranged between 2 and 500. For each of the <italic>K</italic> groups, each observer’s mean <italic>x</italic> and <italic>y</italic> fixation positions were computed (the test set). The distance between these means and the means computed for each observer from the remaining <italic>K–1</italic> groups (the training set) were calculated. The classifier chose the observer, <italic>j</italic>, who produced the training set with the smallest distance to the test location as the prediction for who generated the test data:</p>
<p><disp-formula id="disp-formula1-0956797612471684">
<mml:math display="block" id="math1-0956797612471684">
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>c</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>n</mml:mi>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mrow>
<mml:mi>arg</mml:mi>
<mml:mi>min</mml:mi>
</mml:mrow>
<mml:mi>j</mml:mi>
</mml:munder>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>x</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>x</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>y</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>y</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>t</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>n</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0956797612471684" xlink:href="10.1177_0956797612471684-eq1.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula1-0956797612471684">
<mml:math display="inline" id="math2-0956797612471684">
<mml:mover accent="true">
<mml:mi>x</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula2-0956797612471684">
<mml:math display="inline" id="math3-0956797612471684">
<mml:mover accent="true">
<mml:mi>y</mml:mi>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> represent the mean <italic>x</italic>- and <italic>y</italic>-coordinates for the training- and test-saccade groups. This procedure was repeated for each of the <italic>K</italic> groups. To assess chance performance, we ran the same classifier but randomized the observer labels on the test set.</p>
</sec>
<sec id="section9-0956797612471684">
<title>Optimal point of fixation for a foveated ideal observer</title>
<p>An ideal observer is a model that makes statistically optimal decisions about the presence of a signal that is corrupted by stochastic noise (<xref ref-type="bibr" rid="bibr10-0956797612471684">Geisler, 2011</xref>; <xref ref-type="bibr" rid="bibr17-0956797612471684">Kersten, Mamassian, &amp; Yuille, 2004</xref>; <xref ref-type="bibr" rid="bibr25-0956797612471684">Sekuler, Gaspar, Gold, &amp; Bennett, 2004</xref>). For a given noisy image, such as those presented to the observers in this study, an ideal observer calculates the posterior probabilities for each of the possible stimulus classes that have been presented and takes the maximum of these probabilities as its decision (<xref ref-type="bibr" rid="bibr11-0956797612471684">Green &amp; Swets, 1989</xref>). We modified the ideal observer by implementing a canonical, spatially variant filtering function to simulate the effects of decreasing contrast sensitivity in the periphery (<xref ref-type="bibr" rid="bibr20-0956797612471684">Peli, Yang, &amp; Goldstein, 1991</xref>; <xref ref-type="bibr" rid="bibr21-0956797612471684">Peterson &amp; Eckstein, 2012</xref>). For any fixation point, this foveated ideal observer (FIO) processes the noisy face image with a series of linear filters in which the form of each filter, in the frequency domain, is a function of both the distance from fixation (retinal eccentricity) and the direction (e.g., upper visual field vs. lower visual field). The FIO then compares this filtered stimulus with filtered versions of the possible faces and selects the one most likely to have generated the noisy image. Averaged group performance from the fixed condition was used to fit the free parameters of the model, which were then held constant to compute predicted performance for each possible fixation (<xref ref-type="bibr" rid="bibr21-0956797612471684">Peterson &amp; Eckstein, 2012</xref>). For further details, see the <xref ref-type="app" rid="app1-0956797612471684">appendix</xref>.</p>
</sec>
</sec>
<sec id="section10-0956797612471684" sec-type="results|discussion">
<title>Results and Discussion</title>
<sec id="section11-0956797612471684">
<title>Individual differences in preferred point of fixation and their reliability</title>
<p>The short presentation time allowed for one or, very rarely, two saccades during stimulus presentation (<italic>M</italic> = 1.04; only first saccades analyzed). The speeded nature of the task along with the increased difficulty introduced by noise corruption required observers to execute strategic eye movements that maximized information acquisition given a single fixation. This requirement resulted in eye movement patterns that showed a clear differentiation from the classic T pattern (with saccadic transitions between the two eyes and the mouth) observed in face-perception studies that have used longer presentation times and stimuli that were easier to identify (<xref ref-type="bibr" rid="bibr13-0956797612471684">Henderson, Williams, &amp; Falk, 2005</xref>; <xref ref-type="bibr" rid="bibr23-0956797612471684">Rizzo, Hurtig, &amp; Damasio, 1987</xref>; <xref ref-type="bibr" rid="bibr29-0956797612471684">C. C. Williams &amp; Henderson, 2007</xref>; but see <xref ref-type="bibr" rid="bibr14-0956797612471684">Hsiao &amp; Cottrell, 2008</xref>, for a corresponding observation using similar experimental parameters and Fig. S1, in the Supplemental Material available online, showing a progression toward a feature-targeting pattern in the <italic>long</italic> condition after the initial saccade).</p>
<p>Participants universally moved their eyes close to the vertical midline but displaced slightly though significantly to the right side of the face, µ<sub>distance from midline</sub> = 0.62°, <italic>t</italic>(29) = 7.46, <italic>p</italic> &lt; .001, one-tailed (see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1b</xref> for average saccade landing points). On average, observers fixated a location slightly below the eyes, µ<sub>distance below center of eyes</sub> = 1.48°, <italic>SEM =</italic> 0.20°. In contrast to the tight horizontal grouping, there was greater interindividual variability in the vertical position of observers’ saccadic end points (σ<sub>horizontal</sub> = 0.47°, σ<sub>vertical</sub> = 1.05°; <italic>p</italic> &lt; .002, bootstrap with 10,000 draws; see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1b</xref>). Variation in observers’ mean landing points was accompanied by differences in fixation-distribution variance. The average within-subjects variability, σ<sub>vertical</sub> = 1.12°, mirrored the interindividual variance reported earlier, whereas the ratios of the fixation distributions’ standard deviations to the initial saccade lengths were in close correspondence to those in previous reports (<italic>M</italic> = 8.9%, range = 6.1–13.6%; see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1c</xref>; <xref ref-type="bibr" rid="bibr18-0956797612471684">McGowan, Kowler, Sharma, &amp; Chubb, 1998</xref>). Correlating mean first-saccade landing position between the <italic>long</italic> and <italic>short</italic> conditions (see <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1d</xref>) showed a highly reliable relationship in eye movement behavior, <italic>r</italic>(28) = .89, <italic>p</italic> &lt; .001, which suggests that the preferred point of fixation does not depend on time constraints. Consistent with previous studies on face learning, fixation variance was greater during the first third of the trials in the <italic>long</italic> condition, when observers were learning the faces, than during the trials in the <italic>short</italic> condition, when observers already had learned the faces (see Fig. S2; <xref ref-type="bibr" rid="bibr13-0956797612471684">Henderson et al., 2005</xref>).</p>
</sec>
<sec id="section12-0956797612471684">
<title>Temporal stability of preferred point of fixation</title>
<p>How specific are these strategies to the individual? If observers execute consistent, idiosyncratic eye movement plans, then we should be able to predict which individual generated a given sample of saccades. Using our minimum-distance classifier (see the Method section), we found that individuals consistently executed distinctive eye movement strategies, with classifier performance identifying individuals from their fixations significantly above chance level for all values of the test-group size (<italic>K</italic> = number of averaged saccade end points; all <italic>p</italic>s &lt; .001; see <xref ref-type="fig" rid="fig2-0956797612471684">Fig. 2a</xref> for consistency and reliability of individual differences in eye movement behavior).</p>
<fig id="fig2-0956797612471684" position="float">
<label>Fig. 2.</label>
<caption>
<p>Consistency and reliability of individual differences in eye movement behavior. The graph in (a) shows the accuracy of a simple minimum-distance classifier in predicting which of the 30 observers generated a given random sample of saccades from the <italic>short</italic> condition (black dots). Gray dots indicate chance-level performance given by observer-label permutation. The average landing point for 8 observers is shown in (b); results from the <italic>short</italic> condition in the original test sessions are indicated by solid dots, and results from the retest sessions (completed 3–17 months later) are indicated by open circles. The left inset illustrates the correlation between the vertical positions of observers’ eye movements in the test and retest sessions. The right inset shows the accuracy of the minimum-distance classifier, trained on saccade samples from the original test sessions, in predicting which observer generated a given sample during retesting. Error bars represent ±1 <italic>SEM</italic>.</p>
</caption>
<graphic xlink:href="10.1177_0956797612471684-fig2.tif"/>
</fig>
<p>The <italic>short</italic>-condition sessions were completed during the course of 1 or 2 days. It is feasible that participants could have used ad hoc strategies for that particular testing time that were not representative of their general face-identification behavior. To assess the reliability of observer-specific eye movement patterns, we had 8 observers return to complete another 500 trials in the <italic>short</italic> condition. Inspection of each observer’s centroids for the original (Run 1) and retest (Run 2) sessions suggested a consistent preference for distinctive points of fixation over time (see <xref ref-type="fig" rid="fig2-0956797612471684">Fig. 2b</xref>).</p>
<p>We quantified this temporal stability in two ways. First, we correlated the distance below the eyes of each observer’s mean landing point between Run 1 and Run 2 (see left inset, <xref ref-type="fig" rid="fig2-0956797612471684">Fig. 2b</xref>). The close proximity of points to the identity line suggests a unique fixed strategy for each individual, <italic>r</italic>(6) = .95, <italic>p</italic> &lt; .001. Next, we used the minimum-distance classifier under three different train/test conditions using a leave-one-out methodology (i.e., <italic>K</italic> = 500; see right inset, <xref ref-type="fig" rid="fig2-0956797612471684">Fig. 2b</xref>). First, we trained and tested on data from the original <italic>short</italic>-condition sessions. We then did the same for the retest <italic>short</italic>-condition sessions. Finally, we trained on fixation data from Run 1 and tested on data from Run 2. Unsurprisingly, classification was best when we trained and tested on the same run, although not significantly so, <italic>F</italic>(2, 21) = 0.20, <italic>p</italic> = .82. However, classification accuracy remained significantly above chance when we trained on data collected for the original <italic>short-</italic>condition session and tested on data collected for the subsequent <italic>short</italic>-condition session, <italic>t</italic>(7) = 2.97, <italic>p</italic> = .02. These results show that individuals enact distinctive eye movement strategies when identifying faces and that these strategies are stable over time.</p>
</sec>
<sec id="section13-0956797612471684">
<title>Center-of-gravity fixations</title>
<p>Finally, the possibility exists that the observed fixation patterns are not specific to face identification but, rather, are driven by a general center-of-gravity strategy (<xref ref-type="bibr" rid="bibr26-0956797612471684">Tatler, 2007</xref>). We tested two hypotheses: that observers targeted the geometric center of the visible area of the face (within the black frame; yellow dot in <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1c</xref>) and, alternatively, that observers targeted the geometric center of the square frame and monitor (blue dot in <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1c</xref>). Every observer fixated significantly away from the visible face center, whereas 28 observers fixated significantly away from the frame/monitor center, all <italic>p</italic>s &lt; .001. In addition, 5 new observers participated in a control study in which the positions of both the face image and the initial fixation were variable and independent (see Fig. S3). No significant differences were found in where observers chose to look, on average, between image-location and initial fixation–location conditions. Although the within-subjects variance was slightly greater when the image location was allowed to vary, the between-subjects variance remained unaltered, which supports an interpretation that eye movement strategies are individualized and specific to faces (see Fig. S4 and Table S1) and are mostly determined with respect to the outline of the face and internal features, together or individually, rather than the position of the face relative to the frame or the monitor.</p>
</sec>
<sec id="section14-0956797612471684">
<title>Functional consequences of individual differences in preferred points of fixation</title>
<p>We addressed the question of whether the differences in preferred fixation points are random effects between observers (i.e., idiosyncratic overpracticed behavior) with no perceptual function or consequence or, instead, translate to differences in perceptual performance. To assess the effects of different fixation locations on task performance, we measured face-identification accuracy as a function of forced-fixation location (see the Method section and <xref ref-type="fig" rid="fig1-0956797612471684">Fig. 1a</xref>). The group results showed that different points of fixation led to different levels of performance, with identification accuracy falling off rapidly above the eyes and below the nose (see <xref ref-type="fig" rid="fig3-0956797612471684">Fig. 3</xref> for the relationship between performance and gaze location).</p>
<fig id="fig3-0956797612471684" position="float">
<label>Fig. 3.</label>
<caption>
<p>Relationship between performance and gaze location. The graph in (a) shows the average accuracy in the fixed condition for all 30 observers as a function of the fixation’s degrees of visual angle from the eyes of a face image (indicated by black dots) and the foveated-ideal-observer model’s predicted levels of accuracy (indicated by the curve). The black arrow represents the average landing position in the <italic>short</italic> condition. The scatter plot in (b) illustrates the correlation between observers’ overall accuracy in the <italic>short</italic> condition and average distance of saccade landing points from the optimal fixation point. Plotted points represent results for individual observers, and the best-fitting regression line is shown. Error bars represent ±1 <italic>SEM</italic>.</p>
</caption>
<graphic xlink:href="10.1177_0956797612471684-fig3.tif"/>
</fig>
<p>This relationship between fixation choice and performance can be predicted by an ideal face-identifier model equipped with a simulated canonical foveated visual system estimated from multiple observers (the FIO; see the Method section and the <xref ref-type="app" rid="app1-0956797612471684">appendix</xref>; <xref ref-type="bibr" rid="bibr21-0956797612471684">Peterson &amp; Eckstein, 2012</xref>). Running the FIO on the group data showed a predicted maximum performance peak at 1.48° below the eyes, which corresponded closely to the average group landing position from the free–eye movement conditions (<xref ref-type="fig" rid="fig3-0956797612471684">Fig. 3a</xref>).</p>
<p>If all observers had roughly similar spatially dependent visual processing (referred to as the <italic>visibility map</italic>) and higher-order identification mechanisms, we would expect there to be a single optimal region where fixations lead to maximum identification performance. Here, such an effect would result in a statistical relationship between saccade location (taken as the distance from the observer’s mean <italic>y</italic>-coordinate to the group’s optimal fixation point) and task performance (the proportion of correct identifications in the <italic>short</italic> condition). Specifically, we would expect observers who regularly move their eyes far away from the optimal point to perform poorly relative to their group-optimal counterparts. However, our results showed that there was no relationship between the distance of observers’ preferred points of fixation from that of the theoretical optimal fixation and observers’ face-identification accuracy, <italic>r</italic>(28) = −.08, <italic>p</italic> = .66 (see <xref ref-type="fig" rid="fig3-0956797612471684">Fig. 3b</xref>).</p>
<p>We next tested the hypothesis that observers follow eye movement strategies that maximize their own task performance. For example, individuals who fixate near the nose region would have an associated higher perceptual accuracy when forced to fixate the nose rather than the eyes. Observers who preferentially fixate the eyes would show higher accuracy when forced to fixate the eyes rather than the nose. Our results for the fixed condition showed distinctive performance profiles, with every observer exhibiting peak performance either at the eyes or at the nose tip. We first looked for evidence that fixation-dependent performance varied between separate, well-defined groups of observers. We took the 7 observers whose average saccade landing points were the highest on the face (<italic>eye lookers</italic>) and the 7 observers whose average landing points were the lowest on the face (<italic>nose lookers</italic>) and computed each group’s fixation-dependent performance profile (see <xref ref-type="fig" rid="fig4-0956797612471684">Fig. 4a</xref>). If the differences in observers’ free eye movement behavior are indeed random, then we would expect to find no systematic difference in performance profiles between the groups.</p>
<p>Defining change in proportion correct (ΔPC) as the difference in performance between the eye- and nose-looker groups, we found that performance, when forced to fixate the forehead or the eyes, showed no differentiation between the groups—ΔPC<sub>forehead</sub> = .019, <italic>t</italic>(12) = 0.25, <italic>p</italic> = .81, two-tailed; ΔPC<sub>eyes</sub> = .001, <italic>t</italic>(12) = 0.01, <italic>p</italic> = .99, two-tailed. However, there was a clear discrepancy for forced fixations below the eyes, with the eye lookers experiencing a severe degradation in performance compared with the nose lookers—ΔPC<sub>nose</sub> = −.143, <italic>t</italic>(12) = −1.88, <italic>p</italic> = .04, one-tailed; ΔPC<sub>mouth</sub> = −.215, <italic>t</italic>(12) = −2.96, <italic>p</italic> = .01, one-tailed.</p>
<fig id="fig4-0956797612471684" position="float">
<label>Fig. 4.</label>
<caption>
<p>Correspondence between fixation-dependent performance and saccadic behavior. The graph in (a) shows proportion correct as a function of the distance (degrees of visual angle) between forced-fixation points and the eyes of face images in the fixed condition. Results are shown for two groups of extreme observers: eye lookers and nose lookers. Arrows represent the mean landing positions for eye lookers and nose lookers (black and gray, respectively) in the <italic>short</italic> condition. The scatter plot in (b) illustrates the correlation between the preferred saccadic end point and the difference in accuracy (proportion correct) when observers were forced to fixate the nose versus the eyes. Plotted points represent results for individual observers, and the best-fitting regression line is shown. Error bars represent ±1 <italic>SEM</italic>.</p>
</caption>
<graphic xlink:href="10.1177_0956797612471684-fig4.tif"/>
</fig>
<p>We also analyzed the relationship between eye movements and performance at the individual level to evaluate whether each observer’s distinctive performance profile corresponded to his or her selection of eye movement behavior. We used the difference in performance between the nose- and eye-fixation trials as a metric of the relative benefit for fixating lower versus higher on the face (ΔPC<sub>nose-eyes</sub>). We correlated the distance, in degrees of visual angle, below the eyes of each observer’s preferred fixation location from the <italic>short</italic> condition and ΔPC<sub>nose-eyes</sub> (see <xref ref-type="fig" rid="fig4-0956797612471684">Fig. 4b</xref>). If observers execute eye movements that account for their distinctive fixation-dependent task abilities, then there should be a strong relationship between saccade-end-point choice and the difference in performance for upper- compared with lower-face fixation. <xref ref-type="fig" rid="fig4-0956797612471684">Figure 4b</xref> shows that this was indeed the case: Observers who looked lower on the face when they were able to move their eyes freely showed an associated performance benefit when looking lower on the face, <italic>r</italic>(28) = .78, <italic>p</italic> &lt; .001.</p>
</sec>
<sec id="section15-0956797612471684">
<title>Source of variation in fixation-dependent performance profiles</title>
<p>Unlike results from a previous study (<xref ref-type="bibr" rid="bibr24-0956797612471684">Sekiguchi, 2011</xref>), our results showed that there are systematic differences in the preferred point of fixation across individuals. What might explain this discrepancy? Almost all of the studies in the face-recognition literature have allowed for long viewing times even though humans identify faces very rapidly, often within one or two fixations (<xref ref-type="bibr" rid="bibr14-0956797612471684">Hsiao &amp; Cottrell, 2008</xref>). Thus, the great majority of eye movement data analyzed in these studies were collected after identification had most likely been accomplished. There is a strong possibility that eye movements late in the presentation time represent default social behavior, such as maintaining consistent eye contact, which could be driven by a more homogenous strategy across the population. We focused on the first saccade, which might have paramount importance in acquiring task-relevant information.</p>
<p>A second question relates to the source and cause of these individual differences in eye movement strategies and the associated optimal-performance fixation points. How could different observers, looking at the same stimuli, have such distinctive performance profiles? One plausible explanation is that humans formulate fixation strategies that maximize performance given knowledge of their distinctive foveated system. It is well known that although visibility universally deteriorates in the periphery, the steepness, total amount, and directionality (i.e., differences between upper, lower, and horizontal visual fields; <xref ref-type="bibr" rid="bibr1-0956797612471684">Abrams, Nizam, &amp; Carrasco, 2012</xref>) of degradation differ greatly between individuals. A person who sees very well in the upper visual field but poorly in the lower visual field would do well to fixate toward the bottom of the face, where information from the information-rich eyes (<xref ref-type="bibr" rid="bibr21-0956797612471684">Peterson &amp; Eckstein, 2012</xref>; <xref ref-type="bibr" rid="bibr25-0956797612471684">Sekuler et al., 2004</xref>; <xref ref-type="bibr" rid="bibr27-0956797612471684">Vinette, Gosselin, &amp; Schyns, 2004</xref>) can still be acquired with high fidelity while allowing information from the mouth to fall on the fovea. The ability of humans to maximize task performance through optimal eye movement selection for their specific visibility map leaves this explanation as a possibility (<xref ref-type="bibr" rid="bibr19-0956797612471684">Najemnik &amp; Geisler, 2005</xref>).</p>
<p>However, a second possibility cannot be discarded. Face identification presumably requires, at some stage in the visual stream, the comparison of available visual information with stored representations of each identity’s face. Furthermore, recognizing faces is one of the most common and most socially important tasks humans perform, with constant exposure and practice from birth. If, from early in life, humans adopt a fixation strategy that does not necessarily maximize information gain, it is feasible that the burgeoning face-recognition network develops recognition strategies that maximize performance for the individual’s distinctive choice of looking behavior. This maximized performance could be realized in multiple ways, either at the lower or higher levels of the visual architecture. At the lower level, the individual’s peripheral processing ability itself could be shaped by long-term experience with viewing faces and other perceptual stimuli at a given fixation region (e.g., modulation of the developing contrast-sensitivity function as a function of eccentricity). At the higher level, the face-recognition system could optimize its identification algorithm by using fixation-specific internal representations and computations (fixation-specific coding). Although research providing adequately precise measurements of infant eye movements and their evolution with age currently does not exist to support any strong claims to this possibility, it would seem to be a fruitful avenue for future research.</p>
</sec>
</sec>
</body>
<back>
<app-group>
<app id="app1-0956797612471684">
<title>Appendix</title>
<p>We modeled the decrease in resolution and sensitivity in the visual periphery with a canonical, spatially variant contrast-sensitivity function (<italic>SVCSF</italic>; <xref ref-type="bibr" rid="bibr20-0956797612471684">Peli et al., 1991</xref>) given by</p>
<p><disp-formula id="disp-formula2-0956797612471684">
<mml:math display="block" id="math4-0956797612471684">
<mml:mrow>
<mml:mi>S</mml:mi>
<mml:mi>V</mml:mi>
<mml:mi>C</mml:mi>
<mml:mi>S</mml:mi>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>f</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>r</mml:mi>
<mml:mo>,</mml:mo>
<mml:mtext>θ</mml:mtext>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:msup>
<mml:mi>f</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:msup>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>b</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mi>f</mml:mi>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>θ</mml:mtext>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>r</mml:mi>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0956797612471684" xlink:href="10.1177_0956797612471684-eq2.tif"/>
</disp-formula>
</p>
<p>where <italic>a</italic><sub>0</sub>, <italic>b</italic><sub>0</sub>, and <italic>c</italic><sub>0</sub> are constants chosen to set the peak contrast sensitivity at 1 and the frequency of peak sensitivity in the fovea at 4 cycles per degree of visual angle; <italic>f</italic> is spatial frequency in cycles per degree of visual angle; <italic>r</italic> is distance from fixation in degrees of visual angle; <italic>d</italic><sub>0</sub> is termed the eccentricity factor, which determines how quickly sensitivity is attenuated with peripheral distance; and θ is the direction, an angle in polar coordinates, from fixation.</p>
<p>For any fixation point k, the foveated ideal observer filters each region of the noisy face image in the frequency domain with a unique <italic>SVCSF</italic> specified by its distance and direction from fixation (see Fig. S5 in the Supplemental Material). This image is compared with similarly filtered versions of the possible faces, resulting in a vector of template responses, <bold>r</bold><sub><italic>k</italic></sub>. These responses follow a multivariate normal distribution for which the likelihood, l, of face <italic>i</italic> being present is calculated as</p>
<p><disp-formula id="disp-formula3-0956797612471684">
<mml:math display="block" id="math5-0956797612471684">
<mml:mrow>
<mml:msub>
<mml:mi>ℓ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:mfrac>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>r</mml:mi>
</mml:mstyle>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>μ</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mi>T</mml:mi>
</mml:msup>
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mi>k</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>r</mml:mi>
</mml:mstyle>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mstyle mathsize="normal" mathvariant="bold">
<mml:mi>μ</mml:mi>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0956797612471684" xlink:href="10.1177_0956797612471684-eq3.tif"/>
</disp-formula></p>
<p>where <bold>µ</bold><sub><italic>i,k</italic></sub> is the mean response under the hypothesis that face <italic>i</italic> was present, Σ<sub><italic>k</italic></sub> is the response covariance, and <italic>T</italic> is the transpose operator. The foveated ideal observer takes the maximum likelihood as its decision.</p>
</app>
</app-group>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>Funding for this work was supported by Grant EY-015925 from the National Institutes of Health, National Eye Institute.</p>
</fn>
<fn fn-type="supplementary-material">
<label>Supplemental Material</label>
<p>Additional supporting information may be found at <ext-link ext-link-type="uri" xlink:href="http://pss.sagepub.com/content/by/supplemental-data">http://pss.sagepub.com/content/by/supplemental-data</ext-link></p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Abrams</surname><given-names>J.</given-names></name>
<name><surname>Nizam</surname><given-names>A.</given-names></name>
<name><surname>Carrasco</surname><given-names>M.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Isoeccentric locations are not equivalent: The extent of the vertical meridian asymmetry</article-title>. <source>Vision Research</source>, <volume>52</volume>, <fpage>70</fpage>–<lpage>78</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.visres.2011.10.016</pub-id></citation>
</ref>
<ref id="bibr2-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Althoff</surname><given-names>R. R.</given-names></name>
<name><surname>Cohen</surname><given-names>N. J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Eye-movement-based memory effect: A reprocessing effect in face perception</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>25</volume>, <fpage>997</fpage>–<lpage>1010</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0278-7393.25.4.997</pub-id></citation>
</ref>
<ref id="bibr3-0956797612471684">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Arizpe</surname><given-names>J.</given-names></name>
<name><surname>Kravitz</surname><given-names>D. J.</given-names></name>
<name><surname>Yovel</surname><given-names>G.</given-names></name>
<name><surname>Baker</surname><given-names>C. I.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Start position strongly influences fixation patterns during face processing: Difficulties with eye movements as a measure of information use</article-title>. <source>PLoS ONE</source>, <volume>7</volume>(<issue>2</issue>), <fpage>e31106</fpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0031106">http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0031106</ext-link></citation>
</ref>
<ref id="bibr4-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barton</surname><given-names>J. J. S.</given-names></name>
<name><surname>Radcliffe</surname><given-names>N.</given-names></name>
<name><surname>Cherkasova</surname><given-names>M. V.</given-names></name>
<name><surname>Edelman</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Scan patterns during the processing of facial identity in prosopagnosia</article-title>. <source>Experimental Brain Research</source>, <volume>181</volume>, <fpage>199</fpage>–<lpage>211</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00221-007-0923-2</pub-id></citation>
</ref>
<ref id="bibr5-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barton</surname><given-names>J. J. S.</given-names></name>
<name><surname>Radcliffe</surname><given-names>N.</given-names></name>
<name><surname>Cherkasova</surname><given-names>M. V.</given-names></name>
<name><surname>Edelman</surname><given-names>J.</given-names></name>
<name><surname>Intriligator</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Information processing during face recognition: The effects of familiarity, inversion, and morphing on scanning fixations</article-title>. <source>Perception</source>, <volume>35</volume>, <fpage>1089</fpage>–<lpage>1105</lpage>.</citation>
</ref>
<ref id="bibr6-0956797612471684">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Blais</surname><given-names>C.</given-names></name>
<name><surname>Jack</surname><given-names>R. E.</given-names></name>
<name><surname>Scheepers</surname><given-names>C.</given-names></name>
<name><surname>Fiset</surname><given-names>D.</given-names></name>
<name><surname>Caldara</surname><given-names>R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Culture shapes how we look at faces</article-title>. <source>PLoS ONE</source>, <volume>3</volume>(<issue>8</issue>), <fpage>e3022</fpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosone.org/article/info:doi/10.1371/journal.pone.0003022">http://www.plosone.org/article/info:doi/10.1371/journal.pone.0003022</ext-link></citation>
</ref>
<ref id="bibr7-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dalton</surname><given-names>K. M.</given-names></name>
<name><surname>Nacewicz</surname><given-names>B. M.</given-names></name>
<name><surname>Johnstone</surname><given-names>T.</given-names></name>
<name><surname>Schaefer</surname><given-names>H. S.</given-names></name>
<name><surname>Gernsbacher</surname><given-names>M. A.</given-names></name>
<name><surname>Goldsmith</surname><given-names>H. H.</given-names></name>
<name><surname> . . . Davidson</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Gaze fixation and the neural circuitry of face processing in autism</article-title>. <source>Nature Neuroscience</source>, <volume>8</volume>, <fpage>519</fpage>–<lpage>526</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn1421</pub-id></citation>
</ref>
<ref id="bibr8-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Duchaine</surname><given-names>B.</given-names></name>
<name><surname>Nakayama</surname><given-names>K.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The Cambridge Face Memory Test: Results for neurologically intact individuals and an investigation of its validity using inverted face stimuli and prosopagnosic participants</article-title>. <source>Neuropsychologia</source>, <volume>44</volume>, <fpage>576</fpage>–<lpage>585</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2005.07.001</pub-id></citation>
</ref>
<ref id="bibr9-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Firestone</surname><given-names>A.</given-names></name>
<name><surname>Turk-Browne</surname><given-names>N. B.</given-names></name>
<name><surname>Ryan</surname><given-names>J. D.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Age-related deficits in face recognition are related to underlying changes in scanning behavior</article-title>. <source>Aging, Neuropsychology, and Cognition</source>, <volume>14</volume>, <fpage>594</fpage>–<lpage>607</lpage>. doi:<pub-id pub-id-type="doi">10.1080/13825580600899717</pub-id></citation>
</ref>
<ref id="bibr10-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Geisler</surname><given-names>W. S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Contributions of ideal observer theory to vision research</article-title>. <source>Vision Research</source>, <volume>51</volume>, <fpage>771</fpage>–<lpage>781</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.visres.2010.09.027</pub-id></citation>
</ref>
<ref id="bibr11-0956797612471684">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Green</surname><given-names>D. M.</given-names></name>
<name><surname>Swets</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1989</year>). <source>Signal detection theory and psychophysics</source>. <publisher-loc>Los Altos, CA</publisher-loc>: <publisher-name>Peninsula</publisher-name>.</citation>
</ref>
<ref id="bibr12-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haxby</surname><given-names>J. V.</given-names></name>
<name><surname>Hoffman</surname><given-names>E. A.</given-names></name>
<name><surname>Gobbini</surname><given-names>M. I.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The distributed human neural system for face perception</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>4</volume>, <fpage>223</fpage>–<lpage>233</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S1364-6613(00)01482-0</pub-id></citation>
</ref>
<ref id="bibr13-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henderson</surname><given-names>J. M.</given-names></name>
<name><surname>Williams</surname><given-names>C. C.</given-names></name>
<name><surname>Falk</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Eye movements are functional during face learning</article-title>. <source>Memory &amp; Cognition</source>, <volume>33</volume>, <fpage>98</fpage>–<lpage>106</lpage>. doi:<pub-id pub-id-type="doi">10.3758/BF03195300</pub-id></citation>
</ref>
<ref id="bibr14-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hsiao</surname><given-names>J.</given-names></name>
<name><surname>Cottrell</surname><given-names>G.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Two fixations suffice in face recognition</article-title>. <source>Psychological Science</source>, <volume>19</volume>, <fpage>998</fpage>–<lpage>1006</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02191.x</pub-id></citation>
</ref>
<ref id="bibr15-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jack</surname><given-names>R. E.</given-names></name>
<name><surname>Blais</surname><given-names>C.</given-names></name>
<name><surname>Scheepers</surname><given-names>C.</given-names></name>
<name><surname>Schyns</surname><given-names>P. G.</given-names></name>
<name><surname>Caldara</surname><given-names>R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Cultural confusions show that facial expressions are not universal</article-title>. <source>Current Biology</source>, <volume>19</volume>, <fpage>1543</fpage>–<lpage>1548</lpage>. doi:16/j.cub.2009.07.051</citation>
</ref>
<ref id="bibr16-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kanwisher</surname><given-names>N.</given-names></name>
<name><surname>McDermott</surname><given-names>J.</given-names></name>
<name><surname>Chun</surname><given-names>M. M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>The fusiform face area: A module in human extrastriate cortex specialized for face perception</article-title>. <source>Journal of Neuroscience</source>, <volume>17</volume>, <fpage>4302</fpage>–<lpage>4311</lpage>.</citation>
</ref>
<ref id="bibr17-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kersten</surname><given-names>D.</given-names></name>
<name><surname>Mamassian</surname><given-names>P.</given-names></name>
<name><surname>Yuille</surname><given-names>A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Object perception as Bayesian inference</article-title>. <source>Annual Review of Psychology</source>, <volume>55</volume>, <fpage>271</fpage>–<lpage>304</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev.psych.55.090902.142005</pub-id></citation>
</ref>
<ref id="bibr18-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McGowan</surname><given-names>J. W.</given-names></name>
<name><surname>Kowler</surname><given-names>E.</given-names></name>
<name><surname>Sharma</surname><given-names>A.</given-names></name>
<name><surname>Chubb</surname><given-names>C.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Saccadic localization of random dot targets</article-title>. <source>Vision Research</source>, <volume>38</volume>, <fpage>895</fpage>–<lpage>909</lpage>.</citation>
</ref>
<ref id="bibr19-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Najemnik</surname><given-names>J.</given-names></name>
<name><surname>Geisler</surname><given-names>W. S.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Optimal eye movement strategies in visual search</article-title>. <source>Nature</source>, <volume>434</volume>, <fpage>387</fpage>–<lpage>391</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature03390</pub-id></citation>
</ref>
<ref id="bibr20-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peli</surname><given-names>E.</given-names></name>
<name><surname>Yang</surname><given-names>J.</given-names></name>
<name><surname>Goldstein</surname><given-names>R. B.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Image invariance with changes in size: The role of peripheral contrast thresholds</article-title>. <source>Journal of the Optical Society of America A</source>, <volume>8</volume>, <fpage>1762</fpage>–<lpage>1774</lpage>. doi:<pub-id pub-id-type="doi">10.1364/JOSAA.8.001762</pub-id></citation>
</ref>
<ref id="bibr21-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peterson</surname><given-names>M. F.</given-names></name>
<name><surname>Eckstein</surname><given-names>M. P.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Looking just below the eyes is optimal across face recognition tasks</article-title>. <source>Proceedings of the National Academy of Sciences, USA</source>, <volume>109</volume>, <fpage>E3314</fpage>–<lpage>E3323</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1214269109</pub-id></citation>
</ref>
<ref id="bibr22-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rayner</surname><given-names>K.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Williams</surname><given-names>C. C.</given-names></name>
<name><surname>Cave</surname><given-names>K. R.</given-names></name>
<name><surname>Well</surname><given-names>A. D.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Eye movements during information processing tasks: Individual differences and cultural effects</article-title>. <source>Vision Research</source>, <volume>47</volume>, <fpage>2714</fpage>–<lpage>2726</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.visres.2007.05.007</pub-id></citation>
</ref>
<ref id="bibr23-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rizzo</surname><given-names>M.</given-names></name>
<name><surname>Hurtig</surname><given-names>R.</given-names></name>
<name><surname>Damasio</surname><given-names>A. R.</given-names></name>
</person-group> (<year>1987</year>). <article-title>The role of scanpaths in facial recognition and learning</article-title>. <source>Annals of Neurology</source>, <volume>22</volume>, <fpage>41</fpage>–<lpage>45</lpage>. doi:<pub-id pub-id-type="doi">10.1002/ana.410220111</pub-id></citation>
</ref>
<ref id="bibr24-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sekiguchi</surname><given-names>T.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Individual differences in face memory and eye fixation patterns during face learning</article-title>. <source>Acta Psychologica</source>, <volume>137</volume>, <fpage>1</fpage>–<lpage>9</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.actpsy.2011.01.014</pub-id></citation>
</ref>
<ref id="bibr25-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sekuler</surname><given-names>A. B.</given-names></name>
<name><surname>Gaspar</surname><given-names>C. M.</given-names></name>
<name><surname>Gold</surname><given-names>J.</given-names></name>
<name><surname>Bennett</surname><given-names>P. J.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Inversion leads to quantitative, not qualitative, changes in face processing</article-title>. <source>Current Biology</source>, <volume>14</volume>, <fpage>391</fpage>–<lpage>396</lpage>. doi:16/j.cub.2004.02.028</citation>
</ref>
<ref id="bibr26-0956797612471684">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Tatler</surname><given-names>B. W.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The central fixation bias in scene viewing: Selecting an optimal viewing position independently of motor biases and image feature distributions</article-title>. <source>Journal of Vision</source>, <volume>7</volume>(<issue>14</issue>), Article <fpage>4</fpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.journalofvision.org/content/7/14/4.full">http://www.journalofvision.org/content/7/14/4.full</ext-link></citation>
</ref>
<ref id="bibr27-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vinette</surname><given-names>C.</given-names></name>
<name><surname>Gosselin</surname><given-names>F.</given-names></name>
<name><surname>Schyns</surname><given-names>P. G.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Spatio-temporal dynamics of face recognition in a flash: It’s in the eyes</article-title>. <source>Cognitive Science</source>, <volume>28</volume>, <fpage>289</fpage>–<lpage>301</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cogsci.2004.01.002</pub-id></citation>
</ref>
<ref id="bibr28-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walker-Smith</surname><given-names>G. J.</given-names></name>
<name><surname>Gale</surname><given-names>A. G.</given-names></name>
<name><surname>Findlay</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1977</year>). <article-title>Eye movement strategies involved in face perception</article-title>. <source>Perception</source>, <volume>6</volume>, <fpage>313</fpage>–<lpage>326</lpage>. doi:<pub-id pub-id-type="doi">10.1068/p060313</pub-id></citation>
</ref>
<ref id="bibr29-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Williams</surname><given-names>C. C.</given-names></name>
<name><surname>Henderson</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The face inversion effect is not a consequence of aberrant eye movements</article-title>. <source>Memory &amp; Cognition</source>, <volume>35</volume>, <fpage>1977</fpage>–<lpage>1985</lpage>. doi:<pub-id pub-id-type="doi">10.3758/BF03192930</pub-id></citation>
</ref>
<ref id="bibr30-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Williams</surname><given-names>L. M.</given-names></name>
<name><surname>Loughland</surname><given-names>C. M.</given-names></name>
<name><surname>Gordon</surname><given-names>E.</given-names></name>
<name><surname>Davidson</surname><given-names>D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Visual scanpaths in schizophrenia: Is there a deficit in face recognition?</article-title> <source>Schizophrenia Research</source>, <volume>40</volume>, <fpage>189</fpage>–<lpage>199</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0920-9964(99)00056-0</pub-id></citation>
</ref>
<ref id="bibr31-0956797612471684">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Xivry</surname><given-names>J. O.</given-names></name>
<name><surname>Ramon</surname><given-names>M.</given-names></name>
<name><surname>Lefèvre</surname><given-names>P.</given-names></name>
<name><surname>Rossion</surname><given-names>B.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Reduced fixation on the upper area of personally familiar faces following acquired prosopagnosia</article-title>. <source>Journal of Neuropsychology</source>, <volume>2</volume>, <fpage>245</fpage>–<lpage>268</lpage>. doi:<pub-id pub-id-type="doi">10.1348/174866407X260199</pub-id></citation>
</ref>
</ref-list>
</back>
</article>