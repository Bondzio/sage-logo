<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EVI</journal-id>
<journal-id journal-id-type="hwp">spevi</journal-id>
<journal-title>Evaluation</journal-title>
<issn pub-type="ppub">1356-3890</issn>
<issn pub-type="epub">1461-7153</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1356389012442978</article-id>
<article-id pub-id-type="publisher-id">10.1177_1356389012442978</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The life-cycle approach to performance management: Implications for public management and evaluation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Helden</surname><given-names>G. Jan van</given-names></name>
</contrib>
<aff id="aff1-1356389012442978">University of Groningen, The Netherlands</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Johnsen</surname><given-names>Åge</given-names></name>
</contrib>
<aff id="aff2-1356389012442978">Oslo and Akershus University College of Applied Sciences, Norway</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Vakkuri</surname><given-names>Jarmo</given-names></name>
</contrib>
<aff id="aff3-1356389012442978">University of Tampere, Finland</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1356389012442978">Åge Johnsen, Faculty of Social Sciences, Oslo and Akershus University College of Applied Sciences, P.O. Box 4 St. Olavs plass, NO-0130 Oslo, Norway. Email: <email>aage.johnsen@hioa.no</email></corresp>
<fn fn-type="other" id="bio1-1356389012442978">
<p>G. Jan van Helden is Professor Emeritus of Management Accounting at the Faculty of Economics and Business, University of Groningen. His recent research has focused on management and accounting changes in public sector organizations. Please address correspondence to: Faculty of Economics and Business, University of Groningen, P.O. Box 800, 9700 AV Groningen, The Netherlands. [email: <email>g.j.van.helden@rug.nl</email>]</p>
</fn>
<fn fn-type="other" id="bio2-1356389012442978">
<p>Åge Johnsen is Professor of Public Policy at the Faculty of Social Sciences, Oslo and Akershus University College of Applied Sciences. His research interests are strategy, performance management, audit and accountability, and evaluation in the public sector. Please address correspondence to: Faculty of Social Sciences, Oslo and Akershus University College of Applied Sciences, P.O. Box 4, St. Olavs Plass, NO-0130 Oslo, Norway. [email: <email>aage.johnsen@hioa.no</email>]</p>
</fn>
<fn fn-type="other" id="bio3-1356389012442978">
<p>Jarmo Vakkuri is Professor of Local Government Accounting and Finance at the School of Management, University of Tampere. His research interests are performance measurement and management in public organizations. Please address correspondence to: School of Management, FI-33014, University of Tampere, Finland. [email: <email>jarmo.vakkuri@uta.fi</email>]</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2012</year>
</pub-date>
<volume>18</volume>
<issue>2</issue>
<fpage>159</fpage>
<lpage>175</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>This article discusses how performance-management systems may be conceptualized as tools with a life cycle consisting of several stages. Studies on public-sector performance management generally concern the question of how management can design these systems or address dysfunctional effects when they are used. This article, however, argues that the research in this field should cover the entire life cycle of performance-management systems: it should focus on both their benefits and costs and needs to recognize a broader spectrum of actors involved in the life cycle than that normally associated with the hierarchical conception of principals and agents. The life-cycle approach facilitates a comprehensive mapping of the various performance-management stages and their contingencies from invention to assessment and re-design, including their interdependence. The framework enables policymakers, managers, evaluators, and researchers to better understand performance-management systems, to identify relevant research areas and to communicate the practical problems and solutions related to the systems’ specific stages.</p>
</abstract>
<kwd-group>
<kwd>assessment</kwd>
<kwd>design</kwd>
<kwd>implementation</kwd>
<kwd>performance management</kwd>
<kwd>use</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1356389012442978" sec-type="intro">
<title>Introduction</title>
<p>The purpose of this article is to develop a new framework – the life-cycle model – for a broad assessment of the findings on performance management in the public sector. In the evaluation community there is an ongoing debate about the merits of performance management, how performance management differs from evaluation and how evaluation can strengthen performance management and vice versa (<xref ref-type="bibr" rid="bibr11-1356389012442978">Blalock, 1999</xref>; <xref ref-type="bibr" rid="bibr24-1356389012442978">Davies, 1999</xref>; <xref ref-type="bibr" rid="bibr44-1356389012442978">Kusek and Rist, 2004</xref>; <xref ref-type="bibr" rid="bibr49-1356389012442978">McDavid and Hawthorn, 2006</xref>; <xref ref-type="bibr" rid="bibr59-1356389012442978">Nielsen and Ejler, 2008</xref>; <xref ref-type="bibr" rid="bibr67-1356389012442978">Poister, 2003</xref>). Performance management in the public sector has become a widespread government tool in many countries and a growing amount of research literature is aimed at mapping out this practice (<xref ref-type="bibr" rid="bibr13-1356389012442978">Bouckaert and Halligan, 2008</xref>; <xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al., 2006</xref>; <xref ref-type="bibr" rid="bibr30-1356389012442978">Frederickson and Frederickson, 2006</xref>; <xref ref-type="bibr" rid="bibr57-1356389012442978">Moynihan, 2008</xref>; <xref ref-type="bibr" rid="bibr81-1356389012442978">Talbot, 2010</xref>; <xref ref-type="bibr" rid="bibr86-1356389012442978">Van Dooren and Van de Walle, 2008</xref>). The research often concludes that public sector performance management is problematic, particularly when the performance information available is either not used or only in a limited way, or when it is only used for symbolic purposes (<xref ref-type="bibr" rid="bibr25-1356389012442978">De Bruijn, 2002</xref>; <xref ref-type="bibr" rid="bibr55-1356389012442978">Modell, 2004</xref>; <xref ref-type="bibr" rid="bibr72-1356389012442978">Pollitt, 2006</xref>; <xref ref-type="bibr" rid="bibr73-1356389012442978">Radin, 2006</xref>). Still, performance management is considered important, and it is widely used in the public sector (<xref ref-type="bibr" rid="bibr8-1356389012442978">Behn 2003</xref>; <xref ref-type="bibr" rid="bibr23-1356389012442978">Curristine, 2005</xref>; <xref ref-type="bibr" rid="bibr26-1356389012442978">De Lancer Julnes, 2006</xref>; <xref ref-type="bibr" rid="bibr90-1356389012442978">Williams 2003</xref>). Therefore, the performance management systems need to be sufficiently understandable for its main users: the policymakers, public managers, accountants and evaluators.</p>
<p>As the use of performance management in the public sector is spreading, a comprehensive, interdisciplinary and inter-professional approach is required. Our assertion is that an analysis based on a life-cycle framework can contribute to realizing such an approach. The life-cycle framework will enable scholars to identify gaps in the existing body of knowledge with respect to performance-management systems. Moreover, the framework is beneficial to practitioners in public policy, management and evaluation because they can use the framework to link their experiences with the relevant academic literature.</p>
<p>The life-cycle framework borrows from two constructs: the product life-cycle model, containing the stages market introduction, growth, maturation and decline; and policy making theory, which defines the stages of agenda setting, policy formation, decision, implementation and evaluation. We have divided the performance-management life cycle into design, implementation, use and assessment.</p>
<p>Two arguments justify the development of a life-cycle model for performance management in the public sector. First, much of the research on public-sector performance management in the accounting and public administration literature focuses on design and use, whereas the stages of implementation and the assessment of performance management – although not entirely neglected – have received far less attention (<xref ref-type="bibr" rid="bibr88-1356389012442978">Van Helden et al., 2008</xref>). One notable exception is made by the evaluation literature, which has dealt with these issues more extensively. We have therefore aimed at presenting a more balanced review of the evidence collected in the relevant stages of the life cycle.</p>
<p>Second, the discussion of performance management is too much constrained within the boundaries of academic and professional tribes. There is a need for a more common framework for examining performance-management systems among researchers, policymakers, public managers and evaluators. This article develops one such analytical tool for understanding performance management from multiple perspectives. We contend that most disciplines and research approaches associated with performance management share the goal of shifting from ‘studies to streams’ (<xref ref-type="bibr" rid="bibr75-1356389012442978">Rist and Stame, 2006</xref>). More in-depth evaluative knowledge, results orientation and research-driven public management are all assumed to coalesce with more rational and intelligent decision making in the public sector (<xref ref-type="bibr" rid="bibr64-1356389012442978">Perrin, 1998</xref>, <xref ref-type="bibr" rid="bibr65-1356389012442978">1999</xref>).</p>
<p>Our life-cycle framework is based on a critical review of the relevant performance-management literature. The literature on performance management is vast. We have therefore adopted the following selection criteria. First, the publications chosen had to acknowledge the role of performance- management research in various disciplinary traditions, such as public administration, management accounting and evaluation. Second, in order to acquire a sufficiently balanced overview of the existing body of knowledge the literature had to be focused on all different stages of the performance-management cycle. Third, the studies had to either be influential in such a way as to provide a fundamental understanding of the specific stages of the performance-management life cycle – there are both old and more recent ‘classics’ in public administration, management accounting and evaluation that the current research can learn from – or based on sound empirical evidence, although preferably both criteria were met. Finally, we assumed that interesting evidence and lessons may be retrieved from the ‘grey’ literature, which is why we also reviewed some research and consultancy reports.</p>
<p>The outline of the remainder of this article is as follows. The second section presents the life-cycle approach to performance management. This framework provides the structure for the subsequent discussion. The third section analyses the selected literature regarding the design, implementation, use and assessment of performance management in the public sector. The fourth section presents the discussion, and the last section touches upon the implications of the life-cycle framework for public management and evaluation.</p>
</sec>
<sec id="section2-1356389012442978">
<title>The life cycle of performance-management systems</title>
<p>In this article, performance management is understood as an instrument for improving the efficiency, effectiveness and equity of programmes, organizations and services. Performance management is primarily used for increasing the rationality of decision-making, although ritualistic uses are not excluded (<xref ref-type="bibr" rid="bibr59-1356389012442978">Nielsen and Ejler, 2008</xref>). Performance measurement encompasses the construction and measurement of decision-relevant performance indicators as an important input to performance management, whereby these measures are often compared with standards or norms (<xref ref-type="bibr" rid="bibr11-1356389012442978">Blalock, 1999</xref>; <xref ref-type="bibr" rid="bibr24-1356389012442978">Davies, 1999</xref>) that may be derived from external sources, as in benchmarking. Performance management not only implies measurement and monitoring but also the task of reporting the resulting information to the relevant administrative and political bodies that can analyse and use this information (<xref ref-type="bibr" rid="bibr67-1356389012442978">Poister, 2003</xref>). Performance management serves various functions, particularly accountability, organizational learning, policy (re-)design and planning and control (<xref ref-type="bibr" rid="bibr8-1356389012442978">Behn, 2003</xref>; <xref ref-type="bibr" rid="bibr16-1356389012442978">Boyne and Gould-Williams, 2003</xref>; <xref ref-type="bibr" rid="bibr32-1356389012442978">Hartley and Allison, 2002</xref>; <xref ref-type="bibr" rid="bibr34-1356389012442978">Hood, 2007</xref>).</p>
<p>Performance information may be used in performance management as well as in evaluation. The main difference between performance management and evaluation is that performance management is a frequent, almost ongoing activity intended to ‘ratchet up’ (improve) the performance, often of an activity, service or organization, whereas evaluation is carried out on an either ad hoc or regular basis, with the purpose of independently questioning the relevance and even appropriateness of a service, policy or programme (<xref ref-type="bibr" rid="bibr7-1356389012442978">Bastøe, 2006</xref>; <xref ref-type="bibr" rid="bibr24-1356389012442978">Davies, 1999</xref>; <xref ref-type="bibr" rid="bibr59-1356389012442978">Nielsen and Ejler, 2008</xref>; <xref ref-type="bibr" rid="bibr64-1356389012442978">Perrin, 1998</xref>).</p>
<p>The adoption of a performance management system by a public-sector organization generally involves various stages. Together, these stages shape the so-called performance-management life cycle, which may consists of design, implementation, use and assessment. <xref ref-type="bibr" rid="bibr20-1356389012442978">Carter (1991)</xref>, <xref ref-type="bibr" rid="bibr40-1356389012442978">Johnsen (2005)</xref> and <xref ref-type="bibr" rid="bibr46-1356389012442978">Likierman (1993)</xref> have made similar distinctions, while also in empirical performance measurement studies particular stages of this life cycle can be observed (see e.g. <xref ref-type="bibr" rid="bibr13-1356389012442978">Bouckaert and Halligan, 2008</xref>; <xref ref-type="bibr" rid="bibr21-1356389012442978">Cavalluzzo and Ittner, 2004</xref>; <xref ref-type="bibr" rid="bibr85-1356389012442978">Van Dooren, 2005</xref>).</p>
<p><xref ref-type="fig" rid="fig1-1356389012442978">Figure 1</xref> illustrates the life-cycle model of performance management. <italic>Design</italic> refers to the initiation, content and construction of a performance-management system, particularly in terms of types of performance indicators and the extent to which they are goal-oriented. <italic>Implementation</italic> is associated with the introduction of performance-management systems in organizations, including pilot projects and testing. <italic>Use</italic> concerns a broad spectrum of aspects, such as objectives and styles of adoption. The uses of performance-management systems are conceived to influence the ‘entities involved’ (individuals, services, organizations, programmes, society, etc.) in a particular technical, economic or cultural way. <italic>Assessment</italic> concerns a critical appraisal and possible redesign of the performance-management system. <italic>Impacts</italic> relate to the effects of performance-management systems in terms of behavioural consequences and organizational effectiveness. Impacts of the uses of performance-management systems may be categorized as intended and unintended, as well as functional and dysfunctional. Furthermore, organizational performance management is embedded in an <italic>institutional environment</italic>. This means that the four stages are also influenced by factors other than those directly related to the performance-management life cycle trajectory; for example, by the organization’s strategy and/or the stakeholders of the public service in question.</p>
<fig id="fig1-1356389012442978" position="float">
<label>Figure 1.</label>
<caption>
<p>The performance-management life cycle</p>
</caption>
<graphic xlink:href="10.1177_1356389012442978-fig1.tif"/>
</fig>
<p>The framework in <xref ref-type="fig" rid="fig1-1356389012442978">Figure 1</xref> is obviously a simplification in that the performance-management life cycle is not necessarily a linear process. During the trajectory, organizations may learn from their experiences and employ the information obtained in each of the four stages to reconsider their content. Both feedback and feed-forward mechanisms shape the final assessment stage of the performance-management life cycle, which could lead to particular adjustments, such as a redesign of the performance-management system as a whole or a minor or major change in its implementation or use. Furthermore, public-sector services are often co-produced by other organizations and tiers of government (local, regional, national) as well as by actors outside the public sector.</p>
</sec>
<sec id="section3-1356389012442978">
<title>Analysis</title>
<p>In the following sections, we review the current body of knowledge on public-sector performance management in relation to the framework outlined in <xref ref-type="fig" rid="fig1-1356389012442978">Figure 1</xref>. In addition to the four stages of the life cycle, impacts of performance measurement, which can regard all these stages, will be discussed. At the end of each subsection, we identify possible gaps in the body of literature.</p>
<sec id="section4-1356389012442978">
<title>Design</title>
<p>The design stage often encompasses logical planning steps, including the definition of a vision or mission for the system, formulation of organizational goals and objectives in a consistent way, the development of related performance measures and standards, and the alignment of incentives and sanctions (<xref ref-type="bibr" rid="bibr11-1356389012442978">Blalock, 1999</xref>).</p>
<p><xref ref-type="bibr" rid="bibr77-1356389012442978">Simon (1937)</xref> argued that the measurement of public-sector performance is based on common wisdom applied to administrative issues. This knowledge could be pursued by asking questions regarding what the politicians wish to achieve, how the money is spent and how the services contribute to the achievement of goals. The implicit assumption is that developing systematic knowledge and using available data and methods from statistics, trend analysis, cost accounting and budgeting, in addition to the transparent reporting of the performance information to the public, would improve public policy and management.</p>
<p>Seemingly, much of the early public-sector performance measurement research was primarily concerned with the design stage of the cycle. The more recent development of performance measurement systems includes attempts to combine the search for ‘best practices’ with non-parametric methods such as data envelopment analysis (<xref ref-type="bibr" rid="bibr18-1356389012442978">Bretschneider et al., 2005</xref>; <xref ref-type="bibr" rid="bibr83-1356389012442978">Vakkuri, 2003</xref>). Additional methods such as the balanced scorecard can be regarded as innovations in designing multi- dimensional measurement models relative to traditional management-by-objectives models or common practice. <xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al. (2006)</xref>, however, elaborate on far more sophisticated measurement models for public-sector organizations than simple balanced scorecards.</p>
<p>Performance-measurement design problems cannot be solved without understanding the institutional context. <xref ref-type="bibr" rid="bibr63-1356389012442978">Ouchi (1979)</xref> and <xref ref-type="bibr" rid="bibr91-1356389012442978">Wilson (2000)</xref> were among the early authors who discussed mechanisms of organizational design and control in various contexts. In their view, the design of performance-measurement systems is contingent upon the measurability of outputs and knowledge of the transformation process. Different control mechanisms – particularly market, hierarchy and clan – may be used for different purposes under different contingencies. In a somewhat different framework, <xref ref-type="bibr" rid="bibr33-1356389012442978">Hofstede (1981)</xref> addressed how different contingencies affect management control models (for a more recent contribution to this debate, see <xref ref-type="bibr" rid="bibr60-1356389012442978">Noordegraaf and Abma, 2003</xref>).</p>
<p><xref ref-type="bibr" rid="bibr89-1356389012442978">Wang and Berman (2001)</xref> conducted a survey study on performance-management design, which revealed that involvement in the sense of management commitment positively influences the design of output and outcome measures, whereas mission orientation only influences the design of outcome measures. These explanations corroborate our notion that the institutional context affects performance-management systems, and not only the other way around.</p>
<p>Much of the knowledge on performance measurement has come from research following the public management reforms since the 1960s; for example, in relation to programming, planning and budgeting systems. Some of this research has been directed toward decision-relevant performance measurement. The work of Mayston (<xref ref-type="bibr" rid="bibr51-1356389012442978">1985</xref>, <xref ref-type="bibr" rid="bibr52-1356389012442978">1993</xref>) is an evident example of this. <xref ref-type="bibr" rid="bibr51-1356389012442978">Mayston (1985)</xref> emphasized the importance of the decision relevance of performance measurement systems that face the risk of growing fast due to the fact that many stakeholders wish to measure various aspects. By emphasizing decision relevance and information economics, the risk of information overload and system breakdown could be reduced.</p>
<p>The early phase of performance-management development was often based on a narrow conception of the context of public-sector services. <xref ref-type="bibr" rid="bibr70-1356389012442978">Pollitt (1986)</xref> described how Thatcher’s conservative, market liberal regime put a greater emphasis on performance management, but the performance measurements were unbalanced and excessively oriented toward management. Pollitt’s main conclusion was that the concept of effectiveness must also address issues of equity and not only cost reductions and efficiency, and that the target groups for the performance information must encompass stakeholders other than management only. More recently, <xref ref-type="bibr" rid="bibr73-1356389012442978">Radin (2006)</xref> put forward a similar critique toward the US performance measurement movement. Furthermore, the performance measurements could to a greater extent also use assessments from colleagues, rather than only from superiors, as argued by <xref ref-type="bibr" rid="bibr71-1356389012442978">Pollitt (1988)</xref>.</p>
<p><xref ref-type="bibr" rid="bibr20-1356389012442978">Carter (1991)</xref> discussed criteria for good performance indicators and argued that the indicators should be relevant for the organizational objectives, non-manipulative by the individuals and entities being measured, reliable and produced by accurate information systems and unambiguous and unchallengeable by employees. As practical organizational tools, the performance indicators were characterized according to three criteria: whether the coverage was narrow or extensive, useful in relation to being ‘tailor made’ or not and updated seldom or often. Carter put forward external political pressure on the governmental organizations and the degree of competition with private organizations as explanations for the observed patterns. Carter also argued that the development of performance measurement systems follows a life cycle and faces resistance.</p>
<p>Our review of the literature on the <italic>design</italic> of performance-management systems gives rise to the following conclusions. First, there is an emphasis on efficiency and cost reduction, while aspects of effectiveness, equity and user satisfaction receive less attention. Second, there are theoretical and empirical pointers for contingencies of performance-management design, although a systematic discussion of the impact of various types of contingencies such as technological factors, organizational factors and institutional factors is underdeveloped. Third, too little attention is given to methodological limitations of performance-management systems. Studies in operations research can enrich the discussion about methodological conditions and requirements for performance-management systems to provide solid information. However, some general assumptions and limitations are addressed (<xref ref-type="bibr" rid="bibr62-1356389012442978">Nørreklit et al., 2006</xref>), and there also seems to be an increasing amount of interest in methodological issues (<xref ref-type="bibr" rid="bibr10-1356389012442978">Bevan and Hood, 2006</xref>; <xref ref-type="bibr" rid="bibr36-1356389012442978">Jacobs and Goddard, 2007</xref>; <xref ref-type="bibr" rid="bibr54-1356389012442978">Meyer and Gupta, 1994</xref>). Finally, political rationales for designers could be studied more in-depth; i.e. situations in which designers wish to pursue aims other than improving decision-making rationality.</p>
</sec>
<sec id="section5-1356389012442978">
<title>Implementation</title>
<p>Implementing performance information in management and budgeting is challenging because it affects the entire organization (<xref ref-type="bibr" rid="bibr50-1356389012442978">Mayne, 2007</xref>). The implementation of performance management systems is therefore important because it concerns many issues. For example, combining bottom-up and top-down processes (<xref ref-type="bibr" rid="bibr48-1356389012442978">Long and Franklin, 2004</xref>) and piloting, training and management commitment (<xref ref-type="bibr" rid="bibr53-1356389012442978">Melkers and Willoughby, 2005</xref>) are all factors that may contribute to the effective use and intended impacts.</p>
<p>In an early and much-cited empirical paper within public management, <xref ref-type="bibr" rid="bibr46-1356389012442978">Likierman (1993)</xref> developed 20 lessons from experience in order to enhance the use of performance indicators, including emphasizing the need for conceptual validity applied to the political context, bottom-up participation, patience and pragmatic use of the performance indicators.</p>
<p>One could expect that a top-down control system would be resisted in a strong professional context with extensive clan control (<xref ref-type="bibr" rid="bibr63-1356389012442978">Ouchi, 1979</xref>). <xref ref-type="bibr" rid="bibr48-1356389012442978">Long and Franklin (2004)</xref> described the paradox of how the US Congress and President used the top-down mandate of the Government Performance and Results Act (GPRA) to implement internal bottom-up performance-management processes in the federal agencies. However, this ‘one-size-fits-all’ approach was met with unique implementation processes within many of the agencies. A commonly reported outcome from implementation is resistance and tension, as documented by <xref ref-type="bibr" rid="bibr41-1356389012442978">Jones (2002)</xref> with benchmarking in the UK National Health Service. Resistance is not necessarily the case, and may depend on many institutional factors such as national and organizational culture, as well as implementation processes. An illustration comes from <xref ref-type="bibr" rid="bibr3-1356389012442978">Aidemark (2001)</xref> who examined the meaning of the balanced scorecard in health care management in a Swedish county and argued that the professionals regarded the balanced scorecard as a means of presenting a more compound picture of the health care activities than just financial statements.</p>
<p>The capacity for implementation is a critical resource for successful performance management. <xref ref-type="bibr" rid="bibr9-1356389012442978">Berman and Wang (2000)</xref> studied the organizational and institutional capacities of US counties to implement performance measurement systems. Based on a comprehensive survey, they argued that specific organizational and learning capacities must be present if performance measurement systems are to be successfully implemented.</p>
<p>Some empirical research shows that there may often be ambiguous objectives and loose couplings between objectives and performance indicators in the implementation stage (<xref ref-type="bibr" rid="bibr35-1356389012442978">Hyndman and Eden, 2000</xref>). Nevertheless, decoupling of performance indicators from organizational objectives may be a conducive implementation mode because this can prevent or bypass resistance so that the systems are able to ‘make it’ into a use stage (<xref ref-type="bibr" rid="bibr37-1356389012442978">Jansen, 2008</xref>; <xref ref-type="bibr" rid="bibr38-1356389012442978">Johnsen, 1999</xref>). Other research indicates that strategy linked to structure affects performance (<xref ref-type="bibr" rid="bibr1-1356389012442978">Abernethy and Lillis, 2001</xref>), but this research has not studied the implementation stage’s effect on the use of performance-management models.</p>
<p>We conclude that the <italic>implementation</italic> of performance-management systems benefits from considering a broad spectrum of performance domains, some extent of decoupling of performance indicators from organizational objectives and the availability of management capacities. Moreover, research regarding this stage is rather underdeveloped: understanding what is included in implementation and not in design or use is rather minimal (piloting, testing, creating support), or it overlaps those stages (availability of performance indicators, adoption of performance indicators). One unresolved issue is whether implementation is just an intermediary stage for ‘use’ or has a relevant substance of its own.</p>
</sec>
<sec id="section6-1356389012442978">
<title>Use</title>
<p>In studying why performance-management systems are used and how they are used in the public sector, performance-management research has particularly addressed purposes and styles of use. According to <xref ref-type="bibr" rid="bibr8-1356389012442978">Behn (2003)</xref>, the answer as to why government measures performance is contextual. Performance indicators are required for eight different purposes of use: evaluation, control, budgeting, motivation, promoting, celebrating, learning and improvement. Behn has challenged the widely held assumption that performance measurement systems can be universally designed to simultaneously address various managerial purposes. Moreover, research on the uses of public-sector performance management lacks a detailed analysis of the ‘user’ (cf. <xref ref-type="bibr" rid="bibr57-1356389012442978">Moynihan, 2008</xref>).</p>
<p><xref ref-type="bibr" rid="bibr9-1356389012442978">Berman and Wang’s (2000)</xref> survey study on use showed that technical capacities in particular, as well as support from stakeholders, are associated with an increased use of performance measures. Whereas earlier studies (<xref ref-type="bibr" rid="bibr27-1356389012442978">De Lancer Julnes and Holzer, 2001</xref>; <xref ref-type="bibr" rid="bibr69-1356389012442978">Poister and Streib, 1999</xref>) found little use for performance indicators, <xref ref-type="bibr" rid="bibr53-1356389012442978">Melkers and Willoughby (2005)</xref> found that the use of performance indicators was widespread. <xref ref-type="bibr" rid="bibr53-1356389012442978">Melkers and Willoughby (2005)</xref> also focused on specific aspects of the use of performance measurements such as for budgeting or communication. This study found that a lack of leadership support negatively influences use, which is also dependent upon characteristics of the performance measurement system itself in terms of transparency and density (e.g. use in various stages of the budget cycle). <xref ref-type="bibr" rid="bibr56-1356389012442978">Moynihan (2005)</xref> argued that the adoption of organizational learning forums and developing organizational culture would enhance the use of the information and provide learning.</p>
<p><xref ref-type="bibr" rid="bibr47-1356389012442978">Llewellyn and Northcott (2005)</xref> demonstrated how the notion of an average is being introduced through national cost comparisons of UK hospitals. Being average gives UK hospitals a ‘sense of comfort’ and a perception of ‘not standing out too much’, whereas being too cheap (or too expensive) may include a possibility that such a hospital is going to be set up as a ‘target’. In a similar fashion, benchmarking might be used defensively in order to avoid further rearrangements (cf. <xref ref-type="bibr" rid="bibr14-1356389012442978">Bowerman et al., 2001</xref>; <xref ref-type="bibr" rid="bibr87-1356389012442978">Van Helden and Tillema, 2005</xref>).</p>
<p>The role of performance measurement in political management is most likely still underdeveloped with regard to being decision relevant for various stakeholders and as an instrument in democratic governance (<xref ref-type="bibr" rid="bibr72-1356389012442978">Pollitt, 2006</xref>; <xref ref-type="bibr" rid="bibr82-1356389012442978">Ter Bogt, 2004</xref>). However, studies from the Netherlands (<xref ref-type="bibr" rid="bibr37-1356389012442978">Jansen, 2008</xref>), Norway (<xref ref-type="bibr" rid="bibr4-1356389012442978">Askim, 2007</xref>; <xref ref-type="bibr" rid="bibr5-1356389012442978">Askim et al., 2008</xref>) and the USA (<xref ref-type="bibr" rid="bibr26-1356389012442978">De Lancer Julnes, 2006</xref>) indicate that managers and politicians use performance information in policymaking.</p>
<p>The uses of performance measurement have various consequences, which include the effect on institutional environment. By using performance measurements, decision makers maintain the status quo by reinforcing institutional properties or disturb it by transforming institutional properties. While users may use performance-management systems as they were designed, users may also circumvent accepted ways of use by ignoring certain properties, working around them and inventing completely new ones (<xref ref-type="bibr" rid="bibr84-1356389012442978">Vakkuri and Meklin, 2006</xref>). Or as argued by <xref ref-type="bibr" rid="bibr57-1356389012442978">Moynihan (2008)</xref>, users employ the ambiguity in performance measurements according to their institutional interests. Hence, an interactive dialogue model to understand the role of performance information in public administration can then be helpful.</p>
<p><xref ref-type="bibr" rid="bibr71-1356389012442978">Pollitt (1988)</xref> discussed the applicability of user orientation of performance management in public management. There is a need to consider the conception of the user and his relationship to the service; for example, whether the users are current users, those on waiting lists, those considered to have a need for but do not use the service, or all potential users. Moreover, the incorporation of subjective user assessments must be balanced against more objective data, according to Pollitt.</p>
<p><xref ref-type="bibr" rid="bibr64-1356389012442978">Perrin (1998)</xref> examined important fallacies of performance measurement systems. He argued that evaluators needed to understand some fundamental principles of performance measurement (see also <xref ref-type="bibr" rid="bibr65-1356389012442978">Perrin, 1999</xref>). The most important flaws include ambiguity in conceptual frameworks, goal displacement (i.e. the ‘right’ goals are replaced by measurement-related goals), the use of meaningless and irrelevant measures, an emphasis on cost shiftings instead of cost savings, confusing subgroup differences with overall success indicators, incentives for mediocre and unambitious behaviour (cf. <xref ref-type="bibr" rid="bibr47-1356389012442978">Llewellyn and Northcott 2005</xref>), dysfunctional uses for resource allocation and a limited focus on outcomes. Perrin argued for effective strategies to mitigate these problems.</p>
<p><xref ref-type="bibr" rid="bibr10-1356389012442978">Bevan and Hood (2006)</xref> examined performance-management systems in UK health care systems and identified four types of users’ responses in gaming behaviour. ‘Saints’ are players who may disagree with the rule system of performance measurement, but they have a high public service ethos and are willing to report about their (also dysfunctional) behaviour. ‘Honest triers’ broadly share the rules of the measurement game and do not voluntarily report their misbehaviour, but do not attempt to provide misleading information. ‘Reactive gamers’ broadly agree with the rule system, but if possible, attempt to game the target system. Finally, ‘rational maniacs’ do not agree with the rules, and aim to hide dysfunctional behaviour by manipulating information (see also <xref ref-type="bibr" rid="bibr6-1356389012442978">Banker, 1980</xref>; <xref ref-type="bibr" rid="bibr22-1356389012442978">Charnes et al., 1989</xref>).</p>
<p>Our conclusions are that performance-management <italic>use</italic> is contingent upon various factors such as the goals of these systems as well as managerial and institutional factors. Moreover, use can be modelled through various reaction patterns, such as either supporting or opposing behaviour, or considering a move to the average level within a certain branch. The relationship between uses of performance-management systems and theories on behavioural decision making is underdeveloped, and the understanding of the ‘user’ is limited. Additional research is needed on how the use (and users) shapes or reshapes the systems in the context of political decision making. More understanding is needed on the relationship between politicians and bureaucrats as users of performance information.</p>
</sec>
<sec id="section7-1356389012442978">
<title>Assessment</title>
<p>Performance-management models can be systematically assessed, and some models may be redesigned and re-implemented. There is seemingly not much literature on this stage of the performance-management life cycle. However, there are more examples. <xref ref-type="bibr" rid="bibr76-1356389012442978">Rodgers and Hunter (1992)</xref> used meta-analysis and concluded that management by objectives had positive impacts on private as well as public-sector organizations. <xref ref-type="bibr" rid="bibr54-1356389012442978">Meyer and Gupta’s (1994)</xref> seminal contribution on the running down of performance measures provides a description of how individual performance indicators within performance measurement systems in use are evaluated, discarded or redesigned. Performance indicators have impacts on behaviour, thus over time performance indicators no longer discriminate between behaviour or performance, and therefore new performance indicators have to be designed and implemented. <xref ref-type="bibr" rid="bibr42-1356389012442978">Kaplan (1998)</xref> identified limitations in management practices and redesigned the management by objectives model into the now popular balanced scorecard (<xref ref-type="bibr" rid="bibr43-1356389012442978">Kaplan and Norton, 1996</xref>), while other models might be aborted during the implementation stage or be abandoned after a short time use (<xref ref-type="bibr" rid="bibr19-1356389012442978">Carson et al., 2000</xref>).</p>
<p>The new institutional theory on management fads and fashion (<xref ref-type="bibr" rid="bibr2-1356389012442978">Abrahamson, 1996</xref>) and some critical theory (<xref ref-type="bibr" rid="bibr61-1356389012442978">Nørreklit, 2003</xref>) provide potential explanations on how discarded models may be redesigned to fit contemporary issues or culture. Old models and parts of old models are re-labelled and repackaged, and then re-launched for the management problems of today. For example, the balanced scorecard has been widely adopted as an innovation, but in reality it is a variant of management by objectives (<xref ref-type="bibr" rid="bibr39-1356389012442978">Johnsen, 2001</xref>), which is from the 1950s (<xref ref-type="bibr" rid="bibr29-1356389012442978">Drucker, 1954</xref>), and which many have regarded as being out of fashion or out-dated (<xref ref-type="bibr" rid="bibr68-1356389012442978">Poister and Streib, 1995</xref>).</p>
<p>In <xref ref-type="fig" rid="fig1-1356389012442978">Figure 1</xref>, assessment is a final stage. However, as we have stated earlier, the life-cycle model may or may not be a linear process starting with design and ending with assessment, before resuming with redesign. In practice, given an organization’s or performance measurement system’s history, the process can start at any point. Assessment can also kick in at any point.</p>
<p>We conclude that the <italic>assessment</italic> may consist of adjustments made by the management of an existing system in use or by actors in the performance-management industry – often academics or consultants – as part of the management innovation processes, or by external auditors. Hence, some management models may have an after-life or many life cycles, and systematic research on the <italic>assessment</italic> stage is undeveloped. For instance, feedback mechanisms from use and <italic>assessment</italic> to design are almost uncovered, in addition to the understanding of how dysfunctional effects of performance measurements affect the design and implementation of performance-management systems.</p>
</sec>
<sec id="section8-1356389012442978">
<title>Impacts</title>
<p>There is an extensive literature on organizational effectiveness in sociology and organization theory (<xref ref-type="bibr" rid="bibr28-1356389012442978">Donaldson, 2001</xref>; <xref ref-type="bibr" rid="bibr54-1356389012442978">Meyer and Gupta, 1994</xref>; <xref ref-type="bibr" rid="bibr80-1356389012442978">Steers, 1975</xref>), although performance management is basically a matter of creating impacts through improvements (<xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al., 2006</xref>). The problem of deciding what satisfactory improvements are can be aggravated by the fact that such assessments may depend on issues such as organizational size and age, and whether the organizations have previously been regarded as efficient or not. Opinions on given criteria on the relationships between the realized and intended impacts of public service processes and outputs can assess improvements, but these criteria and the weights that should be assigned to them may vary between stakeholders and over time. In this way, improvements and impacts in our vocabulary will always be a political issue (<xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al., 2006</xref>).</p>
<p>The rationalistic tradition of public-sector performance-management research distinguishes between functional and dysfunctional use. In his classical paper, <xref ref-type="bibr" rid="bibr74-1356389012442978">Ridgway (1956)</xref> referred to the tension between intentions of improving organizational performance and the different uses of performance indexes, though the ultimate outcome may be less favourable to performance improvement than is usually assumed. In performance measurement, the cure may sometimes become worse than the disease.</p>
<p>The research has provided several lists of possible dysfunctional effects of uses of performance measurements, which includes the following seven aspects (<xref ref-type="bibr" rid="bibr79-1356389012442978">Smith, 1995</xref>; <xref ref-type="bibr" rid="bibr84-1356389012442978">Vakkuri and Meklin 2006</xref>): tunnel vision, sub-optimization, myopia, convergence, ossification, gaming, and misrepresentation. This last category is sometimes called ‘creative accounting’ or perverting behaviour (<xref ref-type="bibr" rid="bibr25-1356389012442978">De Bruijn, 2002</xref>).</p>
<p>There are only a few extensive studies of the impact of performance-management models on organizational performance. In one such study, <xref ref-type="bibr" rid="bibr53-1356389012442978">Melkers and Willoughby (2005)</xref> examined the effects of performance measurement information on budgeting in local US governments. They found that there was pervasive use, and that:</p>
<p><disp-quote>
<p>the implementation of performance measurement supports improved communication within and across branches of government, advances learned discussion about the results of government activities and services, and adds value to budgeting decisions by providing relevant information about results, as well as costs and activities. (p. 188)</p>
</disp-quote></p>
<p>Nevertheless, the information had little effect on budgeting processes and outcomes. <xref ref-type="bibr" rid="bibr58-1356389012442978">Moynihan and Pandey (2005)</xref> studied how many doctrines congruent with assumed good performance- management practice affected managers’ perceptions of organizational performance, and found that the clarity of goals and decentralized decision making positively affected performance. <xref ref-type="bibr" rid="bibr15-1356389012442978">Boyne and Chen (2007)</xref> found that the use of targets – a contested issue in public management – improved performance in schooling. There have also been studies, or at least discussions, of the impacts of performance information on democracy and accountability. <xref ref-type="bibr" rid="bibr72-1356389012442978">Pollitt (2006)</xref> argued that based on the available literature, performance information does not seem to be valued much by important decision makers in the public sector in terms of the impact on democracy. <xref ref-type="bibr" rid="bibr26-1356389012442978">De Lancer Julnes (2006)</xref> argued that performance information is important because it can influence decisions and therefore contributes to governmental accountability. Some new empirical research seems to indicate that performance management does have impacts for democracy and accountability (<xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al., 2006</xref>).</p>
<p>Not surprisingly, we have to conclude that <italic>impacts</italic> of performance measurement are difficult to quantify and assess, and two possible gaps may be explored. The first gap concerns the preoccupation with perverse behaviour and <italic>dys</italic>functional effects. The problem of measuring long-term impacts may be one explanation as to why the research has mainly concentrated on dysfunctional behavioural aspects of performance-management systems. Research could benefit from a more systematic approach in which both the possible benefits and costs were addressed, which would again result in a more balanced approach of the public-sector performance-management research such as in <xref ref-type="bibr" rid="bibr1-1356389012442978">Abernethy and Lillis (2001)</xref>, <xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al. (2006)</xref> and <xref ref-type="bibr" rid="bibr86-1356389012442978">Van Dooren and Van de Walle (2008)</xref>. Furthermore, dysfunctional effects should be studied more contextually in various public-sector organizational environments. Albeit difficult to assess, both the functional and dysfunctional effects of performance management should be applied to citizens and other relevant stakeholders of public services and not only to management (<xref ref-type="bibr" rid="bibr13-1356389012442978">Bouckaert and Halligan, 2008</xref>). The impacts of performance management are long-term effects. Understanding impacts is therefore a difficult inter-temporal analysis in which links between causes (performance-management systems use) and effects (performance improvement in the public sector) are complicated to demonstrate. The relationships also vary according to the criteria assigned to the political decisions by stakeholders over time. To include measures for the usage of performance-management models as independent variables in for instance productivity analyses (e.g. data envelopment analysis) could be a viable way forward in the study of impacts.</p>
<p>The second gap relates to a lack of theoretical focus in studying the dysfunctional effects of performance management. The behaviour in public organizations may influence performance measurement and vice versa. It may be the case that users either employ the performance measurement systems for their unique individual, organizational and/or political purposes or that the systems set the conditions for the organizational actors to adapt to. In sum, the research has to explain these various directions of influence more adequately.</p>
</sec>
</sec>
<sec id="section9-1356389012442978" sec-type="discussion">
<title>Discussion</title>
<p>The life-cycle model of performance management can be applied positively or normatively. When applied positively it can be used to map out, develop and evaluate research, as we have done. When applied normatively, it can be used to anticipate the stages that managers and other users should be engaged with.</p>
<p>We argue that the life-cycle framework could contribute to making different actors (researchers, practitioners, evaluators) and disciplines more aware of the ways in which specific problems within specific stages in the area of public-sector performance-management research are addressed, analysed and solved. The life-cycle model provides a systematic framework for this purpose. Proper communication between disciplines and professions is not self-evident, let alone among academic journals. Moreover, researchers, practitioners, evaluators and the consultancy industry emphasize the various performance management stages as well as the problems in this field. This is why they may prefer different meeting points and communication channels. For instance, many behavioural accounting studies (<xref ref-type="bibr" rid="bibr47-1356389012442978">Llewellyn and Northcott, 2005</xref>; <xref ref-type="bibr" rid="bibr55-1356389012442978">Modell, 2004</xref>) are more focused on the dysfunctional effects of performance management than on its intended and realized benefits. Practitioners of management and evaluation however, tend to be particularly interested in the design and implementation of the models for practical purposes (<xref ref-type="bibr" rid="bibr43-1356389012442978">Kaplan and Norton, 1996</xref>; <xref ref-type="bibr" rid="bibr46-1356389012442978">Likierman, 1993</xref>), whereas researchers generally mainly concentrate on the design and use of the models from a theoretical perspective (<xref ref-type="bibr" rid="bibr21-1356389012442978">Cavalluzzo and Ittner, 2004</xref>; <xref ref-type="bibr" rid="bibr85-1356389012442978">Van Dooren, 2005</xref>). In other words, it could be argued that in addition to the lack of mutual communication among the different disciplinary areas (<xref ref-type="bibr" rid="bibr88-1356389012442978">Van Helden et al., 2008</xref>), there is still much to be gained in the facilitation of the communication between academics and practitioners. Here the life-cycle framework could play a crucial role.</p>
<p>As regards the issue of rationality, there may on a broader level be a theoretical development over time in public-sector performance-management research, which mirrors that in administrative theory (<xref ref-type="bibr" rid="bibr78-1356389012442978">Simon, 1997 [1947]</xref>), i.e. economic, administrative and political management. Different notions of rationality may explain the dominant mode of thinking of many of the actors in the different stages of the life cycle: (intended) economic rationality in the design stage, bounded rationality in the implementation stage and political rationality in the use and evaluation stages. <xref ref-type="bibr" rid="bibr17-1356389012442978">Boyne et al. (2006)</xref> regard the performance of public organizations as contested and multidimensional, while they consider all measures of performance – whether quantitative or qualitative – as ‘subjective’. Accordingly, our proposal is to seek a more balanced approach to analysing the various stages of the life cycle and perhaps to identify different forms of rationalities for different stakeholders at the different stages of the life cycle. In that respect, evaluation may learn from accounting and public management, which only seldom regards numbers as ‘objective’ representations of reality. Conversely, however, performance information is often subject to interests and contingent on assumptions and choice.</p>
<p>Our analysis indicates major theoretical gaps in the prevailing body of knowledge of public-sector performance management. First, the design of performance-management systems continues to be biased toward measuring costs and efficiency at the expense of issues of equity and user satisfaction, although this does not apply to the evaluation perspective. Second, despite some studies on implementation, this second stage seems to be under-researched. Third, the common understanding of the use and users of performance information seems to be embedded in the notion of hierarchical management control. There is, however, a need for a broader conception of the use and users of performance information than the one often supported thus far. In particular, public-sector managers could learn from what is available in the evaluation literature; for example, the notion that in political decision making performance information may not be decisive but influential. Fourth, the conceptions of the empirical research on the assessment of performance-management systems and its interaction with the other three stages are underdeveloped. Fifth, the studies into the influence of performance management systems primarily address dysfunctional impacts. Instead, performance-management research should seek a more balanced and theoretically solid approach that includes both the costs and benefits of the uses of performance-management systems. Sixth, a more in-depth analysis of the institutional and organizational contingencies of performance-management design, implementation, use and assessment may show inconsistencies. For example, what works (or not) in one setting in an Anglo-American public management culture may not work in another setting. Seventh, there is a lack of research on the interdependencies among the various performance-management stages. Researchers as well as practitioners may be unaware of the links of their research and practices in public sector performance management with other stages of the performance-management life cycle. In evaluating performance-management systems the evaluation discipline should recognize these gaps in the literature.</p>
</sec>
<sec id="section10-1356389012442978">
<title>Implications of the life-cycle approach for evaluation research and practice</title>
<p>The life-cycle approach primarily regards performance measurement as a managerial problem. Although this view does not fundamentally deviate from the evaluation perspective – both assume that performance can be improved through high-quality knowledge of the entities considered, be they programmes, organizations or services – there are also differences. Next, we discuss these differences, demonstrating how the life-cycle approach to performance measurement can also be beneficial to the evaluation domain.</p>
<p>In evaluation an answer has to be given to the question as to whether a certain programme, organization or service is effective, i.e. whether it accomplishes the relevant goals. Comparing the evaluation to the managerial focus, three key issues stand out. First, in the case of the former the domain is often a <italic>public-sector programme</italic> rather than a public-sector organization or organizational unit. Second, the core is <italic>to find and assess causal links between programme components and programme goals</italic>, which may conflict with the managerial interests as regards the usefulness of performance-management systems for decision making. As already indicated, a management focus often underplays aspects of effectiveness and customer satisfaction while overemphasizing aspects of efficiency and cost saving. Third, performance management systems are important for evaluation, but <italic>evaluation requires much more information</italic> (e.g. on how public-sector organizations develop their goals and how organizations engaged in a programme can enrich their learning capacity) (<xref ref-type="bibr" rid="bibr12-1356389012442978">Bledsoe and Graham, 2005</xref>).</p>
<p>In the design stage of the life-cycle approach the evaluation perspective requires a substantial discussion about the identification of goals and how these goals can be translated into suitable performance indicators. Although performance management also acknowledges the importance of conflicting goals (<xref ref-type="bibr" rid="bibr33-1356389012442978">Hofstede, 1981</xref>), the evaluation stance requires that a broad variety of stakeholders has to be involved in the design of a performance-management system to ensure that all relevant goals are addressed (<xref ref-type="bibr" rid="bibr64-1356389012442978">Perrin, 1998</xref>, <xref ref-type="bibr" rid="bibr66-1356389012442978">2006</xref>). Several guidelines about reporting performance information from <xref ref-type="bibr" rid="bibr31-1356389012442978">GASB (2003)</xref> highlight the importance of the design of a performance-management system, particularly with respect to clarifying the scope of the programme, identifying its goals and stakeholders and trying to find a balance between being concise and comprehensive in selecting performance indicators.</p>
<p>A further implication of the life-cycle approach to evaluation concerns the notion, in evaluation, that performance-management systems have to be evidence-based. This means that a search for causal links between components of the programme and relevant outcome indicators is crucial. Here the main question to be answered is: ‘does the programme work as it was meant to?’, which is more ambitious than simply requiring that performance information is useful for controlling the organization. Indicators can relate to activities, outputs and short-term outcomes, and they have to be measured and compared with targets. The life-cycle approach may help evaluators during the implementation stage to check as to whether sufficient proof can be found for causal links between programme components and relevant outcome indicators, for example, by pilot testing (<xref ref-type="bibr" rid="bibr66-1356389012442978">Perrin, 2006</xref>). The approach may also stimulate evaluators to reconsider these causal links in the assessment stage of the life cycle when experiences with the application of the performance-management systems are available for evaluation purposes.</p>
<p>Furthermore, the life-cycle approach can help evaluators to recognize either positive or negative unintended side effects of the programmes. Although the programmes are developed to achieve certain goals, and defining goal-related performance indicators for assessing the effectiveness of these programmes is crucial, evaluators need to be receptive to the input from stakeholders on, for example, unforeseen side effects of these programmes (<xref ref-type="bibr" rid="bibr45-1356389012442978">Leeuw, 1996</xref>; <xref ref-type="bibr" rid="bibr66-1356389012442978">Perrin, 2006</xref>). The assessment stage of the life-cycle approach focuses on the question of whether performance indicators need to be reconsidered or the whole performance management system should be redesigned given the evidence about the execution of the programme. This reconsideration, which the life-cycle framework conceptualizes as the assessment stage, may help avoiding overly simple feedback mechanisms in which responsible persons listen to what only external evaluators have to say in order to avoid making mistakes in the future. In contrast, organizational learning (conceptualized as taking place in the assessment stage) requires that assumptions underlying programmes are questioned, giving rise to reflections upon possible innovative adaptations to these programmes (<xref ref-type="bibr" rid="bibr45-1356389012442978">Leeuw, 1996</xref>). This aspect is often neglected in the management accounting and public management literatures, but is something that an evaluation perspective may add in order to make the body of knowledge more balanced and complete.</p>
</sec>
</body>
<back>
<ack><p>Earlier versions of this article were presented at the Conference of the European Group of Public Administration (EGPA) ‘Comparing performance’ 19–22 September 2007, Madrid, Study Group II Performance in the public sector and at the Conference ‘Evaluating the Complex’, 29–30 May 2008, Oslo. We are grateful to the attendants at these conferences, Wouter van Dooren, Christopher Pollitt, Isabella Proeller, Steven van de Walle and three anonymous referees for their comments.</p></ack>
<fn-group>
<fn fn-type="financial-disclosure">
<p>This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Abernethy</surname><given-names>MA</given-names></name>
<name><surname>Lillis</surname><given-names>AM</given-names></name>
</person-group> (<year>2001</year>) <article-title>Interdependencies in organization design: a test in hospitals</article-title>. <source>Journal of Management Accounting Research</source> <volume>13</volume>: <fpage>107</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr2-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Abrahamson</surname><given-names>E</given-names></name>
</person-group> (<year>1996</year>) <article-title>Management fashion</article-title>. <source>Academy of Management Review</source> <volume>21</volume>(<issue>1</issue>): <fpage>254</fpage>–<lpage>85</lpage>.</citation>
</ref>
<ref id="bibr3-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aidemark</surname><given-names>LG</given-names></name>
</person-group> (<year>2001</year>) <article-title>The meaning of balanced scorecards in the health care organisation</article-title>. <source>Financial Accountability and Management</source> <volume>17</volume>(<issue>1</issue>): <fpage>23</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr4-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Askim</surname><given-names>J</given-names></name>
</person-group> (<year>2007</year>) <article-title>How do politicians use performance information? An analysis of the Norwegian local government experience</article-title>. <source>International Review of Administrative Sciences</source> <volume>73</volume>(<issue>3</issue>): <fpage>453</fpage>−<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr5-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Askim</surname><given-names>J</given-names></name>
<name><surname>Johnsen</surname><given-names>Å</given-names></name>
<name><surname>Christophersen</surname><given-names>KA</given-names></name>
</person-group> (<year>2008</year>) <article-title>Factors behind organizational learning from benchmarking: experiences from Norwegian municipal benchmarking networks</article-title>. <source>Journal of Public Administration Research and Theory</source> <volume>18</volume>(<issue>2</issue>): <fpage>297</fpage>–<lpage>320</lpage>.</citation>
</ref>
<ref id="bibr6-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Banker</surname><given-names>RD</given-names></name>
</person-group> (<year>1980</year>) <article-title>A game theoretic approach to measuring efficiency</article-title>. <source>European Journal of Operations Research</source> <volume>5</volume>(<issue>4</issue>): <fpage>262</fpage>–<lpage>6</lpage>.</citation>
</ref>
<ref id="bibr7-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bastøe</surname><given-names>PØ</given-names></name>
</person-group> (<year>2006</year>) <article-title>Implementing results-based management</article-title>. In: <person-group person-group-type="editor">
<name><surname>Rist</surname><given-names>RC</given-names></name>
<name><surname>Stame</surname><given-names>N</given-names></name>
</person-group> (ed.) <source>From Studies to Streams: Managing Evaluative Systems</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Transaction Publishers</publisher-name>, <fpage>97</fpage>–<lpage>110</lpage>.</citation>
</ref>
<ref id="bibr8-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Behn</surname><given-names>RD</given-names></name>
</person-group> (<year>2003</year>) <article-title>Why measure performance? Different purposes require different measures</article-title>. <source>Public Administration Review</source> <volume>63</volume>(<issue>5</issue>): <fpage>588</fpage>–<lpage>606</lpage>.</citation>
</ref>
<ref id="bibr9-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Berman</surname><given-names>E</given-names></name>
<name><surname>Wang</surname><given-names>X</given-names></name>
</person-group> (<year>2000</year>) <article-title>Performance measurement in U.S. counties: capacity for reform</article-title>. <source>Public Administration Review</source> <volume>60</volume>(<issue>5</issue>): <fpage>409</fpage>–<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr10-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bevan</surname><given-names>G</given-names></name>
<name><surname>Hood</surname><given-names>C</given-names></name>
</person-group> (<year>2006</year>) <article-title>What’s measured is what matters: targets and gaming in the English public health care system</article-title>. <source>Public Administration</source> <volume>84</volume>(<issue>3</issue>): <fpage>517</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr11-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Blalock</surname><given-names>AB</given-names></name>
</person-group> (<year>1999</year>) <article-title>Evaluation research and the performance management movement: estrangement to useful integration?</article-title> <source>Evaluation</source> <volume>5</volume>(<issue>2</issue>): <fpage>117</fpage>–<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr12-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bledsoe</surname><given-names>KL</given-names></name>
<name><surname>Graham</surname><given-names>JA</given-names></name>
</person-group> (<year>2005</year>) <article-title>The use of multiple evaluation approaches in program evaluation</article-title>. <source>American Journal of Evaluation</source> <volume>26</volume>(<issue>3</issue>): <fpage>302</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr13-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bouckaert</surname><given-names>G</given-names></name>
<name><surname>Halligan</surname><given-names>J</given-names></name>
</person-group> (<year>2008</year>) <source>Managing Performance: International Comparisons</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr14-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bowerman</surname><given-names>M</given-names></name>
<name><surname>Ball</surname><given-names>A</given-names></name>
<name><surname>Francis</surname><given-names>G</given-names></name>
</person-group> (<year>2001</year>) <article-title>Benchmarking as a tool for the modernisation of local government</article-title>. <source>Financial Accountability and Management</source> <volume>17</volume>(<issue>4</issue>): <fpage>321</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr15-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boyne</surname><given-names>GA</given-names></name>
<name><surname>Chen</surname><given-names>AA</given-names></name>
</person-group> (<year>2007</year>) <article-title>Performance targets and public service improvement</article-title>. <source>Journal of Public Administration Research and Theory</source> <volume>17</volume>(<issue>3</issue>): <fpage>455</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr16-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boyne</surname><given-names>GA</given-names></name>
<name><surname>Gould-Williams</surname><given-names>JS</given-names></name>
</person-group> (<year>2003</year>) <article-title>Planning and performance in public organizations: an empirical analysis</article-title>. <source>Public Management Review</source> <volume>5</volume>(<issue>1</issue>): <fpage>115</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr17-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Boyne</surname><given-names>GA</given-names></name>
<name><surname>Meier</surname><given-names>KJ</given-names></name>
<name><surname>O’Toole</surname><given-names>LJ</given-names></name>
<name><surname>Walker</surname><given-names>RM</given-names></name>
</person-group> (eds) (<year>2006</year>) <source>Public Service Performance: Perspectives on Measurement and Management</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bretschneider</surname><given-names>S</given-names></name>
<name><surname>Marc-Aurele</surname><given-names>FJ</given-names><suffix>Jr</suffix></name>
<name><surname>Wu</surname><given-names>J</given-names></name>
</person-group> (<year>2005</year>) <article-title>‘Best practices’ research: a methodological guide for the perplexed</article-title>. <source>Journal of Public Administration Research and Theory</source> <volume>15</volume>(<issue>2</issue>): <fpage>307</fpage>–<lpage>23</lpage>.</citation>
</ref>
<ref id="bibr19-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carson</surname><given-names>PP</given-names></name>
<name><surname>Lanier</surname><given-names>PA</given-names></name>
<name><surname>Carson</surname><given-names>KD</given-names></name>
<name><surname>Guidry</surname><given-names>BN</given-names></name>
</person-group> (<year>2000</year>) <article-title>Clearing a path through the management fashion jungle: some preliminary trailblazing</article-title>. <source>Academy of Management Journal</source> <volume>43</volume>(<issue>6</issue>): <fpage>1143</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr20-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carter</surname><given-names>N</given-names></name>
</person-group> (<year>1991</year>) <article-title>Learning to measure performance: the use of indicators in organizations</article-title>. <source>Public Administration</source> <volume>69</volume>(<issue>1</issue>): <fpage>85</fpage>–<lpage>101</lpage>.</citation>
</ref>
<ref id="bibr21-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cavalluzzo</surname><given-names>KS</given-names></name>
<name><surname>Ittner</surname><given-names>CD</given-names></name>
</person-group> (<year>2004</year>) <article-title>Implementing performance measurement innovations: evidence from government</article-title>. <source>Accounting, Organizations and Society</source> <volume>29</volume>(<issue>3/4</issue>): <fpage>243</fpage>–<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr22-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Charnes</surname><given-names>A</given-names></name>
<name><surname>Clarke</surname><given-names>RL</given-names></name>
<name><surname>Cooper</surname><given-names>WW</given-names></name>
</person-group> (<year>1989</year>) <article-title>An approach to testing for organizational slack via Banker’s game theoretics DEA formulations</article-title>. <source>Research in Governmental and Nonprofit Accounting</source> <volume>5</volume>: <fpage>211</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr23-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Curristine</surname><given-names>T</given-names></name>
</person-group> (<year>2005</year>) <article-title>Government performance: lessons and challenges</article-title>. <source>OECD Journal on Budgeting</source> <volume>5</volume>(<issue>1</issue>): <fpage>127</fpage>–<lpage>51</lpage>.</citation>
</ref>
<ref id="bibr24-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Davies</surname><given-names>IC</given-names></name>
</person-group> (<year>1999</year>) <article-title>Evaluation and performance management in government</article-title>. <source>Evaluation</source> <volume>5</volume>(<issue>2</issue>): <fpage>150</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr25-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>De Bruijn</surname><given-names>H</given-names></name>
</person-group> (<year>2002</year>) <source>Managing Performance in the Public Sector</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr26-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>De Lancer Julnes</surname><given-names>P</given-names></name>
</person-group> (<year>2006</year>) <article-title>Performance measurement: an effective tool for government accountability? The debate goes on</article-title>. <source>Evaluation</source> <volume>12</volume>(<issue>2</issue>): <fpage>219</fpage>–<lpage>35</lpage>.</citation>
</ref>
<ref id="bibr27-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>De Lancer Julnes</surname><given-names>P</given-names></name>
<name><surname>Holzer</surname><given-names>M</given-names></name>
</person-group> (<year>2001</year>) <article-title>Promoting the utilization of performance measures in public organizations: an empirical study of factors affecting adoption and implementation</article-title>. <source>Public Administration Review</source> <volume>61</volume>(<issue>6</issue>): <fpage>693</fpage>–<lpage>708</lpage>.</citation>
</ref>
<ref id="bibr28-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Donaldson</surname><given-names>L</given-names></name>
</person-group> (<year>2001</year>) <source>The Contingency Theory of Organizations</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr29-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Drucker</surname><given-names>PF</given-names></name>
</person-group> (<year>1954</year>) <source>The Practice of Management</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Harper Business</publisher-name>.</citation>
</ref>
<ref id="bibr30-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Frederickson</surname><given-names>DG</given-names></name>
<name><surname>Frederickson</surname><given-names>HG</given-names></name>
</person-group> (<year>2006</year>) <source>Measuring the Performance of the Hollow State</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Georgetown University Press</publisher-name>.</citation>
</ref>
<ref id="bibr31-1356389012442978">
<citation citation-type="book">
<collab>GASB</collab> (<year>2003</year>) <source>Reporting Performance Information: Suggested Criteria for Effective Communication</source>. <publisher-loc>Norwalk, CT</publisher-loc>: <publisher-name>Governmental Accounting Standards Board</publisher-name>.</citation>
</ref>
<ref id="bibr32-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hartley</surname><given-names>J</given-names></name>
<name><surname>Allison</surname><given-names>M</given-names></name>
</person-group> (<year>2002</year>) <article-title>Good, better, best? Inter-organizational learning in a network of local authorities</article-title>. <source>Public Management Review</source> <volume>4</volume>(<issue>1</issue>): <fpage>101</fpage>–<lpage>18</lpage>.</citation>
</ref>
<ref id="bibr33-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hofstede</surname><given-names>G</given-names></name>
</person-group> (<year>1981</year>) <article-title>Management control of public and not-for-profit activities</article-title>. <source>Accounting, Organizations and Society</source> <volume>6</volume>(<issue>3</issue>): <fpage>193</fpage>–<lpage>211</lpage>.</citation>
</ref>
<ref id="bibr34-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hood</surname><given-names>C</given-names></name>
</person-group> (<year>2007</year>) <article-title>Public service management by numbers: why does it vary? Where has it come from? What are the gaps and the puzzles?</article-title> <source>Public Money and Management</source> <volume>27</volume>(<issue>2</issue>): <fpage>95</fpage>–<lpage>102</lpage>.</citation>
</ref>
<ref id="bibr35-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hyndman</surname><given-names>N</given-names></name>
<name><surname>Eden</surname><given-names>R</given-names></name>
</person-group> (<year>2000</year>) <article-title>A study of the coordination of mission, objectives and targets in U.K. executive agencies</article-title>. <source>Management Accounting Research</source> <volume>11</volume>(<issue>2</issue>): <fpage>175</fpage>–<lpage>91</lpage>.</citation>
</ref>
<ref id="bibr36-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jacobs</surname><given-names>R</given-names></name>
<name><surname>Goddard</surname><given-names>M</given-names></name>
</person-group> (<year>2007</year>) <article-title>How do performance indicators add up? An examination of composite indicators in public services</article-title>. <source>Public Money and Management</source> <volume>27</volume>(<issue>2</issue>): <fpage>103</fpage>–<lpage>10</lpage>.</citation>
</ref>
<ref id="bibr37-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jansen</surname><given-names>P</given-names></name>
</person-group> (<year>2008</year>) <article-title>New public management: perspectives on performance and the information use</article-title>. <source>Financial Accountability and Management</source> <volume>24</volume>(<issue>2</issue>): <fpage>169</fpage>–<lpage>91</lpage>.</citation>
</ref>
<ref id="bibr38-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnsen</surname><given-names>Å</given-names></name>
</person-group> (<year>1999</year>) <article-title>Implementation mode and local government performance measurement: a Norwegian experience</article-title>. <source>Financial Accountability and Management</source> <volume>15</volume>(<issue>1</issue>): <fpage>41</fpage>–<lpage>66</lpage>.</citation>
</ref>
<ref id="bibr39-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnsen</surname><given-names>Å</given-names></name>
</person-group> (<year>2001</year>) <article-title>Balanced scorecard: theoretical perspectives and public management implications</article-title>. <source>Managerial Auditing Journal</source> <volume>16</volume>(<issue>6</issue>): <fpage>319</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr40-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnsen</surname><given-names>Å</given-names></name>
</person-group> (<year>2005</year>) <article-title>What does 25 years of experience tell us about the state of performance measurement in public management and policy?</article-title> <source>Public Money and Management</source> <volume>25</volume>(<issue>1</issue>): <fpage>9</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr41-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jones</surname><given-names>CS</given-names></name>
</person-group> (<year>2002</year>) <article-title>The attitudes of British National Health Service managers and clinicians towards the introduction of benchmarking</article-title>. <source>Financial Accountability and Management</source> <volume>18</volume>(<issue>2</issue>): <fpage>163</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr42-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaplan</surname><given-names>RS</given-names></name>
</person-group> (<year>1998</year>) <article-title>Innovation action research: creating new management theory and practice</article-title>. <source>Journal of Management Accounting Research</source> <volume>10</volume>: <fpage>89</fpage>–<lpage>118</lpage>.</citation>
</ref>
<ref id="bibr43-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kaplan</surname><given-names>RS</given-names></name>
<name><surname>Norton</surname><given-names>DP</given-names></name>
</person-group> (<year>1996</year>) <source>The Balanced Scorecard: Translating Strategy into Action</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Harvard Business School Press</publisher-name>.</citation>
</ref>
<ref id="bibr44-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kusek</surname><given-names>JZ</given-names></name>
<name><surname>Rist</surname><given-names>R</given-names></name>
</person-group> (<year>2004</year>) <source>Ten Steps to a Results-Based Monitoring and Evaluation System</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>World Bank</publisher-name>.</citation>
</ref>
<ref id="bibr45-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Leeuw</surname><given-names>FL</given-names></name>
</person-group> (<year>1996</year>) <article-title>Performance auditing, new public management and performance improvement: questions and answers</article-title>. <source>Accounting, Auditing and Accountability Journal</source> <volume>9</volume>(<issue>2</issue>): <fpage>92</fpage>–<lpage>102</lpage>.</citation>
</ref>
<ref id="bibr46-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Likierman</surname><given-names>A</given-names></name>
</person-group> (<year>1993</year>) <article-title>Performance indicators: 20 early lessons from managerial use</article-title>. <source>Public Money and Management</source> <volume>13</volume>(<issue>4</issue>): <fpage>15</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr47-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Llewellyn</surname><given-names>S</given-names></name>
<name><surname>Northcott</surname><given-names>D</given-names></name>
</person-group> (<year>2005</year>) <article-title>The average hospital</article-title>. <source>Accounting, Organizations and Society</source> <volume>30</volume>(<issue>6</issue>): <fpage>555</fpage>–<lpage>83</lpage>.</citation>
</ref>
<ref id="bibr48-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Long</surname><given-names>E</given-names></name>
<name><surname>Franklin</surname><given-names>AL</given-names></name>
</person-group> (<year>2004</year>) <article-title>The paradox of implementing the government performance and results act: top-down direction for bottom-up implementation</article-title>. <source>Public Administration Review</source> <volume>64</volume>(<issue>3</issue>): <fpage>309</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr49-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McDavid</surname><given-names>J</given-names></name>
<name><surname>Hawthorn</surname><given-names>LRL</given-names></name>
</person-group> (<year>2006</year>) <source>Program Evaluation and Performance Measurement: An Introduction to Practice</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr50-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mayne</surname><given-names>J</given-names></name>
</person-group> (<year>2007</year>) <article-title>Challenges and lessons in implementing results-based management</article-title>. <source>Evaluation</source> <volume>13</volume>(<issue>1</issue>): <fpage>87</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr51-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mayston</surname><given-names>DJ</given-names></name>
</person-group> (<year>1985</year>) <article-title>Non-profit performance indicators in the public sector</article-title>. <source>Financial Accountability and Management</source> <volume>1</volume>(<issue>1</issue>): <fpage>51</fpage>–<lpage>74</lpage>.</citation>
</ref>
<ref id="bibr52-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mayston</surname><given-names>DJ</given-names></name>
</person-group> (<year>1993</year>) <article-title>Principals, agents and the economics of accountability in the new public management</article-title>. <source>Accounting, Auditing and Accountability Journal</source> <volume>6</volume>(<issue>3</issue>): <fpage>68</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr53-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Melkers</surname><given-names>J</given-names></name>
<name><surname>Willoughby</surname><given-names>K</given-names></name>
</person-group> (<year>2005</year>) <article-title>Models of performance-measurement use in local governments: understanding budgeting communication and lasting effects</article-title>. <source>Public Administration Review</source> <volume>65</volume>(<issue>2</issue>): <fpage>180</fpage>–<lpage>90</lpage>.</citation>
</ref>
<ref id="bibr54-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Meyer</surname><given-names>MW</given-names></name>
<name><surname>Gupta</surname><given-names>V</given-names></name>
</person-group> (<year>1994</year>) <article-title>The performance paradox</article-title>. <source>Research in Organizational Behavior</source> <volume>16</volume>: <fpage>309</fpage>–<lpage>69</lpage>.</citation>
</ref>
<ref id="bibr55-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Modell</surname><given-names>S</given-names></name>
</person-group> (<year>2004</year>) <article-title>Performance measurement myths in the public sector: a research note</article-title>. <source>Financial Accountability and Management</source> <volume>20</volume>(<issue>1</issue>): <fpage>39</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr56-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>DP</given-names></name>
</person-group> (<year>2005</year>) <article-title>Goal-based learning and the future of performance management</article-title>. <source>Public Administration Review</source> <volume>65</volume>(<issue>2</issue>): <fpage>203</fpage>–<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr57-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>DP</given-names></name>
</person-group> (<year>2008</year>) <source>The Dynamics of Performance Management: Constructing Information and Reform</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Georgetown University Press</publisher-name>.</citation>
</ref>
<ref id="bibr58-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moynihan</surname><given-names>DP</given-names></name>
<name><surname>Pandey</surname><given-names>SK</given-names></name>
</person-group> (<year>2005</year>) <article-title>Testing how management matters in an era of government by performance management</article-title>. <source>Journal of Public Administration Research and Theory</source> <volume>15</volume>: <fpage>421</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr59-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nielsen</surname><given-names>SB</given-names></name>
<name><surname>Ejler</surname><given-names>N</given-names></name>
</person-group> (<year>2008</year>) <article-title>Improving performance? Exploring the complementarities between evaluation and performance management</article-title>. <source>Evaluation</source> <volume>14</volume>(<issue>2</issue>): <fpage>171</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr60-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Noordegraaf</surname><given-names>M</given-names></name>
<name><surname>Abma</surname><given-names>T</given-names></name>
</person-group> (<year>2003</year>) <article-title>Management by measurement? Public management practices amidst ambiguity</article-title>. <source>Public Administration</source> <volume>81</volume>(<issue>4</issue>): <fpage>853</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr61-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nørreklit</surname><given-names>H</given-names></name>
</person-group> (<year>2003</year>) <article-title>The balanced scorecard: what is the score? A rhetorical analysis of the balanced scorecard</article-title>. <source>Accounting, Organizations and Society</source> <volume>28</volume>(<issue>6</issue>): <fpage>592</fpage>–<lpage>619</lpage>.</citation>
</ref>
<ref id="bibr62-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nørreklit</surname><given-names>H</given-names></name>
<name><surname>Nørreklit</surname><given-names>L</given-names></name>
<name><surname>Melander</surname><given-names>P</given-names></name>
</person-group> (<year>2006</year>) <article-title>US ‘fair contract’ based performance management models in a Danish environment</article-title>. <source>Financial Accountability and Management</source> <volume>22</volume>(<issue>3</issue>): <fpage>213</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr63-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ouchi</surname><given-names>W</given-names></name>
</person-group> (<year>1979</year>) <article-title>A conceptual framework for the design of organizational control mechanisms</article-title>. <source>Management Science</source> <volume>25</volume>(<issue>9</issue>): <fpage>833</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr64-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Perrin</surname><given-names>B</given-names></name>
</person-group> (<year>1998</year>) <article-title>Effective use and misuse of performance measurement</article-title>. <source>American Journal of Evaluation</source> <volume>19</volume>(<issue>3</issue>): <fpage>367</fpage>–<lpage>79</lpage>.</citation>
</ref>
<ref id="bibr65-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Perrin</surname><given-names>B</given-names></name>
</person-group> (<year>1999</year>) <article-title>Performance measurement: does the reality match the rhetoric? A rejoinder to Bernstein and Winston</article-title>. <source>American Journal of Evaluation</source> <volume>20</volume>(<issue>1</issue>): <fpage>101</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr66-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Perrin</surname><given-names>B</given-names></name>
</person-group> (<year>2006</year>) <source>Moving from Outputs to Outcomes: Practical Advice from Governments around the World</source>. <publisher-loc>Arlington, VA</publisher-loc>: <publisher-name>IBM Centre for the Business of Government</publisher-name>.</citation>
</ref>
<ref id="bibr67-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Poister</surname><given-names>TH</given-names></name>
</person-group> (<year>2003</year>) <source>Measuring Performance in Public and Nonprofit Organizations</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr68-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Poister</surname><given-names>TH</given-names></name>
<name><surname>Streib</surname><given-names>G</given-names></name>
</person-group> (<year>1995</year>) <article-title>MBO in municipal government: variations on a traditional management tool</article-title>. <source>Public Administration Review</source> <volume>55</volume>(<issue>1</issue>): <fpage>48</fpage>–<lpage>56</lpage>.</citation>
</ref>
<ref id="bibr69-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Poister</surname><given-names>TH</given-names></name>
<name><surname>Streib</surname><given-names>G</given-names></name>
</person-group> (<year>1999</year>) <article-title>Performance measurement in municipal government: assessing the state of practice</article-title>. <source>Public Administration Review</source> <volume>59</volume>(<issue>4</issue>): <fpage>325</fpage>–<lpage>35</lpage>.</citation>
</ref>
<ref id="bibr70-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pollitt</surname><given-names>C</given-names></name>
</person-group> (<year>1986</year>) <article-title>Beyond the managerial model: the case for broadening performance assessment in government and the public services</article-title>. <source>Financial Accountability and Management</source> <volume>2</volume>(<issue>3</issue>): <fpage>155</fpage>–<lpage>70</lpage>.</citation>
</ref>
<ref id="bibr71-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pollitt</surname><given-names>C</given-names></name>
</person-group> (<year>1988</year>) <article-title>Bringing consumers into performance measurement: concepts, consequences and constraints</article-title>. <source>Policy and Politics</source> <volume>16</volume>(<issue>2</issue>): <fpage>77</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr72-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pollitt</surname><given-names>C</given-names></name>
</person-group> (<year>2006</year>) <article-title>Performance information for democracy: the missing link?</article-title> <source>Evaluation</source> <volume>12</volume>(<issue>1</issue>): <fpage>38</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr73-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Radin</surname><given-names>BA</given-names></name>
</person-group> (<year>2006</year>) <source>Challenging the Performance Movement: Accountability, Complexity, and Democratic Values</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Georgetown University Press</publisher-name>.</citation>
</ref>
<ref id="bibr74-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ridgway</surname><given-names>VF</given-names></name>
</person-group> (<year>1956</year>) <article-title>Dysfunctional consequences of performance measurements</article-title>. <source>Administrative Science Quarterly</source> <volume>1</volume>(<issue>2</issue>): <fpage>240</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr75-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rist</surname><given-names>RC</given-names></name>
<name><surname>Stame</surname><given-names>N</given-names></name>
</person-group> (<year>2006</year>) <source>From Studies to Streams: Managing Evaluative Systems</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Transaction Publishers</publisher-name>.</citation>
</ref>
<ref id="bibr76-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rodgers</surname><given-names>R</given-names></name>
<name><surname>Hunter</surname><given-names>JE</given-names></name>
</person-group> (<year>1992</year>) <article-title>A foundation of good management practice in government: management by objectives</article-title>. <source>Public Administration Review</source> <volume>52</volume>(<issue>1</issue>): <fpage>27</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr77-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>HA</given-names></name>
</person-group> (<year>1937</year>) <article-title>Comparative statistics and the measurement of efficiency</article-title>. <source>National Municipal Review</source> <volume>26</volume>: <fpage>524</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr78-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>HA</given-names></name>
</person-group> (<year>1997 [1947]</year>) <source>Administrative Behavior: Study of Decision-Making Processes in Administrative Organizations</source>, <edition>4th edn.</edition> <publisher-loc>New York</publisher-loc>: <publisher-name>The Free Press</publisher-name>.</citation>
</ref>
<ref id="bibr79-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Smith</surname><given-names>P</given-names></name>
</person-group> (<year>1995</year>) <article-title>Outcome-related performance indicators and organisational control in the public sector</article-title>. In: <person-group person-group-type="editor">
<name><surname>Holloway</surname><given-names>J</given-names></name>
<name><surname>Lewis</surname><given-names>J</given-names></name>
<name><surname>Mallory</surname><given-names>G</given-names></name>
</person-group> (eds) <source>Performance Measurement and Evaluation</source>. <publisher-loc>London</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr80-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Steers</surname><given-names>RM</given-names></name>
</person-group> (<year>1975</year>) <article-title>Problems in the measurement of organizational effectiveness</article-title>. <source>Administrative Science Quarterly</source> <volume>20</volume>(<issue>4</issue>): <fpage>546</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr81-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Talbot</surname><given-names>C</given-names></name>
</person-group> (<year>2010</year>) <source>Theories of Performance: Organizational and Service Improvement in the Public Domain</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr82-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ter Bogt</surname><given-names>HJ</given-names></name>
</person-group> (<year>2004</year>) <article-title>Politicians in search of performance information? Survey research on Dutch aldermen’s use of performance information</article-title>. <source>Financial Accountability and Management</source> <volume>20</volume>(<issue>3</issue>): <fpage>221</fpage>–<lpage>52</lpage>.</citation>
</ref>
<ref id="bibr83-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vakkuri</surname><given-names>J</given-names></name>
</person-group> (<year>2003</year>) <article-title>Research techniques and their use in managing non profit organizations: an illustration of DEA analysis in NPO environments</article-title>. <source>Financial Accountability and Management</source> <volume>19</volume>(<issue>3</issue>): <fpage>243</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr84-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vakkuri</surname><given-names>J</given-names></name>
<name><surname>Meklin</surname><given-names>P</given-names></name>
</person-group> (<year>2006</year>) <article-title>Ambiguity in performance measurement – a theoretical approach to organisational uses of performance measurement</article-title>. <source>Financial Accountability and Management</source> <volume>22</volume>(<issue>3</issue>): <fpage>235</fpage>–<lpage>50</lpage>.</citation>
</ref>
<ref id="bibr85-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Van Dooren</surname><given-names>W</given-names></name>
</person-group> (<year>2005</year>) <article-title>What makes organisations measure? Hypotheses on the causes and conditions for performance measurement</article-title>. <source>Financial Accountability and Management</source> <volume>21</volume>(<issue>3</issue>): <fpage>363</fpage>–<lpage>83</lpage>.</citation>
</ref>
<ref id="bibr86-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Van Dooren</surname><given-names>W</given-names></name>
<name><surname>Van de Walle</surname><given-names>S</given-names></name>
</person-group> (eds) (<year>2008</year>) <source>Performance Information in the Public Sector: How it is Used</source>. <publisher-loc>Houndsmill</publisher-loc>: <publisher-name>Palgrave Macmillan</publisher-name>.</citation>
</ref>
<ref id="bibr87-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Van Helden</surname><given-names>GJ</given-names></name>
<name><surname>Tillema</surname><given-names>S</given-names></name>
</person-group> (<year>2005</year>) <article-title>In search of a benchmarking theory for the public sector</article-title>. <source>Financial Accountability and Management</source> <volume>21</volume>(<issue>3</issue>): <fpage>337</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr88-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Van Helden</surname><given-names>GJ</given-names></name>
<name><surname>Johnsen</surname><given-names>Å</given-names></name>
<name><surname>Vakkuri</surname><given-names>J</given-names></name>
</person-group> (<year>2008</year>) <article-title>Distinctive research patterns on public sector performance measurement of public administration and accounting disciplines</article-title>. <source>Public Management Review</source> <volume>10</volume>(<issue>5</issue>): <fpage>641</fpage>–<lpage>51</lpage>.</citation>
</ref>
<ref id="bibr89-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wang</surname><given-names>X</given-names></name>
<name><surname>Berman</surname><given-names>E</given-names></name>
</person-group> (<year>2001</year>) <article-title>Hypotheses about performance measurement in counties: findings from a survey</article-title>. <source>Journal of Public Administration Research and Theory</source> <volume>11</volume>(<issue>3</issue>): <fpage>403</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr90-1356389012442978">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Williams</surname><given-names>DW</given-names></name>
</person-group> (<year>2003</year>) <article-title>Measuring government in the early twentieth century</article-title>. <source>Public Administration Review</source> <volume>63</volume>(<issue>6</issue>): <fpage>643</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr91-1356389012442978">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>JQ</given-names></name>
</person-group> (<year>2000</year>) <source>Bureaucracy: What Government Agencies Do and Why They Do It</source>, <edition>2nd edn.</edition> <publisher-loc>New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>