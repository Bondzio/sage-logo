<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSS</journal-id>
<journal-id journal-id-type="hwp">sppss</journal-id>
<journal-id journal-id-type="nlm-ta">Psychol Sci</journal-id>
<journal-title>Psychological Science</journal-title>
<issn pub-type="ppub">0956-7976</issn>
<issn pub-type="epub">1467-9280</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0956797612459761</article-id>
<article-id pub-id-type="publisher-id">10.1177_0956797612459761</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Articles</subject></subj-group></article-categories>
<title-group>
<article-title>Counting Multidimensional Objects</article-title>
<subtitle>Implications for the Neural-Synchrony Theory</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Goldfarb</surname><given-names>Liat</given-names></name>
<xref ref-type="aff" rid="aff1-0956797612459761">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Treisman</surname><given-names>Anne</given-names></name>
<xref ref-type="aff" rid="aff2-0956797612459761">2</xref>
<xref ref-type="aff" rid="aff3-0956797612459761">3</xref>
</contrib>
</contrib-group>
<aff id="aff1-0956797612459761">
<label>1</label>Edmond J. Safra Brain Research Center for the Study of Learning Disabilities, Department of Learning Disabilities, University of Haifa</aff>
<aff id="aff2-0956797612459761">
<label>2</label>Department of Psychology, Princeton University</aff>
<aff id="aff3-0956797612459761">
<label>3</label>Center for the Study of Brain, Mind, and Behavior, Princeton University</aff>
<author-notes>
<corresp id="corresp1-0956797612459761">Liat Goldfarb, Edmond J. Safra Brain Research Center for the Study of Learning Disabilities, Department of Learning Disabilities, University of Haifa, Mount Carmel, Haifa, Israel 31905 E-mail: <email>goldfarb@edu.haifa.ac.il</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>24</volume>
<issue>3</issue>
<fpage>266</fpage>
<lpage>271</lpage>
<history><date date-type="received"><day>21</day>
<month>2</month>
<year>2011</year></date>
<date date-type="accepted"><day>10</day>
<month>5</month>
<year>2012</year></date></history>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>It has been suggested that a neural instantiation of the temporary multidimensional representations of objects might be synchrony of firing between the neurons representing the features that co-occur in a given location. In this article, we direct attention to a logical problem that arises when certain synchrony assumptions are applied to real situations in which multiple multidimensional objects are presented. We demonstrate a new behavioral effect that shows that this logical problem coincides with a genuine behavioral problem. Even when a display contains only a small number of objects characterized by features on two dimensions, the representation of the display becomes difficult when, according to our described assumptions, the object representations cannot be simultaneously synchronized on both features. This article outlines a new principle that governs object representation, and the experimental results might be unique behavioral evidence for a neural-based theory of feature binding.</p>
</abstract>
<kwd-group>
<kwd>object-file theory</kwd>
<kwd>feature binding</kwd>
<kwd>neural synchrony</kwd>
<kwd>visual perception</kwd>
<kwd>cognitive processes</kwd>
<kwd>cognitive neuroscience</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Representing multifeatured objects is a fundamental task for the perceptual system. The initial representation of such an object seems to take the form of specialized feature “maps”—one for each feature (e.g., color, shape, and orientation). The information in each map is at least partly independent from the information in other maps (e.g., <xref ref-type="bibr" rid="bibr14-0956797612459761">Treisman, 2006</xref>; <xref ref-type="bibr" rid="bibr15-0956797612459761">Treisman &amp; Gelade, 1980</xref>; <xref ref-type="bibr" rid="bibr16-0956797612459761">Treisman &amp; Schmidt, 1982</xref>). For example, when a scene contains a blue car next to a red bicycle, neurons in the color map would register the presence of the colors red and blue. At the same time, neurons in the shape map would register the shapes of a bicycle and a car. This kind of representation by itself does not contain information that allows the observer to know which color belongs to which object. The features must be bound into multifeatured object representations, in addition to activating the basic separate feature maps. If these integrated representations fail, perceptual errors in binding are experienced (e.g., <xref ref-type="bibr" rid="bibr16-0956797612459761">Treisman &amp; Schmidt, 1982</xref>).</p>
<p>Theoretically, the binding could be represented in two different ways. First, there could be a preexisting conjunction detector for each combination. Because the possible combinations of features are limitless, however, this solution is likely to work only for some familiar feature combinations, such as the color red and a strawberry shape, or the color yellow and a banana shape. For other, less frequent and less consistent feature combinations, a post hoc temporary representation of the conjunction must be formed (see <xref ref-type="bibr" rid="bibr5-0956797612459761">Hommel &amp; Colzato, 2009</xref>, for a discussion on this issue).</p>
<p>The object-file theory suggests a framework for this kind of post hoc binding. The theory (<xref ref-type="bibr" rid="bibr6-0956797612459761">Kahneman, Treisman, &amp; Gibbs, 1992</xref>) suggests that different features that characterize the same object are attached together temporarily via their location, which also acts as the retrieval cue for accessing the object. The theory distinguishes the long-term stored knowledge of object categories (or types), represented as nodes in a recognition network with just one representation for each category, and the temporary episodic representations (object files) that mediate “seeing” the specific objects currently present in their particular instantiation. The spatial location of each object file is its unique retrieval cue, or tag. Different locations that represent different objects are represented by distinctive tags. For example, for three separated objects, three distinctive location tags are created.<sup><xref ref-type="fn" rid="fn1-0956797612459761">1</xref></sup> A temporary object file that is created for each filled location specifies the features that are presently in that location. These files can be matched to the types in the recognition network in order to identify the objects that are present. This theory also allows the representation of multiple identical objects as separate object files with identical contents but different locations, even though there is only one type node for any given stored category.</p>
<p>Lately, we (<xref ref-type="bibr" rid="bibr3-0956797612459761">Goldfarb &amp; Treisman, 2012</xref>) have extended this theory and suggested that the representation of temporary object files acts as the platform from which the arithmetic system can count particular subsets of the items present. The perception of number is a basic ability that exists in human adults, human babies, and even some species of animals (e.g., <xref ref-type="bibr" rid="bibr1-0956797612459761">Dehaene, Piazza, Pinel, &amp; Cohen, 2003</xref>; <xref ref-type="bibr" rid="bibr9-0956797612459761">McComb, Packer, &amp; Pusey, 1994</xref>). People can generate a number label for the overall number of things in a scene (e.g., <xref ref-type="bibr" rid="bibr10-0956797612459761">Piazza, Izard, Pinel, Le Bihan, &amp; Dehaene, 2004</xref>; <xref ref-type="bibr" rid="bibr11-0956797612459761">Piazza, Pinel, Le Bihan, &amp; Dehaene, 2007</xref>), but can also count the numbers of objects in specific subsets among those things. For example, an observer can notice that there are four objects in a scene and that there are two cars and two bicycles in the same scene. The numbers in subsets are important not only in representing one’s surroundings, but also in allowing one to perform basic mathematical calculations (e.g., <xref ref-type="bibr" rid="bibr4-0956797612459761">Halberda, Mazzocco, &amp; Feigenson, 2008</xref>). The overall number of items present in a scene can be identified simply by counting the filled locations in a location map without binding the features they contain. In contrast, however, when an observer needs to count a specified subset of similar or identical objects, the defining feature (or features) of that subset must be specified. Thus, within our framework, the countable units need to be object files of bound features.</p>
<p>What might be the neural instantiation of these temporary multidimensional representations, or object files? One suggestion is that they might be encoded as synchrony of firing between the neurons representing the features that belong to the same object (e.g., <xref ref-type="bibr" rid="bibr2-0956797612459761">Engel &amp; Singer, 2001</xref>; <xref ref-type="bibr" rid="bibr5-0956797612459761">Hommel &amp; Colzato, 2009</xref>; <xref ref-type="bibr" rid="bibr17-0956797612459761">Vogel, Woodman, &amp; Luck, 2001</xref>; <xref ref-type="bibr" rid="bibr18-0956797612459761">von der Malsburg, 1999</xref>). Support for this idea has been documented in several experiments with both human and animal participants. (For a review of the evidence, see <xref ref-type="bibr" rid="bibr2-0956797612459761">Engel &amp; Singer, 2001</xref>, and <xref ref-type="bibr" rid="bibr12-0956797612459761">Raffone &amp; Wolters, 2001</xref>; but see <xref ref-type="bibr" rid="bibr8-0956797612459761">Lamme &amp; Spekreijse, 1998</xref>, and <xref ref-type="bibr" rid="bibr13-0956797612459761">Shadlen &amp; Movshon, 1999</xref>, for discussion of some controversial assumptions of this theory). In this account, an object file is represented by the firing synchrony of the neurons that represent the features—such as color, size, and shape—that occupy the same spatial location. Each object file is individuated by its location tag, but its features are integrated by sharing the same neural synchrony within that particular location. It is important to note that binding occurs only within locations. Synchrony across different locations does not result in binding the features of different objects together.</p>
<p>We now provide an example of how the synchrony assumption might fit with the object-file theory and then derive a new prediction about counting items in subsets. We then report two experiments in which we tested this prediction.</p>
<p>In the example display shown in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1a</xref>, the system needs to represent four letters that are in four different locations and printed in four different colors. The hypothesis is that neurons representing the color red and the <italic>X</italic> shape in Location 1 share a common synchrony, which we can label Synchrony Correlation a, or SCa. Similarly, the color green and the <italic>O</italic> shape in Location 2 share a common synchrony, SCb; the color blue and the <italic>T</italic> shape in Location 3 share a common synchrony, SCc; and the color brown and the <italic>S</italic> shape in Location 4 share a common synchrony, SCd. From this representation, the arithmetic system can abstract, for example, that there is one <italic>X</italic> or one green item. Now consider a second case, shown in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1b</xref>. In this example, features are repeated. The identity of a feature can be represented only once, and each distinct object file that contains that feature is bound to this identity. This can be done by synchronizing the firing in each location with the identity of the feature the location contains. In the example in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1b</xref>, the object files in Locations 1 and 4 can be synchronized with the <italic>X</italic> shape, and the object files in Locations 2 and 3 can be synchronized with the <italic>O</italic> shape. From this platform, the arithmetic system can conclude, for example, that there are two <italic>X</italic>s or two <italic>O</italic>s.</p>
<fig id="fig1-0956797612459761" position="float">
<label>Fig. 1.</label>
<caption>
<p>Applying the neural-synchrony explanation to object files. In each example stimulus, four letters appear in four locations. If each location has a unique shape and color (a), a specific shape, a specific color, and a specific location can share a common synchrony. For example, neurons representing the <italic>X</italic> shape and the color red in Location 1 can share a common synchrony, which can be labeled Synchrony Correlation a (SCa). If only letter shapes have to be represented and the letters are repeated (b), the four letter shapes can be represented by synchrony in firing of neurons representing shape and location; locations that contain the same shape will have the same SC. However, if (c) the same letter shape appears in different colors in different locations and both colors and shapes need to be represented (a mixed shape-color association), the stimulus is logically impossible to represent. Neural synchrony can represent which shape is in each location, and it can also represent which color is in each location; however, it is impossible to simultaneously synchronize both the colors and the shapes in all their locations.</p>
</caption>
<graphic xlink:href="10.1177_0956797612459761-fig1.tif"/></fig>
<p>According to this theory, there are some situations that are logically impossible to represent. In the case shown in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1c</xref>, there are repeated features, and in addition, both colors and shapes must be specified. As in the example in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1a</xref>, shape and color must be synchronized in each location. However, in this case, features are repeated. As in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1b</xref>, the firing rate associated with the <italic>X</italic> shape can be represented in Locations 1 and 4, and the firing rate associated with the <italic>O</italic> shape can be represented in Locations 2 and 3. However, another option is for the firing rate associated with the color red to be represented in Locations 1 and 3, and the firing rate associated with the color green to be represented in Locations 2 and 4. But, in this example, it is impossible to simultaneously synchronize both the colors and the shapes in all their locations.</p>
<p>Notice that in <xref ref-type="fig" rid="fig1-0956797612459761">Figure 1c</xref>, if the value SCa is associated with the <italic>X</italic> shape and Locations 1 and 4, and the value SCb is associated with the <italic>O</italic> shape and Locations 2 and 3, then the observer can see the string “XOOX.” However, the correct colors of this string cannot be synchronized with their locations at the same time. The first <italic>X</italic> in the string is red; hence, it is clear that the <italic>X</italic> shape needs to be synchronized with the color red. However, if the system tries to synchronize the red with the <italic>X</italic> by giving the color red the value SCa, then the color red will also be “seen” in Location 4, even though the object in this location is green. Hence, in this example, the specific color, shape, and location of each object cannot be simultaneously synchronized. It follows that the system can either know how many <italic>X</italic>s there are or how many reds there are, but it cannot know both at the same time. Does this theoretically assumed difficulty create a real behavioral problem? In the following experiments, we examined this question by comparing the perception of mixed color-shape associations with that of unique color-shape associations.</p>
<sec id="section1-0956797612459761">
<title>Experiment 1</title>
<p>In Experiment 1, we asked participants to compare the numbers of instances in two subsets, each defined by a value on one of two different dimensions: a color or a shape. The participants’ task was to decide if there were more <italic>X</italic>s than red objects, if there were more red objects than <italic>X</italic>s, or if the number of <italic>X</italic>s was equal to the number of red objects. The experiment had two conditions: In one, it was possible to synchronize the relevant features on the two dimensions simultaneously, according to the assumptions we have just described (i.e., there was a unique color-shape association for the relevant features, <italic>X</italic> and red; see <xref ref-type="fig" rid="fig2-0956797612459761">Fig. 2a</xref>). Thus, both the <italic>X</italic>s and the reds could be synchronized with their locations. In the other condition, such synchronization was impossible (i.e., there were mixed color-shape associations for <italic>X</italic> and red; see <xref ref-type="fig" rid="fig2-0956797612459761">Fig. 2b</xref>). We compared both response times (RTs) and error rates in the two conditions.</p>
<fig id="fig2-0956797612459761" position="float">
<label>Fig. 2.</label>
<caption>
<p>Illustration of the two conditions in Experiment 1. In one condition (a), the target feature <italic>X</italic> was uniquely associated with the color green, and the target feature red was uniquely associated with the <italic>O</italic> shape. Therefore, when both <italic>X</italic> and red needed to be represented, two different synchrony correlations (SCa and SCb) could simultaneously indicate the locations in which each target feature appeared. In the other condition (b), the target feature <italic>X</italic> was associated with both red and green, and the target feature red was associated with both <italic>X</italic> and <italic>O</italic> shapes. Therefore, it was not possible to simultaneously synchronize both the color red and the shape <italic>X</italic> in all their locations.</p>
</caption>
<graphic xlink:href="10.1177_0956797612459761-fig2.tif"/></fig>
<sec id="section2-0956797612459761">
<title>Method</title>
<sec id="section3-0956797612459761">
<title>Participants</title>
<p>Eleven undergraduate students from Princeton University participated in the experiment in partial fulfillment of course requirements. All had normal or corrected-to-normal vision.</p>
</sec>
<sec id="section4-0956797612459761">
<title>Stimuli</title>
<p>The stimulus displays consisted of letter strings composed of the letters <italic>X</italic> and <italic>O</italic>, colored in red and green. The size of each letter was approximately 1.2°. Each string of five letters appeared in the center of a white screen. Each feature (<italic>X, O</italic>, red, or green) could appear either two or three times. On some trials, there were more <italic>X</italic>s than reds; on others, there were more reds than <italic>X</italic>s; and on others, there were equal numbers of <italic>X</italic>s and reds. In the unique-association condition, the <italic>X</italic>s and the reds never shared a common location (i.e., all <italic>X</italic>s were green). In the mixed-associations condition, <italic>X</italic> and red co-occurred in at least one location: When there were more <italic>X</italic>s than reds, either one or two of the three <italic>X</italic>s were green; when there were more reds than <italic>X</italic>s, either one or two of the three <italic>O</italic>s were red; and when there were equal numbers of <italic>X</italic>s and reds, one <italic>X</italic> was green. <xref ref-type="fig" rid="fig3-0956797612459761">Figure 3</xref> shows the complete set of stimuli. The order of the letters was randomized in each display.</p>
<fig id="fig3-0956797612459761" position="float">
<label>Fig. 3.</label>
<caption>
<p>The nine sets of stimuli used in Experiment 1. In each of the two conditions (unique association, mixed associations), there were more <italic>X</italic>s than reds on some trials, more reds than <italic>X</italic>s on other trials, and equal numbers of <italic>X</italic>s and reds on still other trials. The order of the objects in the strings (each shape and color combination) was randomized in the actual displays.</p>
</caption>
<graphic xlink:href="10.1177_0956797612459761-fig3.tif"/></fig>
</sec>
<sec id="section5-0956797612459761">
<title>Procedure</title>
<p>Stimulus presentation and data collection were controlled by a Dell computer with an Intel Xeon central processor. Stimuli were presented on a Dell 19-in. monitor. A keyboard was placed on a table between the participants and the monitor, which was approximately 65 cm from where they were seated. Stickers with the labels “same,” “more Xs,” and “more reds” were pasted on the keys “g,” “h,” and “j,” respectively. Participants completed the experiment individually. They were instructed to compare the number of <italic>X</italic>s with the number of red letters, and they were told that the possible responses were “more <italic>X</italic>s,” “more reds,” or “the same.” Participants were asked to respond as fast as possible but to avoid mistakes. Each trial started with a 1,000-ms white display that was followed by a letter string. The letter strings were chosen randomly for each participant from a list in which 50% of the trials had equal numbers of <italic>X</italic>s and reds, 25% had more reds than <italic>X</italic>s, and 25% had more <italic>X</italic>s than reds; half of the trials chosen belonged to the unique-association condition, and half belonged to the mixed-associations condition. The string on each trial disappeared when the participant responded, and then the next trial began. The computer registered the participant’s responses, as well as the RT (in milliseconds) from the onset of each string to the participant’s response.</p>
<p>Before the beginning of the experimental block, participants were given 4 practice trials, regardless of how many errors they made. They then performed a block of 80 experimental trials.</p>
</sec></sec>
<sec id="section6-0956797612459761">
<title>Results and discussion</title>
<p>The overall mean error rate was 0.5% for the unique-association condition and 6.7% for the mixed-associations condition. The difference between conditions was significant, <italic>t</italic>(10) = 3.34, <italic>p</italic> &lt; .01. For the trials responded to correctly, the mean RT was calculated for each participant in each condition. A paired-samples <italic>t</italic> test was applied to these data. Responses to letter strings with unique color-shape associations were significantly faster (2,464 ms) than responses to letter strings with mixed color-shape associations (3,232 ms). This 768-ms effect was significant, <italic>t</italic>(10) = 4.77, <italic>p</italic> &lt; .001.</p>
<p>To sum up, a large effect was observed for both the RT and the error data. Strings that had unique color-shape associations and therefore—according to our assumptions—could be synchronized neurally were counted faster and with fewer errors in comparison with strings that had mixed color-shape associations and therefore—according to our assumptions—could not be simultaneously synchronized.</p>
</sec></sec>
<sec id="section7-0956797612459761">
<title>Experiment 2</title>
<p>In Experiment 1, the strings with mixed color-shape associations (the ones we assumed are impossible to synchronize) were composed of <italic>X</italic>s (the target shape feature) that were printed both in red (the target color feature) and in green. The strings with unique color-shape associations (the ones we assumed are possible to synchronize) were composed of <italic>X</italic>s that were never printed in the target color feature (red). This observation suggests a possible alternative explanation for the relative difficulty participants experienced in responding to the strings with mixed color-shape associations: If the perceptual system has difficulty in identifying or counting two target features when they share the same location, then the same result would be observed regardless of whether the strings theoretically can or cannot be synchronized. Experiment 2 was designed to rule out this shared-location explanation. In this experiment, we added another condition in which all <italic>X</italic>s were printed in red. That is, the two target features always shared the same location. If the shared-location explanation is valid, then participants should have difficulty responding in this condition. However, if our synchrony assumptions are correct, and consistent color-shape associations are therefore represented more easily than mixed color-shape associations, then it should be easy for participants to count features in this condition (because both red and <italic>X</italic> can have the same SC value).</p>
<sec id="section8-0956797612459761">
<title>Method</title>
<p>Stimulus presentation and data collection were controlled by a Dell laptop computer (Latitude D830) with an Intel central processor and 15-in. monitor. The method of Experiment 2 was the same as that of Experiment 1, except for the following changes. In this experiment, three experimental conditions were included: In one condition, the letter strings had mixed color-shape associations (and were impossible to synchronize, according to our assumptions). In the other two conditions, the letter strings had unique color-shape associations (and were possible to synchronize, according to our assumptions). In one of the latter two conditions, the two target features always appeared in different locations, and in the other, the two target features always shared the same locations. The mixed-associations condition was identical to the mixed-associations condition in Experiment 1. The unique-association condition with target features in different locations was identical to the unique-association condition in Experiment 1. The unique-association condition with target features that shared the same locations was not included in Experiment 1. In this condition, the <italic>X</italic>s were always red (e.g., the stimulus “XOXOO,” with the letters printed in red, green, red, green, and green, respectively). Note that in this kind of display, when the number of <italic>X</italic>s is compared with the number of red objects, the correct response can only be “the same.” Hence, in order to compare the three experimental conditions correctly, we analyzed only “the same” responses in the other conditions as well.</p>
<p>Six volunteers, with normal or corrected-to-normal vision, participated in this experiment. The three conditions were randomly mixed, with 20 trials in each conditions. In addition, 20 filler trials in which there were unequal numbers of <italic>X</italic>s and reds were randomly mixed into the sequence of trials.</p>
</sec>
<sec id="section9-0956797612459761">
<title>Results and discussion</title>
<p>For trials on which the correct response was “the same,” the overall mean error rate was 8.4% for the mixed-associations condition, 1.8% for the unique-association condition with target features in different locations, and 0% for the unique-association condition with target features that shared the same locations. For trials responded to correctly, the mean RT was calculated for each participant in each condition. The mean RT across participants was 3,690 ms for the mixed-associations condition, 2,963 ms for the unique-association condition with target features in different locations, and 2,399 ms for the unique-association condition with target features that shared the same locations. A one-way analysis of variance, with condition as a within-participants factor, revealed a significant effect of condition on RT, <italic>F</italic>(2, 10) = 37.95, <italic>MSE</italic> = 66,253, <italic>p</italic> &lt; .001. As in Experiment 1, RT was slower in the mixed-associations condition than in the unique-association condition with target features in different locations, <italic>F</italic>(1, 5) = 19.24, <italic>MSE</italic> = 82,342, <italic>p</italic> &lt; .01. In addition, RT in the unique-association condition with target features that shared the same locations was not slower than RT in the unique-association condition with target features in different locations, but rather was faster, <italic>F</italic>(1, 5) = 50.46, <italic>MSE</italic> = 18,946, <italic>p</italic> &lt; .001. This last result suggests that the findings of Experiment 1 cannot be explained by a difficulty in counting target features that shared the same location. In addition, the finding that RT was slower in the mixed-associations condition than in the unique-association condition with target features in different locations replicated the results from Experiment 1. Thus, our results were again consistent with our prediction that features would be counted faster when the strings’ relevant features had unique associations rather than mixed associations.</p>
</sec></sec>
<sec id="section10-0956797612459761" sec-type="discussion">
<title>General Discussion</title>
<p>The synchrony hypothesis of binding suggests that neurons that code a certain feature fire in synchrony with neurons that code other features of the same object (e.g., <xref ref-type="bibr" rid="bibr2-0956797612459761">Engel &amp; Singer, 2001</xref>; <xref ref-type="bibr" rid="bibr18-0956797612459761">von der Malsburg, 1999</xref>). This hypothesis offers an elegant solution for binding different features together to form a temporary object-file representation. However, in this article, we have directed attention to a certain logical problem that arises when the synchrony assumptions are applied to situations in which the same features are paired differently in different objects. It seems that this logical problem results in a genuine behavioral problem.</p>
<p>In two experiments, we asked participants to compare the number of <italic>X</italic>s with the number of red objects in each of a series of displays. Given that each feature appeared only two or three times in each display, this task was not arithmetically demanding. Although the required level of computation remained the same in all the experimental conditions, the stimuli that the perceptual system had to represent were manipulated. These stimuli, according to our assumptions, either allowed synchronization of features within the object files (i.e., when the objects in the strings had unique color-shape associations) or did not allow synchronization (i.e., when the objects in the strings had mixed color-shape associations). The results revealed that when the strings had mixed color-shape associations (and were therefore theoretically impossible to synchronize), participants had behavioral difficulties in counting the features.</p>
<p>This study demonstrates a new behavioral principle that governs object representation. When shapes are repeated in several locations and have mixed color-shape associations, they are hard to perceive. In addition, we suggest that the findings might offer unique behavioral evidence for a neural-based theory of feature binding. According to the assumptions of the neural-synchrony hypothesis, letter strings with mixed color-shape associations should be impossible to synchronize simultaneously. The behavioral difficulty our participants demonstrated in the mixed-associations condition fits with this prediction.</p>
<p>Although the findings fit nicely with our assumptions, we should consider whether they could also be explained by some other hypothesis that does not involve neural synchrony. Because none of the alternative theories directly predict the behavioral effect we observed, new assumptions must be added to them in order for them to accommodate these results. For example, it has been suggested that bound objects could be represented in a topographical saliency map (e.g., <xref ref-type="bibr" rid="bibr7-0956797612459761">Koch &amp; Ullman, 1985</xref>). According to this theory, a location becomes more salient the fewer features it shares with other locations; the more salient a location is, the more it “earns” priority in processing. In the experiments reported in this article, all the features were repeated, so it is not clear that there would be any differences in salience across locations. Although it is possible that the conflict reflected in this new effect results from conflict in a saliency map, this result is not directly predicted by this alternative theory.</p>
<p>Note that although participants demonstrated difficulty in counting features in strings that were theoretically impossible to synchronize, they were able to count the features eventually. Our hypothesis is that strings that are impossible to synchronize simultaneously can nevertheless be synchronized for one feature after another. In each new synchrony, new object files must be created, and this might explain the RT cost that we observed in this study.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p></fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research was supported by fellowships from the Israel Science Foundation (Bikura), the Rothschild Foundation, and the Advancing Women in Science program of the Weizmann Institute of Science (L. G.) and by Grants 2004 2RO1 MH 058383-04A1 and EY016975 from the National Institutes of Health (A. T.).</p></fn>
</fn-group>
<notes><fn-group>
<fn fn-type="other" id="fn1-0956797612459761">
<label>1.</label>
<p>Note that when two or more objects share the same location, the different locations must be more finely specified by following the continuity of contours within each object.</p></fn>
</fn-group></notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dehaene</surname><given-names>S.</given-names></name>
<name><surname>Piazza</surname><given-names>M.</given-names></name>
<name><surname>Pinel</surname><given-names>P.</given-names></name>
<name><surname>Cohen</surname><given-names>L.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Three parietal circuits for number processing</article-title>. <source>Cognitive Neuropsychology</source>, <volume>20</volume>, <fpage>487</fpage>–<lpage>506</lpage>.</citation>
</ref>
<ref id="bibr2-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Engel</surname><given-names>A. K.</given-names></name>
<name><surname>Singer</surname><given-names>W.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Temporal binding and the neural correlates of sensory awareness</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>5</volume>, <fpage>16</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr3-0956797612459761">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Goldfarb</surname><given-names>L.</given-names></name>
<name><surname>Treisman</surname><given-names>A.</given-names></name>
</person-group> (<year>2012</year>). <source>Object files, binding errors and number perception: A theory of subset counting and failures of independence in human perception</source>. Manuscript submitted for publication.</citation>
</ref>
<ref id="bibr4-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Halberda</surname><given-names>J.</given-names></name>
<name><surname>Mazzocco</surname><given-names>M. M.</given-names></name>
<name><surname>Feigenson</surname><given-names>L.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Individual differences in non-verbal number acuity correlate with maths achievement</article-title>. <source>Nature</source>, <volume>455</volume>, <fpage>665</fpage>–<lpage>668</lpage>.</citation>
</ref>
<ref id="bibr5-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hommel</surname><given-names>B.</given-names></name>
<name><surname>Colzato</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>When an object is more than a binding of its features: Evidence for two mechanisms of visual feature integration</article-title>. <source>Visual Cognition</source>, <volume>17</volume>, <fpage>120</fpage>–<lpage>140</lpage>.</citation>
</ref>
<ref id="bibr6-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kahneman</surname><given-names>D.</given-names></name>
<name><surname>Treisman</surname><given-names>A.</given-names></name>
<name><surname>Gibbs</surname><given-names>B.</given-names></name>
</person-group> (<year>1992</year>). <article-title>The reviewing of object files: Object-specific integration of information</article-title>. <source>Cognitive Psychology</source>, <volume>24</volume>, <fpage>175</fpage>–<lpage>219</lpage>.</citation>
</ref>
<ref id="bibr7-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Koch</surname><given-names>C.</given-names></name>
<name><surname>Ullman</surname><given-names>S.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Shifts in selective visual attention: Towards the underlying neural circuitry</article-title>. <source>Human Neurobiology</source>, <volume>4</volume>, <fpage>219</fpage>–<lpage>227</lpage>.</citation>
</ref>
<ref id="bibr8-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lamme</surname><given-names>V. A. F.</given-names></name>
<name><surname>Spekreijse</surname><given-names>H.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Neuronal synchrony does not represent texture segregation</article-title>. <source>Nature</source>, <volume>396</volume>, <fpage>362</fpage>–<lpage>366</lpage>.</citation>
</ref>
<ref id="bibr9-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McComb</surname><given-names>K. E.</given-names></name>
<name><surname>Packer</surname><given-names>C.</given-names></name>
<name><surname>Pusey</surname><given-names>A. E.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Roaring and numerical assessment in contests between groups of female lions</article-title>, <source>Panthera leo. Animal Behaviour</source>, <volume>47</volume>, <fpage>379</fpage>–<lpage>387</lpage>.</citation>
</ref>
<ref id="bibr10-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Piazza</surname><given-names>M.</given-names></name>
<name><surname>Izard</surname><given-names>V.</given-names></name>
<name><surname>Pinel</surname><given-names>P.</given-names></name>
<name><surname>Le Bihan</surname><given-names>D.</given-names></name>
<name><surname>Dehaene</surname><given-names>S.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Tuning curves for approximate numerosity in the human intraparietal sulcus</article-title>. <source>Neuron</source>, <volume>44</volume>, <fpage>547</fpage>–<lpage>555</lpage>.</citation>
</ref>
<ref id="bibr11-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Piazza</surname><given-names>M.</given-names></name>
<name><surname>Pinel</surname><given-names>P.</given-names></name>
<name><surname>Le Bihan</surname><given-names>D.</given-names></name>
<name><surname>Dehaene</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A magnitude code common to numerosities and number symbols in human intraparietal cortex</article-title>. <source>Neuron</source>, <volume>53</volume>, <fpage>293</fpage>–<lpage>305</lpage>.</citation>
</ref>
<ref id="bibr12-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Raffone</surname><given-names>A.</given-names></name>
<name><surname>Wolters</surname><given-names>G.</given-names></name>
</person-group> (<year>2001</year>). <article-title>A cortical mechanism for binding in visual working memory</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>13</volume>, <fpage>766</fpage>–<lpage>785</lpage>.</citation>
</ref>
<ref id="bibr13-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shadlen</surname><given-names>M. N.</given-names></name>
<name><surname>Movshon</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Synchrony unbound: A critical evaluation of the temporal binding hypothesis</article-title>. <source>Neuron</source>, <volume>24</volume>, <fpage>67</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr14-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Treisman</surname><given-names>A.</given-names></name>
</person-group> (<year>2006</year>). <article-title>How the deployment of attention determines what we see</article-title>. <source>Visual Cognition</source>, <volume>14</volume>, <fpage>411</fpage>–<lpage>443</lpage>.</citation>
</ref>
<ref id="bibr15-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Treisman</surname><given-names>A.</given-names></name>
<name><surname>Gelade</surname><given-names>G.</given-names></name>
</person-group> (<year>1980</year>). <article-title>A feature integration theory of attention</article-title>. <source>Cognitive Psychology</source>, <volume>12</volume>, <fpage>97</fpage>–<lpage>136</lpage>.</citation>
</ref>
<ref id="bibr16-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Treisman</surname><given-names>A.</given-names></name>
<name><surname>Schmidt</surname><given-names>H.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Illusory conjunctions in the perception of objects</article-title>. <source>Cognitive Psychology</source>, <volume>14</volume>, <fpage>107</fpage>–<lpage>141</lpage>.</citation>
</ref>
<ref id="bibr17-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vogel</surname><given-names>E. K.</given-names></name>
<name><surname>Woodman</surname><given-names>G. F.</given-names></name>
<name><surname>Luck</surname><given-names>S. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Storage of features, conjunctions, and objects in visual working memory</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>27</volume>, <fpage>92</fpage>–<lpage>114</lpage>.</citation>
</ref>
<ref id="bibr18-0956797612459761">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>von der Malsburg</surname><given-names>C.</given-names></name>
</person-group> (<year>1999</year>). <article-title>The what and why of binding: The modeler’s perspective</article-title>. <source>Neuron</source>, <volume>24</volume>, <fpage>95</fpage>–<lpage>104</lpage>.</citation>
</ref></ref-list>
</back>
</article>