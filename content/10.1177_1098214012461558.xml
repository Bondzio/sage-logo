<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AJE</journal-id>
<journal-id journal-id-type="hwp">spaje</journal-id>
<journal-title>American Journal of Evaluation</journal-title>
<issn pub-type="ppub">1098-2140</issn>
<issn pub-type="epub">1557-0878</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1098214012461558</article-id>
<article-id pub-id-type="publisher-id">10.1177_1098214012461558</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Nature and Frequency of Inclusion of People with Disabilities in Program Evaluation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Jacobson</surname>
<given-names>Miriam R.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1098214012461558">1</xref>
<xref ref-type="corresp" rid="corresp1-1098214012461558"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Azzam</surname>
<given-names>Tarek</given-names>
</name>
<xref ref-type="aff" rid="aff1-1098214012461558">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Baez</surname>
<given-names>Jeanette G.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1098214012461558">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1098214012461558">
<label>1</label>Claremont Graduate University, Claremont, CA, USA</aff>
<author-notes>
<corresp id="corresp1-1098214012461558">Miriam R. Jacobson, Claremont Graduate University, 123 East 8th Street, Claremont, CA 91711, USA. Email: <email>jacobson.miriam@gmail.com</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>34</volume>
<issue>1</issue>
<fpage>23</fpage>
<lpage>44</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">American Evaluation Association</copyright-holder>
</permissions>
<abstract>
<p>Although evaluation theorists over the last two decades have argued for the importance of including stakeholders from marginalized groups in program planning and research, little is known about the degree of inclusion in program evaluation practice. In particular, we know little about the type and level of inclusion of people with intellectual, developmental, and psychiatric disabilities in the evaluation of programs that aim to serve them. Through a content analysis of articles published in the last decade describing evaluations of programs for people with these types of disabilities, this article describes which stakeholders have been included in evaluations, how program recipient input was obtained, and in which stages of the evaluation stakeholder participation occurred. The findings indicate that program recipient disability type (developmental, psychiatric, or other) may predict type and level of inclusion, and inclusion tends to occur in later parts of the evaluation process.</p>
</abstract>
<kwd-group>
<kwd>evaluation inclusion</kwd>
<kwd>disabilities</kwd>
<kwd>stakeholder involvement</kwd>
<kwd>data collection</kwd>
<kwd>evaluation practice</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Inclusion of different stakeholders has long been an important consideration of evaluation practice. It is prescribed in many evaluation theories, including democratic, participatory, and empowerment evaluation (<xref ref-type="bibr" rid="bibr20-1098214012461558">Christie, 2003</xref>) and can range from obtaining stakeholder input on a program, to employing their assistance in data collection, to having them actively collaborate in the evaluation design and interpretation of results (<xref ref-type="bibr" rid="bibr46-1098214012461558">Mertens, 1999</xref>). Stakeholder inclusion can increase the likelihood of use (<xref ref-type="bibr" rid="bibr32-1098214012461558">Fleischer &amp; Christie, 2009</xref>; <xref ref-type="bibr" rid="bibr54-1098214012461558">Toal, 2009</xref>), relevancy of the evaluation to the community of interest, and accuracy of results (<xref ref-type="bibr" rid="bibr12-1098214012461558">Botcheva, Shih, &amp; Huffman, 2009</xref>; <xref ref-type="bibr" rid="bibr13-1098214012461558">Brandon, 1998</xref>; <xref ref-type="bibr" rid="bibr19-1098214012461558">Chouinard &amp; Cousins, 2009</xref>). Inclusion may also promote social justice by giving recipients a voice in program decision making (<xref ref-type="bibr" rid="bibr46-1098214012461558">Mertens, 1999</xref>).</p>
<p>The importance of inclusion is reiterated by the Joint Committee on Standards for Educational Evaluation, a network of professional organizations focused on the quality of evaluation practice. In particular, the standards of <italic>attention to stakeholders</italic> and <italic>responsive and inclusive practice </italic>(<xref ref-type="bibr" rid="bibr60-1098214012461558">Yarbrough, Shulha, Hopson, &amp; Caruthers, 2011</xref>) clearly emphasize this point. Although stakeholder inclusion can support other evaluation standards such as <italic>utility</italic> and <italic>accuracy</italic>, a significant focus on inclusion can also compromise standards such as <italic>feasibility</italic>—for example if a high level of inclusion is costly for stakeholders or disruptive to the program (<xref ref-type="bibr" rid="bibr60-1098214012461558">Yarbrough et al., 2011</xref>). In such cases, the evaluator may be required to make a choice of which standard to emphasize (Taut, 2008; <xref ref-type="bibr" rid="bibr60-1098214012461558">Yarbrough et al., 2011</xref>). Therefore, even though inclusion is widely advocated, it may sometimes be unfeasible in practice. In an attempt to understand this struggle, this study examines how evaluators deal with potentially disparate demands when working with stakeholders who have developmental, psychiatric, or other forms of disabilities.</p>
<sec id="section1-1098214012461558">
<title>Inclusion and People With Disabilities: Historical Overview</title>
<p>A disability is a physical or mental impairment that substantially limits one or more major life activities (<xref ref-type="bibr" rid="bibr6-1098214012461558">Americans with Disabilities Act, 1990</xref>). Although disabilities can take numerous forms, of greatest relevance to this discussion and study are developmental, intellectual, and psychiatric disabilities (<xref ref-type="table" rid="table1-1098214012461558">Table 1</xref>), each of which presents unique challenges design and administer service programs and to those who wish to conduct meaningful, useful evaluations of those programs.</p>
<table-wrap id="table1-1098214012461558" position="float">
<label>Table 1.</label>
<caption>
<p>Definitions of Disability Types.</p>
</caption>
<graphic alternate-form-of="table1-1098214012461558" xlink:href="10.1177_1098214012461558-table1.tif"/>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>Disability </td>
<td>A disability is a physical or mental impairment that substantially limits one or more major life activities (<xref ref-type="bibr" rid="bibr6-1098214012461558">Americans with Disabilities Act, 1990</xref>)</td>
</tr>
<tr>
<td>Developmental disability</td>
<td>A developmental disability is a severe, chronic disability of an individual that is attributable to a mental or physical impairment or combination of mental and physical impairments, is manifested before the individual attains age 22, and is likely to continue indefinitely (<xref ref-type="bibr" rid="bibr27-1098214012461558">The Developmental Disabilities Assistance and Bill of Rights Act of 2000</xref>). Some examples are autism, cerebral palsy, and Down syndrome</td>
</tr>
<tr>
<td>Intellectual disability</td>
<td>Intellectual disability is characterized by significant limitations in both intellectual functioning and adaptive behavior, which covers many everyday social and practical skills. This disability originates before the age of 18 (<xref ref-type="bibr" rid="bibr5-1098214012461558">American Association on Intellectual and Developmental Disabilities, 2011</xref>). This type of disability was previously referred to as “mental retardation.” It can be considered one disability within the broader category of developmental disabilities</td>
</tr>
<tr>
<td>Psychiatric disability </td>
<td>A mental or psychological disorder that substantially limits one or more major life activities (<xref ref-type="bibr" rid="bibr28-1098214012461558">Equal Employment Opportunity Commission, 1997</xref>)</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>In the past, evaluators and program staff would often define the interests of program recipients with disabilities by making their own assumptions about the ideal quality of life, and therefore would fail to collect data on issues important to these individuals (<xref ref-type="bibr" rid="bibr15-1098214012461558">Cambell, 1997</xref>; <xref ref-type="bibr" rid="bibr43-1098214012461558">Kiernan, 1999</xref>; <xref ref-type="bibr" rid="bibr46-1098214012461558">Mertens, 1999</xref>). Researchers also tended to overlook the influence of varying cultural and contextual factors on individuals (<xref ref-type="bibr" rid="bibr35-1098214012461558">Harry, 2002</xref>). <xref ref-type="bibr" rid="bibr47-1098214012461558">Mertens (2007a)</xref> refers to this latter issue as the myth of homogeneity, which occurs when a cultural outsider assumes that all members of the cultural group are the same as one another.</p>
<p>Since then, there have been dramatic increases in the rights of individuals with disabilities and more opportunities for participation in research. In the late 1980s, there was a rising movement to include people with disabilities in research and evaluation (<xref ref-type="bibr" rid="bibr8-1098214012461558">Barnes, 2003</xref>; <xref ref-type="bibr" rid="bibr17-1098214012461558">Chappell, 2000</xref>; <xref ref-type="bibr" rid="bibr56-1098214012461558">Walmsley &amp; Johnson, 2003</xref>). Members of the disabilities rights movement have called for people with disabilities to have a voice in decisions about their programs and services, as reflected in the slogan “Nothing About Us Without Us.” In 1992, a group of researchers with disabilities pushed for an emancipatory model of disability research, whereby people with disabilities are in control of the research process, as lead researchers (<xref ref-type="bibr" rid="bibr8-1098214012461558">Barnes, 2003</xref>). They argued that putting people with disabilities in control of research is necessary to shift the research perspective from the medical model (disability arises from problem with the individual) to the social model, whereby disability arises from a problem in society.</p>
<p>These demands for inclusion led to numerous changes in policy and practice (<xref ref-type="bibr" rid="bibr8-1098214012461558">Barnes, 2003</xref>). Increasingly, there were examples of participation of people with disabilities in research and evaluation, and disabilities research funders began requiring participation of people with disabilities in conducting the research (<xref ref-type="bibr" rid="bibr56-1098214012461558">Walmsley &amp; Johnson, 2003</xref>). In 2000, federal legislation called for involvement of all people with developmental disabilities in the planning of their own programs and services (<xref ref-type="bibr" rid="bibr27-1098214012461558">Developmental Disabilities Assistance and Bill of Rights Act, 2000</xref>). People with disabilities have now come to occupy places of influence in the research process and on organizational committees (<xref ref-type="bibr" rid="bibr14-1098214012461558">Caldwell, Hauss, &amp; Stark, 2009</xref>; <xref ref-type="bibr" rid="bibr15-1098214012461558">Cambell, 1997</xref>). While these trends in research and program development have been well documented in the literature, it remains unclear just how evaluation practice as a whole has addressed the issue of inclusion for people with disabilities.</p>
</sec>
<sec id="section2-1098214012461558">
<title>Challenges to Evaluation Inclusion</title>
<p>In nearly any evaluation context, special consideration should be given to linguistic, cognitive, and cultural diversity. This need becomes especially great when individuals with disabilities are participating in the data collection. Within a given group of people, one might encounter a wide range of cognitive abilities or preferences for how to communicate. People with disabilities may prefer to communicate nonverbally or through writing; they may process information or conceptualize words differently. In some cases, words and concepts that make sense to researchers may be misleading or confusing to participants. Data collection procedures must recognize such characteristics to promote the collection of accurate data.</p>
<p>Researchers have discussed the need for careful procedures to collect data from individuals with intellectual or developmental disabilities (<xref ref-type="bibr" rid="bibr57-1098214012461558">Ware, 2004</xref>). These disabilities represent a vast range of functionalities. Many of these individuals have limitations in speech, oral comprehension, or cognition. In addition, some may have great strengths in one of these areas (such as oral comprehension) while having limitations in another (such as speech), making it difficult for an evaluator to design procedures that fit all potential participants.</p>
<p>Importantly, researchers should be aware that obtaining a response from an interviewee does not necessarily mean that he or she understands what is being asked. Participants might acquiesce in surveys not just out of a need to please but also because they have difficulty understanding the questions (<xref ref-type="bibr" rid="bibr29-1098214012461558">Finlay &amp; Lyons, 2001</xref>). One study examined response bias in self-reports among a sample of people with intellectual disabilities in staffed housing. Researchers used items from quality of life measures specifically designed to identify when respondents were exhibiting acquiescence and recency bias, for example, by asking the same question twice in a slightly a different way. The study found that two thirds either demonstrated at least one of these types of response bias or did not respond with relevant answers (<xref ref-type="bibr" rid="bibr49-1098214012461558">Perry &amp; Felce, 2002</xref>).</p>
<p>Researchers have raised concerns about gathering accurate data from those with psychiatric disabilities as well. In particular, some researchers are concerned that associated cognitive impairments or psychiatric symptoms can affect a person’s insight into his or her best interests or ability to self-report on outcomes such as quality of life. While many tools exist to measure psychopathology, fewer are available to measure recipient viewpoints on topics such as program satisfaction (<xref ref-type="bibr" rid="bibr15-1098214012461558">Cambell, 1997</xref>). In addition, some people with certain psychiatric disorders, such as bipolar disorder or schizophrenia, demonstrate impairments in verbal and nonverbal communication (such as incoherent speech or flat facial expressions) as part of their conditions. In such cases, data collection procedures need to adapt for these circumstances (<xref ref-type="bibr" rid="bibr26-1098214012461558">Dadich &amp; Muir, 2009</xref>; <xref ref-type="bibr" rid="bibr36-1098214012461558">Harvey, Wingo, Burdick, &amp; Baldessarini, 2010</xref>).</p>
</sec>
<sec id="section3-1098214012461558">
<title>Strategies for Inclusion</title>
<p>When the reliability of recipient self-report is in doubt, researchers suggest that data be obtained from multiple sources, such as parents and clients, and, if possible, from other sources of evidence—for example, medical records—as well (<xref ref-type="bibr" rid="bibr10-1098214012461558">Boland, Daly, &amp; Staines, 2008</xref>). Simply using a proxy report alone (having a parent or someone close to the person answering on his or her behalf) is not always sufficient. The reliability of proxy reports has been mixed, and for individuals without a certain level of expressive communication, the accuracy of the proxy can never truly be determined (<xref ref-type="bibr" rid="bibr49-1098214012461558">Perry &amp; Felce, 2002</xref>; <xref ref-type="bibr" rid="bibr53-1098214012461558">Stancliffe, 2000</xref>). Researchers have tended to believe that the degree to which a proxy can answer meaningfully for the research participant depends on the type of information involved and the proxy’s relationship to the participant (<xref ref-type="bibr" rid="bibr53-1098214012461558">Stancliffe, 2000</xref>). To address this issue, some evaluations may use two or more proxy reports to better estimate the actual viewpoint of the participant (<xref ref-type="bibr" rid="bibr11-1098214012461558">Bonham et al., 2004</xref>).</p>
<p>The <italic>Ask Me!</italic> Project, conducted for the Maryland Developmental Disabilities Administration, published articles on how to gather reliable information from people with a wide range of developmental disabilities. They found that when severe communication difficulties are present, adapting strategies to each individual allowed them to obtain accurate interview data from most but not all of their clients. Techniques such as limiting response options to two or three choices as well as using simple language and providing multiple ways to perceive questions and provide answers can facilitate communication with a range of participants. These procedures can entail providing pictures with response options, and allowing respondents to speak, point, or gesture answer choices, or to use a translator when necessary (<xref ref-type="bibr" rid="bibr11-1098214012461558">Bonham et al., 2004</xref>). </p>
<p>In recent years, a variety of self-report instruments and interview protocols have been developed to support data collection from people with disabilities. Instruments like the ARC Self-Determination scale are now available to assess constructs such as quality of life, self-determination, or health attitudes directly from the individuals themselves. Designers of these instruments recommend providing assistance to respondents as needed in order to ensure that the measures can be used with participants with a wide range of functionality (<xref ref-type="bibr" rid="bibr58-1098214012461558">Wehmeyer, 1995</xref>). Applied researchers have also developed alternative data collection approaches that may hold advantages over structured interviews and surveys. For example, the researcher may obtain accounts of participants’ experiences in their own words through personal narratives. Another technique is PhotoVoice, in which photographs are taken by participants and discussed in interviews (<xref ref-type="bibr" rid="bibr40-1098214012461558">Jurkowski &amp; Ferguson, 2008</xref>). These open-ended techniques tend to increase participation and are especially useful in answering certain types of research questions. Overall, the increasing availability of validated, structured research tools has potentially encouraged more researchers and evaluators to include people with disabilities in their study designs.</p>
<p>When diversity is present among recipients, appropriately including all people with disabilities within a program can sometimes require greater resources—in the form of trained staff, sources of evidence, and overall time investment—than would otherwise be necessary (<xref ref-type="bibr" rid="bibr9-1098214012461558">Birman, 2007</xref>). For instance, <xref ref-type="bibr" rid="bibr7-1098214012461558">Balch and Mertens (1999)</xref> described a series of focus groups they conducted to understand the experience of deaf individuals in the court system. They included people from different cities who were American Sign Language speakers, Mexican Sign Language speakers, and hard-of-hearing adults with cochlear implants or hearing aids. To include these diverse participants, their project required a range of specialized staff including multiple types of interpreters to accommodate the various languages, appropriate settings to conduct the evaluation, and a court reporter to provide live transcriptions of the discussions that were displayed for focus group members. These added expenses can be prohibitive in many small- or medium-scale evaluation projects and need to be considered when designing an evaluation and figuring its budget.</p>
<sec id="section4-1098214012461558">
<title>Deeper Participation in the Evaluation Process</title>
<p>It is important not only to collect input from recipients but also to involve them more deeply in conducting evaluations of their programs. <xref ref-type="bibr" rid="bibr46-1098214012461558">Mertens (1999)</xref> notes that in the initial stages of an evaluation, it is important to prioritize questions and issues that are directly relevant to community interests. Similarly, criteria for program success and definition of constructs should match those held by the community. Mertens argues that evaluators and those who typically make evaluation decisions remain highly influenced by their own biases and interests, even if they are committed to producing the best potential outcomes for recipients. This bias is of concern for people with disabilities who have been traditionally left out of the program decision-making process. <xref ref-type="bibr" rid="bibr46-1098214012461558">Mertens (1999</xref>, <xref ref-type="bibr" rid="bibr48-1098214012461558">2007b</xref>), who advocates the use of a transformative evaluation approach, argues that people with disabilities should be included as active collaborators throughout the evaluation; program recipients should have meaningful input in identifying evaluation questions, developing measurement procedures, and interpreting results. By taking on a larger role in the evaluation, people with disabilities can influence the project, and simultaneously become empowered to initiate community change in the future (<xref ref-type="bibr" rid="bibr47-1098214012461558">Mertens, 2007a</xref>).</p>
<p>Although many argue that the use of participatory approaches can be beneficial for people with disabilities (<xref ref-type="bibr" rid="bibr22-1098214012461558">Conder, Milner, &amp; Mirfin-Veitch, 2011</xref>; Smith &amp; O'Flynn, 2000), including participants improperly could create unrealistic expectations and potentially cause more harm than good. Former participants in research have spoken of incidents in which researchers promised collaboration but failed to deliver on the promises, compensate them for their assistance, or share the research results (<xref ref-type="bibr" rid="bibr34-1098214012461558">Gill, 1999</xref>; <xref ref-type="bibr" rid="bibr39-1098214012461558">Heller, Pederson, &amp; Miller, 1996</xref>). <xref ref-type="bibr" rid="bibr39-1098214012461558">Heller and colleagues (1996)</xref> conducted a focus group of people with intellectual disabilities who had been involved in research and found that the majority of them noted barriers to participation. These barriers included a lack of training in research ideas and procedures, a failure to be respected or listened to, logistical difficulties, and a lack of personal support. Other difficulties that have been reported in participatory evaluations include unclear roles, ethical concerns, and skills disparities between participants and what is needed for research involvement (<xref ref-type="bibr" rid="bibr52-1098214012461558">Smith &amp; O’Flynn, 2000</xref>). Researchers have commented that even if people are given a high degree of responsibility, inevitable power differences remain between researchers and stakeholders (<xref ref-type="bibr" rid="bibr52-1098214012461558">Smith &amp; O’Flynn, 2000</xref>).</p>
<p>Case examples have provided some guidance on how to optimize stakeholder inclusion. Collaboration has been more successful when research roles are clearly defined, and when stakeholders are involved early in the planning stages, are kept informed of important aspects of the project, and are provided proper training and support (<xref ref-type="bibr" rid="bibr2-1098214012461558">Abma, Nierse, &amp; Widdershoven, 2009</xref>; <xref ref-type="bibr" rid="bibr11-1098214012461558">Bonham et al., 2004</xref>; <xref ref-type="bibr" rid="bibr22-1098214012461558">Conder et al., 2011</xref>; <xref ref-type="bibr" rid="bibr33-1098214012461558">Gilbert, 2004</xref>; <xref ref-type="bibr" rid="bibr42-1098214012461558">Linhorst &amp; Eckert, 2002</xref>; Smith &amp; O'Flynn, 2000; <xref ref-type="bibr" rid="bibr55-1098214012461558">Walmsley, 2004</xref>). To promote an environment of mutual learning and respect, it is helpful for team members to regularly reflect on power dynamics, provide frequent opportunities for informal discussions about the project, and have more than one person with disabilities on the team (<xref ref-type="bibr" rid="bibr2-1098214012461558">Abma et al., 2009</xref>; <xref ref-type="bibr" rid="bibr22-1098214012461558">Conder et al., 2011</xref>). </p>
<p>As with putting together any evaluation team, it is important to assess and consider individual strengths (e.g., interpersonal or analytical skills) or interests when selecting potential collaborators for specific roles (<xref ref-type="bibr" rid="bibr33-1098214012461558">Gilbert, 2004</xref>; <xref ref-type="bibr" rid="bibr55-1098214012461558">Walmsley, 2004</xref>). At the beginning and throughout the evaluation, evaluators should think through what additional resources and flexibility might be needed in the budget, timeline, and staffing and plan accordingly (<xref ref-type="bibr" rid="bibr22-1098214012461558">Conder et al., 2011</xref>; <xref ref-type="bibr" rid="bibr37-1098214012461558">Hassouneh, Alcala-Moss, &amp; McNeff, 2011</xref>). This includes accounting for all reasonable accommodations for participants such as adapting communication mechanisms, providing for transportation needs and planning regular breaks during trainings (<xref ref-type="bibr" rid="bibr37-1098214012461558">Hassouneh et al., 2011</xref>; Read &amp; Maslin-Prothero, 2012).</p>
<p>It is important to note that even when research collaboration is done conscientiously, it may not be desirable or appropriate for all stakeholders. For example, some individuals may not wish to devote the time required to participate (<xref ref-type="bibr" rid="bibr18-1098214012461558">Chen, Poland, &amp; Skinner, 2007</xref>). For some individuals with psychiatric disabilities, there may also be the potential for increase in psychiatric symptoms with the added stress of the project (<xref ref-type="bibr" rid="bibr42-1098214012461558">Linhorst &amp; Eckert, 2002</xref>). It is also possible that those from the community who are thought to be most capable of being active collaborators in the research procedures may not necessarily be representative of the target population (<xref ref-type="bibr" rid="bibr39-1098214012461558">Heller et al., 1996</xref>; <xref ref-type="bibr" rid="bibr52-1098214012461558">Smith &amp; O’Flynn, 2000</xref>; <xref ref-type="bibr" rid="bibr55-1098214012461558">Walmsley, 2004</xref>). All of these issues must be considered as the evaluation is both designed and carried out.</p>
</sec>
</sec>
<sec id="section5-1098214012461558">
<title>The Inclusion Model</title>
<p>
<xref ref-type="fig" rid="fig1-1098214012461558">Figure 1</xref> provides a conceptual model of inclusion of recipients with disabilities that integrates the research and evaluation literature used to frame this study. This model describes the various factors that can inform evaluators’ perceptions of the benefits and feasibility of inclusion. The model takes into account the factors that influence the <italic>Perceived Feasibility</italic> of inclusion, which can include the availability of adequate tools, resources, evaluator training, participant characteristics, and program context. These feasibility issues are then weighed against the <italic>Perceived Benefits</italic> of inclusion, which can be influenced by evaluators’ support of inclusive and transformative evaluation approaches (<xref ref-type="bibr" rid="bibr4-1098214012461558">Azzam, 2011</xref>; <xref ref-type="bibr" rid="bibr20-1098214012461558">Christie, 2003</xref>), the needs of the program context (e.g., in certain programs inclusion might be particularly beneficial, such as programs where recipients typically do not have a voice), and the overarching goals of the evaluation.</p>
<fig id="fig1-1098214012461558" position="float">
<label>Figure 1.</label>
<caption>
<p>Conceptual model of inclusion of people with disabilities in evaluation.</p>
</caption>
<graphic xlink:href="10.1177_1098214012461558-fig1.tif"/>
</fig>
<p>
<italic>Feasibility</italic> and <italic>Benefits</italic> considerations are used in deciding the <italic>Level of Inclusion</italic>. If perceived benefits are high, evaluators may be convinced that inclusion is worth investing in, even if it is perceived to be very costly. Alternatively, if few meaningful benefits are expected, evaluators may be reluctant to devote even a small portion of extra evaluation resources to include recipients. </p>
<p>The model also highlights the importance of the <italic>Quality of Inclusion</italic> and argues that the benefits of inclusion, such as increasing accuracy of findings or recipient empowerment, are derived from high quality and meaningful inclusive practices. For example, methods of collecting data should provide appropriate accommodations for recipients’ needs. Efforts to gather multiple perspectives should be conducted to avoid misconstruing recipients’ viewpoints or provide misleading information. Evaluators must also respect the individuals who participate by providing proper training and appropriate compensation for their time. Otherwise, recipients might feel even further disenfranchised by the program and the evaluation process.</p>
<p>This model was developed specifically to understand how evaluators can reconcile the benefits and feasibility concerns when choosing the level of inclusion. Through review of the literature on transformative evaluation approaches, research methodology, and disability research, five factors underlying perceived feasibility and three factors underlying perceived benefits were identified. Examination of cases of recipient participation and data collection strategies highlighted the need for high quality practices to achieve the desired benefits of inclusion.</p>
<p>This study examines specific elements of this model—those highlighted in gray in <xref ref-type="fig" rid="fig1-1098214012461558">Figure 1</xref>—to provide additional insights on the interactions between <italic>Feasibility</italic> and <italic>Level of Inclusion</italic> levels by describing the frequency with which inclusion occurs and the contextual factors surrounding it. </p>
<p>The choice to focus on “feasibility” was primarily to assess whether having either a psychiatric, developmental, or other type of disability will meaningfully reduce the likelihood of inclusion in the evaluation process. While the model describes multiple factors underlying feasibility, the role of recipient characteristics and program contexts are the least understood and, it could be argued, the most relevant. Understanding the role that program context and recipient characteristics have on feasibility could inform evaluators about the level of inclusion that has been achieved in similar projects and what they can expect when planning their own evaluations. It could also inform efforts to further increase inclusion in areas where it is presently perceived to be less feasible. Many case examples have described the need for additional resources in participatory projects, suggesting that disability type may negatively impact the level of inclusion (<xref ref-type="bibr" rid="bibr22-1098214012461558">Conder et al., 2011</xref>; <xref ref-type="bibr" rid="bibr37-1098214012461558">Hassouneh et al., 2011</xref>). However, case descriptions have not enabled feasibility comparisons across different program contexts, or across recipients of different ages or disability types. It is possible that with increases in the availability of inclusive strategies and data collections tools starting in the 1990s, and changes in researcher/evaluator attitudes, inclusion, is now more feasible across multiple disability groups and contexts (<xref ref-type="bibr" rid="bibr8-1098214012461558">Barnes, 2003</xref>; <xref ref-type="bibr" rid="bibr17-1098214012461558">Chappell, 2000</xref>; <xref ref-type="bibr" rid="bibr45-1098214012461558">Mcdonald, Keys, &amp; Henry, 2008</xref>; <xref ref-type="bibr" rid="bibr56-1098214012461558">Walmsley &amp; Johnson, 2003</xref>).</p>
<p>Specific contextual and recipient variables were selected of study because of their relevance to inclusive practices. However, a couple of potentially pertinent variables (e.g., scope of budget) were not included because they were not consistently present in the evaluation descriptions in most of the articles used in this study. This study also uses the information gathered on these elements to further refine the model’s development, and highlight common methodologies and approaches that evaluators utilize when including individuals with disability in their work.</p>
<sec id="section6-1098214012461558">
<title>Research Questions</title>
<p>Because theorists assert the importance of inclusion of stakeholders, especially those from marginalized groups, it is important that we understand the degree to which principles of inclusion are actually instituted in evaluation practice. Using the conceptual model as a guide (<xref ref-type="fig" rid="fig1-1098214012461558">Figure 1</xref>), this study aimed to understand the role that recipient stakeholders play in evaluation, specifically in terms of the level and type of inclusion, the role of program and recipient characteristics in involvement, and the nature of the strategies that evaluators use. To explore these issues, we conducted a content analysis of peer-reviewed articles that describe evaluations of programs that serve people with developmental, intellectual, psychiatric, and other disabilities. This approach is appropriate in areas of research where theory is underdeveloped, because it allows the researcher to take a close look at a group of cases that can support the development of a theoretical framework and inform further study (<xref ref-type="bibr" rid="bibr25-1098214012461558">Creswell &amp; Plano Clark, 2011</xref>).</p>
<p>Our analysis was guided by the following questions: </p>
<list list-type="order">
<list-item>
<p>To what extent have people with disabilities been included in the evaluation of programs that serve them? </p>
</list-item>
<list-item>
<p>What methodologies have been used to elicit views of people with disabilities? </p>
</list-item>
<list-item>
<p>What has been the role of contextual variables, such as type of program, in moderating inclusion?</p>
</list-item>
</list>
<p>Gaining a deeper understanding of the ways in which evaluators include stakeholders in their work can offer useful guidelines for practitioners who may be wary of inclusive approaches and, ultimately, may lead to more useful, meaningful evaluative practices.</p>
</sec>
</sec>
<sec id="section7-1098214012461558" sec-type="methods">
<title>Method</title>
<sec id="section8-1098214012461558">
<title>Journal Selection</title>
<p>Articles were obtained from peer-reviewed evaluation journals published in paper or online format in the United States during the 10 years prior to the study (2000–2009), using selection criteria adapted from <xref ref-type="bibr" rid="bibr21-1098214012461558">Christie and Fleisher (2010)</xref>. Specifically, evaluation journals were included if they (1) had the word “evaluation” in their title and (2) focused on social sciences or education. With these criteria, 10 journals were selected for this study (<xref ref-type="table" rid="table2-1098214012461558">Table 2</xref>).<sup>
<xref ref-type="fn" rid="fn1-1098214012461558">1</xref>
</sup>
</p>
<table-wrap id="table2-1098214012461558" position="float">
<label>Table 2.</label>
<caption>
<p>Evaluation Journals.</p>
</caption>
<graphic alternate-form-of="table2-1098214012461558" xlink:href="10.1177_1098214012461558-table2.tif"/>
<table>
<thead>
<tr>
<th>Journal</th>
<th>Number of articles selected</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<italic>Evaluation and Program Planning</italic>
</td>
<td>16</td>
</tr>
<tr>
<td>
<italic>New Directions for Evaluation</italic>
</td>
<td>6</td>
</tr>
<tr>
<td>
<italic>American Journal of Evaluation</italic>
</td>
<td>3</td>
</tr>
<tr>
<td>
<italic>Evaluation Review</italic>
</td>
<td>3</td>
</tr>
<tr>
<td>
<italic>Educational Evaluation and Policy Analysis</italic>
</td>
<td>2</td>
</tr>
<tr>
<td>
<italic>Evaluation and the Health Professions</italic>
</td>
<td>2</td>
</tr>
<tr>
<td>
<italic>Measurement and Evaluation in Counseling and Development </italic>
</td>
<td>0</td>
</tr>
<tr>
<td>
<italic>Journal of Multidisciplinary Evaluation</italic>
</td>
<td>0</td>
</tr>
<tr>
<td>
<italic>Policy Evaluation </italic>
</td>
<td>0</td>
</tr>
<tr>
<td>
<italic>Practical Assessment, Research &amp; Evaluation</italic>
</td>
<td>0</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The focus on evaluation journals was necessary because guidelines for focusing our search were needed and this was one of the criteria that we chose to utilize. The focus on evaluation journals also allowed us to hand search each of the journals, and this provided a more sensitive measure for selecting articles rather than using keyword searches, which might have led to missed articles. In addition, we assumed that since the role of stakeholders is an important component of evaluation practice, including only evaluation journals created a sample of articles more likely to discuss in detail the participatory aspects of evaluation design. Articles in these journals are also more likely to describe evaluations rather than applied research or program monitoring projects. It is important to note, however, that this approach may not produce results representative of evaluation practice as a whole, as many evaluation reports do not get published in peer-reviewed journals.</p>
</sec>
<sec id="section9-1098214012461558">
<title>Article Selection</title>
<p>Within these journals, an article was included in the analysis if (1) it described an empirical study of a program and (2) the majority of the program recipients had disabilities. Each journal’s abstracts were manually searched and then a scan was conducted to determine whether the article met the inclusion criteria. A keyword search was conducted within each journal using words such as “disabilities,” “mental retardation,” “psychiatric,” “mental health,” “deaf,” “brain injury,” “special needs,” “autism,” and “blind,” in order to identify articles that were not found in the manual search. If the article did not specifically mention that program recipients had disabilities but they were described as having physical or mental conditions (such as mental illness) that interfered with a major life activity (such as for those living in an institution rather than on their own), the article was included. This was in keeping with the definition of disability in the Americans with Disabilities Act (ADA) of 1990.</p>
<p>While other definitions, such as that of the World Health Organization (<xref ref-type="bibr" rid="bibr59-1098214012461558">WHO, 2011</xref>), cover a broader range of disabilities, the ADA definition was used to focus the study sample mostly on individuals with psychiatric and developmental disabilities, and to compare these groups to a few other types of disabilities such as physical or sensory disabilities. While this study focuses on intellectual, developmental, psychiatric, physical, and communication disabilities, there are many other kinds of disabilities not represented in this study, which can include substance dependence or certain learning disabilities or physical illnesses that do not meet ADA criteria. Selection procedures identified 35 articles for inclusion in the content analysis. Two of the articles described the same evaluation (<xref ref-type="bibr" rid="bibr30-1098214012461558">Fredericks, 2005</xref>; <xref ref-type="bibr" rid="bibr31-1098214012461558">Fredericks, Deegan, &amp; Carman, 2008</xref>), and of those two the most recent article was chosen. During the initial coding phase, we discovered that two articles did not meet our inclusion criteria and they were subsequently discarded. One described the program planning process but not an evaluation or study of a program, and in the other, the people with disabilities were not considered program recipients. Therefore, the final sample consisted of 32 articles.</p>
<p>Of the 32 articles included in the final sample, 16 focused on programs that serve individuals with psychiatric disabilities. Ten of the articles described evaluations of programs designed for people with intellectual or developmental disabilities. Six of the articles focused on programs designed to address other disabilities or did not specify the types of disabilities addressed. Given the small number of articles that focused on other types of disabilities, most of the analyses focused on the other two categories. </p>
</sec>
<sec id="section10-1098214012461558">
<title>Coding Instrument</title>
<p>A coding sheet and guidelines were developed for this study to deductively analyze the articles. An initial list of coding categories (listed in <xref ref-type="table" rid="table3-1098214012461558">Table 3</xref>) was developed and was further refined using the evaluation and research methods literature to identify existing definitions or frameworks that could be adapted or incorporated into the codebook. The code for disability types was also informed by a preliminary review of some of the articles by one of the authors in order to see how disability types were grouped and described. </p>
<table-wrap id="table3-1098214012461558" position="float">
<label>Table 3.</label>
<caption>
<p>Main Coding Categories and Their Definitions.</p>
</caption>
<graphic alternate-form-of="table3-1098214012461558" xlink:href="10.1177_1098214012461558-table3.tif"/>
<table>
<thead>
<tr>
<th>Code category </th>
<th>Definition </th>
</tr>
</thead>
<tbody>
<tr>
<td>Disability type</td>
<td>Disabilities fell into one of the following categories: developmental/intellectual, psychiatric, or other (such as physical/communication)</td>
</tr>
<tr>
<td>Inclusion</td>
<td>Inclusion was divided into two domains: (1) whether data were collected from program recipients with disabilities and (2) whether program recipients participated in the evaluation beyond just being a data source</td>
</tr>
<tr>
<td>Context</td>
<td>Context variables were chosen based on those thought to possibly moderate inclusion. These included program scope (local, state, national, international) and number of sites (single site, multisite, no sites described)</td>
</tr>
<tr>
<td>Data sources</td>
<td>Raters coded whether evaluation data sources were described in the article, and from whom data were collected (e.g., program recipients with disabilities, family members, and other stakeholders with disabilities), and how data were collected</td>
</tr>
<tr>
<td>Stakeholder participation</td>
<td>Our definition was based on <xref ref-type="bibr" rid="bibr24-1098214012461558">Cousins and Whitmore’s (1998)</xref> three dimensions of stakeholder involvement: stakeholder selection (diversity of stakeholders involved in the evaluation), depth of participation (ranging from limited participation in some stages to participation in all stages of the evaluation), and stakeholder control (degree of stakeholder control over evaluation decisions)<sup><xref ref-type="table-fn" rid="table-fn1-1098214012461558">a</xref></sup>
</td>
</tr>
<tr>
<td>Stakeholder groups</td>
<td>We recorded the participation of certain key stakeholder groups (program recipients with disabilities, family members of program recipients, and other stakeholders with disabilities). The codebook also noted the presence of any other stakeholders who participated in the evaluation, including policy makers, decision makers, and program implementers</td>
</tr>
<tr>
<td>Evaluation stages<sup><xref ref-type="table-fn" rid="table-fn2-1098214012461558">b</xref></sup>
</td>
<td>We noted the stages at which stakeholders were involved in the evaluation. These stages were derived from the Centers for Disease Control (CDC) Evaluation Framework (<xref ref-type="bibr" rid="bibr16-1098214012461558">CDC, 1999</xref>). They included:  1. Describing the program</td>
</tr>
<tr>
<td>
</td>
<td>   2. Focusing the evaluation design (questions and scope)</td>
</tr>
<tr>
<td>
</td>
<td>   3. Focusing the evaluation design (methods) </td>
</tr>
<tr>
<td>
</td>
<td>   4. Gathering of credible evidence </td>
</tr>
<tr>
<td>
</td>
<td>   5. Justifying conclusions (analysis and synthesis)</td>
</tr>
<tr>
<td>
</td>
<td>   6. Justifying conclusions (interpretation, judgment, recommendations)</td>
</tr>
<tr>
<td>
</td>
<td>   7. Ensuring use and sharing lessons learned</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1098214012461558">
<p>
<italic>Note</italic>. <sup>a</sup>Stakeholder control, however, was ultimately not used in the coding scheme because it was not ascertainable from the articles.</p>
</fn>
<fn id="table-fn2-1098214012461558">
<p>
<sup>b</sup>The stage <italic>engaging stakeholders</italic>, present in CDC’s framework, was not used since this was thought to be done throughout the other stages.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section11-1098214012461558">
<title>Procedures</title>
<p>Two independent raters read through each article and completed the initial coding instrument. Differences between raters were discussed, and a consensus was reached on the appropriate codes. The raters utilized a sample of 11 articles to clarify coding procedures and guidelines, and to subsequently revise them. These discussions led to the addition of new codes. The final codebook was created and used by each rater to independently code all articles in the sample, and the level of agreement equaled 92%. When coders did not agree, they discussed differences in ratings and came to a consensus on the final ratings for each article. <xref ref-type="table" rid="table3-1098214012461558">Table 3</xref> details the main coding categories and the definitions used in this study.</p>
<p>It is important to note that the study’s sample of peer-reviewed articles in evaluation journals limits the generalizability of the results. There might have been a great deal of involvement that is simply not reported in the articles, either because of editing or because the article only focuses on one part of a larger project. We attempted to create codes that would capture as many details about the context as possible, in order to reduce the impact of this limitation.</p>
</sec>
</sec>
<sec id="section12-1098214012461558">
<title>Results</title>
<p>The results section is divided into two broad areas that represent the type of inclusion that was coded in this study. The first section examines the evaluation’s likelihood of collecting information/data from individuals with disabilities, along with the types of approaches and methods utilized during this process. The second section examines the likelihood of involving individuals with disabilities in the evaluation process, beyond just collecting data from them, along with the strategies utilized during this process.</p>
<sec id="section13-1098214012461558">
<title>Inclusion as a Data Source</title>
<p>Of the articles in which data sources were described (<italic>N</italic> = 31), data were obtained from program recipients with disabilities in 24 (77%) of the articles, from family members in 11 (36%) of the articles, and from other stakeholders with disabilities in 6 (19%) of the articles. In two (6%) of the articles, data were obtained only from family members and not from program recipients. There was variation when we examined the articles according to the types of disabilities addressed by the programs in question. Specifically, in 88% of the articles describing programs that served individuals with psychiatric disabilities, data were collected from recipients. This was true in 80% of the articles focused on programs for recipients with developmental disabilities and in 50% of the articles on programs focused on other types of disabilities.</p>
<p>As shown in <xref ref-type="table" rid="table4-1098214012461558">Table 4</xref>, the context in which the evaluation was conducted generally did not appear to influence the inclusion of program recipients in data collection. One exception was with evaluations conducted in educational settings. Only 57% of the evaluations conducted in this type of setting included stakeholders in their data collection, compared to 75% and 88% in health and community/social service/vocational settings, respectively. Additionally, mixed-methods studies more frequently included data collection from recipients—91% of these studies did so, compared to 64% of quantitative-only evaluations, and 75% of qualitative-only studies.</p>
<table-wrap id="table4-1098214012461558" position="float">
<label>Table 4.</label>
<caption>
<p>Inclusion as a Data Source by Program and Evaluation Context (<italic>N</italic> = 31).</p>
</caption>
<graphic alternate-form-of="table4-1098214012461558" xlink:href="10.1177_1098214012461558-table4.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th colspan="4">Were data collected from recipients?<hr/></th>
</tr>
<tr>
<th>Program and evaluation context</th>
<th colspan="2">Yes <italic>N </italic>= 24<hr/></th>
<th colspan="2">No <italic>N </italic>= 7<hr/></th>
<th>Total <italic>N </italic>= 31<hr/></th>
</tr>
<tr>
<th>
</th>
<th>
<italic>N</italic>
</th>
<th>%</th>
<th>
<italic>N</italic>
</th>
<th>%</th>
<th>
<italic>N</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">Field</td>
</tr>
<tr>
<td> Community/social service/vocational</td>
<td>14</td>
<td>88</td>
<td>2</td>
<td>13</td>
<td>16</td>
</tr>
<tr>
<td> Health</td>
<td>6</td>
<td>75</td>
<td>2</td>
<td>25</td>
<td>8</td>
</tr>
<tr>
<td> Education</td>
<td>4</td>
<td>57</td>
<td>3</td>
<td>43</td>
<td>7</td>
</tr>
<tr>
<td colspan="6">Conducted in the United States </td>
</tr>
<tr>
<td> Yes</td>
<td>15</td>
<td>71</td>
<td>6</td>
<td>29</td>
<td>21</td>
</tr>
<tr>
<td> No</td>
<td>4</td>
<td>80</td>
<td>1</td>
<td>20</td>
<td>5</td>
</tr>
<tr>
<td> Not specified</td>
<td>5</td>
<td>100</td>
<td>0</td>
<td>0</td>
<td>5</td>
</tr>
<tr>
<td colspan="6">Scope</td>
</tr>
<tr>
<td> Local</td>
<td>7</td>
<td>70</td>
<td>3</td>
<td>30</td>
<td>10</td>
</tr>
<tr>
<td> State</td>
<td>8</td>
<td>80</td>
<td>2</td>
<td>20</td>
<td>10</td>
</tr>
<tr>
<td> National</td>
<td>4</td>
<td>67</td>
<td>2</td>
<td>33</td>
<td>6</td>
</tr>
<tr>
<td> Not specified</td>
<td>5</td>
<td>100</td>
<td>0</td>
<td>0</td>
<td>5</td>
</tr>
<tr>
<td colspan="6">Sites</td>
</tr>
<tr>
<td> Single</td>
<td>6</td>
<td>100</td>
<td>0</td>
<td>0</td>
<td>6</td>
</tr>
<tr>
<td> Multi</td>
<td>15</td>
<td>75</td>
<td>5</td>
<td>25</td>
<td>20</td>
</tr>
<tr>
<td> No sites/not described</td>
<td>3</td>
<td>60</td>
<td>2</td>
<td>40</td>
<td>5</td>
</tr>
<tr>
<td>Data collection methods</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td> Quantitative</td>
<td>7</td>
<td>64</td>
<td>4</td>
<td>36</td>
<td>11</td>
</tr>
<tr>
<td> Qualitative</td>
<td>6</td>
<td>75</td>
<td>2</td>
<td>25</td>
<td>8</td>
</tr>
<tr>
<td> Mixed</td>
<td>10</td>
<td>91</td>
<td>1</td>
<td>9</td>
<td>11</td>
</tr>
<tr>
<td> Not specified</td>
<td>1</td>
<td>100</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1098214012461558">
<p>
<italic>Note.</italic> Only consists of articles where data sources are described.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<sec id="section14-1098214012461558">
<title>Methods of obtaining data</title>
<p>Interviews, focus groups, surveys, and observations were all used to collect data from recipients; document analysis did not appear in any of the articles. Interviews were used in 75% of the articles in which data were collected from recipients. In 63% of the articles, either structured or semistructured interviews were used; unstructured interviews were used in 8% and interviews of an unspecified format were used in 17%. </p>
<p>Because of the challenges associated with the participation of individuals with specific types of disabilities, it is useful to examine what types of data collection were used with which recipient populations. We found that interviews were the most common method used to obtain the participation of individuals with developmental disabilities and psychiatric disabilities. In fact, interviews were used in all of the articles in which data were collected from those with psychiatric disabilities. Focus groups were the second most common method used for those with psychiatric disabilities and the least commonly used method for those with developmental disabilities (<xref ref-type="fig" rid="fig2-1098214012461558">Figure 2</xref>).</p>
<fig id="fig2-1098214012461558" position="float">
<label>Figure 2.</label>
<caption>
<p>Methods used to collect data from participants by disability type (<italic>N</italic> = 24). Figure 2 Includes articles where data were collected from program recipients with disabilities. Multiple methods were used in some articles, so totals sometimes exceed the number of articles.</p>
</caption>
<graphic xlink:href="10.1177_1098214012461558-fig2.tif"/>
</fig>
</sec>
<sec id="section15-1098214012461558">
<title>Examples of data collection methods</title>
<p>The interviews used in the evaluations had a variety of formats. Evaluators asked both open- and closed-ended questions; some protocols were brief, and others were in depth. A few data collection tools were standardized and previously validated, while others were newly created for the project. Many included measures of recipients’ subjective views on the program rather than measures of more objective characteristics such as physical condition or academic achievement.</p>
<p>Some of the articles offered suggestions for modifying data collection procedures to accommodate program recipients. The most common suggestions for adapting to various communication styles were to allow for flexibility, to individualize procedures, and to simplify answer choices. <xref ref-type="table" rid="table5-1098214012461558">Table 5</xref> describes specific adaptations. Each example is followed by a notation of the type of data collection utilized in that study and the type of disability addressed by that program. In particular, the articles identified some strategies that could apply both to individuals with developmental and psychiatric disabilities. For example, interaction with stakeholders, either recipients with disabilities or those who knew them well, helped evaluators to tailor data collection strategies to the population’s needs. Visual prompts was another technique that allowed sensitivity to various communication mechanisms, whereby recipients could choose from a set of pictures, and could also supplement their choice with comments of their own. Being involved in the program helped the evaluator build rapport with recipients and better understand the unique program context. Finally, in cases where there was a concern that the voices of the recipients would not be heard, the evaluator could take extra steps to encourage them to speak.</p>
<table-wrap id="table5-1098214012461558" position="float">
<label>Table 5.</label>
<caption>
<p>Excerpts from Articles Where Adaptations to Data Collection Strategies Were Used.</p>
</caption>
<graphic alternate-form-of="table5-1098214012461558" xlink:href="10.1177_1098214012461558-table5.tif"/>
<table>
<tbody>
<tr>
<td>Use of Visual Prompts</td>
</tr>
<tr>
<td> . . . the facilitators distributed a paper with 12 different labeled faces on it to each participant. The participants were asked to circle the face or faces that best illustrated how they generally felt about the program (e.g., anxious, happy, sad, bored, etc.). They were also encouraged to write comments on the back or to verbally provide feedback to the facilitators (<xref ref-type="bibr" rid="bibr38-1098214012461558">Heinz, 2003</xref>, p. 267). [Survey, IDD]</td>
</tr>
<tr>
<td> They were invited to tell a story about themselves and the project with the help of two visual images. They could choose from a set of 40 images we had selected. The set was as diverse as possible, because we wanted to appeal to people with different interests (<xref ref-type="bibr" rid="bibr1-1098214012461558">Abma, 2000</xref>, p. 203). [Focus Group, Psych].</td>
</tr>
<tr>
<td>Stakeholder Involvement</td>
</tr>
<tr>
<td> From this third party, the research team learnt about the needs and preferences of the clients. This included the appropriate time to contact and interview the client, the most suitable interview setting, the language style that should be used, regularity of interludes during the interview, and whether researcher safety would be a potential risk. The third party also liaised with clients about the study. . . (<xref ref-type="bibr" rid="bibr26-1098214012461558">Dadich &amp; Muir, 2009</xref>, p. 47). [Structured/Semi-structured Interview, Psych]</td>
</tr>
<tr>
<td> Selected self-advocates [with disabilities]. . . interviewed each other while the research team observed, and participated in informal focus groups to critique the instrument and procedures. These sessions suggested the need for a flash card which respondents could use to indicate their answers (Schalock, Bonham, &amp; Marchand, 2000, p. 81). [Structured/Semistructured Interview, IDD]</td>
</tr>
<tr>
<td>Proactively Seek Out Recipient's Voice</td>
</tr>
<tr>
<td> The interview protocol for this forum, and for the others, was specifically designed to engage the disenfranchised group, to ensure that their voices were in the mix. As an example, the first question after the general introduction was directed to the people who resided in the institution (<xref ref-type="bibr" rid="bibr44-1098214012461558">MacNeil, 2000</xref>, p. 57). [Focus Group, Psych]</td>
</tr>
<tr>
<td> Standard facial, body, and vocal queues may be absent throughout the entire process. Although it was sometimes difficult to read client disposition, the researchers regularly reminded clients that they could choose to end or break the interview at any time (<xref ref-type="bibr" rid="bibr26-1098214012461558">Dadich &amp; Muir, 2009</xref>, p. 53). [Structured/Semi-structured Interview, Psych]</td>
</tr>
<tr>
<td>Participate in Program Context</td>
</tr>
<tr>
<td> In the evaluation the on-site evaluator. . . could not become a full participant in the program due to the fact that the program was designed to serve a special population. However, she made a sustained effort over several months to participate in the program as much as possible in order to yield the most meaningful observational data (<xref ref-type="bibr" rid="bibr38-1098214012461558">Heinz, 2003</xref>, p. 264). [Observation, IDD]</td>
</tr>
<tr>
<td> Those who are not familiar with an interview for evaluation research often experience it as an examination for therapy or treatment. To avoid this and to gain trust we hung out and worked together with the patients (<xref ref-type="bibr" rid="bibr1-1098214012461558">Abma, 2000</xref>, pp. 201–202). [Interview, Psych]</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-1098214012461558">
<p>
<italic>Note.</italic> IDD = intellectual or developmental disability; Psych = psychiatric disability.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section16-1098214012461558">
<title>Inclusion as a Participant</title>
<p>Of the 29 articles where stakeholder participation in the evaluation was mentioned, program recipients with disabilities participated in 31% of the cases, family members participated in 24% of the cases, and other stakeholders with disabilities participated in 10% of the cases. Within those 29 articles, participation appeared to be related to disability type, in that 47% (7 of the 15) of the evaluations of programs for people with psychiatric disabilities described recipient participation, whereas only 13% (1 of the 8) of the evaluations of programs for people with developmental disabilities described recipient participation.</p>
<p>Our coding process also revealed that participation occurred relatively equally across most of the context subcategories and was not restricted to certain settings (<xref ref-type="table" rid="table6-1098214012461558">Table 6</xref>). However, there was a smaller proportion of recipient participation in evaluations of educational programs (13%) than in evaluations in health (43%) or community/social service/vocational settings (36%), and a smaller proportion of recipient participation in evaluations that only used quantitative data collection methods (11%) versus evaluations where mixed methods (50%) or qualitative data collection methods (38%) were used (<xref ref-type="table" rid="table6-1098214012461558">Table 6</xref>).</p>
<table-wrap id="table6-1098214012461558" position="float">
<label>Table 6.</label>
<caption>
<p>Evaluation Participation by Program and Evaluation Context (N=29).</p>
</caption>
<graphic alternate-form-of="table6-1098214012461558" xlink:href="10.1177_1098214012461558-table6.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th colspan="5">
<italic>Did program recipients participate in the evaluation?</italic><hr/>
</th>
</tr>
<tr>
<th>Program and evaluation characteristics</th>
<th colspan="2">Yes <italic>N</italic> = 9<hr/></th>
<th colspan="2">No <italic>N </italic>= 20<hr/></th>
<th>Total <italic>N </italic>= 29<hr/></th>
</tr>
<tr>
<th>
</th>
<th>
<italic>N</italic>
</th>
<th>%</th>
<th>
<italic>N</italic>
</th>
<th>%</th>
<th>
<italic>N</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">Field</td>
</tr>
<tr>
<td> Health </td>
<td>3</td>
<td>43</td>
<td>4</td>
<td>57</td>
<td>7</td>
</tr>
<tr>
<td> Community/social service/vocational</td>
<td>5</td>
<td>36</td>
<td>9</td>
<td>64</td>
<td>14</td>
</tr>
<tr>
<td> Education</td>
<td>1</td>
<td>13</td>
<td>7</td>
<td>88</td>
<td>8</td>
</tr>
<tr>
<td colspan="6">Conducted in United States</td>
</tr>
<tr>
<td> Yes</td>
<td>4</td>
<td>20</td>
<td>16</td>
<td>80</td>
<td>20</td>
</tr>
<tr>
<td> No</td>
<td>2</td>
<td>50</td>
<td>2</td>
<td>50</td>
<td>4</td>
</tr>
<tr>
<td> Not specified</td>
<td>3</td>
<td>60</td>
<td>2</td>
<td>40</td>
<td>5</td>
</tr>
<tr>
<td colspan="6">Scope</td>
</tr>
<tr>
<td> Local</td>
<td>2</td>
<td>18</td>
<td>9</td>
<td>82</td>
<td>11</td>
</tr>
<tr>
<td> State</td>
<td>3</td>
<td>33</td>
<td>6</td>
<td>67</td>
<td>9</td>
</tr>
<tr>
<td> National</td>
<td>2</td>
<td>33</td>
<td>4</td>
<td>67</td>
<td>6</td>
</tr>
<tr>
<td> Not described</td>
<td>2</td>
<td>67</td>
<td>1</td>
<td>33</td>
<td>3</td>
</tr>
<tr>
<td colspan="6">Sites</td>
</tr>
<tr>
<td> Single</td>
<td>3</td>
<td>43</td>
<td>4</td>
<td>57</td>
<td>7</td>
</tr>
<tr>
<td> Multi</td>
<td>6</td>
<td>30</td>
<td>14</td>
<td>70</td>
<td>20</td>
</tr>
<tr>
<td> No sites/not described</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>100</td>
<td>2</td>
</tr>
<tr>
<td colspan="6">Data Collection Methods</td>
</tr>
<tr>
<td> Quantitative</td>
<td>1</td>
<td>11</td>
<td>8</td>
<td>89</td>
<td>9</td>
</tr>
<tr>
<td> Qualitative</td>
<td>3</td>
<td>38</td>
<td>5</td>
<td>63</td>
<td>8</td>
</tr>
<tr>
<td> Mixed</td>
<td>5</td>
<td>50</td>
<td>5</td>
<td>50</td>
<td>10</td>
</tr>
<tr>
<td> Not specified</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>100</td>
<td>2</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-1098214012461558">
<p>
<italic>Note.</italic> Only includes articles in which any stakeholder participation is mentioned.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>We conducted a frequency count to compare participant and stakeholder involvement across the various evaluation stages (<xref ref-type="fig" rid="fig3-1098214012461558">Figure 3</xref>). Program recipient participation occurred in each of the seven evaluation stages except for the <italic>Focusing Questions</italic> stage. The stages in which program recipients were most often involved were <italic>Interpretation</italic> (6 articles) and <italic>Focusing Methods</italic> (4 articles). These were followed by <italic>Ensuring Use </italic>(3 articles), <italic>Gathering Evidence</italic> (2 articles), <italic>Analysis</italic> (2 articles), and <italic>Describing the Program</italic> (1 article). The most common stage for family participation was <italic>Gathering Evidence</italic> (3 articles); other stakeholders with disabilities most commonly participated in the <italic>Interpretation</italic> stage (3 articles). Other stakeholders tended to participate in the <italic>Focusing Methods</italic> stage (19 articles). Overall, program recipients participated more frequently than family members across almost all stages of the evaluation except for <italic>Gathering Evidence</italic>, but less often than other stakeholders at each evaluation stage. It is important to note that “other stakeholders” could represent the involvement of multiple types of people throughout the evaluation (such as implementers, funders, directors, etc.), rather the sustained participation of one individual or group.</p>
<fig id="fig3-1098214012461558" position="float">
<label>Figure 3.</label>
<caption>
<p>Participation in specific evaluation stages by stakeholder type.</p>
</caption>
<graphic xlink:href="10.1177_1098214012461558-fig3.tif"/>
</fig>
<sec id="section17-1098214012461558">
<title>Description of specific examples</title>
<p>Descriptive examples illustrate the types of participation that occurred across different evaluation stages. Three articles described involvement of program recipients in conducting “member checks,” a tactic used in qualitative studies to validate evaluation findings through review by those from whom the data were collected (<xref ref-type="bibr" rid="bibr25-1098214012461558">Creswell &amp; Plano Clark, 2011</xref>). These three articles were also the only ones that described recipient participation in single-site evaluations. Three included board members in multisite evaluations. <xref ref-type="bibr" rid="bibr51-1098214012461558">Schalock, Bonhamb, and Marchand (2000)</xref> spoke about activities as part of the <italic>Ask Me!</italic> project (described above in the literature review) and was the only author to describe inclusion of people with developmental disabilities. In that example, the recipients provided input on measurement tools and also conducted interviews. <xref ref-type="bibr" rid="bibr41-1098214012461558">LePage-Chabriais (2005)</xref> described limited participation, consisting of some sort of program recipient feedback at one point in the evaluation. This was also the only case in which children or youth were involved. None of the cases described youth participation beyond having them provide passive input into the evaluation methods. <xref ref-type="table" rid="table7-1098214012461558">Table 7</xref> offers examples of these various types of inclusion. Each sample quote is followed by a list of the stages during which participation occurred.</p>
<table-wrap id="table7-1098214012461558" position="float">
<label>Table 7.</label>
<caption>
<p>Sample Descriptions of Program Recipient Participation. </p>
</caption>
<graphic alternate-form-of="table7-1098214012461558" xlink:href="10.1177_1098214012461558-table7.tif"/>
<table>
<thead>
<tr>
<th>Article</th>
<th>Disability type </th>
<th>Evaluation context</th>
<th>Stages where participation occurred</th>
<th>Sample quotes (Stage)</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<xref ref-type="bibr" rid="bibr1-1098214012461558">Abma (2000)</xref></td>
<td>Psychiatric </td>
<td>Organizational Single Site Mixed Methods</td>
<td>Interpret Ensure Use</td>
<td>During and after every interview we asked for feedback from the respondents so we could check the credibility of our findings. . . in addition several group member checks were organized (p. 202). [Interpret]</td>
</tr>
<tr>
<td>
<xref ref-type="bibr" rid="bibr23-1098214012461558">Cook, Carey, Razzano, Burke, and Blyler (2002)</xref></td>
<td>Psychiatric </td>
<td>Organizational Multisite Mixed Methods </td>
<td>Focus Methods Gather Evidence Analyze Interpret Ensure Use</td>
<td>Roles of the consumer assembly have included hypothesis development, examination and interpretation of preliminary findings, qualitative and case study analysis, identification of policy-related issues resulting from EIDP (p. 34). [Focus methods, analysis, interpret, ensure use]</td>
</tr>
<tr>
<td>
<xref ref-type="bibr" rid="bibr41-1098214012461558">Lepage-Chabriais (2005)</xref></td>
<td>Psychiatric </td>
<td>Primary/Secondary Education Multisite Mixed Methods</td>
<td>Focus Methods</td>
<td>With the agreement of both the youths and the institutions, we have chosen the term <italic>successful placement</italic> for that placement that allowed the youth to achieve the fixed goals of the educational program (p. 463). [Focus methods]</td>
</tr>
<tr>
<td>
<xref ref-type="bibr" rid="bibr51-1098214012461558">Schalock et al. (2000)</xref></td>
<td>Intellectual/developmental</td>
<td>Community/Social Service Multisite Quantitative</td>
<td>Focus Methods Gather Evidence</td>
<td>Selected self-advocates were trained as interviewers during these work sessions, interviewed each other while the research team observed, and participated in informal focus groups to critique the instrument and procedures (p. 81). [Focus methods, Gather evidence]</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-1098214012461558">
<p>
<italic>Note</italic>. Coding was not done on quotes in isolation. Rather while specific quotes were highlighted, some could only be coded in the context of the rest of the article. For example, if consumers were said to serve on an advisory board, and this advisory board was said to be involved in a stage, it was presumed that the consumer participated in that stage unless said otherwise.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="section18-1098214012461558">
<title>Discussion</title>
<p>This study examined the type and level of involvement that program recipients with disabilities have in evaluations, and described various strategies that evaluators use when working with populations with disabilities. When the results are mapped on to the inclusion model presented in <xref ref-type="fig" rid="fig1-1098214012461558">Figure 1</xref>, we find noteworthy relationships between feasibility considerations (e.g., participant characteristics) and levels and quality of involvement. For example, individuals with psychiatric disabilities were more likely to be included in evaluations (whether as sources of data or as participants) than were individuals with developmental/intellectual disabilities. This finding is arguably not surprising, since there are more challenges in collecting data from those with developmental disabilities then psychiatric disabilities (<xref ref-type="bibr" rid="bibr29-1098214012461558">Finlay &amp; Lyons, 2001</xref>). In addition, this study found that most inclusion activities tended to revolve around data collection (77%) rather than deeper participation in the evaluation process (31%). Finally, program recipients with disabilities tended to participate in evaluations comparatively less often than other stakeholder groups.</p>
<p>Contextual factors measured in this study appeared to have less of an influence on inclusion levels than other feasibility considerations did. Of the contextual factors we coded, only the field and methodological approach appeared to contain differences in inclusion levels. More specifically, educational contexts and studies that employed solely quantitative research approaches tended to have fewer individuals with disabilities included as data sources and participants. The former difference could be attributable to the fact that many of the educational programs included youth below the age of 12, and in these programs data were often collected from parents or legal guardians, rather than the youth themselves. This appears to be the only major differentiating factor between the educational programs and programs in other areas, however this observation warrants further investigation in subsequent studies. The latter difference may have reflected the greater range of data collection methods available in nonquantitative approaches, as well as the greater consistency between the goals of participatory approaches and qualitative or mixed-method studies as compared to the goals of quantitative studies. In particular, with qualitative components, representing the subjective experience of service recipients may be more valued. </p>
<p>Indeed, one of the other interesting aspects of this study was the different approaches and methods evaluators used when working with individuals with disabilities. Evaluators used a range of techniques, including interviews, focus groups, surveys, and observations. Interviews in particular were especially useful for gathering the input of people with psychiatric and developmental disabilities. Interviews allow the evaluator to tailor procedures to individual respondents, closely assess recipients’ capacity to respond, and make sure questions are understood as the evaluator intended (<xref ref-type="bibr" rid="bibr11-1098214012461558">Bonham et al., 2004</xref>). Regardless of the methods used, the evaluator needs to develop data collection procedures that keep in mind the needs and abilities of specific recipients in the program.</p>
<p>Together, these findings provide tentative support for parts of the inclusion model presented in <xref ref-type="fig" rid="fig1-1098214012461558">Figure 1</xref>. They show a relatively strong connection between participant characteristics and their likelihood of being involved in the evaluation process as well as the quality of inclusion—individuals with psychiatric disabilities were more likely to participate more fully in some aspects of the evaluation versus just being used as a data source. These findings also support the connection between context (e.g., program field) and level of inclusion and evaluation quality. This suggests that the model could change to have participant characteristics and context inform the quality of inclusion. Although not all elements of the model were represented in this study, this is an initial step toward understanding the factors that connect different feasibility considerations with levels of inclusion and how these connections are weighed by evaluators.</p>
<sec id="section19-1098214012461558">
<title>Making Inclusion Work</title>
<p>Evaluators may encounter certain challenges to collecting data in some contexts, and they have various strategies to draw on when this occurs. Involving other stakeholders and piloting data collection tools can help ensure the appropriateness of measurement procedures for the recipient population. Visiting or even taking part in the program can both build rapport with recipients and allow evaluators to better understand what evaluation procedures are appropriate to the program and recipient context. Evaluators might need to actively seek out those quieter voices, either because of power dynamics in a program or because of the communication styles of the recipients. With individuals who communicate differently, it can be helpful to use creative strategies that give recipients multiple ways to access information, whether by listening to the interviewer’s speech, by reading text, or by seeing pictures. Providing room for flexibility in procedures for recipients appears to be helpful as well. As described in some articles, the target population of a program might include a great deal of diversity both in recipient abilities and characteristics of their environmental contexts, (e.g., their living situations). These suggestions can apply to both those with psychiatric or developmental disabilities depending on the individual and their context. Other types of disabilities, not represented in this study, may merit alternative strategies. In addition, most of the participation occurred with adults, and so many of the strategies identified in the articles for <italic>how</italic> to collect data from or involve people with disabilities may not capture those needed when involving children.</p>
<p>Practitioners should consider involving recipients in at least one or two stages of an evaluation, or even throughout the evaluation process. The potential benefits from inclusion include increased evaluation accuracy and empowered program recipients. Meanwhile, evaluators should also think seriously about what they want to accomplish through inclusion, whether involvement is truly in the interest of recipients, and what type of inclusion is needed to accomplish these goals. This will ensure that the engagement with recipients with disabilities is a genuine process that goes beyond merely symbolic benefits.</p>
</sec>
<sec id="section20-1098214012461558">
<title>Directions for Future Research</title>
<p>There remains a great deal for us to discover about the inclusion of individuals with disabilities in the evaluation of programs designed to meet their needs. Future research can build on this study and the inclusion model (<xref ref-type="fig" rid="fig1-1098214012461558">Figure 1</xref>) to continue exploring the factors that influence the levels and types of inclusion in various evaluation efforts, as well as the quality of inclusive practices. The main area of future exploration should focus on the relationship between the level and quality of inclusion and the actual benefits of these efforts. This is an aspect of the model that could be examined in future studies through in-depth interviews and focus groups with evaluation practitioners and, if possible, with program implementers and participants.</p>
<p>Future studies may also examine other contextual factors such as whether a program serves only individuals with disabilities or the general population as well. It will be important to determine the extent to which evaluators are willing to devote the resources needed to overcome potential communication and cognitive barriers when only a minority of program recipients have disabilities. Additional investigations could also focus on evaluator characteristics, which have been previously shown to relate to stakeholder involvement (<xref ref-type="bibr" rid="bibr3-1098214012461558">Azzam, 2010</xref>, <xref ref-type="bibr" rid="bibr4-1098214012461558">2011</xref>; <xref ref-type="bibr" rid="bibr20-1098214012461558">Christie, 2003</xref>). For example, these studies could examine evaluators’ beliefs about social justice, their methodological orientations, and their levels of experience, and then compare these factors to inclusion levels and quality in their practices.</p>
<p>Finally, the validity of data collection methods should be studied further to ensure that recipient voices, when included, are accurately represented, especially in evaluations where this is the only way recipients are involved. Evaluators should ensure that inclusion is designed strategically to achieve the desired goal of participation, and should focus energy and resources accordingly. Further efforts to understand how to increase the quality of inclusion can help ensure that people with disabilities are not only included, but that this inclusion actually benefits them and other stakeholders groups.</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict" id="fn2-1098214012461558">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn3-1098214012461558">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<title>Note</title>
<fn-group>
<fn fn-type="other" id="fn1-1098214012461558">
<label>1.</label>
<p>Please note, the criteria we utilized in selecting journals was derived from the <xref ref-type="bibr" rid="bibr21-1098214012461558">Christie and Fleisher (2010)</xref> article; however, the actual articles were from many different areas including community programs, health programs, vocational programs, and educational programs.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Abma</surname>
<given-names>T. A.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Stakeholder conflict: A case study</article-title>. <source>Evaluation and Program Planning</source>, <volume>23</volume>, <fpage>199</fpage>–<lpage>210</lpage>. <comment>doi:10.1016/S0149-7189(00)00006-9</comment>
</citation>
</ref>
<ref id="bibr2-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author"><name><surname>Abma</surname><given-names>T. A.</given-names></name><name><surname>Nierse</surname><given-names>C. J.</given-names></name><name><surname>Widdershoven</surname><given-names>G. A.</given-names></name></person-group> (<year>2009</year>). <article-title>Patients as partners in responsive research: Methodological notions for collaborations in mixed research teams</article-title>. <source>Qualitative Health Research</source>, <volume>19</volume>, <fpage>401</fpage>–<lpage>415</lpage>. <comment>doi:10.1177/1049732309331869</comment>
</citation>
</ref>
<ref id="bibr3-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Azzam</surname>
<given-names>T.</given-names>
</name>
</person-group> (<year>2010</year>). <article-title>Evaluator responsiveness to stakeholders</article-title>. <source>American Journal of Evaluation</source>, <volume>31</volume>, <fpage>45</fpage>–<lpage>65</lpage>. <comment>doi:10.1177/1098214009354917</comment>
</citation>
</ref>
<ref id="bibr4-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Azzam</surname>
<given-names>T.</given-names>
</name>
</person-group> (<year>2011</year>). <article-title>Evaluator characteristics and methodological choice</article-title>. <source>American Journal of Evaluation</source>, <volume>32</volume>, <fpage>376</fpage>–<lpage>391</lpage>. <comment>doi:10.1177/1098214011399416</comment>
</citation>
</ref>
<ref id="bibr5-1098214012461558">
<citation citation-type="web">
<collab collab-type="author">American Association on Intellectual and Developmental Disabilities</collab>. (<year>2011</year>). <comment>Retrieved December 2010 from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.aamr.org/content_100.cfm?navID=21">http://www.aamr.org/content_100.cfm?navID=21</ext-link>
</citation>
</ref>
<ref id="bibr6-1098214012461558">
<citation citation-type="other">
<collab collab-type="author">Americans with Disabilities Act</collab>. (<year>1990</year>). <article-title>U.S. code</article-title>. <volume>42</volume>, <fpage>12101</fpage>–<lpage>12213</lpage>.</citation>
</ref>
<ref id="bibr7-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Balch</surname>
<given-names>G. I.</given-names>
</name>
<name>
<surname>Mertens</surname>
<given-names>D. M.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Focus group design and group dynamics: Lessons from deaf and hard of hearing participants</article-title>. <source>American Journal of Evaluation</source>, <volume>20</volume>, <fpage>265</fpage>–<lpage>277</lpage>. <comment>doi: 10.1177/109821409902000208</comment>
</citation>
</ref>
<ref id="bibr8-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Barnes</surname>
<given-names>C.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>What a difference a decade makes: Reflections on doing ‘emancipatory' disability research</article-title>. <source>Disability &amp; Society</source>, <volume>18</volume>, <fpage>3</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr9-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Birman</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>2007</year>). <article-title>Sins of omission and commission: To proceed, decline, or alter?</article-title> <source>American Journal of Evaluation</source>, <volume>28</volume>, <fpage>79</fpage>–<lpage>85</lpage>. <comment>doi:10.1177/1098214006298059</comment>
</citation>
</ref>
<ref id="bibr10-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Boland</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Daly</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Staines</surname>
<given-names>A.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Methodological issues in inclusive intellectual disability research: A health promotion needs assessment of people attending Irish disability services</article-title>. <source>Journal of Applied Research in Intellectual Disabilities</source>, <volume>21</volume>, <fpage>199</fpage>–<lpage>209</lpage>. <comment>doi:10.1111/j.1468-3148.2007.00404.x</comment>
</citation>
</ref>
<ref id="bibr11-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author"><name><surname>Bonham</surname><given-names>G. S.</given-names></name><name><surname>Basehart</surname><given-names>S.</given-names></name><name><surname>Schalock</surname><given-names>R. L.</given-names></name><name><surname>Marchand</surname><given-names>C. B.</given-names></name><name><surname>Kirchner</surname><given-names>N.</given-names></name><name><surname>Rumenap</surname><given-names>J. M.</given-names></name><name><surname>Scotti</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>Consumer-based quality of life assessment: The Maryland <italic>Ask Me</italic>! Project</article-title>. <source>Mental Retardation</source>, <volume>42</volume>, <fpage>338</fpage>–<lpage>355</lpage>. <comment>doi: 10.1352/00476765(2004)42</comment>
</citation>
</ref>
<ref id="bibr12-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Botcheva</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Shih</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Huffman</surname>
<given-names>L. C.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Emphasizing cultural competence in evaluation: A process oriented approach</article-title>. <source>American Journal of Evaluation</source>, <volume>30</volume>, <fpage>176</fpage>–<lpage>188</lpage>. <comment>doi:10.1177/1098214009334363</comment>
</citation>
</ref>
<ref id="bibr13-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Brandon</surname>
<given-names>P. R.</given-names>
</name>
</person-group> (<year>1998</year>). <article-title>Stakeholder participation for the purpose of helping ensure evaluation validity: Bridging the gap between collaborative and non-collaborative evaluations</article-title>. <source>American Journal of Evaluation</source>, <volume>19</volume>, <fpage>325</fpage>–<lpage>337</lpage>. <comment>doi:10.1177/109821409801900305</comment>
</citation>
</ref>
<ref id="bibr14-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Caldwell</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Hauss</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Stark</surname>
<given-names>B.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Participation of individuals with developmental disabilities and families on advisory boards and committees</article-title>. <source>Journal of Disability Policy Studies</source>, <volume>20</volume>, <fpage>101</fpage>–<lpage>109</lpage>. <comment>doi:10.1177/1044207308327744</comment>
</citation>
</ref>
<ref id="bibr15-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cambell</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1997</year>). <article-title>How consumers/survivors are evaluating the quality of psychiatric care</article-title>. <source>Evaluation Review</source>, <volume>21</volume>, <fpage>357</fpage>–<lpage>363</lpage>.</citation>
</ref>
<ref id="bibr16-1098214012461558">
<citation citation-type="journal">
<collab collab-type="author">Centers for Disease Control and Prevention</collab>. (<year>1999</year>). <article-title>Framework for program evaluation in public health</article-title>. <source>Morbidity and Mortality Weekly Report</source>, <volume>48</volume> <issue>(No.RR-11)</issue>. <publisher-loc>Atlanta, Georgia</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr17-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chappell</surname>
<given-names>A. L.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Emergence of participatory methodology in learning difficulty research: Understanding the context</article-title>. <source>British Journal of Learning Disabilities</source>, <volume>28</volume>, <fpage>38</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr18-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chen</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Poland</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Skinner</surname>
<given-names>H. A.</given-names>
</name>
</person-group> (<year>2007</year>). <article-title>Youth voices: Evaluation of participatory action research.</article-title> <source>Canadian Journal of Program Evaluation</source>, <volume>22</volume>, <fpage>125</fpage>–<lpage>150</lpage>.</citation>
</ref>
<ref id="bibr19-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chouinard</surname>
<given-names>J. A.</given-names>
</name>
<name>
<surname>Cousins</surname>
<given-names>J. B.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>A review and synthesis of current research on cross-cultural evaluation</article-title>. <source>American Journal of Evaluation</source>, <volume>30</volume>, <fpage>457</fpage>–<lpage>494</lpage>. <comment>doi:10.1177/1098214009349865</comment>
</citation>
</ref>
<ref id="bibr20-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Christie</surname>
<given-names>C. A.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>What guides evaluation? A study of how evaluation practice maps onto evaluation theory</article-title>. <source>New Directions for Evaluation</source>, <volume>97</volume>, <fpage>7</fpage>–<lpage>35</lpage>. <comment>doi:10.1002/ev.72</comment>
</citation>
</ref>
<ref id="bibr21-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Christie</surname>
<given-names>C. A.</given-names>
</name>
<name>
<surname>Fleischer</surname>
<given-names>D. N.</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Insight into evaluation practice: A content analysis of designs and methods used in evaluation studies published in North American evaluation-focused journals</article-title>. <source>American Journal of Evaluation</source>, <volume>31</volume>, <fpage>326</fpage>–<lpage>346</lpage>. <comment>doi:0.1177/1098214010369170</comment>
</citation>
</ref>
<ref id="bibr22-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Conder</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Milner</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Mirfin-Veitch</surname>
<given-names>B.</given-names>
</name>
</person-group> (<year>2011</year>). <article-title>Reflections on a participatory project: The rewards and challenges for the lead researchers</article-title>. <source>Journal of Intellectual and Developmental Disability</source>, <volume>36</volume>, <fpage>39</fpage>–<lpage>48</lpage>. <comment>doi:10.3109/13668250.2010.548753</comment>
</citation>
</ref>
<ref id="bibr23-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cook</surname>
<given-names>J. A</given-names>
</name>
<name>
<surname>Carey</surname>
<given-names>M. A.</given-names>
</name>
<name>
<surname>Razzano</surname>
<given-names>L. A.</given-names>
</name>
<name>
<surname>Burke</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Blyler</surname>
<given-names>C. R.</given-names>
</name>
</person-group> (<year>2002</year>). <article-title>The pioneer: The employment intervention demonstration program</article-title>. <source>New Directions for Evaluation</source>, <volume>94</volume>, <fpage>31</fpage>–<lpage>44</lpage>. <comment>doi:10.1002/ev.49</comment>
</citation>
</ref>
<ref id="bibr24-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cousins</surname>
<given-names>J. B.</given-names>
</name>
<name>
<surname>Whitmore</surname>
<given-names>E.</given-names>
</name>
</person-group> (<year>1998</year>). <article-title>Framing participatory evaluation</article-title>. <source>New Directions for Evaluation</source>, <volume>80</volume>, <fpage>5</fpage>–<lpage>23</lpage>. <comment>doi:10.1002/ev.1114</comment>
</citation>
</ref>
<ref id="bibr25-1098214012461558">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Creswell</surname>
<given-names>J. W.</given-names>
</name>
<name>
<surname>Plano Clark</surname>
<given-names>V. L.</given-names>
</name>
</person-group> (<year>2011</year>). <source>Designing and conducting mixed methods research</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr26-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dadich</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Muir</surname>
<given-names>K.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Tricks of the trade in community mental health research: Working with mental health services and clients</article-title>. <source>Evaluation &amp; the Health Professions</source>, <volume>32</volume>, <fpage>38</fpage>–<lpage>58</lpage>. <comment>doi:10.1177/0163278708328738</comment>
</citation>
</ref>
<ref id="bibr27-1098214012461558">
<citation citation-type="other">
<collab collab-type="author">Developmental Disabilities Assistance and Bill of Rights Act, Public Law 206-402</collab>, <year>2000</year>.</citation>
</ref>
<ref id="bibr28-1098214012461558">
<citation citation-type="web">
<collab collab-type="author">Equal Employment Opportunity Commission</collab>. (<year>1997</year>). <source>EEOC enforcement guidance on the Americans with disabilities act and psychiatric disabilities</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Author</publisher-name>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://www.eeoc.gov/policy/docs/psych.html">http://www.eeoc.gov/policy/docs/psych.html</ext-link>
</citation>
</ref>
<ref id="bibr29-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Finlay</surname>
<given-names>W. M. L.</given-names>
</name>
<name>
<surname>Lyons</surname>
<given-names>E.</given-names>
</name>
</person-group> (<year>2001</year>). <article-title>Methodological issues in interviewing and using self-report questionnaires with people with mental retardation</article-title>. <source>Psychological Assessment</source>, <volume>13</volume>, <fpage>319</fpage>–<lpage>335</lpage>. <comment>doi:10.1037/1040-3590.13.3.319</comment>
</citation>
</ref>
<ref id="bibr30-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fredericks</surname>
<given-names>K. A.</given-names>
</name>
</person-group> (<year>2005</year>). <article-title>Network analysis of a demonstration program for the developmentally disabled</article-title>. <source>New Directions for Evaluation</source>, <volume>107</volume>, <fpage>55</fpage>–<lpage>68</lpage>. <comment>doi:10.1002/ev.161</comment>
</citation>
</ref>
<ref id="bibr31-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fredericks</surname>
<given-names>K. A.</given-names>
</name>
<name>
<surname>Deegan</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Carman</surname>
<given-names>J. G.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Using system dynamics as an evaluation tool: Experience from a demonstration program</article-title>. <source>American Journal of Evaluation</source>, <volume>29</volume>, <fpage>251</fpage>–<lpage>267</lpage>. <comment>doi:10.1177/1098214008319446</comment>
</citation>
</ref>
<ref id="bibr32-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fleischer</surname>
<given-names>D. N.</given-names>
</name>
<name>
<surname>Christie</surname>
<given-names>C. A.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Evaluation use: Results from a survey of U.S. American Evaluation Association members</article-title>. <source>American Journal of Evaluation</source>, <volume>30</volume>, <fpage>158</fpage>–<lpage>175</lpage>. <comment>doi:10.1177/1098214008331009</comment>
</citation>
</ref>
<ref id="bibr33-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gilbert</surname>
<given-names>T.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Involving people with learning disabilities in research: Issues and possibilities</article-title>. <source>Health and Social Care in the Community</source>, <volume>12</volume>, <fpage>298</fpage>–<lpage>308</lpage>.</citation>
</ref>
<ref id="bibr34-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gill</surname>
<given-names>C. J.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Invisible ubiquity: The surprising relevance of disability issues in evaluation</article-title>. <source>American Journal of Evaluation</source>, <volume>20</volume>, <fpage>279</fpage>–<lpage>287</lpage>. <comment>doi:10.1177/109821409902000209</comment>
</citation>
</ref>
<ref id="bibr35-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harry</surname>
<given-names>B.</given-names>
</name>
</person-group> (<year>2002</year>). <article-title>Trends and issues in serving culturally diverse families of children with disabilities</article-title>. <source>Journal of Special Education</source>, <volume>36</volume>, <fpage>131</fpage>–<lpage>138</lpage>.</citation>
</ref>
<ref id="bibr36-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harvey</surname>
<given-names>P. D.</given-names>
</name>
<name>
<surname>Wingo</surname>
<given-names>A. P.</given-names>
</name>
<name>
<surname>Burdick</surname>
<given-names>K. E.</given-names>
</name>
<name>
<surname>Baldessarini</surname>
<given-names>R. J.</given-names>
</name>
</person-group> (<year>2010</year>). <article-title>Cognition and disability in bipolar disorder: Lessons from schizophrenia research</article-title>. <source>Bipolar Disorders</source>, <volume>12</volume>, <fpage>364</fpage>–<lpage>75</lpage>. <comment>doi:10.1111/j.1399-5618.2010.00831.x</comment>
</citation>
</ref>
<ref id="bibr37-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hassouneh</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Alcala-Moss</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>McNeff</surname>
<given-names>E.</given-names>
</name>
</person-group> (<year>2011</year>). <article-title>Practical strategies for promoting full inclusion of individuals with disabilities in community-based participatory intervention research</article-title>. <source>Research in Nursing &amp; Health</source>, <volume>34</volume>, <fpage>253</fpage>–<lpage>265</lpage>. <comment>doi:10.1002/nur.20434</comment>
</citation>
</ref>
<ref id="bibr38-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heinz</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>A process evaluation of a parenting group for parents with intellectual disabilities</article-title>. <source>Evaluation and Program Planning</source>, <volume>26</volume>, <fpage>263</fpage>–<lpage>274</lpage>. <comment>doi:10.1016/S0149-7189(03)00030-2</comment>
</citation>
</ref>
<ref id="bibr39-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heller</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Pederson</surname>
<given-names>E. L.</given-names>
</name>
<name>
<surname>Miller</surname>
<given-names>A. B.</given-names>
</name>
</person-group> (<year>1996</year>). <article-title>Guidelines from the consumer: Improving consumer involvement in research and training for persons with mental retardation</article-title>. <source>Mental Retardation</source>, <volume>34</volume>, <fpage>141</fpage>–<lpage>148</lpage>.</citation>
</ref>
<ref id="bibr40-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author"><name><surname>Jurkowski</surname><given-names>J. M.</given-names></name><name><surname>Ferguson</surname><given-names>P.</given-names></name></person-group> (<year>2008</year>). <article-title>Photovoice as participatory action research tool for engaging people with intellectual disabilities in research and program development</article-title>. <source>Intellectual and Disabilities</source>, <volume>46</volume>, <fpage>1</fpage>–<lpage>11</lpage>. <comment>doi:10.1352/0047-6765 (2008) 46[1:PAPART] 2.0.CO;2</comment>
</citation>
</ref>
<ref id="bibr41-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lepage-Chabriais</surname>
<given-names>M.</given-names>
</name>
</person-group> (<year>2005</year>). <article-title>Evaluation of children’s stay in institutions: What is working?</article-title> <source>Evaluation Review</source>, <volume>29</volume>, <fpage>454</fpage>–<lpage>466</lpage>. <comment>doi:10.1177/0193841X05279082</comment>
</citation>
</ref>
<ref id="bibr42-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Linhorst</surname>
<given-names>D. M.</given-names>
</name>
<name>
<surname>Eckert</surname>
<given-names>A.</given-names>
</name>
</person-group> (<year>2002</year>). <article-title>Involving people with severe mental illness in evaluation and performance improvement</article-title>. <source>Evaluation &amp; The Health Professions</source>, <volume>25</volume>, <fpage>284</fpage>–<lpage>301</lpage>. <comment>doi:10.1177/0163278702025003003</comment>
</citation>
</ref>
<ref id="bibr43-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kiernan</surname>
<given-names>C.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Participation in research by people with learning disability: Origins and issues</article-title>. <source>British Journal of Learning Disabilities</source>, <volume>27</volume>, <fpage>43</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr44-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>MacNeil</surname>
<given-names>C.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Surfacing the realpolitik: Democratic evaluation in an antidemocratic climate</article-title>. <source>New Directions for Evaluation</source>, <volume>85</volume>, <fpage>51</fpage>–<lpage>62</lpage>. <comment>doi:10.1002/ev.1161</comment>
</citation>
</ref>
<ref id="bibr45-1098214012461558">
<citation citation-type="other">
<person-group person-group-type="author">
<name>
<surname>Mcdonald</surname>
<given-names>K. E.</given-names>
</name>
<name>
<surname>Keys</surname>
<given-names>C. B.</given-names>
</name>
<name>
<surname>Henry</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Gatekeepers of science: Attitudes toward the research participation of adults with intellectual disability</article-title>. <italic>American Journal on Mental Retardation</italic>, <volume>113</volume>, <fpage>466</fpage>–<lpage>478</lpage>. <comment>doi:10.1352/2008.113</comment>
</citation>
</ref>
<ref id="bibr46-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mertens</surname>
<given-names>D. M.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Inclusive evaluation: Implications of transformative theory for evaluation</article-title>. <source>American Journal of Evaluation</source>, <volume>20</volume>, <fpage>1</fpage>–<lpage>14</lpage>. <comment>doi: 10.1177/109821409902000102</comment>
</citation>
</ref>
<ref id="bibr47-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mertens</surname>
<given-names>D. M.</given-names>
</name>
</person-group> (<year>2007a</year>). <article-title>Transformative considerations: Inclusion and social justice</article-title>. <source>American Journal of Evaluation</source>, <volume>28</volume>, <fpage>86</fpage>–<lpage>90</lpage>. <comment>doi:10.1177/1098214006298058</comment>
</citation>
</ref>
<ref id="bibr48-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mertens</surname>
<given-names>D. M.</given-names>
</name>
</person-group> (<year>2007b</year>). <article-title>Transformative paradigm: Mixed methods and social justice</article-title>. <source>Journal of Mixed Methods Research</source>, <volume>1</volume>, <fpage>212</fpage>–<lpage>225</lpage>. <comment>doi:10.1177/1558689807302811</comment>
</citation>
</ref>
<ref id="bibr49-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Perry</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Felce</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>2002</year>). <article-title>Subjective and objective quality of life assessment: Responsiveness, response bias, and resident: Proxy concordance</article-title>. <source>Mental Retardation</source>, <volume>40</volume>, <fpage>445</fpage>–<lpage>456</lpage>. <comment>doi:0.1352/00476765 (2002) 040&lt;0445:SAOQOL&gt;2.0.CO;2</comment>
</citation>
</ref>
<ref id="bibr50-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Read</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Maslin-Prothero</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>2011</year>). <article-title>The involvement of users and carers in health and social research: The realities of inclusion and engagement</article-title>. <source>Qualitative Health Research</source>, <volume>21</volume>, <fpage>704</fpage>–<lpage>713</lpage>. <comment>doi:10.1177/1049732310391273</comment>
</citation>
</ref>
<ref id="bibr51-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schalock</surname>
<given-names>R. L.</given-names>
</name>
<name>
<surname>Bonham</surname>
<given-names>G. S.</given-names>
</name>
<name>
<surname>Marchand</surname>
<given-names>C. B.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Consumer based quality of life assessment: A path model of perceived satisfaction</article-title>. <source>Evaluation and Program Planning</source>, <volume>23</volume>, <fpage>77</fpage>–<lpage>87</lpage>. <comment>doi:10.1016/S0149-7189 (99) 00041-5</comment>
</citation>
</ref>
<ref id="bibr52-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smith</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>O’Flynn</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>The use of qualitative strategies in participant and emancipatory research to evaluate developmental disability service organizations</article-title>. <source>European Journal of Work and Organizational Psychology</source>, <volume>9</volume>, <fpage>515</fpage>–<lpage>526</lpage>. <comment>doi: 10.1080/13594320050203111</comment>
</citation>
</ref>
<ref id="bibr53-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stancliffe</surname>
<given-names>R. J.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Proxy respondents and quality of life</article-title>. <source>Evaluation and Program Planning</source>, <volume>23</volume>, <fpage>89</fpage>–<lpage>93</lpage>. <comment>doi:10.1016/S0149-7189 (99) 00042-7</comment>
</citation>
</ref>
<ref id="bibr54-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author"><name><surname>Taut</surname><given-names>S.</given-names></name></person-group> (<year>2008</year>). <article-title>What have we learned about stakeholder involvement in program evaluation?</article-title> <source>Studies in Educational Evaluation</source>, <volume>34</volume>, <fpage>224</fpage>–<lpage>230</lpage>. <comment>doi:10.1016/j.stueduc.2008.10.007</comment></citation>
</ref>
<ref id="bibr54a-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Toal</surname>
<given-names>S. A.</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>The validation of the evaluation involvement scale for use in multisite settings</article-title>. <source>American Journal of Evaluation</source>, <volume>30</volume>, <fpage>349</fpage>–<lpage>362</lpage>. <comment>doi:10.1177/1098214009337031</comment>
</citation>
</ref>
<ref id="bibr55-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Walmsley</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Involving users with learning difficulties in health improvement: Lessons from inclusive learning disability research</article-title>. <source>Nursing Inquiry</source>, <volume>11</volume>, <fpage>54</fpage>–<lpage>64</lpage>. <comment>doi: 10.1111/j.1440-1800.2004.00197.x</comment>
</citation>
</ref>
<ref id="bibr56-1098214012461558">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Walmsley</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>K.</given-names>
</name>
</person-group> (<year>2003</year>). <source>Inclusive research with people with learning disabilities: Past, present and futures</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Jessica Kingsley</publisher-name>.</citation>
</ref>
<ref id="bibr57-1098214012461558">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ware</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Ascertaining the views of people with profound and multiple learning developmental disabilities</article-title>. <source>British Journal of Learning Disabilities</source>, <volume>32</volume>, <fpage>175</fpage>–<lpage>179</lpage>. <comment>doi: 10.1111/j.1468-3156.2004.00316.x</comment> </citation>
</ref>
<ref id="bibr58-1098214012461558">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wehmeyer</surname>
<given-names>M. L.</given-names>
</name>
</person-group> (<year>1995</year>). <source>The ARC's self-determination scale: Procedural guidelines</source>. <publisher-loc>Arlington, TX</publisher-loc>: <publisher-name>The Arc National Headquarters</publisher-name>.</citation>
</ref>
<ref id="bibr59-1098214012461558">
<citation citation-type="web">
<collab collab-type="author">World Health Organization</collab>. (<year>2011</year>). <source>World report on disability</source>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://whqlibdoc.who.int/hq/2011/WHO_NMH_VIP_11.01_eng.pdf">http://whqlibdoc.who.int/hq/2011/WHO_NMH_VIP_11.01_eng.pdf</ext-link>
</citation>
</ref>
<ref id="bibr60-1098214012461558">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Yarbrough</surname>
<given-names>D. B.</given-names>
</name>
<name>
<surname>Shulha</surname>
<given-names>L. M.</given-names>
</name>
<name>
<surname>Hopson</surname>
<given-names>R. K.</given-names>
</name>
<name>
<surname>Caruthers</surname>
<given-names>F. A.</given-names>
</name>
</person-group> (<year>2011</year>). <source>The program evaluation standards: A guide for evaluators and evaluation users</source> (<edition>3rd ed.</edition>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>