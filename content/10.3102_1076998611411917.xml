<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JEB</journal-id>
<journal-id journal-id-type="hwp">spjeb</journal-id>
<journal-title>Journal of Educational and Behavioral Statistics</journal-title>
<issn pub-type="ppub">1076-9986</issn>
<issn pub-type="epub">1935-1054</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.3102/1076998611411917</article-id>
<article-id pub-id-type="publisher-id">10.3102_1076998611411917</article-id>
<title-group>
<article-title>Identification of Average Treatment Effects in Social Experiments Under Alternative Forms of Attrition</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Huber</surname>
<given-names>Martin</given-names>
</name>
</contrib>
<aff id="aff1-1076998611411917">University of St. Gallen, Switzerland</aff>
</contrib-group>
<author-notes>
<fn fn-type="other" id="fn1-1076998611411917">
<p>MARTIN HUBER is assistant professor of quantitative methods in economics at the University of St. Gallen, Department of Economics, Varnbuelstrasse 14, CH-9000 St. Gallen; martin.huber@unisg.ch. His research interests are non- and semiparametric microeconometrics, in particular methods for the evaluation of treatment effects.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>6</month>
<year>2012</year>
</pub-date>
<volume>37</volume>
<issue>3</issue>
<fpage>443</fpage>
<lpage>474</lpage>
<history>
<date date-type="received">
<day>30</day>
<month>06</month>
<year>2010</year>
</date>
<date date-type="rev-recd">
<day>25</day>
<month>1</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>04</month>
<year>2011</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">American Educational Research Association</copyright-holder>
</permissions>
<abstract>
<p>As any empirical method used for causal analysis, social experiments are prone to attrition which may flaw the validity of the results. This article considers the problem of partially missing outcomes in experiments. First, it systematically reveals under which forms of attrition—in terms of its relation to observable and/or unobservable factors—experiments do (not) yield causal parameters. Second, it shows how the various forms of attrition can be controlled for by different methods of inverse probability weighting (IPW) that are tailored to the specific missing data problem at hand. In particular, it discusses IPW methods that incorporate instrumental variables (IVs) when attrition is related to unobservables, which has been widely ignored in the experimental literature before.</p>
</abstract>
<kwd-group>
<kwd>experiments</kwd>
<kwd>attrition</kwd>
<kwd>inverse probability weighting</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1076998611411917">
<title>1. Introduction</title>
<p>Causal inference based on experiments, which dates at least back to <xref ref-type="bibr" rid="bibr54-1076998611411917">Neyman (1923)</xref> and <xref ref-type="bibr" rid="bibr20-1076998611411917">Fisher (1925</xref>, <xref ref-type="bibr" rid="bibr21-1076998611411917">1935</xref>), is a cornerstone of the evaluation of policy interventions. It has been used in many different fields of research such as medicine, welfare policies, labor economics, education, and development economics; see for instance, the literature surveys in <xref ref-type="bibr" rid="bibr18-1076998611411917">Duflo (2006)</xref>, <xref ref-type="bibr" rid="bibr28-1076998611411917">Harrison and List (2004)</xref>, and Imbens and Wooldridge (<xref ref-type="bibr" rid="bibr44-1076998611411917">2009</xref>). If well conducted and appropriate to the research question, experiments are widely regarded to be the most reliable source of causal inference; see for instance, <xref ref-type="bibr" rid="bibr13-1076998611411917">Cochran and Chambers (1965)</xref>, <xref ref-type="bibr" rid="bibr24-1076998611411917">Freedman (2006)</xref>, <xref ref-type="bibr" rid="bibr66-1076998611411917">Rubin (2008)</xref>, and <xref ref-type="bibr" rid="bibr42-1076998611411917">Imbens (2009)</xref>, as they invoke a minimum of identifying assumptions. They neither impose functional form assumptions as regression models nor particular correlations between observables and unobservables, which have to be assumed in observational studies. However, as any empirical method, experiments are prone to attrition which may flaw the validity of the results, see the discussion in <xref ref-type="bibr" rid="bibr29-1076998611411917">Hausman and Wise (1979)</xref>.</p>
<p>In this article, we consider the problem that the outcome of interest is only partially observed due to attrition, whereas the treatment and several socioeconomic characteristics, which are typically measured in baseline surveys prior to the intervention, are fully observed. Thus, attrition here refers to the censoring problem due to missing outcomes, but not to truncation, that is, the absence of information on the outcome, the treatment, <italic>and</italic> further variables for some subpopulation. The missing outcome problem arises, for instance, when individuals with known pretreatment characteristics are randomly assigned to an active labor market policy (such as a training), but some of them do not participate in a follow-up survey that measures labor market success (e.g., employment or income) several months or years later due to reluctance or relocation. Similar problems are inherent in clinical trials when some of the participants randomly assigned to medical treatments pass away before the health outcome is measured. Finally, suppose that high school students are randomly provided with private school vouchers and that we are interested in their scores obtained in college entrance examinations several years later. Attrition in the outcome arises if a subsample of students decides not to take the exam.</p>
<p>Various remedies have been proposed to deal with attrition in outcome data. Multiple imputation of missing values goes back to <xref ref-type="bibr" rid="bibr62-1076998611411917">Rubin (1977</xref>, <xref ref-type="bibr" rid="bibr63-1076998611411917">1978</xref>); see also <xref ref-type="bibr" rid="bibr65-1076998611411917">Rubin (1996)</xref> for a more recent review. Based on Bayesian techniques, the idea is to use multiple attrition models to impute multiple sets of plausible values for the missing data. This allows computing a probability interval for the parameter of interest. Several studies use single imputation methods such as regression adjustments to correct for attrition. For example, <xref ref-type="bibr" rid="bibr29-1076998611411917">Hausman and Wise (1979)</xref> use a probability model of attrition in conjunction with a random effects model of individual response in their evaluation of the Gary Income Maintenance experiment. <xref ref-type="bibr" rid="bibr2-1076998611411917">Angrist, Bettinger, and Kremer (2006)</xref> analyze the effects of school vouchers on test scores in college entrance examinations in Columbia and apply tobit regression to control for the fact that voucher winners are more likely to take the tests than voucher losers. Another approach is based on weighting observations according to their likelihood to respond, that is, by the inverse of their conditional response probability; see for instance, <xref ref-type="bibr" rid="bibr67-1076998611411917">Scharfstein, Rotnitzky, and Robins (1999)</xref>. The idea of inverse probability weighting (IPW) goes back to <xref ref-type="bibr" rid="bibr37-1076998611411917">Horvitz and Thompson (1952)</xref>, who first proposed an estimator of the population mean in the presence of nonrandomly missing data.</p>
<p>
<xref ref-type="bibr" rid="bibr4-1076998611411917">Barnard, Frangakis, Hill, and Rubin (2003)</xref> use a principal stratification framework (see <xref ref-type="bibr" rid="bibr23-1076998611411917">Frangakis &amp; Rubin, 2002</xref>) to estimate treatment effects under attrition (and further missing data and noncompliance problems) by means of a parametric mixture model. Still based on principal stratification, <xref ref-type="bibr" rid="bibr50-1076998611411917">Mealli and Pacini (2008)</xref> exploit discrete instruments to identify effects for particular subgroups under various assumptions. Finally, the estimation of nonparametric bounds (see <xref ref-type="bibr" rid="bibr35-1076998611411917">Horowitz &amp; Manski, 1998</xref>, <xref ref-type="bibr" rid="bibr36-1076998611411917">2000</xref>) does not require a model for attrition at the cost of sacrificing point identification even for particular subpopulations. Empirical studies estimating bounds include <xref ref-type="bibr" rid="bibr2-1076998611411917">Angrist et al. (2006)</xref>, <xref ref-type="bibr" rid="bibr48-1076998611411917">Lee (2009)</xref>, and <xref ref-type="bibr" rid="bibr27-1076998611411917">Grogger (2009)</xref>, who assesses the effectiveness of Connecticut's Jobs First experiment. See also <xref ref-type="bibr" rid="bibr73-1076998611411917">Zhang and Rubin (2003)</xref> and <xref ref-type="bibr" rid="bibr74-1076998611411917">Zhang, Rubin, and Mealli (2008)</xref> who discuss the identification of bounds in a principal stratification framework.</p>
<p>This article makes two contributions to the literature on attrition in social experiments. First, it reveals systematically under which forms of attrition—in terms of its relation to observable or unobservable factors—experiments do (not) yield causal parameters, as a comprehensive discussion on attrition in experiments and its implications for identification is still lacking. Starting from a general treatment effect model, it makes explicit and formally discusses under which conditions experiments identify average treatment effects (ATEs) on the entire population and/or on the subpopulation of respondents.</p>
<p>Second, the article shows how the alternative forms of attrition can be controlled for by IPW methods, that is, by reweighting observations by the inverse of their conditional response and/or treatment probabilities. Depending on whether attrition is related to all or subsets of observable and unobservable variables, we will apply different weighting approaches, each of which is tailored to the specific attrition problem at hand. This provides practitioners with straightforward solutions depending on the suspected missing data problem. Simulation results presented further below suggest that assuming the wrong attrition process (e.g., by neglecting attrition related to unobservables) may do worse than not controlling for attrition at all. This underlines the importance of carefully thinking about the nature of attrition in order to choose an attrition model that is appropriate for the empirical application considered.</p>
<p>The use of IPW to control for attrition related to observables, that is, when outcomes are missing at random (MAR, see <xref ref-type="bibr" rid="bibr61-1076998611411917">Rubin, 1976</xref>), is well established in the literature; see for instance, <xref ref-type="bibr" rid="bibr55-1076998611411917">Robins and Rotnitzky (1995)</xref>, Robins, Rotnitzky, and Zhao (<xref ref-type="bibr" rid="bibr56-1076998611411917">1995</xref>), <xref ref-type="bibr" rid="bibr59-1076998611411917">Rotnitzky and Robins (1995)</xref>, <xref ref-type="bibr" rid="bibr67-1076998611411917">Scharfstein et al. (1999)</xref>, and <xref ref-type="bibr" rid="bibr71-1076998611411917">Wooldridge (2002</xref>, <xref ref-type="bibr" rid="bibr72-1076998611411917">2007</xref>). In contrast, the case when attrition is related to unobservables such that identification requires an instrument for attrition (which does not directly affect the outcome variable) has been widely ignored in experiments. One of the very rare examples is <xref ref-type="bibr" rid="bibr17-1076998611411917">DiNardo, McCrary, and Sanbonmatsu (2006)</xref> who use conventional sample selection correction techniques based on regression (see Heckman, 1976). The present work is the first that discusses the usefulness and application of IPW under attrition on unobservables in an experimental context. This approach is closely related to <xref ref-type="bibr" rid="bibr38-1076998611411917">Huber (2009)</xref>, who uses IPW to control for sample selection and attrition in observational studies.</p>
<p>Attrition related to unobservables is a problem likely to be found in many empirical problems. For example, suppose that motivation is not observed in a labor market policy or education experiment where the outcomes of interest are employment and earnings or test scores and educational achievement, respectively. While there is little doubt that motivation is correlated with these outcomes, there are also good reasons to believe that it affects the response behavior. For example, the least motivated individuals in a labor market policy experiment might be most reluctant to respond to the follow-up survey and unmotivated students are likely to be less inclined to participate in an exam than others. These and similar examples motivate the use of novel IPW methods based on continuous instruments for attrition. Unfortunately, such instruments, which are ideally randomly assigned in a similar way as the treatment, are rare in experiments conducted to date. Therefore, we argue that the creation of randomized instruments should be considered in the design of future experiments. Two potential instruments are the number of phone calls in follow-up surveys or financial incentives to respond to a survey.</p>
<p>Even though this study covers a range of attrition problems that are relevant in many empirical applications, the exposition is not exhaustive, as one can think of many different ways of modeling response behavior. For an alternative set of restrictions, see <xref ref-type="bibr" rid="bibr40-1076998611411917">Imai (2009)</xref> who assumes that attrition is related to the outcome but is independent of the treatment conditional on the outcome and other observable variables. As the author argues, this is plausible when response behavior is strongly driven by the outcome variable (e.g., when considering the outcome “voting,” voters may be more willing to participate in postelection surveys than nonvoters), whereas the treatment represents only a mild intervention that is unlikely to affect attrition (e.g., a psychological voting stimulus). In contrast, we focus on scenarios where the treatment drives attrition even conditional on other variables (with the exception of the introductory case in which outcomes are missing completely at random [MCAR]). Whereas identification in <xref ref-type="bibr" rid="bibr40-1076998611411917">Imai (2009)</xref> relies on controlling for the dependence between attrition and the treatment, we impose different assumptions that allow us to control for the dependence between attrition and the outcome.</p>
<p>The remainder of this article is organized as follows. The next section introduces a general treatment effect model along with attrition. Section 3 discusses identification under random attrition and attrition related to observables. Identification under attrition related to unobservables is treated in Section 4. Section 5 presents simulation studies based on both generated and empirical data. An application to a U.S. labor market policy experiment is provided in Section 6. Section 7 concludes.</p>
</sec>
<sec id="section2-1076998611411917">
<title>2. Model</title>
<p>Let <italic>D</italic> denote a treatment indicator, either 1 (treatment) or 0 (nontreatment), which is randomly assigned to an independent and identically distributed (i.i.d.) sample of <italic>n</italic> units, indexed by <inline-formula id="inline-formula1-1076998611411917">
<mml:math id="mml-inline1-1076998611411917">
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mo stretchy="false">…</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula>. We are interested in the effect of <italic>D</italic> on some outcome variable <italic>Y</italic>. Utilizing the potential outcome framework of <xref ref-type="bibr" rid="bibr60-1076998611411917">Rubin (1974)</xref>, we denote the potential outcome for individual <italic>i</italic> and some hypothetical treatment <italic>D</italic> = <italic>d</italic> as <inline-formula id="inline-formula2-1076998611411917">
<mml:math id="mml-inline2-1076998611411917">
<mml:msubsup>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
</mml:msubsup>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula3-1076998611411917">
<mml:math id="mml-inline3-1076998611411917">
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula>. The difference <inline-formula id="inline-formula4-1076998611411917">
<mml:math id="mml-inline4-1076998611411917">
<mml:msubsup>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:msubsup>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
<mml:mn>0</mml:mn>
</mml:msubsup>
</mml:math>
</inline-formula> would identify the individual treatment effect, but is unknown to the researcher, because each individual is either treated or not treated and cannot appear in both states of the world at the same time.</p>
<p>However, under particular assumptions a randomized experiment allows identifying treatment effects by the fact that the potential outcomes are independent of the treatment assignment. Throughout this article we will therefore rule out any interaction effects between the individuals participating in the experiment such as spill over, peer, or general equilibrium effects. This implies the validity of the Stable Unit Treatment Valuation Assumption (SUTVA); see, for instance, <xref ref-type="bibr" rid="bibr64-1076998611411917">Rubin (1990)</xref>. Furthermore, we will assume that treatment compliance is perfect, that is, everybody being assigned takes the treatment and everybody not assigned does not. If noncompliance occurred, identification would be further complicated. In this case, one might at best recover the effect on the subpopulation of the compliers (those behaving according to the assignment), given that the treatment assignment is a valid instrument for the realized treatment state. Even though we are fully aware that interaction effects and noncompliance in experiments (see, for instance, <xref ref-type="bibr" rid="bibr57-1076998611411917">Robins &amp; Tsiatis, 1991</xref>) may occur in practice, they are beyond the scope of this article. In the subsequent discussion, we will exclusively focus on the identification problems related to attrition in the outcome variable.</p>
<p>Under random treatment assignment, the expected potential outcomes are equal to the expected conditional outcomes given the treatment. Formally, <inline-formula id="inline-formula5-1076998611411917">
<mml:math id="mml-inline5-1076998611411917">
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mi>d</mml:mi>
</mml:msup>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula> for <inline-formula id="inline-formula6-1076998611411917">
<mml:math id="mml-inline6-1076998611411917">
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula>. Therefore, the ATE, denoted as <inline-formula id="inline-formula7-1076998611411917">
<mml:math id="mml-inline7-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
</mml:math>
</inline-formula>, is identified by <inline-formula id="inline-formula8-1076998611411917">
<mml:math id="mml-inline8-1076998611411917">
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula> and is consistently estimated by the mean difference of treated and nontreated outcomes in the sample. Causal inference becomes less straightforward when the outcome variable is only partially observed due to attrition. The problems arising for identification and the remedies that may be used depend on how attrition is related to the treatment and the other parameters affecting the outcome.</p>
<p>To formally discuss the various forms of attrition, we consider a general treatment effect model. Assume that the outcome <italic>Y</italic> is an unknown function of the treatment, a vector of observed covariates <italic>X</italic>, and an unobserved term <italic>U</italic>.<disp-formula id="disp-formula1-1076998611411917">
<label>1</label>
<mml:math id="mml-disp1-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula1-1076998611411917" xlink:href="10.3102_1076998611411917-eq1.tif"/>
</disp-formula>where <inline-formula id="inline-formula9-1076998611411917">
<mml:math id="mml-inline9-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> is a general function. Throughout this article we will maintain the assumption that the treatment is randomly assigned:<list list-type="bullet">
<list-item>
<p>Assumption 1:</p>
</list-item>
</list>
<disp-formula id="disp-formula2-1076998611411917">
<mml:math id="mml-disp2-1076998611411917">
<mml:mi>D</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula2-1076998611411917" xlink:href="10.3102_1076998611411917-eq2.tif"/>
</disp-formula>that is, treatment <italic>D</italic> is independent of the joint distribution of <italic>X</italic> and <italic>U</italic>, where “<inline-formula id="inline-formula10-1076998611411917">
<mml:math id="mml-inline10-1076998611411917">
<mml:mi mathvariant="normal">⊥</mml:mi>
</mml:math>
</inline-formula>” denotes independence. When using the potential outcomes notation, this implies that <inline-formula id="inline-formula11-1076998611411917">
<mml:math id="mml-inline11-1076998611411917">
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mi>D</mml:mi>
</mml:math>
</inline-formula>. In Section 3, we will also assume that <italic>X</italic> contains at least one continuously distributed variable. In Section 4, <italic>X</italic> may or may not be continuous.</p>
<p>This model provides us with a useful framework for the evaluation of policy interventions. Consider for instance the identification of the effect of vouchers for private schooling (<italic>D</italic>) to which high school students are randomly assigned on test scores in college entrance examinations (<italic>Y</italic>) several years later. Empirical evidence suggests that private schooling has an effect on test scores (see Angrist et al., 2006). Thus, we suspect the test scores to be a function of the treatment, but also of observed baseline characteristics (<italic>X</italic>) such as age and gender, which are usually provided in surveys accompanying randomized trials. Furthermore, also unobserved factors <italic>U</italic> such as motivation most likely influence the test scores. As a second example, consider labor market experiments where individuals are randomly assigned into a training; see, for instance, <xref ref-type="bibr" rid="bibr7-1076998611411917">Bloom et al. (1997)</xref>. The labor market outcomes (<italic>Y</italic>), for example, employment, unemployment, or income, are a function of training (<italic>D</italic>); socioeconomic characteristics like age, education, and gender (<italic>X</italic>); and unobservables (<italic>U</italic>) such as innate ability.</p>
<p>To introduce attrition into our framework, let <italic>R</italic> denote a binary response variable which is <inline-formula id="inline-formula12-1076998611411917">
<mml:math id="mml-inline12-1076998611411917">
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula> if <italic>Y</italic> is observed (nonattrition) and <inline-formula id="inline-formula13-1076998611411917">
<mml:math id="mml-inline13-1076998611411917">
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> otherwise. In the context of the school voucher experiment, <italic>R</italic> represents test participation, as test scores are only observed conditional on taking part. In contrast, we will assume that (<italic>D</italic>, <italic>X</italic>) is observed for all individuals. The fact that only <inline-formula id="inline-formula14-1076998611411917">
<mml:math id="mml-inline14-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula> is known instead of <inline-formula id="inline-formula15-1076998611411917">
<mml:math id="mml-inline15-1076998611411917">
<mml:mi>Y</mml:mi>
</mml:math>
</inline-formula> may flaw the validity of experimental results. The experiment bears external validity if it identifies the ATE on the entire population (<inline-formula id="inline-formula16-1076998611411917">
<mml:math id="mml-inline16-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula>) in spite of attrition. It bears internal validity if the ATE on the respondents, <inline-formula id="inline-formula17-1076998611411917">
<mml:math id="mml-inline17-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula>, is identified. Whether external and/or internal validity holds depends on the nature of attrition. The following two sections will impose different assumptions on the relation between attrition and observed and unobserved factors in the treatment effect model and will discuss the implications for identification. When identification fails, we will propose IPW methods to correct for attrition bias and also discuss the required conditions.</p>
<p>While there is little doubt that Δ is an interesting policy parameter (even more so in experiments, where the ATE on the entire population is equal to the ATE on the treated population), the policy relevance of <inline-formula id="inline-formula18-1076998611411917">
<mml:math id="mml-inline18-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> is less clear as it only refers to the particular subpopulation of respondents. The latter might differ from the entire population in characteristics that are important for the effectiveness of the treatment such that Δ and <inline-formula id="inline-formula19-1076998611411917">
<mml:math id="mml-inline19-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> need not necessarily be similar. Therefore, we generally prefer to identify Δ rather than <inline-formula id="inline-formula20-1076998611411917">
<mml:math id="mml-inline20-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> if we have a choice. Indeed, with the exception of <xref ref-type="bibr" rid="bibr52-1076998611411917">Newey (2007)</xref>, the latter parameter has rarely been considered, neither in the sample selection literature, which usually assumes effect homogeneity across subpopulations (such that <inline-formula id="inline-formula21-1076998611411917">
<mml:math id="mml-inline21-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>), nor in the standard treatment evaluation framework that abstracts from attrition.</p>
<p>However, under most forms of attrition, the identification of Δ requires somewhat stronger assumptions than the identification of <inline-formula id="inline-formula22-1076998611411917">
<mml:math id="mml-inline22-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>, which is intuitive because only <inline-formula id="inline-formula23-1076998611411917">
<mml:math id="mml-inline23-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula> is observed. If these stronger assumptions are not satisfied, identification among respondents appears to be the best we can get, see also the discussion in <xref ref-type="bibr" rid="bibr52-1076998611411917">Newey (2007)</xref>. In this case, it often seems preferable to identify at least <inline-formula id="inline-formula24-1076998611411917">
<mml:math id="mml-inline24-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> rather than not recovering any effect at all. Depending on the empirical context, this parameter may still bear policy relevance. For example, in the school voucher experiment it represents the ATE on the test takers that might be exactly what politicians want to learn about.</p>
</sec>
<sec id="section3-1076998611411917">
<title>3. Identification Under Random Attrition and Attrition Related to Observables</title>
<p>The most innocuous form of attrition is the case when outcomes are MCAR; see, for instance, <xref ref-type="bibr" rid="bibr61-1076998611411917">Rubin (1976)</xref> and <xref ref-type="bibr" rid="bibr33-1076998611411917">Heitjan and Basu (1996)</xref>. MCAR says that attrition is not related with any observed or unobserved parameter in the treatment effect model. After considering this benchmark case, we will systematically investigate more severe attrition problems.<list list-type="bullet">
<list-item>
<p>Assumption 2:</p>
</list-item>
</list>
<disp-formula id="disp-formula3-1076998611411917">
<mml:math id="mml-disp3-1076998611411917">
<mml:mi>R</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-1076998611411917" xlink:href="10.3102_1076998611411917-eq3.tif"/>
</disp-formula>Assumption 2 states that attrition is independent of both observed and unobserved factors. Taking the school voucher experiment outlined in the last section as an example, it says that test participation is neither related to winning the school voucher nor to any other variables. This implies that the potential outcomes are independent of the response mechanism, <inline-formula id="inline-formula25-1076998611411917">
<mml:math id="mml-inline25-1076998611411917">
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mtext> </mml:mtext>
<mml:mi>R</mml:mi>
</mml:math>
</inline-formula>, and that the potential outcomes and the response mechanism are jointly independent of the treatment assignment, <inline-formula id="inline-formula26-1076998611411917">
<mml:math id="mml-inline26-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mtext> </mml:mtext>
<mml:mi>D</mml:mi>
</mml:math>
</inline-formula>. To see the implications for identification, note that the potential outcome under treatment <inline-formula id="inline-formula27-1076998611411917">
<mml:math id="mml-inline27-1076998611411917">
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
</mml:math>
</inline-formula> for individual <italic>i</italic> is <inline-formula id="inline-formula28-1076998611411917">
<mml:math id="mml-inline28-1076998611411917">
<mml:msubsup>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>d</mml:mi>
</mml:msubsup>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mi>U</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> for <inline-formula id="inline-formula29-1076998611411917">
<mml:math id="mml-inline29-1076998611411917">
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula>. Furthermore, let <inline-formula id="inline-formula30-1076998611411917">
<mml:math id="mml-inline30-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>A</mml:mi>
</mml:msub>
</mml:math>
</inline-formula> denote the cumulative distribution function (cdf) of a random variable <italic>A</italic> and <inline-formula id="inline-formula31-1076998611411917">
<mml:math id="mml-inline31-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> the conditional cdf given <italic>B</italic>. By MCAR,<disp-formula id="disp-formula4-1076998611411917">
<mml:math id="mml-disp4-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula4-1076998611411917" xlink:href="10.3102_1076998611411917-eq4.tif"/>
</disp-formula>where the first equality follows from Assumption 2 and the second from Assumption 1. Therefore, the experiment bears external validity and identifies the ATE in spite of attrition:<disp-formula id="disp-formula5-1076998611411917">
<mml:math id="mml-disp5-1076998611411917">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula5-1076998611411917" xlink:href="10.3102_1076998611411917-eq5.tif"/>
</disp-formula>As a first deviation from MCAR, we will now assume that response is a function of the treatment (e.g., winning a voucher for private schooling), but not of any other observed or unobserved parameter in the treatment effect model.<list list-type="bullet">
<list-item>
<p>Assumption 3:</p>
</list-item>
</list>
</p>
<p>(3a) <inline-formula id="inline-formula32-1076998611411917">
<mml:math id="mml-inline32-1076998611411917">
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>
</p>
<p>(3b) <inline-formula id="inline-formula33-1076998611411917">
<mml:math id="mml-inline33-1076998611411917">
<mml:mi>V</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
</inline-formula>
</p>
<p>
<inline-formula id="inline-formula34-1076998611411917">
<mml:math id="mml-inline34-1076998611411917">
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula> denotes the indicator function and <inline-formula id="inline-formula35-1076998611411917">
<mml:math id="mml-inline35-1076998611411917">
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> denotes a general function. We assume <italic>V</italic> to be an unobserved term that is independent of (<italic>X</italic>, <italic>U</italic>) (3b). By (3a), <italic>D</italic> shifts <italic>R</italic> such that in general, <inline-formula id="inline-formula36-1076998611411917">
<mml:math id="mml-inline36-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> is different from <inline-formula id="inline-formula37-1076998611411917">
<mml:math id="mml-inline37-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> unless <inline-formula id="inline-formula38-1076998611411917">
<mml:math id="mml-inline38-1076998611411917">
<mml:mi mathvariant="italic">ζ</mml:mi>
</mml:math>
</inline-formula> is of a very particular form. Note that a sufficient condition for <inline-formula id="inline-formula39-1076998611411917">
<mml:math id="mml-inline39-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> is monotonicity of <inline-formula id="inline-formula40-1076998611411917">
<mml:math id="mml-inline40-1076998611411917">
<mml:mi mathvariant="italic">ζ</mml:mi>
</mml:math>
</inline-formula> in its arguments. As <italic>D</italic> also affects <italic>Y</italic>, it follows that <inline-formula id="inline-formula41-1076998611411917">
<mml:math id="mml-inline41-1076998611411917">
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula> because the share of treated individuals changes due to attrition. However, this does not affect identification, because the distribution of (<italic>X</italic>, <italic>U</italic>) is not related to the response behavior. This implies that <inline-formula id="inline-formula42-1076998611411917">
<mml:math id="mml-inline42-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>R</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>R</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mtext> </mml:mtext>
<mml:mi>D</mml:mi>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula43-1076998611411917">
<mml:math id="mml-inline43-1076998611411917">
<mml:msup>
<mml:mi>R</mml:mi>
<mml:mi>d</mml:mi>
</mml:msup>
</mml:math>
</inline-formula> denotes the hypothetical response for <italic>D</italic> = <italic>d</italic>, and <inline-formula id="inline-formula44-1076998611411917">
<mml:math id="mml-inline44-1076998611411917">
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mtext> </mml:mtext>
<mml:mi>R</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
</mml:math>
</inline-formula>. As under Assumption 2, it holds that<disp-formula id="disp-formula6-1076998611411917">
<mml:math id="mml-disp6-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula6-1076998611411917" xlink:href="10.3102_1076998611411917-eq6.tif"/>
</disp-formula>where the first equality follows from Assumption 3 and the second from Assumption 1. The experiment is again externally valid and identifies the ATE.</p>
<p>The forms of attrition considered under Assumptions 2 and 3 are unlikely to hold in many, if not most, social experiments. Empirical evidence suggests that response behavior is often related to the treatment <italic>and</italic> other observed characteristics; see, for instance, <xref ref-type="bibr" rid="bibr29-1076998611411917">Hausman and Wise (1979)</xref>, <xref ref-type="bibr" rid="bibr22-1076998611411917">Fitzgerald, Gottschalk, and Moffitt (1998)</xref>, and <xref ref-type="bibr" rid="bibr26-1076998611411917">Grilo et al. (1998)</xref>. These characteristics, <italic>X</italic>, are typically measured in baseline surveys prior to the intervention and commonly include gender, age, education, and other socioeconomic variables.</p>
<p>In the remainder of this section, we will assume that response is a function of the treatment and the covariates. In a first step, we impose a very particular relationship between <italic>X</italic> and <italic>D</italic>, namely, independence conditional on response. This case is primarily chosen for illustrative reasons rather than practical relevance. Interestingly, it entails internal validity of the experiment while external validity no longer holds without controlling for attrition.<list list-type="bullet">
<list-item>
<p>Assumption 4:</p>
</list-item>
</list>
</p>
<p>(4a) <inline-formula id="inline-formula45-1076998611411917">
<mml:math id="mml-inline45-1076998611411917">
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>
</p>
<p>(4b) <inline-formula id="inline-formula46-1076998611411917">
<mml:math id="mml-inline46-1076998611411917">
<mml:mi>V</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
</inline-formula>
</p>
<p>(4c) <inline-formula id="inline-formula47-1076998611411917">
<mml:math id="mml-inline47-1076998611411917">
<mml:mi>X</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mtext> </mml:mtext>
<mml:mi>D</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1.</mml:mn>
</mml:math>
</inline-formula>
</p>
<p>By Assumption 4, attrition affects the distributions of <italic>D</italic> and <italic>X</italic>, which are, however, not related to each other even conditional on response (4c). This implies that the distributional change in <italic>X</italic> is equal across treatment states. For example, assume that <italic>X</italic> represents age in our school voucher experiment and that it is positively related with response (i.e., older students are more likely to take the test). Then, the age composition must change in the same manner for voucher winners and losers when conditioning on test participation. As <italic>U</italic> does not affect the response, the joint distribution of (<italic>X</italic>, <italic>U</italic>) conditional on <italic>R</italic> = 1 is independent of <italic>D</italic>. Thus, <inline-formula id="inline-formula48-1076998611411917">
<mml:math id="mml-inline48-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>. The mean potential outcome of respondents is equal to the average conditional outcome given <italic>D</italic> = <italic>d</italic> among respondents. Therefore, the experiment identifies the ATE on respondents (<inline-formula id="inline-formula49-1076998611411917">
<mml:math id="mml-inline49-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>) and is internally valid:<disp-formula id="disp-formula7-1076998611411917">
<mml:math id="mml-disp7-1076998611411917">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula7-1076998611411917" xlink:href="10.3102_1076998611411917-eq7.tif"/>
</disp-formula>
</p>
<p>However, it is not externally valid, which would require that <inline-formula id="inline-formula50-1076998611411917">
<mml:math id="mml-inline50-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="normal">Δ</mml:mi>
</mml:math>
</inline-formula>. The latter does not hold because the distribution of <italic>X</italic> is not the same for respondents and nonrespondents such that <inline-formula id="inline-formula51-1076998611411917">
<mml:math id="mml-inline51-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>.</p>
<p>Under certain conditions, the ATE on the entire population is identified by weighting respondents according to the likelihood that their observed characteristics appear in the entire population. To this end, we define the response propensity score (see <xref ref-type="bibr" rid="bibr58-1076998611411917">Rosenbaum &amp; Rubin, 1983</xref>), that is, the conditional response probability given (<italic>D</italic>, <italic>X</italic>), as <inline-formula id="inline-formula52-1076998611411917">
<mml:math id="mml-inline52-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Furthermore, we impose the following common support restriction:<list list-type="bullet">
<list-item>
<p>Assumption 4’:</p>
</list-item>
</list>
<disp-formula id="disp-formula8-1076998611411917">
<mml:math id="mml-disp8-1076998611411917">
<mml:mi>P</mml:mi>
<mml:mi>r</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mi>c</mml:mi>
<mml:mspace width="thickmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">f</mml:mi>
<mml:mi mathvariant="normal">o</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thickmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">a</mml:mi>
<mml:mi mathvariant="normal">l</mml:mi>
<mml:mi mathvariant="normal">l</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thickmathspace"/>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mi mathvariant="italic">χ</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0.</mml:mn>
</mml:math>
<graphic alternate-form-of="disp-formula8-1076998611411917" xlink:href="10.3102_1076998611411917-eq8.tif"/>
</disp-formula>χ denotes the support of <italic>X</italic>. Assumption 4’ states that for any (<italic>D</italic>, <italic>X</italic>), the response probability must be bounded away from zero, otherwise outcomes are never observed for particular combinations of the treatment and the covariates. This allows us to reestablish external validity of the experiment by IPW as suggested in Proposition 1.<list list-type="bullet">
<list-item>
<p>Proposition 1:</p>
</list-item>
</list>
</p>
<p>Under Assumptions 1, 4, and 4’, the ATE is identified by<disp-formula id="disp-formula9-1076998611411917">
<label>2</label>
<mml:math id="mml-disp9-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula9-1076998611411917" xlink:href="10.3102_1076998611411917-eq9.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix A, available online at http://jeb.sagepub.com/supplemental.</p>
</list-item>
</list>Thus, weighting observations by the inverse of their respective response propensity score identifies the ATE. The idea of using IPW to control for attrition or similar selection problems goes back to <xref ref-type="bibr" rid="bibr37-1076998611411917">Horvitz and Thompson (1952)</xref>, who proposed an estimator of the population mean when data are missing nonrandomly. IPW has been frequently applied when the attrition process is assumed to depend only on observables, that is, when outcomes are MAR in the notation of <xref ref-type="bibr" rid="bibr61-1076998611411917">Rubin (1976)</xref>. Formally, the MAR requires that <inline-formula id="inline-formula53-1076998611411917">
<mml:math id="mml-inline53-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1.5</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>t</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, or equivalently, that <inline-formula id="inline-formula54-1076998611411917">
<mml:math id="mml-inline54-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mi>R</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>. For example, <xref ref-type="bibr" rid="bibr55-1076998611411917">Robins and Rotnitzky (1995)</xref>, <xref ref-type="bibr" rid="bibr55-1076998611411917">Robins et al. (1995)</xref>, <xref ref-type="bibr" rid="bibr59-1076998611411917">Rotnitzky and Robins (1995)</xref>, and <xref ref-type="bibr" rid="bibr67-1076998611411917">Scharfstein et al. (1999)</xref> use IPW to adjust for missing data in regression models. <xref ref-type="bibr" rid="bibr71-1076998611411917">Wooldridge (2002)</xref> considers IPW M-estimation of missing data models, and Proposition 1 fits into his general framework as a special case.</p>
<p>To make our framework more general, we relax Assumption 4 somewhat by omitting Assumption (4c). This allows the gradient of <italic>X</italic> on the response process to differ across treatment states. For example, one could imagine that in the school voucher experiment, private schools (<italic>D</italic> = 1) are equally successful in sending younger and older students (<inline-formula id="inline-formula55-1076998611411917">
<mml:math id="mml-inline55-1076998611411917">
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula> = age) to college entrance examinations (<italic>R</italic> = 1), whereas public schools (<italic>D</italic> = 0) more likely send older students. This would change the distribution of <italic>X</italic> across treatments among test takers.<list list-type="bullet">
<list-item>
<p>Assumption 5:</p>
</list-item>
</list>
</p>
<p>(5a) <inline-formula id="inline-formula56-1076998611411917">
<mml:math id="mml-inline56-1076998611411917">
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>
</p>
<p>(5b) <inline-formula id="inline-formula57-1076998611411917">
<mml:math id="mml-inline57-1076998611411917">
<mml:mi>V</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
</inline-formula>
</p>
<p>Without further assumptions,<inline-formula id="inline-formula58-1076998611411917">
<mml:math id="mml-inline58-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>. Thus, internal validity no longer holds because the distribution of <italic>X</italic> generally differs across treatment states among respondents such that the effect of <italic>D</italic> is confounded. However, it still holds that<disp-formula id="disp-formula10-1076998611411917">
<mml:math id="mml-disp10-1076998611411917">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mspace width="thinmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">f</mml:mi>
<mml:mi mathvariant="normal">o</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thinmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">a</mml:mi>
<mml:mi mathvariant="normal">l</mml:mi>
<mml:mi mathvariant="normal">l</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">χ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">,</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula10-1076998611411917" xlink:href="10.3102_1076998611411917-eq10.tif"/>
</disp-formula>where the first equality follows from the randomness of response conditional on (<italic>D</italic>, <italic>X</italic>) implied by Assumption 5, which satisfies MAR, and the second from Assumption 1. Note that this would also hold if we relaxed (5b) somewhat to <inline-formula id="inline-formula59-1076998611411917">
<mml:math id="mml-inline59-1076998611411917">
<mml:mi>V</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>.</p>
<p>It follows that the mean potential outcome among respondents is<disp-formula id="disp-formula11-1076998611411917">
<mml:math id="mml-disp11-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula11-1076998611411917" xlink:href="10.3102_1076998611411917-eq11.tif"/>
</disp-formula>This allows us to identify the ATE on the respondents and to reestablish internal validity. Similarly to the response propensity score, we define the treatment propensity score among respondents, that is, the conditional treatment probability given <italic>X</italic>, as <inline-formula id="inline-formula60-1076998611411917">
<mml:math id="mml-inline60-1076998611411917">
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> and impose the following common support assumption:<list list-type="bullet">
<list-item>
<p>Assumption 5’:</p>
</list-item>
</list>
<disp-formula id="disp-formula12-1076998611411917">
<mml:math id="mml-disp12-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula12-1076998611411917" xlink:href="10.3102_1076998611411917-eq12.tif"/>
</disp-formula>Assumption 5’ states that the treatment propensity score is bounded away from 0 and 1, which rules out arbitrarily large weights in the subsequent proposition that reestablishes internal validity of the experiment.<list list-type="bullet">
<list-item>
<p>Proposition 2:</p>
</list-item>
</list>
</p>
<p>Under Assumptions 1, 5, and 5’, the ATE on respondents is identified by<disp-formula id="disp-formula13-1076998611411917">
<label>3</label>
<mml:math id="mml-disp13-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula13-1076998611411917" xlink:href="10.3102_1076998611411917-eq13.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix B, available online at http://jeb.sagepub.com/supplemental</p>
</list-item>
</list>By reweighting the outcomes of respondents by the inverse of the (non)treatment propensity score, we control for differences in the distributions of <italic>X</italic> across treatment states conditional on response to identify <inline-formula id="inline-formula61-1076998611411917">
<mml:math id="mml-inline61-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>. This is analogous to the application of IPW in a “selection on observables” or “conditional independence” framework; see, for instance, <xref ref-type="bibr" rid="bibr34-1076998611411917">Hirano, Imbens, and Ridder (2003)</xref>. The difference is that in the latter case, the imbalances in <italic>X</italic> exist even without attrition due to nonrandom assignment, whereas here, they only occur conditional on response. Yet, similar remedies can be applied to both problems, but note that <xref ref-type="bibr" rid="bibr34-1076998611411917">Hirano et al. (2003)</xref> identify Δ (not <inline-formula id="inline-formula62-1076998611411917">
<mml:math id="mml-inline62-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>).</p>
<p>However, under somewhat stronger common support conditions, we can even identify the ATE on the entire population and reestablish external validity. To this end, note that the mean potential in the entire population is<disp-formula id="disp-formula14-1076998611411917">
<mml:math id="mml-disp14-1076998611411917">
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>X</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula14-1076998611411917" xlink:href="10.3102_1076998611411917-eq14.tif"/>
</disp-formula>That is, integrating over the distribution of <italic>X</italic> in the entire population identifies the potential outcomes and the ATE. As for Proposition 1, this requires that the response probability is bounded away from zero for any (<italic>D</italic>, <italic>X</italic>).<list list-type="bullet">
<list-item>
<p>Proposition 3:</p>
</list-item>
</list>
</p>
<p>Under Assumptions 1, 4’, 5, and 5’, the ATE is identified by<disp-formula id="disp-formula15-1076998611411917">
<label>4</label>
<mml:math id="mml-disp15-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula15-1076998611411917" xlink:href="10.3102_1076998611411917-eq15.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix C, available online at http://jeb.sagepub.com/supplemental.</p>
</list-item>
</list>Δ is identified by using <inline-formula id="inline-formula63-1076998611411917">
<mml:math id="mml-inline63-1076998611411917">
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> to adjust for differences in the distributions of <italic>X</italic> across <italic>D</italic> among respondents and <italic>p</italic>(<italic>D</italic>, <italic>X</italic>) to control for differences in (<italic>D</italic>, <italic>X</italic>) between respondents and nonrespondents. Note that the strong Assumption (5b) may be replaced by the less severe restriction <inline-formula id="inline-formula64-1076998611411917">
<mml:math id="mml-inline64-1076998611411917">
<mml:mi>V</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>, which might be considerably more plausible in empirical applications. Even then, response is random conditional on (<italic>D</italic>, <italic>X</italic>), MAR is satisfied, and Propositions <xref ref-type="disp-formula" rid="disp-formula9-1076998611411917">2</xref> and <xref ref-type="disp-formula" rid="disp-formula13-1076998611411917">3</xref> still apply.</p>
</sec>
<sec id="section4-1076998611411917">
<title>4. Identification Under Attrition Related to Unobservables</title>
<p>In the last section we considered various forms of attrition related to observables. In our treatment effect model, MAR requires that <italic>U</italic> and <italic>V</italic>, the unobserved terms in the outcome and response equations, are independent, at least conditional on observed characteristics. This assumption will be no longer maintained in this section. Instead, we will assume attrition on unobservables by allowing for a nonzero correlation between <italic>U</italic> and <italic>V</italic> even conditional on <italic>D</italic>, <italic>X</italic>. Analogous to sample selection models (see <xref ref-type="bibr" rid="bibr30-1076998611411917">Heckman 1974</xref>, <xref ref-type="bibr" rid="bibr31-1076998611411917">1976</xref>, <xref ref-type="bibr" rid="bibr32-1076998611411917">1979</xref>)—at least when identification is nonparametric (e.g., <xref ref-type="bibr" rid="bibr15-1076998611411917">Das, Newey, &amp; Vella, 2003</xref>; <xref ref-type="bibr" rid="bibr38-1076998611411917">Huber, 2009</xref>; <xref ref-type="bibr" rid="bibr52-1076998611411917">Newey, 2007</xref>)—point identification hinges on the availability of an instrument that affects response but has no direct effect on the outcome.</p>
<p>Reconsider the school voucher experiment in which only a subpopulation takes the test. Assume that the probability to take the test is a function of unobserved motivation and ability which are correlated with tests scores even conditional on the treatment and observed characteristics (e.g., age and gender). Then, identification requires an instrument that shifts test participation but has no direct effect on the test scores.<list list-type="bullet">
<list-item>
<p>Assumption 6:</p>
</list-item>
</list>
</p>
<p>(6a) <inline-formula id="inline-formula65-1076998611411917">
<mml:math id="mml-inline65-1076998611411917">
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>
</p>
<p>(6b) Cov<inline-formula id="inline-formula66-1076998611411917">
<mml:math id="mml-inline66-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> (and Cov<inline-formula id="inline-formula67-1076998611411917">
<mml:math id="mml-inline67-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mn>0</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. </p>
<p>By Assumption 6, <italic>R</italic> is a function of at least one element that is excluded in <inline-formula id="inline-formula68-1076998611411917">
<mml:math id="mml-inline68-1076998611411917">
<mml:mi mathvariant="italic">φ</mml:mi>
</mml:math>
</inline-formula>, namely, the instrument <italic>Z</italic>. Due to the nonzero covariance of <italic>V</italic> and <italic>U</italic>, the effect of <italic>D</italic> on <italic>Y</italic> among respondents is confounded even conditional on <italic>X</italic>. Identification requires <italic>Z</italic> to be a good predictor for <italic>R</italic>, to contain at least one continuous element, and not to have a direct effect on the outcome. The following restrictions guarantee the validity of the instrument.<list list-type="bullet">
<list-item>
<p>Assumption 6’:</p>
</list-item>
</list>
</p>
<p>(6’a) Cov<inline-formula id="inline-formula69-1076998611411917">
<mml:math id="mml-inline69-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula70-1076998611411917">
<mml:math id="mml-inline70-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mtext> </mml:mtext>
<mml:mi>Z</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>,</p>
<p>(6’b) <inline-formula id="inline-formula71-1076998611411917">
<mml:math id="mml-inline71-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mi>c</mml:mi>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula72-1076998611411917">
<mml:math id="mml-inline72-1076998611411917">
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula73-1076998611411917">
<mml:math id="mml-inline73-1076998611411917">
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula>,</p>
<p>(6’c) <inline-formula id="inline-formula74-1076998611411917">
<mml:math id="mml-inline74-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>,</p>
<p>(6’d) <inline-formula id="inline-formula75-1076998611411917">
<mml:math id="mml-inline75-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, the cdf of <italic>V</italic>, is strictly monotonic in the argument <inline-formula id="inline-formula76-1076998611411917">
<mml:math id="mml-inline76-1076998611411917">
<mml:mi>t</mml:mi>
</mml:math>
</inline-formula>. </p>
<p>Assumption (6’a) states that <italic>Z</italic> shifts <italic>R</italic> but is not directly related with <italic>Y</italic>. Assumption (6’b) rules out that being treated or nontreated predicts attrition perfectly. For example, not winning a school voucher must not rule out test participation. To see the usefulness of this assumption, assume the opposite such that units with <italic>D</italic> = 0 never respond independent of the values of (<italic>X</italic>, <italic>Z</italic>). Obviously, the treatment effect cannot be evaluated as no comparisons with <italic>D</italic> = 0 are available in the subpopulation of respondents.</p>
<p>By (6’c), we impose that (<italic>D</italic>, <italic>Z</italic>) are jointly independent of the unobservables (<italic>U</italic>, <italic>V</italic>). Independence between (<italic>U</italic>, <italic>V</italic>) and <italic>D</italic> is satisfied by the randomization of the treatment if <italic>V</italic> is not a posttreatment variable. Still, it needs to be plausibly argued that <inline-formula id="inline-formula77-1076998611411917">
<mml:math id="mml-inline77-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mi>Z</mml:mi>
</mml:math>
</inline-formula>. In the school voucher experiment, where we only observe test scores conditional on test participation, one might think of distance or transportation costs to the test center as a valid instrument if it is plausibly unrelated to unobserved motivation and ability. However, there may exist credible concerns that the distribution of motivation differs for students close and distant to the test center such that Assumption (6’c) is violated. For example, if families with higher educated parents systematically choose neighborhoods closer to the test centers for some reason (e.g., central location or good infrastructure) and if higher educated parents also better motivate their children to strive for a higher education, then the instrument is not independent of the unobserved terms.</p>
<p>As argued by <xref ref-type="bibr" rid="bibr17-1076998611411917">DiNardo et al. (2006)</xref>, the instrument should ideally be randomly assigned in a similar way as the treatment. This would plausibly justify Assumption (6’c). For example, in a follow-up telephone survey, <italic>Z</italic> may be the number of phone calls per experimental unit which is randomized prior to the treatment assignment. A higher number of attempted calls should increase the response probability while being unrelated with other factors under random assignment. Also financial incentives are likely to affect response behavior (see Castiglioni, Pforr, and Krieger, <xref ref-type="bibr" rid="bibr12-1076998611411917">2008</xref>). In the school voucher example, students could be randomly offered different levels of cash payments or refunding of travel expenses in the case that they take the test. Of course, one would need to unambiguously communicate that the payment is conditional on participation alone, not on the test score (otherwise the motivation to prepare oneself for the test is likely to be affected). A further example would be the randomization of the distance to the test center, given that the choice of various test locations is feasible in the experimental design. Note that (6’c) could be relaxed to <inline-formula id="inline-formula78-1076998611411917">
<mml:math id="mml-inline78-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
</mml:math>
</inline-formula>, that is, conditional independence given observed variables (such as parents' education), which might be more plausible in applications without randomized instruments.</p>
<p>Concerning Assumption (6’d), first note that <inline-formula id="inline-formula79-1076998611411917">
<mml:math id="mml-inline79-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Assumption (6’d) states that the likelihood to respond increases strictly monotonically in <inline-formula id="inline-formula80-1076998611411917">
<mml:math id="mml-inline80-1076998611411917">
<mml:mi mathvariant="italic">ζ</mml:mi>
</mml:math>
</inline-formula>. This allows us to back out the distribution of <italic>V</italic> by pinning down (<italic>D</italic>, <italic>X</italic>, <italic>Z</italic>). By comparing individuals with the same response propensity score we control for <italic>V</italic> and, thus, also for the dependence between <italic>V</italic> and <italic>U</italic>. Without strict monotonicity, a 1:1 relation between <inline-formula id="inline-formula81-1076998611411917">
<mml:math id="mml-inline81-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula82-1076998611411917">
<mml:math id="mml-inline82-1076998611411917">
<mml:mi mathvariant="italic">ζ</mml:mi>
</mml:math>
</inline-formula> would not exist such that <inline-formula id="inline-formula83-1076998611411917">
<mml:math id="mml-inline83-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> would generally not correspond to a unique value of <italic>V</italic>. Under (6’d), however, <italic>V</italic> can be fixed to rule out confounding of the treatment effect due to attrition related to unobservables. That is, the response propensity score serves as a control function where the exogenous variation comes from <italic>Z</italic>. Control functions have been applied in semi- and nonparametric sample selection models, for example, <xref ref-type="bibr" rid="bibr1-1076998611411917">Ahn and Powell (1993)</xref> and <xref ref-type="bibr" rid="bibr15-1076998611411917">Das, Newey, and Vella (2003)</xref>, as well as in nonparametric models with endogeneity; see, for example, <xref ref-type="bibr" rid="bibr53-1076998611411917">Newey, Powell, and Vella (1999)</xref>, <xref ref-type="bibr" rid="bibr8-1076998611411917">Blundell and Powell (2003)</xref>, and Imbens and Newey (<xref ref-type="bibr" rid="bibr43-1076998611411917">2009</xref>). Furthermore, strict monotonicity is implicit in linear index restrictions used in the parametric sample selection literature (see <xref ref-type="bibr" rid="bibr30-1076998611411917">Heckman, 1974</xref>, <xref ref-type="bibr" rid="bibr31-1076998611411917">1976</xref>, <xref ref-type="bibr" rid="bibr32-1076998611411917">1979</xref>).</p>
<p>However, conditioning on the response propensity score alone does not suffice for causal inference. A first reason is that, similar to Assumptions 4 and 5, response is a function of <italic>X</italic> and <italic>D</italic>. Therefore, random treatment assignment does not necessarily entail independence of <italic>D</italic> and <italic>X</italic> among respondents, as the distribution of <italic>X</italic> might differ across treatment states conditional on <italic>R</italic> = 1. Second, this is even more likely to be the case conditional on the response propensity score. To see this, note that individuals in different treatment states <italic>D</italic> but with equal values of <italic>X</italic> and <italic>Z</italic> must have distinct response propensity scores. That is, <inline-formula id="inline-formula84-1076998611411917">
<mml:math id="mml-inline84-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. As we need to compare treated and nontreated individuals with identical response propensity scores to control for the attrition bias, these individuals necessarily differ with respect to (<italic>X</italic>, <italic>Z</italic>). Despite the randomization of the treatment in the entire population, identification requires conditioning on both the response propensity score <italic>and</italic> the covariates among respondents. That is, conditional on <italic>X</italic> = <italic>x</italic> we need to compare the outcomes of treated and nontreated observations that satisfy <inline-formula id="inline-formula85-1076998611411917">
<mml:math id="mml-inline85-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mi>z</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:msup>
<mml:mi>z</mml:mi>
<mml:mo>′′</mml:mo>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> for some <inline-formula id="inline-formula86-1076998611411917">
<mml:math id="mml-inline86-1076998611411917">
<mml:msup>
<mml:mi>z</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo stretchy="false">,</mml:mo>
<mml:msup>
<mml:mi>z</mml:mi>
<mml:mo>′′</mml:mo>
</mml:msup>
</mml:math>
</inline-formula> in the support of <italic>Z</italic>. This generally forces the instrument to include at least one continuous element, otherwise comparable treated and nontreated observations might not exist.</p>
<p>We will now formally discuss identification. For notational ease, let <inline-formula id="inline-formula87-1076998611411917">
<mml:math id="mml-inline87-1076998611411917">
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> and the response propensity score <inline-formula id="inline-formula88-1076998611411917">
<mml:math id="mml-inline88-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Under Assumption (6’c), <italic>U</italic> and <italic>D</italic> are independent conditional on <italic>p</italic>(<italic>W</italic>) and <italic>X</italic>, which can be shown analogously to the proof of Theorem 1 in <xref ref-type="bibr" rid="bibr52-1076998611411917">Newey (2007)</xref>. Let <italic>a</italic>(<italic>U</italic>) denote any bounded function of <italic>U</italic>. Note that <inline-formula id="inline-formula89-1076998611411917">
<mml:math id="mml-inline89-1076998611411917">
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:msubsup>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula>. Then,<disp-formula id="disp-formula16-1076998611411917">
<mml:math id="mml-disp16-1076998611411917">
<mml:mtable columnalign="center" columnspacing="1em" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:msubsup>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>v</mml:mi>
</mml:mrow>
</mml:mfenced>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:msubsup>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>v</mml:mi>
</mml:mrow>
</mml:mfenced>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mn>0.5</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:msubsup>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>v</mml:mi>
</mml:mrow>
</mml:mfenced>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfenced>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mspace width="1em"/>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>3</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">,</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula16-1076998611411917" xlink:href="10.3102_1076998611411917-eq16.tif"/>
</disp-formula>where the first equality follows from iterated expectations, the second and third from (6’c), the fourth from the fact that <inline-formula id="inline-formula90-1076998611411917">
<mml:math id="mml-inline90-1076998611411917">
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula> for any variables <italic>A</italic>, <italic>B</italic>, and <italic>C</italic>, and the last from a backward application of the law of iterated expectations.</p>
<p>Thus, treatment effects are identified by conditioning on the response propensity score and the covariates. To see this, note that the conditional ATE given <italic>X</italic> and <italic>p</italic>(<italic>W</italic>) conditional on response is defined as<disp-formula id="disp-formula17-1076998611411917">
<mml:math id="mml-disp17-1076998611411917">
<mml:mtable columnalign="center" columnspacing="1em" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="2em"/>
<mml:mspace width="2em"/>
<mml:mspace width="2em"/>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula17-1076998611411917" xlink:href="10.3102_1076998611411917-eq17.tif"/>
</disp-formula> 
<inline-formula id="inline-formula91-1076998611411917">
<mml:math id="mml-inline91-1076998611411917">
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mi>d</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula> is the expected potential outcome for a hypothetical treatment <italic>d</italic> given <italic>X</italic> and <italic>p</italic>(<italic>W</italic>) among respondents. By the conditional independence of <italic>U</italic> and <italic>D</italic> given <italic>p</italic>(<italic>W</italic>) and <italic>X</italic>, it holds that<disp-formula id="disp-formula18-1076998611411917">
<mml:math id="mml-disp18-1076998611411917">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mi>d</mml:mi>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula18-1076998611411917" xlink:href="10.3102_1076998611411917-eq18.tif"/>
</disp-formula>Hence, the expected <italic>potential</italic> outcome is equal to the expected <italic>conditional</italic> outcome, given <italic>D</italic> = <italic>d</italic>. The ATE on respondents <inline-formula id="inline-formula92-1076998611411917">
<mml:math id="mml-inline92-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> is identified by the integration over the marginal distributions of <italic>X</italic> and <italic>p</italic>(<italic>W</italic>) in the subpopulation with observed outcomes.<disp-formula id="disp-formula19-1076998611411917">
<label>5</label>
<mml:math id="mml-disp19-1076998611411917">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">]</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">]</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msup>
<mml:mo stretchy="false">−</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mn>0</mml:mn>
</mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula19-1076998611411917" xlink:href="10.3102_1076998611411917-eq19.tif"/>
</disp-formula>Therefore, the identification of <inline-formula id="inline-formula93-1076998611411917">
<mml:math id="mml-inline93-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> hinges on the common support of the treatment in <italic>X</italic> and <inline-formula id="inline-formula94-1076998611411917">
<mml:math id="mml-inline94-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Δ is not identified without further assumptions (see also Newey, <xref ref-type="bibr" rid="bibr52-1076998611411917">2007</xref>), as <italic>Y</italic> is not even observed when <italic>R</italic> = 0. However, under the additional restrictions that the response propensity score is positive for any (<italic>X</italic>, <italic>p</italic>(<italic>W</italic>)) and that <italic>Y</italic> is homoscedastic conditional on (<italic>D</italic>, <italic>X</italic>) one also identifies the ATE on the entire population. To this end, we impose the following assumption:<list list-type="bullet">
<list-item>
<p>Assumption 6”:</p>
</list-item>
</list>
</p>
<p>(6”a) <inline-formula id="inline-formula95-1076998611411917">
<mml:math id="mml-inline95-1076998611411917">
<mml:mtext mathcolor="red">\scale</mml:mtext>
<mml:mn>95</mml:mn>
</mml:math>
</inline-formula> for all <inline-formula id="inline-formula96-1076998611411917">
<mml:math id="mml-inline96-1076998611411917">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula97-1076998611411917">
<mml:math id="mml-inline97-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> χ, for all <inline-formula id="inline-formula98-1076998611411917">
<mml:math id="mml-inline98-1076998611411917">
<mml:mi>Z</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula99-1076998611411917">
<mml:math id="mml-inline99-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula100-1076998611411917">
<mml:math id="mml-inline100-1076998611411917">
<mml:mrow>
<mml:mi mathvariant="script">Z</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>,</p>
<p>(6”b) <inline-formula id="inline-formula101-1076998611411917">
<mml:math id="mml-inline101-1076998611411917">
<mml:mspace width="thickmathspace"/>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mi>P</mml:mi>
<mml:mi>r</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>c</mml:mi>
</mml:math>
</inline-formula>, for all <inline-formula id="inline-formula102-1076998611411917">
<mml:math id="mml-inline102-1076998611411917">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula103-1076998611411917">
<mml:math id="mml-inline103-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> χ, for all <inline-formula id="inline-formula104-1076998611411917">
<mml:math id="mml-inline104-1076998611411917">
<mml:mspace width="1em"/>
<mml:mn>5</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula105-1076998611411917">
<mml:math id="mml-inline105-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula106-1076998611411917">
<mml:math id="mml-inline106-1076998611411917">
<mml:mrow>
<mml:mi mathvariant="script">P</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula107-1076998611411917">
<mml:math id="mml-inline107-1076998611411917">
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>,</p>
<p>(6”c) <inline-formula id="inline-formula108-1076998611411917">
<mml:math id="mml-inline108-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>U</mml:mi>
</mml:math>
</inline-formula>.</p>
<p>
<inline-formula id="inline-formula109-1076998611411917">
<mml:math id="mml-inline109-1076998611411917">
<mml:mrow>
<mml:mi mathvariant="script">Z</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula110-1076998611411917">
<mml:math id="mml-inline110-1076998611411917">
<mml:mrow>
<mml:mi mathvariant="script">P</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula> denote the support regions of <italic>Z</italic> and <italic>p</italic>(<italic>W</italic>). Note that (6”a) is stronger than (6’b). Effects on the entire population could not be identified if there existed individuals with a response propensity score equal to zero, as this would rule out suitable comparisons in the subpopulation of respondents. Assumption (6”c) decreases the generality of our model due to separability of the observed and unobserved terms (see also <xref ref-type="bibr" rid="bibr15-1076998611411917">Das et al., 2003</xref>), but ensures homoscedasticity of <italic>Y</italic> given (<italic>D</italic>, <italic>X</italic>). This is required for the identification of Δ, as outlined further below. Similar to the last section, let <inline-formula id="inline-formula111-1076998611411917">
<mml:math id="mml-inline111-1076998611411917">
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> denote the treatment propensity score, <inline-formula id="inline-formula112-1076998611411917">
<mml:math id="mml-inline112-1076998611411917">
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Propositions <xref ref-type="disp-formula" rid="disp-formula15-1076998611411917">4</xref> and <xref ref-type="disp-formula" rid="disp-formula19-1076998611411917">5</xref> show identification of the ATEs on the respondents and on the entire population.<list list-type="bullet">
<list-item>
<p>Proposition 4:</p>
</list-item>
</list>Under Assumptions 1, 6, 6’, and (6”b), the ATE on the respondents is identified by<disp-formula id="disp-formula20-1076998611411917">
<label>6</label>
<mml:math id="mml-disp20-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula20-1076998611411917" xlink:href="10.3102_1076998611411917-eq20.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix D, available online at http://jeb.sagepub.com/supplemental.</p>
</list-item>
</list>By weighting observations by the inverse of the (non-)treatment propensity score, we adjust for differences in the distributions of <italic>X</italic> and <italic>p</italic>(<italic>W</italic>) between treated and nontreated respondents. Proposition 4 is similar to Proposition 3, with the exception that we have to additionally condition on the response propensity score in the treatment propensity score to control for attrition on unobservables.</p>
<p>It seems useful to compare our approach based on the propensity score and a continuous instrument to <xref ref-type="bibr" rid="bibr50-1076998611411917">Mealli and Pacini (2008)</xref> who control for attrition by conditioning on a binary instrument (<inline-formula id="inline-formula113-1076998611411917">
<mml:math id="mml-inline113-1076998611411917">
<mml:mi>Z</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula114-1076998611411917">
<mml:math id="mml-inline114-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> {0,1}) directly. This allows them to classify the population into subgroups (or “latent strata”) according to their response behavior conditional on hypothetical values of the treatment and the instrument (here for a given <italic>X</italic>). Identification relies (among other restrictions) on the fact that attrition is random for individuals with the same response behavior. One assumption considered by <xref ref-type="bibr" rid="bibr50-1076998611411917">Mealli and Pacini (2008)</xref> is a perfect instrument: <italic>R</italic> = 1 always holds if <italic>Z</italic> = 1, such that treated and nontreated individuals with <italic>Z</italic> = 1 have the same response behavior. In terms of the response propensity score, this implies that <inline-formula id="inline-formula115-1076998611411917">
<mml:math id="mml-inline115-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula>.</p>
<p>This example illustrates that conditioning on the propensity score is equivalent to conditioning on the response behavior, which can be easily shown in a principal stratification framework. For this reason and as already discussed before, effects are identified if particular combinations of <italic>D</italic> and <italic>Z</italic> yield the same response propensity scores across treatment states (which need not necessarily be equal to one) for a given <italic>X</italic>, for example, if <inline-formula id="inline-formula116-1076998611411917">
<mml:math id="mml-inline116-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. However, for a discrete <italic>Z</italic>, the existence of comparable propensity scores across treatment states does not hold in general (not even for a subpopulation) such that <xref ref-type="bibr" rid="bibr50-1076998611411917">Mealli and Pacini (2008)</xref> also consider further assumptions. In contrast, it holds in the presence of a sufficiently strong continuous instrument. There obviously exists a trade-off between identification and econometric feasibility between the two approaches if the instrument is not perfect. Discrete instruments, on one hand, are easier to find in empirical applications but only allow for partial identification or at best point identification in some subpopulation. Continuous instruments, on the other hand, are very hard to find in reality, but have more identifying power. They even allow us to identify the ATE on the entire population, given that the common support Assumption 6” is satisfied.<list list-type="bullet">
<list-item>
<p>Proposition 5:</p>
</list-item>
</list>Under Assumptions 1, 6, 6’, and 6”, the ATE is identified by<disp-formula id="disp-formula21-1076998611411917">
<label>7</label>
<mml:math id="mml-disp21-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula21-1076998611411917" xlink:href="10.3102_1076998611411917-eq21.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix E, available online at http://jeb.sagepub.com/supplemental.</p>
</list-item>
</list>The ATE on the entire population is identified based on reweighting observations (in addition to the inverse treatment propensity score) by the inverse of the response propensity score, that is, by using the relative likelihood of a particular triple (<italic>D</italic>, <italic>X</italic>, <italic>Z</italic>) to appear in the entire population, as weighting function.</p>
<p>This result may seem surprising, given the fact that outcomes are only partially observed and observed outcomes do not allow inferring on the unobserved outcomes. That is, <inline-formula id="inline-formula117-1076998611411917">
<mml:math id="mml-inline117-1076998611411917">
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:math>
</inline-formula> due to different conditional distributions of the unobserved term <italic>U</italic>. Nevertheless, Assumptions 6’ and 6” imply that <inline-formula id="inline-formula118-1076998611411917">
<mml:math id="mml-inline118-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. To see this, note that <inline-formula id="inline-formula119-1076998611411917">
<mml:math id="mml-inline119-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> for <inline-formula id="inline-formula120-1076998611411917">
<mml:math id="mml-inline120-1076998611411917">
<mml:mi>r</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula> by (6’c) such that<disp-formula id="disp-formula22-1076998611411917">
<mml:math id="mml-disp22-1076998611411917">
<mml:mtable columnalign="center" columnspacing="1em" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">[</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="2em"/>
<mml:mspace width="2em"/>
<mml:mspace width="2em"/>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">[</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">[</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mspace width="2em"/>
<mml:mspace width="2em"/>
<mml:mspace width="2em"/>
<mml:mo stretchy="false">−</mml:mo>
<mml:mo stretchy="false">∫</mml:mo>
<mml:mo stretchy="false">[</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo>φ</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mspace width="thickmathspace"/>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula22-1076998611411917" xlink:href="10.3102_1076998611411917-eq22.tif"/>
</disp-formula>
<inline-formula id="inline-formula121-1076998611411917">
<mml:math id="mml-inline121-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula122-1076998611411917">
<mml:math id="mml-inline122-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> only differ with respect to the integrals over different conditional distributions of <italic>U</italic>, given <italic>R</italic> = 1 and <italic>R</italic> = 0, which cancel out in the subtractions by (6”c). Thus, <inline-formula id="inline-formula123-1076998611411917">
<mml:math id="mml-inline123-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Therefore, reweighting the conditional treatment effects of the respondents according to the distribution of (<italic>D</italic>, <italic>X</italic>, <italic>Z</italic>) in the entire population identifies Δ.</p>
<p>For completeness, we will briefly discuss identification under a particular deviation from the previous model, assuming that response is a function of <italic>D</italic>, <italic>Z</italic>, and <italic>V</italic>, but is not related with the covariates <italic>X</italic>.<list list-type="bullet">
<list-item>
<p>Assumption 7:</p>
</list-item>
</list>
</p>
<p>(7a) <inline-formula id="inline-formula124-1076998611411917">
<mml:math id="mml-inline124-1076998611411917">
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mi mathvariant="italic">ζ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≥</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>
</p>
<p>(7b) Cov<inline-formula id="inline-formula125-1076998611411917">
<mml:math id="mml-inline125-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>. </p>
<p>Under this particular form of attrition, the response behavior is merely a function of the treatment and unobservables but unrelated to the observed covariates. Whether Assumption 7 is plausible depends on the evaluation problem at hand and may even be tested (by testing the explanatory power of <italic>X</italic> on <italic>R</italic>). The response propensity score is now <inline-formula id="inline-formula126-1076998611411917">
<mml:math id="mml-inline126-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. We impose the following instrumental variable (IV) and common support assumptions.<list list-type="bullet">
<list-item>
<p>Assumption 7’:</p>
</list-item>
</list>
</p>
<p>(7’a) Cov<inline-formula id="inline-formula127-1076998611411917">
<mml:math id="mml-inline127-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≠</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula128-1076998611411917">
<mml:math id="mml-inline128-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mi>Z</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
</mml:math>
</inline-formula>,</p>
<p>(7’b) <inline-formula id="inline-formula129-1076998611411917">
<mml:math id="mml-inline129-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mi>c</mml:mi>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula130-1076998611411917">
<mml:math id="mml-inline130-1076998611411917">
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula131-1076998611411917">
<mml:math id="mml-inline131-1076998611411917">
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
</mml:math>
</inline-formula>,</p>
<p>(7’c) <inline-formula id="inline-formula132-1076998611411917">
<mml:math id="mml-inline132-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>V</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi mathvariant="normal">⊥</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>,</p>
<p>(7’d) <inline-formula id="inline-formula133-1076998611411917">
<mml:math id="mml-inline133-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>V</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, the cdf of <italic>V</italic>, is strictly monotonic in the argument <inline-formula id="inline-formula134-1076998611411917">
<mml:math id="mml-inline134-1076998611411917">
<mml:mi>t</mml:mi>
</mml:math>
</inline-formula>.<list list-type="bullet">
<list-item>
<p>Assumption 7”:</p>
</list-item>
</list>
</p>
<p>(7”a) <inline-formula id="inline-formula135-1076998611411917">
<mml:math id="mml-inline135-1076998611411917">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
</inline-formula> for all <inline-formula id="inline-formula136-1076998611411917">
<mml:math id="mml-inline136-1076998611411917">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula137-1076998611411917">
<mml:math id="mml-inline137-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> χ, for all <inline-formula id="inline-formula138-1076998611411917">
<mml:math id="mml-inline138-1076998611411917">
<mml:mi>Z</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula139-1076998611411917">
<mml:math id="mml-inline139-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula140-1076998611411917">
<mml:math id="mml-inline140-1076998611411917">
<mml:mrow>
<mml:mi mathvariant="script">Z</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>,</p>
<p>(7”b) <inline-formula id="inline-formula141-1076998611411917">
<mml:math id="mml-inline141-1076998611411917">
<mml:mspace width="thickmathspace"/>
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&lt;</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>c</mml:mi>
</mml:math>
</inline-formula>, for all <inline-formula id="inline-formula142-1076998611411917">
<mml:math id="mml-inline142-1076998611411917">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula143-1076998611411917">
<mml:math id="mml-inline143-1076998611411917">
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> χ, for all <inline-formula id="inline-formula144-1076998611411917">
<mml:math id="mml-inline144-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula145-1076998611411917">
<mml:math id="mml-inline145-1076998611411917">
<mml:mspace width="1em"/>
<mml:mn>3</mml:mn>
<mml:mi>p</mml:mi>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">∈</mml:mo>
</mml:math>
</inline-formula> 
<inline-formula id="inline-formula146-1076998611411917">
<mml:math id="mml-inline146-1076998611411917">
<mml:mrow>
<mml:mi mathvariant="script">P</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="inline-formula147-1076998611411917">
<mml:math id="mml-inline147-1076998611411917">
<mml:mi>c</mml:mi>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>,</p>
<p>(7”c) <inline-formula id="inline-formula148-1076998611411917">
<mml:math id="mml-inline148-1076998611411917">
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="italic">φ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">+</mml:mo>
<mml:mi>U</mml:mi>
</mml:math>
</inline-formula>. </p>
<p>Assumptions 7’ and 7” are straightforward modifications of 7’ and 7”, with the exception of (7’c), which assumes independence of the (<italic>D</italic>, <italic>Z</italic>) also with respect to <italic>X</italic>. Again, the treatment is independent by randomization, whereas the independence of <italic>Z</italic> and <italic>X</italic> may or may not be plausible and might be tested. By Assumptions 1, 7, and (7’c) it holds that <italic>X</italic> is independent of <italic>D</italic> conditional on <italic>p</italic>(<italic>D</italic>, <italic>Z</italic>) and <italic>R</italic> = 1, because <inline-formula id="inline-formula149-1076998611411917">
<mml:math id="mml-inline149-1076998611411917">
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mrow>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>D</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>X</mml:mi>
</mml:msub>
</mml:math>
</inline-formula>. Therefore, treatment effects are identified conditional on <italic>p</italic>(<italic>D</italic>, <italic>Z</italic>) or on the simplified treatment propensity score <inline-formula id="inline-formula150-1076998611411917">
<mml:math id="mml-inline150-1076998611411917">
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">≡</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">P</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, respectively. Similar to Propositions <xref ref-type="disp-formula" rid="disp-formula15-1076998611411917">4</xref> and <xref ref-type="disp-formula" rid="disp-formula19-1076998611411917">5</xref>, the ATEs on the respondents and the entire population can be expressed by the following equations:<list list-type="bullet">
<list-item>
<p>Proposition <xref ref-type="disp-formula" rid="disp-formula20-1076998611411917">6</xref>:</p>
</list-item>
</list>
</p>
<p>Under Assumptions 1, 7, 7’, and (7”b), the ATE on the respondents is identified by<disp-formula id="disp-formula23-1076998611411917">
<label>8</label>
<mml:math id="mml-disp23-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula23-1076998611411917" xlink:href="10.3102_1076998611411917-eq23.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix F, available online at http://jeb.sagepub.com/supplemental.</p>
</list-item>
<list-item>
<p>Proposition 7:</p>
</list-item>
</list>Under Assumptions 1, 7, 7’, and 7”, the ATE is identified by<disp-formula id="disp-formula24-1076998611411917">
<label>9</label>
<mml:math id="mml-disp24-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>E</mml:mi>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula24-1076998611411917" xlink:href="10.3102_1076998611411917-eq24.tif"/>
</disp-formula>
<list list-type="bullet">
<list-item>
<p>Proof: See Appendix G, available online at http://jeb.sagepub.com/supplemental.</p>
</list-item>
</list>In the last two sections, we have covered several forms of attrition and provided a guideline on which weighting methods are appropriate under specific assumptions. In particular, the use of IPW incorporating IVs when attrition is on unobservables has been discussed, a case widely ignored in the experimental literature. The subsequent sections will present simulation results and an empirical application to a U.S. labor market policy experiment.</p>
</sec>
<sec id="section5-1076998611411917">
<title>5. Simulation Studies</title>
<p>In this section, we run a horse race between the experimental mean difference estimator not controlling for attrition and IPW estimators assuming that attrition is related to observables and unobservables as treated under Assumptions 5 and 6, respectively. For this reason, we conduct simulation studies based on both generated and empirical data. Starting with the former scenario, we consider the following data generating process (DGP):<disp-formula id="disp-formula25-1076998611411917">
<mml:math id="mml-disp25-1076998611411917">
<mml:mtable columnalign="right left" columnspacing="thickmathspace" displaystyle="true" rowspacing=".5em">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>U</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mspace width="thinmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">s</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">o</mml:mi>
<mml:mi mathvariant="normal">b</mml:mi>
<mml:mi mathvariant="normal">s</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
<mml:mi mathvariant="normal">r</mml:mi>
<mml:mi mathvariant="normal">v</mml:mi>
<mml:mi mathvariant="normal">e</mml:mi>
<mml:mi mathvariant="normal">d</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thinmathspace"/>
<mml:mspace width="thinmathspace"/>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">i</mml:mi>
<mml:mi mathvariant="normal">f</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mspace width="thinmathspace"/>
<mml:msub>
<mml:mi>R</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:msub>
<mml:mi>R</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>Z</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula25-1076998611411917" xlink:href="10.3102_1076998611411917-eq25.tif"/>
</disp-formula>Apart from the treatment <italic>D</italic>, the covariate <italic>X</italic>, and the unobserved term <italic>U</italic>, the outcome <italic>Y</italic> also depends on an interaction term of <italic>D</italic> and <italic>X</italic>, which introduces effect heterogeneity with respect to <italic>X</italic>. <italic>X</italic> and <italic>Z</italic> are uniformly distributed with support regions [–1, 1] and [–1, 2], respectively. <italic>D</italic> is Bernoulli and either 1 or 0 with equal probability. (<italic>U</italic>, <italic>V</italic>) are drawn from a multivariate standard normal distribution. Their covariance is set to zero in the case of attrition on observables and to <inline-formula id="inline-formula151-1076998611411917">
<mml:math id="mml-inline151-1076998611411917">
<mml:mn>0.8</mml:mn>
</mml:math>
</inline-formula> under attrition on unobservables. The coefficients in the outcome equation are set to <inline-formula id="inline-formula152-1076998611411917">
<mml:math id="mml-inline152-1076998611411917">
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">α</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>.25</mml:mn>
</mml:math>
</inline-formula>. Under attrition on observables <inline-formula id="inline-formula153-1076998611411917">
<mml:math id="mml-inline153-1076998611411917">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula154-1076998611411917">
<mml:math id="mml-inline154-1076998611411917">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> such that roughly two thirds of the outcomes are observed. Under attrition on unobservables, <inline-formula id="inline-formula155-1076998611411917">
<mml:math id="mml-inline155-1076998611411917">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0.5</mml:mn>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula156-1076998611411917">
<mml:math id="mml-inline156-1076998611411917">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula>, that is, <inline-formula id="inline-formula157-1076998611411917">
<mml:math id="mml-inline157-1076998611411917">
<mml:mi>R</mml:mi>
</mml:math>
</inline-formula> is also a function of the instrument <inline-formula id="inline-formula158-1076998611411917">
<mml:math id="mml-inline158-1076998611411917">
<mml:mi>Z</mml:mi>
</mml:math>
</inline-formula>, which is excluded from the outcome equation. Approximately 70% of the outcomes are observed in this case.</p>
<p>We use normalized versions (such that weights add up to unity, see <xref ref-type="bibr" rid="bibr41-1076998611411917">Imbens, 2004</xref>; <xref ref-type="bibr" rid="bibr10-1076998611411917">Busso, DiNardo, &amp; McCrary, 2009b</xref>) of the sample analogs of Propositions <xref ref-type="disp-formula" rid="disp-formula9-1076998611411917">2</xref>, <xref ref-type="disp-formula" rid="disp-formula13-1076998611411917">3</xref>, <xref ref-type="disp-formula" rid="disp-formula15-1076998611411917">4</xref>, and <xref ref-type="disp-formula" rid="disp-formula5-1076998611411917">5</xref> as estimators of the ATE on the entire population (denoted as <inline-formula id="inline-formula159-1076998611411917">
<mml:math id="mml-inline159-1076998611411917">
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>) and on the respondents (<inline-formula id="inline-formula160-1076998611411917">
<mml:math id="mml-inline160-1076998611411917">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>). The response and treatment propensity scores <inline-formula id="inline-formula161-1076998611411917">
<mml:math id="mml-inline161-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi mathvariant="italic">π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> are specified as probit models. We run 2,000 Monte Carlo simulations for two different sample sizes (<italic>n</italic> = 500, 2,000) and compare the accuracy of IPW estimators to naively taking mean differences of treated and nontreated outcomes among respondents. The following tables report the results for untrimmed IPW estimators as hardly any propensity score estimate in any Monte Carlo replication is close to the boundaries of 0 and 1. Therefore, methods incorporating propensity score trimming (see, for instance, <xref ref-type="bibr" rid="bibr9-1076998611411917">Busso, DiNardo, &amp; McCrary, 2009a</xref>; <xref ref-type="bibr" rid="bibr14-1076998611411917">Crump, Hotz, Imbens, &amp; Mitnik, 2009</xref>) yield virtually the same results and are omitted in the article, but are available upon request.</p>
<p>
<xref ref-type="table" rid="table1-1076998611411917">Table 1</xref>

 displays the estimates, bias, standard errors (<italic>SE</italic>) and mean squared errors (MSEs) for the different methods when attrition is related to observables. Note that the ATEs on the entire population and on the respondents are normalized to unity. The IPW estimators following from Propositions <xref ref-type="disp-formula" rid="disp-formula9-1076998611411917">2</xref> and <xref ref-type="disp-formula" rid="disp-formula13-1076998611411917">3</xref> are effective in controlling for attrition bias. <inline-formula id="inline-formula162-1076998611411917">
<mml:math id="mml-inline162-1076998611411917">
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula> are close to the true values and their accuracy in terms of MSE increases in the sample size. In contrast, the mean difference estimator is substantially biased. For the estimation of the ATE on the entire population under the smaller sample size it is, however, competitive in terms of the MSE. This is due to its smaller variance compared to IPW, which introduces additional uncertainty through the estimation of two propensity scores. Under the larger sample size, the persistence of the bias of the mean difference estimator dominates its better precision, such that IPW is clearly superior. In conclusion, the simulation results suggest that IPW is likely to reduce the MSE if the sample size is sufficiently large. Note that many recently conducted social experiments exceed the sample sizes considered in the simulations and typically contain several thousand observations, for example, <xref ref-type="bibr" rid="bibr2-1076998611411917">Angrist et al. (2006)</xref>, <xref ref-type="bibr" rid="bibr3-1076998611411917">Angrist and Lavy (2009)</xref>, <xref ref-type="bibr" rid="bibr6-1076998611411917">Bertrand and Mullainathan (2004)</xref>, <xref ref-type="bibr" rid="bibr25-1076998611411917">Gertler (2004)</xref>, and <xref ref-type="bibr" rid="bibr47-1076998611411917">Krueger and Zhu (2004)</xref>, or even more (<xref ref-type="bibr" rid="bibr45-1076998611411917">Karlan &amp; List, 2007</xref>).</p>
<table-wrap id="table1-1076998611411917" position="float">
<label>Table 1.</label>
<caption>
<p>Attrition on Observables, Simulated Data
</p>
</caption>
<graphic alternate-form-of="table1-1076998611411917" xlink:href="10.3102_1076998611411917-table1.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>
<inline-formula id="inline-formula163-1076998611411917">
<mml:math id="mml-inline163-1076998611411917">
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>
</th>
<th>Bias</th>
<th>
<italic>SE</italic>
</th>
<th>MSE</th>
<th>
<inline-formula id="inline-formula164-1076998611411917">
<mml:math id="mml-inline164-1076998611411917">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>
</th>
<th>Bias</th>
<th>
<italic>SE</italic>
</th>
<th>MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<italic>n</italic> = 500</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td rowspan="3"> IPW obs mean difference true effect (normalized)</td>
<td>1.001</td>
<td>0.001</td>
<td>0.180</td>
<td>0.032</td>
<td>0.998</td>
<td>−0.002</td>
<td>0.112</td>
<td>0.012</td>
</tr>
<tr>
<td>0.883</td>
<td>−0.117</td>
<td>0.135</td>
<td>0.032</td>
<td>0.851</td>
<td>−0.149</td>
<td>0.130</td>
<td>0.039</td>
</tr>
<tr>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
<inline-formula id="inline-formula165-1076998611411917">
<mml:math id="mml-inline165-1076998611411917">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula>= 2,000</td>
<td colspan="8">
</td>
</tr>
<tr>
<td rowspan="3"> IPW obs mean difference true effect (normalized)</td>
<td>1.000</td>
<td>0.000</td>
<td>0.087</td>
<td>0.008</td>
<td>0.998</td>
<td>−0.002</td>
<td>0.056</td>
<td>0.003</td>
</tr>
<tr>
<td>0.882</td>
<td>−0.118</td>
<td>0.066</td>
<td>0.018</td>
<td>0.849</td>
<td>−0.151</td>
<td>0.064</td>
<td>0.027</td>
</tr>
<tr>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1076998611411917">
<p>
<italic>Note</italic>: 2,000 Monte Carlo replications. “IPW obs” controls for attrition related to observables. All effects are normalized to 1.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>
<xref ref-type="table" rid="table2-1076998611411917">Table 2</xref>
 shows the results for IPW estimators (a) controlling for attrition on unobservables (“IPW unobs,” following from Propositions <xref ref-type="disp-formula" rid="disp-formula15-1076998611411917">4</xref> and <xref ref-type="disp-formula" rid="disp-formula19-1076998611411917">5</xref>) and (b) observables alone (“IPW obs,” following from Propositions <xref ref-type="disp-formula" rid="disp-formula9-1076998611411917">2</xref> and <xref ref-type="disp-formula" rid="disp-formula13-1076998611411917">3</xref>) when response depends on unobservables, too. The former methods exploiting the instrument entail only moderate biases and MSEs, whereas the accuracy of IPW only controlling for attrition on observables is considerably lower. When estimating the ATE on the entire population, “IPW obs” performs even worse than the mean difference estimator. That is, omitting the unobserved factor in the attrition model entails poorer results than not controlling for response bias at all. This finding bears great relevance for empirical applications. It implies that using the wrong attrition model and/or accounting for an incomplete set of variables may even be worse than completely ignoring the problem. This underlines the importance of carefully thinking about the attrition process in order to choose a model that is appropriate for the empirical problem at hand.</p>
<table-wrap id="table2-1076998611411917" position="float">
<label>Table 2.</label>
<caption>
<p>Attrition on Unobservables, Simulated Data</p>
</caption>
<graphic alternate-form-of="table2-1076998611411917" xlink:href="10.3102_1076998611411917-table2.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>
<inline-formula id="inline-formula166-1076998611411917">
<mml:math id="mml-inline166-1076998611411917">
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>
</th>
<th>Bias</th>
<th>
<italic>SE</italic>
</th>
<th>MSE</th>
<th>
<inline-formula id="inline-formula167-1076998611411917">
<mml:math id="mml-inline167-1076998611411917">
<mml:msub>
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>
</th>
<th>Bias</th>
<th>
<italic>SE</italic>
</th>
<th>MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<italic>n</italic> = 500</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td rowspan="4"> IPW unobs IPW obs mean difference true effect (normalized)</td>
<td>0.974</td>
<td>−0.026</td>
<td>0.118</td>
<td>0.015</td>
<td>1.009</td>
<td>0.009</td>
<td>0.110</td>
<td>0.012</td>
</tr>
<tr>
<td>0.780</td>
<td>−0.220</td>
<td>0.108</td>
<td>0.060</td>
<td>0.898</td>
<td>−0.102</td>
<td>0.098</td>
<td>0.020</td>
</tr>
<tr>
<td>0.891</td>
<td>−0.109</td>
<td>0.118</td>
<td>0.026</td>
<td>0.878</td>
<td>−0.122</td>
<td>0.116</td>
<td>0.028</td>
</tr>
<tr>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
<italic>n</italic> = 2,000</td>
<td colspan="8">
</td>
</tr>
<tr>
<td rowspan="4"> IPW unobs IPW obs mean difference true effect (normalized)</td>
<td>0.979</td>
<td>−0.021</td>
<td>0.059</td>
<td>0.004</td>
<td>1.014</td>
<td>0.014</td>
<td>0.054</td>
<td>0.003</td>
</tr>
<tr>
<td>0.783</td>
<td>−0.217</td>
<td>0.055</td>
<td>0.050</td>
<td>0.900</td>
<td>−0.100</td>
<td>0.049</td>
<td>0.012</td>
</tr>
<tr>
<td>0.892</td>
<td>−0.108</td>
<td>0.059</td>
<td>0.015</td>
<td>0.879</td>
<td>−0.121</td>
<td>0.058</td>
<td>0.018</td>
</tr>
<tr>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>1.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1076998611411917">
<p>
<italic>Note</italic>: 2,000 Monte Carlo replications. “IPW unobs” controls for attrition related to observables and unobservables, “IPW obs” only for attrition related to observables. All effects are normalized to 1.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Finally, we use a publicly available subsample of Tennessee’s Project STAR Experiment for a simulation study based on empirical data to illustrate the potential gains of IPW when attrition is related to unobservables. The motivation for the use of empirical data is to conduct simulations that are more closely linked to real-world problems with the hope that they are more realistic than studies merely based on generated data. For further examples of simulations that rely on empirical data, see, for instance, <xref ref-type="bibr" rid="bibr5-1076998611411917">Bertrand, Duflo, and Mullainathan (2004)</xref>, <xref ref-type="bibr" rid="bibr16-1076998611411917">Diamond and Sekhon (2006)</xref>, <xref ref-type="bibr" rid="bibr39-1076998611411917">Huber, Lechner, and Wunsch (2010)</xref>, and <xref ref-type="bibr" rid="bibr49-1076998611411917">Lee and Whang (2010)</xref>.</p>
<p>Project STAR was conducted in the mid-1980s to evaluate the effects of small class sizes (target 13–17 students instead of 22–25 students in regular classes) in kindergartens and schools on student achievement; see, for example, Finn and Achilles (1990, <xref ref-type="bibr" rid="bibr19-1076998611411917">1999</xref>) and <xref ref-type="bibr" rid="bibr46-1076998611411917">Krueger (1999)</xref>. A major issue for the applicability of the proposed IPW methods under attrition related to unobservables is the requirement of a continuous instrument. Therefore, future experimental designs might consider the inclusion of (close to) continuous instruments that should ideally be randomly assigned in a similar way as the treatment. As mentioned before, the number of phone calls or financial incentives could be used to instrument the response rate to posttreatment surveys. Up to date, however, such variables are typically not available in social experiments and this is also the case for Project STAR. For this reason, we will pursue a somewhat unorthodox simulation approach to investigate the performance of IPW when estimating the ATE on the entire population under attrition related to unobservables.</p>
<p>The original data set that our simulations are based upon contains 6,325 children in kindergarten. We only use those 5,852 observations for which we observe our outcome of interest (<italic>Y</italic>), namely, the Stanford Achievement Test (SAT) in maths at the end of the kindergarten year (average test score: 485.377, standard deviation: 47.698). From the sample, 1,757 children were randomly assigned to a small class in kindergarten. We discard all treated observations and only keep the sample of controls (<italic>n</italic> = 4,095), which will serve as the population of interest in the simulations. Moreover, a binary placebo treatment <italic>D</italic> is randomly assigned among the controls with a “treatment” probability of 0.5. Thus, the true treatment effect is equal to zero as none of the observations was assigned to a small class. Therefore, we know the correct ATE and can determine the bias and MSE in our simulations, despite the use of empirical data.</p>
<p>In a next step, the experiment is artificially broken by the introduction of the following response process, which is designed such that roughly two thirds of the outcomes are observed:<disp-formula id="disp-formula26-1076998611411917">
<mml:math id="mml-disp26-1076998611411917">
<mml:msub>
<mml:mi>R</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mo fence="false" stretchy="false">{</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>Z</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">−</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>4</mml:mn>
</mml:msub>
<mml:msub>
<mml:mi>U</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">+</mml:mo>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo fence="false" stretchy="false">}</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula26-1076998611411917" xlink:href="10.3102_1076998611411917-eq26.tif"/>
</disp-formula>where <inline-formula id="inline-formula168-1076998611411917">
<mml:math id="mml-inline168-1076998611411917">
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>2.5</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>3</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">β</mml:mi>
<mml:mn>4</mml:mn>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>2</mml:mn>
</mml:math>
</inline-formula>. <italic>X</italic> denotes race (one if white and zero otherwise) which we treat as being observed. <italic>U</italic> represents socioeconomic status (one if eligible for free lunches, zero otherwise) and is assumed not to be observed for the sake of the subsequent simulation. The only generated variables apart from the treatment are the instrument <italic>Z</italic> (uniform, support [–1.5, 1.5]) and the error term <italic>V</italic> (standard normal). As a side remark, note that one could also define <italic>Z</italic> to be an empirical variable that is both continuous and unrelated with <italic>Y</italic> to even further increase the use of real data. Unfortunately, such a variable is not available in the public use file of Project STAR. An inspection of the data shows that both <italic>X</italic> and <italic>U</italic> are strongly correlated with <italic>Y</italic>. Thus, neglecting attrition supposedly biases estimation. Note, however, that the exact relation between race, socioeconomic status, and the SAT score is unknown due to the use of the empirical data. This is fundamentally different to the conventional Monte Carlo design (see the previous simulations) where the outcome equation is explicitly modeled.</p>
<p>In each of the 2,000 Monte Carlo replications, (<italic>Y</italic>, <italic>X</italic>, <italic>U</italic>) are randomly drawn from the “population” without replacement and (<italic>D</italic>, <italic>Z</italic>, <italic>V</italic>) from their respective distributions in order to compute <italic>R</italic>. Then, we estimate the response propensity score by regressing <italic>R</italic> on (1, <italic>D</italic>, <italic>X</italic>, <italic>Z</italic>) and the treatment propensity score, which is unknown in our simulation due to the use of empirical data, by regressing <italic>D</italic> on <inline-formula id="inline-formula169-1076998611411917">
<mml:math id="mml-inline169-1076998611411917">
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mover accent="true">
<mml:mi>p</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">×</mml:mo>
<mml:mover accent="true">
<mml:mi>p</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>W</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> using probit specifications. Contrary to the previous simulations, we estimate the effects with and without trimming of propensity scores as some values are close to the boundaries. We consider two trimming levels, where response propensity scores smaller than 5% (10%) and treatment propensity scores smaller than 5% (10%) or larger than 95% (90%) are trimmed to the respective threshold values.</p>
<p>
<xref ref-type="table" rid="table3-1076998611411917">Table 3</xref>
 presents the results which are in line with the previous simulations. The bias of the IPW estimator is moderate irrespective of the sample size and the trimming level, whereas it amounts to roughly 1.8 SAT scores when taking mean differences. Yet, when considering the smaller sample size, the mean difference estimator is superior with respect to the MSE as it is more precise than IPW. However, as the sample size gets larger IPW increasingly outperforms mean differences. We therefore conclude that weighting based on instruments is effective in reestablishing the validity of experiments under attrition on unobservables, at least when the sample size is not too small such that the gain in bias reduction outweighs the loss in precision due to the estimation of the propensity scores and weighting. Of course, a precondition for this result is the availability of a continuous instrument that is both relevant (sufficiently correlated with response behavior) and valid (no direct effect on the outcome). <xref ref-type="table" rid="table3-1076998611411917">Table 3</xref> also reports the average numbers of trimmed response and treatment propensity scores in the simulations, which are acceptable even under the 10% trimming level.</p>
<table-wrap id="table3-1076998611411917" position="float">
<label>Table 3.</label>
<caption>
<p>Attrition on Unobservables, Empirical Data, Zero Treatment Effect</p>
</caption>
<graphic alternate-form-of="table3-1076998611411917" xlink:href="10.3102_1076998611411917-table3.tif"/>
<table>
<thead>
<tr>
<th>
</th>
<th>
<inline-formula id="inline-formula170-1076998611411917">
<mml:math id="mml-inline170-1076998611411917">
<mml:mover accent="true">
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mo accent="true" stretchy="false">ˆ</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>
</th>
<th>Bias</th>
<th>
<italic>SE</italic>
</th>
<th>MSE</th>
<th>Average Number of Trimmed <inline-formula id="inline-formula171-1076998611411917">
<mml:math id="mml-inline171-1076998611411917">
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi mathvariant="italic">π</mml:mi>
</mml:math>
</inline-formula>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<italic>n</italic> = 500</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td rowspan="5"> IPW unobs (untrimmed) IPW unobs (5% trimming) IPW unobs (10% trimming) mean difference true effect</td>
<td>0.425</td>
<td>0.425</td>
<td>6.197</td>
<td>38.585</td>
<td>
</td>
</tr>
<tr>
<td>0.428</td>
<td>0.428</td>
<td>6.198</td>
<td>38.594</td>
<td>0.000, 16.191</td>
</tr>
<tr>
<td>0.443</td>
<td>0.443</td>
<td>6.200</td>
<td>38.631</td>
<td>0.452, 46.177</td>
</tr>
<tr>
<td>1.768</td>
<td>1.768</td>
<td>5.420</td>
<td>32.389</td>
<td>
</td>
</tr>
<tr>
<td>0.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
<italic>n</italic> = 2,000</td>
<td colspan="5">
</td>
</tr>
<tr>
<td rowspan="5"> IPW unobs (untrimmed) IPW unobs (5% trimming) IPW unobs (10% trimming) mean difference true effect</td>
<td>0.411</td>
<td>0.411</td>
<td>2.994</td>
<td>9.134</td>
<td>
</td>
</tr>
<tr>
<td>0.412</td>
<td>0.412</td>
<td>2.994</td>
<td>9.137</td>
<td>0.000,  24.315</td>
</tr>
<tr>
<td>0.423</td>
<td>0.423</td>
<td>2.997</td>
<td>9.158</td>
<td>0.012, 142.857</td>
</tr>
<tr>
<td>1.772</td>
<td>1.772</td>
<td>2.667</td>
<td>10.252</td>
<td>
</td>
</tr>
<tr>
<td>0.000</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1076998611411917">
<p>
<italic>Note</italic>: 2,000 Monte Carlo replications. “IPW unobs” controls for attrition related to observables and unobservables.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In summary, both studies based on simulated and empirical data suggest that IPW becomes increasingly accurate in terms of the MSE and relatively superior to taking mean differences, as the sample size gets larger and given that the correct attrition process is assumed. This is an interesting finding because there exists, as already briefly mentioned, an important difference between the two designs: Parts of the model, for example, the outcome equation, remain unknown when using empirical data. Therefore, it may not be taken for granted that IPW performs equally well in the latter case, because the threat of incorrectly specifying the treatment propensity score remains even when assuming the correct form of attrition. This advocates a flexible specification of the propensity scores and motivates the use of specification tests in the empirical application presented below.</p>
</sec>
<sec id="section6-1076998611411917">
<title>6. Empirical Application</title>
<p>We present an application of Propositions <xref ref-type="disp-formula" rid="disp-formula15-1076998611411917">4</xref> and <xref ref-type="disp-formula" rid="disp-formula19-1076998611411917">5</xref> (attrition related to observables <italic>and</italic> unobservables) to a labor market policy experiment which was conducted in the United States in the mid-1990s in order to assess the publicly funded Job Corps program. This program (<italic>D</italic>), which is currently administered by 124 local Job Corps centers throughout the United States, targets young individuals (aged 16–24 years) who have a legal residence in the United States and come from a low-income household (see Schochet, Burghardt, and Glazerman, <xref ref-type="bibr" rid="bibr68-1076998611411917">2001</xref>) for further details. It provides participants with approximately 1,100 hours of vocational training and education as well as with housing, board, and health services over an average duration of roughly 8 months. Here, we use a subset of the experimental data analyzed by <xref ref-type="bibr" rid="bibr48-1076998611411917">Lee (2009)</xref>, namely, the female sample that includes 4,044 observations.</p>
<p>Suppose that we would like to learn about the ATE on women’s potential log wages (<italic>Y</italic>) 1 year after program assignment (mean: 1.661; standard deviation: .415). However, we face the problem that wages are only observed for the nonrandom subsample of the 1,454 employed females (<italic>R</italic> = 1). Economic theory suggests that the latter are likely to differ from the nonworking with respect to unobservables such as motivation and ability. From an econometric perspective, this sample selection problem is equivalent to the attrition problem discussed in Section 4. Furthermore, empirical results (see, for instance, <xref ref-type="bibr" rid="bibr51-1076998611411917">Mulligan &amp; Rubinstein, 2008</xref>, among many others) provide strong evidence that socioeconomic characteristics as education, age, race, and labor market experience are important confounders related to both the employment probability and the potential wages. Fortunately, the data set contains information on all of these factors (<italic>X</italic>) that were measured in the baseline survey at the program assignment. Finally, we require one or more instruments (<italic>Z</italic>) that plausibly affect the labor supply decision, but have no direct affect on wages. Following the literature (see, for instance, <xref ref-type="bibr" rid="bibr15-1076998611411917">Das et al., 2003</xref>), we assume the number of children and parents' education to be valid instruments for employment, at least given the other information in the data.</p>
<p>We use a probit specification (see Appendix H, available online at <ext-link ext-link-type="uri" xlink:href="http://jeb.sagepub.com/supplemental">http://jeb.sagepub.com/supplemental</ext-link>) to estimate the labor supply equation required for the computation of the response propensity score. Interestingly, the treatment coefficient is significantly negative, which points to the prevalence of so-called lock-in effects due to reduced job search effort during program participation. This phenomenon is well documented in the literature (see, for instance, <xref ref-type="bibr" rid="bibr70-1076998611411917">Sianesi, 2004</xref>). As expected, education, age, and a favorable labor market history all increase the employment probability. This implies that the working females have better labor market preconditions than the entire sample. Also mother’s education has a positive impact, supposedly through role models, while the coefficient on number of children is negative, albeit not significant. As a model check, we conducted the nonparametric specification test for propensity scores suggested by <xref ref-type="bibr" rid="bibr69-1076998611411917">Shaikh, Simonsen, Vytlacil, and Yildiz (2009)</xref>. The test yields a <italic>p</italic> value of .81 and, therefore, does not reject the null hypothesis of a correct specification. In the second step, we regress the treatment on the observed variables <italic>X</italic> and the response propensity score in order to estimate the treatment propensity score. Again, the specification test does not reject the null at any conventional level.</p>
<p>We estimate the ATEs on the respondents (<inline-formula id="inline-formula172-1076998611411917">
<mml:math id="mml-inline172-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>) and on the entire population (Δ) by the sample analogs of Propositions <xref ref-type="disp-formula" rid="disp-formula14-1076998611411917">4</xref> and <xref ref-type="disp-formula" rid="disp-formula19-1076998611411917">5</xref> and compare them to naively taking mean differences. As in the simulations, we use two trimming levels such that response propensity scores smaller than 5% (10%) and treatment propensity scores smaller than 5% (10%) or larger than 95% (90%) are trimmed to the respective threshold values. Under the first trimming rule, only 1 response and 2 treatment propensity scores are trimmed; under the second rule the respective numbers are 9 and 24. That is, most propensity scores lie well in the interior of the theoretical support. Finally, standard errors are computed based on 1,999 bootstrap replications.</p>
<p>
<xref ref-type="table" rid="table4-1076998611411917">Table 4</xref>
 shows the results on estimation and inference. The estimates suggest that the program increases the wages of working women on average by 5.5% (which is only borderline significant) and those of the entire population by 6%, irrespective of the trimming level. These effects are up to one third higher than the mean difference of 4.5%. Therefore, the results, which are robust under alternative propensity score specifications not reported here, suggest that the mean difference may be downward biased, albeit the differences in the effects are not statistically significant. In conclusion, the ATEs on the working and on all women are within the range (but rather at the lower end) of those commonly found for an additional year of schooling (see, for instance, <xref ref-type="bibr" rid="bibr11-1076998611411917">Card, 1999</xref>). This appears reasonable, given that the scale of the Job Corps program roughly corresponds to a full year in high school, as argued by <xref ref-type="bibr" rid="bibr48-1076998611411917">Lee (2009)</xref>.</p>
<table-wrap id="table4-1076998611411917" position="float">
<label>Table 4.</label>
<caption>
<p>ATE of Training Participation on Log Wage 1 Year Later</p>
</caption>
<graphic alternate-form-of="table4-1076998611411917" xlink:href="10.3102_1076998611411917-table4.tif"/>
<table>
<thead>
<tr>
<th>Method</th>
<th>Estimate</th>
<th>
<italic>SE</italic>
</th>
<th>
<italic>p</italic>-value</th>
</tr>
</thead>
<tbody>
<tr>
<td>IPW unobs (5% trimming): <inline-formula id="inline-formula173-1076998611411917">
<mml:math id="mml-inline173-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>
</td>
<td>0.055</td>
<td>0.034</td>
<td>.108</td>
</tr>
<tr>
<td>IPW unobs (10% trimming): <inline-formula id="inline-formula174-1076998611411917">
<mml:math id="mml-inline174-1076998611411917">
<mml:msub>
<mml:mi mathvariant="normal">Δ</mml:mi>
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:math>
</inline-formula>
</td>
<td>0.055</td>
<td>0.033</td>
<td>.090</td>
</tr>
<tr>
<td>IPW unobs (5% trimming): <inline-formula id="inline-formula175-1076998611411917">
<mml:math id="mml-inline175-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
</mml:math>
</inline-formula>
</td>
<td>0.060</td>
<td>0.028</td>
<td>.031</td>
</tr>
<tr>
<td>IPW unobs (10% trimming): <inline-formula id="inline-formula176-1076998611411917">
<mml:math id="mml-inline176-1076998611411917">
<mml:mi mathvariant="normal">Δ</mml:mi>
</mml:math>
</inline-formula>
</td>
<td>0.060</td>
<td>0.028</td>
<td>.034</td>
</tr>
<tr>
<td>Mean difference conditional on employment</td>
<td>0.045</td>
<td>0.022</td>
<td>.040</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-1076998611411917">
<p>
<italic>Note</italic>: Standard errors are based on 1,999 bootstrap replications. “IPW unobs” controls for attrition related to observables and unobservables.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section7-1076998611411917">
<title>7. Conclusion</title>
<p>This article discusses the identification of treatment effects in randomized experiments when outcomes are only partially observed due to attrition and nonresponse in follow-up surveys. Its first contribution is the systematic coverage of various forms of attrition, that is, when outcomes are MCAR and when attrition is related to observables (MAR) and unobservables. We treat these various forms by imposing different assumptions on the relation between the response behavior and the treatment, the observed covariates, and the unobserved characteristics in a fairly general treatment effect model.</p>
<p>The second contribution is to show point identification of ATEs on the respondents and on the entire population based on different implementations of IPW. Each IPW method is tailored to the specific nature of attrition considered, which provides practitioners with straightforward solutions depending on the suspected missing data problem. In particular, we introduce an IPW approach based on an IV strategy to tackle attrition on unobservables, which was not considered in the experimental literature before. Our simulation results suggest that an incorrect model for attrition, which, for instance, omits attrition on unobservables, may do worse in terms of bias and MSE than not controlling for the missing outcome problem at all. This highlights the importance of a thorough analysis and correct specification of the response behavior.</p>
<p>Despite its technical ease of implementation, the IV-based IPW approach appears to be rarely applicable in social experiments conducted up to date, due to the lack of credible continuous instruments for attrition. This is unfortunate, as attrition on unobservables seems to be a potential threat in many fields of research where randomized trials are conducted (such as education and labor economics), in particular when the number of observed baseline characteristics is low. For example, in an education experiment, unobserved motivation is likely to be correlated both with the outcome (such as the grade or the test score) and the likelihood to respond (e.g., to participate in a test or exam). Therefore, we argue that future experimental research should seriously consider the creation and random assignment of instruments in order to increase the credibility of experimental inference in the presence of attrition. The number of phone calls in follow-up surveys or financial incentives for responding are just two examples for potentially interesting instruments.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The author has benefited from comments by Eva Deuchert, Bernd Fitzenberger, Michael Lechner, Blaise Melly, conference/seminar participants in Freiburg i. B. (research seminar), London (EALE 2010), and Fribourg (SSES 2010), and two anonymous referees.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="bibr1-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ahn</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Powell</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1993</year>). <article-title>Semiparametric estimation of censored selection models with a nonparametric selection mechanism</article-title>. <source>Journal of Econometrics</source>, <volume>58</volume>, <fpage>3</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr2-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Angrist</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Bettinger</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Kremer</surname>
<given-names>M.</given-names>
</name>
</person-group> (<year>2006</year>). <article-title>Long-term educational consequence of secondary school vouchers: Evidence from administrative records in Colombia</article-title>. <source>American Economic Review</source>, <volume>96</volume>, <fpage>847</fpage>–<lpage>862</lpage>.</citation>
</ref>
<ref id="bibr3-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Angrist</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Lavy</surname>
<given-names>V.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>The effects of high stakes high school achievement awards: Evidence from a randomized trial</article-title>. <source>The American Economic Review</source>, <volume>99</volume>, <fpage>1384</fpage>–<lpage>1414</lpage>.</citation>
</ref>
<ref id="bibr4-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Barnard</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Frangakis</surname>
<given-names>C. E.</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>J. L.</given-names>
</name>
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Principal stratification approach to broken randomized experiments: A case study of school choice vouchers in New York City</article-title>. <source>Journal of the American Statistical Association</source>, <volume>98</volume>, <fpage>299</fpage>–<lpage>311</lpage>.</citation>
</ref>
<ref id="bibr5-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bertrand</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Duflo</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Mullainathan</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>How much should we trust differences-in-differences estimates?</article-title>. <source>The Quarterly Journal of Economics</source>, <volume>119</volume>, <fpage>249</fpage>–<lpage>275</lpage>.</citation>
</ref>
<ref id="bibr6-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bertrand</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Mullainathan</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination</article-title>. <source>The American Economic Review</source>, <volume>94</volume>, <fpage>991</fpage>–<lpage>1013</lpage>.</citation>
</ref>
<ref id="bibr7-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bloom</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Orr</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Bell</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Cave</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Doolittle</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Lin</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Bos</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1997</year>). <article-title>The benefits and costs of JTPA title II-A programs: Key findings from the National Job Training Partnership Act study</article-title>. <source>Journal of Human Resources</source>, <volume>32</volume>, <fpage>549</fpage>–<lpage>576</lpage>.</citation>
</ref>
<ref id="bibr8-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Blundell</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Powell</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Endogeneity in nonparametric and semiparametric regression models</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Dewatripont</surname>
<given-names>L. H. M.</given-names>
</name>
<name>
<surname>Turnovsky</surname>
<given-names>S.</given-names>
</name>
</person-group> (Eds.), <source>Advances in economics and econometrics</source> (pp. <fpage>312</fpage>–<lpage>357</lpage>). <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr9-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Busso</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>DiNardo</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>McCrary</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2009a</year>). <source>Finite sample properties of semiparametric estimators of average treatment effects</source>. <comment>Working paper, University of California, Berkeley</comment>
</citation>
</ref>
<ref id="bibr10-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Busso</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>DiNardo</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>McCrary</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2009b</year>). <article-title>New evidence on the finite sample properties of propensity score matching and reweighting estimators</article-title>. <comment>IZA Discussion Paper No. 3998</comment>
</citation>
</ref>
<ref id="bibr11-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Card</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>The causal effect of education on earnings</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Ashenfelter</surname>
<given-names>O.</given-names>
</name>
<name>
<surname>Card</surname>
<given-names>D.</given-names>
</name>
</person-group> (Eds.), <source>Handbook of labor economics</source> (pp. <fpage>1802</fpage>–<lpage>1863</lpage>). <publisher-loc>Amsterdam, Netherlands</publisher-loc>: <publisher-name>North-Holland</publisher-name>.</citation>
</ref>
<ref id="bibr12-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Castiglioni</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Pforr</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Krieger</surname>
<given-names>U.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>The effect of incentives on response rates and panel attrition: Results of a controlled experiment</article-title>. <source>Survey Research Methods</source>, <volume>2</volume>, <fpage>151</fpage>–<lpage>158</lpage>.</citation>
</ref>
<ref id="bibr13-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cochran</surname>
<given-names>W. G.</given-names>
</name>
<name>
<surname>Chambers</surname>
<given-names>S. P.</given-names>
</name>
</person-group> (<year>1965</year>). <article-title>The planning of observational studies of human populations</article-title>. <source>Journal of the Royal Statistical Society Series A</source>, <volume>128</volume>, <fpage>234</fpage>–<lpage>265</lpage>.</citation>
</ref>
<ref id="bibr14-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Crump</surname>
<given-names>R. K.</given-names>
</name>
<name>
<surname>Hotz</surname>
<given-names>V. J.</given-names>
</name>
<name>
<surname>Imbens</surname>
<given-names>G. W.</given-names>
</name>
<name>
<surname>Mitnik</surname>
<given-names>O. A.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Dealing with limited overlap in estimation of average treatment effects</article-title>. <source>Biometrika</source>, <volume>96</volume>, <fpage>187</fpage>–<lpage>199</lpage>.</citation>
</ref>
<ref id="bibr15-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Das</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Newey</surname>
<given-names>W. K.</given-names>
</name>
<name>
<surname>Vella</surname>
<given-names>F.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Nonparametric estimation of sample selection models</article-title>. <source>Review of Economic Studies</source>, <volume>70</volume>, <fpage>33</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr16-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Diamond</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Sekhon</surname>
<given-names>J. S.</given-names>
</name>
</person-group> (<year>2006</year>). . In <source>Genetic matching for estimating causal effects: A general multivariate matching method for achieving balance in observational studies</source>. <publisher-name>Institute of Governmental Studies Working Paper. University of California, Berkeley</publisher-name>.</citation>
</ref>
<ref id="bibr17-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>DiNardo</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>McCrary</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Sanbonmatsu</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>2006</year>). . In <source>Constructive proposals for dealing with attrition: An empirical example</source>. <publisher-loc>Ann Arbor</publisher-loc>: <publisher-name>University of Michigan</publisher-name>.<comment>. Working paper</comment>
</citation>
</ref>
<ref id="bibr18-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Duflo</surname>
<given-names>E.</given-names>
</name>
</person-group> (<year>2006</year>). <article-title>Field experiments in development economics</article-title>. In 
<person-group person-group-type="editor">
<name>
<surname>Blundell</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Newey</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Persson</surname>
<given-names>T.</given-names>
</name>
</person-group> (Eds.), <source>Advances in economics and econometrics</source> (<volume>Vol. 2</volume>, pp. <fpage>322</fpage>–<lpage>48</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>
</citation>
</ref>
<ref id="bibr19-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Finn</surname>
<given-names>H. D.</given-names>
</name>
<name>
<surname>Achilles</surname>
<given-names>C. M.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Tennessee’s class size study: Findings, implications, misconceptions</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>21</volume>, <fpage>97</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr20-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Fisher</surname>
<given-names>R.</given-names>
</name>
</person-group> (<year>1925</year>). . In <source>Statistical methods for research workers</source>. <publisher-loc>Edinburgh, UK</publisher-loc>: <publisher-name>Oliver and Boyd</publisher-name>.</citation>
</ref>
<ref id="bibr21-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Fisher</surname>
<given-names>R.</given-names>
</name>
</person-group> (<year>1935</year>). . In <source>The design of experiments</source>. <publisher-loc>Edinburgh, UK</publisher-loc>: <publisher-name>Oliver and Boyd</publisher-name>.</citation>
</ref>
<ref id="bibr22-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fitzgerald</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Gottschalk</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Moffitt</surname>
<given-names>R.</given-names>
</name>
</person-group> (<year>1998</year>). <article-title>An analysis of sample attrition in panel data: The Michigan panel study of income dynamics</article-title>. <source>The Journal of Human Resources</source>, <volume>33</volume>, <fpage>251</fpage>–<lpage>299</lpage>.</citation>
</ref>
<ref id="bibr23-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Frangakis</surname>
<given-names>C. E.</given-names>
</name>
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>2002</year>). <article-title>The defining role of principal stratification and effects for comparing treatments adjusted for posttreatment variables: From treatment noncompliance to surrogate endpoints</article-title>. <source>Biometrics</source>, <volume>58</volume>, <fpage>191</fpage>–<lpage>199</lpage>.</citation>
</ref>
<ref id="bibr24-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Freedman</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>2006</year>). <article-title>Statistical models for causation: What inferential leverage do they provide</article-title>. <source>Evaluation Review</source>, <volume>30</volume>, <fpage>691</fpage>–<lpage>713</lpage>.</citation>
</ref>
<ref id="bibr25-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gertler</surname>
<given-names>P.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Do conditional cash transfers improve child health? Evidence form PROGRESA’s control randomized experiment</article-title>. <source>The American Economic Review</source>, <volume>94</volume>, <fpage>336</fpage>–<lpage>341</lpage>.</citation>
</ref>
<ref id="bibr26-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Grilo</surname>
<given-names>C. M.</given-names>
</name>
<name>
<surname>Money</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Barlow</surname>
<given-names>D. H.</given-names>
</name>
<name>
<surname>Goddard</surname>
<given-names>A. W.</given-names>
</name>
<name>
<surname>Gorman</surname>
<given-names>J. M.</given-names>
</name>
<name>
<surname>Hofmann</surname>
<given-names>S. G., </given-names>
</name>
<name>
<surname>… Woods</surname>
<given-names>S. W.</given-names>
</name>
</person-group> (<year>1998</year>). <article-title>Pretreatment patient factors predicting attrition from a multicenter randomized controlled treatment study for panic disorder</article-title>. <source>Comprehensive Psychiatry</source>, <volume>39</volume>, <fpage>323</fpage>–<lpage>332</lpage>.</citation>
</ref>
<ref id="bibr27-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Grogger</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Bounding the effects of social experiments: Accounting for attrition in administrative data</article-title>. <source>mimeo</source>, </citation>
</ref>
<ref id="bibr28-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harrison</surname>
<given-names>G. W.</given-names>
</name>
<name>
<surname>List</surname>
<given-names>J. A.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Field experiments</article-title>. <source>Journal of Economic Literature</source>, <volume>42</volume>, <fpage>1009</fpage>–<lpage>1055</lpage>.</citation>
</ref>
<ref id="bibr29-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hausman</surname>
<given-names>J. A.</given-names>
</name>
<name>
<surname>Wise</surname>
<given-names>D. A.</given-names>
</name>
</person-group> (<year>1979</year>). <article-title>Attrition bias in experimental and panel date: The Gary income maintenance experiment</article-title>. <source>Econometrica</source>, <volume>47</volume>, <fpage>455</fpage>–<lpage>473</lpage>.</citation>
</ref>
<ref id="bibr30-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heckman</surname>
<given-names>J. J.</given-names>
</name>
</person-group> (<year>1974</year>). <article-title>Shadow prices, market wages and labor supply</article-title>. <source>Econometric</source>, <volume>42</volume>, <fpage>679</fpage>–<lpage>694</lpage>.</citation>
</ref>
<ref id="bibr31-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heckman</surname>
<given-names>J. J.</given-names>
</name>
</person-group> (<year>1976</year>). <article-title>The common structure of statistical models of truncation, sample selection and limited dependent variables and a simple estimator for such models</article-title>. <source>Annals of Economic and Social Measurement</source>, <volume>5</volume>, <fpage>475</fpage>–<lpage>492</lpage>.</citation>
</ref>
<ref id="bibr32-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heckman</surname>
<given-names>J. J.</given-names>
</name>
</person-group> (<year>1979</year>). <article-title>Sample selection bias as a specification error</article-title>. <source>Econometrica</source>, <volume>47</volume>, <fpage>153</fpage>–<lpage>161</lpage>.</citation>
</ref>
<ref id="bibr33-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heitjan</surname>
<given-names>D. F.</given-names>
</name>
<name>
<surname>Basu</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>1996</year>). <article-title>Distinguishing missing at random and missing completely at random</article-title>. <source>The American Statisticia</source>, <volume>50</volume>, <fpage>207</fpage>–<lpage>213</lpage>.</citation>
</ref>
<ref id="bibr34-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hirano</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Imbens</surname>
<given-names>G. W.</given-names>
</name>
<name>
<surname>Ridder</surname>
<given-names>G.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Efficient estimation of average treatment effects using the estimated propensity score</article-title>. <source>Econometrica</source>, <volume>71</volume>, <fpage>1161</fpage>–<lpage>1189</lpage>.</citation>
</ref>
<ref id="bibr35-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Horowitz</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Manski</surname>
<given-names>C. F.</given-names>
</name>
</person-group> (<year>1998</year>). <article-title>Censoring of outcomes and regressors due to survey nonresponse: Identification and estimation using weights and Imputations</article-title>. <source>Journal of Econometrics</source>, <volume>84</volume>, <fpage>37</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr36-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Horowitz</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Manski</surname>
<given-names>C. F.</given-names>
</name>
</person-group> (<year>2000</year>). <article-title>Nonparametric analysis of randomized experiments with missing covariate and outcome data</article-title>. <source>Journal of the American Statistical Association</source>, <volume>95</volume>, <fpage>77</fpage>–<lpage>84</lpage>.</citation>
</ref>
<ref id="bibr37-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Horvitz</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Thompson</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>1952</year>). <article-title>A generalization of sampling without replacement from a finite population</article-title>. <source>Journal of American Statistical Association</source>, <volume>47</volume>, <fpage>663</fpage>–<lpage>685</lpage>.</citation>
</ref>
<ref id="bibr38-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Huber</surname>
<given-names>B.</given-names>
</name>
</person-group> (<year>2009</year>). . In <source>Treatment evaluation in the presence of sample selection <italic>(Department of Economics Discussion Paper no. 2009–07)</italic>
</source>. <publisher-loc>Switzerland</publisher-loc>: <publisher-name>University of St. Gallen</publisher-name>.</citation>
</ref>
<ref id="bibr39-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Huber</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Lechner</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Wunsch</surname>
<given-names>C.</given-names>
</name>
</person-group> (<year>2010</year>). . In <source>How to control for many covariates? Reliable estimators based on the propensity score</source>. <comment>IZA Discussion Paper no. 5268. Institute for the Study of Labor, Bonn, Germany</comment>
</citation>
</ref>
<ref id="bibr40-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Imai</surname>
<given-names>K.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Statistical analysis of randomized experiments with non-ignorable missing binary outcomes: An application to a voting experiment</article-title>. <source>Journal of the Royal Statistical Society Series C</source>, <volume>58</volume>, <fpage>83</fpage>–<lpage>104</lpage>.</citation>
</ref>
<ref id="bibr41-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Imbens</surname>
<given-names>G. W.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Nonparametric estimation of average treatment effects under exogeneity: A review</article-title>. <source>The Review of Economics and Statistics</source>, <volume>86</volume>, <fpage>4</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr42-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Imbens</surname>
<given-names>G. W.</given-names>
</name>
</person-group> (<year>2009</year>). <source>Better LATE than nothing: Some Comments on Deaton (2009) and Heckman and Urzua (2009)</source>. <comment>NBER Working Paper No. 14896. The National Bureau of Economic Research, Cambridge, MA</comment>
</citation>
</ref>
<ref id="bibr43-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Imbens</surname>
<given-names>G. W.</given-names>
</name>
<name>
<surname>Newey</surname>
<given-names>W.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Identification and estimation of triangular simultaneous equations models without additivity</article-title>. <source>Econometrica</source>, <volume>77</volume>, <fpage>1481</fpage>–<lpage>1512</lpage>.</citation>
</ref>
<ref id="bibr44-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Imbens</surname>
<given-names>G. W.</given-names>
</name>
<name>
<surname>Wooldridge</surname>
<given-names>J. M.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Recent developments in the econometrics of program evaluation</article-title>. <source>Journal of Economic Literature</source>, <volume>47</volume>, <fpage>5</fpage>–<lpage>86</lpage>.</citation>
</ref>
<ref id="bibr45-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Karlan</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>List</surname>
<given-names>J. A.</given-names>
</name>
</person-group> (<year>2007</year>). <article-title>Does price matter in charitable giving? Evidence from a large-scale natural field experiment</article-title>. <source>The American Economic Review</source>, <volume>97</volume>, <fpage>1774</fpage>–<lpage>1793</lpage>.</citation>
</ref>
<ref id="bibr46-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krueger</surname>
<given-names>A. B.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Experimental estimates of education production functions</article-title>. <source>Quarterly Journal of Economics</source>, <volume>114</volume>, <fpage>497</fpage>–<lpage>532</lpage>.</citation>
</ref>
<ref id="bibr47-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krueger</surname>
<given-names>A. B.</given-names>
</name>
<name>
<surname>Zhu</surname>
<given-names>P.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>Another look at the New York City school voucher experiment</article-title>. <source>American Behavioral Scientist</source>, <volume>47</volume>, <fpage>658</fpage>–<lpage>698</lpage>.</citation>
</ref>
<ref id="bibr48-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lee</surname>
<given-names>D. S.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>Training, wages, and sample selection: Estimating sharp bounds on treatment effects</article-title>. <source>Review of Economic Studies</source>, <volume>76</volume>, <fpage>1071</fpage>–<lpage>1102</lpage>.</citation>
</ref>
<ref id="bibr49-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lee</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Whang</surname>
<given-names>Y.-J.</given-names>
</name>
</person-group> (<year>2010</year>). <source>Nonparametric tests of conditional treatment effects</source>, <comment>. CeMMAP Working Paper CWP36/09. Centre for Microdata Methods and Practice, London, UK</comment>
</citation>
</ref>
<ref id="bibr50-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Mealli</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Pacini</surname>
<given-names>B.</given-names>
</name>
</person-group>, (<year>2008</year>). <article-title>Exploiting instrumental variables in causal inference with nonignorable outcome nonresponse using principal stratification</article-title>. <source>mimeo</source>
</citation>
</ref>
<ref id="bibr51-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mulligan</surname>
<given-names>C. B.</given-names>
</name>
<name>
<surname>Rubinstein</surname>
<given-names>Y.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Selection, investment, and women’s relative wages over time</article-title>. <source>Quarterly Journal of Economics</source>, <volume>123</volume>, <fpage>1061</fpage>–<lpage>1110</lpage>.</citation>
</ref>
<ref id="bibr52-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Newey</surname>
<given-names>W. K.</given-names>
</name>
</person-group> (<year>2007</year>). <article-title>Nonparametric continuous/discrete choice models</article-title>. <source>International Economic Review</source>, <volume>48</volume>, <fpage>1429</fpage>–<lpage>1439</lpage>.</citation>
</ref>
<ref id="bibr53-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Newey</surname>
<given-names>W. K.</given-names>
</name>
<name>
<surname>Powell</surname>
<given-names>J. L.</given-names>
</name>
<name>
<surname>Vella</surname>
<given-names>F.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Nonparametric estimation of triangular simultaneous equations models</article-title>. <source>Econometrica</source>, <volume>67</volume>, <fpage>565</fpage>–<lpage>603</lpage>.</citation>
</ref>
<ref id="bibr54-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Neyman</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1923</year>). <article-title>On the application of probability theory to agricultural experiments. Essay on principles</article-title>. <source>Statistical Science</source>, <volume>Reprint, 5</volume>, <fpage>463</fpage>–<lpage>480</lpage>.</citation>
</ref>
<ref id="bibr55-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Robins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rotnitzky</surname>
<given-names>A.</given-names>
</name>
</person-group> (<year>1995</year>). <article-title>Semiparametric efficiency in multivariate regression models with missing data</article-title>. <source>Journal of American Statistical Association</source>, <volume>90</volume>, <fpage>122</fpage>–<lpage>129</lpage>.</citation>
</ref>
<ref id="bibr56-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Robins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rotnitzky</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Zhao</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>1995</year>). <article-title>Analysis of semiparametric regression models for repeated outcomes in the presence of missing data</article-title>. <source>Journal of American Statistical Association</source>, <volume>90</volume>, <fpage>106</fpage>–<lpage>121</lpage>.</citation>
</ref>
<ref id="bibr57-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Robins</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Tsiatis</surname>
<given-names>A.</given-names>
</name>
</person-group> (<year>1991</year>). <article-title>Correcting for non-compliance in randomized trials using rank-preserving structural failure time models</article-title>. <source>Communications in Statistics</source>, <volume>20</volume>, <fpage>2069</fpage>–<lpage>2631</lpage>.</citation>
</ref>
<ref id="bibr58-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rosenbaum</surname>
<given-names>P. R.</given-names>
</name>
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1983</year>). <article-title>The central role of the propensity score in observational studies for causal effects</article-title>. <source>Biometrika</source>, <volume>70</volume>, <fpage>41</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr59-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rotnitzky</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Robins</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>1995</year>). <article-title>Semiparametric regression estimation in the presence of dependent censoring</article-title>. <source>Biometrika</source>, <volume>82</volume>, <fpage>805</fpage>–<lpage>820</lpage>.</citation>
</ref>
<ref id="bibr60-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1974</year>). <article-title>Estimating causal effects of treatments in randomized and nonrandomized studies</article-title>. <source>Journal of Educational Psychology</source>, <volume>66</volume>, <fpage>688</fpage>–<lpage>701</lpage>.</citation>
</ref>
<ref id="bibr61-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1976</year>). <article-title>Inference and missing data</article-title>. <source>Biometrika</source>, <volume>63</volume>, <fpage>581</fpage>–<lpage>592</lpage>.</citation>
</ref>
<ref id="bibr62-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1977</year>). <article-title>Formalizing subjective notions about the effect of nonrespondents in sample surveys</article-title>. <source>Journal of the American Statistical Association</source>, <volume>72</volume>, <fpage>538</fpage>–<lpage>543</lpage>.</citation>
</ref>
<ref id="bibr63-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1978</year>). <article-title>Multiple imputations in sample surveys—A phenomenological Bayesian approach to nonresponse</article-title>. In <source>Proceedings of the Survey Research Methods Section, American Statistical Association</source> (pp. <fpage>20</fpage>–<lpage>34</lpage>). <publisher-loc>Alexandria, VA</publisher-loc>: <publisher-name>American Statistical Association</publisher-name>.</citation>
</ref>
<ref id="bibr64-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1990</year>). <article-title>Formal modes of statistical inference for causal effects</article-title>. <source>Journal of Statistical Planning and Inference</source>, <volume>25</volume>, <fpage>279</fpage>–<lpage>292</lpage>.</citation>
</ref>
<ref id="bibr65-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1996</year>). <article-title>Multiple imputation after 18+ Years</article-title>. <source>Journal of the American Statistical Association</source>, <volume>91</volume>, <fpage>473</fpage>–<lpage>489</lpage>.</citation>
</ref>
<ref id="bibr66-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>For objective causal inference, design trumps analysis</article-title>. <source>The Annals of Applied Statistics</source>, <volume>2</volume>, <fpage>808</fpage>–<lpage>840</lpage>.</citation>
</ref>
<ref id="bibr67-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Scharfstein</surname>
<given-names>D. O.</given-names>
</name>
<name>
<surname>Rotnitzky</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Robins</surname>
<given-names>J. M.</given-names>
</name>
</person-group> (<year>1999</year>). <article-title>Adjusting for nonignorable drop-out using semiparametric nonresponse models</article-title>. <source>Journal of the American Statistical Association</source>, <volume>94</volume>, <fpage>1096</fpage>–<lpage>1120</lpage>.</citation>
</ref>
<ref id="bibr68-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Schochet</surname>
<given-names>P. Z.</given-names>
</name>
<name>
<surname>Burghardt</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Glazerman</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>2001</year>). . In <source>National Job Corps study: The impacts of Job Corps on participants employment and related outcomes</source>. <publisher-loc>Report. Washington, DC</publisher-loc>: <publisher-name>Mathematica Policy Research</publisher-name>.</citation>
</ref>
<ref id="bibr69-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Shaikh</surname>
<given-names>A. M.</given-names>
</name>
<name>
<surname>Simonsen</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Vytlacil</surname>
<given-names>E. J.</given-names>
</name>
<name>
<surname>Yildiz</surname>
<given-names>N.</given-names>
</name>
</person-group> (<year>2009</year>). <article-title>A specification test for the propensity score using its distribution conditional on participation</article-title>. <source>Journal of Econometrics</source>, <volume>151</volume>, <fpage>33</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr70-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sianesi</surname>
<given-names>B.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>An evaluation of the Swedish system of active labour market programs in the 1990s</article-title>. <source>Review of Economics and Statistics</source>, <volume>86</volume>, <fpage>133</fpage>–<lpage>155</lpage>.</citation>
</ref>
<ref id="bibr71-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wooldridge</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2002</year>). <article-title>Inverse probability weighted M-estimators for sample selection, attrition and stratification</article-title>. <source>Portuguese Economic Journal</source>, <volume>1</volume>, <fpage>141</fpage>–<lpage>162</lpage>.</citation>
</ref>
<ref id="bibr72-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wooldridge</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2007</year>). <article-title>Inverse probability weighted estimation for general missing data problems</article-title>. <source>Journal of Econometrics</source>, <volume>141</volume>, <fpage>1281</fpage>–<lpage>1301</lpage>.</citation>
</ref>
<ref id="bibr73-1076998611411917">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>2003</year>). <article-title>Estimation of causal effects via principal stratification when some outcome are truncated by death</article-title>. <source>Journal of Educational and Behavioral Statistics</source>, <volume>28</volume>, <fpage>353</fpage>–<lpage>368</lpage>.</citation>
</ref>
<ref id="bibr74-1076998611411917">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rubin</surname>
<given-names>D. B.</given-names>
</name>
<name>
<surname>Mealli</surname>
<given-names>F.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Evaluating the effects of job training programs on wages through principal stratification</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Millimet</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Smith</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Vytlacil</surname>
<given-names>E.</given-names>
</name>
</person-group> (Eds.), <source>Advances in econometrics: Modelling and evaluating treatment effects in econometrics</source> (<volume>Vol. 21</volume>, pp. <fpage>117</fpage>–<lpage>145</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Elsevier Science Ltd</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>