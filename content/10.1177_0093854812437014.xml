<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">CJB</journal-id>
<journal-id journal-id-type="hwp">spcjb</journal-id>
<journal-title>Criminal Justice and Behavior</journal-title>
<issn pub-type="ppub">0093-8548</issn>
<issn pub-type="epub">1552-3594</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0093854812437014</article-id>
<article-id pub-id-type="publisher-id">10.1177_0093854812437014</article-id>
<title-group>
<article-title>LIE Detection by Inducing Cognitive Load</article-title>
<subtitle>Eye Movements and Other Cues to the False Answers of “Witnesses” to Crimes</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Walczyk</surname><given-names>Jeffrey J.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Griffith</surname><given-names>Diana A.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Yates</surname><given-names>Rachel</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Visconte</surname><given-names>Shelley R.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Simoneaux</surname><given-names>Byron</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Harris</surname><given-names>Laura L.</given-names></name>
</contrib>
<aff id="aff1-0093854812437014">Louisiana Tech University</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0093854812437014">Jeffrey J. Walczyk, Psychology &amp; Behavioral Sciences, P.O. Box 10048, Louisiana Tech University, Ruston, LA 71272 e-mail: <email>Walczyk@latech.edu</email>.</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2012</year>
</pub-date>
<volume>39</volume>
<issue>7</issue>
<fpage>887</fpage>
<lpage>909</lpage>
<permissions>
<copyright-statement>© 2012 International Association for Correctional and Forensic Psychology</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">International Association for Correctional and Forensic Psychology</copyright-holder>
</permissions>
<abstract>
<p>Research on the accuracy of eyewitness testimony has expanded dramatically in recent years. Most of it concerns the issue of mistaken identification, not the problem of uncovering deceptive accounts of witnesses, which is the focus of this research. In the literature, a technique for lie detection has been proposed that induces cognitive load on liars by averting their rehearsal of deception: <italic>Time Restricted Integrity-Confirmation</italic>. The current authors tested it by instructing “witnesses” of actual crime videos to lie or tell the truth to related questions. Each of 145 adults was randomly assigned to a truth telling, an unrehearsed lying, or a rehearsed lying condition. The cognitive cues were response time, answer consistency, eye movements, and pupil dilation. Eye data were gathered with an infrared eye tracker. Truth tellers had the quickest response times and the fewest inconsistencies. Moreover, they generally had more eye movements, suggesting low cognitive loads. Discriminant analyses classified rehearsed liars, unrehearsed liars, and truth tellers up to 69% accurately, with few false positives. Further refinement is warranted.</p>
</abstract>
<kwd-group>
<kwd>lie detection</kwd>
<kwd>rehearsal</kwd>
<kwd>cognition and deception</kwd>
<kwd>eyewitness testimony</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Eyewitness testimony is often the evidence most persuasive to juries despite its unreliability (<xref ref-type="bibr" rid="bibr2-0093854812437014">Bond &amp; DePaulo, 2006</xref>; <xref ref-type="bibr" rid="bibr18-0093854812437014">Loftus, 2007</xref>). In some cases, such testimony was crucial for conviction, even when there was compelling exculpatory evidence (<xref ref-type="bibr" rid="bibr17-0093854812437014">Loftus, 1979</xref>). Advances in DNA testing applied to postconviction cases have led to the release of more than 240 inmates wrongfully convicted partly by mistaken eyewitness testimony (<xref ref-type="bibr" rid="bibr8-0093854812437014">Garrett, 2010</xref>). Most validity concerns over eyewitness testimony involve mistaken identification (<xref ref-type="bibr" rid="bibr18-0093854812437014">Loftus, 2007</xref>; <xref ref-type="bibr" rid="bibr42-0093854812437014">Wells &amp; Olson, 2003</xref>), not the deceptive testimony of witnesses. More research is needed on detecting it. The present study is relevant to eventually reducing false confessions, false alibis, and perjured testimony of witnesses through cognitive lie detection.</p>
<sec id="section1-0093854812437014">
<title>Lies During Questioning, Perjured Testimony, and Their Detection</title>
<p>A pernicious source of invalid testimony is witnesses giving deceptive accounts to investigators or perjuring themselves on the stand. If witnesses know the accused, they sometimes feel compelled to provide a false alibi or identification to shield him or her or to protect themselves from reprisal from a disgruntled suspect (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>). Researchers have identified a number of signs of deceptive testimony. <xref ref-type="bibr" rid="bibr26-0093854812437014">Porter and Yuille (1996)</xref> instructed participants to lie about their involvement in a mock crime and had some create false alibis. Investigators observed that accounts of those in the false alibi condition had fewer details, less coherence, and were less likely to admit they had forgotten a detail of an event. Overconfidence when recounting details of events can thus signal deception.</p>
<p>Researchers have also compared the police with lay people in their ability to detect deception. <xref ref-type="bibr" rid="bibr9-0093854812437014">Garrido, Masip, and Herrero (2004)</xref> contrasted 121 officers with 146 college students in the accuracy of judging deceptive and truthful videotaped statements. The accuracy of the officers was at chance level, whereas that of laypeople was slightly higher. Police officers reported higher confidence in their lie detection abilities, though Garrido et al. argued that officers’ overconfidence potentially hinders their learning of actual cues to deceit. These findings, replicated by others (<xref ref-type="bibr" rid="bibr11-0093854812437014">Hartwig, Granhag, Stromwall, &amp; Vrij, 2004</xref>; <xref ref-type="bibr" rid="bibr31-0093854812437014">Vrij, 1993</xref>), run contrary to the stereotype of the public that police officers are superlative lie detectors (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>). However, in a review of studies of the accuracy of police officers, <xref ref-type="bibr" rid="bibr24-0093854812437014">O’Sullivan, Frank, and Hurley (2009)</xref> found that police could detect deception significantly beyond chance when the lies being witnessed involve high stakes for the liar, such as when a perpetrator discloses a false alibi (see also <xref ref-type="bibr" rid="bibr2-0093854812437014">Bond &amp; DePaulo, 2006</xref>). Cues to deception multiply as motivated liars monitor and try to control their behavior to appear truthful (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>).</p>
<p>Jurors often do no better as lie detectors. <xref ref-type="bibr" rid="bibr14-0093854812437014">Landström, Granhag, and Hartwig (2005)</xref> examined various cues to deception available to 122 mock jurors who evaluated the testimony of 12 witnesses, half of whom lied when testifying about a staged accident that took place 3 weeks prior. Jurors were asked to judge the truthfulness of witnesses, justify their judgments, and rate witnesses on various behavioral dimensions. Analyses showed that observers’ perceptions of truthfulness were influenced by the plausibility of statements, how much detail they contained, and how confidently witnesses relayed them. Additionally, the appearance of witnesses affected judgments, including how hard witnesses had to think, how at ease they were, their eloquence in speech, and their pleasantness. Jurors performed poorly at detecting deception. In fact, how hard the witness had to think (e.g., the time needed to respond) was the only cue they used that correlated with deception, which is also a basic cue of the cognitive lie detector tested in this research.</p>
<p>In conclusion, lies during questioning and deceptive testimony in courtrooms are serious threats to procedural justice (<xref ref-type="bibr" rid="bibr8-0093854812437014">Garrett, 2010</xref>). Moreover, deceptive and perjured testimony (e.g., false alibis) can slip past investigators and jurors because of their weak abilities as lie detectors. Regarding the latter, there has been much recent criticism of the validity of the polygraph, the most common method of lie detection, and calls for alternatives technologies (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>; <xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>; <xref ref-type="bibr" rid="bibr22-0093854812437014">National Research Council [NRC], 2003</xref>). This research advances the development of a cognitive-based alternative to the polygraph with potential to uncover deceptive testimony.</p>
</sec>
<sec id="section2-0093854812437014">
<title>Lie Detection by Inducing Cognitive Load: Averting Rehearsal</title>
<p><xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al. (2005</xref>) introduced a novel approach to lie detection intended to maximize cognitive load on liars and minimize it on truth tellers by averting the rehearsal of deceptive answers: Time Restricted Integrity-Confirmation (TRI-Con). In essence, it surprises examinees with questions by following these guidelines during lie detection examinations: (a) Examinees are prompted about the focus of the questions to follow (e.g., “The next 15 questions concern your relationship with the suspect prior to the crime”). By preactivating relevant nodes of episodic memory, <italic>prompting</italic> reduces examinees’ need for explicit memory searching to answer truthfully and so should make cognitive cues to deception less confounded. (b) The specific questions are not made known to examinees until the examination itself to discourage the rehearsal of lies. (c) Questions should be answerable in one or two words (e.g., “Did you see the shooting?”), thereby making determination of the time needed to fully answer a question clearer compared to questions evoking narratives (e.g., “What happened during the crime?”). (d) Examinees are instructed to answer quickly to limit their opportunity to prepare lies. (e) Interrelated questions are asked to increase liars’ cognitive load and provoke contradictions, found to be higher in liars (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>), especially without rehearsal (<xref ref-type="bibr" rid="bibr34-0093854812437014">Vrij et al., 2009</xref>). We now add another guideline to enhance cognitive load on liars. (f) When feasible, examinees should be instructed to maintain eye contact with the examiner (<xref ref-type="bibr" rid="bibr36-0093854812437014">Vrij, Mann, Leal, &amp; Fisher, 2010</xref>).</p>
<p>Requiring sustained eye contact should make gaze aversion and eye movements more obvious. <xref ref-type="bibr" rid="bibr10-0093854812437014">Glenberg, Schroeder, and Robertson (1998)</xref> asked participants moderately difficult general informational questions requiring memory searching and showed that averting gaze away from environmental distraction facilitated the allocation of cognitive resources to internal processing that enhanced performance. <xref ref-type="bibr" rid="bibr7-0093854812437014">Doherty-Sneddon and Phelps (2005)</xref> and <xref ref-type="bibr" rid="bibr6-0093854812437014">Doherty-Sneddon, Bruce, Bonner, Longbotham, and Doyle (2002)</xref> replicated these results with children. If lying is more cognitively demanding than truth telling, we propose that a corollary of Glenberg et al.’s position is that less eye movement should be evident during deception. Clearly, eye movements can increase visual stimulation that might be distracting to someone who is focusing attention inwardly to generate a lie. This study is the first to test this possibility.</p>
</sec>
<sec id="section3-0093854812437014">
<title>Lie Detection by Inducing Cognitive Load: Dual Tasking</title>
<p>Following TRI-Con’s introduction, researchers have proposed other ways that lie detection procedures might induce cognitive load selectively on liars. <xref ref-type="bibr" rid="bibr33-0093854812437014">Vrij, Fisher, Mann, and Leal (2008)</xref> labeled two load-related approaches. The <italic>mere cognitive load approach</italic> is based on the hypothesis that lying is inherently more cognitively demanding of limited attention and working memory than truth telling (<xref ref-type="bibr" rid="bibr30-0093854812437014">Sporer &amp; Schwandt, 2007</xref>; <xref ref-type="bibr" rid="bibr43-0093854812437014">Zuckerman, DePaulo, &amp; Rosenthal, 1981</xref>). Empirical support for this hypothesis is weak (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>; <xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al., 2005</xref>). Vrij et al. named another the <italic>increase cognitive load approach</italic>, which concerns methods for inducing cognitive load on liars. These authors discussed what we now call <italic>dual tasking</italic> (performing two tasks concurrently). This is a well-known experimental paradigm for determining the architecture of the mind (<xref ref-type="bibr" rid="bibr25-0093854812437014">Pashler, 1994</xref>). As an example of a concurrent task in lie detection, Vrij et al. suggested that examinees could answer an investigator’s questions while also engaging in a computerized driving simulation. If deception is more cognitively demanding than truthfulness, the simulation should interfere more with liars than truth tellers and enhance cognitive cues. In a milder form of what investigators argue is dual tasking, <xref ref-type="bibr" rid="bibr36-0093854812437014">Vrij et al. (2010)</xref> found that liars instructed to maintain eye contact during an interview about money taken from a wallet showed more cues (fewer auditory and temporal details in a narrative, slower speech) than liars not so instructed. Because making eye contact is a natural part of conversing, we are not sure that requiring it rises to the level of dual tasking. However, we added it to TRI-Con because it may increase cognitive load more on liars. Though the dual tasking approach is promising, theoretical consideration should be given to what concurrent tasks will interfere more with lying than truth telling and why (see <xref ref-type="bibr" rid="bibr25-0093854812437014">Pashler, 1994</xref>).</p>
<p>To summarize, averting-rehearsal approaches induce cognitive load selectively on liars by blindsiding examinees with questions and by having them answer quickly. Dual tasking induces load by imposing split attention interference such that liars are more adversely affected. Though theoretically distinct, the two approaches are practically compatible and can be integrated by investigators.</p>
</sec>
<sec id="section4-0093854812437014">
<title>Rehearsal: An Attenuator of Cognitive Load</title>
<p>Studies have examined the effects of planning a lie on its detection. In their meta-analysis of the accuracy of judgments of deception, <xref ref-type="bibr" rid="bibr2-0093854812437014">Bond and DePaulo (2006)</xref> noted that lies were easier to detect if baseline behaviors of individuals were available to observers and the lies were unrehearsed. Likewise, <xref ref-type="bibr" rid="bibr15-0093854812437014">Littlepage and Pineault (1985)</xref> found that observers were less accurate at detecting planned deceptions than spontaneous ones. <xref ref-type="bibr" rid="bibr16-0093854812437014">Littlepage, Tang, and Pineault (1986)</xref> investigated why and found that planning allowed liars to control effectively nonverbal cues to deception. <xref ref-type="bibr" rid="bibr23-0093854812437014">O’Hair, Cody, and McLaughlin (1981)</xref> observed that planned lies were briefer, took less time, and involved fewer illustrators. Although such results are interesting, they do not advance understanding of the effects of rehearsal on indices of cognitive load. Research on the cognition of deception has largely ignored the effects of rehearsal on cognitive cues. In two recent meta-analyses of verbal and nonverbal cues, <xref ref-type="bibr" rid="bibr29-0093854812437014">Sporer and Schwandt (2006</xref>, <xref ref-type="bibr" rid="bibr30-0093854812437014">2007</xref>) sought to include rehearsal as a moderator but were unable to locate sufficient studies that manipulated it. Still, to ensure its validity, any cognitive-load-inducing lie detector must consider rehearsal to be a likely countermeasure. <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk, Mahoney, Doverspike, and Griffith-Ross (2009)</xref> found that rehearsal decreased lying response times and inconsistencies compared to unrehearsed lying. More research is needed, however, on the effects of rehearsal on these and other cognitive cues.</p>
</sec>
<sec id="section5-0093854812437014">
<title>Current Study</title>
<p>In their influential meta-analysis of cues to deception, <xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al. (2003)</xref> concluded that there are no unequivocal signs of deception and recommended lie detection via converging cues. <xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al. (2005</xref>, <xref ref-type="bibr" rid="bibr37-0093854812437014">2009</xref>) helped validate TRI-Con but only with response time and answer inconsistency, not using multiple cognitive cues or in a forensically relevant context of “eye witnessed” crimes, limitations that are overcome in this research. Specifically, we showed 145 participants two videos of actual crimes and then instructed them to play the role of witnesses and answer crime-related questions either (a) truthfully or with (b) rehearsed or (c) unrehearsed lies. They also answered 18 general questions truthfully to provide ground-truth behavioral baselines. The four cues evaluated were response time, the inconsistency of answers to interrelated questions, eye movements, and pupil dilation. These cues were selected systematically, each accessing a distinct aspect of cognitive load. Response time and pupil dilation are direct measures of the extent of processing (<xref ref-type="bibr" rid="bibr28-0093854812437014">Solso, 2001</xref>). Answer consistency is the output of processing (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>). Reducing eye movements is hypothesized to reflect attempts to lower cognitive load. This is the first study to assess eye movements as a cognitive cue as individuals answer questions.</p>
<p>Two types of questions were asked: those requiring yes or no responses and open-ended questions evoking short responses besides yes or no. Because yes–no and open-ended questions differ in the syntactic constraints that each puts on permissible responses, <xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al. (2005</xref>) urged analyzing the cues of each separately, which we do. Moreover, <xref ref-type="bibr" rid="bibr40-0093854812437014">Walters (1996)</xref> argued that the accuracy of deception detection increases if truth telling baseline rates are established for each behavioral cue against which suspected deceptive responding can be compared. In effect, this controls for individual differences in baseline rates, which confound strictly between-subjects comparisons. The polygraph, too, involves within-subject comparison by establishing physiological base rates (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>). Similarly, <xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al. (2005</xref>) proposed controlling for such individual differences by subtracting truthful base rates from base rates of questions suspected of deception, a suggestion we follow. Finally, participants adopted the roles of “witnesses” to two different crime videos to see if the pattern of cues observed with one could be replicated with the second. Four hypotheses and their theoretical and empirical rationales follow.</p>
<list id="list1-0093854812437014" list-type="simple">
<list-item><p><italic>H1: Unrehearsed liars will have longer response times than truth tellers, who will have longer response times than rehearsed liars</italic>. Studies show that unrehearsed lying takes longer than truth telling (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>; <xref ref-type="bibr" rid="bibr27-0093854812437014">Seymour, Seifert, Shafto, &amp; Mosmann, 2000</xref>). Moreover, rehearsal can decrease the time required to lie (<xref ref-type="bibr" rid="bibr23-0093854812437014">O’Hair et al., 1981</xref>; <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al., 2009</xref>). The ample rehearsal of this study should lower response times below that of truth tellers.</p></list-item>
<list-item><p><italic>H2: Total inconsistencies across interrelated questions will be greatest for unrehearsed liars, followed by rehearsed liars, and then truth tellers</italic>. Liars are often more inconsistent than truth tellers, likely due to not having generated sufficiently coherent and detailed narratives before lying (<xref ref-type="bibr" rid="bibr26-0093854812437014">Porter &amp; Yuille, 1996</xref>; <xref ref-type="bibr" rid="bibr34-0093854812437014">Vrij et al., 2009</xref>). We expected rehearsal to reduce inconsistency below that of unrehearsed lying (<xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al., 2009</xref>).</p></list-item>
<list-item><p><italic>H3: Truth tellers will move their eyes the most, followed by rehearsed liars; unrehearsed liars will move their eyes the least</italic>. Unrehearsed liars should move their eyes little as they focus on internal processes. Recall also that the instruction to maintain eye contact increased the cognitive load of lying and cues to deception. <xref ref-type="bibr" rid="bibr36-0093854812437014">Vrij et al. (2010)</xref> videotaped participants and later coded tapes for the eye contact made during interviews, whereas we precisely measured eye movements with an infrared eye tracker while participants answered.</p></list-item>
<list-item><p><italic>H4: Unrehearsed liars will have more pupil dilation than rehearsed liars, followed by truth tellers</italic>. Studies demonstrate more pupil dilation in liars than truth tellers, likely due to a greater cognitive load accompanying deception (<xref ref-type="bibr" rid="bibr3-0093854812437014">Bradley &amp; Janisse, 1979</xref>; <xref ref-type="bibr" rid="bibr5-0093854812437014">Dionisio, Granholm, Hillix, &amp; Perrine, 2001</xref>; <xref ref-type="bibr" rid="bibr12-0093854812437014">Heilveil, 1976</xref>; <xref ref-type="bibr" rid="bibr19-0093854812437014">Lubow &amp; Fein, 1996</xref>; <xref ref-type="bibr" rid="bibr41-0093854812437014">Webb, Honts, Kircher, Bernhardt, &amp; Cook, 2009</xref>). Although studies have not considered the effects of rehearsal on the pupil dilation of deceptive answers, it was expected to be lower than that of unrehearsed liars.</p></list-item>
</list>
</sec>
<sec id="section6-0093854812437014" sec-type="methods">
<title>Method</title>
<sec id="section7-0093854812437014">
<title>Participants</title>
<p>Recruited from psychology classes at a southern university, 145 adults received extra credit. The racial composition was 105 White (72.4%), 31 Black (21.4%), 5 Asian (3.5%), and 4 Latino (2.8%). The gender breakdown was 82 females (56.6%) and 63 males (43.4%). The mean age was 22.23 years (<italic>SD</italic> = 5.92). All were American citizens and native English speakers.</p>
</sec>
<sec id="section8-0093854812437014">
<title>Research Design</title>
<p>A multilevel, completely randomized, between-subjects design was used. The independent variable (IV), lie condition, involved the video-related questions and had three levels: truth telling, unrehearsed lying, and rehearsed lying. The dependent variables were these cognitive cues: response time, answer consistency, eye movements, and pupil dilation.</p>
</sec>
<sec id="section9-0093854812437014">
<title>General Procedure</title>
<p>Participants were tested individually, each session lasting about 30 min. Two experimenters were required: a greeter and an examiner. The greeter first obtained informed consent, then handed a hardcopy of general instructions to participants and read them aloud as they followed along. Participants were informed that they would “witness” two surveillance videos of actual crimes and were instructed to watch and listen carefully because they would only be shown each video once and would be questioned after each. Consistent with TRI-Con, they were told to answer “all questions as quickly as possible while constantly maintaining eye contact with me” as well as to answer in a clear, loud voice.</p>
<p>All participants were directed to answer truthfully the 18 general questions asked first. The instructions then diverged depending on the lie condition to which a participant was randomly assigned. (a) <italic>Truth tellers</italic> were instructed to adopt the role of a witness who wants the perpetrators brought to justice and to answer all questions about the videos “truthfully to the best of your recollection.” (b) <italic>Unrehearsed liars</italic> were asked to assume that the perpetrators were friends of theirs whom they did not want to see have criminal records for a lapse of judgment, in effect, covering for them. They were instructed to answer all video-related questions deceptively and to be sure that all answers were logically consistent and plausible. However, they had no prior exposure to the questions, consistent with TRI-Con. (c) <italic>Rehearsed liars</italic> had the exact same instructions as unrehearsed liars but, after viewing each video, were also given a copy of questions and 5 min for preparing lies. Afterward, participants were interviewed with these questions. Pilot testing on 11 college students before the experiment, who were otherwise uninvolved, confirmed that 5 min was adequate time for all to prepare deceptive answers for each video question set. Such rehearsal is ecologically valid in that allowing examinees to “preview” questions is a common practice with the polygraph (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>).</p>
<p>After receiving their instructions, all participants were ushered by the greeter into the eye tracking lab. During all three question sets of the eye tracking interview, the greeter sat directly in front of participants, making direct eye contact throughout and reminding participants to do so as needed, which rarely was necessary. The 18 general questions were asked first as eye data were collected. After that, participants were moved to a computer in the same room and were shown the first of two crime videos. Video order was counterbalanced over participants. Rehearsed liars were given the opportunity to prepare lies afterward. Next, participants were “interviewed” about the video just seen as the cognitive cues were assessed. Then this procedure was repeated for the second video. Even though neither the greeter nor the examiner was blind to the experimental conditions of participants, given that the eye tracking interview task was largely automated, there were minimal opportunities for either to bias the results. Finally, the postexperiment questionnaire was administered, followed by a debriefing.</p>
</sec>
<sec id="section10-0093854812437014">
<title>Materials</title>
<sec id="section11-0093854812437014">
<title>Crime videos</title>
<p>The local police department provided digital copies of two surveillance training videos (with audio) of actual thefts, which were shown on a Dell desktop computer in full-screen mode (13.5 × 11 in.).</p>
</sec>
<sec id="section12-0093854812437014">
<title>Video 1</title>
<p>This video is 106 s in length and features a young, White male working as a janitor. He enters an office to empty the garbage. While alone, he sees cash in an open purse on the floor and steals it. Shortly after, the office’s occupant, an elderly White female who does not detect the pilferage, enters the office and exchanges pleasantries with the perpetrator, who then nonchalantly leaves. The video features a 3-s close-up of the perpetrator’s face.</p>
</sec>
<sec id="section13-0093854812437014">
<title>Video 2</title>
<p>Lasting 75 s, this crime is set in a convenience store. Two individuals are visible throughout: a salesclerk behind the counter, who is distracted while on the Internet rather than “minding the store,” and a customer (perpetrator). Both are young, White males. The perpetrator is clearly visible. Only the head of the salesclerk is visible but shows clearly his race and dark hair. The two talk throughout mostly about their cars. When the salesclerk is distracted, the perpetrator pilfers a box of some nondescript product from the lower shelf of a counter and conceals it under a coat draped on his left shoulder. Next, he calmly leaves the store.</p>
</sec>
<sec id="section14-0093854812437014">
<title>Categories of questions (i. e., question set)</title>
<p>Three categories of questions were written—<italic>general, Video 1</italic>, and <italic>Video 2—</italic>each a mixture of yes–no and open-ended questions. All 37 appear in the appendix. Per TRI-Con guidelines, most were answerable with a word or two. The appendix specifies which question pairs were written to be logically interrelated. The 18 general questions probed personal information and general knowledge to provide ground truth behavioral baseline data (<xref ref-type="bibr" rid="bibr40-0093854812437014">Walters, 1996</xref>). The boldfaced questions tested facts that could be verified to ensure compliance with instructions to answer truthfully. The 19 interview questions (10 Video 1, 9 Video 2) addressed what happened in the videos, including characteristics of the perpetrators and the nature of the theft. They are of the kind often asked by detectives (<xref ref-type="bibr" rid="bibr13-0093854812437014">Inbau, Reid, Buckley, &amp; Jayne, 2001</xref>).</p>
</sec>
<sec id="section15-0093854812437014">
<title>Postexperiment questionnaire</title>
<p>A postexperimenter questionnaire was prepared that listed the 10 Video 1 questions and 9 Video 2 questions to assess whether the truth had been encoded by participants. The instructions directed participants to answer them all truthfully.</p>
</sec>
</sec>
<sec id="section16-0093854812437014">
<title>Audacity Digital Recording Software</title>
<p>Audacity version 1.3.8 (<ext-link ext-link-type="uri" xlink:href="http://audacity.sourceforge.net">http://audacity.sourceforge.net</ext-link>), an open source digital recording and editing software, was used to record the instructions that preceded each set of questions (prompting the focus of the questions to follow) and each question as its own digital file. A young woman read the instructions and questions in a clear, authoritative voice. A JAVA program presented the instructions for a set of questions, followed by the appropriate questions in their order of appearance in the appendix.</p>
</sec>
<sec id="section17-0093854812437014">
<title>The Eye Tracking System and Interview Task</title>
<p>The Eye Tracking Laboratory (ETL) 400 Infrared eye tracking system (manufactured by ISCAN Inc., 21 Cabot Road, Woburn, MA 01801; website: <ext-link ext-link-type="uri" xlink:href="http://iscaninc.com">http://iscaninc.com</ext-link>) assessed pupil dilation and eye movements. A computer ran the JAVA program that controlled the procedure. The time needed to answer was measured to the millisecond by a voice key. Any noise following a question, usually the answer, caused the voice key to trip and an audible beep. Answers were also digitally recorded. When an irrelevant noise caused the voice key to trip prematurely, response times were determined using the recordings.</p>
<p>Participants’ chins were positioned on a chinrest. The greeter sat 4 feet in front of them. Before testing, the ETL 400 was calibrated using four numbered corners on a rectangle 29 in. wide and 23 in. tall on the wall behind the greeter. The eye tracker imposed a virtual coordinate system of pixels corresponding to where participants were looking. The origin was in the upper, left-hand corner (horizontal = 0, vertical = 0). The bottom right had maximum coordinates (horizontal = 511, vertical = 511). The greeter sat such that her eyes were about in the middle of the rectangle. Throughout the ETL 400 took 60 “snapshots” of the right eye per second. In each, the pupil dilation and point of regard (i.e., virtual coordinates where the fovea was centered at any instant) were measured. Pupil dilation and eye movements of <xref ref-type="table" rid="table3-0093854812437014">Tables 3</xref> through <xref ref-type="table" rid="table6-0093854812437014">6</xref> are expressed in pixels. For each test question, the eye data analyzed started with the beginning of a question and ended when the voice key tripped, that is, for the full <italic>question–answer event</italic>. The mean pupil dilation for this interval was used. Also, the ETL 400 is designed to analyze eye movements into vertical and horizontal components, which is why vertical and horizontal eye data were analyzed separately. ISCAN recommended using the standard deviation of the vertical points of regard and the standard deviation of the horizontal points of regard for each question–answer event to assess eye movement, which we did. Smaller mean standard deviations in <xref ref-type="table" rid="table3-0093854812437014">Tables 3</xref>, <xref ref-type="table" rid="table4-0093854812437014">4</xref>, and <xref ref-type="table" rid="table6-0093854812437014">6</xref> indicate more stationary eyes. Readers interested in obtaining more details about this or any other aspect of the procedure can contact the lead author.</p>
</sec>
<sec id="section18-0093854812437014">
<title>Transcribing Audio Recordings and Coding for Inconsistencies</title>
<p>A graduate assistant (GA) transcribed audio recordings for all utterances following each question. Rarely were answers inaudible. Transcriptions were later coded for the number of inconsistencies within a question set. An inconsistency occurred when the second answer of an interrelated pair was implausible if the answer to the first question was assumed true. For example, in Video 1, inconsistencies occurred when Question 22 (see the appendix) was answered “yes” but the answer to Questions 23 began with “He . . .” For Video 2, a common inconsistency was answering Question 29 with “a violent crime” and later answering Question 33 with “he hid the stolen item with his jacket.”</p>
<p>To assess interrater reliability, copies of 47 transcriptions, randomly selected from the 145, were independently coded for inconsistencies by the GA and by another GA otherwise unaffiliated with this project. Pearson correlations between inconsistency totals of the two raters for the general, Video 1, and Video 2 questions were .92, .67, and .78, respectively, all significant and large enough to justify having the first GA code the remaining transcripts (<xref ref-type="bibr" rid="bibr1-0093854812437014">Anastasi &amp; Urbina, 1997</xref>). Her inconsistency totals are used in the analyses.</p>
</sec>
<sec id="section19-0093854812437014">
<title>Summarizing Data for Each Category of Question</title>
<p>For each question–answer event, there was a mean for response time and pupil dilation, as well as a vertical eye movement standard deviation and a horizontal eye movement standard deviation. These data were summarized for hypothesis testing as follows. Within each question category, the mean pupil dilation for yes–no questions was determined, as well as for open-ended questions. Also, within each question category, the mean horizontal and vertical eye movement standard deviations were determined by question type. Since response times often were positively skewed, the median response time within each question category and question type was used to control for outliers (<xref ref-type="bibr" rid="bibr28-0093854812437014">Solso, 2001</xref>).</p>
</sec>
<sec id="section20-0093854812437014">
<title>Checking Transcriptions for Compliance</title>
<p>The transcribed answers were checked for participant compliance with instructions to answer general questions truthfully, which was possible with the boldfaced factual general questions of the appendix. No one answered more than two of them incorrectly, and few inconsistencies occurred. Compliance was good. Regarding the postexperimenter questionnaire data, the mean number of questions correctly answered for Video 1 for all 145 was 9.81 (<italic>SD</italic> =.44, 98% correct). For Video 2, mean accuracy was 7.48 (<italic>SD</italic> =.65, 83% correct), results showing that participants generally had encoded truths. Finally, comparing the post-experiment surveys with the transcriptions, it was clear that participants assigned to truth telling generally answered Video 1 and 2 questions truthfully or with an “I don’t know.” Liars, rehearsed and unrehearsed, overall answered &lt;10% of the Video 1 and 2 questions truthfully. The eye and response time data of questions answered truthfully or inaudibly were treated as missing.</p>
</sec>
<sec id="section21-0093854812437014">
<title>Data Analysis</title>
<p>H1, H3, and H4 were tested with a 2 × 3 mixed ANOVA for Video 1 and Video 2. The within-subjects factor was question type (yes–no, open-ended). The between-subjects factor was lie condition (truth telling, unrehearsed lying, rehearsed lying). To avoid overwhelming readers with statistics, main effects for question type and Question Type × Lie Condition interactions are only reported when significant. Moreover, the <italic>F</italic> statistics of simple main effects used to understand interactions are not reported. H2 was tested with a one-way ANOVA. For a significant main effect or simple main effect for lie condition, the Studentized-Newman-Keuls (S-N-K) procedure determined which means were significantly different. ANOVAs on the cues for general questions were conducted to ensure equality of the conditions that random assignment produces. Only if significant lie condition effects occurred are these results reported.</p>
</sec>
</sec>
<sec id="section22-0093854812437014" sec-type="results">
<title>Results</title>
<p>Four hypotheses were tested, one for each cognitive cue evaluated. H1, regarding longer response times with lying, was well supported, as was H2, predicting more inconsistencies with deception. H3 asserts greater eye movement with truth telling and was partially confirmed. H4, predicting greater pupil dilation with deception, was not supported.</p>
<sec id="section23-0093854812437014">
<title>H1: Response Time</title>
<p>Descriptive statistics for response times are provided in <xref ref-type="table" rid="table1-0093854812437014">Table 1</xref>. In all tables, condition <italic>N</italic>s are boldfaced. There were no missing data with this cue. In the case of Video 1, question type made a difference, <italic>F</italic>(1, 142) = 260.89, <italic>p</italic> = .001, ή = .648, (yes–no <italic>M</italic> = 574, open-ended <italic>M</italic> = 1,007), with open-ended questions taking longer. Lie condition was significant, <italic>F</italic>(2, 142) = 32.42, <italic>p</italic> = .001, ή = .313. The Question Type × Lie Condition interaction was also significant, <italic>F</italic>(2, 142) = 14.34, <italic>p</italic> = .001, ή = .168. In the case of yes–no questions, truth tellers and rehearsed liars were significantly faster than unrehearsed liars. For open-ended questions, rehearsed liars answered the fastest, followed by truth tellers. Unrehearsed liars answered the slowest. For Video 2, open-ended questions took longer than yes–no questions, <italic>F</italic>(1, 142) = 97.24, <italic>p</italic> = .001, ή = .406 (yes–no <italic>M</italic> = 629, open-ended <italic>M</italic> = 878). Lie condition made a difference, <italic>F</italic>(2, 142) = 22.74, <italic>p</italic> = .001, ή = .243. The interaction was significant, <italic>F</italic>(2, 142) = 23.11, <italic>p</italic> = .001, ή = .246. For yes–no questions, rehearsed liars and truth tellers were significantly faster than unrehearsed liars. In the case of open-ended questions, all three conditions were significantly different, with rehearsed liars the fastest and unrehearsed liars the slowest. A constant pattern of results occurred across videos that supports H1, especially with open-ended questions.</p>
<table-wrap id="table1-0093854812437014" position="float">
<label>Table 1:</label>
<caption><p>Statistics for Response Times (in milliseconds) by Lie Condition, Question Type, and Question Category</p></caption>
<graphic alternate-form-of="table1-0093854812437014" xlink:href="10.1177_0093854812437014-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">Lie Condition</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="2">Truth Telling</th>
<th align="center" colspan="2">Unrehearsed Lying</th>
<th align="center" colspan="2">Rehearsed Lying</th>
<th/>
</tr>
<tr>
<th align="left">Questions</th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Means Significantly Different</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="8">Yes–no questions</td>
</tr>
<tr>
<td> General</td>
<td>545</td>
<td>171</td>
<td>575</td>
<td>157</td>
<td>544</td>
<td>174</td>
<td>None</td>
</tr>
<tr>
<td> Video 1</td>
<td>498</td>
<td>214</td>
<td>758</td>
<td>366</td>
<td>475</td>
<td>237</td>
<td>1-2,2-3</td>
</tr>
<tr>
<td> Video 2</td>
<td>583</td>
<td>202</td>
<td>751</td>
<td>279</td>
<td>558</td>
<td>262</td>
<td>1-2,2-3</td>
</tr>
<tr>
<td> Adj. Video 1</td>
<td>–47</td>
<td>165</td>
<td>183</td>
<td>323</td>
<td>–69</td>
<td>229</td>
<td>1-2,2-3</td>
</tr>
<tr>
<td> Adj. Video 2</td>
<td>37</td>
<td>197</td>
<td>176</td>
<td>242</td>
<td>14</td>
<td>232</td>
<td>1-2,2-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>48</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>50</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Mean no.</td>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
<tr>
<td colspan="8">Open-ended questions</td>
</tr>
<tr>
<td> General</td>
<td>676</td>
<td>211</td>
<td>748</td>
<td>270</td>
<td>683</td>
<td>218</td>
<td>None</td>
</tr>
<tr>
<td> Video 1</td>
<td>1,028</td>
<td>340</td>
<td>1,304</td>
<td>372</td>
<td>708</td>
<td>332</td>
<td>1-2,1-3,2-3</td>
</tr>
<tr>
<td> Video 2</td>
<td>936</td>
<td>314</td>
<td>1,148</td>
<td>515</td>
<td>567</td>
<td>270</td>
<td>1-2,1-3,2-3</td>
</tr>
<tr>
<td> Adj. Video 1</td>
<td>352</td>
<td>304</td>
<td>556</td>
<td>430</td>
<td>25</td>
<td>276</td>
<td>1-2,1-3,2-3</td>
</tr>
<tr>
<td> Adj. Video 2</td>
<td>260</td>
<td>285</td>
<td>399</td>
<td>600</td>
<td>–115</td>
<td>231</td>
<td>1-3,2-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>48</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>50</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Mean no.</td>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<p>Consistent with <xref ref-type="bibr" rid="bibr40-0093854812437014">Walters (1996)</xref> and Walczyk and colleagues (<xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al. 2005</xref>; <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al., 2009</xref>), truthful base rate means were used to adjust means of cues of questions suspected of deception. Specifically, <italic>adjusted Video 1 response times</italic> were computed by subtracting the yes–no and open-ended means of general questions from the corresponding means of the Video 1 questions. These adjustments also occurred for Video 2 response times. For adjusted means, see <xref ref-type="table" rid="table1-0093854812437014">Table 1</xref>. For adjusted Video 1 means, a main effect was found for question type, <italic>F</italic>(1, 142) = 79.60, <italic>p</italic> = .001, ή = .359 (yes–no <italic>M</italic> = 20, open-ended <italic>M</italic> = 306), and for lie condition, <italic>F</italic>(2, 142) = 36.49, <italic>p</italic> = .001, ή = .339. Because of a significant interaction, <italic>F</italic>(2, 142) = 9.18, <italic>p</italic> = .001, ή = .115, simple main effects were examined. For yes–no questions, unrehearsed liars took significantly longer than the other two conditions. For open-ended questions, all three condition means differed significantly, with unrehearsed liars taking the most time, rehearsed liars the least. These results parallel those of the unadjusted scores. Adjusted Video 2 means showed a main effect for question type, <italic>F</italic>(1, 142) = 12.02, <italic>p</italic> = .001, ή = .078 (yes–no <italic>M</italic> = 74, open-ended <italic>M</italic> = 176); another for lie condition, <italic>F</italic>(2, 142) = 19.36, <italic>p</italic> = .001, ή =. 214; and an interaction, <italic>F</italic>(2, 142) = 15.11, <italic>p</italic> = .001, ή = .176. For yes–no questions, unrehearsed liars took longer than truth tellers and rehearsed liars. Rehearsed liars were faster than truth tellers and unrehearsed liars with open-ended questions.</p>
<p>The pattern is that open-ended questions took longer to answer. Moreover, unrehearsed lying took the longest for Videos 1 and 2. For open-ended questions, rehearsal often reduced response times below those of truth tellers. Finally, adjusting for individual differences by subtracting yes–no or open-ended means produced a pattern of differences similar to those of the unadjusted means while controlling for individual differences in base rates. H1 was supported.</p>
</sec>
<sec id="section24-0093854812437014">
<title>H2: Inconsistencies</title>
<p><xref ref-type="table" rid="table2-0093854812437014">Table 2</xref> reports statistics for total inconsistencies by question set. <italic>N</italic>s are occasionally reduced due to at least one answer of an interrelated pair being inaudible such that total inconsistency within a set could not be determined. Although infrequent, inconsistencies occurred enough to discriminate among conditions for the videos. A significant main effect for lie condition occurred for Video 1, <italic>F</italic>(2, 140) = 8.33, <italic>p</italic> = .001. Truth tellers had fewer inconsistencies than the other two conditions. A significant lie condition main effect was also observed for Video 2, <italic>F</italic>(2, 138) = 10.67, <italic>p</italic> = .001. Once again, truth tellers had fewer inconsistencies than the other conditions. H2 was partially supported.</p>
<table-wrap id="table2-0093854812437014" position="float">
<label>Table 2:</label>
<caption><p>Total Inconsistency</p></caption>
<graphic alternate-form-of="table2-0093854812437014" xlink:href="10.1177_0093854812437014-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">Lie Condition</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="2">Truth Telling</th>
<th align="center" colspan="2">Unrehearsed Lying</th>
<th align="center" colspan="2">Rehearsed Lying</th>
<th/>
</tr>
<tr>
<th align="left">Questions</th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Means Significantly Different</th>
</tr>
</thead>
<tbody>
<tr>
<td>General</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.04</td>
<td>0.20</td>
<td>None</td>
</tr>
<tr>
<td>Video 1</td>
<td>0.04</td>
<td>0.20</td>
<td>0.61</td>
<td>0.93</td>
<td>0.48</td>
<td>0.75</td>
<td>1-2,1-3</td>
</tr>
<tr>
<td><italic>N</italic></td>
<td><bold>47</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>50</bold></td>
<td/>
<td/>
</tr>
<tr>
<td>Video 2</td>
<td>0.14</td>
<td>0.49</td>
<td>0.80</td>
<td>0.78</td>
<td>0.69</td>
<td>0.91</td>
<td>1-2,1-3</td>
</tr>
<tr>
<td><italic>N</italic></td>
<td><bold>47</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td><bold>49</bold></td>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section25-0093854812437014">
<title>H3: Eye Movement</title>
<sec id="section26-0093854812437014">
<title>Vertical eye movements</title>
<p>See <xref ref-type="table" rid="table3-0093854812437014">Table 3</xref> for statistics on vertical eye movements. Reduced condition <italic>N</italic>s were usually due to loss of calibration of point of regard caused by head movements, which did not affect the assessment of pupil dilation. For Video 1, a main effect occurred for type of question, <italic>F</italic>(1, 133) = 10.17, <italic>p</italic> = .002, ή = .071 (yes–no <italic>M</italic> = 50, open-ended <italic>M</italic> = 57). Open-ended questions entailed slightly more eye movements. There was also a lie condition main effect, <italic>F</italic>(2, 133) = 3.65, <italic>p</italic> = .028, ή = .071. A significant Question Type × Lie Condition interaction occurred as well, <italic>F</italic>(2, 133) = 5.99, <italic>p</italic> = .003, ή = .083. For yes–no questions, truth tellers had significantly more eye movements than rehearsed or unrehearsed liars. Regarding Video 2, question type generated a main effect, <italic>F</italic>(1, 128) = 4.61, <italic>p</italic> = .034, ή = .035, by which yes–no questions elicited less eye movement (yes–no <italic>M</italic> = 50, open-ended <italic>M</italic> = 57). A main effect for lie condition happened, <italic>F</italic>(2, 128) = 3.52, <italic>p</italic> = .032, ή = .052. Truth tellers had significantly more eye movements than rehearsed liars. These analyses partially support H3. Truth tellers generally had more eye movements, especially for yes–no questions.</p>
<table-wrap id="table3-0093854812437014" position="float">
<label>Table 3:</label>
<caption><p>Vertical Eye Movements (in pixels)</p></caption>
<graphic alternate-form-of="table3-0093854812437014" xlink:href="10.1177_0093854812437014-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">Lie Condition</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="2">Truth Telling</th>
<th align="center" colspan="2">Unrehearsed Lying</th>
<th align="center" colspan="2">Rehearsed Lying</th>
<th/>
</tr>
<tr>
<th align="left">Questions</th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Means Significantly Different</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="8">Yes–no questions</td>
</tr>
<tr>
<td> General</td>
<td>53</td>
<td>40</td>
<td>44</td>
<td>36</td>
<td>54</td>
<td>45</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>45</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 1</td>
<td>67</td>
<td>45</td>
<td>44</td>
<td>40</td>
<td>40</td>
<td>36</td>
<td>1-2,1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 2</td>
<td>60</td>
<td>46</td>
<td>46</td>
<td>43</td>
<td>37</td>
<td>34</td>
<td>1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>42</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 1</td>
<td>14</td>
<td>39</td>
<td>0</td>
<td>31</td>
<td>–14</td>
<td>38</td>
<td>1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 2</td>
<td>5</td>
<td>36</td>
<td>2</td>
<td>28</td>
<td>–18</td>
<td>41</td>
<td>1-3, 2-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>42</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td/>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
<tr>
<td colspan="8">Open-ended questions</td>
</tr>
<tr>
<td> General</td>
<td>58</td>
<td>36</td>
<td>50</td>
<td>36</td>
<td>49</td>
<td>35</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>45</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 1</td>
<td>64</td>
<td>38</td>
<td>58</td>
<td>43</td>
<td>49</td>
<td>36</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 2</td>
<td>62</td>
<td>40</td>
<td>51</td>
<td>37</td>
<td>42</td>
<td>34</td>
<td>1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>42</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 1</td>
<td>5</td>
<td>36</td>
<td>8</td>
<td>27</td>
<td>0</td>
<td>30</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 2</td>
<td>4</td>
<td>31</td>
<td>1</td>
<td>28</td>
<td>–6</td>
<td>34</td>
<td>1-3, 2-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>42</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td/>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
<p>Adjusted Video 1 eye movements were calculated by subtracting the general yes–no vertical eye movement means from the yes–no Video 1 vertical eye movement means. The same was done for the open-ended means as well as for Video 2. Corresponding adjustments were also done for the horizontal eye movement data of both videos. Adjusted vertical means are reported in <xref ref-type="table" rid="table3-0093854812437014">Table 3</xref>. Adjusted horizontal means appear in <xref ref-type="table" rid="table4-0093854812437014">Table 4</xref>. For adjusted vertical eye movements of Video 1, a significant interaction occurred, <italic>F</italic>(2, 131) = 6.39, <italic>p</italic> = .002, ή = .089. Also, lie condition mattered, <italic>F</italic>(2, 131) = 3.24, <italic>p</italic> = .042, ή = .047. In the case of yes–no questions, truth tellers had significantly more movement than rehearsed liars. Regarding Video 2, lie condition had an impact, <italic>F</italic>(2, 126) = 3.88, <italic>p</italic> = .023, ή = .058. Rehearsed liars had less eye movements the other two conditions.</p>
<table-wrap id="table4-0093854812437014" position="float">
<label>Table 4:</label>
<caption><p>Horizontal Eye Movements</p></caption>
<graphic alternate-form-of="table4-0093854812437014" xlink:href="10.1177_0093854812437014-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">Lie Condition</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="2">Truth Telling</th>
<th align="center" colspan="2">Unrehearsed Lying</th>
<th align="center" colspan="2">Rehearsed Lying</th>
<th/>
</tr>
<tr>
<th align="left">Questions</th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Means Significantly Different</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="8">Yes–no questions</td>
</tr>
<tr>
<td> General</td>
<td>55</td>
<td>41</td>
<td>47</td>
<td>37</td>
<td>53</td>
<td>42</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>45</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 1</td>
<td>70</td>
<td>40</td>
<td>45</td>
<td>39</td>
<td>43</td>
<td>43</td>
<td>1-2, 1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 2</td>
<td>63</td>
<td>41</td>
<td>49</td>
<td>46</td>
<td>38</td>
<td>36</td>
<td>1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>43</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 1</td>
<td>14</td>
<td>38</td>
<td>–2</td>
<td>37</td>
<td>–9</td>
<td>34</td>
<td>1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 2</td>
<td>6</td>
<td>32</td>
<td>1</td>
<td>34</td>
<td>–16</td>
<td>33</td>
<td>1-3, 2-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>43</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td/>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
<tr>
<td colspan="8">Open-ended questions</td>
</tr>
<tr>
<td> General</td>
<td>60</td>
<td>40</td>
<td>52</td>
<td>34</td>
<td>50</td>
<td>36</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>45</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 1</td>
<td>67</td>
<td>42</td>
<td>60</td>
<td>43</td>
<td>48</td>
<td>36</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Video 2</td>
<td>66</td>
<td>37</td>
<td>54</td>
<td>42</td>
<td>44</td>
<td>39</td>
<td>1-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>43</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 1</td>
<td>5</td>
<td>37</td>
<td>8</td>
<td>27</td>
<td>–1</td>
<td>32</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>43</bold></td>
<td/>
<td><bold>46</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td> Adj. Video 2</td>
<td>5</td>
<td>28</td>
<td>3</td>
<td>29</td>
<td>–5</td>
<td>33</td>
<td>1-3, 2-3</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>42</bold></td>
<td/>
<td><bold>43</bold></td>
<td/>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td/>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section27-0093854812437014">
<title>Horizontal eye movements</title>
<p><xref ref-type="table" rid="table4-0093854812437014">Table 4</xref> summarizes horizontal eye movements. As in <xref ref-type="table" rid="table3-0093854812437014">Table 3</xref>, the largest means are observed with truth tellers. For Video 1, an effect for type of question occurred, <italic>F</italic>(1, 133) = 6.06, <italic>p</italic> = .015, ή = .044. Open-ended questions elicited more eye movements (yes–no <italic>M</italic> = 52, open-ended <italic>M</italic> = 58). Lie condition had an impact, <italic>F</italic>(2, 133) = 4.14, <italic>p</italic> = .018, ή = .059, with an interaction, <italic>F</italic>(2, 133) = 5.59, <italic>p</italic> = .005, ή = .078. Truth tellers had more eye movements than either rehearsed or unrehearsed liars with yes–no questions only. For Video 2, there was a main effect for question type, <italic>F</italic>(1, 129) = 6.93, <italic>p</italic> = .009, ή = .051. Open-ended questions elicited more eye movement (yes–no <italic>M</italic> = 50, open-ended <italic>M</italic> = 54). Lie condition was significant, <italic>F</italic>(1, 129) = 4.24, <italic>p</italic> = .016, ή = .062. Truth tellers moved their eye more than rehearsed liars.</p>
<p>For the adjusted Video 1 horizontal eye movements, a significant interaction occurred, <italic>F</italic>(2, 131) = 5.04, <italic>p</italic> = .008, ή = .071, but no effect of lie condition, <italic>F</italic>(2, 131) = 2.32, <italic>p</italic> = .102. Truth tellers had significantly more eye movements than rehearsed liars with yes–no questions. Regarding adjusted Video 2 horizontal means, lie condition was significant, <italic>F</italic>(3, 95) = 3.95, <italic>p</italic> = .022, ή = .059. Rehearsed liars had less eye movement than unrehearsed liars and truth tellers.</p>
<p>Importantly, the same pattern of significant differences was found for vertical (<xref ref-type="table" rid="table3-0093854812437014">Table 3</xref>) and horizontal (<xref ref-type="table" rid="table4-0093854812437014">Table 4</xref>) eye movements. For the videos, open-ended questions elicited the most eye movements. Mixed support was obtained for H3. Whether or not means were adjusted, truth tellers tended to have the most eye movements, and yes–no question tended to produce the best discrimination across conditions.</p>
</sec>
</sec>
<sec id="section28-0093854812437014">
<title>H4: Pupil Dilation During Deception</title>
<p><xref ref-type="table" rid="table5-0093854812437014">Table 5</xref> summarizes pupil dilation. For Video 1, there was a main effect for question type, <italic>F</italic>(1, 142) = 32.72, <italic>p</italic> = .001, ή = .187. Open-ended questions involved more pupil dilation (yes–no <italic>M</italic> = 67, open-ended <italic>M</italic> = 69). Lie condition had no effect, <italic>F</italic>(2, 142) =.16, <italic>p</italic> = .850. For Video 2, open-ended questions entailed more pupil dilation, <italic>F</italic>(1, 142) = 12.55, <italic>p</italic> = .001, ή = .081 (yes–no <italic>M</italic> = 65, open-ended <italic>M</italic> = 67). Lie condition had no impact, <italic>F</italic>(2, 142) =.67, <italic>p</italic> = .513. A significant interaction occurred, <italic>F</italic>(2, 142) = 3.62, <italic>p</italic> = .029, ή = .049. The simple main effects across question type were not significant. However, pair-sample <italic>t</italic> tests across lie conditions clarified the interaction. For truth tellers, open-ended questions involved more pupil dilation, which also occurred for unrehearsed liars, but not for rehearsed liars. Rehearsing answers apparently equated the cognitive load of answering across question types. H4 was not supported.</p>
<table-wrap id="table5-0093854812437014" position="float">
<label>Table 5:</label>
<caption><p>Pupil Dilation (in pixels)</p></caption>
<graphic alternate-form-of="table5-0093854812437014" xlink:href="10.1177_0093854812437014-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">Lie Condition</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="2">Truth Telling</th>
<th align="center" colspan="2">Unrehearsed Lying</th>
<th align="center" colspan="2">Rehearsed Lying</th>
<th/>
</tr>
<tr>
<th align="left">Questions</th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Means Significantly Different</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="8">Yes–no questions</td>
</tr>
<tr>
<td> General</td>
<td>67</td>
<td>19</td>
<td>67</td>
<td>14</td>
<td>70</td>
<td>20</td>
<td>None</td>
</tr>
<tr>
<td> Video 1</td>
<td>66</td>
<td>18</td>
<td>67</td>
<td>12</td>
<td>67</td>
<td>16</td>
<td>None</td>
</tr>
<tr>
<td> Video 2</td>
<td>64</td>
<td>18</td>
<td>68</td>
<td>16</td>
<td>66</td>
<td>16</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>48</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>50</bold></td>
<td/>
<td/>
</tr>
<tr>
<td/>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
<tr>
<td colspan="8">Open-ended questions</td>
</tr>
<tr>
<td> General</td>
<td>65</td>
<td>16</td>
<td>66</td>
<td>14</td>
<td>69</td>
<td>20</td>
<td>None</td>
</tr>
<tr>
<td> Video 1</td>
<td>67</td>
<td>18</td>
<td>70</td>
<td>14</td>
<td>70</td>
<td>17</td>
<td>None</td>
</tr>
<tr>
<td> Video 2</td>
<td>66</td>
<td>18</td>
<td>69</td>
<td>17</td>
<td>66</td>
<td>16</td>
<td>None</td>
</tr>
<tr>
<td> <italic>N</italic></td>
<td><bold>48</bold></td>
<td/>
<td><bold>47</bold></td>
<td/>
<td><bold>50</bold></td>
<td/>
<td/>
</tr>
<tr>
<td/>
<td>1</td>
<td/>
<td>2</td>
<td/>
<td>3</td>
<td/>
<td/>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section29-0093854812437014">
<title>Discriminant Analyses</title>
<p>Two exploratory discriminant analyses, one for each video, assessed the collective potential of the cognitive cues except pupil dilation. They served as the IVs. Only adjusted IV means were used (<xref ref-type="bibr" rid="bibr40-0093854812437014">Walters, 1996</xref>) and inconsistency totals. Lie condition was the dependent (grouping) variable for both, with three levels: truth tellers, unrehearsed liars, and rehearsed liars. Condition means are reported in <xref ref-type="table" rid="table6-0093854812437014">Table 6</xref>, along with the results of one way ANOVAs comparing them. <italic>N</italic>s were reduced by only including observations that have complete data for all the IVs. Rows of IVs with significant models are italicized. All but the open-ended eye movement means were significant.</p>
<table-wrap id="table6-0093854812437014" position="float">
<label>Table 6:</label>
<caption><p>Lie Condition Means and ANOVA Results for Independent Variables of the Discriminant Analyses</p></caption>
<graphic alternate-form-of="table6-0093854812437014" xlink:href="10.1177_0093854812437014-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="3">Lie Condition</th>
<th/>
<th/>
</tr>
<tr>
<th/>
<th align="center">Truth Telling</th>
<th align="center">Unrehearsed Lying</th>
<th align="center">Rehearsed Lying</th>
<th/>
<th/>
</tr>
<tr>
<th/>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>F</italic></th>
<th align="center"><italic>p</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">Adjusted yes–no response times</td>
</tr>
<tr>
<td> Video 1</td>
<td><italic>–43.90</italic></td>
<td><italic>192.71</italic></td>
<td><italic>–78.54</italic></td>
<td><italic>15.15</italic></td>
<td>.<italic>001</italic></td>
</tr>
<tr>
<td> Video 2</td>
<td><italic>37.10</italic></td>
<td><italic>204.80</italic></td>
<td><italic>16.40</italic></td>
<td><italic>8.47</italic></td>
<td>.<italic>001</italic></td>
</tr>
<tr>
<td colspan="6">Adjusted open-ended response times</td>
</tr>
<tr>
<td> Video 1</td>
<td><italic>356.66</italic></td>
<td><italic>569.57</italic></td>
<td><italic>31.05</italic></td>
<td><italic>26.73</italic></td>
<td>.<italic>001</italic></td>
</tr>
<tr>
<td> Video 2</td>
<td><italic>247.24</italic></td>
<td><italic>446.59</italic></td>
<td><italic>–110.95</italic></td>
<td><italic>23.09</italic></td>
<td>.<italic>001</italic></td>
</tr>
<tr>
<td> Total Video 1 inconsistency</td>
<td><italic>0.05</italic></td>
<td><italic>0.62</italic></td>
<td><italic>0.51</italic></td>
<td><italic>7.62</italic></td>
<td>.<italic>001</italic></td>
</tr>
<tr>
<td> Total Video 2 inconsistency</td>
<td><italic>0.12</italic></td>
<td><italic>0.82</italic></td>
<td><italic>0.68</italic></td>
<td><italic>9.34</italic></td>
<td>.<italic>001</italic></td>
</tr>
<tr>
<td colspan="6">Adjusted vertical eye movements</td>
</tr>
<tr>
<td colspan="6">Yes–no</td>
</tr>
<tr>
<td> Video 1</td>
<td><italic>13.17</italic></td>
<td><italic>0.57</italic></td>
<td><italic>–13.94</italic></td>
<td><italic>6.13</italic></td>
<td>.<italic>003</italic></td>
</tr>
<tr>
<td> Video 2</td>
<td><italic>5.45</italic></td>
<td><italic>0.95</italic></td>
<td><italic>–17.79</italic></td>
<td><italic>5.04</italic></td>
<td>.<italic>008</italic></td>
</tr>
<tr>
<td colspan="6">Open-ended</td>
</tr>
<tr>
<td> Video 1</td>
<td>5.46</td>
<td>8.79</td>
<td>–0.02</td>
<td>0.92</td>
<td>.401</td>
</tr>
<tr>
<td> Video 2</td>
<td>4.43</td>
<td>2.62</td>
<td>–6.49</td>
<td>1.52</td>
<td>.221</td>
</tr>
<tr>
<td colspan="6">Adjusted horizontal eye movements</td>
</tr>
<tr>
<td colspan="6">Yes–no</td>
</tr>
<tr>
<td> Video 1</td>
<td><italic>12.93</italic></td>
<td><italic>–0.96</italic></td>
<td><italic>–9.00</italic></td>
<td><italic>4.03</italic></td>
<td>.<italic>020</italic></td>
</tr>
<tr>
<td> Video 2</td>
<td><italic>5.79</italic></td>
<td><italic>2.49</italic></td>
<td><italic>–15.51</italic></td>
<td><italic>5.06</italic></td>
<td>.<italic>008</italic></td>
</tr>
<tr>
<td colspan="6">Open-ended</td>
</tr>
<tr>
<td> Video 1</td>
<td>4.02</td>
<td>8.49</td>
<td>–1.27</td>
<td>1.05</td>
<td>.352</td>
</tr>
<tr>
<td> Video 2</td>
<td>4.40</td>
<td>4.51</td>
<td>–5.28</td>
<td>1.45</td>
<td>.237</td>
</tr>
<tr>
<td><italic>N</italic> for Video 1</td>
<td><bold>42</bold></td>
<td><bold>45</bold></td>
<td><bold>45</bold></td>
<td/>
<td/>
</tr>
<tr>
<td><italic>N</italic> for Video 2</td>
<td><bold>41</bold></td>
<td><bold>40</bold></td>
<td><bold>44</bold></td>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0093854812437014">
<p><italic>Note</italic>. ANOVAs in italicized rows have <italic>p</italic> values &lt; .05 and were used in discriminant analyses.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The discriminant model of Video 1 was significant, Wilks’s Lambda =.77, <italic>p</italic> = .001; 67% of the sample was accurately classified, 33% accuracy expected by chance. The false positive rate (truth tellers misclassified as liars) was 9%. The false negative rate (liars misclassified as truth tellers) was 17%. Video 2’s discriminant model was also significant, Wilks’s Lambda =.81, <italic>p</italic> = .001; 69% of the sample was classified accurately. The rate of false positive was very close to that of Video 1 at 8%, as was the false negative rate at 14%. Overall, these results show across videos that the adjusted cognitive cues of this research, along with inconsistencies, perform well beyond chance and with low false positive rates.</p>
</sec>
</sec>
<sec id="section30-0093854812437014" sec-type="discussion">
<title>Discussion</title>
<p>Though highly valued by juries (<xref ref-type="bibr" rid="bibr2-0093854812437014">Bond &amp; DePaulo, 2006</xref>), the testimony of eyewitnesses has several threats to its validity, especially misidentification (<xref ref-type="bibr" rid="bibr18-0093854812437014">Loftus, 2007</xref>; <xref ref-type="bibr" rid="bibr42-0093854812437014">Wells &amp; Olson, 2003</xref>). Perjury is the most pernicious threat and an impediment to evenhanded justice. Given recent concerns with the polygraph’s validity (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>; <xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>; <xref ref-type="bibr" rid="bibr22-0093854812437014">NRC, 2003</xref>), an effective alternative lie detector would benefit the criminal justice system by uncovering deception during interviews, thereby reducing perjury. We sought to help refine TRI-Con, a method of lie detection designed to induce cognitive load selectively on liars (<xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al., 2005</xref>). Participants adopted the roles of eyewitnesses of videos of actual thefts and then told the truth or lied, rehearsed or unrehearsed, when questioned. Moreover, although others have considered the effects of rehearsal on deception detection (e.g., <xref ref-type="bibr" rid="bibr16-0093854812437014">Littlepage et al., 1986</xref>; <xref ref-type="bibr" rid="bibr15-0093854812437014">Littlepage &amp; Pineault, 1985</xref>; <xref ref-type="bibr" rid="bibr23-0093854812437014">O’Hair et al., 1981</xref>), this study is the first to examine its effects on multiple cognitive cues: response time, answer consistency, eye movements, and pupil dilation. The analyses suggest the individual and collective value of most of these cues for lie detection.</p>
<sec id="section31-0093854812437014">
<title>Response Time</title>
<p>The longer response times hypothesized to occur with deception, especially unrehearsed, were confirmed. Response time, a valuable cue to deception (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>; <xref ref-type="bibr" rid="bibr27-0093854812437014">Seymour et al., 2000</xref>; <xref ref-type="bibr" rid="bibr30-0093854812437014">Sporer &amp; Schwandt, 2007</xref>), was the best one of those we evaluated. Also, open-ended questions elicited longer response times than yes–no questions, replicating previous studies (<xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al., 2005</xref>; <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al., 2009</xref>). Importantly, the same general pattern of group differences of Video 1 was replicated with Video 2 (see <xref ref-type="table" rid="table1-0093854812437014">Table 1</xref>), but not across question types. For yes–no questions, unrehearsed liars took significantly longer to answer than both truth tellers and rehearsed liars. That rehearsed liars did not differ significantly from truth tellers may partially reflect that answers to yes–no questions are syntactically constrained. The adjusted yes–no scores showed the same pattern as the unadjusted ones but also control for individual differences (<xref ref-type="bibr" rid="bibr40-0093854812437014">Walters, 1996</xref>), making them most appropriate for lie detection examinations.</p>
<p>For the unadjusted open-ended response times of both videos, rehearsed liars answered the quickest, followed by truth tellers. Unrehearsed liars were the slowest. This pattern was maintained with the adjusted open-ended scores, except for a nonsignificant difference between truth tellers and unrehearsed liars for Video 2. For yes–no and open-ended questions, rehearsal is an effective cognitive load-attenuating countermeasure as assessed by response time, replicating others’ findings (<xref ref-type="bibr" rid="bibr23-0093854812437014">O’Hair et al., 1981</xref>; <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al., 2009</xref>). That open-ended question response times were significantly below those of truth tellers implies that the use of rehearsal is a detectable countermeasure for this question type.</p>
<p>These findings suggest that open-ended questions involving eyewitness accounts can provide better cues than yes–no questions. Why? <xref ref-type="bibr" rid="bibr38-0093854812437014">Walczyk, Roper, Seemann, and Humphrey (2003)</xref> observed that lying to yes–no questions was less cognitively demanding in general than lying to open-ended questions according to participant self-reports of lie construction. For the yes–no questions, they reported flipping an answer from yes to no or vice versa to make it untrue. For open-ended questions, more thought was given to the plausibility of answers due to their greater range of possible responses. Likewise, in this study, owing to fewer syntactic and more plausibility constraints, open-ended questions may generally have imposed greater cognitive loads, which can multiply the cues to deception (<xref ref-type="bibr" rid="bibr36-0093854812437014">Vrij et al., 2010</xref>). In short, the less constrained the response, the greater are the opportunities for cues to deception to manifest (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>). Still, open-ended questions will not always impose greater cognitive load. For instance, if answering a yes–no question truthfully requires retrieval of a truth long-dormant but an open-ended question accesses a truth of a recent event, the former should cause more load.</p>
</sec>
<sec id="section32-0093854812437014">
<title>Inconsistencies</title>
<p>This hypothesis was generally supported. Although the frequencies of inconsistencies were low across question categories, truth tellers had significantly fewer than rehearsed or unrehearsed liars across videos. The two lying conditions did not differ. <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al. (2009)</xref> and <xref ref-type="bibr" rid="bibr36-0093854812437014">Vrij et al. (2010)</xref> both found more inconsistencies in liars than truth tellers, especially when deceptions are unrehearsed. Importantly, total inconsistency depends on how many interrelated questions are asked and the depth of their logical interdependence. Video 1 and Video 2 had only five and four interrelated question pairs, respectively, which may not have been sufficiently cognitive load inducing to provoke many contradictions. Even so, they did help distinguish truth tellers from liars. Also, the present data showed that the inconsistencies are often subtle, blurting “he” instead of “she.” Having to answer under time restriction may maximize inconsistencies as question interrelatedness increases, which future research can explore.</p>
</sec>
<sec id="section33-0093854812437014">
<title>Eye Movements</title>
<p>The hypothesis that truth tellers would have the most eye movements was partially supported. Because of the ETL 400’s design, eye movements were analyzed into vertical and horizontal components. On examining the vertical eye movements of <xref ref-type="table" rid="table3-0093854812437014">Table 3</xref> and the horizontal movements of <xref ref-type="table" rid="table4-0093854812437014">Table 4</xref>, it is evident that the largest unadjusted vertical eye movement means occurred for truth tellers’ yes–no and open-ended questions of both videos, although the differences were not always significant. Importantly, the same pattern of significant differences held across tables. For Video 1, yes–no questions of truth tellers entailed greater eye movements than unrehearsed and rehearsed liars. For Video 2, truth tellers moved their eyes more than rehearsed liars for both question types. Truth tellers were expected to have the most eye movements. The unadjusted means thus partially supported this hypothesis. The adjusted yes–no means retained the same general pattern of truth tellers having the most eye movements and surprisingly showed that rehearsed liars had less eye movements than unrehearsed liars. For Video 1, truth tellers had more eye movement than rehearsed liars with yes–no questions. For Video 2, rehearsed liars had less than truth tellers and unrehearsed liars for both question types. Adjusting means support this hypothesis in that the largest means tend to be with truth tellers, but do not support it with the smallest means tending to go with rehearsed liars, especially for yes–no questions. Searching memory for rehearsed lies may require less environmental distraction than unrehearsed lying.</p>
<p>Stimulation from the environment can be distracting and impair internal processing (<xref ref-type="bibr" rid="bibr6-0093854812437014">Doherty-Sneddon et al., 2002</xref>; <xref ref-type="bibr" rid="bibr7-0093854812437014">Doherty-Sneddon &amp; Phelps, 2005</xref>; <xref ref-type="bibr" rid="bibr10-0093854812437014">Glenberg et al., 1998</xref>). Expanding on this notion, we predicted less eye movements for liars because their high cognitive loads focused on internal processing would have them reducing environmental distraction. In addition to having to generate or recall deceptive answers, liars’ loads were presumed high due to having to maintain eye contact (<xref ref-type="bibr" rid="bibr36-0093854812437014">Vrij et al., 2010</xref>). As noted above, sometimes rehearsed liars had the least eye movements likely to minimize environmental distraction, which we believe helped them recall their prepared lies. Future research should try to replicate these results and assess the effects of extensive rehearsal of lies on eye movements. We expect that well-rehearsed lies will have eye movement rates exceeding those of truth tellers. The present data show that eye movements can distinguish truth tellers from liars and run contrary to the stereotype that liars are shifty-eyed (<xref ref-type="bibr" rid="bibr32-0093854812437014">Vrij, 2000</xref>). Out of cognitive necessity, their eyes often must be stationary.</p>
</sec>
<sec id="section34-0093854812437014">
<title>Pupil Dilation</title>
<p>Surprisingly, the greater pupil dilation hypothesized with deception was not observed. Researchers have nonetheless found more pupil dilation in lying (<xref ref-type="bibr" rid="bibr3-0093854812437014">Bradley &amp; Janisse, 1979</xref>; <xref ref-type="bibr" rid="bibr5-0093854812437014">Dionisio et al., 2001</xref>; <xref ref-type="bibr" rid="bibr12-0093854812437014">Heilveil, 1976</xref>; <xref ref-type="bibr" rid="bibr19-0093854812437014">Lubow &amp; Fein, 1996</xref>; <xref ref-type="bibr" rid="bibr41-0093854812437014">Webb et al., 2009</xref>). One problem in this study may have been that dilation reflected not only cognitive load but emotional arousal as well (<xref ref-type="bibr" rid="bibr4-0093854812437014">DePaulo et al., 2003</xref>). Of the cues of this research, it may be the most confounded index of cognitive load. For instance, the novelty of the procedure and the stress of having to maintain eye contact may have been sufficiently arousing, even for truth tellers, to have overshadowed small group differences due to lying. Given its utility in past studies, though, researchers should continue to examine it. If cognitive lie detection examination procedures become standardized, it will likely become less ambiguous as an index of the cognitive load of deception.</p>
</sec>
<sec id="section35-0093854812437014">
<title>Exploratory Discriminant Analyses</title>
<p>The verbal skills of liars moderate the efficiency of lie generation (<xref ref-type="bibr" rid="bibr38-0093854812437014">Walczyk et al., 2003</xref>), so do social skills (<xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al., 2005</xref>) and other individual differences (<xref ref-type="bibr" rid="bibr32-0093854812437014">Vrij, 2000</xref>). We controlled for them by following the recommendation of <xref ref-type="bibr" rid="bibr40-0093854812437014">Walters (1996)</xref>. Specifically, only response time and eye movement means adjusted by means of general questions were used to estimate discriminant functions, along with inconsistency data. Collectively they discriminated among truth tellers, rehearsed liars, and unrehearsed liars. Moreover, although <xref ref-type="bibr" rid="bibr37-0093854812437014">Walczyk et al. (2009)</xref> demonstrated the value of adjusted response times and inconsistency totals as discriminators, our research contributes by also considering the effects of rehearsal on eye data.</p>
<p><xref ref-type="table" rid="table6-0093854812437014">Table 6</xref> reveals an interesting contrast. The best discriminators for response times involved open-ended questions, whereas for eye movements they were with yes–no questions. Our explanation follows. Eye movements and response times both index cognitive load, but differently. Measuring the amount of processing, response time is a direct consequence of cognitive load (<xref ref-type="bibr" rid="bibr28-0093854812437014">Solso, 2001</xref>), but gaze aversion and eye movements reflect attempts to manage load (<xref ref-type="bibr" rid="bibr6-0093854812437014">Doherty-Sneddon et al., 2002</xref>; <xref ref-type="bibr" rid="bibr7-0093854812437014">Doherty-Sneddon &amp; Phelps, 2005</xref>; <xref ref-type="bibr" rid="bibr10-0093854812437014">Glenberg et al., 1998</xref>). Minimal syntactic constraint on answers to open-ended questions likely required extended memory search for plausible lies for unrehearsed liars, causing the long responses times, but also dramatic reduction in processing below that of truth telling when lies are rehearsed. The processing reduction caused by rehearsal could not be matched with the constrained yes–no questions. In contrast, <xref ref-type="table" rid="table6-0093854812437014">Table 6</xref> shows a much greater range of adjusted eye movement means across lie conditions for yes–no questions than for open-ended questions. Adjusted yes–no means for unrehearsed liars are close to those of general questions (near zero). Truth tellers have the most eye movements, reflecting minimal need to reduce load. Rehearsed liars have eye movements dramatically below those of general questions, suggestive of attempted load reduction. Reduced eye movements for yes–no questions may reflect rehearsed liars’ lessening of environmental distraction to focus on overcoming the Stroop-like interference of giving mildly practiced responses that were incompatible with a habitual behavior: answering truthfully syntactically constrained yes–no questions. Stated generally, rehearsing responses lightens cognitive load more for unconstrained responding than for constrained responding, but rehearsal of atypical responding (e.g., lying) produces the most interference and need for focused attention when response options are highly constrained. This account must be verified by future research.</p>
<p>Admittedly, some polygraph validity studies have achieved higher classification accuracies than those of this research (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>; <xref ref-type="bibr" rid="bibr22-0093854812437014">NRC, 2003</xref>). Even so, we caution readers against dismissing prematurely TRI-Con and other cognitive load-inducing lie detection techniques. The polygraph has been refined over many decades, whereas TRI-Con and similar techniques (see <xref ref-type="bibr" rid="bibr33-0093854812437014">Vrij, Fisher et al., 2008</xref>) are new. Only research aimed at refining averting-rehearsal, dual tasking, and combined approaches will realize their potential. Some encouraging findings for TRI-Con are the low rates of false positives we observed, which are a problem with the polygraph and a major reason for its limited use in the criminal justice system (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>).</p>
</sec>
<sec id="section36-0093854812437014">
<title>Using TRI-Con within The Criminal Justice System</title>
<p>There are many legal and psychological obstacles to the adoption of new forensic technologies like cognitive-load-inducing lie detection techniques. Will judges, lawyers, victims, suspects, defendants, and witnesses accept TRI-Con and similar approaches, even if they become well validated? Having to answers questions under the guidelines of TRI-Con might not be accepted by professionals initially. However, to put this in a historical perspective, the public’s initial reaction to the invasiveness of the polygraph was negative. Still, the device was eventually accepted (<xref ref-type="bibr" rid="bibr20-0093854812437014">Lykken, 1998</xref>). If TRI-Con and other load-inducing techniques can prove their worth, they likely will be accepted, too. TRI-Con has potential to assess truthfulness and deception wherever short answers can be given. For instance, if a suspect provides an alibi that police believe is false, a series of yes–no and open-ended questions could be written based on the alibi-probing details the individual may not have anticipated. Moreover, as in this research, prompting, the asking of questions, and the assessment of cues can be largely automated. Also, determining whether an examinee is answering honestly or lying rehearsed or unrehearsed can be done using statistical procedures like logistical regression or discriminant analyses. Of course, more refinement of TRI-Con is needed, especially on authentic samples and involving high stakes lies.</p>
</sec>
<sec id="section37-0093854812437014">
<title>Limitations and Future Research Directions</title>
<p>A few limitations are noteworthy. Unlike the polygraph, lie detection did not occur at the level of the question. Rather, it occurred for question set. <xref ref-type="bibr" rid="bibr39-0093854812437014">Walczyk et al. (2005</xref>) noted that the cognitive cues to an individual question may be too unreliable at present to support such precise lie detection. However, the present data suggest that response times, inconsistency, and eye movements can discriminate truth tellers from rehearsed and unrehearsed liars. Future refinement of load-inducing approaches that adds cognitive cues, tweaks the procedures to prevent rehearsal further, and imposes concurrent tasks that interfere selectively with lying may make question-level detection a reality. Another limitation is the fact that two factors were actually manipulated in this research under the IV lie condition: lie instructions (lie, tell the truth) and level of rehearsal (rehearsed, unrehearsed). Moreover, they were not fully crossed in a 2 × 2 factorial design. That is, there was no rehearsed, truth teller condition. Had there been one, then interactions between these factors could have been examined. However, readers can discern the effects of lie instructions by comparing unrehearsed liars and truth tellers and can consider the effects of level of rehearsal by comparing rehearsed and unrehearsed liars. The rehearsal of truthful responses is rare in authentic contexts but should be added as a condition in future research. Another limitation relates to instructions to maintain eye contact; these might be ineffective with Japanese and other non-Western cultures for whom such eye contact goes against a societal norm. These instructions might induce inordinately high levels of anxiety and be distracting within these cultures (<xref ref-type="bibr" rid="bibr21-0093854812437014">McCarthy, Lee, Itakura, &amp; Muir, 2006</xref>), even for truth tellers. Finally, the motivation of our participants to appear truthful was not as high as that of actual witnesses lying to protect someone. Future research testing TRI-Con and similar approaches should increase the incentive for lying by offering cash rewards to participants who can deceive while appearing sincere, as well as test more authentic samples (e.g., prisoners). Still, the promising results of this study justify more research on TRI-Con and other cognitive load-inducing techniques with the hope of uncovering deception during interviews of witnesses and thereby reducing perjured testimony.</p>
</sec>
</sec>
</body>
<back>
<app-group>
<app id="app1-0093854812437014">
<title>Appendix</title>
<sec id="section38-0093854812437014">
<title>General and Video-Related Questions</title>
<table-wrap id="table7-0093854812437014" position="float">
<graphic alternate-form-of="table7-0093854812437014" xlink:href="10.1177_0093854812437014-table7.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<tbody>
<tr>
<td><bold>General Questions</bold></td>
<td>Question pairs involving inconsistencies: 2-16, 3-15, 5-10, 7-17</td>
</tr>
<tr>
<td colspan="2"><bold>1) What was president Washington’s first name?*</bold></td>
</tr>
<tr>
<td colspan="2"><bold>2) Is Independence Day celebrated during August?</bold></td>
</tr>
<tr>
<td colspan="2"><bold>3) Is it possible for a person to be burned when operating an oven?</bold></td>
</tr>
<tr>
<td colspan="2">4) What is your last name?</td>
</tr>
<tr>
<td colspan="2">5) What is your age?</td>
</tr>
<tr>
<td colspan="2">6) What is your biological mother’s first name?</td>
</tr>
<tr>
<td colspan="2"><bold>7) In what city is the White House located?</bold></td>
</tr>
<tr>
<td colspan="2">8) You received your GED or graduated from high school in what year?</td>
</tr>
<tr>
<td colspan="2">9) What is your gender?</td>
</tr>
<tr>
<td colspan="2">10) Were you born before the year 1979?</td>
</tr>
<tr>
<td colspan="2">11) What is your race?</td>
</tr>
<tr>
<td colspan="2">12) Are you a freshman?</td>
</tr>
<tr>
<td colspan="2"><bold>13) Is our current president’s first name Leo?</bold></td>
</tr>
<tr>
<td colspan="2">14) Are you a student?</td>
</tr>
<tr>
<td colspan="2"><bold>15) Can an oven get hot?</bold></td>
</tr>
<tr>
<td colspan="2"><bold>16) On what date does the United States celebrate Independence Day?</bold></td>
</tr>
<tr>
<td colspan="2"><bold>17) Is Los Angeles the location of the White House?</bold></td>
</tr>
<tr>
<td colspan="2"><bold>18) What is the name of city of the Louisiana state capital?</bold></td>
</tr>
<tr>
<td><bold>Video 1 Questions</bold></td>
<td>Question pairs involving inconsistencies: 19-20, 19-23, 19-28, 22-23, 22-25</td>
</tr>
<tr>
<td colspan="2">19) What job did the perpetrator have?</td>
</tr>
<tr>
<td colspan="2">20) Following the crime, who came into the office and talked with the perpetrator?</td>
</tr>
<tr>
<td colspan="2">21) What was the perpetrator’s race?</td>
</tr>
<tr>
<td colspan="2">22) Was the perpetrator a woman?</td>
</tr>
<tr>
<td colspan="2">23) What was the perpetrator’s job-related reason for being in the office?</td>
</tr>
<tr>
<td colspan="2">24) Was the perpetrator wearing a baseball cap?</td>
</tr>
<tr>
<td colspan="2">25) What was the perpetrator’s criminal act?</td>
</tr>
<tr>
<td colspan="2">26) Approximately what was the perpetrator’s age?</td>
</tr>
<tr>
<td colspan="2">27) Was the perpetrator wearing shorts?</td>
</tr>
<tr>
<td colspan="2">28) Was the perpetrator wearing formal black shoes?</td>
</tr>
<tr>
<td><bold>Video 2 Questions</bold></td>
<td>Question pairs involving inconsistencies: 29-33, 29-34, 30-33, 30-35</td>
</tr>
<tr>
<td colspan="2">29) What was the criminal act?</td>
</tr>
<tr>
<td colspan="2">30) Was the perpetrator a man?</td>
</tr>
<tr>
<td colspan="2">31) Was the perpetrator Asian?</td>
</tr>
<tr>
<td colspan="2">32) What was the race of the clerk behind the counter?</td>
</tr>
<tr>
<td colspan="2">33) How did the perpetrator try to conceal the criminal act?</td>
</tr>
<tr>
<td colspan="2">34) Where did the criminal act take place?</td>
</tr>
<tr>
<td colspan="2">35) What did the perpetrator and the clerk talk about?</td>
</tr>
<tr>
<td colspan="2">36) Was the perpetrator wearing a hat?</td>
</tr>
<tr>
<td colspan="2">37) At the time of the crime, how many were visible in the store?</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0093854812437014">
<p><italic>Note</italic>. Boldfaced general questions have verifiable truths.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</app>
</app-group>
<fn-group>
<fn fn-type="other">
<p>This material is based on work funded by National Science Foundation (NSF) Grant 648375. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors, not NSF. The authors thank Alexandra Bellone, Melissa Bordelon, Victoria Gault, and Coleen Maidlow for their assistance with data collection and coding.</p>
</fn>
</fn-group>
<bio>
<p><bold>Jeffrey J. Walczyk</bold> is a professor of psychology at Louisiana Tech University. He is former associate editor of the <italic>Journal of Educational Psychology</italic>. His research interests include cognitive and social aspects of deception as well as the psychology of reading.</p>
<p><bold>Diana A. Griffith</bold> is a research associate at Louisiana Tech. Formerly an editorial assistant of the <italic>Journal of Educational Psychology</italic>, she writes grants and conducts research on deception.</p>
<p><bold>Rachel Yates</bold> received her master’s degree in industrial-organizational psychology in 2009. Presently she is the administrative assistant at the Center for Secure Cyberspace of Louisiana Tech.</p>
<p><bold>Shelley R. Visconte</bold> is a doctoral candidate in counseling psychology at Louisiana Tech. Her research interests include the study of autism.</p>
<p><bold>Byron Simoneaux</bold> is a doctoral candidate in counseling psychology at Louisiana Tech. His dissertation concerns gender differences in the attribution of deception in others.</p>
<p><bold>Laura L. Harris</bold> is a doctoral student in counseling psychology at Louisiana Tech.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Anastasi</surname><given-names>A.</given-names></name>
<name><surname>Urbina</surname><given-names>S.</given-names></name>
</person-group> (<year>1997</year>). <source>Psychological testing</source>. <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation>
</ref>
<ref id="bibr2-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bond</surname><given-names>C. F.</given-names><suffix>Jr.</suffix></name>
<name><surname>DePaulo</surname><given-names>B. M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Accuracy of deception judgments</article-title>. <source>Personality and Social Psychology Review</source>, <volume>10</volume>, <fpage>214</fpage>-<lpage>234</lpage>.</citation>
</ref>
<ref id="bibr3-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradley</surname><given-names>M. T.</given-names></name>
<name><surname>Janisse</surname><given-names>M. P.</given-names></name>
</person-group> (<year>1979</year>). <article-title>Pupil size and lie detection. The effect of certainty on detection</article-title>. <source>Psychology: A Quarterly Journal of Human Behavior</source>, <volume>16</volume>, <fpage>33</fpage>-<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr4-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DePaulo</surname><given-names>B. M.</given-names></name>
<name><surname>Lindsay</surname><given-names>J. J.</given-names></name>
<name><surname>Malone</surname><given-names>B. E.</given-names></name>
<name><surname>Muhlenbruck</surname><given-names>L.</given-names></name>
<name><surname>Charlton</surname><given-names>K.</given-names></name>
<name><surname>Harris</surname><given-names>C.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Cues to deception</article-title>. <source>Psychological Bulletin</source>, <volume>129</volume>, <fpage>74</fpage>-<lpage>112</lpage>.</citation>
</ref>
<ref id="bibr5-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dionisio</surname><given-names>D. P.</given-names></name>
<name><surname>Granholm</surname><given-names>E.</given-names></name>
<name><surname>Hillix</surname><given-names>W. A.</given-names></name>
<name><surname>Perrine</surname><given-names>W. F.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Differentiation of deception using pupillary response as an index of cognitive processing</article-title>. <source>Psychophysiology</source>, <volume>38</volume>, <fpage>205</fpage>-<lpage>211</lpage>.</citation>
</ref>
<ref id="bibr6-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Doherty-Sneddon</surname><given-names>G.</given-names></name>
<name><surname>Bruce</surname><given-names>V.</given-names></name>
<name><surname>Bonner</surname><given-names>L.</given-names></name>
<name><surname>Longbotham</surname><given-names>S.</given-names></name>
<name><surname>Doyle</surname><given-names>C.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Development of gaze aversion as disengagement from visual information</article-title>. <source>Developmental Psychology</source>, <volume>38</volume>, <fpage>438</fpage>-<lpage>445</lpage>.</citation>
</ref>
<ref id="bibr7-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Doherty-Sneddon</surname><given-names>G.</given-names></name>
<name><surname>Phelps</surname><given-names>F. G.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Gaze aversion: A response to cognitive or social difficulty?</article-title> <source>Memory &amp; Cognition</source>, <volume>33</volume>, <fpage>727</fpage>-<lpage>733</lpage>.</citation>
</ref>
<ref id="bibr8-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garrett</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The substance of false confessions</article-title>. <source>Stanford Law Review</source>, <volume>62</volume>, <fpage>1051</fpage>-<lpage>1119</lpage>.</citation>
</ref>
<ref id="bibr9-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garrido</surname><given-names>E.</given-names></name>
<name><surname>Masip</surname><given-names>J.</given-names></name>
<name><surname>Herrero</surname><given-names>C.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Police officers’ credibility judgments: Accuracy and estimated ability</article-title>. <source>International Journal of Psychology</source>, <volume>39</volume>, <fpage>254</fpage>-<lpage>275</lpage>.</citation>
</ref>
<ref id="bibr10-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Glenberg</surname><given-names>A. M.</given-names></name>
<name><surname>Schroeder</surname><given-names>J. L.</given-names></name>
<name><surname>Robertson</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Averting the gaze disengages the environment and facilitates remembering</article-title>. <source>Memory &amp; Cognition</source>, <volume>26</volume>, <fpage>651</fpage>-<lpage>658</lpage>.</citation>
</ref>
<ref id="bibr11-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hartwig</surname><given-names>M.</given-names></name>
<name><surname>Granhag</surname><given-names>P. A.</given-names></name>
<name><surname>Stromwall</surname><given-names>L. A.</given-names></name>
<name><surname>Vrij</surname><given-names>A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Police officers’ lie detection accuracy: Interrogating freely versus observing video</article-title>. <source>Police Quarterly</source>, <volume>7</volume>, <fpage>429</fpage>-<lpage>456</lpage>.</citation>
</ref>
<ref id="bibr12-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heilveil</surname><given-names>I.</given-names></name>
</person-group> (<year>1976</year>). <article-title>Deception and pupil size</article-title>. <source>Journal of Clinical Psychology</source>, <volume>32</volume>, <fpage>443</fpage>-<lpage>449</lpage>.</citation>
</ref>
<ref id="bibr13-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Inbau</surname><given-names>F. E.</given-names></name>
<name><surname>Reid</surname><given-names>J. E.</given-names></name>
<name><surname>Buckley</surname><given-names>J. P.</given-names></name>
<name><surname>Jayne</surname><given-names>B. C.</given-names></name>
</person-group> (<year>2001</year>). <source>Criminal interrogation and confessions</source>. <publisher-loc>Gaithersburg, MD</publisher-loc>: <publisher-name>Aspen</publisher-name>.</citation>
</ref>
<ref id="bibr14-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Landström</surname><given-names>S.</given-names></name>
<name><surname>Granhag</surname><given-names>P.</given-names></name>
<name><surname>Hartwig</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Witnesses appearing live versus on video: Effects on observers’ perception, veracity assessments, and memory</article-title>. <source>Applied Cognitive Psychology</source>, <volume>19</volume>, <fpage>913</fpage>-<lpage>933</lpage>.</citation>
</ref>
<ref id="bibr15-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Littlepage</surname><given-names>G. E.</given-names></name>
<name><surname>Pineault</surname><given-names>M. A.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Detection of deception of planned and spontaneous communications</article-title>. <source>Journal of Social Psychology</source>, <volume>125</volume>, <fpage>195</fpage>-<lpage>201</lpage>.</citation>
</ref>
<ref id="bibr16-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Littlepage</surname><given-names>G. E.</given-names></name>
<name><surname>Tang</surname><given-names>D. W.</given-names></name>
<name><surname>Pineault</surname><given-names>M. A.</given-names></name>
</person-group> (<year>1986</year>). <article-title>Nonverbal and content factors in the detection of planned and spontaneous communications</article-title>. <source>Journal of Social Behavior and Personality</source>, <volume>1</volume>, <fpage>439</fpage>-<lpage>450</lpage>.</citation>
</ref>
<ref id="bibr17-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Loftus</surname><given-names>E.</given-names></name>
</person-group> (<year>1979</year>). <source>Eyewitness testimony</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Loftus</surname><given-names>E. F.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Memory distortions: Problems solved and unsolved</article-title>. In <person-group person-group-type="editor">
<name><surname>Garry</surname><given-names>M.</given-names></name>
<name><surname>Hayne</surname><given-names>H.</given-names></name>
</person-group> (Eds.), <source>Do justice and let the sky fall: Elizabeth Loftus and her contributions to science, law, and academic freedom</source> (pp. <fpage>1</fpage>-<lpage>14</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr19-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lubow</surname><given-names>R. E.</given-names></name>
<name><surname>Fein</surname><given-names>D.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Pupillary size in response to a visual guilty knowledge test: New technique for the detection of deception</article-title>. <source>Journal of Experimental Psychology: Applied</source>, <volume>2</volume>, <fpage>164</fpage>-<lpage>177</lpage>.</citation>
</ref>
<ref id="bibr20-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lykken</surname><given-names>D. T.</given-names></name>
</person-group> (<year>1998</year>). <source>A tremor in the blood: Uses and abuses of the lie detector</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</citation>
</ref>
<ref id="bibr21-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCarthy</surname><given-names>A.</given-names></name>
<name><surname>Lee</surname><given-names>K.</given-names></name>
<name><surname>Itakura</surname><given-names>S.</given-names></name>
<name><surname>Muir</surname><given-names>D.W.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Cultural display rules drive eye gaze during thinking</article-title>. <source>Journal of Cross-Cultural Psychology</source>, <volume>37</volume>, <fpage>717</fpage>-<lpage>722</lpage>.</citation>
</ref>
<ref id="bibr22-0093854812437014">
<citation citation-type="book">
<collab>National Research Council</collab>. (<year>2003</year>). <source>The polygraph and lie detection</source>. <comment>Committee to Review the Scientific Evidence on the Polygraph</comment>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academies Press</publisher-name>.</citation>
</ref>
<ref id="bibr23-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>O’Hair</surname><given-names>H. D.</given-names></name>
<name><surname>Cody</surname><given-names>M. J.</given-names></name>
<name><surname>McLaughlin</surname><given-names>M. L.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Prepared lies, spontaneous lies, Machiavellianism, and nonverbal communication</article-title>. <source>Human Communication Research</source>, <volume>7</volume>, <fpage>325</fpage>-<lpage>339</lpage>.</citation>
</ref>
<ref id="bibr24-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>O’Sullivan</surname><given-names>M.</given-names></name>
<name><surname>Frank</surname><given-names>M. G.</given-names></name>
<name><surname>Hurley</surname><given-names>C M.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Police lie detection accuracy: The effect of lie scenario</article-title>. <source>Law and Human Behavior</source>, <volume>33</volume>, <fpage>530</fpage>-<lpage>538</lpage>.</citation>
</ref>
<ref id="bibr25-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pashler</surname><given-names>H.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Dual-task interference in simple tasks: Data and theory</article-title>. <source>Psychological Bulletin</source>, <volume>116</volume>, <fpage>220</fpage>-<lpage>244</lpage>.</citation>
</ref>
<ref id="bibr26-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Porter</surname><given-names>S.</given-names></name>
<name><surname>Yuille</surname><given-names>J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>The language of deceit: An investigation of the verbal clues to deception in the interrogation context</article-title>. <source>Law and Human Behavior</source>, <volume>20</volume>, <fpage>443</fpage>-<lpage>458</lpage>.</citation>
</ref>
<ref id="bibr27-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Seymour</surname><given-names>T. L</given-names></name>
<name><surname>Seifert</surname><given-names>C. M.</given-names></name>
<name><surname>Shafto</surname><given-names>M. G.</given-names></name>
<name><surname>Mosmann</surname><given-names>A. L.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Using response time measures to assess “guilty knowledge.”</article-title> <source>Journal of Applied Psychology</source>, <volume>85</volume>, <fpage>30</fpage>-<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr28-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Solso</surname><given-names>R. L.</given-names></name>
</person-group> (<year>2001</year>). <source>Cognitive psychology</source> (<edition>6th ed.</edition>). <publisher-loc>Needham Heights, MA</publisher-loc>: <publisher-name>Allyn &amp; Bacon</publisher-name>.</citation>
</ref>
<ref id="bibr29-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sporer</surname><given-names>S. L.</given-names></name>
<name><surname>Schwandt</surname><given-names>B.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Paraverbal indicators of deception: A meta-analytic synthesis</article-title>. <source>Applied Cognitive Psychology</source>, <volume>20</volume>, <fpage>421</fpage>-<lpage>446</lpage>.</citation>
</ref>
<ref id="bibr30-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sporer</surname><given-names>S. L.</given-names></name>
<name><surname>Schwandt</surname><given-names>B.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Moderators of nonverbal indicators of deception: A meta-analytic synthesis</article-title>. <source>Psychology, Public Policy, and Law</source>, <volume>13</volume>, <fpage>1</fpage>-<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr31-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vrij</surname><given-names>A.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Credibility judgments and detectives: The impact of nonverbal behaviour, social skills and physical characteristics on impression formation</article-title>. <source>Journal of Social Psychology</source>, <volume>133</volume>, <fpage>601</fpage>-<lpage>611</lpage>.</citation>
</ref>
<ref id="bibr32-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vrij</surname><given-names>A.</given-names></name>
</person-group> (<year>2000</year>). <source>Detecting lies and deceit</source>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr33-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vrij</surname><given-names>A.</given-names></name>
<name><surname>Fisher</surname><given-names>R.</given-names></name>
<name><surname>Mann</surname><given-names>S.</given-names></name>
<name><surname>Leal</surname><given-names>S.</given-names></name>
</person-group> (<year>2008</year>). <article-title>A cognitive load approach to lie detection</article-title>. <source>Journal of Investigative Psychology and Offender Profiling</source>, <volume>5</volume>, <fpage>39</fpage>-<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr34-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vrij</surname><given-names>A.</given-names></name>
<name><surname>Leal</surname><given-names>S.</given-names></name>
<name><surname>Granhag</surname><given-names>P. A.</given-names></name>
<name><surname>Mann</surname><given-names>S.</given-names></name>
<name><surname>Fisher</surname><given-names>R. P.</given-names></name>
<name><surname>Hillman</surname><given-names>J.</given-names></name>
<name><surname>Sperry</surname><given-names>K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Outsmarting the liars: The benefits of asking unanticipated questions</article-title>. <source>Law &amp; Human Behavior</source>, <volume>33</volume>, <fpage>159</fpage>-<lpage>166</lpage>.</citation>
</ref>
<ref id="bibr35-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vrij</surname><given-names>A.</given-names></name>
<name><surname>Mann</surname><given-names>S.</given-names></name>
<name><surname>Fisher</surname><given-names>R.</given-names></name>
<name><surname>Leal</surname><given-names>S.</given-names></name>
<name><surname>Milne</surname><given-names>B.</given-names></name>
<name><surname>Bull</surname><given-names>R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Increasing cognitive load to facilitate lie detection: The benefit of recalling an event in reverse order</article-title>. <source>Law &amp; Human Behavior</source>, <volume>32</volume>, <fpage>253</fpage>-<lpage>265</lpage>.</citation>
</ref>
<ref id="bibr36-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vrij</surname><given-names>A.</given-names></name>
<name><surname>Mann</surname><given-names>S.</given-names></name>
<name><surname>Leal</surname><given-names>S.</given-names></name>
<name><surname>Fisher</surname><given-names>R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>“Look into my eyes”: Can an instruction to maintain eye contract facilitate lie detection?</article-title> <source>Psychology, Crime, &amp; Law</source>, <volume>16</volume>, <fpage>327</fpage>-<lpage>348</lpage>.</citation>
</ref>
<ref id="bibr37-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walczyk</surname><given-names>J. J.</given-names></name>
<name><surname>Mahoney</surname><given-names>K. T.</given-names></name>
<name><surname>Doverspike</surname><given-names>D.</given-names></name>
<name><surname>Griffith-Ross</surname><given-names>D. A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Cognitive lie detection: Response time and consistency of answers as cues to deception</article-title>. <source>Journal of Business and Psychology</source>, <volume>24</volume>, <fpage>33</fpage>-<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr38-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walczyk</surname><given-names>J. J.</given-names></name>
<name><surname>Roper</surname><given-names>K.</given-names></name>
<name><surname>Seemann</surname><given-names>E.</given-names></name>
<name><surname>Humphrey</surname><given-names>A. M.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Cognitive mechanisms underlying lying to questions: Response time as a cue to deception</article-title>. <source>Applied Cognitive Psychology</source>, <volume>17</volume>, <fpage>755</fpage>-<lpage>774</lpage>.</citation>
</ref>
<ref id="bibr39-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walczyk</surname><given-names>J. J.</given-names></name>
<name><surname>Schwartz</surname><given-names>J. P.</given-names></name>
<name><surname>Clifton</surname><given-names>R.</given-names></name>
<name><surname>Adams</surname><given-names>B.</given-names></name>
<name><surname>Wei</surname><given-names>M.</given-names></name>
<name><surname>Zha</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Lying person to person about life events: A cognitive framework for lie detection</article-title>. <source>Personnel Psychology</source>, <volume>58</volume>, <fpage>141</fpage>-<lpage>170</lpage>.</citation>
</ref>
<ref id="bibr40-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Walters</surname><given-names>S. B.</given-names></name>
</person-group> (<year>1996</year>). <source>Principles of Kinesic Interview and Interrogation</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>CRC</publisher-name>.</citation>
</ref>
<ref id="bibr41-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Webb</surname><given-names>A. K.</given-names></name>
<name><surname>Honts</surname><given-names>C. R.</given-names></name>
<name><surname>Kircher</surname><given-names>J. C.</given-names></name>
<name><surname>Bernhardt</surname><given-names>P.</given-names></name>
<name><surname>Cook</surname><given-names>A. E.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Effectiveness of pupil diameter in a probable-lie comparison question test for deception</article-title>. <source>Legal and Criminal Psychology</source>, <volume>14</volume>, <fpage>279</fpage>-<lpage>292</lpage>.</citation>
</ref>
<ref id="bibr42-0093854812437014">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wells</surname><given-names>G. L.</given-names></name>
<name><surname>Olson</surname><given-names>E. A.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Eyewitness testimony</article-title>. <source>Annual Review of Psychology</source>, <volume>54</volume>, <fpage>277</fpage>-<lpage>295</lpage>.</citation>
</ref>
<ref id="bibr43-0093854812437014">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Zuckerman</surname><given-names>M.</given-names></name>
<name><surname>DePaulo</surname><given-names>B. M.</given-names></name>
<name><surname>Rosenthal</surname><given-names>R.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Verbal and nonverbal communication of deception</article-title>. In <person-group person-group-type="editor">
<name><surname>Berkowitz</surname><given-names>L.</given-names></name>
</person-group> (Ed.), <source>Advances in experimental social psychology</source> (<volume>Vol. 14</volume>, pp. <fpage>1</fpage>-<lpage>59</lpage>). <publisher-loc>New York</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>