<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EMR</journal-id>
<journal-id journal-id-type="hwp">spemr</journal-id>
<journal-title>Emotion Review</journal-title>
<issn pub-type="ppub">1754-0739</issn>
<issn pub-type="epub">1754-0747</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1754073912451504</article-id>
<article-id pub-id-type="publisher-id">10.1177_1754073912451504</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Special Section: Facial Expressions</subject></subj-group></article-categories>
<title-group>
<article-title>Understanding the Mechanisms Underlying the Production of Facial Expression of Emotion: A Componential Perspective</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Scherer</surname><given-names>Klaus R.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Mortillaro</surname><given-names>Marcello</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Mehu</surname><given-names>Marc</given-names></name>
</contrib>
<aff id="aff1-1754073912451504">Swiss Center for Affective Sciences, University of Geneva, Switzerland</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1754073912451504">Klaus R. Scherer, Swiss Centre for Affective Sciences, University of Geneva, Rue des Battoirs 7, CH-1205 Geneva, Switzerland. <italic>Email</italic>: <email>Klaus.Scherer@unige.ch</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>5</volume>
<issue>1</issue>
<fpage>47</fpage>
<lpage>53</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">ISRE and SAGE</copyright-holder>
</permissions>
<abstract>
<p>We highlight the need to focus on the underlying determinants and production mechanisms to fully understand the nature of facial expression of emotion and to settle the theoretical debate about the meaning of motor expression. Although emotion theorists have generally remained rather vague about the details of the process, this has been a central concern of componential appraisal theories. We describe the fundamental assumptions and predictions of this approach regarding the patterning of facial expressions for different emotions. We also review recent evidence for the assumption that specific facial muscle movements may be reliable symptoms of certain appraisal outcomes and that facial expressions unfold over time on the basis of a sequence of appraisal check results.</p>
</abstract>
<kwd-group>
<kwd>appraisal</kwd>
<kwd>component process model</kwd>
<kwd>emotion perception</kwd>
<kwd>expression and perception mechanisms</kwd>
<kwd>facial expression</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Movements of the face are central sign vehicles for the expression and communication of emotions among higher primates, particularly man. Unsurprisingly, the study of facial expression has a long history and has generated an extraordinary amount of research. What is surprising is that this sustained activity has, to date, yielded little insight into the nature of the underlying <italic>mechanisms</italic>. There seem to be three major reasons for this: (a) the neglect of the dynamic nature of facial expression, given the prevalent focus on static expressions or configurations; (b) the neglect of the production mechanisms for facial expressions, given that most research has focused only on emotion recognition; and (c) the relative vagueness of theoretical models about these mechanisms, which impairs clear research designs and an accumulation of evidence (<xref ref-type="bibr" rid="bibr34-1754073912451504">Scherer, Clark-Polner, &amp; Mortillaro, 2011</xref>).</p>
<p>At the most general level, a comprehensive theoretical framework is needed to study the emotion expression and perception process. To this aim, <xref ref-type="bibr" rid="bibr31-1754073912451504">Scherer (2011)</xref> suggested the tripartite emotion expression and perception model (TEEP). This dynamic model, shown in <xref ref-type="fig" rid="fig1-1754073912451504">Figure 1</xref>, is based on a combination of the modified versions of <xref ref-type="bibr" rid="bibr4-1754073912451504">Brunswik’s (1956)</xref> lens model of perception and <xref ref-type="bibr" rid="bibr5-1754073912451504">Bühler’s (1934/1984)</xref> organon model of speech (<xref ref-type="bibr" rid="bibr23-1754073912451504">Scherer, 1978</xref>, <xref ref-type="bibr" rid="bibr25-1754073912451504">1988</xref>, <xref ref-type="bibr" rid="bibr29-1754073912451504">2003</xref>), as well as on the first author’s component process model of emotion (CPM; <xref ref-type="bibr" rid="bibr24-1754073912451504">Scherer, 1984</xref>, <xref ref-type="bibr" rid="bibr28-1754073912451504">2001</xref>, <xref ref-type="bibr" rid="bibr30-1754073912451504">2009</xref>). It proposes that sequences of sign vehicles (including muscular movements in the face) are symptoms or externalizations of unfolding emotion processes (appraisal-driven modulations of the autonomic and somatic parts of the peripheral nervous system) with or without communicative intention of the expresser (symptom function). The observer perceives these sign vehicles as proximal percepts and, on this basis, appraises the significance of the expression, using a variety of inference and attribution mechanisms. The result can be the attribution of an emotion to the expresser and/or a variety of behavior changes (appeal function). Importantly, the sociocultural setting strongly affects the communication process as a result of conventional feeling and display rules and, in particular, the fact that expressive signs can be part of a shared symbolic nonverbal code (representation function).</p>
<fig id="fig1-1754073912451504" position="float">
<label>Figure 1.</label>
<caption>
<p>The tripartite emotion expression and perception model (TEEP). E = eliciting factors (events, objects, behaviors); ANS = autonomic nervous system; SNS = somatic nervous system. Reprinted from <xref ref-type="bibr" rid="bibr31-1754073912451504">Scherer (2011)</xref>.</p>
</caption>
<graphic xlink:href="10.1177_1754073912451504-fig1.tif"/></fig>
<p>There is ongoing debate between the proponents of different emotion theories about the functions and meanings of facial expressions. For discrete emotion theorists, the experience of one of the basic emotions will produce a prototypical response configuration that includes an <italic>emotion-specific pattern of facial expression</italic> (<xref ref-type="bibr" rid="bibr7-1754073912451504">Ekman, 1992</xref>; <xref ref-type="bibr" rid="bibr8-1754073912451504">Ekman, Sorenson, &amp; Friesen, 1969</xref>; <xref ref-type="bibr" rid="bibr13-1754073912451504">Izard, 1994</xref>). In contrast, componential appraisal theorists suggest that the <italic>individual elements of facial expression are determined by appraisal results</italic> and represent the efferent effects of the latter on motor behavior (<xref ref-type="bibr" rid="bibr24-1754073912451504">Scherer, 1984</xref>, <xref ref-type="bibr" rid="bibr26-1754073912451504">1992</xref>, <xref ref-type="bibr" rid="bibr28-1754073912451504">2001</xref>, <xref ref-type="bibr" rid="bibr30-1754073912451504">2009</xref>; <xref ref-type="bibr" rid="bibr37-1754073912451504">Smith, 1989</xref>; <xref ref-type="bibr" rid="bibr38-1754073912451504">Smith &amp; Scott, 1997</xref>). Other researchers suggest that facial expressions mainly convey the <italic>action readiness</italic> component of the emotion (<xref ref-type="bibr" rid="bibr12-1754073912451504">Frijda &amp; Tcherkassof, 1997</xref>) or are indicators of <italic>valence and activation</italic> (<xref ref-type="bibr" rid="bibr22-1754073912451504">Russell, 1997</xref>). Finally, <xref ref-type="bibr" rid="bibr10-1754073912451504">Fridlund (1994)</xref> maintains that facial expressions serve as <italic>social messages</italic> that evolved to convey intentions and contingencies relevant to a specific audience.</p>
<p>The TEEP model may help us identify the central issues in this debate. As shown in <xref ref-type="fig" rid="fig1-1754073912451504">Figure 1</xref>, one needs to distinguish between the representational or symbolic meaning as part of a shared code and the subjective meaning based on the inference of the observer, the latter meaning being generally constructed from inferences concerning the origin of the visible symptoms and the observer’s expectations and preconceptions. Clearly, to understand the ways in which elements of facial expressions can be symptoms (distal cues) of underlying emotion processes, we need to focus on the nature of the <italic>production mechanisms</italic> and the <italic>underlying determinants</italic>. Until now, there has been little concern with this issue, most emotion theories being rather vague about the details, with the exception of the componential appraisal approach. Here we describe the detailed assumptions and predictions of the componential appraisal approach and the pertinent evidence to date.</p>
<sec id="section1-1754073912451504">
<title>The Component Process Model of Emotion</title>
<p>Componential appraisal theories of emotion (<xref ref-type="bibr" rid="bibr9-1754073912451504">Ellsworth &amp; Scherer, 2003</xref>; <xref ref-type="bibr" rid="bibr11-1754073912451504">Frijda, 1986</xref>; <xref ref-type="bibr" rid="bibr21-1754073912451504">Roseman &amp; Smith, 2001</xref>; <xref ref-type="bibr" rid="bibr24-1754073912451504">Scherer, 1984</xref>, <xref ref-type="bibr" rid="bibr28-1754073912451504">2001</xref>; <xref ref-type="bibr" rid="bibr37-1754073912451504">Smith, 1989</xref>) define emotion as a process that reflects the cognitive activity, physiological arousal, action tendencies, motor expression, and subjective feeling state in reaction to salient events in the environment. Some of these theories assume that these components are linked (or even synchronized) during an emotion episode (see <xref ref-type="bibr" rid="bibr24-1754073912451504">Scherer, 1984</xref>, <xref ref-type="bibr" rid="bibr28-1754073912451504">2001</xref>). Although componential theories of emotion generally do not endorse the idea of a small number of basic emotions (and potential blends), but rather consider that there is a large number of different emotions, they tend to agree that there are overarching emotion families. This view is reflected in <xref ref-type="bibr" rid="bibr27-1754073912451504">Scherer’s (1994)</xref> concept of <italic>modal emotions</italic>, defined as frequent patterns of appraisal occurring in response to event types that are universally encountered by organisms, such as sadness in the case of loss, or anger in the case of blocked goals (see also the notion of <italic>relational themes</italic> suggested by <xref ref-type="bibr" rid="bibr17-1754073912451504">Lazarus, 1991</xref>). Thus, componential models do not fundamentally question the idea that facial expressions mark differentiated emotional states; rather, they propose that the different muscular elements present in complex expressive configurations of the face are driven by appraisals of an eliciting event, mediated by autonomic and somatic components.</p>
<p>One major contribution of componential appraisal theories is the effort to make the link between emotion elicitation and response patterning more explicit than has been the case in discrete emotion theories. Thus, theorists have elaborated detailed predictions of physiological, expressive, and motivational changes expected to occur as a result of specific appraisal outcomes (<xref ref-type="bibr" rid="bibr24-1754073912451504">Scherer, 1984</xref>, <xref ref-type="bibr" rid="bibr26-1754073912451504">1992</xref>, <xref ref-type="bibr" rid="bibr28-1754073912451504">2001</xref>; <xref ref-type="bibr" rid="bibr37-1754073912451504">Smith, 1989</xref>; <xref ref-type="bibr" rid="bibr38-1754073912451504">Smith &amp; Scott, 1997</xref>). In his CPM, <xref ref-type="bibr" rid="bibr24-1754073912451504">Scherer (1984</xref>, <xref ref-type="bibr" rid="bibr28-1754073912451504">2001</xref>, <xref ref-type="bibr" rid="bibr30-1754073912451504">2009</xref>) defends the idea that the unique, context- and individual-specific response pattern observed during an emotional episode represents the efferent effects of sequentially accrued and cumulated appraisal results (based on the following criteria: (a) relevance of the event; (b) implications for major needs, goals, and values; (c) ability to deal with these consequences or coping potential; and (d) normative significance of the event). The model predicts that the results of sequential appraisal checks will generate appropriate response patterns.</p>
<p>Predictions for facial expression (<xref ref-type="bibr" rid="bibr28-1754073912451504">Scherer, 2001</xref>, <xref ref-type="bibr" rid="bibr30-1754073912451504">2009</xref>; <xref ref-type="bibr" rid="bibr35-1754073912451504">Scherer &amp; Ellgring, 2007</xref>; see also <xref ref-type="bibr" rid="bibr14-1754073912451504">Kaiser &amp; Wehrle, 2001</xref>) have been elaborated from several classes of determinants: (a) the effects of physiological change; (b) the preparation of specific instrumental motor actions; and (c) the production of sociocommunicative signals. The first two determinants refer to what the first author has called “push effects,” that is, neurobiological changes that affect the expressive motor system (the symptom function). In contrast, the communicative function is served by “pull effects,” that is, particular visual or auditory signal configurations that are part of a socially shared code for symbolic exchanges. These two classes of determinants closely interact to produce complex and multimodal emotional expressions (<xref ref-type="bibr" rid="bibr25-1754073912451504">Scherer, 1988</xref>). Given the multifactorial determination of muscles in the oropharyngeal and orofacial systems, and the fact that different demands upon the organism may be more or less prevalent depending on the specific context, predictions about the link between internal states and observable units of behavior are mostly probabilistic rather than deterministic. The final expression resulting from the sequential cumulative appraisal process can be predicted on the basis of the assumptions and theoretically predicted appraisal profiles for major modal emotions. The facial configurations predicted as final outcomes for a number of modal emotions, as based on the mechanism described, are shown in <xref ref-type="table" rid="table1-1754073912451504">Table 1</xref> (for further details, see <xref ref-type="bibr" rid="bibr28-1754073912451504">Scherer, 2001</xref>; <xref ref-type="bibr" rid="bibr35-1754073912451504">Scherer &amp; Ellgring, 2007</xref>). The underlying philosophy for elaborating these predictions for modal emotions is that we start with the hypothesized effects of appraisal results and consequent action tendencies (with interacting push and pull effects) and work forward (assuming sequential accumulation of elements) to larger configurations. Because the configuration predictions shown in <xref ref-type="table" rid="table1-1754073912451504">Table 1</xref> correspond to modal emotions (see <xref ref-type="bibr" rid="bibr27-1754073912451504">Scherer, 1994</xref>), they are somewhat similar to prototypical patterns as proposed by discrete emotion theorists. However, the CPM mechanisms suggest that these configurations are the exception rather than the rule, the generative mechanisms based on appraisal results dynamically producing a multitude of different configurations.</p>
<table-wrap id="table1-1754073912451504" position="float">
<label>Table 1.</label>
<caption>
<p>Prediction of sequential appearance of action units (AUs) in response to appraisal check results for five major emotions</p>
</caption>
<graphic alternate-form-of="table1-1754073912451504" xlink:href="10.1177_1754073912451504-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Order</th>
<th align="left">Appraisal domain</th>
<th align="left">Check</th>
<th align="left">Subcheck</th>
<th align="left">AUs</th>
<th align="left">Fear</th>
<th align="left">Anger</th>
<th align="left">Joy</th>
<th align="left">Sadness</th>
<th align="left">Disgust</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Relevance</td>
<td>Novelty</td>
<td>Sudden</td>
<td>1 + 2, 5</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
</tr>
<tr>
<td>2</td>
<td/>
<td/>
<td>Unfamiliar, unpredictable</td>
<td>4 + 7</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
</tr>
<tr>
<td>3</td>
<td/>
<td>Intrinsic pleasantness</td>
<td>Pleasant</td>
<td>12 + 25 + 38</td>
<td>—</td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>3</td>
<td/>
<td/>
<td>Unpleasant</td>
<td>9, 10, 15, 39</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td>—</td>
<td>—</td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
</tr>
<tr>
<td>4</td>
<td>Implications</td>
<td>Expectation</td>
<td>Discrepant</td>
<td>4 + 7</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
</tr>
<tr>
<td>5</td>
<td/>
<td>Goal attainment</td>
<td>Conducive</td>
<td>6 + 12 + 25</td>
<td>—</td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>5</td>
<td/>
<td/>
<td>Obstructive</td>
<td>17 + 23, 17 + 24</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td/>
</tr>
<tr>
<td>6</td>
<td>Coping potential</td>
<td>Power/control</td>
<td>Low</td>
<td>20, 26, 27</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td>—</td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td>—</td>
</tr>
<tr>
<td>6</td>
<td/>
<td/>
<td>High</td>
<td>23 + 25, 17 + 23, 6 + 17 + 24</td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">**</xref></td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
</tr>
<tr>
<td>7</td>
<td>Norm compatibility</td>
<td>External standards</td>
<td>Violated</td>
<td>10</td>
<td>—</td>
<td><xref ref-type="table-fn" rid="table-fn1-1754073912451504">*</xref></td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td>7</td>
<td/>
<td>Internal standards</td>
<td>Violated</td>
<td>14</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1754073912451504"><p><italic>Note:</italic> + Indicates AU combinations in which two or more AUs are expected to occur simultaneously. AUs separated by a comma represent alternative expressions (in some cases, two of these AUs may occur together or in close sequence). ** Indicates “strongly expected to occur in many instances”; * indicates “expected to occur in some instances”(modified from <xref ref-type="bibr" rid="bibr35-1754073912451504">Scherer &amp; Ellgring, 2007</xref>).</p></fn>
</table-wrap-foot></table-wrap>
</sec>
<sec id="section2-1754073912451504">
<title>Evidence for a Link between Appraisals and Facial Expressions</title>
<p>What is the currently available empirical evidence supporting the CPM framework and concrete predictions? Ideally, one would want a large set of video recordings of facial expressions of naturalistic emotions in which one has measured the appraisal results that have generated the emotion. Clearly, such a corpus does not exist and is unlikely to be assembled. The main problems are that we have only indirect access to appraisal processes occurring in real-life emotion episodes and that most occur in public or private settings in which it is difficult to have access to or to record the face from close up. Furthermore, in public settings, there is a strong tendency to suppress, modify, or mask emotions. For example, using unobtrusive video recordings of the faces of airline passengers reporting lost baggage to an airport agent, <xref ref-type="bibr" rid="bibr33-1754073912451504">Scherer and Ceschi (2000)</xref> found very few facial expressions other than smiles. Similar studies of selected expressions recorded in public can be found in the literature, but the nature of the underlying emotion is often difficult to assess (see <xref ref-type="bibr" rid="bibr32-1754073912451504">Scherer &amp; Bänziger, 2010</xref>). The attempt to record dynamic emotion expressions in real-life contexts should not be given up, but researchers need to be conscious of the scarcity of full-blown emotion expressions in public settings and the problems of convenience sampling that often neglects fundamental requirements of experimental control (see <xref ref-type="bibr" rid="bibr31-1754073912451504">Scherer, 2011</xref>).</p>
<p>More viable research options involve experimental manipulations of appraisals, imagery tasks, and analysis of enacted expressions. A number of experimental studies have provided evidence supporting the assumption that facial actions covary with specific appraisals. In these studies, researchers recorded the electromyography activity of two or more facial muscles (corrugator supercilii, brow region: frowning; zygomaticus major, cheek region: smiling; frontalis, forehead region: eyebrow raise) in different appraisal conditions. <xref ref-type="bibr" rid="bibr1-1754073912451504">Aue, Flykt, and Scherer (2007)</xref> used visual stimuli that varied in relevance (biological threat vs. cultural threat vs. neutral) and manipulated their goal conduciveness (monetary gain vs. loss). Consistent with the idea of more difficulty in processing cultural threat, the stimuli belonging to this category were related to higher activation of the corrugator. Furthermore, consistent with predictions, greater activity in the cheek region (smiling) was recorded when the participants thought they were winning money. <xref ref-type="bibr" rid="bibr2-1754073912451504">Aue and Scherer (2008)</xref> used stimuli that varied in intrinsic pleasantness and manipulated goal conduciveness through a behavioral task. Results showed that the two appraisals affected activity of the facial muscles in accordance with CPM predictions: Activity in the cheek region was higher for pleasant stimuli and goal conducive events; activity in the brow region was higher for unpleasant stimuli and obstructive events. <xref ref-type="bibr" rid="bibr6-1754073912451504">Delplanque et al. (2009)</xref> presented pleasant or unpleasant odors that were either novel or familiar to the participants and investigated physiological and facial reactions to appraisals of novelty and intrinsic pleasantness. The results showed a highly significant increase in the activity of muscle over the forehead region (frontalis) for novel stimuli and over the forehead and brow region (corrugator) for unpleasant stimuli.</p>
<p>Other researchers investigated the relationship between appraisals and expressions by using an imagery task. <xref ref-type="bibr" rid="bibr37-1754073912451504">Smith (1989)</xref> tested the relationship between frowning and appraisals of anticipated effort and other agency in imagined scenarios. Results showed that effort manipulation had a strong effect on the activity of the brow region, but not other agency. From the analysis of the self-reported appraisals, it emerged that participants dissociated the two appraisals related to effort manipulation, that is, anticipated effort and perceived obstacles. The appraisal of perceived obstacles, more than anticipated effort, was particularly responsible for the frown activity. This finding was replicated by <xref ref-type="bibr" rid="bibr20-1754073912451504">Pope and Smith (1994)</xref>, who used an imagery task to study the activity of the corrugator muscle (frown) and zygomaticus major (smile) associated with appraisals of pleasantness, perceived goal obstacle, anticipated effort, and motivational congruence. Results confirmed the association of corrugator activity with perceived goal obstacles and motivational incongruence, and the association between zygomaticus activity and subjective pleasantness.</p>
<p>The plausibility of the predictions made by componential appraisal theorists can be examined indirectly by asking professional actors to enact a large number of emotions by using imagery and other induction techniques and by examining which patterns of facial action units (AUs; <xref ref-type="bibr" rid="bibr7-1754073912451504">Ekman, 1992</xref>) they produce in enacting the different emotions. Note that the special enactment procedure, in which actors are induced through a variety of techniques to reexperience earlier emotional states similar to the target emotions, is very different from portrayal approaches in which actors are encouraged or even required to produce certain patterns of AUs (see <xref ref-type="bibr" rid="bibr3-1754073912451504">Bänziger, Mortillaro, &amp; Scherer, 2011</xref>). Thus, <xref ref-type="bibr" rid="bibr35-1754073912451504">Scherer and Ellgring (2007)</xref> examined the frequency with which AUs were activated in enacted expressions of several major emotions. They found very few of the prototypical facial configurations postulated for basic emotions. Nevertheless, the enacted expressions were generally recognized with high accuracy by raters. Overall, the results are highly compatible with appraisal predictions, and the authors argued that the patterns of AUs used to express emotions were in line with the functional adaptive considerations at the basis of the componential model of emotion. More recently, using the same paradigm on a new corpus of emotional expressions (Geneva Multimodal Emotion Portrayals; <xref ref-type="bibr" rid="bibr3-1754073912451504">Bänziger et al., 2011</xref>), <xref ref-type="bibr" rid="bibr19-1754073912451504">Mortillaro, Mehu, and Scherer (2011)</xref> analyzed the facial expressions of four positive emotions: interest, joy, pride, and pleasure. Results showed that these emotions could not be discriminated from single facial movements. Nevertheless, differences in facial activity emerged when the expressions were contrasted in terms of the appraisals underlying the emotions. In particular, the appraisal dimension of novelty—suddenness—was reflected in the degree of eye opening. Other possible links were advanced: cheek raise (AU6) for intrinsically pleasant emotions and eyelid tightening (AU7) for goal obstructive emotions. Overall, the study strengthened the plausibility of interpreting single facial movements in terms of appraisals. The same suggestion is also advanced by <xref ref-type="bibr" rid="bibr18-1754073912451504">Mehu, Mortillaro, Bänziger, and Scherer (2012)</xref> in their investigation of the role of facial muscles in conveying reliable emotional information. The authors found that some individual AUs, although not indicative of an emotion category per se, convey emotional meaning in that perceivers use these movements to evaluate the authenticity of the emotional expression.</p>
<p>Supporting evidence for the predictions of the CPM is available concerning three appraisal checks: (a) Appraisal of novelty is associated with activity in the forehead (eyebrow raise) and eyelid opening; (b) appraisal of intrinsic pleasantness is associated with activity of the zygomaticus major, cheek raise (pleasant events), and the corrugator (unpleasant events); and (c) goal conducive events are associated with activity of the zygomaticus major and goal obstructive events with increased activity of the corrugator muscle. Predictions of facial movements for the remaining appraisal dimensions of the CPM—coping potential and normative significance—have not been tested.</p>
</sec>
<sec id="section3-1754073912451504">
<title>The Sequential Hypothesis of Appraisal Unfolding</title>
<p>As briefly indicated, the CPM assumes that different appraisal checks recursively occur in a fixed order (based on phylogenetic, ontogenetic, and microgenetic grounds; <xref ref-type="bibr" rid="bibr28-1754073912451504">Scherer, 2001</xref>, <xref ref-type="bibr" rid="bibr30-1754073912451504">2009</xref>). If facial actions were indeed determined by the outcome of sequential appraisal checks, specific facial movements (mediated by physiological concomitants or functional action preparation; e.g., tuning of sensory organs for information intake or fight or flight) should also occur in a discriminable sequence rather that arising simultaneously. The suggested process is illustrated in <xref ref-type="fig" rid="fig2-1754073912451504">Figure 2</xref> (reproduced from <xref ref-type="bibr" rid="bibr35-1754073912451504">Scherer &amp; Ellgring, 2007</xref>). A list of predictions can be drawn up for sequence patterns that can be expected for certain emotions in connection with the postulated appraisal structure (see <xref ref-type="table" rid="table1-1754073912451504">Table 1</xref>).</p>
<fig id="fig2-1754073912451504" position="float">
<label>Figure 2.</label>
<caption>
<p>Example of cumulative and sequential effects of appraisals on facial expressions as hypothesized by the component process model. Numbers refer to action unit numbers as defined in the FACS manual. Reprinted from <xref ref-type="bibr" rid="bibr35-1754073912451504">Scherer and Ellgring (2007)</xref>.</p>
</caption>
<graphic xlink:href="10.1177_1754073912451504-fig2.tif"/></fig>
<p>Only a few studies have investigated the temporal unfolding of facial movements in the framework of appraisal theory. Thus, <xref ref-type="bibr" rid="bibr1-1754073912451504">Aue et al. (2007)</xref> showed that, as predicted by the CPM, the effect of stimulus relevance appeared earlier in the activity of both corrugator and zygomaticus than the effect of goal conduciveness appraisal. <xref ref-type="bibr" rid="bibr16-1754073912451504">Lanctôt and Hess (2007)</xref> investigated the onset of movement in three facial muscles (corrugator supercilii, zygomaticus major, and orbicularis oculi) in response to appraisals of intrinsic pleasantness and goal conduciveness. In the framework of a video-game paradigm, the authors manipulated these two appraisals and found that muscles were activated more rapidly in response to evaluation of intrinsic pleasantness than to evaluation of goal conduciveness, suggesting that the former is evaluated prior to the latter.</p>
<p>In the <xref ref-type="bibr" rid="bibr6-1754073912451504">Delplanque et al. (2009)</xref> odor study, the authors found an increase in muscle activity over the forehead region for novel stimuli, in comparison to familiar stimuli, at about 100 ms after the presentation of the stimulus. In contrast, the effect of pleasantness on frontalis and corrugator was observed about 500 ms after the presentation of the stimulus, supporting the hypothesized sequence of appraisal checks. Finally, <xref ref-type="bibr" rid="bibr15-1754073912451504">Krumhuber and Scherer (2011)</xref> investigated the sequence of facial AUs displayed in the expression of five emotions. From the analysis of 100 expressions taken from the Geneva Multimodal Emotion Portrayal corpus (<xref ref-type="bibr" rid="bibr3-1754073912451504">Bänziger et al., 2011</xref>), the authors found that individual AUs reached their apexes at different times in the expression of different emotions. Although specific predictions concerning the timing of AU4 (frowning) were not confirmed, general results support the notion of sequentiality of facial movements in the expression of emotion.</p>
<p>These few studies show preliminary evidence for some elements of the sequential hypothesis: evaluation of novelty preceding evaluation of intrinsic pleasantness, in turn preceding evaluation of goal conduciveness.</p>
</sec>
<sec id="section4-1754073912451504" sec-type="conclusions">
<title>Conclusion</title>
<p>Limited space does not allow us to expand on the consequences of the component patterning model for the remaining parts of the TEEP model. In a recent review of studies on cross-cultural emotion recognition (<xref ref-type="bibr" rid="bibr34-1754073912451504">Scherer et al., 2011</xref>), we reported the extent to which the area suffers from the lack of theoretical grounding and absence of concern about the dynamic nature of emotional expression. Thus, a review of the emotion recognition literature has demonstrated the need to at least complement the study of static photos with dynamic multimodal—or at least facial—stimuli and that many of the hotly debated issues (e.g., universality vs. cultural specificity of expression) cannot be fruitfully discussed, given the lack of comprehensive research designs.</p>
<p>We also argue for the need to study expression production and perception in a single paradigm (e.g., using the TEEP model) on the basis of clear theoretical predictions. Thus, the discussion of the type of information that observers can reliably infer from facial expressions (emotion labels, appraisals, valence and arousal, action tendencies, or social messages; see <xref ref-type="bibr" rid="bibr36-1754073912451504">Scherer &amp; Grandjean, 2008</xref>) would greatly profit from measuring or manipulating production factors such as the nature of the facial AUs used and the sequence of their occurrence. In addition, researchers should turn toward other aspects of the appeal function of facial signs, such as contagion, empathy, or behavior change, rather that exclusively pursuing the question of accurate recognition based on verbal labels. Although there is some work on these issues, it is generally conducted outside of the area of emotion expression research.</p>
<p>In addition, the third function of facial signals contained in the TEEP model—the symbolic or representational function of facial movements—has been generally neglected by emotion researchers. This is all the more problematic because the likelihood is high that few expressions are the result of pure push effects in the sense of a classic symptom function. Given the widespread occurrence of expression control, modification, and masking, as well as sheer strategic manipulation (<xref ref-type="bibr" rid="bibr32-1754073912451504">Scherer &amp; Bänziger, 2010</xref>), we need to know much more about the way in which facial signals are part of a shared representational and symbolic code. If anything, the extraordinary increase in the use of graphic emoticons in interpersonal communication over the Internet demonstrates the degree of codification attained.</p>
<p>We conclude that the facial expression mechanisms proposed by componential appraisal theory are not only plausible, having a high degree of explanatory power, but are also supported by recent studies from different laboratories. Specifically, the highly controlled experimental work reported earlier provides strong evidence that certain appraisal outcomes (a) reliably produce the predicted facial AUs, and (b) generally occur in the theoretically postulated sequence. Not all hypotheses of the CPM have been studied or confirmed, but we believe that, given the small number of researchers working in this area, the available evidence is extremely promising. Even more important, the level of details of the predictions should allow other researchers to test them and replicate or disconfirm findings. Although some of the work described earlier is based on basic emotion categories (given the need to compare with other theories), the CPM account of facial expression mechanisms is much more general, assuming that all facial movements, even outside of what would strictly be considered an emotion episode, can potentially be explained by the underlying architecture. This work is still at the beginning, limited to a handful of research groups. It is to be hoped that the accumulating evidence will encourage other investigators to use this promising paradigm. We believe that such a paradigm shift is likely to make headway in solving the three fundamental problems outlined earlier: neglect of the dynamics of facial expression, neglect of the production mechanisms, and lack of explicit and comprehensive theoretical models to guide research.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other">
<label>Author note:</label>
<p>This research was supported by an Advanced Grant of the European Research Council (ERC) to Klaus Scherer and the Swiss Center for Affective Sciences.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aue</surname><given-names>T.</given-names></name>
<name><surname>Flykt</surname><given-names>A.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2007</year>). <article-title>First evidence for differential and sequential efferent effects of goal relevance and goal conduciveness appraisal</article-title>. <source>Biological Psychology</source>, <volume>74</volume>, <fpage>347</fpage>–<lpage>357</lpage>.</citation>
</ref>
<ref id="bibr2-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aue</surname><given-names>T.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Appraisal-driven somatovisceral response patterning: Effects of intrinsic pleasantness and goal conduciveness</article-title>. <source>Biological Psychology</source>, <volume>79</volume>, <fpage>158</fpage>–<lpage>164</lpage>.</citation>
</ref>
<ref id="bibr3-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bänziger</surname><given-names>T.</given-names></name>
<name><surname>Mortillaro</surname><given-names>M.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Introducing a new multimodal expression corpus for experimental research on emotion perception</article-title>. <source>Emotion</source>. Advance online publication. doi: <pub-id pub-id-type="doi">10.1037/a0025827</pub-id></citation>
</ref>
<ref id="bibr4-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brunswik</surname><given-names>E.</given-names></name>
</person-group> (<year>1956</year>). <source>Perception and the representative design of psychological experiments</source>. <publisher-loc>Berkeley, CA</publisher-loc>: <publisher-name>University of California Press</publisher-name>.</citation>
</ref>
<ref id="bibr5-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bühler</surname><given-names>K.</given-names></name>
</person-group> (<year>1984</year>). <source>Sprachtheorie</source> [<trans-source xml:lang="en">Theory of speech</trans-source>]. <publisher-loc>Jena, Germany</publisher-loc>: <publisher-name>Fischer</publisher-name>. (Original work published 1934)</citation>
</ref>
<ref id="bibr6-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Delplanque</surname><given-names>S.</given-names></name>
<name><surname>Grandjean</surname><given-names>D.</given-names></name>
<name><surname>Chrea</surname><given-names>C.</given-names></name>
<name><surname>Coppin</surname><given-names>G.</given-names></name>
<name><surname>Aymard</surname><given-names>L.</given-names></name>
<name><surname>Cayeux</surname><given-names>I.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Sequential unfolding of novelty and pleasantness appraisals of odors: Evidence from facial electromyography and autonomic reactions</article-title>. <source>Emotion</source>, <volume>9</volume>, <fpage>316</fpage>–<lpage>328</lpage>.</citation>
</ref>
<ref id="bibr7-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Facial expressions of emotion: New findings, new questions</article-title>. <source>Psychological Science</source>, <volume>3</volume>, <fpage>34</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr8-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
<name><surname>Sorenson</surname><given-names>E. R.</given-names></name>
<name><surname>Friesen</surname><given-names>W. V.</given-names></name>
</person-group> (<year>1969</year>). <article-title>Pan-cultural elements in facial displays of emotion</article-title>. <source>Science</source>, <volume>164</volume>, <fpage>86</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr9-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ellsworth</surname><given-names>P. C.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Appraisal processes in emotion</article-title>. In <person-group person-group-type="editor">
<name><surname>Davidson</surname><given-names>R. J.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Goldsmith</surname><given-names>H.</given-names></name>
</person-group> (Eds.), <source>Handbook of the affective sciences</source> (pp. <fpage>572</fpage>–<lpage>595</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fridlund</surname><given-names>A.</given-names></name>
</person-group> (<year>1994</year>). <source>Human facial expression: An evolutionary view</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr11-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Frijda</surname><given-names>N. H.</given-names></name>
</person-group> (<year>1986</year>). <source>The emotions</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr12-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Frijda</surname><given-names>N. H.</given-names></name>
<name><surname>Tcherkassof</surname><given-names>A.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Facial expressions as modes of action readiness</article-title>. In <person-group person-group-type="editor">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>The psychology of facial expression</source> (pp. <fpage>78</fpage>–<lpage>102</lpage>). <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Izard</surname><given-names>C. E.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Innate and universal facial expressions: Evidence from developmental and cross-cultural research</article-title>. <source>Psychological Bulletin</source>, <volume>115</volume>, <fpage>288</fpage>–<lpage>299</lpage>.</citation>
</ref>
<ref id="bibr14-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kaiser</surname><given-names>S.</given-names></name>
<name><surname>Wehrle</surname><given-names>T.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Facial expressions as indicators of appraisal processes</article-title>. In <person-group person-group-type="editor">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Schorr</surname><given-names>A.</given-names></name>
<name><surname>Johnstone</surname><given-names>T.</given-names></name>
</person-group> (Eds.), <source>Appraisal processes in emotion : Theory, methods, research</source> (pp. <fpage>285</fpage>–<lpage>300</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr15-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Krumhuber</surname><given-names>E. G.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Affect bursts: Dynamic patterns of facial expression</article-title>. <source>Emotion</source>, <volume>11</volume>, <fpage>825</fpage>–<lpage>841</lpage>.</citation>
</ref>
<ref id="bibr16-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lanctôt</surname><given-names>N. G.</given-names></name>
<name><surname>Hess</surname><given-names>U.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The timing of appraisals</article-title>. <source>Emotion</source>, <volume>7</volume>, <fpage>201</fpage>–<lpage>212</lpage>.</citation>
</ref>
<ref id="bibr17-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lazarus</surname><given-names>R. S.</given-names></name>
</person-group> (<year>1991</year>). <source>Emotion and adaptation</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mehu</surname><given-names>M.</given-names></name>
<name><surname>Mortillaro</surname><given-names>M.</given-names></name>
<name><surname>Bänziger</surname><given-names>T.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Reliable facial muscle activation enhances recognizability and credibility of emotional expression</article-title>. <source>Emotion</source>. Advance online publication. doi: <pub-id pub-id-type="doi">10.1037/a0026717</pub-id></citation>
</ref>
<ref id="bibr19-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mortillaro</surname><given-names>M.</given-names></name>
<name><surname>Mehu</surname><given-names>M.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Subtly different positive emotions can be distinguished by their facial expressions</article-title>. <source>Social Psychological and Personality Science</source>, <volume>2</volume>, <fpage>262</fpage>–<lpage>271</lpage>.</citation>
</ref>
<ref id="bibr20-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pope</surname><given-names>L. K.</given-names></name>
<name><surname>Smith</surname><given-names>C. A.</given-names></name>
</person-group> (<year>1994</year>). <article-title>On the distinct meanings of smiles and frowns</article-title>. <source>Cognition and Emotion</source>, <volume>8</volume>, <fpage>65</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr21-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Roseman</surname><given-names>I. J.</given-names></name>
<name><surname>Smith</surname><given-names>C. A.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Appraisal theory: Overview, assumptions, varieties, controversies</article-title>. In <person-group person-group-type="editor">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Schorr</surname><given-names>A.</given-names></name>
<name><surname>Johnstone</surname><given-names>T.</given-names></name>
</person-group> (Eds.), <source>Appraisal processes in emotion: Theory, methods, research</source> (pp. <fpage>3</fpage>–<lpage>34</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Reading emotions from and into faces: Resurrecting a dimensional-contextual perspective</article-title>. In <person-group person-group-type="editor">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>The psychology of facial expression</source> (pp. <fpage>295</fpage>–<lpage>320</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr23-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1978</year>). <article-title>Personality inference from voice quality: The loud voice of extroversion</article-title>. <source>European Journal of Social Psychology</source>, <volume>8</volume>, <fpage>467</fpage>–<lpage>487</lpage>.</citation>
</ref>
<ref id="bibr24-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1984</year>). <article-title>On the nature and function of emotion: A component process approach</article-title>. In <person-group person-group-type="editor">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Ekman</surname><given-names>P.</given-names></name>
</person-group> (Eds.), <source>Approaches to emotion</source> (pp. <fpage>293</fpage>–<lpage>317</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr25-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1988</year>). <article-title>On the symbolic functions of vocal affect expression</article-title>. <source>Journal of Language and Social Psychology</source>, <volume>7</volume>, <fpage>79</fpage>–<lpage>100</lpage>.</citation>
</ref>
<ref id="bibr26-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1992</year>). <article-title>What does facial expression express?</article-title> In <person-group person-group-type="editor">
<name><surname>Strongman</surname><given-names>K.</given-names></name>
</person-group> (Ed.), <source>International review of studies on emotion</source> (<volume>Vol. 2</volume>, pp. <fpage>139</fpage>–<lpage>165</lpage>). <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr27-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Toward a concept of “modal” emotions</article-title>. In <person-group person-group-type="editor">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
<name><surname>Davidson</surname><given-names>R. J.</given-names></name>
</person-group> (Eds.), <source>The nature of emotion: Fundamental questions</source> (pp. <fpage>25</fpage>–<lpage>31</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr28-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Appraisal considered as a process of multilevel sequential checking</article-title>. In <person-group person-group-type="editor">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Schorr</surname><given-names>A.</given-names></name>
<name><surname>Johnstone</surname><given-names>T.</given-names></name>
</person-group> (Eds.), <source>Appraisal processes in emotion: Theory, methods, research</source> (pp. <fpage>92</fpage>–<lpage>120</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr29-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Vocal communication of emotion: A review of research paradigms</article-title>. <source>Speech Communication</source>, <volume>40</volume>, <fpage>227</fpage>–<lpage>256</lpage>.</citation>
</ref>
<ref id="bibr30-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The dynamic architecture of emotion: Evidence for the component process model</article-title>. <source>Cognition &amp; Emotion</source>, <volume>23</volume>, <fpage>1307</fpage>–<lpage>1351</lpage>.</citation>
</ref>
<ref id="bibr31-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Vocal markers of emotion: Comparing induction and acting elicitation</article-title>. <source>Computer Speech and Language</source>. Advance online publication. doi:<pub-id pub-id-type="doi">10.1016/j.csl.2011.11.003</pub-id></citation>
</ref>
<ref id="bibr32-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Bänziger</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>On the use of actor portrayals in research on emotional expression</article-title>. In <person-group person-group-type="editor">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Bänziger</surname><given-names>T.</given-names></name>
<name><surname>Roesch</surname><given-names>E. B.</given-names></name>
</person-group> (Eds.), <source>Blueprint for affective computing: A sourcebook</source> (pp. <fpage>166</fpage>–<lpage>178</lpage>). <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr33-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Ceschi</surname><given-names>G.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Criteria for emotion recognition from verbal and nonverbal expression: Studying baggage loss in the airport</article-title>. <source>Personality and Social Psychology Bulletin</source>, <volume>26</volume>, <fpage>327</fpage>–<lpage>339</lpage>.</citation>
</ref>
<ref id="bibr34-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Clark-Polner</surname><given-names>E.</given-names></name>
<name><surname>Mortillaro</surname><given-names>M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>In the eye of the beholder? Universality and cultural specificity in the expression and perception of emotion</article-title>. <source>International Journal of Psychology</source>, <volume>46</volume>, <fpage>401</fpage>–<lpage>435</lpage>.</citation>
</ref>
<ref id="bibr35-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Ellgring</surname><given-names>H.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Are facial expressions of emotion produced by categorical affect programs or dynamically driven by appraisal?</article-title> <source>Emotion</source>, <volume>7</volume>, <fpage>113</fpage>–<lpage>130</lpage>.</citation>
</ref>
<ref id="bibr36-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Grandjean</surname><given-names>D.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Inferences from facial expressions of emotion have many facets</article-title>. <source>Cognition &amp; Emotion</source>, <volume>22</volume>, <fpage>789</fpage>–<lpage>801</lpage>.</citation>
</ref>
<ref id="bibr37-1754073912451504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Smith</surname><given-names>C. A.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Dimensions of appraisal and physiological response in emotion</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>56</volume>, <fpage>339</fpage>–<lpage>353</lpage>.</citation>
</ref>
<ref id="bibr38-1754073912451504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Smith</surname><given-names>C. A.</given-names></name>
<name><surname>Scott</surname><given-names>H.</given-names></name>
</person-group> (<year>1997</year>). <article-title>A componential approach to the meaning of facial expressions</article-title>. In <person-group person-group-type="editor">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>The psychology of facial expression</source> (pp. <fpage>229</fpage>–<lpage>254</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref></ref-list>
</back>
</article>