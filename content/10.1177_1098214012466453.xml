<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AJE</journal-id>
<journal-id journal-id-type="hwp">spaje</journal-id>
<journal-title>American Journal of Evaluation</journal-title>
<issn pub-type="ppub">1098-2140</issn>
<issn pub-type="epub">1557-0878</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1098214012466453</article-id>
<article-id pub-id-type="publisher-id">10.1177_1098214012466453</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Method Notes</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>SAS Code for Calculating Intraclass Correlation Coefficients and Effect Size Benchmarks for Site-Randomized Education Experiments</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Brandon</surname>
<given-names>Paul R.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1098214012466453">1</xref>
<xref ref-type="corresp" rid="corresp1-1098214012466453"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Harrison</surname>
<given-names>George M.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1098214012466453">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lawton</surname>
<given-names>Brian E.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1098214012466453">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1098214012466453">
<label>1</label>University of Hawaii, at Manoa, Honolulu, HI USA</aff>
<author-notes>
<corresp id="corresp1-1098214012466453">Paul R. Brandon, University of Hawaii at Manoa, 1776 University Avenue, Castle Memorial Hall, Rm. 118, Honolulu, HI 96822, USA. Email: <email>brandon@hawaii.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>34</volume>
<issue>1</issue>
<fpage>85</fpage>
<lpage>90</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">American Evaluation Association</copyright-holder>
</permissions>
<abstract>
<p>When evaluators plan site-randomized experiments, they must conduct the appropriate statistical power analyses. These analyses are most likely to be valid when they are based on data from the jurisdictions in which the studies are to be conducted. In this method note, we provide software code, in the form of a SAS macro, for producing statistical power analyses using such data. The macro is designed to estimate statistical parameters for multiple school subjects and multiple grades in a single computer run. Among other convenient features, the macro calculates intraclass correlation coefficient confidence intervals, which are essential for planning studies conservatively. We also provide a SAS macro for calculating benchmarks–again, using locally-based–data for interpreting the feasibility of achieving the minimum detectable effect sizes that are calculated in statistical power analyses. The benchmarks are potentially useful for interpreting the meaning of the effect sizes that are achieved in completed studies, as well. We describe the macros, describe how we verified their accuracy, show how they can be useful to education evaluators, and give examples of their use with statewide educational assessment data. It is our hope that the macros will help evaluators use local data when conducting group-randomized studies.</p>
</abstract>
<kwd-group>
<kwd>group-randomized experiments</kwd>
<kwd>statistical power analyses</kwd>
<kwd>intraclass correlation coefficients</kwd>
<kwd>effect size benchmarks</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Site-randomized education evaluation experiments (also known as group-randomized, cluster-randomized, or cluster-sample experiments) have become increasingly common over the past decade. These studies require that evaluators conduct statistical power analyses for calculating the minimum detectable effect size (MDES) at the beginning of studies and that they have benchmarks for interpreting the feasibility of achieving the MDESs, as well as for interpreting the effect sizes that are achieved in completed studies. In this brief method note, we provide two SAS macros, one for assisting evaluators in conducting power analyses and one for interpreting MDESs. The first macro, entitled “A SAS Macro for Estimating Education-Study Statistical Power Parameters,” is used to analyze data sets to produce key statistical power parameters for studies with two-level data (students clustered within schools). Statistical power analyses are most likely to be valid when they are based on student data (increasingly available to researchers) from the district or state education jurisdictions in which the studies are conducted. Our macro is intended to help evaluators calculate power parameters of data from such jurisdictions, including parameters not readily available from standard software. Our second macro, entitled “A SAS Macro for Producing Benchmarks for Interpreting School Effect Sizes,” is useful for interpreting estimated MDESs or actual between-school effect sizes when other benchmarks are unavailable.</p>
<p>In this note, we describe each of the macros, discuss their usefulness to education evaluators, and provide evidence for their accuracy. We assume a basic level of understanding of statistical power analyses and target our discussion toward evaluators of district- and state-wide education programs with access to student-level data sets. Our macros are described in <xref ref-type="table" rid="table1-1098214012466453">Table 1</xref> and are available online (Harrison, 2012; Lawton, 2012a, 2012b).</p>
<table-wrap id="table1-1098214012466453" position="float">
<label>Table 1.</label>
<caption>
<p>Steps in the Two SAS Macros.</p>
</caption>
<graphic alternate-form-of="table1-1098214012466453" xlink:href="10.1177_1098214012466453-table1.tif"/>
<table>
<thead>
<tr>
<th>Section of code</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" colspan="2">A SAS Macro For Estimating Education-Study Statistical Power Parameters</td>
</tr>
<tr>
<td>Data specification</td>
<td>Prompts the user to enter information into the code to specify (a) the details for identifying which data to include in the analysis and (b) the proposed design for their planned analysis. In the design, the user can specify whether to include all students in the school in their planned study or a given number of students per school. The user is asked to specify the outcome variable (test), the number of schools, and a known covariate (if any).</td>
</tr>
<tr>
<td>Macro code generation</td>
<td>Generates code, based on the user-specified design, which will be automatically used to invoke macros.</td>
</tr>
<tr>
<td>Subset selection</td>
<td>Eliminates invalid observations and creates subsets of data by grade. Eliminates schools with less than the user-specified minimum number of students.</td>
</tr>
<tr>
<td>Parameter estimation</td>
<td>For each subset of data, the code (a) calculates the harmonic mean number of students (which is needed if the user specifies using all available student-level data); (b) estimates the variance components for calculating the intraclass correlation coefficients (ICCs); (c) calculates the ICCs, the standard error of the ICCs, and the confidence limits of the ICCs; and (d) calculates the MDESs based on the ICCs and the user-specified covariate (if any).</td>
</tr>
<tr>
<td>Merging</td>
<td>Places the subsets’ ICC and MDES estimates into one file for subsequent printing.</td>
</tr>
<tr>
<td>Printing</td>
<td>Prints, for each test, every subset’s ICC and MDES estimates as well as the upper boundary of the confidence interval of these estimates. </td>
</tr>
<tr>
<td align="center" colspan="2">A SAS Macro For Producing Benchmarks For Interpreting School Effect Sizes</td>
</tr>
<tr>
<td>Data specification</td>
<td>Prompts the user to specify (a) the outcome variable, (b) the name of the SAS data set to use in the analysis, (c) the path directories for retrieving this data set and for storing the SAS files required for running the program, and (d) the minimum number of students for each school included in the analysis.</td>
</tr>
<tr>
<td>Subset selection</td>
<td>Creates subsets of the data based on the outcome variable that the user specifies and removes invalid scores and schools which do not have the minimum number of students.</td>
</tr>
<tr>
<td>Effect calculation</td>
<td>Calculates the effect size for all possible pairs of schools within a grade for each year. Estimates the descriptive statistics of this set of effect sizes, including the first quartile, the median, and the third quartile. </td>
</tr>
<tr>
<td>Printing</td>
<td>Prints the descriptive statistics of the effect size calculations for each grade within each year.</td>
</tr>
<tr>
<td>Mean effects per grade</td>
<td>Calculates and reports the first, second, and third quartile of effect sizes for one grade across all years.</td>
</tr>
</tbody>
</table>
</table-wrap>
<sec id="section1-1098214012466453">
<title>A SAS Macro for Estimating Education-Study Statistical Power Parameters</title>
<p>The first macro that we present (Harrison, 2012) produces several statistics that education evaluators will find useful when planning two-level group-randomized studies (students within schools). We show its major features in <xref ref-type="table" rid="table1-1098214012466453">Table 1</xref>. The macro produces estimates of the MDES, the intraclass correlation coefficient (ICC), ICC standard errors, and 95% ICC confidence intervals. The MDES is defined as the smallest standardized difference between treatment and control group means that can be detected at a specified level of probability (traditionally 80%). The ICC is a key parameter in calculating the MDES. It is calculated as <inline-formula id="inline-formula1-1098214012466453">
<mml:math id="mml-inline1-1098214012466453">
<mml:mi mathvariant="italic">ρ</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:msubsup><mml:mi mathvariant="italic">σ</mml:mi><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">÷</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="italic">σ</mml:mi><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">+</mml:mo><mml:msubsup><mml:mi mathvariant="italic">σ</mml:mi><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula2-1098214012466453">
<mml:math id="mml-inline2-1098214012466453">
<mml:msubsup><mml:mi mathvariant="italic">σ</mml:mi><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msubsup>
</mml:math>
</inline-formula> is the between-site variance and <inline-formula id="inline-formula3-1098214012466453">
<mml:math id="mml-inline3-1098214012466453">
<mml:msubsup><mml:mi mathvariant="italic">σ</mml:mi><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msubsup>
</mml:math>
</inline-formula> is the within-site variance. The standard error of the ICC is calculated as the square root of the variance (<xref ref-type="bibr" rid="bibr5-1098214012466453">Jacob, Zhu, &amp; Bloom, 2010</xref>),<disp-formula id="disp-formula1-1098214012466453">
<mml:math id="mml-inline4-1098214012466453">
<mml:mrow><mml:mo form="prefix" mathvariant="normal" movablelimits="true">var</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">ρ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">−</mml:mo><mml:mi mathvariant="italic">ρ</mml:mi><mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="italic">ρ</mml:mi><mml:mrow><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-1098214012466453" xlink:href="10.1177_1098214012466453-eq1.tif"/>
</disp-formula>
where ρ = the estimated ICC, <italic>N</italic> = the harmonic mean number of individuals per group, and <italic>J </italic>= the total number of groups. The confidence interval for the ICC is calculated as a multiple of the estimated standard error of the ICC. The upper level of the confidence interval is used when calculating the MDES to ensure that statistical power analyses are conducted in a conservative manner.</p>
<p>The macro is designed for analyzing state or district student-level data sets for multiple subjects in multiple grades with varying numbers of sites and students per site. It has three primary strengths. First, the ability to calculate parameters for multiple subjects in multiple grades in a single computer run provides considerable convenience to the analyst. Second, the ability to vary the numbers of sites and students per site specified in an analysis can help evaluators decide how many subjects and sites are necessary for conducting a study. By conducting multiple analyses based on varying conditions, the macro estimates power parameters under varying study or contextual conditions. The evaluator can use the results of the analyses to design a study that is feasible in the context of the study. Third, the macro helps design a study that is likely to achieve its estimated MDES. Specifying the upper boundary of the ICC confidence interval as the ICC parameter when calculating the MDES in a power analysis ensures that a study will result in an achievable MDES. Convenient calculation of ICC confidence intervals, and the corresponding MDES estimates, with the option to calculate for multiple grades, varying numbers of students, and varying numbers of sites in a single run of the macro, are not features packaged in existing software.</p>
<p>By way of an example, in <xref ref-type="table" rid="table2-1098214012466453">Table 2</xref> we show the results of using the macro on Hawaii third-grade students’ total reading scores on a state-wide achievement test across multiple years. The table shows no trends in the upper boundaries of the confidence interval across years; therefore, an evaluator might wish to calculate the mean across years (shown in the table). The results (not provided here) of using the macro for the same students’ total mathematics scores show a decreasing trend across years; evaluators examining those results might wish to use the results for the most recent year.</p>
<table-wrap id="table2-1098214012466453" position="float">
<label>Table 2.</label>
<caption>
<p>Upper Boundaries of 95% Confidence Intervals for Intraclass Correlation Coefficients for Hawaii State Assessment Total Reading, 40 Schools, By Grade and Year.</p>
</caption>
<graphic alternate-form-of="table2-1098214012466453" xlink:href="10.1177_1098214012466453-table2.tif"/>
<table>
<thead>
<tr>
<th rowspan="2">Year</th>
<th colspan="7">Grade</th>
<th rowspan="2">Mean</th>
</tr>
<tr>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr>
<td>2002</td>
<td>.189</td>
<td align="center">—</td>
<td>.178</td>
<td align="center">—</td>
<td align="center">—</td>
<td>.139</td>
<td>.136</td>
<td>.161</td>
</tr>
<tr>
<td>2003</td>
<td>.175</td>
<td align="center">—</td>
<td>.198</td>
<td align="center">—</td>
<td align="center">—</td>
<td>.134</td>
<td>.134</td>
<td>.160</td>
</tr>
<tr>
<td>2004</td>
<td>.172</td>
<td align="center">—</td>
<td>.186</td>
<td align="center">—</td>
<td align="center">—</td>
<td>.145</td>
<td>.187</td>
<td>.173</td>
</tr>
<tr>
<td>2005</td>
<td>.194</td>
<td>.191</td>
<td>.174</td>
<td>.224</td>
<td>.178</td>
<td>.147</td>
<td>.137</td>
<td>.178</td>
</tr>
<tr>
<td>2006</td>
<td>.173</td>
<td>.179</td>
<td>.169</td>
<td>.247</td>
<td>.132</td>
<td>.129</td>
<td>.140</td>
<td>.167</td>
</tr>
<tr>
<td>2007</td>
<td>.151</td>
<td>.154</td>
<td>.177</td>
<td>.200</td>
<td>.158</td>
<td>.136</td>
<td>.119</td>
<td>.156</td>
</tr>
<tr>
<td>2008</td>
<td>.170</td>
<td>.162</td>
<td>.159</td>
<td>.182</td>
<td>.170</td>
<td>.136</td>
<td>.122</td>
<td>.157</td>
</tr>
<tr>
<td>2009</td>
<td>.182</td>
<td>.160</td>
<td>.174</td>
<td>.182</td>
<td>.127</td>
<td>.135</td>
<td>.111</td>
<td>.153</td>
</tr>
<tr>
<td>Mean </td>
<td>.176</td>
<td>.169</td>
<td>.177</td>
<td>.207</td>
<td>.153</td>
<td>.137</td>
<td>.136</td>
<td>.163</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>To validate the accuracy of the software code for our first macro, we applied it in three ways. First, we verified that the macro (which uses SAS PROC MIXED with restricted maximum likelihood estimation) produced the same ICC point estimates as those calculated with other software. Analyzing data from <xref ref-type="bibr" rid="bibr6-1098214012466453">Lane, Nimon, and Roberts (2013</xref>), our ICC point estimate was .81, which was identical to that reported by Lane et al. Analyzing the reading scores from the 2002 Educational Longitudinal Study, we compared the ICC calculated by our macro with that using HLM software (<xref ref-type="bibr" rid="bibr4-1098214012466453">Bryk, Raudenbush, &amp; Congdon, 2004</xref>); our results were congruent with the HLM software results (ICC = .23). Second, to verify that our standard error calculation was correct, we compared our ICC standard error estimates to those reported in <xref ref-type="bibr" rid="bibr5-1098214012466453">Jacob, Zhu, and Bloom (2010</xref>, Table 8) after imputing their ICC point estimates and sample size parameters into our macro. For example, Jacob et al. reported an ICC of .083, based on 48.1 students per school and 225 schools, with a standard error of .009—identical to that produced by our macro output. (Our confidence intervals were identical to those reported in their table when we used the traditional 1.96 multiplier. Our macro uses the <italic>t</italic> distribution in calculating the ICC confidence limits, allowing for more accurate confidence interval estimates with small numbers of schools.) Third, we compared our MDES calculations with those produced by Optimal Design software (<xref ref-type="bibr" rid="bibr8-1098214012466453">Spybrook, Bloom, Congdon, Martinez, &amp; Raudenbush, 2011</xref>) and found results identical to the second decimal place. Our macro estimated an MDES of 0.285 (with an ICC of .105, a covariate of .35, and 30 students in a sample of 40 schools) compared with Optimal Design’s MDES of 0.287, given the same parameters.</p>
</sec>
<sec id="section2-1098214012466453">
<title>A SAS Macro for Producing Benchmarks for Interpreting School Effect Sizes</title>
<p>Evaluators need benchmarks for judging the reasonableness of achieving estimated MDESs. In some instances, these are available from previous analyses (e.g., <xref ref-type="bibr" rid="bibr9-1098214012466453">Xu &amp; Nichols, 2010</xref>). Benchmarks are most likely to be accurate when they are based on local data, however. As <xref ref-type="bibr" rid="bibr3-1098214012466453">Bloom, Hill, Black, and Lipsey (2008</xref>) stated, “Too little is known about the extent of local variability … to be sure that any basis other than the relevant local data provides appropriate benchmarks for the effect sizes associated with a given intervention” (p. 319).</p>
<p>Our second macro (Lawton, 2012) provides a method for producing a version of a benchmark for interpreting effect sizes, as described in <xref ref-type="table" rid="table1-1098214012466453">Table 1</xref>. It is designed for studies comparing school-level programs and produces distributions of differences among schools’ typical achievement levels. The macro calculates the difference between school means (in standard deviation units) among all possible pairs of schools within a grade, where the number of pairs = <italic>N</italic>(<italic>N</italic> − 1)/2 and <italic>N</italic> = the total number of schools. This results in a distribution of between-school differences, expressed in effect size units (i.e., the difference between means shown in standard deviation units) for a specified subject. When categorized by quartile, the distributions provide an empirical basis for judging effect sizes that are calculated in power analyses. They also are useful as benchmarks for effect sizes that are achieved in completed studies.</p>
<p>We provide an example of the results of using the macro in <xref ref-type="table" rid="table3-1098214012466453">Table 3</xref>. The table presents statistics for the distribution of between-school differences in mean student scores on the Hawaii state-wide reading assessment for each of eight years. For example, the between-school difference in mean scores at the 50th percentile of the distribution in 2009 is shown in <xref ref-type="table" rid="table2-1098214012466453">Table 2</xref> as .39. This can be interpreted as an effect size. An evaluator seeking to interpret the feasibility of an MDES calculated in a power analysis—or seeking to interpret an actual effect size that is achieved when a school-randomized study is conducted—might find this result useful if the expectation is that the intervention being studied should match the average of the differences between school scores.</p>
<table-wrap id="table3-1098214012466453" position="float">
<label>Table 3.</label>
<caption>
<p>Benchmarks for Interpreting Effect Sizes Based on Grade 3 Hawaii State Assessment Reading Total Scores, by Year.</p>
</caption>
<graphic alternate-form-of="table3-1098214012466453" xlink:href="10.1177_1098214012466453-table3.tif"/>
<table>
<thead>
<tr>
<th>Year</th>
<th>25th percentile</th>
<th>50th percentile</th>
<th>75th percentile</th>
</tr>
</thead>
<tbody>
<tr>
<td>2002</td>
<td>.19</td>
<td>.39</td>
<td>.67</td>
</tr>
<tr>
<td>2003</td>
<td>.18</td>
<td>.37</td>
<td>.64</td>
</tr>
<tr>
<td>2004</td>
<td>.16</td>
<td>.36</td>
<td>.62</td>
</tr>
<tr>
<td>2005</td>
<td>.18</td>
<td>.39</td>
<td>.67</td>
</tr>
<tr>
<td>2006</td>
<td>.17</td>
<td>.37</td>
<td>.62</td>
</tr>
<tr>
<td>2007</td>
<td>.14</td>
<td>.31</td>
<td>.55</td>
</tr>
<tr>
<td>2008</td>
<td>.16</td>
<td>.35</td>
<td>.62</td>
</tr>
<tr>
<td>2009</td>
<td>.17</td>
<td>.37</td>
<td>.64</td>
</tr>
<tr>
<td>Mean</td>
<td>.17</td>
<td>.36</td>
<td>.63</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The effect sizes produced in analyses using our second macro are not as useful as the effect sizes calculated for actual interventions, such as those summarized by <xref ref-type="bibr" rid="bibr7-1098214012466453">Lipsey and Wilson (1993</xref>), among others. The macro simply produces results reflecting existing differences on common subjects such as reading and mathematics. However, in the absence of other benchmarks, the macro might help evaluators interpret the MDESs that they calculate in their statistical power analyses when planning group-randomized experiments as well as help evaluators interpret the achieved effect sizes at the conclusions of studies.</p>
<p>Unlike our presentation of our first macro, which we validated using actual results, we offer the macro code itself (Lawton, 2012) as evidence for the accuracy of the macro. It is easily interpretable and can be verified upon a simple examination.</p>
</sec>
<sec id="section3-1098214012466453">
<title>Conclusion</title>
<p>Our purpose in this method note is to provide evaluators with convenient methods for estimating ICC estimates and for calculating benchmarks for interpreting estimated or actual effect sizes. While recognizing that the software for calculating ICCs is widely available (e.g., <xref ref-type="bibr" rid="bibr8-1098214012466453">Spybrook et al., 2011</xref>), we believe that evaluators will find our first macro helpful. It is designed to easily estimate ICCs for multiple school subjects, and grades, using student-level data of the evaluators’ choice, in a single computer run; in particular, it is useful for producing ICC confidence intervals, which are essential for planning studies conservatively. We also recognize that MDES benchmarks are available and simply provide our second macro as an alternative means for producing another type of benchmark that has the advantage of being locally based. Macros of the type that we present here take time and effort to develop (particularly our first macro); we hope that our efforts will help evaluators make use of data from their local contexts when conducting group-randomized studies.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict" id="fn1-1098214012466453"><label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn2-1098214012466453"><label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr3-1098214012466453">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bloom</surname>
<given-names>H. S.</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>C. J.</given-names>
</name>
<name>
<surname>Black</surname>
<given-names>A. R.</given-names>
</name>
<name>
<surname>Lipsey</surname>
<given-names>M. W.</given-names>
</name>
</person-group> (<year>2008</year>). <article-title>Performance trajectories and performance gaps as achievement effect-size benchmarks for educational interventions</article-title>. <source>Journal of Research on Educational Effectiveness</source>, <volume>1</volume>, <fpage>289</fpage>–<lpage>328</lpage>.</citation>
</ref>
<ref id="bibr4-1098214012466453">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bryk</surname>
<given-names>A. S.</given-names>
</name>
<name>
<surname>Raudenbush</surname>
<given-names>S. W.</given-names>
</name>
<name>
<surname>Congdon</surname>
<given-names>R.</given-names>
</name>
</person-group> (<year>2004</year>). <article-title>HLM 6 for Windows [Computer software]</article-title>. <publisher-loc>Skokie, IL</publisher-loc>: <publisher-name>Scientific Software International</publisher-name>.</citation>
</ref>
<ref id="bibr4a-1098214012466453">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Harrison</surname><given-names>G. M.</given-names></name></person-group>
 (<year>2012</year>). <article-title>A SAS macro for estimating education-study statistical power parameters [Computer software code]</article-title>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://goo.gl/moLFl">http://goo.gl/moLFl</ext-link></citation>
</ref>
<ref id="bibr5-1098214012466453">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jacob</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Zhu</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Bloom</surname>
<given-names>H.</given-names>
</name>
</person-group> (<year>2010</year>). <article-title>New empirical evidence for the design of group randomized trials in education</article-title>. <source>Journal of Research on Educational Effectiveness</source>, <volume>3</volume>, <fpage>157</fpage>–<lpage>198</lpage>.</citation>
</ref>
<ref id="bibr6-1098214012466453">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lane</surname>
<given-names>F. C.</given-names>
</name>
<name>
<surname>Nimon</surname>
<given-names>K. F.</given-names>
</name>
<name>
<surname>Roberts</surname>
<given-names>J. K.</given-names>
</name>
</person-group> (<year>2013</year>). <article-title>A random intercepts model of part-time employment and standardized testing using SPSS</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Garson</surname>
<given-names>G. D.</given-names>
</name>
</person-group> (Ed.), <source>Hierarchical linear modeling: Guide and applications</source> (pp. <fpage>149</fpage>–<lpage>165</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr6a-1098214012466453">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Lawton</surname>
<given-names>B. E.</given-names></name></person-group>
 (<year>2012</year>). <article-title>A SAS macro for producing benchmarks for interpreting school effect sizes [Computer software code]</article-title>. <comment>Retrieved from</comment> <ext-link ext-link-type="uri" xlink:href="http://goo.gl/Op3q4">http://goo.gl/Op3q4</ext-link></citation>
</ref>
<ref id="bibr7-1098214012466453">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lipsey</surname>
<given-names>M. W.</given-names>
</name>
<name>
<surname>Wilson</surname>
<given-names>D. B.</given-names>
</name>
</person-group> (<year>1993</year>). <article-title>The efficacy of psychological, educational, and behavioral treatment: Confirmation from meta-analysis</article-title>. <source>The American Psychologist</source>, <volume>48</volume>, <fpage>1181</fpage>–<lpage>1209</lpage>.</citation>
</ref>
<ref id="bibr8-1098214012466453">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Spybrook</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Bloom</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Congdon</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Martinez</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Raudenbush</surname>
<given-names>S. W.</given-names>
</name>
</person-group> (<year>2011</year>). <source>Optimal design plus empirical evidence: Documentation for the “optimal design” software</source>. <publisher-loc>Ann Arbor, MI</publisher-loc>: <publisher-name>University of Michigan</publisher-name>.</citation>
</ref>
<ref id="bibr9-1098214012466453">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Xu</surname>
<given-names>Z.</given-names>
</name>
<name>
<surname>Nichols</surname>
<given-names>A.</given-names>
</name>
</person-group> (<year>2010</year>). <source>New estimates of design parameters for clustered randomization studies: Findings from North Carolina and Florida</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>The Urban Institute, National Center for Analysis of Longitudinal Data in Education Research</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>