<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JPE</journal-id>
<journal-id journal-id-type="hwp">spjpe</journal-id>
<journal-title>Journal of Planning Education and Research</journal-title>
<issn pub-type="ppub">0739-456X</issn>
<issn pub-type="epub">1552-6577</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0739456X12447976</article-id>
<article-id pub-id-type="publisher-id">10.1177_0739456X12447976</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Studio Pedagogy Symposium</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Commentary</article-title>
<subtitle>Writing Papers on Pedagogy</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Brooks</surname><given-names>Michael</given-names></name>
<xref ref-type="aff" rid="aff1-0739456X12447976">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wu</surname><given-names>Weiping</given-names></name>
<xref ref-type="aff" rid="aff2-0739456X12447976">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0739456X12447976"><label>1</label>Virginia Commonwealth University, Richmond, VA, USA</aff>
<aff id="aff2-0739456X12447976"><label>2</label>Tufts University, Medford, MA, USA</aff>
<author-notes>
<corresp id="corresp1-0739456X12447976">Michael Brooks, Virginia Commonwealth University, Richmond, VA, USA Email: <email>mpbrks@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>12</month>
<year>2012</year>
</pub-date>
<volume>32</volume>
<issue>4</issue>
<fpage>491</fpage>
<lpage>492</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Association of Collegiate Schools of Planning</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<p>The fact that a paper deals with pedagogy is not an excuse for ignoring analytical rigor. Indeed, papers on planning pedagogy, submitted for possible publication in the <italic>Journal of Planning Education and Research</italic> (<italic>JPER</italic>), should manifest the same high standards of scholarship that are expected of all papers.</p>
<p>Too many of the pedagogy papers we received while serving as <italic>JPER</italic> editors (2008-2012) did little more than describe “how we do it at our school,” usually accompanied by some claims regarding the efficacy of that approach—claims most often unsupported by any genuine evidence. Such papers can be moderately interesting to those teaching similar courses at other institutions, but they are rarely very persuasive regarding the value of a certain approach and relative merits of alternative approaches.</p>
<p>There are three broad types of pedagogy articles <italic>JPER</italic> has published in the past. The first involves new or innovative conceptualization of issues related to planning education (e.g., faculty and student diversity, planning schools assessment, student recruitment and advising). The second provides assessments of the state of planning instruction and curricula regarding specific topics (e.g., teaching of environmental planning, addressing global megatrends). Such assessments often rely on survey research and quantitative methods, but robust qualitative analysis also can yield fresh insights. The third type offers accounts of specific courses or teaching innovations. Recently, such innovations have included the use of new technology (e.g., multimedia, simulation, and virtual space) and new learning practices (e.g., work-based or experiential learning, distance learning, and international education and exchange).</p>
<p>Specific papers do not always fall neatly into one of the three categories, of course, nor is it necessary that they do so. But authors must manifest the same degree of thoughtfulness and rigor that is expected in other kinds of research-based articles. To write an effective pedagogy article, authors need to design and conduct an investigation that is based on teaching practices. To situate the paper in the relevant context, authors may need to go beyond planning literature; learning theories, for example, might be relevant in some instances.</p>
<p>We cannot emphasize too strongly the importance of obtaining and analyzing evidence of student learning outcomes, particularly for papers that fall into the third category above. To generate such evidence, one must first address the following questions: (1) What is a particular course attempting to accomplish—that is, what are the objectives in terms of the knowledge and/or skills that it is attempting to impart to its students? (2) What elements of this course distinguish it from other courses, taught elsewhere, that deal with the same (or similar) subject matter? (3) What must be done to assess the extent to which the course accomplished its objectives, and to relate this degree of accomplishment to the distinguishing elements of the course?</p>
<p>Attempting to impart a measure of “data analysis” to their papers, authors frequently present data from student course evaluations, or from other surveys in which participants are asked to comment on various aspects of the course. The evidentiary value of this approach is minimal at best; course evaluation data are highly subjective, subject to a number of extraneous forces, and are not what is meant by “concrete evidence of learning outcomes.” Awards, compliments from community clients, and other external forms of recognition, while nice to receive, are also not very helpful in this regard. What, then, should be done instead?</p>
<p>Best (but rarely done) would be a process whereby alternative approaches are evaluated comparatively on the basis of pre- and post-course measurements of the knowledge and/or skills that they impart (i.e., a quasi-experimental research design). This would require one to identify other courses—studios in other planning programs, for example—and collaborate with their instructors in designing a structured comparison of program outcomes. This would involve the development of instruments for measuring the knowledge and/or skill levels of students prior to taking the courses, then employing the same instruments at the courses’ conclusions. This approach sets the bar very high. It would require advance planning and interuniversity collaboration of a sort that few of us in academia are generally able to muster where our teaching is concerned!</p>
<p>The fallback position, then, is to forego the comparative dimension and simply do this kind of thing for a single course. A respectable pedagogy paper might well feature, for example, (1) the identification of a clear set of objectives for a particular course, (2) the operationalization of some or all of the learning objectives into measurable elements (e.g., what constitutes an understanding of planning process), (3) the development of an instrument that assesses the extent to which those objectives and elements are or are not accomplished, and (4) the administration of that instrument at both the beginning and the end of the course. A procedure of this sort would enable the reader to assess the course’s “learning outcomes.” It wouldn’t necessarily allow for claims of superiority over other methods of teaching such courses, but it would certainly yield some evidence regarding what was accomplished by teaching the course in a particular way. (If research of this kind were to become sufficiently robust over time, moreover, comparative data might indeed begin to emerge.) In the absence of such evidence, the reader is presented with little more than a description. “Well, that’s interesting, but why should I consider teaching my course that way, rather than the way I do at present?”</p>
<p>A colleague from many years ago, Carl Patton, once expressed to one of us his distaste for what he described as the “we fry ours in chicken fat” genre of papers in the planning field. He wanted less description, more scholarly analysis. Much of today’s pedagogical writing is mired in that same genre, and we need to move beyond it. Part of the problem, of course, is that we frequently decide to write a paper about a particular course only after the course has been taught; having concluded that it went well, we decide that we should “write it up.” This is usually too late. Only rarely do instructors take the extra step of developing learning objectives, along with appropriate measurement instruments, in advance. We must do so more often if we want our discipline to feature a high-quality body of literature on pedagogical research. Given sufficient care and forethought, there is no reason why we can’t do so.</p>
</body>
<back>
<bio>
<title>Bios</title>
<p><bold>Michael Brooks</bold>, an editor of <italic>JPER</italic> in 2008-2012, is a professor emeritus of urban and regional planning at Virginia Commonwealth University. His research focuses on the processes and politics of urban planning, social planning, and planning education.</p>
<p><bold>Weiping Wu</bold>, an editor of <italic>JPER</italic> in 2008-2012, is a professor of urban and environmental policy and planning at Tufts University. Her research focuses on urban economic policy, comparative urban development, and China’s urban development.</p>
</bio>
</back>
</article>