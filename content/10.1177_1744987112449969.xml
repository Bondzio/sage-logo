<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="editorial">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JRN</journal-id>
<journal-id journal-id-type="hwp">spjrn</journal-id>
<journal-title>Journal of Research in Nursing</journal-title>
<issn pub-type="ppub">1744-9871</issn>
<issn pub-type="epub">1744-988X</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1744987112449969</article-id>
<article-id pub-id-type="publisher-id">10.1177_1744987112449969</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The challenges of developing and evaluating complex care scenarios using simulation in nursing education</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Gobbi</surname><given-names>Mary</given-names></name>
<xref ref-type="corresp" rid="corresp1-1744987112449969"/>
</contrib>
<aff id="aff1-1744987112449969">Senior Lecturer in Nursing, Faculty of Health Sciences, University of Southampton, UK</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Monger</surname><given-names>Eloise</given-names></name>
</contrib>
<aff id="aff2-1744987112449969">Faculty of Health Sciences, University of Southampton, UK</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Weal</surname><given-names>Mark J.</given-names></name>
</contrib>
<aff id="aff3-1744987112449969">Faculty of Electronics and Computer Science, University of Southampton, UK</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>McDonald</surname><given-names>John W.</given-names></name>
</contrib>
<aff id="aff4-1744987112449969">Centre for Longitudinal Studies, Institute of Education, University of London, UK</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Michaelides</surname><given-names>Danius</given-names></name>
</contrib>
<aff id="aff5-1744987112449969">Faculty of Electronics and Computer Science, University of Southampton, UK</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>De Roure</surname><given-names>David</given-names></name>
</contrib>
<aff id="aff6-1744987112449969">Faculty of Electronics and Computer Science, University of Southampton, UK</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1744987112449969">Mary Gobbi, Senior Lecturer in Nursing, Nightingale Building 67, Faculty of Health Sciences, University of Southampton, Highfield, Southampton SO17 1BJ, UK Email: <email>mog1@soton.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2012</year>
</pub-date>
<volume>17</volume>
<issue>4</issue>
<fpage>329</fpage>
<lpage>345</lpage>
<permissions>
<copyright-statement>© The Author(s) 2011 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Demonstrating the impact and effectiveness of educational interventions, including medium and high-fidelity simulation, has long been fraught with methodological challenges and ambiguities. This is particularly the case when there are several confounding factors and variables operating in situations where control trials are inappropriate, and investigative costs can be high. Current theoretical and empirical evidence, while emerging, is parsimonious and fails to take account of the characteristics of different modes of simulation, their contested theoretical models of learning and the opportunities presented by cutting edge computer science. Medium and high-fidelity simulations, situated within technology-rich environments, generate new forms of complex data that have the potential to provide insights into ‘real-world’ practices. Drawing on a range of locally based studies, we argue that until the methodological questions and data management systems can be addressed, the evidence to determine the judicious and optimal use of simulation to improve student and practitioner performance and patient outcomes will remain primarily reliant on proxy measures of self-efficacy and competence.</p>
</abstract>
<kwd-group>
<kwd>mixed methodologies</kwd>
<kwd>new technologies</kwd>
<kwd>mixed methods</kwd>
<kwd>research impact</kwd>
<kwd>simulation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="sec1-1744987112449969" sec-type="intro"><title>Introduction</title>
<p>Simulation as a teaching strategy in professional health care, including nursing education, has rapidly developed during the last decade. This has occurred for several reasons. First, there has been a shortage in the number and availability of clinical experiences and resources required by different professional groups, compounded by a necessity for students and practitioners to safely achieve required competences for registration or role requirements (<xref ref-type="bibr" rid="bibr11-1744987112449969">Gobbi et al., 2004</xref>; <xref ref-type="bibr" rid="bibr25-1744987112449969">Ricketts, 2011</xref>). Second, the acuity and complexity of some clinical environments means that it is not appropriate, nor ethical, to enable inexperienced staff to rehearse their skills on vulnerable clients in high risk situations. Within medical education similar problems have arisen, augmented in the European context by the reduction in working hours due to the <xref ref-type="bibr" rid="bibr7-1744987112449969">European Working Time Directives (1998)</xref>. Third, the rapid expansion of virtual and other related interactive technologies have generated learning resources and tools that can simulate professional practises and thereby provide educators with new strategies for learning. Establishing cost effective strategies to enhance student learning and competence without disadvantaging services users is a significant driver in contemporary health care education. More recently in the United Kingdom (UK), the Chief Government Medical Officer argued that simulation was vital to building a safer health care system and recommended increased adoption by the health service (<xref ref-type="bibr" rid="bibr5-1744987112449969">Donaldson, 2009</xref>). This was accompanied by a rapid investment in medium and high fidelity simulators for medical education. Recent North American studies (<xref ref-type="bibr" rid="bibr10-1744987112449969">Garret et al., 2007</xref>; <xref ref-type="bibr" rid="bibr21-1744987112449969">National Council of State Boards of Nursing, 2009</xref>), the United Kingdom <xref ref-type="bibr" rid="bibr22-1744987112449969">Nursing and Midwifery Council (NMC) study (NMC, 2007)</xref> and research or systematic reviews (<xref ref-type="bibr" rid="bibr2-1744987112449969">Cant and Cooper, 2009</xref>; <xref ref-type="bibr" rid="bibr25-1744987112449969">Ricketts, 2011</xref>; <xref ref-type="bibr" rid="bibr26-1744987112449969">Sanford, 2010</xref>) have concluded that medium to high-fidelity simulations using mannequins are at least comparable to other teaching modalities and have a role to play in the clinical education and development of nursing skills (including procedural, teamwork and clinical/cognitive decision-making skills). However, as <xref ref-type="bibr" rid="bibr26-1744987112449969">Sanford (2010</xref>: 1010) argues, there is a lack of ‘supporting theory and evidence based research’, although signs of theory development are emerging (<xref ref-type="bibr" rid="bibr1-1744987112449969">Berragan, 2011</xref>). There is general agreement that quantitative measures are still lacking concerning the efficacy of simulation with respect to patient outcomes, error reduction, team interactions and the cost effectiveness of the human and technical resources. Furthermore, the reliance on proxy measures of student competence via self-reports of confidence, efficacy and competence has been criticised (<xref ref-type="bibr" rid="bibr2-1744987112449969">Cant and Cooper, 2009</xref>).</p>
<p>This paper draws on literature and locally based studies conducted over a seven-year period (2003–2010) to address the challenges associated with the expansion of simulation education in a technologically rich environment.</p>
<p>The initial aim of the project was to develop and evaluate the necessary infrastructures to conduct, research and analyse the extent to which Virtual Interactive Practice (VIP<bold>®</bold>) and similar activities were as effective as other educational modes in accelerating the achievement of clinical/professional competence. VIP® is<disp-quote>
<p>… a designated period of assigned practice where technological, computer and/or simulator based scenarios are integrated to provide coherent experiences with which students can interact. The scenarios are constructed with real patient data; the student interactions and the feedback mechanisms are designed to mimic real practice contexts and responses; and where possible, are situated in specially constructed locations resembling clinical environments. <xref ref-type="bibr" rid="bibr11-1744987112449969">Gobbi et al. (2004)</xref></p></disp-quote></p>
<p>While simulation itself was then unproven as a reliable and cost effective way to enhance student learning and competence, the VIP® developmental strategy needed to ascertain and evaluate:
<list list-type="order">
<list-item><p>The skills and resources teachers and technologists require to design, deliver and evaluate these pedagogies.</p></list-item>
<list-item><p>The experience of the students and teachers.</p></list-item>
<list-item><p>Whether the VIP pedagogy influenced student learning, development of, confidence and competence.</p></list-item>
</list></p>
<p>The ultimate goals were to discern whether, how, and when, to use successfully these pedagogies and to improve our knowledge concerning student/practitioner learning, development and achievement. However, it was soon apparent that the technologies involved in conducting video captured simulations with associated web based learning opportunities offered new ways of analyzing student behaviours. It was necessary to establish how the new technologies themselves could be best exploited, mindful that the capital and/or recurrent costs of the simulators could be significant, and that simulation activities can be very labour intensive.</p>
<p>The paper focuses on the strategies used to design and evaluate the VIP® initiatives including the tools designed to manage and analyse the large and complicated data sets. Most of the work reported here refers to medium fidelity scenario based simulations incorporating web based materials and SimMan®. This project comprised three stages. Stage 1 (2003–2004) involved in-depth evaluation and analysis of week-long simulation exercises for child branch students (15–20 students per annum). In stage 2 (2005–2007), medium fidelity simulation was embedded within the entire curriculum for both adult and child students (approximately 400 students per annum). The focus was scaling up activities without compromising educational quality and establishing a strategy for the handling of complex data sets. This included analytical tools and processes involving web logs, sequence analysis and video capture. Stage 3 (2007–2010) further developed the annotation tools and began to link these to the tracking of student and equipment movement in the clinical skills laboratories/mini wards.</p>
</sec>
<sec id="sec2-1744987112449969"><title>Context</title>
<p>Facing the challenges of student placement capacity, combined with the recognition that not all students could experience some important aspects of care during their registration programme, stimulated our interest and motivation to explore the effective and appropriate use of simulation within the curricula. The delivery of simulation was challenged by timetabling high numbers of student cohorts, yet facilitated by a committed group of nurse educators and investment of then ‘state of the art’ clinical simulation wards. These factors combined to generate a climate of innovation which provided the platform from which a desire to use simulation effectively and efficiently could be realised. Here we outline the journey to deliver, and then investigate, high quality student experiences, with positive learning outcomes using available technologies, underpinned by a robust evidence base.</p>
<p>The practical simulation activities were situated within two purposively designed mini wards of 6 beds with an accompanying nurses’ station with access to internet based computers. Each ward had six 360-degree span audio and visual cameras feeding into a common control room from which the student activities could be analysed and recorded. Students typically engaged in groups of 3 with 20-minute clinical scenarios, followed by a 20–30-minute debriefing and evaluation session. The scenarios and debriefing events could be video captured. Data from the computer mannequins and cameras can record how long it takes a student to recognise deterioration in a patient, call for an emergency team, or simply whether, and how, they wash their hands. However, there are no ‘natural clinical’ benchmarks from which to make comparisons of student performance. These benchmarks may eventually be derived from simulation activities themselves. The interactions and performances captured in real time, highly realistic simulated/virtual situations, provide rich data from which questions concerning complex situated decision making, reflection in/on action, performance modes, discourses and the many nuances of clinical interactions and practises can be analysed. Associated debriefing sessions and group interactions give insights into the way students, peers, practitioners and researchers explore and construct the meaning and intention in their practices. With many simulation suites having access to these forms of data, nurse educators and researchers can begin to investigate more aspects of student/practitioner performance and learning. The challenge is to target those key elements of a scenario amenable to analysis and from which meaningful findings can be elicited.</p>
</sec>
<sec id="sec3-1744987112449969"><title>Background and literature</title>
<p>Simulation as an educational tool to aid learning and development in nursing education is well established, with simulation practices originating in ‘practical rooms’ where skills are rehearsed using inert mannequins, medical equipment and fellow students acting as ‘patients’. Simulation can be understood as the ‘controlled representation of a piece of reality that learners can manipulate to better understand the corresponding real situation’ (<xref ref-type="bibr" rid="bibr3-1744987112449969">DeYoung, 2003</xref>: 144). <xref ref-type="bibr" rid="bibr8-1744987112449969">Gaba (2004: i2)</xref> argues that simulation is a ‘technique—not a technology—to replace or amplify real experiences with guided experiences that evoke or replicate substantial aspects of the real world in a fully interactive manner’. The extent to which simulation activities represent or engender reality is termed their degree of fidelity.</p>
<p>Traditionally, health care simulation focused upon low-fidelity procedural tasks or discrete events, such as taking blood pressures, performing basic resuscitation techniques, administering an injection or rehearsing communication skills through role play, often as a prelude to, or following, clinical experience (<xref ref-type="bibr" rid="bibr12-1744987112449969">Hovanscek, 2007</xref>). The detail and duration of simulated experiences are often limited in the literature. Aside from <xref ref-type="bibr" rid="bibr31-1744987112449969">Watkinson et al. (2004)</xref> and <xref ref-type="bibr" rid="bibr11-1744987112449969">Gobbi et al. (2004)</xref>, who pioneered ward-based simulation work over 4–5 days, most simulations are short (1–3 hours) and focus on predetermined procedures with explicit criteria and behaviour sequences. Given the appropriate conditions and context, simulations can generate an interactive and responsive environment, which can motivate, engage and inspire learners (<xref ref-type="bibr" rid="bibr10-1744987112449969">Garret et al., 2007</xref>). The majority of simulated activity, however, involves combinations of simulated ward environments, mannequins/equipment and/r simulated patients (actors) and the students’ interactions with a set scenario (<xref ref-type="bibr" rid="bibr16-1744987112449969">Kneebone et al., 2006</xref>).</p>
<p>The rapid expansion of simulator use and simulation practices has been driven internationally by several factors, mainly associated with advances in technologies and elearning (mobile, wireless and web based), patient safety concerns and the challenges presented by (a) reduced working hours for many clinicians, (b) an inability to guarantee essential training experiences that occur infrequently, (c) the necessity to provide safe rehearsal opportunities for trainees without compromising patient safety or experience and (d) the importance of fostering individual, team and decision-making competences. With patient safety initiatives high on the agenda, simulation is also used to promote positive learning to reduce, prevent and manage human error in high-risk environments. Training for these purposes includes attention to organisational context, technological systems, team structure, knowledge management and the design of working processes (<xref ref-type="bibr" rid="bibr28-1744987112449969">Sexton et al., 2000</xref>).</p>
<p><xref ref-type="fig" rid="fig1-1744987112449969">Figure 1</xref> demonstrates how simulation activities can accommodate, or foster, varying degrees of complexity, reality, student immersion in the process, ethical engagement, sensori-motor skills, cognition and decision-making skills. In our case we sought increasing degrees of complexity over the three year programme. Each simulation was designed to give high degrees of realism, immersion and to include ethical aspects and the full range of skills. Analysis of simulation activities is thus fraught by these inter-related variables to which the associated factors of simulator, simulation scenario and individual students should be added (see Nursing Education Simulation Framework (<xref ref-type="bibr" rid="bibr14-1744987112449969">Jeffries, 2007: Figure 3.1, p.23</xref>).<boxed-text id="boxed-text-1744987112449969" position="float">
<title>Key points</title>
<p>
<list id="list1-1744987112449969" list-type="simple">
<list-item><p>Collaboration with computer and social scientists provides opportunities for the development of analytical tools to handle meaningfully large educational data sets.</p></list-item>
<list-item><p>Different modalities of data representation can offer new insights into the behaviours of students.</p></list-item>
<list-item><p>More detailed understandings of student/staff experiences, achievements and behaviours may be facilitated by the use of sequence analysis, event histories, literal tracking of movements and video annotations.</p></list-item>
<list-item><p>Future developments in web-based technologies, tracking devices and semantic annotation offer exciting opportunities for the analysis of nursing activities and roles and the development of new ways of working. This will require nurse researchers and educators to learn the skills of co-design.</p></list-item>
</list></p></boxed-text>
<fig id="fig1-1744987112449969" position="float"><label>Figure 1.</label><caption><p>Factors influencing the student experience of simulation</p></caption><graphic xlink:href="10.1177_1744987112449969-fig1.tif"/>
</fig></p>
<p>Simulators are categorised according to their key function or capacity, namely part task trainers (such as intravenous arms), computer-enhanced mannequins (<italic>SimMan</italic>®, METI man®) and virtual reality (VR) simulators (radiotherapy practice). Students respond to the interaction of the simulator type and simulation activity, implying that educators should carefully choose their design for the desired outcome (<xref ref-type="bibr" rid="bibr29-1744987112449969">Smith and Roehrs, 2009</xref>). While it is generally recognised that simulators have a place in nurse education, their efficacy remains under researched (<xref ref-type="bibr" rid="bibr27-1744987112449969">Schiavenato, 2009</xref>; <xref ref-type="bibr" rid="bibr26-1744987112449969">Sanford, 2010</xref>) and the guidance for simulation design is embryonic (<xref ref-type="bibr" rid="bibr9-1744987112449969">Gaberson and Oermann, 2010</xref>). As the complexity of simulation activities increases, and is accompanied by advances in technology and web-based platforms, the potential to embed simulations within virtual and elearning activities like VIP® increases. The emergence of advanced forms of VR using headsets and sensory manipulation (e.g. using gloves: ‘haptics’) into radiotherapy education (<xref ref-type="bibr" rid="bibr19-1744987112449969">Philips et al., 2008</xref>), while costly, demonstrates how simulators have rapidly developed since the 1990s. However, total immersion virtual clinical practice in nursing remains rare if one excludes single-performance activities.</p>
<p>In the US context, where there are licence and accreditation requirements associated with the number of procedures a physician must perform, Kanter (2006) proposed that there were four benefits of simulation in medical education, improved educational experience, increased patient safety, cost efficiency and on-going training opportunities. Interestingly, he argues that cost efficiency is achieved because the investment cost in the simulator centre is less than the cost of instruction, its accompanying supplies/resources and the savings accrued from the ability of the trainee to perform more quickly and with few complications in real practice. While medical staff are familiar with the role of simulation in the certification of competence, this is now emerging within nursing. While Kanter noted a concern that an over reliance on simulation activities could lead staff to `forget the human component', this would depend on the design of the simulation scenario.</p>
<p>As technologies expand in healthcare, medical simulation in particular can be used to support their safe introduction. This is currently witnessed in the expansion of robotic surgery. From single operator tasks to complex multi-professional team engagements in patient care, simulation has been demonstrated to have a role in the development and maintenance of competence. Traditionally, assessment and feedback concerning student performance, before, during or after simulation is predominantly based on observational methods, whether tutor or peer led. It is possible to analyse events (<xref ref-type="bibr" rid="bibr4-1744987112449969">DiGiacomo et al., 1997</xref>) and processes (<xref ref-type="bibr" rid="bibr24-1744987112449969">Ram et al., 1999</xref>) and to conduct Objective Structured Video Examinations (<xref ref-type="bibr" rid="bibr13-1744987112449969">Humphris and Kaney, 2000</xref>; <xref ref-type="bibr" rid="bibr30-1744987112449969">Vivekananda-Schmidt et al., 2007</xref>). More recently, innovative work to track student movements (<xref ref-type="bibr" rid="bibr33-1744987112449969">Weal et al., 2007</xref>, <xref ref-type="bibr" rid="bibr34-1744987112449969">2009a</xref>) and analyse performance/behaviour sequences (<xref ref-type="bibr" rid="bibr18-1744987112449969">McDonald et al., 2008a</xref>, <xref ref-type="bibr" rid="bibr19-1744987112449969">2008b</xref>) has generated new forms of data requiring support from computer scientists and statisticians. These data have the potential to give rich portrayals of the way care is delivered, how participants interact with objects and each other within the clinical environment.</p>
<p>As clinical simulation scenarios improve in delivery, realism and complexity, it is crucial to (a) determine the pedagogic and quality implications for learning, teaching and assessment, (b) judge their impact and efficacy upon students’ acquisition of professional skills and (c) ascertain whether it has a positive and sustainable effect on their performance for patient safety and benefit in the ‘real clinical environment’. In fiscally restrained health and education budgets, this becomes more crucial. <xref ref-type="table" rid="table1-1744987112449969">Table 1</xref> summarises variables that influence the simulation process.
<table-wrap id="table1-1744987112449969" position="float"><label>Table 1.</label><caption><p>Variables at work in a simulation interaction</p></caption>
<graphic alternate-form-of="table1-1744987112449969" xlink:href="10.1177_1744987112449969-table1.tif"/>
<table frame="hsides"><thead align="left">
<tr><th>Student related</th>
<th>Facilitator related</th>
<th>Simulation design</th>
<th>Simulator/simulated patient and context</th></tr></thead>
<tbody align="left">
<tr>
<td align="justify">Prior experience of clinical scenario</td>
<td align="justify">Expertise in facilitation and/or scenario</td>
<td align="justify">Aims and purpose Pedagogic approach</td>
<td align="justify">Environmental context</td></tr>
<tr>
<td align="justify">Prior and current capability and competence</td>
<td align="justify">Expectation of student competence and ability to react to simulator</td>
<td align="justify">Complexity of activities</td>
<td align="justify">Technical expertise required to use the simulator and manage the scenario</td></tr>
<tr>
<td align="justify">Motivation to learn</td>
<td align="justify">Perceived enthusiasm</td>
<td/>
<td/></tr>
<tr>
<td align="justify">Willingness to ‘immerse’ in situation</td>
<td align="justify">Role is clarified to be naturalistic or interventional</td>
<td align="justify">Degree of realism and naturalism expected of scenario and actors in the scenario</td>
<td align="justify">Degree of fidelity, realism of equipment and actors Situational realism</td></tr>
<tr>
<td align="justify">Ascribed or enacted role in scenario – individual or team role</td>
<td align="justify">Perceives role as facilitator, coach or instructor</td>
<td align="justify">Extent to which student behaviours are controlled</td>
<td align="justify">Capacity to be responsive to unfolding events</td></tr>
<tr>
<td align="justify">Preferred learning style</td>
<td align="justify">Ability to adjust to requirements</td>
<td align="justify">Focus on cognition, behaviours, procedures and/or affect</td>
<td/></tr>
<tr>
<td align="justify">Academic and personal data</td>
<td/>
<td/>
<td/></tr>
<tr>
<td align="justify">Feedback and assessment</td>
<td align="justify">Model of feedback and assessment employed</td>
<td align="justify">Time for debriefing and post-activity learning</td>
<td align="justify">Degree of data available from simulator Availability of audio visual capture of simulation exercise</td></tr>
</tbody>
</table>
</table-wrap></p>
</sec>
<sec id="sec4-1744987112449969"><title>Challenges</title>
<sec id="sec5-1744987112449969"><title>Stage 1: scoping the terrain</title>
<p>As <xref ref-type="table" rid="table1-1744987112449969">Table 1</xref> illustrated, the evaluation needed to identify and determine the extent to which the factors influencing the student experience had an impact upon their learning and achievement. Here <xref ref-type="bibr" rid="bibr15-1744987112449969">Kirkpatrick and Kirkpatrick's (2006)</xref> four evaluative steps or `levels' were helpful, namely to (1) elicit the reaction of the students to the simulation and its related activities; (2) determine what they had learnt; (3) ascertain any changes in their behaviours or capabilities and finally, (4) establish any results of the interventions in terms of cost, quality, efficiency of both the training and its impact on the working practises. Level 4 remains problematic, in that while the personnel and simulation resources can be established to deliver simulation, studies on its efficacy upon durable performance in real practice remain embryonic and very difficult to conduct. Even with robust control trials, establishing direct causality and attribution in educational research is difficult due to the unique prior experiences, motivations and capabilities of each individual person. Furthermore, the ability to ‘control’ educational environments involving professional practice is itself questionable, particularly if the process is to be responsive to the students. What can be elicited, however, is the extent to which an individual learner’s performance (or values) has been changed by the intervention, whether by self-report, external review or measured against predetermined criteria (level 3 and level 4).</p>
<p>In 2003 and 2004 (17 and 19 students, respectively), week-long ward-based simulation activities for child branch students approaching registration were conducted (<xref ref-type="bibr" rid="bibr11-1744987112449969">Gobbi et al., 2004</xref>; <xref ref-type="bibr" rid="bibr31-1744987112449969">Watkinson et al., 2004</xref>, <xref ref-type="bibr" rid="bibr32-1744987112449969">2006</xref>). The multiplicity of factors that influenced student learning and achievement became evident quickly as we sought to judge the efficacy of the simulation activities and student engagement, satisfaction and professional development. For each aspect of the week, students indicated their prior experience, rated their competence, expressed their degree of satisfaction and offered qualitative comments. <xref ref-type="fig" rid="fig1-1744987112449969">Figure 1</xref> factors were included within the survey questions (e.g. realism, relevance to practice, degree of stress). In addition, the second cohort provided self-reports and retrospective evaluation six months following registration, enabling some measurement of the impact of simulation.</p>
<p>Qualitative data were relatively simple to analyse using thematic analysis. These data provided insights into the student experiences that enabled adjustment, direction and subsequent development of the simulation pedagogy, confirming the importance of scenario factors related to degree of realism, immersion and the achievement of a balance between sufficient stress and the avoidance of cognitive and emotional overload. This next comment encapsulates these points.<disp-quote>
<p>Thank you … I was so tired and stressed but by the end I felt a major sense of achievement. I’ve realised since starting my job that the intensity of the week is not unlike some weeks at work. It really did prepare me for this and I think the week is a valuable experience for any student nurse. (Student six months post registration)</p></disp-quote></p>
<p>Quantitative data were statistically analysed descriptively, predominantly using means or percentages for the five-point Likert scales. Mindful of the numbers and the necessity to drill down further into the student self-reports, we experimented with the data representation scheme known as ‘data mosaics’ (<xref ref-type="bibr" rid="bibr6-1744987112449969">Downs, 2000</xref>). Data mosaics are useful when there are particular constraints on the data, such as fixed length sequences or small samples (see <xref ref-type="table" rid="table2-1744987112449969">Table 2</xref>). Changes in the colour or density of shading represent ordinal data changes. For example, in the competence domain ‘Management and Decision Making’ three sub items were flexibility (A), managing difficult and complex situations (B) and dealing with complaints (C). Five was the maximum score representing being ‘fully competent’ using the then NMC definition of competence with which the students were familiar. As <xref ref-type="table" rid="table2-1744987112449969">Table 2</xref> shows, the different shading patterns enable visualisation of an individual student’s progress (horizontal row) across all their competences and skills. The cohort’s pattern is seen through the vertical columns. These data also provided benchmarks for subsequent analysis and contributed to an understanding of the impact of simulation upon individuals and cohorts.
<table-wrap id="table2-1744987112449969" position="float"><label>Table 2.</label><caption><p>Data mosaic. Student self-rating of competence (rating scale 1–5, with 5 as ‘fully competent’)</p></caption>
<graphic alternate-form-of="table2-1744987112449969" xlink:href="10.1177_1744987112449969-table2.tif"/>
<table frame="hsides"><thead align="left">
<tr><th colspan="10">Competence domain ‘Management and Decision Making’<hr/></th></tr>
<tr><th/>
<th colspan="3">Competence A<hr/></th>
<th colspan="3">Competence B<hr/></th>
<th colspan="3">Competence C<hr/></th></tr>
<tr><th>Student</th>
<th>Pre</th>
<th>Post</th>
<th/>
<th>Pre</th>
<th>Post</th>
<th/>
<th>Pre</th>
<th>Post</th>
<th/></tr></thead>
<tbody align="left">
<tr>
<td>A</td>
<td>4</td>
<td/>
<td/>
<td>3</td>
<td/>
<td/>
<td>3</td>
<td/>
<td/></tr>
<tr>
<td>B</td>
<td>3</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/></tr>
<tr>
<td>C</td>
<td>4</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/></tr>
<tr>
<td>D</td>
<td>4</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/>
<td>4</td>
<td>4</td>
<td/></tr>
<tr>
<td>E</td>
<td>4</td>
<td>3</td>
<td/>
<td>3</td>
<td>3</td>
<td/>
<td>3</td>
<td>3</td>
<td/></tr>
<tr>
<td>F</td>
<td>4</td>
<td>4</td>
<td/>
<td>4</td>
<td>5</td>
<td/>
<td>3</td>
<td>5</td>
<td/></tr>
<tr>
<td>H</td>
<td>3</td>
<td>4</td>
<td/>
<td>1</td>
<td>4</td>
<td/>
<td>2</td>
<td>4</td>
<td/></tr>
<tr>
<td>J</td>
<td>4</td>
<td>5</td>
<td/>
<td>3</td>
<td>5</td>
<td/>
<td>3</td>
<td>5</td>
<td/></tr>
<tr>
<td>K</td>
<td>3</td>
<td>3</td>
<td/>
<td>3</td>
<td>3</td>
<td/>
<td>2</td>
<td>3</td>
<td/></tr>
<tr>
<td>L</td>
<td>4</td>
<td>4</td>
<td/>
<td>3</td>
<td>5</td>
<td/>
<td>3</td>
<td>5</td>
<td/></tr>
<tr>
<td>M</td>
<td>3</td>
<td>3</td>
<td/>
<td>2</td>
<td>4</td>
<td/>
<td>2</td>
<td>4</td>
<td/></tr>
<tr>
<td>N</td>
<td>3</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/>
<td>3</td>
<td>4</td>
<td/></tr>
<tr>
<td>Change</td>
<td colspan="3">Pre–Post</td>
<td colspan="3">Pre–Post</td>
<td colspan="3">Pre–Post</td></tr>
<tr>
<td>Positive</td>
<td colspan="3">4</td>
<td colspan="3">9</td>
<td colspan="3">9</td></tr>
<tr>
<td>None</td>
<td colspan="3">6</td>
<td colspan="3">2</td>
<td colspan="3">2</td></tr>
<tr>
<td>Negative</td>
<td colspan="3">1</td>
<td colspan="3">0</td>
<td colspan="3">0</td></tr>
</tbody>
</table>
</table-wrap></p>
<p>From <xref ref-type="table" rid="table2-1744987112449969">Table 2</xref>, one can count the number or percentage of students who reported a change in their competence rating: whether positive (+), negative (–) or no change (0). This gives tutors feedback on the impact of a given scenario on the students as a group. Hence for competence A, the majority experienced no change in their competence. This contrasts with competences B and C, where nine students reported an improvement in their competence by the end of the week. In competence A, a lone student (E) reported deterioration in their performance. Interestingly, however, this student subsequently returned the post six-month survey with a score of 4. This illustrates one dilemma of self-reporting, namely the individual’s capacity to re-appraise their performance and alter their perception of what constitutes being ‘fully competent’, for example. It could be hypothesised that the experience of simulation for some students may challenge their perception of their competence and thus provoke re-appraisal. There is some evidence to support this from the NMC (2007) general survey questions when 75% of the first-year and 88% of the second-year students reported that the simulation exercises had ‘led me to think carefully about my personal competence in these practical skills’. First-year students had engaged in low fidelity simulation, while second-year students experienced medium fidelity simulations.</p>
<p>Another way of representing these data is graphically. <xref ref-type="fig" rid="fig2-1744987112449969">Figure 2</xref> shows student self-ratings with respect to the students’ skill in handling anaphylaxis through a medium fidelity scenario augmented by wen-based learning. Here, there are three points of reporting, pre simulation (pre), post simulation week (post) and six months after qualification (end). In this skill, students made most change following simulation; however, there was a noticeable decline in skill following registration. Without accompanying qualitative data, explanations for these apparent elements of ‘decay’ in competence are purely speculative. Nonetheless, they raise questions concerning which activities are best suited to simulations in professional contexts, and the role of student exposure to a challenging clinical event that many students had not previously encountered.
<fig id="fig2-1744987112449969" position="float"><label>Figure 2.</label><caption><p>Graphic representation ‘dealing with anaphylaxis’ Pre-post: competence ranking at the beginning and end of the week. Post-end: competence ranking from the end of the week to six months later</p></caption><graphic xlink:href="10.1177_1744987112449969-fig2.tif"/>
</fig></p>
<p>Having improved the simulation design and processes following the 2003 and 2004 studies, the challenge of scaling this to the full student body, with cohorts in the hundreds, became the next problem. In an attempt to generate benchmark data for subsequent comparison, students had consented to a total data set that included surveys, (open and closed responses), group interviews and debriefs, observational field notes, audio visual data, computer mannequin logs, sequences of student activities (performance and computer interactions), event histories of web-based products and student record data related to their academic biography and course achievements. We realised that some of the data sets, whether as single items or in combination with others, had generated data beyond our ability to manage. For example, a single student in one simulation could generate 2–3 hours of video, a related mannequin log of interaction and associated elearning and web-based engagement. By 2006/2007, simulation had been embedded within the curriculum for all three years of the registration nursing programmes, with the adult branch comprising over 300 students per year.</p>
<p>External funding from the Economic and Social Research Council (ESRC) and the Higher Education Academy (HEA) coincided with our engagement as a pilot site for the NMC Simulation in Practice Project (2007). New trials were extended to the first-year and second-year students to address the large volumes of complex data and the necessity to exploit the video-captured data. Using the NMC project as a platform, the evaluative techniques concerning the pragmatics of simulation were refined and applied to the entire cohorts. The interdisciplinary collaboration with computer and social scientists through the ESRC and HEA projects led to ‘proof of concept’ trial work to develop techniques that could handle the data capture and analysis of multiple simultaneous video and audio sources, video focus groups, data streams from pervasive devices (e.g. the instrumented simulated patients), control event streams, scenario storyboards and multiple layers of annotation.</p>
</sec>
<sec id="sec6-1744987112449969"><title>Stage 2: scaling up and finding the limits of data management</title>
<p><xref ref-type="fig" rid="fig3-1744987112449969">Figure 3</xref> shows how a standard simulation scenario involving a computerised mannequin, a predetermined responsive scenario, one or more students, a supervisor/actor, various artefacts and equipment; and audio visual captured data – all gathered from more than one camera – generates large volumes of complex data.
<fig id="fig3-1744987112449969" position="float"><label>Figure 3.</label><caption><p>Screen shot – simulation in action</p></caption><graphic xlink:href="10.1177_1744987112449969-fig3.tif"/>
</fig></p>
<p>This snapshot is one part of a sequence within a given simulation episode, which is itself a component of related curricula activity. Each participant follows their own sequence of activities within the simulation episode, sometimes, as in <xref ref-type="fig" rid="fig3-1744987112449969">Figure 3</xref>, overlapping in time with other participants. Before and after each simulation, each person will have their own sequences of planned and incidental learning activities. Where the data mosaics helped analyse sequences/change for small numbers, more advanced statistical and computer techniques were required to handle the large numbers. Rather like the way an observation chart in clinical practice tracks the parameters of a patient, event history charts can be used to track and plot timed events at the individual level (see <xref ref-type="bibr" rid="bibr18-1744987112449969">McDonald et al., 2008a</xref>, <xref ref-type="bibr" rid="bibr19-1744987112449969">2008b</xref>). Each individual is represented by a single horizontal line and corresponding events are denoted by various symbols placed along the time line. The size of the symbol can then be proportionally enlarged according to the number of times the event occurred within a given time span. While this technique requires sophisticated mathematical and computational analysis, the results can be illuminating. For example, when we used this technique to analyse student interactions with different web pages on the skills elearning platform, we discovered that some pages were rarely accessed; raising questions about the usefulness of the material (see Weal et al.). Work has yet to be undertaken to apply these techniques to the detailed analysis of the computer mannequin data, which is linked to concurrent student performance captured on video. However, the potential to analyse performance sequences in simulation relies upon the ability to annotate the video-captured materials in resource-efficient ways.</p>
<p>Video annotation, the ability to mark and classify an activity in time on a video so that is can be retrieved, replayed and the data extracted, is crucial to the ability to handle hundreds of videos, and more pragmatically to be able to track student performance over time and different students within a scenario. Similarly, if video-captured clinical assessments are to be conducted in a reliable and valid manner, then mechanisms to search the videos for particular events would reduce the workload of examiners, provide accurate insights into student performance, and assist with issues concerning inter-rater reliability. This is work at the cutting edge of science. <xref ref-type="fig" rid="fig3-1744987112449969">Figure 3</xref> illustrates the difficulties in selecting what annotations or markers might be relevant for feedback to students on their performance, whether related to their general performance or specifically to the nature of the scenario. The first step was to identify elements for analysis and marking, then form these into overarching categories (or vice versa) within a taxonomy, for example annotations concerned with communication, infection control, assessing the patient and so on. Hence, the first action in systematic video annotation is to develop classification systems (or ontologies) that enable objective representations to be made. The co-design development of such ontology is discussed by <xref ref-type="bibr" rid="bibr33-1744987112449969">Weal et al. (2007)</xref>. Most importantly, any analysis needs to be explicitly linked to the desired learning outcomes of the simulation scenario, if only to be time efficient.</p>
</sec>
<sec id="sec7-1744987112449969"><title>Stage 3: tracking further developments in video analysis – the way forward</title>
<p>Stages 1 and 2 demonstrated that analytical techniques acquired from statistics and computer science provided new insights on student-related data, whether through web logs, self-reports of competence or the challenge of creating ontologies suitable for ‘mouse clicking’ while watching fast moving activity in simulation. Data concerning students that has a sequence or history can be analysed to reveal collective and individual patterns of behaviour. Video observation of over 300 students in simulation provided the raw material to generate ontologies related to specific scenarios, and confirmed the importance of domain-specific ontologies. Inevitably, during the time span since 2003, technological advances have enabled further refinements to be made to the techniques for analysing the simulation data. This has been augmented by the advent of more sophisticated and wireless technologies for the computerised mannequins.</p>
<p>Co-design of software solutions to facilitate video analysis revealed the substantive challenges, both technically and pragmatically, that our data presents. The next development was to establish whether it was possible to link the sensory tracking of student movement and their associated equipment with the video analysis (see <xref ref-type="bibr" rid="bibr34-1744987112449969">Weal et al., 2009a</xref>, <xref ref-type="bibr" rid="bibr35-1744987112449969">2009b</xref>). This involved the students captured in <xref ref-type="fig" rid="fig3-1744987112449969">Figure 3</xref> wearing sensory devices that tracked their movements in simulation. <xref ref-type="fig" rid="fig3-1744987112449969">Figure 3</xref> draws attention to students working as individuals, in teams and with complex client needs. Following these trials, we concluded that it may be possible to develop automated techniques to link tracking information with the video capture of student activity. As we have shown, we are beginning to manage the scale and complexity of the data sources and their eventual integration. Once effective video marking and annotation can be achieved, this will greatly augment the reality of valid and reliable assessment, feedback and longitudinal analysis of student performance. We have shown through tracking, web log analysis and simulation that it will be possible to measure student activity with respect to time, within physical space and via human computer interfaces. These data could then be triangulated or explored in relation to both individual and cohort characteristics, for example the sequence of clinical placements, academic achievements or experience of clinical incidents. Tracking and video analysis facilitates greater analysis of teamwork and patterns of practice, particularly in the ward-based environment or within community-based simulation suites. This has huge potential for studying and improving the ergonomics and working practices within clinical areas.</p>
<p>There is no doubt that this series of trials and evaluative studies have opened windows into new research possibilities for nursing and health care educators and researchers. Once the tools are sufficiently robust, they can be applied to the analysis of purposive designed simulations for practitioner teams that replicate clinical challenges so as to (a) improve training; (b) give insights into the messy world of clinical practice; (c) increase our knowledge and understanding of working practices and habits; and (d) provide a platform to ‘trial’ innovations before their application to the clinical area.</p>
</sec>
</sec>
<sec id="sec8-1744987112449969"><title>Ethics and consent</title>
<p>Each study was subject to ethical approval from the local University Ethics Committee and operated within the umbrella of a purposively designed protocol (Programme of Research and Education/Ethics into Virtual Interactive Practice: PREVIP®) (see, <xref ref-type="bibr" rid="bibr20-1744987112449969">Monger &amp; Gobbi, 2006</xref>) whose primary purpose is to protect the participants involved in any related research programme. Participants fall within two categories. Category 1 individuals are those filmed or recorded for the development of multimedia resources, for example National Health Service (NHS) patients, University staff or members of the public. Category 2 comprises the students, actors and staff involved in the research by virtue of their interaction with the multimedia resources and simulation exercises. PREVIP® was peer reviewed and scrutinised by experts in United Kingdom NHS Ethics, indemnity, risk, governance and legal issues associated with the use of digital and multimedia data. The protocol designated specific individuals to comprise a ‘Guardian Group’ to protect the rights of participants’ data and to handle specific requests for data access or secondary use. Participant information sheets and consent forms were designed for each category of participant and individual study. They included consent for different levels of publication and dissemination.</p>
</sec>
<sec id="sec9-1744987112449969"><title>Sampling and access</title>
<p>Each study adopted the principle of voluntary, non-coercive purposive sampling in which all relevant students, staff, persons and technicians were invited by letter and oral presentation to participate in the relevant study. Participants were recruited through intermediaries to prevent any potential conflicts of interest or coercion. It was possible that individual participants may be known to the research staff due to their concurrent academic roles. Consent was verified at the point of data collection and at the end of participation.</p>
</sec>
<sec id="sec10-1744987112449969"><title>Limitations</title>
<p>The necessity to trial different ways of analysing simulation-related data has necessarily limited the studies to one case study institution. While scenarios can be replicated, the technical infrastructures between establishments are not always compatible. Further work will be required in other sites so that comparative studies can strengthen the generalisability of the data findings.</p>
</sec>
<sec id="sec11-1744987112449969" sec-type="conclusions"><title>Conclusions</title>
<p>In a constrained economic climate, where simulation education is expanding, planners and managers need assurance that simulation is cost effective, evidence based and led by prepared trainers. Evaluations that address students/trainees' experience, learning, behaviours and the subsequent impact on resources and patient outcomes will become increasingly important. While current evidence demonstrates that simulation can increase competency and confidence in clinicians, provide instant feedback and reduce patient risk, we lack the necessary analytical tools to measure and understand the complexity of student/practitioner learning, behaviours and performance over time. Studies need to take account of individual student characteristics, professional trajectories and inter-related curricula activities. While proxy measures of student performance, educational evaluations concerning simulation design and student experience, have their place in developing the pedagogic evidence base, nurse and health care educators must collaborate with social and computer scientists to bring cutting edge science to the analysis of practitioner performance and engagement. We have shown that simulation practices and their associated web-based learning interactions provide a platform from which new forms of research and methods of analysis can emerge. The goal of trying to triangulate and interpret different data streams continues to test our ability to handle these data. However, advances in science and technology have, and will, generate new opportunities for expanding our knowledge concerning the ways through which students and practitioners learn, behave and interact. In so doing, nursing science gains access to new tools from which the investigation of nursing practices and their acquisition can advance. A future in which studies to investigate the efficacy of new professional practices and innovations take place in high-fidelity environments, prior to their introduction within the clinical field, no longer seems an unrealistic dream.</p>
</sec>
<sec id="sec12-1744987112449969"><title>Key points</title>
<p>
<list id="list2-1744987111434191" list-type="bullet">
<list-item><p>Collaboration with computer and social scientists provides opportunities for the development of analytical tools to handle meaningfully large educational data sets.</p></list-item>
<list-item><p>Different modalities of data representation can offer fresh insights into the behaviours of students.</p></list-item>
<list-item><p>More detailed understandings of student/staff experiences, achievements and behaviours may be facilitated by the use of sequence analysis, event histories, literal tracking of movements and video annotations.</p></list-item>
<list-item><p>Future developments in web-based technologies, tracking devices and semantic annotation offer exciting opportunities for the analysis of nursing activities and roles and the development of new ways of working. This will require nurse researchers and educators to learn the skills of co-design.</p></list-item>
</list></p>
</sec>
</body>
<back>
<ack><title>Acknowledgement</title>
<p>The authors wish to express their thanks to Felix Martinez of the University of Nottingham for his support with the tracking experiments.</p></ack>
<sec id="sec13-1744987112449969"><title>Funding</title>
<p>This work was supported by the Economic and Social Research Council (RES-149-25-1056) the Higher Education Academy (Grant 501286101) and the University of Southampton.</p>
</sec>
<sec id="sec14-1744987112449969"><title>Conflict of interest statement</title>
<p>None declared.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="bibr1-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Berragan</surname><given-names>L</given-names></name></person-group> (<year>2011</year>) <article-title>Simulation: An effective pedagogical approach for nursing?</article-title> <source>Nurse Education Today</source>. <comment>February 21. doi:10.1016/j.nedt.2011.01.019</comment>.</citation></ref>
<ref id="bibr2-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cant</surname><given-names>RF</given-names></name><name><surname>Cooper</surname><given-names>SJ</given-names></name></person-group> (<year>2009</year>) <article-title>Simulation-based learning in nurse education: a systematic review</article-title>. <source>Journal of Advanced Nursing</source> <volume>66</volume>: <fpage>3</fpage>–<lpage>15</lpage>.</citation></ref>
<ref id="bibr3-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>DeYoung</surname><given-names>S</given-names></name></person-group> (<year>2003</year>) <source>Teaching Strategies for Nurse Educators</source>, <edition>2nd edn</edition>. <publisher-loc>NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation></ref>
<ref id="bibr4-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>DiGiacomo</surname><given-names>JC</given-names></name><name><surname>Hoff</surname><given-names>W</given-names></name><name><surname>Rotondo</surname><given-names>MF</given-names></name><etal/></person-group> (<year>1997</year>) <article-title>Barrier precautions in trauma resuscitation: Real-time analysis utilising videotape review</article-title>. <source>American Journal of Emergency Medicine</source> <volume>15</volume>: <fpage>34</fpage>–<lpage>39</lpage>.</citation></ref>
<ref id="bibr5-1744987112449969"><citation citation-type="web"><person-group person-group-type="author"><name><surname>Donaldson</surname><given-names>L</given-names></name></person-group> (<year>2009</year>) <article-title>Annual report of the chief medical officer on the state of public health 2008–2009</article-title>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="www.dh.gov.uk/en/Publicationsandstatistics/Publications/AnnualReports/DH_096206">www.dh.gov.uk/en/Publicationsandstatistics/Publications/AnnualReports/DH_096206</ext-link></comment>.</citation></ref>
<ref id="bibr6-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Downs</surname><given-names>M</given-names></name></person-group> (<year>2000</year>) <source>Visualizing Longitudinal Ordinal Data using Data Mosaics</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Statistics Collaborative, Inc</publisher-name>.</citation></ref>
<ref id="bibr7-1744987112449969"><citation citation-type="book"><collab>European Working Time Directives</collab> (<year>1998</year>) <publisher-loc>London</publisher-loc>: <comment>Health Services. Circular, No 204</comment>.</citation></ref>
<ref id="bibr8-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gaba</surname><given-names>DM</given-names></name></person-group> (<year>2004</year>) <article-title>The future vision of simulation in health care</article-title>. <source>Quality and Safety in Health Care</source> <volume>13</volume>: <fpage>i2</fpage>–<lpage>i10</lpage>.</citation></ref>
<ref id="bibr9-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gaberson</surname><given-names>KB</given-names></name><name><surname>Oermann</surname><given-names>MH</given-names></name></person-group> (<year>2010</year>) <source>Clinical Teaching Strategies in Nursing</source>, <edition>3rd edn</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer Publishing Co</publisher-name>.</citation></ref>
<ref id="bibr10-1744987112449969"><citation citation-type="book"><comment>Garret B, van der Wal R and Gable E (2007) <italic>Developing a Collaborative Infrastructure for the Implementation of Simulations for Clinical Professional Healthcare Education: 2005-2007</italic>. University of British Columbia and Vancouver Coastal Health, Canada: British Columbia Academic Health Council PEIF Project</comment>.</citation></ref>
<ref id="bibr11-1744987112449969"><citation citation-type="book"><comment>Gobbi M, Monger E, Watkinson G, et al. (2004) Virtual Interactive Practice: A strategy to enhance learning and competence in health care students. In: Fieschi M, et al. (eds) <italic>proceedings of the 11th world congress on medical informatics. Building high performance health care organisations (Medinfo 2004)</italic>, Biomedical Informatics for Enhancing Health Care, Research &amp; Education, San Francisco, USA, 7-11 September 2004, pp.874–878. Amsterdam: IOS Press</comment>.</citation></ref>
<ref id="bibr12-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hovanscek</surname><given-names>MT</given-names></name></person-group> (<year>2007</year>) <article-title>Using simulation in nursing education</article-title>. In: <person-group person-group-type="editor"><name><surname>Jeffries</surname><given-names>PM</given-names></name></person-group> (ed.) <source>Simulation in Nursing Education; From Conceptualisation to Evaluation</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>National League for Nursing</publisher-name>.</citation></ref>
<ref id="bibr13-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Humphris</surname><given-names>GM</given-names></name><name><surname>Kaney</surname><given-names>S</given-names></name></person-group> (<year>2000</year>) <article-title>The objective structured video exam for assessment of communication skills</article-title>. <source>Medical Education</source> <volume>34</volume>: <fpage>939</fpage>–<lpage>945</lpage>.</citation></ref>
<ref id="bibr14-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jeffries</surname><given-names>PM</given-names></name></person-group> (<year>2007</year>) <source>Simulation in Nursing Education; From Conceptualisation to Evaluation</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>National League for Nursing</publisher-name>.</citation></ref>
<ref id="bibr15-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>D</given-names></name><name><surname>Kirkpartick</surname><given-names>JD</given-names></name></person-group> (<year>2006</year>) <comment>Evaluating Training Programmes: The four levels. 3rd Edition. San Francisco: Berrett-Koehler Publishers</comment>.</citation></ref>
<ref id="bibr16-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kneebone</surname><given-names>R</given-names></name><name><surname>Nestel</surname><given-names>D</given-names></name><name><surname>Yadollahi</surname><given-names>F</given-names></name><etal/></person-group> (<year>2006</year>) <article-title>Assessing procedural skills in context: exploring the feasibility of an Integrated Procedural Performance Instrument (IPPI)</article-title>. <source>Medical Education</source> <volume>40</volume>: <fpage>1105</fpage>–<lpage>1114</lpage>.</citation></ref>
<ref id="bibr17-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kunkler</surname><given-names>K</given-names></name></person-group> (<year>2006</year>) <article-title>The role of medical simulation: an overview</article-title>. <source>The International Journal of Medical Robotics and Computer Assisted Surgery</source> <volume>2</volume>: <fpage>203</fpage>–<lpage>210</lpage>. <comment>doi: 10.1002/rcs.101</comment>.</citation></ref>
<ref id="bibr18-1744987112449969"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>McDonald</surname><given-names>JW</given-names></name><name><surname>Gobbi</surname><given-names>MO</given-names></name><name><surname>Michaelides</surname><given-names>D</given-names></name><etal/></person-group> (<year>2008a</year>) <article-title>Grid-enabled data collection and analysis – semantic annotation in skills-based learning</article-title>, <conf-name>4th international conference on e-social science</conf-name> <conf-date>18–20 June 2008</conf-date>, <conf-loc>Manchester, UK</conf-loc>.</citation></ref>
<ref id="bibr19-1744987112449969"><citation citation-type="book"><comment>McDonald JW, Michaelides D, Weal MJ, et al. (2008b) Visualisation of human-computer interaction within an interactive web-based learning environment. Technical Report, School of Electronics and Computer Science, University of Southampton</comment>.</citation></ref>
<ref id="bibr20-1744987112449969"><citation citation-type="book"><comment>Monger E and Gobbi M (2006) PREVIP Protocol version 4, Programme of Research and Education/Ethics into Virtual Interactive Practice (VIP), University of Southampton</comment></citation></ref>
<ref id="bibr21-1744987112449969"><citation citation-type="book"><comment>National Council of State Boards of Nursing (2009) <italic>Report of Findings from the Effect of High-Fidelity Simulation on Nursing Students’ Knowledge and Performance: A Pilot Study</italic>. (Research Brief Vol. 40). Chicago, IL: National Council of State Boards of Nursing</comment>.</citation></ref>
<ref id="bibr22-1744987112449969"><citation citation-type="book"><collab>Nursing and Midwifery Council</collab> (<year>2007</year>) <source>Simulation in Practice Learning Project</source>. <publisher-loc>London</publisher-loc>: <publisher-name>NMC</publisher-name>.</citation></ref>
<ref id="bibr23-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>R</given-names></name><name><surname>Ward</surname><given-names>JW</given-names></name><name><surname>Page</surname><given-names>L</given-names></name><etal/></person-group> (<year>2008</year>) <article-title>Virtual reality training for radiotherapy becomes a reality</article-title>. <source>Studies in Health Technology and Informatics</source> <volume>132</volume>: <fpage>366</fpage>–<lpage>371</lpage>.</citation></ref>
<ref id="bibr24-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ram</surname><given-names>P</given-names></name><name><surname>Grol</surname><given-names>R</given-names></name><name><surname>Rethans</surname><given-names>JJ</given-names></name><etal/></person-group> (<year>1999</year>) <article-title>Assessment of General Practitioners by video observation of communicative and medical performance in daily practice: issues of validity, reliability and feasibility</article-title>. <source>Medical Education</source> <volume>33</volume>: <fpage>447</fpage>–<lpage>454</lpage>.</citation></ref>
<ref id="bibr25-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ricketts</surname><given-names>B</given-names></name></person-group> (<year>2011</year>) <article-title>The role of simulation for learning within pre-registration nursing education: A literature review</article-title>. <source>Nurse Education Today</source> <volume>31</volume>: <fpage>650</fpage>–<lpage>654</lpage>.</citation></ref>
<ref id="bibr26-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sanford</surname><given-names>PG</given-names></name></person-group> (<year>2010</year>) <article-title>Simulation in nursing education: A review of the research</article-title>. <source>The Qualitative Report</source> <volume>15</volume>: <fpage>1006</fpage>–<lpage>1011</lpage>.</citation></ref>
<ref id="bibr27-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schiavenato</surname><given-names>M</given-names></name></person-group> (<year>2009</year>) <article-title>Reevaluating simulation in nursing education: Beyond the human patient simulator</article-title>. <source>Journal of Nursing Education</source> <volume>48</volume>: <fpage>388</fpage>–<lpage>394</lpage>.</citation></ref>
<ref id="bibr28-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sexton</surname><given-names>JB</given-names></name><name><surname>Thomas</surname><given-names>EJ</given-names></name><name><surname>Helmreich</surname><given-names>RJ</given-names></name></person-group> (<year>2000</year>) <article-title>Error, stress, and teamwork in medicine and aviation: cross sectional surveys</article-title>. <source>Br Med J</source> <volume>18</volume>: <fpage>7237, 745</fpage>–<lpage>749</lpage>.</citation></ref>
<ref id="bibr29-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SJ</given-names></name><name><surname>Roehrs</surname><given-names>CJ</given-names></name></person-group> (<year>2009</year>) <article-title>High-fidelity simulation: factors correlated with nursing student satisfaction and self-confidence</article-title>. <source>Nursing Education Perspectives</source> <volume>30</volume>: <fpage>74</fpage>–<lpage>78</lpage>.</citation></ref>
<ref id="bibr30-1744987112449969"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vivekananda-Schmidt</surname><given-names>P</given-names></name><name><surname>Lewis</surname><given-names>M</given-names></name><name><surname>Coady</surname><given-names>D</given-names></name><etal/></person-group> (<year>2007</year>) <article-title>Exploring the use of videotaped objective structured clinical examination in the assessment of joint examination skills of medical students</article-title>. <source>Arthritis and Rheumatism (Arthritis Care and Research)</source> <volume>57</volume>: <fpage>869</fpage>–<lpage>876</lpage>.</citation></ref>
<ref id="bibr31-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Watkinson</surname><given-names>G</given-names></name><name><surname>Spencer</surname><given-names>A</given-names></name><name><surname>Monger</surname><given-names>E</given-names></name><etal/></person-group>. (<year>2004</year>) <comment>Virtual Interactive Practice: Utilising healthcare information systems to contextualise the skills associated with clinical decision making within nurse education. In: Fieschi M, et al (eds) <italic>proceedings of the 11th world congress on medical informatics. Building high performance health care organisations (Medinfo 2004)</italic>, Biomedical Informatics for Enhancing Health Care, Research &amp; Education, San Francisco, USA, 7–11 September 2004, pp.746–749, Amsterdam: IOS Press</comment>.</citation></ref>
<ref id="bibr32-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Watkinson</surname><given-names>G</given-names></name><name><surname>Spencer</surname><given-names>A</given-names></name><name><surname>Monger</surname><given-names>E</given-names></name><etal/></person-group> (<year>2006</year>) <article-title>Case study 17A, using technology to teach clinical skills</article-title>. In: <person-group person-group-type="editor"><name><surname>Weaver</surname><given-names>C</given-names></name><name><surname>White Delaney</surname><given-names>C</given-names></name><name><surname>Weber</surname><given-names>P</given-names></name><etal/></person-group> (eds) <source><italic>In:</italic> 2006 nursing and informatics for the 21st century: an international look at practice, trends and the future</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>HIMSS</publisher-name>.</citation></ref>
<ref id="bibr33-1744987112449969"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Weal</surname><given-names>MJ</given-names></name><name><surname>Michaelides</surname><given-names>DT</given-names></name><name><surname>De Roure</surname><given-names>DC</given-names></name><etal/></person-group> (<year>2007</year>) <article-title>Semantic annotation in ubiquitous healthcare skills-based learning environments</article-title>. <source><italic>In:</italic> Workshop on Semantic web in ubiquitous healthcare in conjunction with (ISWC2007)</source> <comment>November, Busan, South Korea</comment>.</citation></ref>
<ref id="bibr34-1744987112449969"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Weal</surname><given-names>MJ</given-names></name><name><surname>Michaelides</surname><given-names>D</given-names></name><name><surname>Page</surname><given-names>K</given-names></name><etal/></person-group> (<year>2009a</year>) <article-title>Tracking and annotation in skills-based learning environments</article-title>, <conf-name>IEEE international workshop on pervasive e learning as part of the seventh annual IEEE international conference on pervasive computing and communications (PerEL 2009)</conf-name> <conf-date>9 March 2009</conf-date>, <conf-loc>Galveston, TX</conf-loc>.</citation></ref>
<ref id="bibr35-1744987112449969"><citation citation-type="confproc"><person-group person-group-type="author"><name><surname>Weal</surname><given-names>MJ</given-names></name><name><surname>Michaelides</surname><given-names>DT</given-names></name><name><surname>Page</surname><given-names>KR</given-names></name><etal/></person-group> (<year>2009b</year>) <article-title>Location based semantic annotation for ward analysis</article-title>, <conf-name>3rd international conference on pervasive computing technologies for healthcare 2009</conf-name> <conf-date>1–3 April 2009</conf-date>, <conf-loc>London, UK</conf-loc>.</citation></ref>
</ref-list>
<bio>
<p><bold>Mary Gobbi</bold> (PhD MA(Ed), Dip N, Dip N Ed, RGN) is a Senior Lecturer in Nursing at the Faculty of Health Sciences at the University of Southampton. Her research includes educational development and research with simulation and virtual interactive practice for patient safety, leadership, use of technologies in nursing and accelerated student/practitioner competence. Email: <email>mog1@soton.ac.uk</email></p>
<p><bold>Eloise Monger</bold> is a lecturer in Critical Care Nursing at the University of Southampton. Her research interests include the use of simulation and virtual interactive practice for educational development and research and research ethics in nursing.</p>
<p><bold>Mark Weal</bold> is a lecturer in the Web and Internet Science Group, Faculty of Electronics and Computer Science, at the University of Southampton. His research interests include Web science and the application of Semantic Web technologies in healthcare, e-learning, and pervasive systems.</p>
<p><bold>John W. McDonald</bold> is Professor of Longitudinal Studies at the Institute of Education, University of London. While much of his research has been at the interface of statistics and social science, he has also undertaken interdisciplinary research with colleagues in Computer Science, Medicine and Nursing.</p>
<p><bold>Danius Michaelides</bold> is a senior research fellow in the Web and Internet Science Group, Faculty of Electronics and Computer Science, at the University of Southampton. His current research includes developing research environments for scientists.</p>
<p><bold>David De Roure</bold> is Professor of e-Research in the Oxford e-Research Centre and the National Strategic Director for Digital Social Research. He focuses on the co-evolution of digital technologies and research methods in and between multiple disciplines.</p>
</bio>
</back>
</article>