<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPA</journal-id>
<journal-id journal-id-type="hwp">spepa</journal-id>
<journal-title>Educational Evaluation and Policy Analysis</journal-title>
<issn pub-type="ppub">0162-3737</issn>
<issn pub-type="epub">1935-1062</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.3102/0162373712461851</article-id>
<article-id pub-id-type="publisher-id">10.3102_0162373712461851</article-id>
<title-group>
<article-title>Effects of Two Scientific Inquiry Professional Development Interventions on Teaching Practice</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Grigg</surname><given-names>Jeffrey</given-names></name>
<aff id="aff1-0162373712461851">University of Wisconsin-Madison</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Kelly</surname><given-names>Kimberle A.</given-names></name>
<aff id="aff2-0162373712461851">University of Southern California</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Gamoran</surname><given-names>Adam</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Borman</surname><given-names>Geoffrey D.</given-names></name>
<aff id="aff3-0162373712461851">University of Wisconsin-Madison</aff>
</contrib>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>35</volume>
<issue>1</issue>
<fpage>38</fpage>
<lpage>56</lpage>
<history>
<date date-type="received">
<day>10</day>
<month>1</month>
<year>2012</year>
</date>
<date date-type="received">
<day>26</day>
<month>4</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>30</day>
<month>7</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© 2012 AERA</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">American Educational Research Association</copyright-holder>
</permissions>
<abstract>
<p>In this article, we examine classroom observations from a 3-year large-scale randomized trial in the Los Angeles Unified School District (LAUSD) to investigate the extent to which a professional development initiative in inquiry science influenced teaching practices in in 4th and 5th grade classrooms in 73 schools. During the course of the study, LAUSD introduced an additional districtwide scientific inquiry professional development initiative, which complicates the experimental analysis but allows us to conduct a quasiexperimental analysis of the second Multilevel models predicting the presence of science inquiry in observed classroom lessons show that both interventions increased the incidence of inquiry-based science teaching, but the impact was limited to selected features of the inquiry process. We also found that the experimental impacts on teaching practice correspond with the features of scientific inquiry to which the teachers were most frequently exposed during the professional development.</p>
</abstract>
<kwd-group>
<kwd>science instruction</kwd>
<kwd>professional development</kwd>
<kwd>randomized field trial</kwd>
<kwd>elementary school</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>T<sc>eaching</sc> practice, or what teachers do, has a major influence on student achievement (<xref ref-type="bibr" rid="bibr22-0162373712461851">Gamoran, Nystrand, Berends, &amp; LePore, 1995</xref>; <xref ref-type="bibr" rid="bibr5-0162373712461851">Barr &amp; Dreeben, 1983</xref>; <xref ref-type="bibr" rid="bibr12-0162373712461851">Carlisle, Kelcey, Berebitsky, &amp; Phelps, 2011</xref>; <xref ref-type="bibr" rid="bibr25-0162373712461851">Hamre &amp; Pianta, 2005</xref>; <xref ref-type="bibr" rid="bibr43-0162373712461851">Measures of Effective Teaching Project, 2010</xref>; <xref ref-type="bibr" rid="bibr51-0162373712461851">Palardy &amp; Rumberger, 2008</xref>). Consequently, teacher learning that yields changes in teaching practice is one way to improve student achievement (<xref ref-type="bibr" rid="bibr7-0162373712461851">Borko, 2004</xref>; <xref ref-type="bibr" rid="bibr16-0162373712461851">Desimone, 2009</xref>; <xref ref-type="bibr" rid="bibr58-0162373712461851">Wayne, Yoon, Zhu, Cronen, &amp; Garet, 2008</xref>). These changes are necessary in many academic content areas, but the need is pressing in science, in which a new vision of constructivist, learner-centered instruction known as scientific inquiry has been proposed to replace the practices commonly used by many teachers (American Association for the Advancement of Science <xref ref-type="bibr" rid="bibr2-0162373712461851">[AAAS], 1993</xref>; <xref ref-type="bibr" rid="bibr15-0162373712461851">Davis, Petish, &amp; Smithey, 2006</xref>; <xref ref-type="bibr" rid="bibr27-0162373712461851">Hewson, 2007</xref>; <xref ref-type="bibr" rid="bibr40-0162373712461851">Loucks-Horsley, Stiles, Mundry, Love, &amp; Hewson, 2009</xref>; National Research Council <xref ref-type="bibr" rid="bibr45-0162373712461851">[NRC], 1996</xref>, <xref ref-type="bibr" rid="bibr46-0162373712461851">2000</xref>, <xref ref-type="bibr" rid="bibr47-0162373712461851">2012</xref>).</p>
<p>Major changes in teaching practice will require substantial learning and guidance (<xref ref-type="bibr" rid="bibr3-0162373712461851">Ball &amp; Cohen, 1999</xref>; <xref ref-type="bibr" rid="bibr7-0162373712461851">Borko, 2004</xref>; <xref ref-type="bibr" rid="bibr60-0162373712461851">Wilson &amp; Berne, 1999</xref>), and although teachers learn in many ways, professional development promotes systemic and coordinated teacher learning, which in turn may influence student achievement (<xref ref-type="bibr" rid="bibr23-0162373712461851">Gamoran, Secada, &amp; Marrett, 2000</xref>; <xref ref-type="bibr" rid="bibr7-0162373712461851">Borko, 2004</xref>; <xref ref-type="bibr" rid="bibr16-0162373712461851">Desimone, 2009</xref>; <xref ref-type="bibr" rid="bibr24-0162373712461851">Garet, Porter, Desimone, Birman, &amp; Yoon, 2001</xref>). Support for teacher learning is especially necessary when promoting challenging and complex pedagogies, such as scientific inquiry (<xref ref-type="bibr" rid="bibr14-0162373712461851">Crawford, 2007</xref>; <xref ref-type="bibr" rid="bibr15-0162373712461851">Davis, Petish, &amp; Smithey, 2006</xref>). Professional development can take many forms, including mentoring, coaching, and lesson study, but the standard approach in the United States remains training in the form of in-service workshops, on which billions of dollars are spent annually (<xref ref-type="bibr" rid="bibr6-0162373712461851">Birman et al., 2007</xref>).</p>
<p>Rigorous evidence of the impact of professional development in typical, real-world settings is limited (<xref ref-type="bibr" rid="bibr53-0162373712461851">Rice, 2009</xref>; <xref ref-type="bibr" rid="bibr58-0162373712461851">Wayne et al., 2008</xref>), and several recent randomized field trials of professional development workshops have yielded no evidence of an impact on student achievement (e.g., <xref ref-type="bibr" rid="bibr26-0162373712461851">Heller, 2012</xref>; <xref ref-type="bibr" rid="bibr48-0162373712461851">Newman et al., 2012</xref>) or, in some cases, a negative impact (e.g., <xref ref-type="bibr" rid="bibr8-0162373712461851">Borman, Gamoran, &amp; Bowdon, 2008</xref>; <xref ref-type="bibr" rid="bibr52-0162373712461851">Pane, McCaffrey, Slaughter, Steele, &amp; Ikemoto, 2010</xref>). Given these findings, it is imperative to understand why these interventions are not producing the expected results. To do so, we need studies that investigate how professional development influences teaching practice, one of the ways in which professional development influences student achievement (<xref ref-type="bibr" rid="bibr16-0162373712461851">Desimone, 2009</xref>). When possible, these studies should include multiple professional development programs in multiple sites (<xref ref-type="bibr" rid="bibr7-0162373712461851">Borko, 2004</xref>).</p>
<p>In this article, we investigate how professional development changes teaching practice by examining the effect of two professional development initiatives designed to increase the prevalence of scientific inquiry instruction in 80 elementary schools in the Los Angeles Unified School District (LAUSD). The first initiative in “Science Immersion” was evaluated experimentally: Forty of the schools were randomly assigned the opportunity to send two teachers a year to an intensive summer training workshop. This professional development initiative negatively affected student achievement during the 1st year of the study (<xref ref-type="bibr" rid="bibr8-0162373712461851">Borman et al., 2008</xref>), and during the 2nd year of the study, there was no difference in student achievement between the treatment and control schools (<xref ref-type="bibr" rid="bibr10-0162373712461851">Bowdon, Borman, &amp; Gamoran, 2009</xref>). Between the 1st and 2nd years of the experiment, LAUSD increased its commitment to scientific inquiry by adopting the Full Option Science System (FOSS) curriculum and providing at least 1 day of professional development for all teachers in the district. We derive quasiexperimental estimates of the impact of the districtwide FOSS initiative by using the 1st-year classroom observations in the experimental control schools as a preintervention measure for the FOSS professional development initiative. We use data from observations of classroom instruction and of the Science Immersion professional development workshops to answer the following research questions:</p>
<list id="list1-0162373712461851" list-type="order">
<list-item><p>Did either professional development initiative change science instruction in elementary schools?</p></list-item>
<list-item><p>How did science instruction change?</p></list-item>
<list-item><p>How does the content of the professional development relate to the changes in teachers’ observed science instruction?</p></list-item>
</list>
<p>We demonstrate that although Science Immersion and FOSS both resulted in changes in teaching practice, neither produced the full-scale implementation of the inquiry cycle hypothesized to yield major improvements in scientific understanding (<xref ref-type="bibr" rid="bibr46-0162373712461851">NRC, 2000</xref>). Instead, both interventions produced changes in the instructional use of asking and responding to scientific questions through investigation. The full vision of scientific inquiry that includes synthesizing and communicating scientific concepts was not achieved consistently under either professional development regime. However, we did observe that the experimental impacts on teaching practice correspond with the features of scientific inquiry to which the teachers were most frequently exposed during their professional development workshops.</p>
<sec id="section1-0162373712461851">
<title>Scientific Inquiry: A New Vision of Science Instruction</title>
<p>Science teaching at the elementary level offers an opportunity to investigate how teachers respond to ambitious instructional reform initiatives. Most elementary science instruction is traditional (<xref ref-type="bibr" rid="bibr30-0162373712461851">Kennedy, 1998</xref>; <xref ref-type="bibr" rid="bibr40-0162373712461851">Loucks-Horsleyet al., 2009</xref>), but an alternative vision—scientific inquiry—has been consistently promoted for the past 20 years (<xref ref-type="bibr" rid="bibr2-0162373712461851">AAAS, 1993</xref>; <xref ref-type="bibr" rid="bibr45-0162373712461851">NRC, 1996</xref>, <xref ref-type="bibr" rid="bibr46-0162373712461851">2000</xref>, <xref ref-type="bibr" rid="bibr47-0162373712461851">2012</xref>). In traditional science instruction, science is conceived primarily as a body of content and a set of procedures, and the goal of learning is to acquire the content and master the procedures. In these lessons, teachers present a scientific fact or principle to students, which may be accompanied by a confirmatory laboratory exercise demonstrating the fact or principle. Traditional science instruction has failed to produce uniformly high levels of scientific literacy (<xref ref-type="bibr" rid="bibr54-0162373712461851">Romberg, Carpenter, &amp; Dremock, 2005</xref>). In contrast, scientific inquiry allows students to conduct investigations to test questions about the natural world and then use the evidence they collect during their investigations to articulate an explanation in terms of scientific concepts and principles. These investigations are not purely exploratory; inquiry with minimal guidance from teachers does not lead to learning (<xref ref-type="bibr" rid="bibr33-0162373712461851">Kirschner, Sweller, &amp; Clark, 2006</xref>). Rather, scientific inquiry resembles the work of practicing scientists, with teachers serving as guides, ready to respond to the student questions as they emerge from their investigations. According to the <xref ref-type="bibr" rid="bibr45-0162373712461851">National Research Council (1996)</xref>,
<disp-quote>
<p>scientific inquiry refers to the diverse ways in which scientists study the natural world and propose explanations based on the evidence derived from their work. Inquiry also refers to the activities of students in which they develop knowledge and understanding of scientific ideas, as well as an understanding of how scientists study the natural world. (p. 23)</p>
</disp-quote></p>
<p>The NRC elaborated on this definition by presenting five “essential features of classroom inquiry” (<xref ref-type="bibr" rid="bibr46-0162373712461851">NRC, 2000</xref>, <xref ref-type="table" rid="table2-0162373712461851">Table 2</xref><xref ref-type="table" rid="table3-0162373712461851"/><xref ref-type="table" rid="table4-0162373712461851"/>-<xref ref-type="table" rid="table5-0162373712461851">5</xref>). At the time of this study, the latest vision of K–12 science instruction—the National Science Education Standards (NSES)—consisted of the following five features:</p>
<list id="list2-0162373712461851" list-type="bullet">
<list-item><p>Feature 1: Learner engages in scientifically oriented questions</p></list-item>
<list-item><p>Feature 2: Learner gives priority to evidence in responding to questions</p></list-item>
<list-item><p>Feature 3: Learner formulates explanations from evidence</p></list-item>
<list-item><p>Feature 4: Learner connects explanations to scientific knowledge</p></list-item>
<list-item><p>Feature 5: Learner communicates and justifies explanations</p></list-item>
</list>
<p>The features are intended to embody scientific inquiry so that students can actively experience it. Although the features are numbered, they are not intended to be executed in order. Rather, scientific inquiry is viewed as a cycle, with different features following one another. The NRC recently reframed the K–12 science standards to emphasize, among other things, eight “practices” rather than five “features” of scientific inquiry (<xref ref-type="bibr" rid="bibr47-0162373712461851">NRC, 2012</xref>), but regardless of which version of the NSES one follows, scientific inquiry—asking questions, gathering and interpreting evidence, and communicating explanations—remains central.<sup><xref ref-type="fn" rid="fn1-0162373712461851">1</xref></sup></p>
<p>A number of developers created curricula aligned with the NSES to engage students with scientific inquiry. In California, these curricula cover three elementary science content areas: life science, earth science, and physical science. The System-Wide Change for All Learners and Educators (SCALE) partnership developed a Science Immersion (hereafter Immersion) curriculum at the University of Wisconsin-Madison in partnership with the University of Pittsburgh and LAUSD (Schunn, Millar, Lauffer, &amp; SCALE Immersion Team, 2005). The Immersion curriculum for fourth grade is a unit called “Rot it Right” that covers the life science standards on the transfer of matter and energy through food chains, the living and nonliving components of ecosystems, and the role of microorganisms in ecosystems. It consists of thirteen 45-minute lessons, or about 10 hours of instructional time. The fifth-grade Immersion curriculum is a unit called “Weather Forces and Prediction” that covers the earth science standards on the role of convection currents, the ocean, and the water cycle in weather patterns and severe weather events. The unit consists of twenty-one 50-minute lessons, or about 17 hours of instructional time.</p>
<p>The FOSS project at the Lawrence Hall of Science, University of California-Berkeley, developed kit-based science units for use in elementary schools (<xref ref-type="bibr" rid="bibr20-0162373712461851">FOSS, 2009</xref>). FOSS is a complete curriculum covering all three elementary science content areas; the comparable kits to the Immersion units are “Environments” (fourth grade) and “Water Planet” (fifth grade). Because both curricula are aligned with the NSES, classroom observation protocols that identify the essential features of inquiry can be used to document the implementation of both Immersion and FOSS. Moreover, to the extent that average teaching practices in LAUSD are traditional, we can attribute differences in the observed features of inquiry to professional development in these curricula.</p>
<sec id="section2-0162373712461851">
<title>Professional Development as a Reform Strategy</title>
<p>We adopt the “nested layers” model of school organization in which inputs at one level (e.g., classroom instruction) lead to outputs at another (e.g., student achievement; <xref ref-type="bibr" rid="bibr23-0162373712461851">Gamoran et al., 2000</xref>; <xref ref-type="bibr" rid="bibr5-0162373712461851">Barr &amp; Dreeben, 1983</xref>). Put another way, teaching practices mediate the relationship between professional development initiatives and student learning (<xref ref-type="bibr" rid="bibr16-0162373712461851">Desimone, 2009</xref>).</p>
<p>There is little convincing evidence, however, that professional development initiatives influence student achievement. The “loose coupling” view of school organization suggests, in fact, that classrooms are insulated from external influences on the core technology of teaching (<xref ref-type="bibr" rid="bibr44-0162373712461851">Meyer &amp; Rowan, 1978</xref>; <xref ref-type="bibr" rid="bibr59-0162373712461851">Weick, 1976</xref>), and there is mixed evidence that professional development changes teaching practice. Prior research has documented a positive association between professional development and teaching practice, but most of the existing evidence relies on teacher self-reports, such as using large surveys (<xref ref-type="bibr" rid="bibr17-0162373712461851">Desimone, Porter, Garet, Yoon, &amp; Birman, 2002</xref>; <xref ref-type="bibr" rid="bibr24-0162373712461851">Garet et al., 2001</xref>; <xref ref-type="bibr" rid="bibr56-0162373712461851">Supovitz &amp; Turner, 2000</xref>) or teachers’ daily instructional logs (<xref ref-type="bibr" rid="bibr13-0162373712461851">Correnti, 2007</xref>). Many of the studies of science teaching used pre- and postintervention data without the benefit of a comparison group (e.g., <xref ref-type="bibr" rid="bibr1-0162373712461851">Akerson &amp; Hanusci, 2006</xref>; <xref ref-type="bibr" rid="bibr29-0162373712461851">Jeanpierre, Oberhauser, &amp; Freeman, 2005</xref>; <xref ref-type="bibr" rid="bibr49-0162373712461851">Oliveira, 2010</xref>) or have used quasiexperimental designs (<xref ref-type="bibr" rid="bibr31-0162373712461851">Kelly, 2011</xref>; <xref ref-type="bibr" rid="bibr32-0162373712461851">Kelly, Rickles, Sass, Ullah, &amp; Foster, 2008</xref>; <xref ref-type="bibr" rid="bibr36-0162373712461851">Lee, Deaktor, Hart, Cuevas, &amp; Enders, 2005</xref>). We draw from one of very few large-scale, experimental studies of the effects of professional development on directly observed teaching practice.</p>
<p>Recent large-scale experimental evaluations of the potential impact of professional development workshops present a complicated picture. On the whole, professional development in real-world settings seems to have limited impact on student achievement. Recent researchers have begun to investigate teaching practice as well, although often using teacher-self report or simple measures of time use. An evaluation of professional development for a scientific inquiry curriculum in Alabama elementary and middle schools, for example, found that teachers in the intervention schools reported spending more time using “active learning strategies” but that students in these schools performed equivalently on achievement tests (<xref ref-type="bibr" rid="bibr48-0162373712461851">Newman et al., 2012</xref>, p. xxiv–xxvi). Rather than relying on teacher reports of how much time students are actively learning, we investigate teaching practice with data collected by classroom observers using a multidimensional rubric.</p>
<p>A recent evaluation of a science professional development initiative in California and Arizona found that teachers in the intervention schools performed better on a content knowledge assessment and reported being more confident teaching science, but student performance was not different in the two groups of schools (<xref ref-type="bibr" rid="bibr26-0162373712461851">Heller, 2012</xref>). An evaluation of a mathematics initiative in sixth-grade classrooms in the mid-Atlantic region of the United States found no impact on student achievement but used both teacher self-report and classroom observations to measure implementation (<xref ref-type="bibr" rid="bibr42-0162373712461851">Martin, Brasiel, Turner, &amp; Wise, 2012</xref>). The classroom observations showed that teachers in the intervention schools placed more responsibility on students for learning and complex thinking and that the students showed evidence of responsibility for learning when working in groups, but there was no difference in student responsibility for learning when in class discussion, and there was no significant difference in the extent to which teachers made connections for students (<xref ref-type="bibr" rid="bibr42-0162373712461851">Martin et al., 2012</xref>, Table 3.4).</p>
<p>An evaluation of a learner-centered geometry curriculum deployed in eight Baltimore high schools yielded a statistically significant impact on student achievement: Like the 1st-year results of the study from which our data are drawn, the impact was negative (<xref ref-type="bibr" rid="bibr52-0162373712461851">Pane et al., 2010</xref>). Observations and interviews conducted by the researchers revealed that the teachers in the study found the learner-centered pedagogy difficult to implement. Difficulty of implementation is a critical problem, since incomplete implementation may harm students if it leaves them without sufficient guidance to navigate the learning process (<xref ref-type="bibr" rid="bibr33-0162373712461851">Kirschner et al., 2006</xref>). Teachers need guidance as well, both from curriculum materials and from professional development facilitators. The Immersion and FOSS curricula and accompanying professional development differ in their design, and these differences may yield different impacts on the individual features of scientific inquiry. Moreover, observing the Immersion professional development workshops may inform how the workshops influenced teaching practice.</p>
</sec>
</sec>
<sec id="section3-0162373712461851" sec-type="methods">
<title>Method</title>
<sec id="section4-0162373712461851">
<title>Research Design</title>
<p>We use data from the System-Wide Change (SWC) study, a school-based randomized field trial funded by the National Science Foundation of professional development in the Immersion curriculum developed by SCALE. The study took place in the LAUSD, one of the country’s poorest-performing school districts in elementary science (<xref ref-type="bibr" rid="bibr41-0162373712461851">Lutkus, Lauko, &amp; Brockway, 2006</xref>). A study timeline is presented in <xref ref-type="table" rid="table1-0162373712461851">Table 1</xref>.</p>
<table-wrap id="table1-0162373712461851" position="float">
<label>Table 1</label>
<caption><p>Timeline of LAUSD Initiatives, Scientific Inquiry Professional Development, and Data Collection</p></caption>
<graphic alternate-form-of="table1-0162373712461851" xlink:href="10.3102_0162373712461851-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Time</th>
<th align="center">LAUSD Initiative</th>
<th align="center">Professional Development</th>
<th align="center">Data Collection</th>
</tr>
</thead>
<tbody>
<tr>
<td>Before summer 2006</td>
<td>LAUSD endorses inquiry science instruction and makes Science Immersion and FOSS available; System-Wide Change experiment approved</td>
<td>Science Immersion pilot: 2- and 5-day Immersion institutes available to volunteers</td>
<td>School demographics, student achievement</td>
</tr>
<tr>
<td>Summer 2006</td>
<td/>
<td>5-day Science Immersion institutes for 4th-grade earth science (“Rot it Right”)</td>
<td>Immersion institute observations: 3 (4th grade) coded for analysis</td>
</tr>
<tr>
<td>Year 1: 2006–2007</td>
<td>November 2006: California State Board of Education approves five elementary science curricula including FOSS</td>
<td>2-day Science Immersion institutes and Science Immersion follow-up sessions</td>
<td>4th-grade classroom observations: 194 lessons from 81 teachers in 51 schools (100 lessons [52%] from Immersion schools)</td>
</tr>
<tr>
<td>Summer 2007</td>
<td>July 2007: LAUSD adopts FOSS as the new elementary science curriculum for K–5 students districtwide</td>
<td>5-day Science Immersion institutes continue for 4th grade; 5th grade physical science (“Weather Forces and Prediction”) introduced</td>
<td>Immersion institute observations: 1 (5th grade) coded for analysis</td>
</tr>
<tr>
<td>Year 2: 2007–2008</td>
<td>LAUSD schools receive three FOSS kits per grade level (covering earth, life, and physical science content areas) for teachers to share</td>
<td>1-day FOSS workshops; Science Immersion follow-up sessions</td>
<td>4th-grade classroom observations: 232 lessons from 88 teachers in 54 schools (120 lessons [52%] from Immersion schools)</td>
</tr>
<tr>
<td>Summer 2008</td>
<td/>
<td>5-day Science Immersion institutes in 4th and 5th grades</td>
<td>Immersion institute observations: 2 (5th grade) coded for analysis</td>
</tr>
<tr>
<td>Year 3: 2008–2009</td>
<td/>
<td>1- to 2-day FOSS workshops; Science Immersion follow-up sessions</td>
<td>5th-grade classroom observations: 285 lessons from 100 teachers in 62 schools (137 lessons [48%] from Immersion schools)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0162373712461851">
<p><italic>Note</italic>. LAUSD = Los Angeles Unified School District; FOSS = Full Option Science System.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>LAUSD had a long-standing commitment to scientific inquiry at the elementary level. Since providing curricular resources alone is not sufficient to change teaching practice (<xref ref-type="bibr" rid="bibr21-0162373712461851">Gamoran, Anderson, Quiroz, Secada, Williams, &amp; Ashmann, 2003</xref>), LAUSD provided professional development to accompany these science curricula, including Immersion and FOSS. This professional development consisted of single-day workshops in Immersion or FOSS for interested teachers and more extensive training (about 3 days per year) for the science lead teachers (SLTs). A 2-day workshop on “Rot it Right” was also made available to interested teachers. Because of limited resources and a strategic decision to train as many teachers as possible, these professional development workshops were brief and did not conform with the sustained, active learning called for by the “best practices” in professional development (<xref ref-type="bibr" rid="bibr24-0162373712461851">Garet et al., 2001</xref>; <xref ref-type="bibr" rid="bibr56-0162373712461851">Supovitz &amp; Turner, 2000</xref>).</p>
<p>In early 2006, LAUSD approved a 3-year school-based randomized field trial of a 5-day professional development workshop known as an “Immersion institute.” The Immersion institute went beyond the typical LAUSD professional development initiative by offering a reflective experience for an entire week. The institutes were facilitated by teams of education and natural science faculty from partner universities, LAUSD central and local district science instructional leaders, and LAUSD science teachers. The facilitation teams explicitly engaged the teachers in the lessons of the Immersion unit from a student perspective, and then reflectively as a practitioner, in a process deemed the Science Immersion Model of Professional Learning (SIMPL; <xref ref-type="bibr" rid="bibr35-0162373712461851">Lauffer &amp; Lauffer, 2009</xref>). A key component of this model is that teachers were to experience the Immersion unit authentically—that is, as students—and then reflect on the experience as teachers who will deliver the lessons (<xref ref-type="bibr" rid="bibr34-0162373712461851">Lauffer, 2010</xref>). Participating teachers were invited to attend follow-up sessions during the school year in which they could reflect on their pedagogy and discuss student work, but in practice few teachers attended these sessions.</p>
<p>The eight LAUSD local district superintendents nominated 190 schools they considered to be at least “minimally prepared” to undertake the initiative, and we selected a stratified random sample of 10 schools from each local district, yielding a study sample of 80 schools. Five schools in each local district (40 total) were randomly assigned to the experimental condition: They were encouraged to send two teachers per year—an SLT and a grade-level colleague—to Immersion institutes, starting in summer 2006. Fourth-grade teachers were invited in summers 2006 and 2007; fifth-grade teachers were invited in summers 2007 and 2008.</p>
<p>Forty-five teachers from 27 schools attended the five Immersion institutes offered to fourth-grade teachers in 2006, 32 teachers from 20 schools attended the four Immersion institutes offered to fourth- and fifth-grade teachers in 2007, and 19 teachers from 14 schools attended the two institutes offered to fifth-grade teachers in 2008. Project staff observed 9 of the 11 institutes and coded the observations with the same instrument that we employed in classrooms. We present data from the six Immersion institutes for which at least 4 of the 5 days were observed (three in fourth grade and three in fifth grade) to answer our third research question: to illustrate the relation between what teachers experienced in professional development and the changes in teaching practice.</p>
<p>The SWC study collected multiple forms of data: student achievement; teacher surveys; teacher, principal, and district staff interviews; and classroom and professional development observations. We use school average student achievement as a covariate to analyze the classroom observation data. District data on prior achievement and student demographics revealed no statistically significant differences between the two experimental groups of schools at the outset of the study (<xref ref-type="bibr" rid="bibr8-0162373712461851">Borman et al., 2008</xref>). In the 1st year, fourth-grade students in the 40 Immersion schools performed approximately one quarter of a standard deviation <italic>lower</italic> in fourth-grade life science than students in the 40 comparison schools on districtwide standardized assessments (<xref ref-type="bibr" rid="bibr8-0162373712461851">Borman et al., 2008</xref>). Moreover, students of SLTs—who were targeted for the Immersion institutes—performed approximately one half of a standard deviation <italic>lower</italic> in the 1st year of the study than students of SLTs in comparison schools. No differences in fourth- or fifth-grade student achievement on district and state standardized assessments were apparent in the 2nd and 3rd years of implementation (<xref ref-type="bibr" rid="bibr10-0162373712461851">Bowdon et al., 2009</xref>; <xref ref-type="bibr" rid="bibr9-0162373712461851">Borman, Gamoran &amp; Bowdon, 2010</xref>). We believe that the professional development and classroom observation data can inform these initially negative, then null, student achievement findings by documenting the extent to which teaching practice reflects the intended vision of scientific inquiry embodied in the NSES.</p>
</sec>
<sec id="section5-0162373712461851">
<title>The Interventions: Two Professional Development Initiatives in Scientific Inquiry</title>
<p>In July 2007, after the classroom observers had been in the field for a year, LAUSD adopted FOSS districtwide in kindergarten through fifth grade (<xref ref-type="bibr" rid="bibr38-0162373712461851">LAUSD, 2007a</xref>, Section I) following the California State Board of Education’s inclusion of FOSS as an adopted elementary science curriculum (<xref ref-type="bibr" rid="bibr11-0162373712461851">California Department of Education, 2007</xref>). As with the Immersion initiative LAUSD did not simply make FOSS available; it undertook a series of three 1-day professional development workshops, 1 day per science content area. SLTs were required to attend all three workshops, and every fourth- and fifth-grade teacher was told to attend a single workshop in one of the three content areas (<xref ref-type="bibr" rid="bibr39-0162373712461851">LAUSD, 2007b</xref>, Sec. 36). Interviews with teachers revealed that these brief workshops emphasized use, maintenance, and coordination of the FOSS kits rather than providing teachers with an authentic learning experience as the Immersion institutes attempted to do. Fourth- and fifth-grade teachers who wished to continue using Immersion were welcome to do so as long as they supplemented their instruction with the FOSS units that covered the additional science content areas that Immersion did not cover. Fifth-grade teachers were presented with a “blended” FOSS-Immersion curriculum as another option (LAUSD, <xref ref-type="bibr" rid="bibr39-0162373712461851">2007b</xref>, Sections 15, 16). This blended curriculum was introduced during the institutes in a sequence of twenty-five 45-minute lessons—nearly 19 hours of instruction—adding FOSS lessons on air pressure and processes of the water cycle (evaporation, condensation, deposition, distribution) to the Immersion weather unit’s lesson sequence.</p>
<p>The attributes of the two professional development initiatives—Immersion and FOSS—are compared in <xref ref-type="table" rid="table2-0162373712461851">Table 2</xref>. They share a number of similarities but differ substantially in their design and deployment. Both curricula are aligned with the NSES and the California science content area standards and aim to engage students in scientific inquiry (<xref ref-type="bibr" rid="bibr18-0162373712461851">FOSS, 2002</xref>, <xref ref-type="bibr" rid="bibr19-0162373712461851">2007</xref>; <xref ref-type="bibr" rid="bibr55-0162373712461851">Schunn et al., 2005</xref>). This alignment is the primary justification for using the same observation protocol for classrooms taught by teachers trained in either or both interventions. Both professional development initiatives took the form of institutes or workshops, but the Immersion institutes were 2 to 5 days long (with most participating teachers attending the 5-day version), and the FOSS trainings were 1 to 3 days long (with most participating teachers attending the 1-day version). All teachers attended the brief FOSS trainings, however, and only two teachers per year from each treatment school could attend the sustained Immersion institutes because of financial constraints.</p>
<table-wrap id="table2-0162373712461851" position="float">
<label>Table 2</label>
<caption><p>Characteristics of Science Immersion and Full Option Science System (FOSS) Initiatives</p></caption>
<graphic alternate-form-of="table2-0162373712461851" xlink:href="10.3102_0162373712461851-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Characteristic</th>
<th align="center">Science Immersion</th>
<th align="center">FOSS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Curriculum availability</td>
<td>Curriculum available to teachers prior to initiative</td>
<td>Curriculum available to teachers prior to initiative</td>
</tr>
<tr>
<td>Professional development model</td>
<td>Institute/workshop</td>
<td>Institute/workshop</td>
</tr>
<tr>
<td>Pedagogy</td>
<td>Scientific inquiry</td>
<td>Scientific inquiry</td>
</tr>
<tr>
<td>Standards</td>
<td>National Science Education Standards and California Content Standards</td>
<td>National Science Education Standards and California content standards</td>
</tr>
<tr>
<td>Form of inquiry</td>
<td>Open inquiry</td>
<td>Guided inquiry</td>
</tr>
<tr>
<td>Curricular adoption</td>
<td>Encouraged but not formally adopted</td>
<td>LAUSD adopted districtwide in 2007</td>
</tr>
<tr>
<td>Content areas covered</td>
<td>Earth science (Grade 4), physical science (Grade 5)</td>
<td>Earth, life, and physical science (Grades 4 and 5)</td>
</tr>
<tr>
<td>Workshop length</td>
<td>5-day Immersion institute</td>
<td>1-day workshop for each content area</td>
</tr>
<tr>
<td>Workshop content</td>
<td>Science content, pedagogy, and procedures</td>
<td>Science pedagogy and procedures</td>
</tr>
<tr>
<td>Invited teachers</td>
<td>Science lead teacher (SLT) and one grade-level colleague per year</td>
<td>All grade-level classroom teachers for one content area each; SLTs for all three workshops</td>
</tr>
<tr>
<td>Schools involved</td>
<td>40 randomly selected schools</td>
<td>All schools</td>
</tr>
<tr>
<td>Hands-on materials</td>
<td>Organized by teachers with support from district staff (as available)</td>
<td>Schools provided with three “FOSS kits” per grade level, each covering a content area; teachers rotate kits</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0162373712461851">
<p><italic>Note</italic>. LAUSD = Los Angeles Unified School District.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table3-0162373712461851" position="float">
<label>Table 3</label>
<caption><p>Classroom Observation Summary Statistics</p></caption>
<graphic alternate-form-of="table3-0162373712461851" xlink:href="10.3102_0162373712461851-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Variable</th>
<th align="center">Overall</th>
<th align="center">Immersion</th>
<th align="center">Comparison</th>
<th align="center">Pr(I− C ≠ 0)</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="5">School variables</td>
</tr>
<tr>
<td> Immersion school</td>
<td>0.49</td>
<td>1</td>
<td>0</td>
<td/>
</tr>
<tr>
<td> Year 2</td>
<td>0.31</td>
<td>0.32</td>
<td>0.30</td>
<td>0.745</td>
</tr>
<tr>
<td> Immersion × Year 2</td>
<td>0.16</td>
<td>0.32</td>
<td>0</td>
<td/>
</tr>
<tr>
<td> Year 3</td>
<td>0.42</td>
<td>0.41</td>
<td>0.44</td>
<td>0.743</td>
</tr>
<tr>
<td> Immersion × Year 3</td>
<td>0.2</td>
<td>0.41</td>
<td>0</td>
<td/>
</tr>
<tr>
<td> Pretest % correct</td>
<td>57.0</td>
<td>58.0</td>
<td>56.0</td>
<td>0.304</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td>73</td>
<td>36</td>
<td>37</td>
<td/>
</tr>
<tr>
<td colspan="5">Lesson variables</td>
</tr>
<tr>
<td> Length in minutes</td>
<td>51.6</td>
<td>53.0</td>
<td>50.1</td>
<td>0.014</td>
</tr>
<tr>
<td> 5-minute segments</td>
<td>10.3</td>
<td>10.6</td>
<td>10.0</td>
<td>0.013</td>
</tr>
<tr>
<td> Taught by science lead teacher</td>
<td>0.52</td>
<td>0.53</td>
<td>0.51</td>
<td>0.474</td>
</tr>
<tr>
<td> <italic>n</italic></td>
<td>711</td>
<td>357</td>
<td>354</td>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0162373712461851">
<p><italic>Note</italic>. Pr(I– C ≠ 0) = probability of a two-sample <italic>t</italic> test that the Immersion and comparison schools (and lessons in those schools) have equal means.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Immersion addressed one science content area in fourth and fifth grade—life science and earth science, respectively—whereas the FOSS kits were “wall to wall,” covering all three components in each grade (one kit per content area). Immersion required teachers to facilitate students’ open questioning (open inquiry), whereas the FOSS curriculum was more structured (guided inquiry). Immersion required the classroom teachers to collect and prepare instructional materials on their own, whereas FOSS consisted of prefabricated “FOSS kits.” The kits required ongoing maintenance to remain useful, however, which may diminish this distinction over time. Moreover, since each grade had only three kits, the grade-level classrooms had to coordinate their instruction so they were not teaching the same content areas at the same time. Teachers could use Immersion simultaneously. Finally, the two initiatives were deployed in different ways: The Immersion institutes were assigned experimentally to schools and attendance was optional for two teachers per target grade per year, whereas the shorter FOSS training sessions were mandatory for all elementary school teachers. Consequently, the contrast in the Immersion experiment is between randomized conditions, whereas the contrast in the FOSS quasi experiment is a pre- and postintervention analysis using the 1st year of the classroom observation data of fourth-grade classrooms as a baseline measure.</p>
</sec>
<sec id="section6-0162373712461851">
<title>Data Collection and Measures</title>
<sec id="section7-0162373712461851">
<title>Classroom observations: Sampling</title>
<p>Immersion institute and classroom observation data were collected for 3 consecutive years. Fourth-grade classrooms were observed during the 1st and 2nd years of the study, and fifth-grade classrooms were observed during the 3rd year of the study. Each year, observers asked the SLT and a randomly selected colleague in each of the 80 schools to sit in on three science lessons. Not all schools complied with the request every year, but in the 1st year, nearly two thirds of the schools were sampled (52 of 80), and by the 3rd year, nearly three quarters of the schools were sampled (63 of 80).<sup><xref ref-type="fn" rid="fn2-0162373712461851">2</xref></sup> Across all 3 years, classrooms from 75 of the 80 study schools were observed. Most teachers who agreed to participate did so fully, with 196 of 274 teachers (72%) represented by at least three classroom observations. Scores on LAUSD’s life science “periodic assessment” that we use as a pretest covariate were not available for 2 schools, so our analytic sample includes at least 1 year of observations from 73 of the 80 schools in the SWC study. Thirty-six of the 73 schools (49%) were in the treatment group, which suggests to us that there was no differential attrition. The two groups are equivalent on the life science pretest, are balanced across years, and are equally likely to have been taught by a SLT. Overall, the analytic sample includes 711 classroom observations, 357 from Immersion schools and 354 from comparison schools.</p>
<p>The science lessons in our data are not randomly selected from the school year. Rather, they were purposefully selected to cover the science standards that the Immersion units address. That is, the lessons were sampled so that the observers were more likely to witness scientific inquiry than randomly selected lessons would reveal. Furthermore, the observers spread their observations out over time to represent the range of activities related to the California science standards covered by the Immersion unit.</p>
<p>Observers also attended six of the seven fourth-grade Immersion institutes and three of the four fifth-grade Immersion institutes offered during the course of the study. Some of the observations were used for training purposes. We coded the six observed Immersion institutes that a trained observer attended for at least 4 of the 5 days. The unit of analysis for both classrooms and professional development institutes was a “day” of observation, which averaged 51.6 minutes (10.3 five-minute segments) for the classroom lessons and more than 5 hours (21.0 fifteen-minute segments) for the professional development sessions. The observations from the Immersion schools were 3 minutes longer than those from the comparison schools. Because the observation length is different in the two conditions and because longer observations are more likely to yield evidence of scientific inquiry, we include observation length in our statistical models. The trained observers recorded narrative notes in 5-minute segments for classroom observations and 15-minute segments for professional development sessions.</p>
</sec>
<sec id="section8-0162373712461851">
<title>Classroom observations: Coding the outcome variable</title>
<p>The narrative notes for both the classroom and professional development observations were subsequently coded to identify the use of the essential features of scientific inquiry. For their training, a team of five raters spent 50 hours iteratively coding sample observations until they came to a consensus on which essential features of inquiry were present. The consensus among the raters was not perfect, but an analysis of observations conducted of 15 raters on a videotaped sixth-grade lesson revealed that 85%, on average, agreed with the modal inquiry feature in the 5-minute segment (<xref ref-type="bibr" rid="bibr50-0162373712461851">Osthoff &amp; Ferrare, 2007</xref>).<sup><xref ref-type="fn" rid="fn3-0162373712461851">3</xref></sup> The activities described in a 5-minute segment could be coded as more than one feature of inquiry; for example, if students gave priority to evidence (Feature 2) and formulated an explanation from that evidence (Feature 3) in a 5-minute period, the segment would count for both features.<sup><xref ref-type="fn" rid="fn4-0162373712461851">4</xref></sup></p>
<p>This approach produced a complicated outcome variable that we simplify for analysis. Although the data produce counts of 5-minute segments with evidence of inquiry in each lesson (e.g., four segments of Feature 1, two segments of Feature 2, etc.), we reduce the count data to a binary indicator of whether the feature of inquiry was documented in the entire lesson (e.g., Feature 1 was observed, Feature 2 was observed, Feature 3 was not observed, etc.). This simplifies the analysis from segments of lessons to entire lessons.<sup><xref ref-type="fn" rid="fn5-0162373712461851">5</xref></sup> We examine the features separately to investigate how science teaching changed (our second research question), and we examine them together (in a single collapsed “any feature” variable) to examine whether professional development changed teaching practice (our first research question).</p>
<p>As can be seen in the summary statistics reported in <xref ref-type="table" rid="table4-0162373712461851">Table 4</xref>, some form of scientific inquiry was evident in most of the observed lessons. Given that the lessons were purposefully sampled to reveal scientific inquiry and that any instance of inquiry at any time in the lesson is a relatively low standard, this is not surprising. Not all of the inquiry features were equally represented, however. Eighty-six percent of all observed lessons had at least one 5-minute segment with at least one feature of inquiry. Features 1 and 2 were observed most frequently (62% and 61% of lessons, respectively), followed by Feature 3 (41% of lessons), whereas Features 4 and 5 were rarely observed (15% and 9% of lessons, respectively). Even though the features were intended to be iterative and not follow a sequence from Feature 1 to Feature 5, we might expect the initial stages of the inquiry cycle to be more prevalent. That being said, we interpret the findings for Features 4 and 5 as prima facie evidence that the “full cycle” of inquiry did not take place.</p>
<table-wrap id="table4-0162373712461851" position="float">
<label>Table 4</label>
<caption><p>Proportion of Lessons With Evidence of Scientific Inquiry by Year and Experimental Condition</p></caption>
<graphic alternate-form-of="table4-0162373712461851" xlink:href="10.3102_0162373712461851-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Year</th>
<th align="center">Experimental Condition</th>
<th align="center">Any Feature</th>
<th align="center">Feature 1</th>
<th align="center">Feature 2</th>
<th align="center">Feature 3</th>
<th align="center">Feature 4</th>
<th align="center">Feature 5</th>
</tr>
</thead>
<tbody>
<tr>
<td/>
<td>Overall mean</td>
<td>.86</td>
<td>.62</td>
<td>.61</td>
<td>.41</td>
<td>.15</td>
<td>.09</td>
</tr>
<tr>
<td>Year 1</td>
<td>Immersion (<italic>n</italic> = 100)</td>
<td>.87</td>
<td>.46</td>
<td>.72</td>
<td>.39</td>
<td>.07</td>
<td>.12</td>
</tr>
<tr>
<td/>
<td>Comparison (<italic>n</italic> = 94)</td>
<td>.67</td>
<td>.28</td>
<td>.57</td>
<td>.23</td>
<td>.04</td>
<td>.11</td>
</tr>
<tr>
<td>Year 2</td>
<td>Immersion (<italic>n</italic> = 120)</td>
<td>.91</td>
<td>.73</td>
<td>.68</td>
<td>.43</td>
<td>.18</td>
<td>.07</td>
</tr>
<tr>
<td/>
<td>Comparison (<italic>n</italic> = 112)</td>
<td>.87</td>
<td>.72</td>
<td>.60</td>
<td>.39</td>
<td>.21</td>
<td>.08</td>
</tr>
<tr>
<td>Year 3</td>
<td>Immersion (<italic>n</italic> = 137)</td>
<td>.92</td>
<td>.71</td>
<td>.62</td>
<td>.56</td>
<td>.18</td>
<td>.09</td>
</tr>
<tr>
<td/>
<td>Comparison (<italic>n</italic> = 148)</td>
<td>.86</td>
<td>.71</td>
<td>.53</td>
<td>.42</td>
<td>.20</td>
<td>.07</td>
</tr>
</tbody>
</table>
</table-wrap>
<p><xref ref-type="table" rid="table4-0162373712461851">Table 4</xref> also breaks down the evidence of scientific inquiry by experimental condition and year of the study. Three trends are evident. First, the features of inquiry were not unique to the schools that were randomly assigned the opportunity to attend the Immersion institutes: In the 1st year of the study, some form of inquiry was apparent in 87% of the lessons from the Immersion schools, but 67% of lessons from the comparison schools also showed some evidence of scientific inquiry. Second, there is an apparent difference between the 1st year of the study and the subsequent years of the study after LAUSD undertook the FOSS initiative: In the 2nd year, some form of inquiry was observed in 87% of the lessons from comparison schools. Third, the experimental and longitudinal contrasts differ by feature. Feature 2, for example, is more prevalent in the Immersion schools and remains stable over time. Feature 1, on the other hand, is higher in the Immersion schools in Year 1 and increases in all schools over time. Our statistical model will focus on these observed differences between the Immersion and comparison schools over time.</p>
</sec>
<sec id="section9-0162373712461851">
<title>Statistical methods</title>
<p>To answer our first two research questions (Did either professional development initiative change science instruction in elementary schools? How did science instruction change?), we use multilevel logistic regression models. These models account for the clustered nature of our data; we wish to estimate the impact of an intervention assigned at the school level, but our data are lessons within schools. The model is shown in Equation 1:</p>
<p>
<disp-formula id="disp-formula1-0162373712461851">
<mml:math display="block" id="math1-0162373712461851">
<mml:mrow>
<mml:mi>log</mml:mi>
<mml:mtext>it</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>π</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mtext>Immersion</mml:mtext>
</mml:mrow>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mi>L</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0162373712461851" xlink:href="10.3102_0162373712461851-eq1.tif"/>
</disp-formula>
</p>
<p>The outcome π<sub><italic>ij</italic></sub> is a binary indicator of whether any feature of inquiry (or an individual feature of inquiry to answer our second research question) was observed in lesson <italic>i</italic> in school <italic>j</italic>. β<sub>1</sub> estimates the impact of the assignment to the Immersion institute, β<italic><sub>S</sub>X<sub>j</sub></italic> is a vector of school-level variables, β<italic><sub>L</sub>X<sub>ij</sub></italic> is a vector of lesson-level variables, and <italic>u<sub>j</sub></italic> is the random effect that makes this a two-level random intercept model. The lesson-level variables include the length of the lesson in segments (centered on the sample mean) and whether the lesson was taught by a SLT. We estimate models with two sets of school-level covariates. In Model 1, the school-level covariates include indicators for the LAUSD local districts that served as randomization blocks and a baseline student achievement measure (the school mean percentage correct on the fourth-grade life science periodic assessment in 2005–2006). Model 2 includes the variables in Model 1 as well as indicators for the 2nd and 3rd years of the study and interaction terms between the year and treatment assignment to identify how the lessons changed over time.</p>
<p>We interpret the Immersion coefficients as reflecting the experimental effect of the opportunity to attend the Immersion institutes. In the 2nd and 3rd years of the study, these effects interact with the deployment of FOSS, but they remain causal estimates of the Immersion training effect in the presence of the FOSS substitute. That is, we assume that the scientific inquiry teaching practices in the Immersion schools would have resembled those of the comparison schools in the absence of institute training, and therefore any observed differences are effects of the opportunity to send teachers to the Immersion institute.</p>
<p>For the quasiexperimental analysis, we interpret the Year 2 and Year 3 coefficients as longitudinal estimates of the effect of the FOSS curriculum and training on the comparison schools. The observers were present in the fourth-grade classrooms prior to the adoption of FOSS, which establishes a baseline rate of scientific inquiry teaching in these schools. Indeed, in <xref ref-type="table" rid="table4-0162373712461851">Table 4</xref>, we see that the comparison schools had fewer observed instances of scientific inquiry in the 1st year of the study. We assume that the teaching practices in the comparison schools would have remained the same in the 2nd year, which allows us to attribute any observed changes in teaching practices over time to the introduction of FOSS. The observers were not in the fifth-grade classrooms in the 1st year, so the Year 3 coefficients combine the effect of time with a change in the grade observed. We assume that the prevalence of inquiry teaching and the relative distribution of the inquiry features do not fundamentally differ in fifth grade, but we acknowledge this is a limitation in the study design. In sum, the Immersion coefficients are the experimental estimates of the Immersion professional development initiative, and the year coefficients are the quasiexperimental estimates of the systemwide rollout of the FOSS professional development initiative in fourth grade between Year 1 and Year 2, with an additional change to fifth-grade classrooms in Year 3. Because the year coefficients are fully interacted with the treatment coefficients in the model, and because FOSS was randomly preceded by the Immersion initiative in half the schools, the model yields separate estimates of the effects of Immersion and FOSS as well as the combination.</p>
</sec>
</sec>
</sec>
<sec id="section10-0162373712461851" sec-type="results">
<title>Results</title>
<sec id="section11-0162373712461851">
<title>Any Scientific Inquiry</title>
<p>We start with the experimental results and our first research question: whether the professional development initiative changed the prevalence of scientific inquiry in the observed lessons, both overall (Model 1) and in the different years of the study (Model 2). For the <italic>any feature</italic> outcome in <xref ref-type="table" rid="table5-0162373712461851">Table 5</xref>, Models 1 and 2 show that the offer to attend the Immersion institute increased the log odds of observing some form of scientific inquiry in a lesson. In Model 1, the Immersion coefficient is 0.611, which corresponds to an odds ratio of 1.84, or that the odds of observing any scientific inquiry was 84% higher in a lesson from an Immersion school than a lesson from a comparison school. As we expect, longer observations and lessons taught by SLTs are more likely to demonstrate some features of scientific inquiry.</p>
<table-wrap id="table5-0162373712461851" position="float">
<label>Table 5</label>
<caption><p>Results From Logistic Regression Models Predicting the Evidence of Science Inquiry in Classroom Observations</p></caption>
<graphic alternate-form-of="table5-0162373712461851" xlink:href="10.3102_0162373712461851-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">Any Feature<hr/></th>
<th align="center" colspan="2">Feature 1<hr/></th>
<th align="center" colspan="2">Feature 2<hr/></th>
<th align="center" colspan="2">Feature 3<hr/></th>
<th align="center" colspan="2">Feature 4<hr/></th>
<th align="center" colspan="2">Feature 5<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Model 1</th>
<th align="center">Model 2</th>
<th align="center">Model 1</th>
<th align="center">Model 2</th>
<th align="center">Model 1</th>
<th align="center">Model 2</th>
<th align="center">Model 1</th>
<th align="center">Model 2</th>
<th align="center">Model 1</th>
<th align="center">Model 2</th>
<th align="center">Model 1</th>
<th align="center">Model 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Immersion school</td>
<td>0.611<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.922<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.063</td>
<td>0.640<xref ref-type="table-fn" rid="table-fn5-0162373712461851">+</xref></td>
<td>0.391<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.459</td>
<td>0.466<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.716<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>−0.156</td>
<td>0.457</td>
<td>0.153</td>
<td>0.128</td>
</tr>
<tr>
<td/>
<td>(0.253)</td>
<td>(0.415)</td>
<td>(0.191)</td>
<td>(0.339)</td>
<td>(0.166)</td>
<td>(0.328)</td>
<td>(0.194)</td>
<td>(0.362)</td>
<td>(0.275)</td>
<td>(0.689)</td>
<td>(0.294)</td>
<td>(0.506)</td>
</tr>
<tr>
<td>School pretest</td>
<td>−0.011</td>
<td>−0.014</td>
<td>0.003</td>
<td>0.002</td>
<td>−0.034<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>−0.033<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>−0.020</td>
<td>−0.022</td>
<td>−0.019</td>
<td>−0.019</td>
<td>−0.024</td>
<td>−0.027</td>
</tr>
<tr>
<td/>
<td>(0.017)</td>
<td>(0.018)</td>
<td>(0.014)</td>
<td>(0.014)</td>
<td>(0.012)</td>
<td>(0.012)</td>
<td>(0.015)</td>
<td>(0.015)</td>
<td>(0.022)</td>
<td>(0.022)</td>
<td>(0.025)</td>
<td>(0.025)</td>
</tr>
<tr>
<td>Lesson taught by SLT</td>
<td>0.443<xref ref-type="table-fn" rid="table-fn5-0162373712461851">+</xref></td>
<td>0.478<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.348<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.389<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td>0.245</td>
<td>0.233</td>
<td>−0.160</td>
<td>−0.152</td>
<td>0.287</td>
<td>0.303</td>
<td>0.212</td>
<td>0.266</td>
</tr>
<tr>
<td/>
<td>(0.234)</td>
<td>(0.241)</td>
<td>(0.170)</td>
<td>(0.178)</td>
<td>(0.164)</td>
<td>(0.166)</td>
<td>(0.169)</td>
<td>(0.172)</td>
<td>(0.238)</td>
<td>(0.242)</td>
<td>(0.290)</td>
<td>(0.295)</td>
</tr>
<tr>
<td>Lesson length</td>
<td>0.170<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.140<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.141<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.108<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.154<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.165<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.105<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.096<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.138<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.115<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.126<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td>0.155<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
</tr>
<tr>
<td/>
<td>(0.040)</td>
<td>(0.041)</td>
<td>(0.029)</td>
<td>(0.030)</td>
<td>(0.028)</td>
<td>(0.029)</td>
<td>(0.027)</td>
<td>(0.028)</td>
<td>(0.037)</td>
<td>(0.039)</td>
<td>(0.043)</td>
<td>(0.045)</td>
</tr>
<tr>
<td>Year 2</td>
<td/>
<td>1.037<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td/>
<td>1.823<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td/>
<td>−0.208</td>
<td/>
<td>0.631<xref ref-type="table-fn" rid="table-fn5-0162373712461851">+</xref></td>
<td/>
<td>1.510<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td/>
<td>−0.905<xref ref-type="table-fn" rid="table-fn5-0162373712461851">+</xref></td>
</tr>
<tr>
<td/>
<td/>
<td>(0.388)</td>
<td/>
<td>(0.336)</td>
<td/>
<td>(0.311)</td>
<td/>
<td>(0.345)</td>
<td/>
<td>(0.594)</td>
<td/>
<td>(0.544)</td>
</tr>
<tr>
<td>Immersion × Year 2</td>
<td/>
<td>−0.527</td>
<td/>
<td>−0.547</td>
<td/>
<td>−0.086</td>
<td/>
<td>−0.446</td>
<td/>
<td>−0.611</td>
<td/>
<td>−0.076</td>
</tr>
<tr>
<td/>
<td/>
<td>(0.600)</td>
<td/>
<td>(0.454)</td>
<td/>
<td>(0.440)</td>
<td/>
<td>(0.452)</td>
<td/>
<td>(0.768)</td>
<td/>
<td>(0.732)</td>
</tr>
<tr>
<td>Year 3</td>
<td/>
<td>1.031<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td/>
<td>1.960<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td/>
<td>−0.399</td>
<td/>
<td>0.889<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td/>
<td>1.701<xref ref-type="table-fn" rid="table-fn5-0162373712461851">**</xref></td>
<td/>
<td>−0.515</td>
</tr>
<tr>
<td/>
<td/>
<td>(0.362)</td>
<td/>
<td>(0.323)</td>
<td/>
<td>(0.291)</td>
<td/>
<td>(0.329)</td>
<td/>
<td>(0.584)</td>
<td/>
<td>(0.512)</td>
</tr>
<tr>
<td>Immersion × Year 3</td>
<td/>
<td>−0.349</td>
<td/>
<td>−0.867<xref ref-type="table-fn" rid="table-fn5-0162373712461851">*</xref></td>
<td/>
<td>−0.149</td>
<td/>
<td>−0.127</td>
<td/>
<td>−0.680</td>
<td/>
<td>0.060</td>
</tr>
<tr>
<td/>
<td/>
<td>(0.580)</td>
<td/>
<td>(0.433)</td>
<td/>
<td>(0.416)</td>
<td/>
<td>(0.435)</td>
<td/>
<td>(0.754)</td>
<td/>
<td>(0.688)</td>
</tr>
<tr>
<td>Log likelihood</td>
<td>−262.742</td>
<td>−256.452</td>
<td>−442.264</td>
<td>−408.824</td>
<td>−433.770</td>
<td>−431.144</td>
<td>−447.324</td>
<td>−439.350</td>
<td>−269.440</td>
<td>−261.007</td>
<td>−176.048</td>
<td>−172.994</td>
</tr>
<tr>
<td>χ<sup>2</sup></td>
<td>44.459</td>
<td>53.521</td>
<td>43.622</td>
<td>89.376</td>
<td>68.690</td>
<td>72.444</td>
<td>47.871</td>
<td>59.845</td>
<td>41.812</td>
<td>53.041</td>
<td>49.693</td>
<td>52.896</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0162373712461851">
<p><italic>Note</italic>. 711 observed lessons from 73 schools. Lesson length in 5-minute segments and centered on the sample mean. Cluster-adjusted standard errors in parentheses. Controls for local district randomization block and intercept coefficients not shown. SLT = science lead teacher.</p>
</fn>
<fn id="table-fn5-0162373712461851">
<label>+</label>
<p><italic>p</italic> &lt; .1. *<italic>p</italic> &lt; .05. **<italic>p</italic> &lt; .01.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Accounting for the different years of the study (Model 2) shows that the magnitude of the treatment difference changed over time. In these models, the Immersion coefficient describes the difference between the Immersion schools and the comparison schools in Year 1; adding the year estimates and the interaction terms produces contrasts for different years.<sup><xref ref-type="fn" rid="fn7-0162373712461851">7</xref></sup> This model reveals that the contrast between the experimental conditions was very large in the 1st year of the study (0.922, odds ratio = 2.51) and smaller in the subsequent two years (0.922 – 0.527 = 0.395 in Year 2, odds ratio = 1.48; 0.922 – 0.349 = 0.573 in Year 3, odds ratio = 1.75). The quasiexperimental estimates for the differences from Year 1 to Year 2 (1.037, odds ratio = 2.82) and Year 1 to Year 3 (1.031, odds ratio = 2.80) suggest that evidence of scientific inquiry increased substantially in the comparison schools after the 1st year, thereby attenuating the difference between lessons from the Immersion and comparison schools in any form of scientific inquiry.</p>
</sec>
<sec id="section12-0162373712461851">
<title>Features of Scientific Inquiry</title>
<p>To address our second research question—how teaching practice changed—the subsequent models investigate each feature of scientific inquiry to describe how individual features responded to the professional development initiatives. The results suggest that the increase in the overall level of scientific inquiry was limited to a subset of the features of inquiry. The pooled data in Model 1 for Feature 1 suggest that the two experimental conditions were comparable overall, but Model 2 suggests a dynamic situation. The Immersion coefficient in Model 2—representing the experimental contrast in the 1st year—is large (0.640, odds ratio = 1.90), with a <italic>p</italic> value of 0.059. The quasiexperimental year coefficients are larger still (1.821, odds ratio = 6.19; and 1.960, odds ratio = 7.10), suggesting that a lesson from a comparison school was 6 or 7 times more likely to reveal evidence of scientific questioning in the 2nd and 3rd years of the study than in the 1st year. The interaction of the treatment with year suggests that there was no difference between Immersion and comparison school in the subsequent years of the study; the experimental difference is apparent only in the 1st year, but the increase in Feature 1 in the comparison schools eroded the initial difference. We take this to mean that both professional development interventions increased the amount of questioning that occurred in LAUSD classrooms.</p>
<p>In contrast to Feature 1, the experimental estimate for Feature 2 (“Learner gives priority to evidence in responding to questions”) moderates less across years. Overall, the Model 1 estimate (0.391, odds ratio = 1.48) suggests that lessons from the Immersion schools were more likely to show evidence of Feature 2, but the Model 2 experimental estimate is not statistically significant because of a larger standard error. The quasiexperimental estimates and interaction terms show no evidence that Feature 2 responded to the introduction of FOSS.</p>
<p>Both Immersion and FOSS appear to have influenced Feature 3 (“Learner formulates explanations from evidence”). The overall experimental estimate in Model 1 (0.466, odds ratio = 1.59) is similar in magnitude to Feature 2; the experimental estimate for Year 1 is larger still (0.719, odds ratio = 2.05) and is statistically significant. The quasiexperimental contrast in the comparison group between Year 1 and Year 3 is large enough to be statistically significant (0.889, odds ratio = 2.43) and is marginally significant between Year 1 and Year 2.</p>
<p>There is no evidence of an experimental impact in Feature 4 (“Learner connections explanations to scientific knowledge”). There is quasiexperimental evidence, however, of an increase in Feature 4 between the 1st and subsequent years of the study. The year coefficients for Feature 4 are quite large (1.510, odds ratio = 4.53; 1.701, odds ratio = 5.48), but the basis for this substantial increase is quite low: Only 4% of comparison classrooms showed evidence of Feature 4 in Year 1 (see <xref ref-type="table" rid="table4-0162373712461851">Table 4</xref>). Neither professional development initiative appeared to have an impact on Feature 5 (“Learner communicates and justifies explanations”).</p>
</sec>
<sec id="section13-0162373712461851">
<title>Professional Development Observations</title>
<p>To investigate our third research question—how the classroom observation findings relate to teachers’ professional development experiences—we turn to the coded observations of six of the Immersion institutes. The results are reported in <xref ref-type="table" rid="table6-0162373712461851">Table 6</xref>. We wish to know whether the relative emphasis during the workshops on the different features of inquiry resembles the experimental impact estimates. The workshops consisted of two types of activities: periods when the facilitators modeled the Immersion unit lessons to teachers assuming the role of students and periods when facilitators engaged teachers in reflective discussions about implementing the lessons. We focus on the periods when the teachers behaved as students, which on average consisted of 8.29 segments, or slightly more than 2 hours each day.<sup><xref ref-type="fn" rid="fn8-0162373712461851">8</xref></sup> In light of the analysis of the individual features of inquiry, we are most interested in how the five inquiry features were presented to the teachers when they assumed the role of students.</p>
<table-wrap id="table6-0162373712461851" position="float">
<label>Table 6</label>
<caption><p>Features of Inquiry Present in Science Immersion Professional Development Institutes</p></caption>
<graphic alternate-form-of="table6-0162373712461851" xlink:href="10.3102_0162373712461851-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Variable</th>
<th align="center">Mean</th>
</tr>
</thead>
<tbody>
<tr>
<td>Observation characteristics</td>
<td/>
</tr>
<tr>
<td> Observation length (min)</td>
<td>317.46</td>
</tr>
<tr>
<td> Coded segments</td>
<td>21.04</td>
</tr>
<tr>
<td> Coded segments with teacher as “student learner”</td>
<td>8.29</td>
</tr>
<tr>
<td>For teacher-as-student-learner segments</td>
<td/>
</tr>
<tr>
<td> Feature 1</td>
<td>1.54</td>
</tr>
<tr>
<td> Feature 2</td>
<td>3.39</td>
</tr>
<tr>
<td> Feature 3</td>
<td>3.04</td>
</tr>
<tr>
<td> Feature 4</td>
<td>1.21</td>
</tr>
<tr>
<td> Feature 5</td>
<td>0.93</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-0162373712461851">
<p><italic>Note</italic>. Twenty-nine professional development sessions from six Science Immersion institutes observed (three fourth-grade institute in summer/fall 2006, one fifth-grade institute in 2007, and two fifth-grade institutes in 2008). Each coded segment is 15 minutes long.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Each 15-minute segment covered one or more of the features of inquiry. Feature 1 was prominent during the reflective segments of the day (not shown), but the segments during which the teachers were treated as students emphasized Feature 2 and Feature 3 (3.39 and 3.04 segments per day, respectively), and Feature 4 and Feature 5 were not often present (1.21 and 0.93 segments per day, respectively). Although we can make only limited inferences from these data, we do note that the two features that were most frequently present in the Immersion institutes—Feature 2 and Feature 3—are the same features for which we observe statistically significant experimental treatment estimates. We take this as suggestive evidence that the impact in the classroom corresponds to the emphasis placed in the professional development. Moreover, the fact that the professional development facilitators modeled Feature 4 and Feature 5 approximately once each day suggests that the features emphasizing conceptual connections and communicating scientific knowledge were difficult not only for the teachers but also for the facilitators to implement in practice.</p>
</sec>
</sec>
<sec id="section14-0162373712461851" sec-type="discussion">
<title>Discussion</title>
<p>This article investigated science instruction in LAUSD classrooms to document the impact of two different professional development initiatives on scientific inquiry instruction: Immersion and FOSS. The experimental and quasiexperimental analyses using any feature of scientific inquiry as an outcome provide rigorous evidence that teaching practices can be influenced by professional development at a large scale in a setting such as LAUSD. This article also illustrates the value of directly observing the relationship between intervention elements and teaching practices to inform the achievement findings in a randomized cluster trial. Particularly in the presence of negative or null effects, it is vital to examine the design and delivery of training to teachers as well as classroom instruction in order to interpret student achievement findings and design more effective interventions.</p>
<p>Our first research question was whether the two professional development workshops changed teaching at all. We found evidence that both initiatives changed teaching practice. The experimental analysis showed that there was more evidence of scientific inquiry observed in lessons from the schools that were randomly selected to send teachers to the Immersion institutes. Not all of the observed teachers attended an Immersion institute, but the lessons from the Immersion schools were nearly twice as likely to show evidence of any kind of scientific inquiry relative to lessons from the Immersion schools across all 3 years of the study (odds ratio = 1.84). This contrast was strongest in the 1st year (odds ratio = 2.51). Sending a small number of teachers to an intensive professional development workshop changed teaching practice. The experimental contrast weakened in the subsequent years of the study not because scientific inquiry was no longer apparent in lessons from the Immersion schools but rather because scientific inquiry was more apparent in the lessons from the comparison schools after the universal FOSS training was introduced (Year 2 odds ratio = 2.82; Year 3 odds ratio = 2.80). One-day workshops, such as the FOSS training, have been characterized as having little value (<xref ref-type="bibr" rid="bibr24-0162373712461851">Garet et al., 2001</xref>; <xref ref-type="bibr" rid="bibr37-0162373712461851">Little, 1993</xref>), but the odds of observing some form of scientific inquiry in the observed classrooms nearly tripled after every elementary teacher in the district was provided with at least 1 day of training. In sum, both professional development initiatives changed teaching practice.</p>
<p>This finding is tempered by the individual results for the five essential features of inquiry we used to answer our second research question (<xref ref-type="bibr" rid="bibr45-0162373712461851">NRC, 1996</xref>, <xref ref-type="bibr" rid="bibr46-0162373712461851">2000</xref>). Using an observational tool that records the essential features of inquiry, we were able to see that the full cycle of inquiry was not evident in the professional development sessions or in the subsequently observed lessons. There is some evidence that the Immersion initiative doubled the extent to which students asked scientific questions (Feature 1) in the 1st year (odds ratio = 1.90, <italic>p</italic> = .059). The Immersion professional development increased the extent to which students gave priority to evidence to answer questions (Feature 2). In the 1st year, the observers were twice as likely to observe students forming explanations from evidence (Feature 3; odds ratio = 2.05); this contrast was smaller but still substantial in the pooled data (odds ratio = 1.59). There is little evidence, however, that the Immersion intervention influenced the extent to which students connected these explanations to scientific knowledge (Feature 4) and no evidence that they communicated or justified these explanations (Feature 5). Notably, teachers were exposed most frequently in the Immersion institutes to Features 1, 2, and 3, with Features 2 and 3 being most prominent (observed in three segments per day).</p>
<p>In the years after the districtwide FOSS training, Features 1, 3, and 4 were more prevalent (Year 2 odds ratios = 6.19, 2.43, and 4.53, respectively). The odds of observing scientific questioning (Feature 1) were 6 times higher after the FOSS training, which is a dramatic increase. The odds of observing students connect explanations to scientific knowledge (Feature 4) also increased substantially, but the absolute level remained low. There is no evidence of an impact of FOSS on Feature 2 and Feature 5. Schools in which Immersion was followed by FOSS had higher levels of Feature 2 than in schools in which FOSS was introduced alone, but Feature 5 increased under no circumstances. Future research should look more closely at the differences between open inquiry and guided inquiry curricula and professional development. On the basis of these two examples, open inquiry (Immersion) seems to promote the use of evidence, and guided inquiry (FOSS) promotes questioning and, importantly, connecting evidence to scientific knowledge.</p>
<p>On the whole and despite substantial differences in curriculum design and deployment, professional development in either Immersion or FOSS—and for some Immersion school teachers in later years, both—stimulated teachers to initiate scientific inquiry but fell short of exposing students to all of its elements in a way consistent with the original vision of scientific inquiry described in the NSES. Both interventions emphasized questioning and gathering evidence, but no regime stimulated all of the features of inquiry at once, and under neither did students communicate and justify their explanations. In light of these findings, the <xref ref-type="bibr" rid="bibr47-0162373712461851">NRC’s (2012)</xref> current effort to redefine scientific inquiry more concretely seems appropriate, but reframing standards will bear fruit only if teachers can successfully practice them with their students.</p>
<p>Although we do not have evidence that engaging in all of the features of scientific inquiry will improve student achievement, we are concerned that partial exposure to scientific inquiry may be detrimental. After all, students in the Immersion schools performed worse on standardized tests than students in the comparison schools in the 1st year of the study (<xref ref-type="bibr" rid="bibr8-0162373712461851">Borman et al., 2008</xref>). Conducting empirical forays without connecting the results back to scientific concepts or requiring students to articulate their conceptual understanding is likely to leave teachers and students unclear as to the implications of their investigations and may not lead to learning (<xref ref-type="bibr" rid="bibr33-0162373712461851">Kirschner et al., 2006</xref>). Future research should investigate how the individual features of scientific inquiry influence student achievement as well as other outcomes, such as motivation or interest in science.</p>
<p>We suspect that the similar response of LAUSD fourth- and fifth-grade teachers to these two workshops on scientific inquiry reflects the challenges of activity-based learner-centered instruction as well as the LAUSD setting. As others as have found (e.g., <xref ref-type="bibr" rid="bibr52-0162373712461851">Pane et al., 2010</xref>), learner-centered instruction is difficult. One reason may be that learner-centered instruction often is designed around activities. These activities are exciting but may not lend themselves to all of the features or practices of scientific inquiry. In a detailed video study of teaching practices in high school engineering classrooms, <xref ref-type="bibr" rid="bibr57-0162373712461851">Walkington and colleagues (Walkington, Nathan, Wolfgram, Alibali, &amp; Srisurichan, in press</xref>) find that students and teachers tend to miss opportunities for “reflection and integration of ideas” when engaging in learner-centered activities. Moreover, they caution against “activity for activity’s own sake.” Activity of this sort is what <xref ref-type="bibr" rid="bibr33-0162373712461851">Kirschner and his colleagues (2006)</xref> warn does not lead to learning. We suspect a similar phenomenon in our study may account for the relative deemphasis of Feature 4 and Feature 5 in our study and propose that curriculum developers not only heed the specificity of the new K–12 framework (<xref ref-type="bibr" rid="bibr47-0162373712461851">NRC, 2012</xref>) but also follow the example of <xref ref-type="bibr" rid="bibr4-0162373712461851">Barab and colleagues (2007)</xref> and redesign curricula to expose students to more challenging and integrating experiences. Furthermore, our observations of the professional development sessions suggest that the facilitators also found it challenging to present Feature 4 and Feature 5 to the teachers. It may be more reasonable to expect teachers to reproduce the experience they had in training than to rebalance the distribution of inquiry features they introduce to students.</p>
<p>In follow-up interviews, teachers reported a related constraint: Science was not an instructional priority relative to literacy and mathematics, and consequently, they had little classroom time for science. Reflection and integration require both guidance and time. Inquiry approaches may not provide sufficient guidance to students or teachers, and time constraints limited classroom opportunities to complete the cycle of scientific inquiry. Both the Immersion and the FOSS initiatives were subject to these constraints, which we think contribute—along with the difficulty of the task and the training teachers were given—to the limited implementation of the cycle of scientific inquiry. There remains much to be understood about how professional development initiatives translate into classrooms, such as those in LAUSD, but the responsibility for achieving a new vision of scientific inquiry may lie not with teachers alone but with curriculum developers, facilitators, and administrators as well.</p>
</sec>
</body>
<back>
<ack>
<p>The authors are grateful for comments on prior drafts from Jill Bowdon, Sarah Bruch, and Paul Hanselman and for research assistance from Alexan Chalaganyan, Erika Hernandez, Phil Selvey, Ashley Turner, and Sun Young Yoon.</p>
</ack>
<fn-group>
<fn fn-type="other">
<label>Authors’ Note</label>
<p>A previous version of this article was presented at the 2011 Annual Meeting of the American Educational Research Association, New Orleans, Louisiana, and at the Interdisciplinary Training Program in the Education Sciences at the University of Wisconsin-Madison.</p>
</fn>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: Research for this article was supported by grants from the National Science Foundation (Award No. ESI-0554566) and the Institute of Education Sciences at the U.S. Department of Education (Grant No. R305C050055) to the Wisconsin Center for Education Research, School of Education, University of Wisconsin-Madison. Findings and conclusions in the article do not necessarily represent the views of the supporting agencies.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0162373712461851">
<label>1.</label>
<p>The new practices for K–12 science are (a) asking questions, (b) developing and using models, (c) planning and carrying out investigations, (d) analyzing and interpreting data, (e) using mathematics and computational thinking, (f) constructing explanations, (g) engaging in argument from evidence, and (h) obtaining, evaluating, and communicating information (National Research Council <xref ref-type="bibr" rid="bibr47-0162373712461851">[NRC], 2012</xref>, Box 3-1).</p>
</fn>
<fn fn-type="other" id="fn2-0162373712461851">
<label>2.</label>
<p>It is unclear to us how compliance with the request to observe a science lesson is related to teaching practice. If teachers who use scientific inquiry methods are more likely to consent to be observed, then our data overestimate the amount of inquiry taking place. This would only introduce bias to our estimation if the overestimation differed between the Immersion and comparison schools.</p>
</fn>
<fn fn-type="other" id="fn3-0162373712461851">
<label>3.</label>
<p>Conventional measures of interrater reliability, such as Cronbach’s alpha or the interclass correlation, are not appropriate for ordinal data (<xref ref-type="bibr" rid="bibr28-0162373712461851">Jakobsson &amp; Westergren, 2005</xref>).</p>
</fn>
<fn fn-type="other" id="fn4-0162373712461851">
<label>4.</label>
<p>The features of inquiry can be further refined by the extent to which the activity is student or teacher centered, yielding four subcategories of each feature of inquiry (e.g., 1A through 1D; <xref ref-type="bibr" rid="bibr46-0162373712461851">NRC, 2000</xref>, <xref ref-type="table" rid="table2-0162373712461851">Table 2</xref><xref ref-type="table" rid="table3-0162373712461851"/><xref ref-type="table" rid="table4-0162373712461851"/><xref ref-type="table" rid="table5-0162373712461851"/>-<xref ref-type="table" rid="table6-0162373712461851">6</xref>).</p>
</fn>
<fn fn-type="other" id="fn5-0162373712461851">
<label>5.</label>
<p>We also used a zero-inflated negative binomial (ZINB) model to estimate the count data (number of segments per lesson). The ZINB model produced similar results to the logistic models, so we present the simpler data and models here. Descriptive statistics for the count data and results of the ZINB models are available from the authors by request.</p>
</fn>
<fn fn-type="other" id="fn6-0162373712461851">
<label>6.</label>
<p>We used the xtmelogit package in Stata (Version 12).</p>
</fn>
<fn fn-type="other" id="fn7-0162373712461851">
<label>7.</label>
<p>For example, the estimate of contrast between the Immersion and comparison schools in Year 2 is the Immersion coefficient plus the Immersion × Year 2 interaction (0.922 – 0.527 = 0.395), and the estimate of change in the Immersion schools from Year 1 to Year 2 is the Year 2 coefficient plus the Immersion × Year 2 interaction (1.037 – 0.527 = 0.510).</p>
</fn>
<fn fn-type="other" id="fn8-0162373712461851">
<label>8.</label>
<p>Coding the reflective periods as well increases the prevalence of all of the inquiry features somewhat and increases the count of Feature 1 substantially. The teachers still experienced Feature 4 and Feature 5 relatively infrequently.</p>
</fn>
</fn-group>
</notes>
<bio>
<title>Authors</title>
<p>JEFFREY GRIGG is a doctoral student in the Department of Sociology at the University of Wisconsin-Madison. His research interests include educational inequality and causal inference in real-world settings.</p>
<p>KIMBERLE A. KELLY is a Lecturer in the Department of Psychology at the University of Southern California. She has spent the last ten years directing research and program evaluation in STEM initiatives focused on improving teaching and learning in science.</p>
<p>ADAM GAMORAN is the John D. MacArthur Professor of Sociology and Educational Policy Studies and director of the Wisconsin Center for Education Research at the University of Wisconsin-Madison. His research focuses on educational inequality and school reform.</p>
<p>GEOFFREY D. BORMAN is Professor of Education and Sociology at the University of Wisconsin-Madison. His areas of research include experimental and quasi-experimental design, educational policy, and educational inequality.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Akerson</surname><given-names>V. L.</given-names></name>
<name><surname>Hanusci</surname><given-names>D. L.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Teaching nature of science through inquiry: Results of a 3-year professional development program</article-title>. <source>Journal of Research in Science Teaching</source>, <volume>44</volume>(<issue>5</issue>), <fpage>653</fpage>–<lpage>680</lpage>.</citation>
</ref>
<ref id="bibr2-0162373712461851">
<citation citation-type="book">
<collab>American Association for the Advancement of Science</collab>. (<year>1993</year>). <source>Benchmarks for science literacy</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ball</surname><given-names>D. L.</given-names></name>
<name><surname>Cohen</surname><given-names>D. K.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Developing practice, developing practitioners: Toward a practice-based theory of professional education</article-title>. In <person-group person-group-type="editor">
<name><surname>Darling-Hammond</surname><given-names>L.</given-names></name>
<name><surname>Sykes</surname><given-names>G.</given-names></name>
</person-group> (Eds.), <source>Teaching as the learning profession</source> (pp. <fpage>3</fpage>–<lpage>31</lpage>). <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr4-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barab</surname><given-names>S.</given-names></name>
<name><surname>Zuiker</surname><given-names>S.</given-names></name>
<name><surname>Warren</surname><given-names>S.</given-names></name>
<name><surname>Hickey</surname><given-names>D.</given-names></name>
<name><surname>Ingram-Goble</surname><given-names>A.</given-names></name>
<name><surname>Kwon</surname><given-names>E-J.</given-names></name>
<name><surname>. . . Herring</surname><given-names>S. C.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Situationally embodied curriculum: Relating formalisms and contexts</article-title>. <source>Science Education</source>, <volume>91</volume>(<issue>5</issue>), <fpage>750</fpage>–<lpage>782</lpage>.</citation>
</ref>
<ref id="bibr5-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Barr</surname><given-names>R.</given-names></name>
<name><surname>Dreeben</surname><given-names>R.</given-names></name>
</person-group> (<year>1983</year>). <source>How schools work</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr6-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Birman</surname><given-names>B.</given-names></name>
<name><surname>Le Floch</surname><given-names>K. C.</given-names></name>
<name><surname>Klekotka</surname><given-names>A.</given-names></name>
<name><surname>Ludwig</surname><given-names>M.</given-names></name>
<name><surname>Taylor</surname><given-names>J.</given-names></name>
<name><surname>Walters</surname><given-names>K.</given-names></name>
<name><surname>. . . O’Day</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <source>State and local implementation of the No Child Left Behind Act: Vol. 2. Teacher quality under NCLB: Interim report</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Department of Education; Office of Planning, Evaluation, and Policy Development; Policy and Program Studies Service</publisher-name>.</citation>
</ref>
<ref id="bibr7-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Borko</surname><given-names>H.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Professional development and teacher learning: Mapping the terrain</article-title>. <source>Educational Researcher</source>, <volume>33</volume>(<issue>8</issue>), <fpage>3</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr8-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Borman</surname><given-names>G.D.</given-names></name>
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
<name><surname>Bowdon</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>A randomized trial of teacher development in elementary science: First-year achievement effects</article-title>. <source>Journal of Research on Educational Effectiveness</source>, <volume>1</volume>(<issue>4</issue>), <fpage>237</fpage>–<lpage>264</lpage>.</citation>
</ref>
<ref id="bibr9-0162373712461851">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Borman</surname><given-names>G.D.</given-names></name>
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
<name><surname>Bowdon</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>, <month>April</month>). <source>The final outcomes of a school-randomized trial on the effects of professional development on student achievement in elementary science</source>. <conf-name>Paper presented at the annual meeting of the American Educational Research Association</conf-name>, <conf-loc>Denver, CO</conf-loc>.</citation>
</ref>
<ref id="bibr10-0162373712461851">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bowdon</surname><given-names>J.</given-names></name>
<name><surname>Borman</surname><given-names>G.D.</given-names></name>
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
</person-group> (<year>2009</year>, <month>April</month>). <source>Growing capacity or dissipation? Second-year outcomes of a school-randomized trial of the effects of professional development on student achievement in elementary science</source>. <conf-name>Paper presented at the annual meeting of the American Educational Research Association</conf-name>, <conf-loc>San Diego, CA</conf-loc>.</citation>
</ref>
<ref id="bibr11-0162373712461851">
<citation citation-type="gov">
<collab>California Department of Education</collab>. (<year>2007</year>). <source>2006 science primary adoption report</source>. <publisher-loc>Sacramento, CA</publisher-loc>: <publisher-name>California Department of Education Press</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.cde.ca.gov/ci/sc/im/documents/sciprimadoptrep06f.pdf">http://www.cde.ca.gov/ci/sc/im/documents/sciprimadoptrep06f.pdf</ext-link></citation>
</ref>
<ref id="bibr12-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carlisle</surname><given-names>J.</given-names></name>
<name><surname>Kelcey</surname><given-names>B.</given-names></name>
<name><surname>Berebitsky</surname><given-names>D.</given-names></name>
<name><surname>Phelps</surname><given-names>G.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Embracing the complexity of instruction: A study of the effects of teachers’ instruction on students’ reading comprehension</article-title>. <source>Scientific Studies of Reading</source>, <volume>15</volume>(<issue>5</issue>), <fpage>409</fpage>–<lpage>439</lpage>.</citation>
</ref>
<ref id="bibr13-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Correnti</surname><given-names>R.</given-names></name>
</person-group> (<year>2007</year>). <article-title>An empirical investigation of professional development effects on literacy instruction using daily logs</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>29</volume>(<issue>4</issue>), <fpage>239</fpage>–<lpage>261</lpage>.</citation>
</ref>
<ref id="bibr14-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Crawford</surname><given-names>B. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Learning to teach science as inquiry in the rough and tumble of practice</article-title>. <source>Journal of Research in Science Teaching</source>, <volume>44</volume>(<issue>4</issue>), <fpage>613</fpage>–<lpage>642</lpage>.</citation>
</ref>
<ref id="bibr15-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Davis</surname><given-names>E. A.</given-names></name>
<name><surname>Petish</surname><given-names>D.</given-names></name>
<name><surname>Smithey</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Challenges new science teachers face</article-title>. <source>Review of Educational Research</source>, <volume>76</volume>(<issue>4</issue>), <fpage>607</fpage>–<lpage>651</lpage>.</citation>
</ref>
<ref id="bibr16-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Desimone</surname><given-names>L.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Improving impact studies of teachers’ professional development: Toward better conceptualizations and measures</article-title>. <source>Educational Researcher</source>, <volume>38</volume>(<issue>3</issue>), <fpage>181</fpage>–<lpage>199</lpage>.</citation>
</ref>
<ref id="bibr17-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Desimone</surname><given-names>L. M.</given-names></name>
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
<name><surname>Garet</surname><given-names>M. S.</given-names></name>
<name><surname>Yoon</surname><given-names>K. S.</given-names></name>
<name><surname>Birman</surname><given-names>B. F.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Effects of professional development on teachers’ instruction: Results from a three-year longitudinal study</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>24</volume>(<issue>2</issue>), <fpage>81</fpage>–<lpage>112</lpage>.</citation>
</ref>
<ref id="bibr18-0162373712461851">
<citation citation-type="web">
<collab>Full Option Science System</collab>. (<year>2002</year>). <source>NSES/FOSS correlation, grades K–4</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://lhsfoss.org/scope/correlations/pdfs/FOSS.NSES_K-4_8_20_02.pdf">http://lhsfoss.org/scope/correlations/pdfs/FOSS.NSES_K-4_8_20_02.pdf</ext-link></citation>
</ref>
<ref id="bibr19-0162373712461851">
<citation citation-type="web">
<collab>Full Option Science System</collab>. (<year>2007</year>). <source>NSES/FOSS correlation, grades 5–8</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://lhsfoss.org/scope/correlations/pdfs/NSES5-8_10.23.07.pdf">http://lhsfoss.org/scope/correlations/pdfs/NSES5-8_10.23.07.pdf</ext-link></citation>
</ref>
<ref id="bibr20-0162373712461851">
<citation citation-type="web">
<collab>Full Option Science System</collab>. (<year>2009</year>). <source>What is FOSS?</source> Retrieved from <ext-link ext-link-type="uri" xlink:href="http://lhsfoss.org/scope/correlations/pdfs/NSES5-8_10.23.07.pdf">http://lhsfoss.org/scope/correlations/pdfs/NSES5-8_10.23.07.pdf</ext-link></citation>
</ref>
<ref id="bibr21-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
<name><surname>Anderson</surname><given-names>C. W.</given-names></name>
<name><surname>Quiroz</surname><given-names>P. A.</given-names></name>
<name><surname>Secada</surname><given-names>W. G.</given-names></name>
<name><surname>Williams</surname><given-names>T.</given-names></name>
<name><surname>Ashmann</surname><given-names>S.</given-names></name>
</person-group> (<year>2003</year>). <source>Transforming teaching in math and science: How schools and districts can support change</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Teachers College Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
<name><surname>Nystrand</surname><given-names>M.</given-names></name>
<name><surname>Berends</surname><given-names>M.</given-names></name>
<name><surname>LePore</surname><given-names>P.C.</given-names></name>
</person-group> (<year>1995</year>). <article-title>An organizational analysis of the effects of ability grouping</article-title>. <source>American Educational Research Journal</source>, <volume>32</volume>(<issue>4</issue>), <fpage>687</fpage>–<lpage>715</lpage>.</citation>
</ref>
<ref id="bibr23-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gamoran</surname><given-names>A.</given-names></name>
<name><surname>Secada</surname><given-names>W. G.</given-names></name>
<name><surname>Marrett</surname><given-names>C. B.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The organizational context of teaching and learning: Changing theoretical perspectives</article-title>. In <person-group person-group-type="editor">
<name><surname>Hallinan</surname><given-names>M.T.</given-names></name>
</person-group> (Ed.), <source>Handbook of research in the sociology of education</source> (pp. <fpage>37</fpage>–<lpage>63</lpage>). <publisher-loc>New York</publisher-loc>: <publisher-name>Kluwer Academic/Plenum</publisher-name>.</citation>
</ref>
<ref id="bibr24-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garet</surname><given-names>M. S.</given-names></name>
<name><surname>Porter</surname><given-names>A. C.</given-names></name>
<name><surname>Desimone</surname><given-names>L.</given-names></name>
<name><surname>Birman</surname><given-names>B. F.</given-names></name>
<name><surname>Yoon</surname><given-names>K. S.</given-names></name>
</person-group> (<year>2001</year>). <article-title>What makes professional development effective? Results from a national sample of teachers</article-title>. <source>American Educational Research Journal</source>, <volume>38</volume>(<issue>4</issue>), <fpage>915</fpage>–<lpage>945</lpage>.</citation>
</ref>
<ref id="bibr25-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hamre</surname><given-names>B. K.</given-names></name>
<name><surname>Pianta</surname><given-names>R. C.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Can instructional and emotional support in the first-grade classroom make a difference for children at risk of school failure?</article-title> <source>Child Development</source>, <volume>76</volume>(<issue>5</issue>), <fpage>949</fpage>–<lpage>967</lpage>.</citation>
</ref>
<ref id="bibr26-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Heller</surname><given-names>J. I.</given-names></name>
</person-group> (<year>2012</year>). <source>Effects of Making Sense of SCIENCE™ professional development on the achievement of middle school students, including English language learners</source> (NCEE 2012-4002). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Center for Education Evaluation and Regional Assistance, Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr27-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hewson</surname><given-names>P. W.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Teacher professional development in science</article-title>. In <person-group person-group-type="editor">
<name><surname>Abell</surname><given-names>S. K.</given-names></name>
<name><surname>Lederman</surname><given-names>N. G.</given-names></name>
</person-group> (Eds.), <source>Handbook of research on science education</source> (pp. <fpage>1179</fpage>–<lpage>1203</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr28-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jakobsson</surname><given-names>U.</given-names></name>
<name><surname>Westergren</surname><given-names>A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Statistical methods for assessing agreement for ordinal data</article-title>. <source>Scandinavian Journal of Caring Sciences</source>, <volume>19</volume>(<issue>4</issue>), <fpage>427</fpage>–<lpage>431</lpage>.</citation>
</ref>
<ref id="bibr29-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jeanpierre</surname><given-names>B.</given-names></name>
<name><surname>Oberhauser</surname><given-names>K.</given-names></name>
<name><surname>Freeman</surname><given-names>C.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Characteristics of professional development that effect change in secondary science teachers’ classroom practices</article-title>. <source>Journal of Research in Science Teaching</source>, <volume>42</volume>(<issue>6</issue>), <fpage>668</fpage>–<lpage>690</lpage>.</citation>
</ref>
<ref id="bibr30-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kennedy</surname><given-names>M.</given-names></name>
</person-group> (<year>1998</year>). <source>Form and substance in in-service teacher education</source>. <publisher-loc>Arlington, VA</publisher-loc>: <publisher-name>National Science Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr31-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kelly</surname><given-names>K. A.</given-names></name>
</person-group> (<year>2011</year>). <source>CaMSP local evaluation, Year 3 Research Cohort (2010-11): Local Evaluation-Summative findings through October, 2011</source>. Annual report for the California Mathematics Science Partnership.</citation>
</ref>
<ref id="bibr32-0162373712461851">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Kelly</surname><given-names>K. A.</given-names></name>
<name><surname>Rickles</surname><given-names>J.</given-names></name>
<name><surname>Sass</surname><given-names>J.</given-names></name>
<name><surname>Ullah</surname><given-names>A.</given-names></name>
<name><surname>Foster</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>, <month>March</month>). <source>A longitudinal evaluation of grade 7 science reform utilizing classroom observations and regression discontinuity analysis</source>. <conf-name>Presented at the American Educational Research Association Annual Meeting</conf-name>, <conf-loc>New York</conf-loc>.</citation>
</ref>
<ref id="bibr33-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kirschner</surname><given-names>P. A.</given-names></name>
<name><surname>Sweller</surname><given-names>J.</given-names></name>
<name><surname>Clark</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Why minimal guidance during instruction does not work: An analysis of the failure of constructivist, discovery, problem-based, experiential, and inquiry-based teaching</article-title>. <source>Educational Psychologist</source>, <volume>41</volume>(<issue>2</issue>), <fpage>75</fpage>–<lpage>86</lpage>.</citation>
</ref>
<ref id="bibr34-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lauffer</surname><given-names>H. B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>SIMPL: A framework for designing and facilitating professional development to change classroom practice</article-title>. <source>Science Teacher Education</source>, <volume>59</volume>, <fpage>13</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr35-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lauffer</surname><given-names>H. B.</given-names></name>
<name><surname>Lauffer</surname><given-names>D.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Building professional development cadres</article-title>. In <person-group person-group-type="editor">
<name><surname>Mundry</surname><given-names>S.</given-names></name>
<name><surname>Stiles</surname><given-names>K.</given-names></name>
</person-group> (Eds.), <source>Professional learning communities for science teaching: Lessons from research and practice</source> (pp. <fpage>55</fpage>–<lpage>72</lpage>). <publisher-loc>Arlington, VA</publisher-loc>: <publisher-name>National Science Teachers Association</publisher-name>.</citation>
</ref>
<ref id="bibr36-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>O.</given-names></name>
<name><surname>Deaktor</surname><given-names>R. A.</given-names></name>
<name><surname>Hart</surname><given-names>J. E.</given-names></name>
<name><surname>Cuevas</surname><given-names>P.</given-names></name>
<name><surname>Enders</surname><given-names>C.</given-names></name>
</person-group> (<year>2005</year>). <article-title>An instructional intervention’s impact on the science and literacy achievement of culturally and linguistically diverse elementary students</article-title>. <source>Journal of Research in Science Teaching</source>, <volume>42</volume>(<issue>8</issue>), <fpage>857</fpage>–<lpage>887</lpage>.</citation>
</ref>
<ref id="bibr37-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Little</surname><given-names>J. W.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Teachers’ professional development in a climate of educational reform</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>15</volume>(<issue>2</issue>), <fpage>129</fpage>–<lpage>151</lpage>.</citation>
</ref>
<ref id="bibr38-0162373712461851">
<citation citation-type="web">
<collab>Los Angeles Unified School District</collab>. (<year>2007a</year>). <source>Elementary science Full Option Science System (FOSS) instructional materials use and management at school sites</source> (Memorandum 3783.2). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://notebook.lausd.net/pls/ptl/ptl_apps.nbk_doc_info.docinfo?p_doc_id=902297">http://notebook.lausd.net/pls/ptl/ptl_apps.nbk_doc_info.docinfo?p_doc_id=902297</ext-link></citation>
</ref>
<ref id="bibr39-0162373712461851">
<citation citation-type="web">
<collab>Los Angeles Unified School District</collab>. (<year>2007b</year>). <source>FOSS California implementation frequently asked questions</source>. Revised November 9, 2007. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.lausd.net/District_2/resources/science/07-08/elementary/FOSS_FAQs.pdf">http://www.lausd.net/District_2/resources/science/07-08/elementary/FOSS_FAQs.pdf</ext-link></citation>
</ref>
<ref id="bibr40-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Loucks-Horsley</surname><given-names>S.</given-names></name>
<name><surname>Stiles</surname><given-names>K. E.</given-names></name>
<name><surname>Mundry</surname><given-names>S.</given-names></name>
<name><surname>Love</surname><given-names>N.</given-names></name>
<name><surname>Hewson</surname><given-names>P. W.</given-names></name>
</person-group> (<year>2009</year>). <source>Designing professional development for teachers of science and mathematics</source> (<edition>3rd ed.</edition>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Corwin Press</publisher-name>.</citation>
</ref>
<ref id="bibr41-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lutkus</surname><given-names>A. D.</given-names></name>
<name><surname>Lauko</surname><given-names>M.</given-names></name>
<name><surname>Brockway</surname><given-names>D.</given-names></name>
</person-group> (<year>2006</year>). <source>The nation’s report card: Trial urban district assessment science 2005</source> (NCES 2007-453). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Government Printing Office</publisher-name>.</citation>
</ref>
<ref id="bibr42-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Martin</surname><given-names>T.</given-names></name>
<name><surname>Brasiel</surname><given-names>S. J.</given-names></name>
<name><surname>Turner</surname><given-names>H.</given-names></name>
<name><surname>Wise</surname><given-names>J. C.</given-names></name>
</person-group> (<year>2012</year>). <source>Effects of the Connected Mathematics Project 2 (CMP2) on the mathematics achievement of grade 6 students in the mid-Atlantic region</source> (NCEE 2012-4017). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Center for Education Evaluation and Regional Assistance, Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr43-0162373712461851">
<citation citation-type="web">
<collab>Measures of Effective Teaching Project</collab>. (<year>2010</year>). <source>Learning about teaching: Initial findings from the Measures of Effective Teaching Project</source>. <publisher-loc>Seattle, WA</publisher-loc>: <publisher-name>Bill and Melinda Gates Foundation. Retrieved from at</publisher-name> <ext-link ext-link-type="uri" xlink:href="http://www.metproject.org/downloads/Preliminary_Findings-Research_Paper.pdf">http://www.metproject.org/downloads/Preliminary_Findings-Research_Paper.pdf</ext-link></citation>
</ref>
<ref id="bibr44-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Meyer</surname><given-names>J. W.</given-names></name>
<name><surname>Rowan</surname><given-names>B.</given-names></name>
</person-group> (<year>1978</year>). <article-title>The structure of educational organizations</article-title>. In <person-group person-group-type="editor">
<name><surname>Meyer</surname><given-names>M.</given-names></name>
</person-group> Associates, <source>Environments and organizations</source> (pp. <fpage>78</fpage>–<lpage>109</lpage>). <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr45-0162373712461851">
<citation citation-type="book">
<collab>National Research Council</collab>. (<year>1996</year>). <source>National science education standards</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academies Press</publisher-name>.</citation>
</ref>
<ref id="bibr46-0162373712461851">
<citation citation-type="book">
<collab>National Research Council</collab>. (<year>2000</year>). <source>Inquiry and the National Science Education Standards: A guide for teaching and learning</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academies Press</publisher-name>.</citation>
</ref>
<ref id="bibr47-0162373712461851">
<citation citation-type="book">
<collab>National Research Council</collab>. (<year>2012</year>). <source>A framework for K–12 science education: Practices, crosscutting concepts, and core ideas</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Academies Press</publisher-name>.</citation>
</ref>
<ref id="bibr48-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Newman</surname><given-names>D.</given-names></name>
<name><surname>Finney</surname><given-names>P. B.</given-names></name>
<name><surname>Bell</surname><given-names>S.</given-names></name>
<name><surname>Turner</surname><given-names>H.</given-names></name>
<name><surname>Jaciw</surname><given-names>A. P.</given-names></name>
<name><surname>Zacamy</surname><given-names>J. L.</given-names></name>
<name><surname>Feagans Gould</surname><given-names>L.</given-names></name>
</person-group> (<year>2012</year>). <source>Evaluation of the effectiveness of the Alabama Math, Science, and Technology Initiative (AMSTI)</source> (NCEE 2012–4008). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Center for Education Evaluation and Regional Assistance, Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr49-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Oliveira</surname><given-names>A. W.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Improving teacher questioning in science inquiry discussions through professional development</article-title>. <source>Journal of Research in Science Teaching</source>, <volume>47</volume>(<issue>4</issue>), <fpage>422</fpage>–<lpage>453</lpage>.</citation>
</ref>
<ref id="bibr50-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Osthoff</surname><given-names>E.</given-names></name>
<name><surname>Ferrare</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <source>LAUSD middle school science immersion inter-rater agreement</source>. <publisher-loc>Madison</publisher-loc>: <publisher-name>Wisconsin Center for Education Research</publisher-name>.</citation>
</ref>
<ref id="bibr51-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Palardy</surname><given-names>G. J.</given-names></name>
<name><surname>Rumberger</surname><given-names>R. W.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Teacher effectiveness in first grade: The importance of background qualifications, attitudes, and instructional practices for student learning</article-title>. <source>Educational Evaluation and Policy Analysis</source>, <volume>30</volume>(<issue>2</issue>), <fpage>111</fpage>–<lpage>140</lpage>.</citation>
</ref>
<ref id="bibr52-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pane</surname><given-names>J. F.</given-names></name>
<name><surname>McCaffrey</surname><given-names>D. F.</given-names></name>
<name><surname>Slaughter</surname><given-names>M. E.</given-names></name>
<name><surname>Steele</surname><given-names>J. L.</given-names></name>
<name><surname>Ikemoto</surname><given-names>G. S.</given-names></name>
</person-group> (<year>2010</year>). <article-title>An experiment to evaluate the efficacy of cognitive tutor geometry</article-title>. <source>Journal of Research on Educational Effectiveness</source>, <volume>3</volume>(<issue>3</issue>), <fpage>254</fpage>–<lpage>281</lpage>.</citation>
</ref>
<ref id="bibr53-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rice</surname><given-names>J. K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Investing in human capital through teacher professional development</article-title>. In <person-group person-group-type="editor">
<name><surname>Goldhaber</surname><given-names>D.</given-names></name>
<name><surname>Hannaway</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <source>Creating a new teaching profession</source> (pp. <fpage>227</fpage>–<lpage>247</lpage>). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Urban Institute</publisher-name>.</citation>
</ref>
<ref id="bibr54-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>Romberg</surname><given-names>T. A.</given-names></name>
<name><surname>Carpenter</surname><given-names>T. P.</given-names></name>
<name><surname>Dremock</surname><given-names>F.</given-names></name>
</person-group> (Eds.). (<year>2005</year>). <source>Understanding mathematics and science matters</source>. <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr55-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Schunn</surname><given-names>C.</given-names></name>
<name><surname>Millar</surname><given-names>T.</given-names></name>
<name><surname>Lauffer</surname><given-names>D.</given-names></name>
</person-group> <collab>SCALE Immersion Team</collab>. (<year>2005</year>). <source>Full-cycle science and design for all K–12 students: SCALE science immersion definitions and design</source>. <publisher-loc>Pittsburgh, PA</publisher-loc>: <publisher-name>University of Pittsburgh, Learning Research and Development Center</publisher-name>.</citation>
</ref>
<ref id="bibr56-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Supovitz</surname><given-names>J. A.</given-names></name>
<name><surname>Turner</surname><given-names>H. M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The effects of professional development on science teaching practices and classroom culture</article-title>. <source>Journal of Research on Science Teaching</source>, <volume>37</volume>(<issue>9</issue>), <fpage>963</fpage>–<lpage>980</lpage>.</citation>
</ref>
<ref id="bibr57-0162373712461851">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Walkington</surname><given-names>C. A.</given-names></name>
<name><surname>Nathan</surname><given-names>M. J.</given-names></name>
<name><surname>Wolfgram</surname><given-names>M.</given-names></name>
<name><surname>Alibali</surname><given-names>M. W.</given-names></name>
<name><surname>Srisurichan</surname><given-names>R.</given-names></name>
</person-group> (in press). <article-title>Bridges and barriers to constructing conceptual cohesion across modalities and temporalities: Challenges of STEM integration in the precollege engineering classroom</article-title>. In <person-group person-group-type="editor">
<name><surname>Strobel</surname><given-names>J.</given-names></name>
<name><surname>Purzer</surname><given-names>S.</given-names></name>
<name><surname>Cardella</surname><given-names>M.</given-names></name>
</person-group> (Eds.), <source>Engineering in pre-college settings: Research into practice</source>. <publisher-loc>Rotterdam, Netherlands</publisher-loc>: <publisher-name>Sense</publisher-name>.</citation>
</ref>
<ref id="bibr58-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wayne</surname><given-names>A. J.</given-names></name>
<name><surname>Yoon</surname><given-names>K. S.</given-names></name>
<name><surname>Zhu</surname><given-names>P.</given-names></name>
<name><surname>Cronen</surname><given-names>S.</given-names></name>
<name><surname>Garet</surname><given-names>M. S.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Experimenting with teacher professional development: Motives and methods</article-title>. <source>Educational Researcher</source>, <volume>37</volume>(<issue>8</issue>), <fpage>469</fpage>–<lpage>479</lpage>.</citation>
</ref>
<ref id="bibr59-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Weick</surname><given-names>K. E.</given-names></name>
</person-group> (<year>1976</year>). <article-title>Educational organizations as loosely coupled systems</article-title>. <source>Administrative Science Quarterly</source>, <volume>21</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr60-0162373712461851">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>S. M.</given-names></name>
<name><surname>Berne</surname><given-names>J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Teacher learning and the acquisition of professional knowledge: An examination of research on contemporary professional development</article-title>. <source>Review of Research in Education</source>, <volume>24</volume>, <fpage>173</fpage>–<lpage>209</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>