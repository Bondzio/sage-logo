<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ORM</journal-id>
<journal-id journal-id-type="hwp">sporm</journal-id>
<journal-title>Organizational Research Methods</journal-title>
<issn pub-type="ppub">1094-4281</issn>
<issn pub-type="epub">1552-7425</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1094428111403815</article-id>
<article-id pub-id-type="publisher-id">10.1177_1094428111403815</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>An Examination of Power and Type I Errors for Two Differential Item Functioning Indices Using the Graded Response Model</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Clark</surname>
<given-names>Patrick C.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094428111403815">1</xref>
<xref ref-type="corresp" rid="corresp1-1094428111403815"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>LaHuis</surname>
<given-names>David M.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094428111403815">1</xref>
</contrib>
<aff id="aff1-1094428111403815">
<label>1</label>Department of Psychology, Wright State University, Dayton, OH, USA</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1094428111403815">Patrick C. Clark, Department of Psychology, Wright State University, Dayton, OH 45435-0001 Email: <email>clark.274@wright.edu</email>
</corresp>
<fn fn-type="other" id="fn1-1094428111403815">
<p>
<bold>Patrick C. Clark</bold> is a PhD student at Wright State University in Dayton, Ohio. His research interests include item response theory, differential item functioning, multilevel modeling, and policy capturing.</p>
</fn>
<fn fn-type="other" id="fn2-1094428111403815">
<p>
<bold>David M. LaHuis</bold> received his doctorate in industrial and organizational psychology from the University of Connecticut in 2002 and is currently an associate professor of psychology at Wright State University in Dayton, Ohio. His research interests include personnel selection, performance appraisal, item response theory, and multilevel modeling.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2012</year>
</pub-date>
<volume>15</volume>
<issue>2</issue>
<fpage>229</fpage>
<lpage>246</lpage>
<permissions>
<copyright-statement>© SAGE Publications 2011</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>This study examined two methods for detecting differential item functioning (DIF): Raju, van der Linden, and Fleer’s 1995 differential functioning of items and tests (DFIT) procedure and Thissen, Steinberg, and Wainer’s 1988 likelihood ratio test (LRT). The major research questions concerned which test provides the best balance of Type I errors and power and if the tests differ in terms of detecting different types of DIF. Monte Carlo simulations were conducted to address these questions. Equal and unequal sample size conditions were fully crossed with test lengths of 10 and 20 items. In addition, α and β parameters were manipulated in order to simulate DIF. Findings indicate that DFIT and LRT both had acceptable Type I error rates when sample sizes were equal but that DFIT produced too many Type I errors when sample sizes were unequal. Overall, the LRT exhibited greater power to detect both α and β parameter DIF than did DFIT. However, DFIT was more powerful than LRT when the last two β parameters had DIF as opposed to when the extreme β parameters had DIF.</p>
</abstract>
<kwd-group>
<kwd>computer simulation procedures</kwd>
<kwd>Monte Carlo</kwd>
<kwd>bootstrapping</kwd>
<kwd>item response theory</kwd>
<kwd>ANOVA methods</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Differential item functioning (DIF) is an important research topic for psychologists because people with the same underlying ability from different groups may have different probabilities of endorsing the same item. DIF analyses have been used in several different ways in organizational research. One way is to develop tests and scales that have measurement equivalence across subgroups. In these situations, DIF analyses can be used to identify problem items that can be removed from the scale. A second use of DIF analyses has been to assess the measurement equivalence of existing scales across groups or situations. For example, researchers have used DIF to examine differences between male and female respondents (e.g., <xref ref-type="bibr" rid="bibr5-1094428111403815">Braddy, Meade, &amp; Johnson, 2006</xref>; <xref ref-type="bibr" rid="bibr8-1094428111403815">Collins, Raju, &amp; Edwards, 2000</xref>), different test versions (e.g., <xref ref-type="bibr" rid="bibr9-1094428111403815">Donovan, Drasgow, &amp; Probst, 2000</xref>), and racial differences (e.g., <xref ref-type="bibr" rid="bibr5-1094428111403815">Braddy et al., 2006</xref>; <xref ref-type="bibr" rid="bibr8-1094428111403815">Collins et al., 2000</xref>; <xref ref-type="bibr" rid="bibr29-1094428111403815">Raju, Laffitte, &amp; Byrne, 2002</xref>). Finally, DIF analyses can be used to test interesting hypotheses about item responding. For example, <xref ref-type="bibr" rid="bibr33-1094428111403815">Robie, Zickar, and Schmit (2001)</xref> investigated faking on personality assessments by comparing applicants and incumbents using DIF analyses.</p>
<p>These various studies involving DIF have allowed researchers to answer a variety of research questions. Thus, it is important that researchers are able to use DIF techniques that perform accurately. A number of different DIF techniques have been developed. Some examples of these different methods include the area between two item response functions (<xref ref-type="bibr" rid="bibr26-1094428111403815">IRF; Raju, 1988</xref>, <xref ref-type="bibr" rid="bibr27-1094428111403815">1990</xref>); <xref ref-type="bibr" rid="bibr14-1094428111403815">Lord’s (1980)</xref> χ<sup>2</sup> test; the Mantel-Haenszel technique (<xref ref-type="bibr" rid="bibr12-1094428111403815">Holland &amp; Thayer, 1988</xref>); the delta method (<xref ref-type="bibr" rid="bibr1-1094428111403815">Angoff &amp; Ford, 1973</xref>); the differential functioning of items and tests (DFIT) procedure (<xref ref-type="bibr" rid="bibr30-1094428111403815">Raju, van der Linden, &amp; Fleer, 1995</xref>); and <xref ref-type="bibr" rid="bibr37-1094428111403815">Thissen, Steinberg, and Wainer’s (1988)</xref> likelihood ratio test (LRT). Of these, the DFIT and LRT appear to be the most frequently used in organizational research (e.g., <xref ref-type="bibr" rid="bibr8-1094428111403815">Collins et al., 2000</xref>; <xref ref-type="bibr" rid="bibr9-1094428111403815">Donovan et al., 2000</xref>; <xref ref-type="bibr" rid="bibr11-1094428111403815">Henry &amp; Raju, 2006</xref>; <xref ref-type="bibr" rid="bibr16-1094428111403815">Maurer, Raju, &amp; Collins, 1998</xref>; <xref ref-type="bibr" rid="bibr20-1094428111403815">Morales, Flowers, Gutierrez, Kleinman, &amp; Teresi, 2006</xref>; <xref ref-type="bibr" rid="bibr29-1094428111403815">Raju et al., 2002</xref>; <xref ref-type="bibr" rid="bibr35-1094428111403815">Stark, Chernyshenko, Drasgow, &amp; Williams, 2006</xref>). Unfortunately, there has been a lack of empirical work comparing the performance of these two tests, and it is not clear which should be preferred under certain circumstances.</p>
<p>In the present study, we examined the Type I error rates and power of the DFIT framework (<xref ref-type="bibr" rid="bibr30-1094428111403815">Raju et al., 1995</xref>) and the LRT (<xref ref-type="bibr" rid="bibr37-1094428111403815">Thissen et al., 1988</xref>) using the graded response model (GRM). We manipulated a number of conditions in order to identify which fit index should be preferred overall for DIF detection and whether different indices capture different sources of DIF. In the following sections, we briefly review the GRM that is often used to analyze polytomous items and then describe the two DIF indices.</p>
<sec id="section2-1094428111403815">
<title>Graded Response Model</title>
<p>In many situations, researchers use polytomous Likert-type scale items with more than two response options. <xref ref-type="bibr" rid="bibr34-1094428111403815">Samejima’s (1969)</xref> GRM has been typically applied to analyze this type of item data. The GRM assumes that an item has <italic>m</italic> ordered categories. Estimates are based on <italic>m</italic> – 1 boundary response functions (BRFs). Each BRF represents the cumulative probability of selecting a response option greater than the option of interest. For example, a Likert-type scale with five response options would have four BRFs. The first BRF is the probability of choosing the lowest response option versus the cumulative probability of choosing the other four options. The second BRF is the probability of choosing the lowest two response options versus the probability of choosing the other three, and so on. The equation for a BRF is<disp-formula id="disp-formula1-1094428111403815">
<label>1</label>
<mml:math id="mml-disp1-1094428111403815"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="false">∗</mml:mo></mml:msubsup><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo></mml:mrow></mml:mrow><mml:mi>Y</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi mathvariant="italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo mathvariant="normal" stretchy="false">[</mml:mo><mml:mi mathvariant="italic">α</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mi mathvariant="italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">β</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi/><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">)</mml:mo><mml:mo mathvariant="normal" stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:mrow><mml:mo stretchy="false">+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo mathvariant="normal" stretchy="false">[</mml:mo><mml:mi mathvariant="italic">α</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mi mathvariant="italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">β</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi/><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">)</mml:mo><mml:mo mathvariant="normal" stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math>
<graphic alternate-form-of="disp-formula1-1094428111403815" xlink:href="10.1177_1094428111403815-eq1.tif"/>
</disp-formula>In this equation, α<sub>
<italic>i</italic>
</sub> is the item discrimination parameter, β<sub>
<italic>ik</italic>
</sub> is a difficulty parameter for option <italic>k,</italic> and θ is the ability parameter for the individual. There are <italic>m</italic> – 1 threshold parameters. For example, the β<sub>
<italic>ik</italic>
</sub> difficulty parameter for choosing greater than the lowest option represents the point on the θ scale where there is 50% probability that the response is greater than the lowest option. Using Equations 2 through 6, the probability of responding to each of the five categories (<italic>P<sub>i</sub>
</italic>
<sub>1</sub> to <italic>P<sub>i</sub>
</italic>
<sub>5</sub>) may be calculated.<disp-formula id="disp-formula2-1094428111403815">
<label>2</label>
<mml:math id="mml-disp2-1094428111403815">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">1</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">1</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula2-1094428111403815" xlink:href="10.1177_1094428111403815-eq2.tif"/>
</disp-formula>
<disp-formula id="disp-formula3-1094428111403815">
<label>3</label>
<mml:math id="mml-disp3-1094428111403815">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">2</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">1</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">2</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-1094428111403815" xlink:href="10.1177_1094428111403815-eq3.tif"/>
</disp-formula>
<disp-formula id="disp-formula4-1094428111403815">
<label>4</label>
<mml:math id="mml-disp4-1094428111403815">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">3</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">2</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">3</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula4-1094428111403815" xlink:href="10.1177_1094428111403815-eq4.tif"/>
</disp-formula>
<disp-formula id="disp-formula5-1094428111403815">
<label>5</label>
<mml:math id="mml-disp5-1094428111403815">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">4</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">3</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">4</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula5-1094428111403815" xlink:href="10.1177_1094428111403815-eq5.tif"/>
</disp-formula>and<disp-formula id="disp-formula6-1094428111403815">
<label>6</label>
<mml:math id="mml-disp6-1094428111403815">
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">5</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:msubsup>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">4</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">∗</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
<mml:mi mathvariant="italic">θ</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>0.</mml:mn>
</mml:math>
<graphic alternate-form-of="disp-formula6-1094428111403815" xlink:href="10.1177_1094428111403815-eq6.tif"/>
</disp-formula>After the probability of responding to each of the five categories is estimated, a measure of the expected item score can be calculated. For polytomous data, an expected score (<italic>ES<sub>si</sub>
</italic>) can be calculated for examinee <italic>s</italic> on item <italic>i</italic> as <disp-formula id="disp-formula7-1094428111403815">
<label>7</label>
<mml:math id="mml-disp7-1094428111403815">
<mml:mi>E</mml:mi>
<mml:msub>
<mml:mi>S</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:munderover>
<mml:mo movablelimits="false" stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>m</mml:mi>
</mml:munderover>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi mathvariant="italic">θ</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula7-1094428111403815" xlink:href="10.1177_1094428111403815-eq7.tif"/>
</disp-formula>where <italic>X<sub>ik</sub>
</italic> is the score for category <italic>k,</italic> 
<italic>m</italic> is the number of categories, and <italic>P<sub>ik</sub>
</italic> is the probability of responding to category <italic>k</italic>. Put simply, the expected score is the sum of the product between the probability of endorsing a response option and the value of the response option. Summing the expected scores across a test will result in an expected test score function,<disp-formula id="disp-formula8-1094428111403815">
<label>8</label>
<mml:math id="mml-disp8-1094428111403815">
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:mo stretchy="false">=</mml:mo>
<mml:mrow>
<mml:munderover>
<mml:mo movablelimits="false" stretchy="false">∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:munderover>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:msub>
<mml:mi>S</mml:mi>
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula8-1094428111403815" xlink:href="10.1177_1094428111403815-eq8.tif"/>
</disp-formula>where <italic>n</italic> is the number of items on the test.</p>
</sec>
<sec id="section3-1094428111403815">
<title>The Differential Functioning of Items and Tests Framework</title>
<p>The DFIT procedure includes three measures: differential test functioning (DTF), compensatory DIF (CDIF), and noncompensatory DIF (NCDIF). The DFIT indices allow for the determination of whether individual items exhibit DIF (CDIF and NCDIF) and/or whether the test as a whole functions differently (DTF). The DTF index is based on the notion that although individual items may function differentially, these differences can cancel each other out across items, so the test may not exhibit DTF. If there is no DTF and the researcher is not worried about individual-item DIF, then all of the items in the test may remain. The DTF index is defined as the average squared difference between the true test score functions for the focal and reference groups. For a polytomous model, the difference is based on comparing the expected test scores of examinees using the focal and reference groups' item parameters, respectively:<disp-formula id="disp-formula9-1094428111403815">
<label>9</label>
<mml:math id="mml-disp9-1094428111403815">
<mml:mi>D</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">θ</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">)</mml:mo>
<mml:mo mathvariant="normal" stretchy="false">=</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">F</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">θ</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">)</mml:mo>
<mml:mo mathvariant="normal" stretchy="false">−</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">R</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">θ</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">)</mml:mo>
<mml:mo mathvariant="normal" stretchy="false">,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-1094428111403815" xlink:href="10.1177_1094428111403815-eq9.tif"/>
</disp-formula>where <italic>T</italic>
<sub>F</sub> is the expected test score based on the focal group’s parameters, and <italic>T</italic>
<sub>R</sub> is the expected test score based on the reference group’s parameters. DTF is the expected value of the squared difference between the focal and the reference groups across the θ distribution from the focal group (<italic>E</italic>
<sub>F</sub>):<disp-formula id="disp-formula10-1094428111403815">
<label>10</label>
<mml:math id="mml-disp10-1094428111403815">
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">D</mml:mi>
<mml:mi mathvariant="normal">T</mml:mi>
<mml:mi mathvariant="normal">F</mml:mi>
<mml:mo mathvariant="normal" stretchy="false">=</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">F</mml:mi>
</mml:mrow>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">[</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mi>D</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">θ</mml:mi>
<mml:mi>s</mml:mi>
</mml:msub>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mn mathvariant="normal">2</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">]</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal">.</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-1094428111403815" xlink:href="10.1177_1094428111403815-eq10.tif"/>
</disp-formula>CDIF and NCDIF are the two item-level DIF indices in the DFIT framework. One can use the CDIF index to identify items that contribute to DTF. Under this index, all of the items on the test are considered, and items that if removed would lower DTF are noted. When one sums CDIF values across items, the outcome is equal to DTF. CDIF can be calculated by finding the covariance of <italic>D</italic> and <italic>d</italic> (the probability of success on an item for a person in the focal group and the probability of success on an item for a person in the reference group) and adding that to the product of the mean of <italic>d</italic> and the mean of <italic>D</italic> :<disp-formula id="disp-formula11-1094428111403815">
<label>11</label>
<mml:math id="mml-disp11-1094428111403815">
<mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mi mathvariant="normal">D</mml:mi>
<mml:mi mathvariant="normal">I</mml:mi>
<mml:mi mathvariant="normal">F</mml:mi>
</mml:mrow>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">=</mml:mo>
<mml:mi mathvariant="normal">C</mml:mi>
<mml:mi mathvariant="normal">o</mml:mi>
<mml:mi mathvariant="normal">v</mml:mi>
<mml:mo mathvariant="normal" stretchy="false">(</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>D</mml:mi>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal" stretchy="false">)</mml:mo>
<mml:mo mathvariant="normal" stretchy="false">+</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:msub>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mrow>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mi mathvariant="italic">μ</mml:mi>
<mml:mi>D</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo mathvariant="normal">.</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-1094428111403815" xlink:href="10.1177_1094428111403815-eq11.tif"/>
</disp-formula>The NCDIF index can be used to identify individual items exhibiting DIF independent of other items on the test. This means that NCDIF will flag an item even if the item’s DIF is canceled out at the test level. NCDIF is similar to DTF except that it is based on comparing expected item scores among focal group respondents' expected scores using focal group item parameters versus reference group item parameters. The NCDIF index is the expectation over the focal group (<italic>E</italic>
<sub>F</sub>) of squared differences between the probability of endorsing an item using the focal item parameters, <italic>P<sub>i</sub>
</italic>
<sub>F</sub>(θ), and the probability of endorsing an item using the reference group parameters, <italic>P<sub>i</sub>
</italic>
<sub>R</sub>(θ). If <italic>d<sub>i</sub>
</italic> equals the difference between the expected item scores under the focal and reference group parameters, then <disp-formula id="disp-formula12-1094428111403815">
<label>12</label>
<mml:math id="mml-disp12-1094428111403815"><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">=</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">[</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="italic">θ</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">−</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="italic">θ</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">)</mml:mo><mml:mo mathvariant="normal" stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">=</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">=</mml:mo></mml:mrow></mml:mrow><mml:msubsup><mml:mi mathvariant="italic">σ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mo mathvariant="normal" stretchy="false">+</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi mathvariant="italic">μ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn><mml:mo mathvariant="normal" stretchy="false">,</mml:mo></mml:mrow></mml:mrow></mml:math>
<graphic alternate-form-of="disp-formula12-1094428111403815" xlink:href="10.1177_1094428111403815-eq12.tif"/>
</disp-formula>where σ and μ are the standard deviations and means, respectively, of <italic>d<sub>i</sub>
</italic>.</p>
</sec>
<sec id="section4-1094428111403815">
<title>Item Parameter Replication Method</title>
<p>
<xref ref-type="bibr" rid="bibr30-1094428111403815">Raju et al. (1995)</xref> originally proposed χ<sup>2</sup> tests to evaluate the statistical significance of the DTF and NCDIF indices. However, these tests tended to commit too many Type I errors. The focus then shifted to establishing cutoff values for the two indices. Raju et al. and <xref ref-type="bibr" rid="bibr10-1094428111403815">Flowers, Oshima, and Raju (1999)</xref> proposed overall cutoff values of .006 and .016, respectively, for the NCDIF index. However, these cutoff values were not generalizable to other items and were also specific to the item response theory (IRT) model being used. Empirically derived cutoff values for the NCDIF index have been explored, and research has generally supported their use. Several studies have found acceptable Type I errors and reasonable power for overall empirical cutoffs (<xref ref-type="bibr" rid="bibr4-1094428111403815">Bolt, 2002</xref>; <xref ref-type="bibr" rid="bibr10-1094428111403815">Flowers et al., 1999</xref>; <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade, Lautenschlager, &amp; Johnson, 2007</xref>). However, despite the promise in using empirically derived cutoff values, most researchers have neither the expertise nor the time to do these sorts of calculations. To address this, <xref ref-type="bibr" rid="bibr25-1094428111403815">Oshima, Raju, and Nanda (2006)</xref> developed the item parameter replication (IPR) method for use with dichotomous data. This method has been extended recently to polytomous data (<xref ref-type="bibr" rid="bibr28-1094428111403815">Raju et al., 2009</xref>).</p>
<p>The IPR method utilizes estimates of item parameters for the reference group, as well as variances and covariances for those estimates, in order to obtain a distribution of NCDIF values that can be rank ordered. Based on these estimates, a number of replications of item parameters are then generated using the same sampling variance and covariance as the original item parameters. This assumes that any differences between the original parameters and the newly generated parameters are due to sampling error. After a large number of replications are complete, an empirical sampling distribution of NCDIF under the null hypothesis that both groups (the focal and reference) are equal is produced.</p>
<p>The IPR method has been a fairly recent addition to the DFIT framework. As such, most of the existing research on the DFIT framework does not use this method. In particular, the empirical evaluations of Type I errors and power (e.g., <xref ref-type="bibr" rid="bibr4-1094428111403815">Bolt, 2002</xref>; <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al., 2007</xref>) predated its development. Thus, it is not clear how well the IPR method performs in terms of Type I errors and power. One potential problem with the IPR method is that it assumes that the item parameter estimates' variances and covariance for the reference group generalize to the focal group. This assumption may be violated when the sample sizes for the two groups differ, as sample size will likely affect the variances of the item parameters. In the present study, we assessed the magnitude of the effect of unequal sample sizes on the evaluation of the extent of DIF for a set of items.</p>
</sec>
<sec id="section5-1094428111403815">
<title>The Likelihood Ratio Test</title>
<p>The LRT is based on comparing the relative goodness of fit of nested models and can be implemented in two ways (e.g., <xref ref-type="bibr" rid="bibr31-1094428111403815">Rivas, Stark, &amp; Chernyshenko, 2009</xref>; <xref ref-type="bibr" rid="bibr35-1094428111403815">Stark et al., 2006</xref>; <xref ref-type="bibr" rid="bibr38-1094428111403815">Wang, 2004</xref>; <xref ref-type="bibr" rid="bibr39-1094428111403815">Wang &amp; Yeh, 2003</xref>). One way is the constrained baseline method where a baseline model is formed by constraining all item parameters to be equal across groups. DIF is detected by estimating a series of comparison models by freeing the item parameters one item at a time. The second method is called the free baseline method where the baseline model is formed by freeing all of the item parameters except a referent subset of items. Comparison models are formed constraining the item parameters to be equal across groups. Again, this is done item by item.</p>
<p>Research suggests that the free baseline method results in lower Type I error rates and more power compared with the constrained baseline method (<xref ref-type="bibr" rid="bibr35-1094428111403815">Stark et al., 2006</xref>; <xref ref-type="bibr" rid="bibr39-1094428111403815">Wang &amp; Yeh, 2003</xref>). In addition<xref ref-type="bibr" rid="bibr31-1094428111403815">, Rivas et al. (2009)</xref> found that using highly discriminating items as anchors improved performance. Based on this, we used the free software program IRTLRDIF 2.0 (item response theory likelihood ratio differential item functioning; <xref ref-type="bibr" rid="bibr36-1094428111403815">Thissen, 2001</xref>) to conduct LRTs using the free baseline method.</p>
<p>Under the free baseline method, the user specifies a set of anchor and candidate items. The anchor items are items that the researcher believes do not exhibit DIF. <xref ref-type="bibr" rid="bibr31-1094428111403815">Rivas et al. (2009)</xref> found that a single highly discriminating item can be an effective anchor item when large amounts of DIF are present, and additional anchor items increase power for detecting smaller amounts of DIF. Candidate items are the items that are tested for DIF. A series of augmented models are formed by constraining the item parameters of the candidate items to be equivalent across groups. This is done item by item. The fit of the baseline and augmented models is compared using a likelihood ratio test:<disp-formula id="disp-formula13-1094428111403815">
<label>13</label>
<mml:math id="mml-disp13-1094428111403815">
<mml:msup>
<mml:mi>G</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>d</mml:mi>
<mml:mi>f</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">=</mml:mo>
<mml:mo stretchy="false">−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo form="prefix" movablelimits="false">log</mml:mo>
<mml:mfenced close="]" open="[">
<mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mrow>
</mml:mfenced>
<mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula13-1094428111403815" xlink:href="10.1177_1094428111403815-eq13.tif"/>
</disp-formula>where <italic>L</italic> represents the likelihood of the data given the maximum likelihood estimates of the parameters of the model, <italic>A</italic> refers to the augmented model, and <italic>B</italic> refers to the baseline model. <italic>G</italic>
<sup>2</sup> is distributed as a χ<sup>2</sup> with degrees of freedom equal to the difference between the number of parameters in the augmented model and the number of parameters in the baseline model. The LRT essentially tests the equivalent of the item parameters across groups.</p>
</sec>
<sec id="section6-1094428111403815">
<title>Research on DFIT and LRT</title>
<p>The DFIT framework and LRT have been two of the most frequently used ways of testing for DIF, and there has been some research investigating their performance. For example, numerous studies have shown the DFIT framework to be successful at detecting items and tests that may be biased (e.g., <xref ref-type="bibr" rid="bibr10-1094428111403815">Flowers et al., 1999</xref>; <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al., 2007</xref>; <xref ref-type="bibr" rid="bibr30-1094428111403815">Raju et al., 1995</xref>). A number of researchers have examined the LRT and have shown that the test has enough power to detect DIF at the item level (e.g., <xref ref-type="bibr" rid="bibr2-1094428111403815">Ankenmann, Witt, &amp; Dunbar, 1999</xref>; <xref ref-type="bibr" rid="bibr13-1094428111403815">Kim &amp; Cohen, 1998</xref>; <xref ref-type="bibr" rid="bibr37-1094428111403815">Thissen et al., 1988</xref>).</p>
<p>Little research has directly compared the NCDIF index with LRT. One exception is <xref ref-type="bibr" rid="bibr4-1094428111403815">Bolt’s (2002)</xref> study. He generated 30 items with three different IRT models, the GRM, the generalized partial credit model, and the two-parameter sequential response model for sample sizes of 300 and 1,000. Type I error rates for the LRT were in the acceptable 5% range when Bolt used the GRM to generate the data but went up to 20% when the model was misspecified. Type I error rates for the NCDIF index were acceptable regardless of the generating model. Both procedures had acceptable power across most conditions, but the LRT exhibited more power overall than did the NCDIF index. It is important to note that Bolt’s study did not include the IPR method for the NCDIF index or the free-baseline LRT.</p>
<p>
<xref ref-type="bibr" rid="bibr5-1094428111403815">Braddy et al. (2006)</xref> also compared the DFIT framework and LRT directly. They found that the DFIT procedure indicated that the test as a whole did not have DTF and only identified 1 item in all of the conditions as DIF. In contrast, the LRT identified 10 DIF items. These results do not indicate which DIF detection method was more accurate at assessing DIF because the true magnitude of population DIF in this study was unknown. The different conclusions implied from Braddy et al.’s study indicate that it is crucial to know which of these fit indices to use in order to avoid producing a test with extensive DIF. Thus, there are still a number of questions concerning which DIF test should be preferred overall and how various conditions affect the DIF tests.</p>
</sec>
<sec id="section7-1094428111403815">
<title>Present Study</title>
<p>In the present study, we examined the Type I error rates and power for the NCDIF index using the IPR method and the free-baseline LRT across a number of conditions. Specifically, we varied the test length and source of DIF by manipulating the discrimination and threshold parameters. We were interested primarily in (a) how the manipulations affected the Type I errors across tests, (b) how the manipulations affected the power estimates across tests, (c) which test had more acceptable Type I error rates, and (d) which test had better power estimates.</p>
</sec>
<sec id="section8-1094428111403815">
<title>Method</title>
<sec id="section9-1094428111403815">
<title>Design</title>
<p>We generated item data for a simulation study with 116 conditions. The study design was based primarily on <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al.’s (2007)</xref> study. Type I errors were assessed using four control conditions: 10-item equal samples, 10-item unequal samples, 20-item equal samples, and 20-item unequal samples. No parameters were manipulated, and thus no DIF was present in these control conditions. Meade et al. found that manipulating sample size (ω<sup>2</sup> = .001) and the number of DIF items (ω<sup>2</sup> = .002) had little impact on power for DFIT. Based on this, for half of the conditions we used a sample size of 500 for the focal group and 500 for the reference group as well as 4 DIF items in each DIF condition. In most real-world settings, one of the groups will have fewer individuals than the other group. For example, <xref ref-type="bibr" rid="bibr9-1094428111403815">Donovan et al. (2000)</xref> had sample sizes of 509 in the focal group and 1,777 in the reference group. <xref ref-type="bibr" rid="bibr20-1094428111403815">Morales et al. (2006)</xref> had sample sizes of 665 in the focal group and 913 in the reference group. To address this, we also used unequal sample size conditions with a sample size of 250 for the focal group and 500 for the reference group. For each manipulation of DIF, we included a no-DIF cancellation condition and a DIF cancellation condition. In the no-DIF cancellation condition, we subtracted values for all 4 DIF items. In the DIF cancellation condition, we subtracted for 2 of the DIF items and added for the other 2 DIF items. Finally, we conducted 100 repetitions of each of the conditions.</p>
</sec>
<sec id="section10-1094428111403815">
<title>Data Generation</title>
<p>We generated the item data using SPSS 12.0. First, population values for the α and β parameter estimates were generated. The α parameters were sampled from a random normal distribution with a mean of 1.25 and a standard deviation of 0.07. We generated four β values for each item to simulate items with five response options. We sampled the β value for the lowest of the four BRFs from a random normal distribution with a mean of –1.7 and a standard deviation of 0.45. To create the three other β values, we added constants of 1.2, 2.4, and 3.6 to the lowest difficulty (<xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al., 2007</xref>). Second, we sampled θ values for each simulee from a random normal distribution with a mean of 0 and a standard deviation of 1. Third, we calculated the probability for endorsing each option for each item by plugging the generated item parameters and θ values into the GRM equations. We used the probabilities for endorsing each option to calculate a cumulative probability of endorsing each response option. Finally, we generated item responses by comparing previously generated random numbers (between 0 and 1) with the cumulative probabilities of endorsing each response option. The lowest response option for which the cumulative probability exceeds the random number is a simulee’s item response.</p>
<p>We introduced DIF in one of two ways. First, items' α parameters were simulated to differ across groups by subtracting either 0.25 or 0.50 from the reference group’s α parameter in order to create the focal group’s α parameters. This gave the effect of the item not distinguishing as well between high and low performers for the focal group. Second, items' β parameters were simulated to differ across groups in one of four ways: (a) adding or subtracting 0.4 or 1.0 from the last two β values, (b) adding or subtracting 0.4 or 1.0 from the two most extreme β values, (c) adding or subtracting 0.4 or 1.0 from the last two β values and having the DIF cancel, and (d) adding or subtracting 0.4 or 1.0 from the two most extreme β values and having the DIF cancel. We do not believe that this DIF will cancel perfectly, but we do believe that it will approximately cancel. Adding a constant to the β parameter simulates the effect of the focal group having a lower likelihood of endorsing the option (i.e., the item becomes more difficult). Subtracting a constant from the β parameter simulates the effect of the focal group having a greater likelihood of endorsing the option (i.e., the item becomes easier). These values are similar to the DIF seen in a number of studies using real data (<xref ref-type="bibr" rid="bibr5-1094428111403815">Braddy et al., 2006</xref>; <xref ref-type="bibr" rid="bibr9-1094428111403815">Donovan et al., 2000</xref>; <xref ref-type="bibr" rid="bibr16-1094428111403815">Maurer et al., 1998</xref>; <xref ref-type="bibr" rid="bibr29-1094428111403815">Raju et al., 2002</xref>; <xref ref-type="bibr" rid="bibr33-1094428111403815">Robie et al., 2001</xref>). For example, <xref ref-type="bibr" rid="bibr5-1094428111403815">Braddy et al. (2006)</xref> found α parameter values of 1.95 for women and 1.35 for men on a particular item. They also found β parameter values of 0.83 and 2.47 for the last two β values for the female group and 1.42 and 3.40 for the last two β values for the male group. In addition, they found β parameter values of –2.16 and 3.08 for the two most extreme β values for the female group and –1.80 and 2.50 for the two most extreme β values for the male group. <xref ref-type="bibr" rid="bibr29-1094428111403815">Raju et al. (2002)</xref> found α parameter values of 2.32 for Blacks and 1.81 for Whites on a particular item. <xref ref-type="bibr" rid="bibr33-1094428111403815">Robie et al. (2001)</xref> found α parameter values of 0.99 for an applicant group and 1.50 for and incumbent group on a particular item.</p>
<p>We calculated effect sizes for each condition to assess the amount DIF generated. The effect sizes for each condition are in <xref ref-type="table" rid="table7-1094428111403815">Table 1</xref>
. We have reported three effect size indices—expected score standardized difference (ESSD), signed item difference in sample (SIDS), and unsigned item difference in sample (UIDS)—based on <xref ref-type="bibr" rid="bibr17-1094428111403815">Meade’s (2010)</xref> work. The ESSD is an expected score version of Cohen’s <italic>d</italic>. The SIDS is the average difference in expected scores across focal group sample respondents, allowing the DIF to cancel in cases of nonuniform differences. The UIDS is the average difference in expected scores across focal group sample respondents had they always favored one group.</p>
<table-wrap id="table1-1094428111403815" position="float">
<label>Table 1.</label>
<caption>
<p>Effect Sizes for 10-Item Conditions</p>
</caption>
<graphic alternate-form-of="table1-1094428111403815" xlink:href="10.1177_1094428111403815-table7.tif"/>
<table>
<thead>
<tr>
<th>α DIF</th>
<th align="center">B DIF</th>
<th>ESSD</th>
<th>SIDS</th>
<th>UIDS</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>0.40 to extremes</td>
<td>–.13</td>
<td>–.10</td>
<td>.10</td>
</tr>
<tr>
<td>None</td>
<td>0.40 to last two</td>
<td>–.16</td>
<td>–.13</td>
<td>.13</td>
</tr>
<tr>
<td>None</td>
<td>1.00 to extremes</td>
<td>–.32</td>
<td>–.26</td>
<td>.26</td>
</tr>
<tr>
<td>None</td>
<td>1.00 to last two</td>
<td>–.35</td>
<td>–.27</td>
<td>.27</td>
</tr>
<tr>
<td>0.25</td>
<td>None</td>
<td>.00</td>
<td>.00</td>
<td>.05</td>
</tr>
<tr>
<td>0.25</td>
<td>0.40 to extremes</td>
<td>–.13</td>
<td>–.10</td>
<td>.10</td>
</tr>
<tr>
<td>0.25</td>
<td>0.40 to last two</td>
<td>–.15</td>
<td>–.12</td>
<td>.13</td>
</tr>
<tr>
<td>0.25</td>
<td>1.00 to extremes</td>
<td>–.32</td>
<td>–.26</td>
<td>.26</td>
</tr>
<tr>
<td>0.25</td>
<td>1.00 to last two</td>
<td>–.34</td>
<td>–.26</td>
<td>.27</td>
</tr>
<tr>
<td>0.50</td>
<td>None</td>
<td>.00</td>
<td>.01</td>
<td>.12</td>
</tr>
<tr>
<td>0.50</td>
<td>0.40 to extremes</td>
<td>–.12</td>
<td>–.10</td>
<td>.14</td>
</tr>
<tr>
<td>0.50</td>
<td>0.40 to last two</td>
<td>–.14</td>
<td>–.11</td>
<td>.17</td>
</tr>
<tr>
<td>0.50</td>
<td>1.00 to extremes</td>
<td>–.30</td>
<td>–.24</td>
<td>.25</td>
</tr>
<tr>
<td>0.50</td>
<td>1.00 to last two</td>
<td>–.32</td>
<td>–.24</td>
<td>.27</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1094428111403815">
<p>Note: DIF = differential item functioning; ESSD = expected score standardized difference; SIDS = signed item difference in sample; UIDS = unsigned item difference in sample.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section11-1094428111403815">
<title>Data Analysis</title>
<p>The DFIT analysis requires item parameters for the reference and focal group to be estimated and put on the same metric using a linking procedure. Item parameters were estimated using PARSCALE (<xref ref-type="bibr" rid="bibr23-1094428111403815">Muraki &amp; Bock, 2003</xref>). We used single-stage linking implemented with the Equate 2.1 program (<xref ref-type="bibr" rid="bibr3-1094428111403815">Baker, 1995</xref>) and specified the non-DIF items as anchors when conducting the linking. NCDIF analyses were conducted using the DFIT8 program (<xref ref-type="bibr" rid="bibr24-1094428111403815">Oshima, Kushubar, Scott, &amp; Raju, 2009</xref>). The DFIT8 program requires the input of the variances and covariances of the item parameters. We extracted these from the PARSCALE output using the polycov software program (<xref ref-type="bibr" rid="bibr21-1094428111403815">Morris, 2008</xref>).</p>
<p>We conducted the free-baseline LRT analysis with the IRTLRDIF program (<xref ref-type="bibr" rid="bibr36-1094428111403815">Thissen, 2001</xref>). The last three non-DIF items served as the anchors.</p>
<p>To evaluate the effectiveness of each of the DIF detection methods, we evaluated Type I errors and power. The Type I error rates were calculated by dividing the number of non-DIF items that are flagged as DIF by the index by the total number of items simulated not to contain DIF for that particular sample. In the conditions where α and β were not manipulated, Type I error rates were based on all of the items. For conditions with DIF, Type I error rates were based on the items that did not have their parameters changed. We assessed power by calculating the number of differentially functioning items that are successfully detected as DIF items divided by the total number of DIF items generated for the sample. We then averaged these Type I error rates and power across 100 replications for each condition. In addition, to determine the effects of study variables, a mixed model analysis of variance (ANOVA) was conducted with type of test as a within-group variable and the manipulations as between-group variables. Because of the large sample sizes, we focused on interpreting effect sizes rather than statistical significance.</p>
</sec>
</sec>
<sec id="section12-1094428111403815">
<title>Results</title>
<p>
<xref ref-type="table" rid="table6-1094428111403815">Tables 2</xref> and <xref ref-type="table" rid="table5-1094428111403815">3</xref>

 present effect sizes for the mixed model ANOVAs. We conducted simple effects analyses for two-way interactions with nontrivial effect sizes. As shown in <xref ref-type="table" rid="table6-1094428111403815">Table 2</xref>, the DIF detection method explained 28% of the variance in Type I error rates, with the LRT being associated with lower Type I errors. The interaction between the DIF detection method and sample equality (partial η<sup>2</sup> = .15) had the next largest effect. The simple effects analyses revealed that sample equality had a larger effect on Type I errors for NCDIF (partial η<sup>2</sup> = .13) compared with LRT (partial η<sup>2</sup> = .00). As shown in <xref ref-type="fig" rid="fig1-1094428111403815">Figure 1</xref>
, the Type I error rates are similar across test type for equal sample sizes. However, when the samples are unequal, the Type I error rates for NCDIF (18%) were much higher than the Type I error rates for LRT (1%). None of the other manipulations had sizable interaction effects on Type I error rates.</p>
<table-wrap id="table2-1094428111403815" position="float">
<label>Table 2.</label>
<caption>
<p>Mixed Model ANOVA (Type I)</p>
</caption>
<graphic alternate-form-of="table2-1094428111403815" xlink:href="10.1177_1094428111403815-table6.tif"/>
<table>
<thead>
<tr>
<th>Source</th>
<th>
<italic>df</italic>
</th>
<th align="center">
<italic>F</italic>
</th>
<th>Partial η<sup>2</sup>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Differential item functioning (DIF) detection method</td>
<td>1</td>
<td>4,347.32</td>
<td>.28</td>
</tr>
<tr>
<td>DIF Detection Method × Magnitude of α DIF (A)</td>
<td>2</td>
<td>1.72</td>
<td>.00</td>
</tr>
<tr>
<td>DIF Detection Method × Magnitude of β DIF (M)</td>
<td>1</td>
<td>6.30</td>
<td>.00</td>
</tr>
<tr>
<td>DIF Detection Method × Which β Parameters DIF (W)</td>
<td>1</td>
<td>0.48</td>
<td>.00</td>
</tr>
<tr>
<td>DIF Detection Method × Number of Items (N)</td>
<td>1</td>
<td>38.39</td>
<td>.00</td>
</tr>
<tr>
<td>DIF Detection Method × Cancellation of DIF (C)</td>
<td>1</td>
<td>0.13</td>
<td>.00</td>
</tr>
<tr>
<td>DIF Detection Method × Equal Samples (E)</td>
<td>1</td>
<td>1,953.44</td>
<td>.15</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1094428111403815">
<p>Note: Percentages are out of 100 samples and across all items. Only interactions explaining greater than 1% of the variance were included.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table3-1094428111403815" position="float">
<label>Table 3.</label>
<caption>
<p>Mixed Model ANOVA (power)</p>
</caption>
<graphic alternate-form-of="table3-1094428111403815" xlink:href="10.1177_1094428111403815-table5.tif"/>
<table>
<thead>
<tr>
<th>Source</th>
<th>
<italic>df</italic>
</th>
<th align="center">
<italic>F</italic>
</th>
<th>Partial η<sup>2</sup>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>Differential item functioning detection method (D)</td>
<td>1</td>
<td>178.15</td>
<td>.02</td>
</tr>
<tr>
<td>D × Magnitude of α DIF (A)</td>
<td>2</td>
<td>423.33</td>
<td>.07</td>
</tr>
<tr>
<td>D × Magnitude of β DIF (M)</td>
<td>1</td>
<td>48.79</td>
<td>.00</td>
</tr>
<tr>
<td>D × Which β parameters DIF (W)</td>
<td>1</td>
<td>2,402.43</td>
<td>.17</td>
</tr>
<tr>
<td>D × Number of items (N)</td>
<td>1</td>
<td>43.52</td>
<td>.00</td>
</tr>
<tr>
<td>D × Cancellation of DIF (C)</td>
<td>1</td>
<td>15.05</td>
<td>.00</td>
</tr>
<tr>
<td>D × Equal samples (E)</td>
<td>1</td>
<td>413.15</td>
<td>.04</td>
</tr>
<tr>
<td>D × M × W</td>
<td>1</td>
<td>2,182.99</td>
<td>.16</td>
</tr>
<tr>
<td>D × M × E</td>
<td>1</td>
<td>200.24</td>
<td>.02</td>
</tr>
<tr>
<td>D × A × M</td>
<td>2</td>
<td>99.26</td>
<td>.02</td>
</tr>
<tr>
<td>D × A × W</td>
<td>2</td>
<td>316.69</td>
<td>.05</td>
</tr>
<tr>
<td>D × A × E</td>
<td>2</td>
<td>86.40</td>
<td>.02</td>
</tr>
<tr>
<td>D × A × M × W</td>
<td>2</td>
<td>315.99</td>
<td>.05</td>
</tr>
<tr>
<td>D × A × M × E</td>
<td>2</td>
<td>41.1</td>
<td>.01</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1094428111403815">
<p>Note: Percentages are out of 100 samples and across all items. Only interactions explaining greater than 1% of the variance were included.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig1-1094428111403815" position="float">
<label>Figure 1.</label>
<caption>
<p>The interaction between the DIF detection method and sample equality.</p>
</caption>
<graphic alternate-form-of="fig1-1094428111403815" xlink:href="10.1177_1094428111403815-fig1.tif"/>
</fig>
<p>As shown in <xref ref-type="table" rid="table5-1094428111403815">Table 3</xref>, the DIF detection method explained 2% of the variance in power, with the LRT being associated with higher power. The interaction between DIF detection method and magnitude of α DIF was 7%. Simple effects analyses revealed that the α DIF manipulation had a smaller effect on the power of NCDIF (partial η<sup>2</sup> = .12) than on the power of LRT (partial η<sup>2</sup> = .38). The effect size for the interaction between DIF detection method and magnitude of β DIF was smaller (partial η<sup>2</sup> = .00). The interaction between the DIF detection method and which β parameters were manipulated (partial η<sup>2</sup> = .17) had the largest effect. The effect was weaker for the NCDIF (partial η<sup>2</sup> = .06) than for the LRT (partial η<sup>2</sup> = .15). Similarly, the three-way interaction between DIF detection method, magnitude of β DIF, and which β parameters were manipulated had a large effect (partial η<sup>2</sup> = .16). The NCDIF does a better job of detecting the DIF when the last two β parameters were changed by 0.40. In contrast, the LRT does a better job of detecting the DIF when the two most extreme β parameters were manipulated changed by 0.40. Few differences were observed when the β parameters were changed by 1.0. The interactions between the number of items (partial η<sup>2</sup> = .00), cancellation of DIF (partial η<sup>2</sup> = .00), and sample equality (partial η<sup>2</sup> = .04) with test type did not explain much variance in power.</p>
<sec id="section13-1094428111403815">
<title>Type I Error Rates and Power Estimates</title>
<p>
<xref ref-type="table" rid="table4-1094428111403815">Tables 4</xref> and <xref ref-type="table" rid="table3-1094428111403815">5</xref>

 present the Type I error rates and power estimates for the NCDIF index for equal and unequal sample sizes, respectively. Type I error rates were the percentage of non-DF items that were detected as DF averaged across all 100 samples for each condition. The number in parentheses, power, refers to the number of times the index correctly identified a DF item as DIF per 100 cases. All Type I error rates were less than 7% in the equal samples sizes condition for the NCDIF index. Type I error rates for the unequal sample sizes condition were all between 16% and 21%. Overall, for equal sample sizes, the NCDIF index had acceptable Type I error rates (≤5) in 49 of the 58 conditions but did not have acceptable error rates in any of the conditions for unequal sample sizes.</p>
<table-wrap id="table4-1094428111403815" position="float">
<label>Table 4.</label>
<caption>
<p>Type I Errors and Power for Equal Sample Sizes (differential functioning of items and tests procedure)</p>
</caption>
<graphic alternate-form-of="table4-1094428111403815" xlink:href="10.1177_1094428111403815-table4.tif"/>
<table>
<thead>
<tr>
<th>β DIF</th>
<th>Items</th>
<th>Cancellation of DIF</th>
<th>No α DIF</th>
<th>0.25 α DIF</th>
<th>0.50 α DIF</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>10</td>
<td>No</td>
<td align="center">5</td>
<td>5 (23)</td>
<td>3 (72)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td align="center">–</td>
<td>5 (22)</td>
<td>5 (51)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td align="center">5</td>
<td>5 (20)</td>
<td>4 (75)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td align="center">–</td>
<td>5 (15)</td>
<td>4 (51)</td>
</tr>
<tr>
<td>0.4 highest 2</td>
<td>10</td>
<td>No</td>
<td>5 (83)</td>
<td>5 (77)</td>
<td>6 (92)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>5 (86)</td>
<td>3 (86)</td>
<td>4 (89)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>4 (81)</td>
<td>5 (80)</td>
<td>4 (91)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>4 (85)</td>
<td>5 (86)</td>
<td>4 (92)</td>
</tr>
<tr>
<td>0.4 extremes</td>
<td>10</td>
<td>No</td>
<td>3 (56)</td>
<td>4 (61)</td>
<td>5 (84)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>3 (60)</td>
<td>6 (60)</td>
<td>5 (76)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>4 (53)</td>
<td>4 (59)</td>
<td>4 (85)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>4 (58)</td>
<td>5 (56)</td>
<td>4 (71)</td>
</tr>
<tr>
<td>1.0 highest 2</td>
<td>10</td>
<td>No</td>
<td>4 (100)</td>
<td>5 (99)</td>
<td>5 (99)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>4 (100)</td>
<td>4 (100)</td>
<td>4 (99)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>5 (100)</td>
<td>5 (100)</td>
<td>6 (99)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>5 (100)</td>
<td>5 (100)</td>
<td>6 (100)</td>
</tr>
<tr>
<td>1.0 extremes</td>
<td>10</td>
<td>No</td>
<td>6 (100)</td>
<td>4 (100)</td>
<td>7 (99)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>4 (100)</td>
<td>6 (99)</td>
<td>6 (98)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>5 (100)</td>
<td>4 (100)</td>
<td>4 (98)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>4 (100)</td>
<td>5 (100)</td>
<td>7 (99)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-1094428111403815">
<p>Note: DIF = differential item functioning.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table5-1094428111403815" position="float">
<label>Table 5.</label>
<caption>
<p>Type I Errors and Power for Unequal Sample Sizes (differential functioning of items and tests procedure)</p>
</caption>
<graphic alternate-form-of="table5-1094428111403815" xlink:href="10.1177_1094428111403815-table3.tif"/>
<table>
<thead>
<tr>
<th>β DIF</th>
<th>Items</th>
<th>Cancellation of DIF</th>
<th>No α DIF</th>
<th>0.25 α DIF</th>
<th>0.50 α DIF</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>10</td>
<td>No</td>
<td align="center">17</td>
<td>17 (40)</td>
<td>17 (76)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td align="center">–</td>
<td>16 (38)</td>
<td>16 (60)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td align="center">18</td>
<td>18 (41)</td>
<td>17 (72)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td align="center">–</td>
<td>18 (27)</td>
<td>17 (54)</td>
</tr>
<tr>
<td>0.4 highest 2</td>
<td>10</td>
<td>No</td>
<td>16 (74)</td>
<td>17 (76)</td>
<td>20 (89)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>19 (80)</td>
<td>16 (83)</td>
<td>18 (87)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>18 (72)</td>
<td>18 (79)</td>
<td>17 (87)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>18 (77)</td>
<td>20 (80)</td>
<td>16 (89)</td>
</tr>
<tr>
<td>0.4 extremes</td>
<td>10</td>
<td>No</td>
<td>18 (62)</td>
<td>17 (67)</td>
<td>21 (81)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>15 (66)</td>
<td>17 (66)</td>
<td>20 (71)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>18 (58)</td>
<td>18 (66)</td>
<td>16 (82)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>17 (58)</td>
<td>18 (63)</td>
<td>18 (73)</td>
</tr>
<tr>
<td>1.0 highest 2</td>
<td>10</td>
<td>No</td>
<td>19 (99)</td>
<td>18 (99)</td>
<td>21 (98)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>18 (100)</td>
<td>19 (100)</td>
<td>17 (99)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>20 (99)</td>
<td>18 (99)</td>
<td>19 (99)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>19 (100)</td>
<td>18 (99)</td>
<td>19 (99)</td>
</tr>
<tr>
<td>1.0 extremes</td>
<td>10</td>
<td>No</td>
<td>18 (99)</td>
<td>19 (99)</td>
<td>19 (97)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>19 (99)</td>
<td>20 (99)</td>
<td>20 (96)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>17 (100)</td>
<td>17 (99)</td>
<td>19 (96)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>16 (100)</td>
<td>19 (99)</td>
<td>21 (97)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-1094428111403815">
<p>Note: DIF = differential item functioning.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Overall, out of the 112 conditions the NCDIF index had acceptable power levels (≥80%) in 70 of the conditions. Acceptable levels of power for the NCDIF index were not found when only the α parameter was manipulated in either condition. Similarly, acceptable power levels were not found when the last two β parameters were changed by 0.40 in either condition. Power levels near 100% were found when the β parameters were changed by 1.00, for both conditions where β parameters were manipulated. Combining α and β DIF generally produced acceptable levels of power, with the exception of when the α parameter was changed by 0.25 and the extreme β parameters where changed by 0.40.</p>
<p>
<xref ref-type="table" rid="table2-1094428111403815">Tables 6</xref> and <xref ref-type="table" rid="table1-1094428111403815">7</xref>

 present the Type I error rates and power estimates for the LRT index for equal and unequal sample sizes, respectively. All Type I error rates were less than 5% across both sample size conditions. Overall, the LRT had acceptable Type I error rates in every condition.</p>
<table-wrap id="table6-1094428111403815" position="float">
<label>Table 6.</label>
<caption>
<p>Type I Errors and Power for Equal Sample Sizes (likelihood ratio test)</p>
</caption>
<graphic alternate-form-of="table6-1094428111403815" xlink:href="10.1177_1094428111403815-table2.tif"/>
<table>
<thead>
<tr>
<th>β DIF</th>
<th>Items</th>
<th>Cancellation of DIF</th>
<th>No α DIF</th>
<th>0.25 α DIF</th>
<th>0.50 α DIF</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>10</td>
<td>No</td>
<td align="center">5</td>
<td>1 (46)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td align="center">–</td>
<td>0 (33)</td>
<td>0 (98)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td align="center">0</td>
<td>1 (49)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td align="center">–</td>
<td>1 (33)</td>
<td>0 (97)</td>
</tr>
<tr>
<td>0.4 highest 2</td>
<td>10</td>
<td>No</td>
<td>1 (67)</td>
<td>1 (41)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>0 (77)</td>
<td>1 (56)</td>
<td>1 (95)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>0 (69)</td>
<td>0 (44)</td>
<td>0 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>0 (80)</td>
<td>1 (61)</td>
<td>1 (95)</td>
</tr>
<tr>
<td>0.4 extremes</td>
<td>10</td>
<td>No</td>
<td>0 (87)</td>
<td>0 (100)</td>
<td>0 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>0 (88)</td>
<td>1 (99)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>0 (87)</td>
<td>1 (99)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>1 (90)</td>
<td>1 (99)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>1.0 highest 2</td>
<td>10</td>
<td>No</td>
<td>0 (100)</td>
<td>1 (100)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>1 (100)</td>
<td>0 (100)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>1 (100)</td>
<td>1 (100)</td>
<td>0 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>0 (100)</td>
<td>1 (99)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>1.0 extremes</td>
<td>10</td>
<td>No</td>
<td>0 (100)</td>
<td>2 (100)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>1 (100)</td>
<td>0 (100)</td>
<td>2 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>1 (100)</td>
<td>0 (100)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>1 (100)</td>
<td>1 (100)</td>
<td>2 (100)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-1094428111403815">
<p>Note: DIF = differential item functioning.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table7-1094428111403815" position="float">
<label>Table 7.</label>
<caption>
<p>Type I Errors and Power for Unequal Sample Sizes (likelihood ratio test)</p>
</caption>
<graphic alternate-form-of="table7-1094428111403815" xlink:href="10.1177_1094428111403815-table1.tif"/>
<table>
<thead>
<tr>
<th>β DIF</th>
<th>Items</th>
<th>Cancellation of DIF</th>
<th>No α DIF</th>
<th>0.25 α DIF</th>
<th>0.50 α DI</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>10</td>
<td>No</td>
<td align="center">1</td>
<td>2 (29)</td>
<td>1 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td align="center">–</td>
<td>2 (24)</td>
<td>1 (84)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td align="center">2</td>
<td>2 (31)</td>
<td>2 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td align="center">–</td>
<td>2 (23)</td>
<td>2 (84)</td>
</tr>
<tr>
<td>0.4 highest 2</td>
<td>10</td>
<td>No</td>
<td>3 (44)</td>
<td>3 (28)</td>
<td>3 (95)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>2 (56)</td>
<td>1 (38)</td>
<td>2 (84)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>3 (45)</td>
<td>2 (33)</td>
<td>2 (98)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>3 (55)</td>
<td>2 (42)</td>
<td>1 (85)</td>
</tr>
<tr>
<td>0.4 extremes</td>
<td>10</td>
<td>No</td>
<td>2 (66)</td>
<td>2 (91)</td>
<td>2 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>3 (70)</td>
<td>2 (87)</td>
<td>2 (98)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>2 (64)</td>
<td>2 (89)</td>
<td>2 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>2 (67)</td>
<td>2 (86)</td>
<td>2 (98)</td>
</tr>
<tr>
<td>1.0 highest 2</td>
<td>10</td>
<td>No</td>
<td>2 (100)</td>
<td>2 (95)</td>
<td>3 (99)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>3 (100)</td>
<td>2 (98)</td>
<td>2 (99)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>2 (100)</td>
<td>3 (96)</td>
<td>2 (98)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>2 (100)</td>
<td>2 (98)</td>
<td>3 (99)</td>
</tr>
<tr>
<td>1.0 extremes</td>
<td>10</td>
<td>No</td>
<td>2 (100)</td>
<td>3 (100)</td>
<td>3 (100)</td>
</tr>
<tr>
<td>
</td>
<td>10</td>
<td>Yes</td>
<td>3 (100)</td>
<td>2 (100)</td>
<td>2 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>No</td>
<td>4 (100)</td>
<td>2 (100)</td>
<td>2 (100)</td>
</tr>
<tr>
<td>
</td>
<td>20</td>
<td>Yes</td>
<td>4 (100)</td>
<td>2 (100)</td>
<td>2 (100)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn7-1094428111403815">
<p>Note: DIF = differential item functioning.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The LRT had acceptable power levels in 85 of the conditions. Acceptable levels of power were not found when only the α parameter was changed by 0.25 in either condition. Unlike the NCDIF index, acceptable power was found when only the α parameter was changed by 0.50 in 7 out of the 8 conditions. Acceptable power levels were also found in all conditions in which the two extreme β parameters were changed by 0.4 and the α parameter was changed by at least 0.25. In the unequal sample size condition when there was no α parameter DIF and the β parameter was changed by 0.40, acceptable power was not found. In the equal sample size condition, when there was no α parameter DIF and the extreme two β parameters were changed by 0.40, acceptable power was found in all of the conditions. However, when there was no α parameter DIF and the highest two β parameters were changed by 0.40, acceptable power was found in only one of the conditions. Power was also low when the highest two β parameters were changed by 0.4 and there was α parameter DIF of 0.25.</p>
</sec>
<sec id="section14-1094428111403815">
<title>Additional Analyses</title>
<p>We conducted some exploratory analyses to further examine the Type I error rates for the NCDIF index with unequal sample sizes. One possibility is that the small sample size (<italic>N</italic> = 250) for the focal group caused the poor Type I error rates. To assess this, we conducted analyses with sample sizes of 500 in the focal group and 1,000 in the reference group using the methods described above. No DIF was manipulated. The Type I error rates were 13% for the 10-item condition and 4% for the 20-item condition. This suggests that larger samples sizes and numbers of items may ameliorate the problem of unequal sample sizes. To further assess the 10-item condition, we conducted analyses to assess whether it was sample size inequality that drove the higher Type I errors for DFIT or whether it was solely the sample size of the focal group. We conducted analyses with sample sizes of 750 in the focal group and 1,000 in the reference group, a condition with 750 in the focal group and 1,500 in the reference group, and also a condition with 750 in the focal group and 3,000 in the reference group. Again, no DIF was manipulated. The Type I error rates were 1% in all three conditions. These results suggest that it is not necessarily the inequality of the sample sizes that creates larger Type I errors but instead the size of the focal group sample.</p>
</sec>
</sec>
<sec id="section15-1094428111403815">
<title>Discussion</title>
<p>Our first research question concerned how the manipulations affected the Type I error rates across tests. Overall, the LRT resulted in fewer Type I errors compared with NCDIF. In addition, the interaction between test type and sample equality suggested that the LRT had acceptable Type I error rates when sample sizes were equal or unequal. The NCDIF index performed adequately when sample sizes were equal but resulted in too many Type I errors when sample sizes were unequal. None of the other manipulations explained considerable, or greater than 1%, variance in Type I errors. This suggests that for both NCDIF and LRT, the test for items without DIF are not affected by the presence of items with DIF in the test. This is similar to <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al.’s (2007)</xref> work in which they found acceptable Type I error rates for non-DIF items when there were DIF items on the test.</p>
<p>Our second research question concerned how the manipulations affected the power estimates across tests. Overall, the LRT resulted in greater power to detect α parameter DIF compared with NCDIF. The power estimates suggest that when there was a small change in the α parameter, one test was not better at detecting the DIF than the other test. However, when there was a large change in the α parameter, the LRT had more power than NCDIF did. This suggests that NCDIF does not have the power to detect DIF when the item is more discriminating for one group versus another group. LRT, on the other hand, had acceptable power in all conditions when just the α parameter was changed by a large amount. This indicates that when an item is more discriminating for one group, the LRT is better at detecting this difference. This is consistent with <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al.’s (2007)</xref> study; they found that the NCDIF index did not consistently detect DIF when there was a small change in α parameter DIF.</p>
<p>Overall, the LRT exhibited greater power to detect β parameter DIF than NCDIF did. However, the interaction between test type and which β parameters DIF suggested that the NCDIF index was better able to detect the DIF when the last two β parameters were manipulated. The LRT was better able to detect the DIF caused by manipulating the two most extreme β parameters. This may have implications for researchers who expect that group differences occur only at the higher end of the scale. For example, applicants who fake may be more likely than incumbents to endorse the higher response options. In this situation, the NCDIF index may more applicable because it is more sensitive to this type of DIF. None of the other manipulations explained considerable variance in power.</p>
<p>Our results suggest that the NCDIF and LRT both had acceptable Type I error rates when sample sizes were equal but that NCDIF produced too many Type I errors when sample sizes were unequal. This was probably caused by the smaller sample sizes used for the focal group. This effect was decreased when the focal group’s sample size increased. The differences in sample sizes between the focal and reference groups did not appear to affect Type I errors.</p>
<p>Finally, the LRT demonstrated more power across conditions. In particular, LRT had greater power to detect DIF caused by different α parameters. This is important because previous research has suggested that NCDIF is not sensitive to this type of DIF (<xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al., 2007</xref>). The LRT also demonstrated acceptable power to detect β DIF in most conditions. However, the NCDIF index has higher power when the last two β parameters are manipulated, but LRT has higher power when the two most extreme β parameters are manipulated. This makes sense because the NCDIF is based on the difference between expected scores for each of the two groups. Changing the two highest β parameters will have a larger effect on expected scores compared to changing the two extreme β parameters.</p>
<p>It is interesting to compare the results of the NCDIF analysis with those of <xref ref-type="bibr" rid="bibr19-1094428111403815">Meade et al. (2007)</xref>. Similar to Meade et al., we found that the Type I error rates for the NCDIF index were acceptable across most conditions for equal sample sizes and that the NCDIF index is not sensitive to α parameter DIF when there is no β parameter DIF. Meade et al. found that when DIF cancelled, the NCDIF index was better able to detect it. We found this to be the case as well. Finally, similar to Meade et al., we found that NCDIF was more powerful when the last two β parameters had DIF as opposed to the extreme β parameters. However, we found the magnitude of the β DIF had a less of an impact on power than Meade et al. found. This may be due to the fact that, unlike Meade et al., we did not use the condition of changing all four β parameters.</p>
<p>It is more difficult to compare the results for the LRT to previous research because there have been few studies examining it as we did. In general, the previous research has suggested that the LRT has acceptable Type I errors across most situations, and it is powerful when sample sizes are adequate (e.g., <xref ref-type="bibr" rid="bibr2-1094428111403815">Ankenmann et al., 1999</xref>; <xref ref-type="bibr" rid="bibr13-1094428111403815">Kim &amp; Cohen, 1998</xref>; <xref ref-type="bibr" rid="bibr18-1094428111403815">Meade &amp; Lautenschlager, 2004</xref>). Our results are consistent with this. In addition, we found that it compared favorably to the NCDIF index in terms of Type I errors and power.</p>
<p>It is also worthy of note that there is a difference in the number of anchor items across the two methods. The LRT linked on three items, whereas all available non-DIF items were used for linking for the NCDIF. Past researchers have found that increasing the number of anchor items improves DIF detection (e.g., <xref ref-type="bibr" rid="bibr31-1094428111403815">Rivas et al., 2009</xref>; <xref ref-type="bibr" rid="bibr39-1094428111403815">Wang &amp; Yeh, 2003</xref>). Thus, the NCDIF may have had an advantage over the LRT in our study. However, we found the LRT to be more powerful in general, and our results may provide somewhat of a conservative estimate of the advantage of LRT over NCDIF.</p>
<sec id="section16-1094428111403815">
<title>Limitations and Future Research</title>
<p>We investigated only how well NCDIF and LRT could detect DIF when using the GRM as the generating model, but researchers should investigate other models. Generating the data using the generalized partial credit model (<xref ref-type="bibr" rid="bibr22-1094428111403815">Muraki, 1992</xref>) or the generalized graded unfolding model (<xref ref-type="bibr" rid="bibr32-1094428111403815">Roberts, Donoghue, &amp; Laughlin, 2000</xref>), for example, could have different results. In addition, we generated all of the θ values using a standard normal distribution. Future research could examine the effects of other distributions of θ. It may also be interesting to generate θ values with different distributions for the focal and reference group. For example, it may be useful to assess the performance of tests for DIF when one of the groups has a restricted θ distribution. This may reflect a common situation in comparing applicants and incumbents where one of the groups may have a restricted range.</p>
<p>Researchers should examine different sample sizes and test lengths to ensure that the results from this study are constant across conditions. Using smaller sample sizes that are more likely to occur in the real world would yield useful information. Previous research has found that the LRT does not have optimal power in conditions where sample sizes are less than 500 (e.g., <xref ref-type="bibr" rid="bibr2-1094428111403815">Ankenmann et al., 1999</xref>; <xref ref-type="bibr" rid="bibr18-1094428111403815">Meade &amp; Lautenschlager, 2004</xref>). More research should examine how the NCDIF handles smaller sample sizes. Finally, there are a number of other DIF detection indices that should be examined in addition to LRT and DFIT. The poly-SIBTEST (<xref ref-type="bibr" rid="bibr7-1094428111403815">Chang, Mazzeo, &amp; Roussos, 1996</xref>) and Mantel-Haenszel (<xref ref-type="bibr" rid="bibr15-1094428111403815">Mantel &amp; Haenszel, 1959</xref>) are two examples that could be more closely examined and directly compared with the two indices in the present study.</p>
</sec>
<sec id="section17-1094428111403815">
<title>Implications and Recommendations</title>
<p>Our results have several implications for using tests of DIF. First, the LRT should be preferred when there are unequal sample sizes. We found that when the sample sizes are unequal the NCDIF index commits more Type I errors than the LRT and that the LRT still had acceptable Type I errors. This is important because it is likely that DIF studies will have unequal sample sizes. In addition, the LRT has higher power estimates than NCDIF does when sample sizes are unequal.</p>
<p>The LRT has better power across most conditions. In particular, LRT had more power to detect DIF caused by different item discrimination parameters. However, the LRT had less power than NCDIF to detect DIF when the two highest difficulty values were changed by a moderate amount. This suggests that the LRT and NCDIF indices may be able to capture different patterns of DIF, and the preference of which test to use depends on the type of DIF present. In practice, researchers will not know what type of DIF, but they may have some expectations. For example, it may be that applicants are more likely than incumbents to endorse the highest two response options on conscientiousness items. Our findings suggest that the NCDIF index would be better able to detect this and therefore might be preferred for that situation.</p>
<p>Although there are some specific situations where the NCDIF index may be preferred, we suggest that the LRT should be preferred overall because of its consistent Type I error rates and overall power. In addition, we found the LRT is easier to implement than the NCDIF index. The LRT output indicates the χ<sup>2</sup> statistic associated with the overall item as well as the χ<sup>2</sup> statistic associated with the α parameter and the β parameter. This allows the researchers to identify where the DIF is located for a particular item. In addition, the LRT does not require the linking or calculation of empirical cutoffs needed by the NCDIF index.</p>
<p>Despite all of the differences mentioned throughout the article, as one reviewer pointed out, it should be noted that NCDIF and LRT are similar methodologies. They are essentially both area methods. The difference lies in how these indices use the area information. NCDIF uses the equated parameter estimates to assess differences between IRFs. The LRT directly calculates the likelihood under the constraint of equal item parameters and compares it against the likelihood if parameters were free. Conceptually, both indices are comparing IRFs. Furthermore, the two indices lead to the same conclusion most of the time.</p>
<p>One issue in using the LRT (and for NCDIF) is choosing the appropriate anchor items. Using anchor items that exhibit DIF can lead to inflated Type I errors. In the present study, we had the advantage of knowing a priori which items had DIF. Obviously, this would not be the case in most situations. This creates a bit of a chicken-and-egg problem where researchers need to identify a couple of items that do not have DIF that can serve as anchors to test for DIF. Past researchers have recommended using an initial run of the constrained baseline method to identify DIF-free items that can serve as anchors (<xref ref-type="bibr" rid="bibr35-1094428111403815">Stark et al., 2006</xref>). The major problem with the constrained baseline method is the large Type I errors. Thus, items that are not flagged as having DIF with this method probably do not have DIF. This approach is somewhat similar to the multistage linking process, often called <italic>iterative linking,</italic> required by the NCDIF index (<xref ref-type="bibr" rid="bibr6-1094428111403815">Candell &amp; Drasgow, 1998</xref>), and will likely lead to the identification of appropriate anchor items.</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict" id="fn3-1094428111403815">
<p>The author(s) declared no potential conflicts of interest with respect to the authorship and/or publication of this article. </p>
</fn>
<fn fn-type="financial-disclosure" id="fn4-1094428111403815">
<p>The author(s) received no financial support for the research and/or authorship of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Angoff</surname>
<given-names>W. H.</given-names>
</name>
<name>
<surname>Ford</surname>
<given-names>S. F.</given-names>
</name>
</person-group> (<year>1973</year>)
<article-title>Item-race interaction on a test of scholastic aptitude</article-title>
<source>Journal of Educational Measurement</source>
<volume>10</volume>
<comment>doi:10.1111/j.1745-3984.1973.tb00787.x</comment>
</citation>
</ref>
<ref id="bibr2-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ankenmann</surname>
<given-names>R. D.</given-names>
</name>
<name>
<surname>Witt</surname>
<given-names>E. A.</given-names>
</name>
<name>
<surname>Dunbar</surname>
<given-names>S. B.</given-names>
</name>
</person-group> (<year>1999</year>)
<article-title>An investigation of the power of the likelihood ratio goodness-of-fit statistic in detecting differential item functioning</article-title>
<source>Journal of Educational Measurement</source>
<volume>36</volume>
<comment>doi:10.1111/j.1745-3984.1999.tb00558.x</comment>
</citation>
</ref>
<ref id="bibr3-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Baker</surname>
<given-names>F. B.</given-names>
</name>
</person-group> (<year>1995</year>). <article-title>EQUATE 2.1: <italic>Computer program for equating two metrics in item response theory</italic></article-title> [<comment>Computer program</comment>]. <publisher-name>Madison</publisher-name>: <publisher-loc>University of Wisconsin, Laboratory of Experimental Design</publisher-loc>
</citation>
</ref>
<ref id="bibr4-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bolt</surname>
<given-names>D. M.</given-names>
</name>
</person-group> (<year>2002</year>)
<article-title>A Monte Carlo comparison of parametric and nonparametric polytomous DIF detection methods</article-title>
<source>Applied Measurement in Education</source>
<volume>15</volume>
<comment>doi:10.1207/S15324818AME1502_01</comment>
</citation>
</ref>
<ref id="bibr5-1094428111403815">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name>
<surname>Braddy</surname>
<given-names>P. W.</given-names>
</name>
<name>
<surname>Meade</surname>
<given-names>A. W.</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>E. C.</given-names>
</name>
</person-group> (<year>2006</year>). <source>Practical implications of using different tests of measurement invariance for polytomous measures</source>. <conf-loc>Paper presented at the 21st Annual Conference of the Society for Industrial and Organizational Psychology, Dallas, TX</conf-loc>.</citation>
</ref>
<ref id="bibr6-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Candell</surname>
<given-names>G. L.</given-names>
</name>
<name>
<surname>Drasgow</surname>
<given-names>F.</given-names>
</name>
</person-group> (<year>1988</year>)
<article-title>An iterative procedure for linking metrics and assessing item bias in item response theory</article-title>
<source>Applied Psychological Measurement</source>
<volume>12</volume>
</citation>
</ref>
<ref id="bibr7-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chang</surname>
<given-names>H. H.</given-names>
</name>
<name>
<surname>Mazzeo</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Roussos</surname>
<given-names>L.</given-names>
</name>
</person-group> (<year>1996</year>)
<article-title>Detecting DIF for polytomously scored items: An adaptation of the SIBTEST procedure</article-title>
<source>Journal of Educational Measurement</source>
<volume>33</volume>
</citation>
</ref>
<ref id="bibr8-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Collins</surname>
<given-names>W. C.</given-names>
</name>
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
<name>
<surname>Edwards</surname>
<given-names>J. E.</given-names>
</name>
</person-group> (<year>2000</year>)
<article-title>Assessing differential functioning in a satisfaction scale</article-title>
<source>Journal of Applied Psychology</source>
<volume>85</volume>
<comment>doi:10.1037/0021-9010.85.3.451</comment>
</citation>
</ref>
<ref id="bibr9-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Donovan</surname>
<given-names>M. A.</given-names>
</name>
<name>
<surname>Drasgow</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Probst</surname>
<given-names>T. M.</given-names>
</name>
</person-group> (<year>2000</year>)
<article-title>Does computerizing paper-and-pencil job attitude scales make a difference? New IRT analyses offer insight</article-title>
<source>Journal of Applied Psychology</source>
<volume>85</volume>
<comment>doi:10.1037/0021-9010.85.2.305</comment>
</citation>
</ref>
<ref id="bibr10-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Flowers</surname>
<given-names>C. P.</given-names>
</name>
<name>
<surname>Oshima</surname>
<given-names>T. C.</given-names>
</name>
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
</person-group> (<year>1999</year>)
<article-title>A description and demonstration of the polytomous-DFIT framework</article-title>
<source>Applied Psychological Measurement</source>
<volume>23</volume>
<comment>doi:10.1177/01466219922031437</comment>
</citation>
</ref>
<ref id="bibr11-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Henry</surname>
<given-names>M. S.</given-names>
</name>
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
</person-group> (<year>2006</year>)
<article-title>The effects of trailed and situational impression management on a personality test: An empirical analysis</article-title>
<source>Psychological Science</source>
<volume>48</volume>
</citation>
</ref>
<ref id="bibr12-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Holland</surname>
<given-names>P. W.</given-names>
</name>
<name>
<surname>Thayer</surname>
<given-names>D. T.</given-names>
</name>
</person-group> (<year>1988</year>)
<article-title>Differential item functioning and the Mantel-Haenszel procedure</article-title>
<person-group person-group-type="editor">
<name>
<surname>Wainer</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Braun</surname>
<given-names>H. I.</given-names>
</name>
</person-group> (Eds.), <publisher-loc>Hillsdale, NJ</publisher-loc>
<publisher-name>Lawrence Erlbaum</publisher-name>
</citation>
</ref>
<ref id="bibr13-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kim</surname>
<given-names>S. -H.</given-names>
</name>
<name>
<surname>Cohen</surname>
<given-names>A. S.</given-names>
</name>
</person-group>  (<year>1988</year>)
<article-title>Detection of differential item functioning under the graded response model with the likelihood ratio test</article-title>
<source>Applied Psychological Measurement</source>
<volume>22</volume>
<comment>doi:10.1177/014662169802200403</comment>
</citation>
</ref>
<ref id="bibr14-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lord</surname>
<given-names>F. M.</given-names>
</name>
</person-group> (<year>1980</year>) <source>Applications of item response theory to practical testing problems</source>.
<publisher-loc>Hillsdale, NJ</publisher-loc>
<publisher-name>Lawrence Erlbaum</publisher-name>
</citation>
</ref>
<ref id="bibr15-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mantel</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Haenszel</surname>
<given-names>W.</given-names>
</name>
</person-group> (<year>1959</year>)
<article-title>Statistical aspects of the analysis of data from retrospective studies of disease</article-title>
<source>Journal of the National Cancer Institute</source>
<volume>22</volume>
</citation>
</ref>
<ref id="bibr16-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Maurer</surname>
<given-names>T. J.</given-names>
</name>
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
<name>
<surname>Collins</surname>
<given-names>W. C.</given-names>
</name> 
</person-group> (<year>1998</year>)
<article-title>Peer and subordinate performance appraisal measurement equivalence</article-title>
<source>Journal of Applied Psychology</source>
<volume>83</volume>
</citation>
</ref>
<ref id="bibr17-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meade</surname>
<given-names>A. W.</given-names>
</name>
</person-group> (<year>2010</year>)
<article-title>A taxonomy of effect size measures for the differential functioning of items and scales</article-title>
<source>Journal of Applied Psychology</source>
<volume>95</volume>
</citation>
</ref>
<ref id="bibr18-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meade</surname>
<given-names>A. W.</given-names>
</name>
<name>
<surname>Lautenschlager</surname>
<given-names>G. J.</given-names>
</name>
</person-group> (<year>2004</year>)
<article-title>A comparison of item response theory and confirmatory factor analytic methodologies for establishing measurement equivalence/invariance</article-title>
<source>Organizational Research Methods</source>
<volume>7</volume>
<comment>doi:10.1177/1094428104268027</comment>
</citation>
</ref>
<ref id="bibr19-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meade</surname>
<given-names>A. W.</given-names>
</name>
<name>
<surname>Lautenschlager</surname>
<given-names>G. J.</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>E. C.</given-names>
</name>
</person-group> (<year>2007</year>)
<article-title>A Monte Carlo examination of the sensitivity of the differential functioning of items and tests framework for tests of measurement invariance with Likert data</article-title>
<source>Applied Psychological Measurement</source>
<volume>31</volume>
<comment>doi:10.1177/0146621606297316</comment>
</citation>
</ref>
<ref id="bibr20-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Morales</surname>
<given-names>L. S.</given-names>
</name>
<name>
<surname>Flowers</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Gutierrez</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Kleinman</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Teresi</surname>
<given-names>J. A.</given-names>
</name>
</person-group> (<year>2006</year>)
<article-title>Item and scale differential functioning of the Mini-Mental State Exam assessed using the differential item and test functioning (DFIT) framework</article-title>
<source>Medical Care</source>
<volume>44</volume>
</citation>
</ref>
<ref id="bibr21-1094428111403815">
<citation citation-type="web">
<person-group person-group-type="author">
<name>
<surname>Morris</surname>
<given-names>S.</given-names>
</name>
</person-group> (<year>2008</year>). <source>Polycov</source> [<comment>Computer program</comment>]. <comment>Retrieved August 2009 from</comment> <ext-link ext-link-type="uri" xlink:href="http://mypages.iit.edu/~morriss/polycov/polycov.html">http://mypages.iit.edu/~morriss/polycov/polycov.html</ext-link>
</citation>
</ref>
<ref id="bibr22-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Muraki</surname>
<given-names>E.</given-names>
</name>
</person-group> (<year>1992</year>)
<article-title>A generalized partial credit model: Application of an EM algorithm</article-title>
<source>Applied Psychological Measurement</source>
<volume>16</volume>
<comment>doi:10.1177/014662169201600206</comment>
</citation>
</ref>
<ref id="bibr23-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Muraki</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Bock</surname>
<given-names>R. D.</given-names>
</name>
</person-group> (<year>2003</year>). <source>PARSCALE 4: IRT item analysis and test scoring for rating-scale data</source> [<comment>Computer program</comment>]. <publisher-loc>Chicago</publisher-loc>: <publisher-name>Scientific Software</publisher-name>
</citation>
</ref>
<ref id="bibr24-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Oshima</surname>
<given-names>T. C.</given-names>
</name>
<name>
<surname>Kushubar</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Scott</surname>
<given-names>J. C.</given-names>
</name>
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
</person-group> (<year>2009</year>)
<publisher-loc>St. Paul, MN</publisher-loc>
<publisher-name>Assessment Systems Corporation</publisher-name>
</citation>
</ref>
<ref id="bibr25-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Oshima</surname>
<given-names>T. C.</given-names>
</name>
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
<name>
<surname>Nanda</surname> 
<given-names>A. O.</given-names>
</name>
</person-group> (<year>2006</year>)
<article-title>A new method for assessing the statistical significance in the differential functioning of items and tests (DFIT) framework</article-title>
<source>Journal of Educational Measurement</source>
<volume>43</volume>
<comment>doi:10.1111/j.1745-3984.2006.00001.x</comment>
</citation>
</ref>
<ref id="bibr26-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
</person-group> (<year>1988</year>)
<article-title>The area between two item characteristic curves</article-title>
<source>Psychometrika</source>
<volume>53</volume>
<comment>doi:10.1007/BF02294403</comment>
</citation>
</ref>
<ref id="bibr27-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
</person-group> (<year>1990</year>)
<article-title>Determining the significance of estimated signed and unsigned areas between two item response functions</article-title>
<source>Applied Psychological Measurement</source>
<volume>14</volume>
<comment>doi:10.1177/014662169001400208</comment>
</citation>
</ref>
<ref id="bibr28-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
<name>
<surname>Fortmann-Johnson</surname>
<given-names>K. A.</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Morris</surname>
<given-names>S. B.</given-names>
</name>
<name>
<surname>Nering</surname>
<given-names>M. L.</given-names>
</name>
<name>
<surname>Oshima</surname>
<given-names>T. C.</given-names>
</name>
</person-group> (<year>2009</year>)
<article-title>The item parameter replication method for detecting differential functioning in the polytomous DFIT framework</article-title>
<source>Applied Psychological Measurement</source>
<volume>33</volume>
</citation>
</ref>
<ref id="bibr29-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
<name>
<surname>Laffitte</surname>
<given-names>L. J.</given-names>
</name>
<name>
<surname>Byrne</surname>
<given-names>B. M.</given-names>
</name>
</person-group> (<year>2002</year>)
<article-title>Measurement equivalence: A comparison of methods based on confirmatory factor analysis and item response theory</article-title>
<source>Journal of Applied Psychology</source>
<volume>87</volume>
<comment>doi:10.1037/0021-9010.87.3.517</comment>
</citation>
</ref>
<ref id="bibr30-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Raju</surname>
<given-names>N. S.</given-names>
</name>
<name>
<surname>van der Linden</surname>
<given-names>W. J.</given-names>
</name>
<name>
<surname>Fleer</surname>
<given-names>P. F.</given-names>
</name>
</person-group> (<year>1995</year>)
<article-title>IRT-based internal measures of differential functioning of items and tests</article-title>
<source>Applied Psychological Measurement</source>
<volume>19</volume>
<comment>doi:10.1177/014662169501900405</comment>
</citation>
</ref>
<ref id="bibr31-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rivas</surname>
<given-names>G. E.</given-names>
</name>
<name>
<surname>Stark</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Chernyshenko</surname>
<given-names>O. S.</given-names>
</name>
</person-group> (<year>2009</year>)
<article-title>The effects of referent item parameters on differential item functioning detection using the free baseline likelihood ratio test</article-title>
<source>Applied Psychological Measurement</source>
<volume>33</volume>
<comment>doi:10.1177/0146621608321760</comment>
</citation>
</ref>
<ref id="bibr32-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Roberts</surname>
<given-names>J. S.</given-names>
</name>
<name>
<surname>Donoghue</surname>
<given-names>J. R.</given-names>
</name>
<name>
<surname>Laughlin</surname>
<given-names>J. E.</given-names>
</name>
</person-group> (<year>2000</year>)
<article-title>A general item response theory model for unfolding unidimensional polytomous responses</article-title>
<source>Applied Psychological Measurement</source>
<volume>24</volume>
<comment>doi:10.1177/01466216000241001</comment>
</citation>
</ref>
<ref id="bibr33-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Robie</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Zickar</surname>
<given-names>M. J. , &amp; Schmit, M. J.</given-names>
</name>
</person-group> (<year>2001</year>)
<article-title>Measurement equivalence between applicant and incumbent groups: An IRT analysis of personality scales</article-title>
<source>Human Performance</source>
<volume>14</volume>
<comment>doi:10.1207/S15327043HUP1402_04</comment>
</citation>
</ref>
<ref id="bibr34-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Samejima</surname>
<given-names>F.</given-names>
</name>
</person-group> (<year>1969</year>). <source>Estimation of latent ability using a response pattern of graded scores</source>. (<comment>Psychometric Monograph No. 17</comment>). <publisher-loc>Richmond, VA</publisher-loc>: <publisher-name>Psychometric Society</publisher-name>
</citation>
</ref>
<ref id="bibr35-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stark</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Chernyshenko</surname>
<given-names>O. S.</given-names>
</name>
<name>
<surname>Drasgow</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>B. A.</given-names>
</name>
</person-group> (<year>2006</year>)
<article-title>Detecting differential item functioning with confirmatory factor analysis and item response theory: Toward a unified strategy</article-title>
<source>Journal of Applied Psychology</source>
<volume>91</volume>
<comment>. doi:10.1037/0021-9010.91.6.1292</comment>
</citation>
</ref>
<ref id="bibr36-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Thissen</surname>
<given-names>D.</given-names>
</name>
</person-group> (<year>2001</year>). <source>IRTLRDIF v.2.0b: Software for the computation of the statistics involved in item response theory likelihood-ratio tests for differential item functioning</source> [<comment>Computer software</comment>]. <publisher-loc>Chapel Hill</publisher-loc>: <publisher-name>University of North Carolina</publisher-name>.
</citation>
</ref>
<ref id="bibr37-1094428111403815">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Thissen</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Steinberg</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Wainer</surname>
<given-names>H.</given-names>
</name>
</person-group> (<year>1988</year>)
<article-title>Use of item response theory in the study of group differences in trace lines</article-title>
<person-group person-group-type="editor">
<name>
<surname>Wainer</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Braun</surname>
<given-names>H. I.</given-names>
</name>
</person-group> (Eds.), <publisher-loc>Hillsdale, NJ</publisher-loc>
<publisher-name>Lawrence Erlbaum</publisher-name>
</citation>
</ref>
<ref id="bibr38-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>W. C.</given-names>
</name>
</person-group> (<year>2004</year>)
<article-title>Effects of anchor item methods on differential item functioning detection within the family of Rasch models</article-title>
<source>Journal of Experimental Education</source>
<volume>72</volume>
</citation>
</ref>
<ref id="bibr39-1094428111403815">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>W. C.</given-names>
</name>
<name>
<surname>Yeh</surname>
<given-names>Y. L.</given-names>
</name>
</person-group> (<year>2003</year>)
<article-title>Effects of anchor item methods on differential item functioning detection with the likelihood ratio test</article-title>
<source>Applied Psychological Measurement</source>
<volume>27</volume>
<comment>doi:10.1177/0146621603259902</comment>
</citation>
</ref>
</ref-list>
</back>
</article>