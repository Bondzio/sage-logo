<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JPA</journal-id>
<journal-id journal-id-type="hwp">spjpa</journal-id>
<journal-title>Journal of Psychoeducational Assessment</journal-title>
<issn pub-type="ppub">0734-2829</issn>
<issn pub-type="epub">1557-5144</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0734282912439504</article-id>
<article-id pub-id-type="publisher-id">10.1177_0734282912439504</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Factor-Analytic Study of the Structure of the Brigance Comprehensive Inventory of Basic Skills-II</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Breidenbach</surname><given-names>Daniel H.</given-names></name>
<xref ref-type="aff" rid="aff1-0734282912439504">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>French</surname><given-names>Brian F.</given-names></name>
<xref ref-type="aff" rid="aff2-0734282912439504">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0734282912439504"><label>1</label>Applied Measurement Professionals, Inc., Olathe, KS, USA</aff>
<aff id="aff2-0734282912439504"><label>2</label>Washington State University, Pullman, WA, USA</aff>
<author-notes>
<corresp id="corresp1-0734282912439504">Brian F. French, College of Education, Washington State University, Cleveland Hall, Rm 362, Pullman, WA 99163, USA Email: <email>frenchb@wsu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>30</volume>
<issue>5</issue>
<fpage>478</fpage>
<lpage>487</lpage>
<permissions>
<copyright-statement>© 2012 SAGE Publications</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The Brigance Comprehensive Inventory of Basic Skills-II (CIBS-II) is the newest version of a long-standing instrument that is useful for identifying student achievement, identifying and monitoring academic strengths and weaknesses, obtaining data to support referrals, and reporting progress for individual educational plans. Since the CIBS-II is intended to comply with requirements of the No Child Left Behind Act (NCLB) and the Individuals with Disabilities Education Act (IDEA), validity studies are required. This study provides evidence to support the use of CIBS-II scores. Confirmatory factor analysis (CFA) was used to evaluate the proposed factor model and rival models. A randomly split sample design allowed for cross-validation evidence. The best-fitting model was in accordance with the proposed structure.</p>
</abstract>
<kwd-group>
<kwd>confirmatory factor analysis</kwd>
<kwd>achievement tests</kwd>
<kwd>validation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Validation studies for achievement tests typically address the suitability of the tests for making inferences about strengths and weaknesses of individual students or the relative standing of students compared to others. In light of the increased push for accountability and the associated increase in public scrutiny of test scores, it is crucial that achievement tests meet the highest standards in all aspects of the testing process (e.g., <xref ref-type="bibr" rid="bibr1-0734282912439504">American Educational Research Association [AERA], American Psychological Association [APA], &amp; National Council on Measurement in Education [NCME], 1999</xref>). Well-conceived and properly reported validity studies provide evidence that test scores are meaningful and inform test users of the intended uses of the scores. We do recognize that much of the assessment focus is occurring in the United States. However, this testing environment does influence an international population such as students wanting to study in the United States (e.g., GRE, TOFEL) as well as publication outlets (e.g., <italic>International Journal of Testing; Language Testing</italic>).</p>
<p>Although many state achievement assessments are developed to comply with such governmental mandates as the No Child Left Behind Act (<xref ref-type="bibr" rid="bibr29-0734282912439504">NCLB, 2002</xref>), other achievement tests are published for diagnostic use, low-stakes monitoring of student performance, and screening of students with learning difficulties (<xref ref-type="bibr" rid="bibr23-0734282912439504">Koretz &amp; Hamilton, 2006</xref>), in accord with Individuals with Disabilities Education Act (<xref ref-type="bibr" rid="bibr18-0734282912439504">IDEA, 2004</xref>). However, evidence must be provided that the scores and structure are useful for the developer’s and user’s intended interpretation (<xref ref-type="bibr" rid="bibr28-0734282912439504">Messick, 1989</xref>). That said, factor analytic studies of achievement tests are uncommon, in comparison to other student-level measures (e.g., motivation, test anxiety, intelligence). Validity studies for achievement tests typically do not investigate factor structures (e.g., <xref ref-type="bibr" rid="bibr8-0734282912439504">Connolly, 1998</xref>; <xref ref-type="bibr" rid="bibr11-0734282912439504">Erford &amp; Dutton, 2005</xref>), and “there is surprisingly little published evidence that supports the structure of such instruments” (<xref ref-type="bibr" rid="bibr30-0734282912439504">Stevens &amp; Zvoch, 2007</xref>, p. 977).</p>
<sec id="section1-0734282912439504">
<title>Brigance Comprehensive Inventory of Basic Skills-II</title>
<p>This study focuses on the Brigance Comprehensive Inventory of Basic Skills-II (CIBS-II; <xref ref-type="bibr" rid="bibr5-0734282912439504">Brigance, 2010</xref>). The CIBS-II is presented as an instrument useful for identifying students’ levels of performance, identifying and monitoring academic strengths and weaknesses, obtaining data to support referrals for further diagnostic testing, and monitoring and reporting student progress for individual educational plans (<xref ref-type="bibr" rid="bibr14-0734282912439504">French &amp; Glascoe, 2010</xref>). The CIBS-II can be administered by school psychologists, diagnosticians, or classroom teachers. Indeed, the appeal of the CIBS-II is that multidisciplinary teams may use composite scores in the complex assessment process to identify a specific learning disability.</p>
<p>The nine subtests included in the standardization version of the CIBS-II are designed to cluster into the following composites: Basic Reading, Reading Comprehension, Mathematics, Written Expression, and Listening Comprehension as seen in <xref ref-type="table" rid="table1-0734282912439504">Table 1</xref>. These composites align with areas of achievement designated under the IDEA to be used in the detection of learning disabilities. Since the CIBS-II is intended to comply with requirements of the IDEA and the NCLB act, validity studies are required.</p>
<table-wrap id="table1-0734282912439504" position="float">
<label>Table 1.</label>
<caption>
<p>Composite Score Structure of the CIBS-II Subtests</p>
</caption>
<graphic alternate-form-of="table1-0734282912439504" xlink:href="10.1177_0734282912439504-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Subtest</th>
<th align="center">Internal Consistency Reliability</th>
<th align="center">Composite</th>
</tr>
</thead>
<tbody>
<tr>
<td>Word recognition</td>
<td>.987</td>
<td>Basic reading</td>
</tr>
<tr>
<td>Word analysis survey</td>
<td>.955</td>
<td/>
</tr>
<tr>
<td>Reading vocabulary comprehension</td>
<td>.921</td>
<td>Reading comprehension</td>
</tr>
<tr>
<td>Comprehends passages</td>
<td>.974</td>
<td/>
</tr>
<tr>
<td>Computational skills</td>
<td>.925</td>
<td>Mathematics</td>
</tr>
<tr>
<td>Problem solving</td>
<td>.859</td>
<td/>
</tr>
<tr>
<td>Spelling</td>
<td>.960</td>
<td>Written expression</td>
</tr>
<tr>
<td>Sentence writing</td>
<td>.807</td>
<td/>
</tr>
<tr>
<td>Listening vocabulary comprehension</td>
<td>.894</td>
<td>Listening comprehension</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>As early as 1983, the lack of validity evidence for the CIBS was noted: “The test author, while explaining how grade levels were derived, provided no statistical data justifying the procedure or verifying the validity of the test scores” (<xref ref-type="bibr" rid="bibr24-0734282912439504">Krawiec &amp; Spadafore, 1983</xref>, p. 230). Early studies focused on content validity (e.g., <xref ref-type="bibr" rid="bibr12-0734282912439504">Ferguson &amp; Kersting, 1988</xref>) because the CIBS was intended for instructional decision making, not prediction or educational placement. The CIBS-Revised (CIBS-R; <xref ref-type="bibr" rid="bibr4-0734282912439504">Brigance, 1998</xref>) introduced a composite score structure that implies that a group of constructs are being measured by the subtests. The CIBS-R technical manual (<xref ref-type="bibr" rid="bibr15-0734282912439504">Glascoe, 1999</xref>) uses correlations among subtests as evidence of construct validity; however, this evidence is inadequate, as correlations do not necessarily support the intended interpretation of the scores (<xref ref-type="bibr" rid="bibr7-0734282912439504">Cizek, 2001</xref>) and a lack of dimensionality evidence can lead to erroneous conclusions about the test structure (<xref ref-type="bibr" rid="bibr16-0734282912439504">Green, 2007</xref>). The widespread use of previous versions of the CIBS (<xref ref-type="bibr" rid="bibr27-0734282912439504">McLellan, 2001</xref>) suggests that the CIBS-II has the potential to influence many children.</p>
<p>The proposed structure of the CIBS-II contains the same composites as the CIBS-R; however, the CIBS-II standardization sample is larger and more representative of the intended audience. A validation study of the internal structure of the CIBS-II will provide evidence to support interpretations of the test’s scores. Moreover, as school-based multidisciplinary teams and evaluating psychologists employ composite scores in making diagnostic and eligibility decisions, such validity evidence is needed to support these uses of the scores.</p>
<p>Evidence to support a proposed structure can be collected via confirmatory factor analysis (CFA). CFA can assist in understanding the internal structure of a test and provide evidence in support of a proposed interpretation of the scores. Alternative models can be tested, which may lead to stronger evidence of validity (<xref ref-type="bibr" rid="bibr32-0734282912439504">Thompson &amp; Daniel, 1996</xref>). Thus, we sought confirming or disconfirming evidence about the proposed score structure. The specific question in the present study was, “To what extent do scores from the standardization sample of the CIBS-II support the composite score structure provided by the publisher?”</p>
</sec>
<sec id="section2-0734282912439504" sec-type="methods">
<title>Method</title>
<sec id="section3-0734282912439504">
<title>Participants</title>
<p>CIBS-II national standardization sample data were provided by Curriculum Associates, Inc. See the technical manual for a description of data collection procedures and the standardization sample (<xref ref-type="bibr" rid="bibr14-0734282912439504">French &amp; Glascoe, 2010</xref>). The stratified random sample (<italic>N</italic> = 1,411) was composed of students from the four main regions of the United States: Northeast (12%), South (32%), Midwest (36%), and West (21%). Sex representations were approximately equal (48% = female, 52% = male), and racial representations closely matched national proportions for elementary school–aged children (e.g., <xref ref-type="bibr" rid="bibr10-0734282912439504">Department of Education, Institute of Education Sciences, 2007</xref>): 48% White, 19% Hispanic, 20% African American, 2% Asian, 4% multiple races, 3% other, with 4% not reporting. To allow for model cross-validation, participant records were randomly assigned to subgroups of 706 and 705 participants, respectively.</p>
</sec>
<sec id="section4-0734282912439504">
<title>Instrument</title>
<p>The CIBS-II for Grades 1 to 6 includes more than 150 subtests. Nine subtests that comprise the standardized portion of the CIBS-II were used in this study. The typical administration time is 45 to 55 min. A brief description of each subtest follows. The Basic Reading composite includes (a) the Word Recognition subtest where children quickly read aloud words arranged into lists by grade level, from preprimer to Grade 8, and (b) the Word Analysis Survey subtest where children identify sounds heard in words read aloud by the test administrator, read aloud words and nonsense words to sample phonemic awareness, and divide words into syllables. The Reading Comprehension composite is composed of (a) the Reading Vocabulary Comprehension subtest where children indicate single-word comprehension of printed words by choosing the one word with a different meaning from groups of five words each, and (b) the Comprehends Passages subtest where children read a short passage between primer and Grade 9 levels and answer five oral-response, multiple-choice questions about the passage. The Math composite is composed of (a) the Computational Skills subtest where children solve arithmetic problems involving addition, subtraction, multiplication, division, fractions, and percentages, and (b) the Problem-Solving subtest where children solve arithmetic word problems. The Written Expression composite is composed of (a) the Spelling subtest where children complete a standard written spelling test with words arranged in first-grade through eighth-grade lists, and (b) the Sentence Writing subtest where children attempt to compose a single sentence from a given set of words. Last, the Listening Comprehension Indicator is composed of the Listening Vocabulary Comprehension subtest where children indicate single-word comprehension of words read aloud by the test administrator.</p>
<p>The subtests consist of dichotomously scored items. Subtest scores were normalized by age category and scaled to have a mean of 10 and a standard deviation of 3. Composite scores were created by summing the subtest scaled scores associated with the respective composite and then reported as standard scores, with a mean of 100 and standard deviation of 15. Internal consistency reliability coefficients (Cronbach’s alpha) of the subtest scores ranged from .81 to .98 (see <xref ref-type="table" rid="table1-0734282912439504">Table 1</xref>).</p>
</sec>
<sec id="section5-0734282912439504">
<title>Analysis</title>
<sec id="section6-0734282912439504">
<title>Confirmatory factor structure</title>
<p>The factor structure of the subtests was examined with CFA. We employed half of the sample to conduct model testing and modifications if justified. The hold-out sample was employed to cross-validate the best-fitting model in the first analysis. The individual subtest scores do not show dramatic departures from normality (skew range = −0.01 to 0.07, kurtosis range = −0.53 to 0.35); relative multivariate kurtosis is 1.064, which is within the bounds of assuming multivariate normality (<xref ref-type="bibr" rid="bibr3-0734282912439504">Bentler, 1998</xref>). LISREL 8.80 (<xref ref-type="bibr" rid="bibr20-0734282912439504">Jöreskog &amp; Sörbom, 2006</xref>) with maximum likelihood estimation was used to estimate the models.</p>
</sec>
<sec id="section7-0734282912439504">
<title>Model specification</title>
<p>We posited four plausible models prior to analysis. Model 1 is a one-factor model to test the hypothesis that the subtests are simply facets of a single “achievement” trait. Model 2 is the test author’s model, which was inferred from the composite score structure for the CIBS-II. Covariances between the factors were estimated freely. Model 3 was specified as an extension of Model 2 to test the hypothesis that the constructs influencing subtest scores are related to a higher-order “general achievement factor” and follows recommendations to test such a model in the presence of correlated first-order factors (e.g., <xref ref-type="bibr" rid="bibr31-0734282912439504">Thompson, 2004</xref>). Model 4 is a three-factor model based on the supposition that all reading-related subtests could be linked to a general reading factor and that the Listening Comprehension subtest could be linked to a general writing factor since it involves understandings of word meanings but does not assess a reading skill.</p>
<p>Model 2 includes the Listening Comprehension Indicator, which has the Listening Vocabulary subtest as its only indicator. Single-indicator factors pose technical (i.e., an indeterminate, or underidentified, model) and substantive problems in latent variable models. To solve the former, the pattern coefficient was set to 1, and the error variance for the indicator was set to an estimate based on the reliability and the variance of the subtest as suggested by <xref ref-type="bibr" rid="bibr22-0734282912439504">Kline (2005</xref>, p. 230). Specifically, the estimate is obtained by multiplying the variable’s sample variance by 1 minus the internal consistency reliability estimate. This resulted in 0.545 as the estimate of error variance. There is disagreement over whether a latent factor with a single indicator should be considered a factor at all (<xref ref-type="bibr" rid="bibr6-0734282912439504">Brown, 2006</xref>); however, the composite score structure for the CIBS-II as developed by the test’s author is used in practice, and thus the model based on that structure was tested.</p>
</sec>
<sec id="section8-0734282912439504">
<title>Evaluation of model fit</title>
<p>Model fit was evaluated using a combination of fit indices, following the recommendations of <xref ref-type="bibr" rid="bibr17-0734282912439504">Hu and Bentler (1999)</xref> and <xref ref-type="bibr" rid="bibr6-0734282912439504">Brown (2006)</xref>. The χ<sup>2</sup> statistic is a measure of absolute model fit and is sensitive to sample size. However, χ<sup>2</sup> statistics are useful in comparing nested models and are informative in combination with other indices. The standardized root mean square residual index (SRMR) was reported with a fit criterion of SRMR &lt; .08 (<xref ref-type="bibr" rid="bibr17-0734282912439504">Hu &amp; Bentler, 1999</xref>). The root mean square error of approximation (RMSEA) was reported with a criterion of RMSEA &lt; .06 (<xref ref-type="bibr" rid="bibr17-0734282912439504">Hu &amp; Bentler, 1999</xref>). The comparative fit index (CFI; <xref ref-type="bibr" rid="bibr2-0734282912439504">Bentler, 1990</xref>) and the Tucker–Lewis index (TLI; <xref ref-type="bibr" rid="bibr33-0734282912439504">Tucker &amp; Lewis, 1973</xref>) were reported with values above 0.95 suggesting good fit (<xref ref-type="bibr" rid="bibr17-0734282912439504">Hu &amp; Bentler, 1999</xref>). Models were judged as having acceptable fit only if <italic>all</italic> the selected fit indices met the criteria. We note that Hu and Bentler’s criteria were empirically derived to minimize Type 1 and Type 2 error.</p>
<p>In addition, parameter admissibility, significance, and interpretability guided model choice. Models were evaluated by examining modification indices and residuals. Residuals for good-fitting models should be approximately normally distributed, and standardized residuals with magnitude greater than 2 may indicate localized poor fit (<xref ref-type="bibr" rid="bibr6-0734282912439504">Brown, 2006</xref>, p. 118). The chi-square difference test provided statistical comparisons of nested models. Post hoc alterations of models were conducted in response to results and with consideration of their conceptual meaningfulness (<xref ref-type="bibr" rid="bibr6-0734282912439504">Brown, 2006</xref>; <xref ref-type="bibr" rid="bibr19-0734282912439504">Jöreskog &amp; Sörbom, 1996</xref>). Cross-validating a respecified model provides evidence that the new model is not merely capitalizing on chance features of the original sample (<xref ref-type="bibr" rid="bibr25-0734282912439504">MacCallum, 1995</xref>).</p>
</sec>
</sec>
</sec>
<sec id="section9-0734282912439504" sec-type="results">
<title>Results</title>
<p>The fit indices for the four models tested appear in <xref ref-type="table" rid="table2-0734282912439504">Table 2</xref>. Model 1 did not fit given a very low <italic>p</italic> value and RMSEA well outside the set criterion. The lack of fit provides support for the existence of a multifactor model (<xref ref-type="bibr" rid="bibr31-0734282912439504">Thompson, 2004</xref>).</p>
<table-wrap id="table2-0734282912439504" position="float">
<label>Table 2.</label>
<caption>
<p>Model Fit Indices for Models 1 to 4</p>
</caption>
<graphic alternate-form-of="table2-0734282912439504" xlink:href="10.1177_0734282912439504-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">χ<sup>2</sup></th>
<th align="center"><italic>df</italic></th>
<th align="center"><italic>p</italic></th>
<th align="center">RMSEA</th>
<th align="center">SRMR</th>
<th align="center">CFI</th>
<th align="center">TLI</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>271.904</td>
<td>27</td>
<td>&lt;.0001</td>
<td>.113</td>
<td>.041</td>
<td>.972</td>
<td>.972</td>
</tr>
<tr>
<td>2</td>
<td>47.470</td>
<td>18</td>
<td>.0002</td>
<td>.048</td>
<td>.021</td>
<td>.996</td>
<td>.996</td>
</tr>
<tr>
<td>3</td>
<td>159.833</td>
<td>23</td>
<td>&lt;.0001</td>
<td>.096</td>
<td>.032</td>
<td>.983</td>
<td>.983</td>
</tr>
<tr>
<td>4<sup><xref ref-type="table-fn" rid="table-fn2-0734282912439504">a</xref></sup></td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0734282912439504">
<p>Note: RMSEA = root mean square error of approximation; SRMR = standardized root mean square residual; CFI = comparative fit index; TLI = Tucker–Lewis Index.</p>
</fn>
<fn id="table-fn2-0734282912439504">
<label>a</label>
<p>Fit indices are not reported due to an inadmissible solution.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Model 2 met fit criteria (see <xref ref-type="table" rid="table2-0734282912439504">Table 2</xref>). As an additional check on the RMSEA, the 90% confidence interval (0.0181, 0.0763) was examined, and the upper bound of this interval suggests possible room for improvement. Model 3 was substantially degraded in fit compared to Model 2 (<inline-formula id="inline-formula1-0734282912439504">
<mml:math display="inline" id="math1-0734282912439504">
<mml:mrow>
<mml:msubsup>
<mml:mi>χ</mml:mi>
<mml:mtext>difference</mml:mtext>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> = 112.363, <italic>p</italic> &lt; .0001). Model 4 produced an inadmissible solution (i.e., <italic>r</italic> &gt; 1.00 between the Reading and Writing factors).</p>
<p>All parameters in Model 2 were statistically significant (i.e., <italic>p</italic> values &lt; .01). Pattern, structure, and correlation coefficients were reviewed to further examine fit. Although the theoretical basis of Model 2 assumes, for example, that the Basic Reading factor directly influences only the Word Analysis subtest scores and Word Recognition subtest scores, the structure coefficients showed that the Basic Reading factor and the Spelling subtest had a correlation coefficient of .843. The Basic Reading, Reading Comprehension, and Written Expression factors each had at least one subtest with a structure coefficient higher than one of its pattern coefficients.</p>
<p>High factor correlations between Basic Reading and Reading Comprehension (.93) and Basic Reading and Written Expression (.95) did suggest the model had too many factors (<xref ref-type="bibr" rid="bibr6-0734282912439504">Brown, 2006</xref>). However, models with fewer factors (e.g., Verbal and Math) or variations of the higher-order model did not meet fit criteria. In fact, large modification indices for correlated error variance of indicators with a simpler model suggested missing factors!</p>
<p>Although Model 2 had good fit, there was local strain, with four particularly large residuals that were outside the desired normal distribution and several large modification indices. The largest modification index was 22.985 for the covariance of errors for the Spelling and Word Recognition subtests. The content of the two subtests are likely linked: Spelling asks children to recall or “sound out” how to spell words quickly, and Word Recognition asks children to sight-read lists of words with no context. Both subtests require familiarity and fluency with phonics as well as knowledge of many of the peculiar spelling and pronunciation rules of the English language. Thus, we specified Model 2A, allowing the covariance of errors between the two subtests.</p>
<p>Model 2A had excellent fit, χ<sup>2</sup>(17) = 23.227, <italic>p</italic> = .113, RMSEA = 0.024 (90% CI [0.0, 0.043], SRMR = .014, CFI = .999, TLI = .998). The chi-square difference test indicated improved fit over Model 2, χ<sup>2</sup>(1) = 24.243, <italic>p</italic> &lt; .0001. The residuals were within limits and approximately normally distributed. No large modification indices were indicated. Some interfactor correlations remained large (&gt;.90). Likewise, structure coefficients showed high correlations between some indicators and factors to which they are not presumed to be linked.</p>
<sec id="section10-0734282912439504">
<title>Cross-Validation</title>
<p>Model 2A was selected as the best-fitting model. A cross-validation analysis investigated whether the factor structure was invariant across the two subgroups by means of a multisample CFA. To cross-validate Model 2A, first the model is simultaneously, but independently, fit to the covariance matrices of both subgroups. If fit is achieved, then the estimation is repeated with a series of increasingly restrictive constraints on the matrices. There was good fit to the data (see <xref ref-type="table" rid="table3-0734282912439504">Table 3</xref>). Next we tested the invariance of the pattern coefficients (i.e., the Λ matrices were identical), then the error variances (i.e., the Λ and Θ matrices were identical), and last the factor covariances (i.e., the Λ, Θ, and Φ matrices were identical). Fit indices at each step are listed in <xref ref-type="table" rid="table3-0734282912439504">Table 3</xref>. The chi-square difference test was used to assess invariance (<xref ref-type="bibr" rid="bibr13-0734282912439504">French &amp; Finch, 2006</xref>). This test checks for a statistically significant decline in fit as the models are constrained. No significant differences were observed (<italic>p &gt;</italic> .05).</p>
<table-wrap id="table3-0734282912439504" position="float">
<label>Table 3.</label>
<caption>
<p>Global Model Fit Indices for Cross-Validation</p>
</caption>
<graphic alternate-form-of="table3-0734282912439504" xlink:href="10.1177_0734282912439504-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Step</th>
<th align="center">Invariance Constraint</th>
<th align="center">χ<sup>2</sup></th>
<th align="center"><italic>df</italic></th>
<th align="center"><italic>P</italic></th>
<th align="center">RMSEA</th>
<th align="center">SRMR</th>
<th align="center">CFI</th>
<th align="center">TLI</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>None</td>
<td>67.532</td>
<td>34</td>
<td>.0005</td>
<td>.037</td>
<td>.017</td>
<td>.998</td>
<td>.996</td>
</tr>
<tr>
<td>2</td>
<td>Λ</td>
<td>71.689</td>
<td>38</td>
<td>.0008</td>
<td>.035</td>
<td>.019</td>
<td>.998</td>
<td>.996</td>
</tr>
<tr>
<td>3</td>
<td>Λ &amp; Θ</td>
<td>85.920</td>
<td>47</td>
<td>.0005</td>
<td>.034</td>
<td>.021</td>
<td>.998</td>
<td>.996</td>
</tr>
<tr>
<td>4</td>
<td>Λ, Θ, &amp; Φ</td>
<td>102.868</td>
<td>62</td>
<td>.0009</td>
<td>.031</td>
<td>.028</td>
<td>.997</td>
<td>.997</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Final model parameters were estimated by fitting the entire sample to Model 2A. The final parameters (see <xref ref-type="table" rid="table4-0734282912439504">Tables 4</xref> and <xref ref-type="table" rid="table5-0734282912439504">5</xref>) have the same interpretive problems as do the initial parameters for Model 2A. Only final parameters are reported. Correlations are large among the Reading and Writing factors (.902 and .952) and moderately large among the Math, Reading, and Writing factors (.770, .805, and .846). The structure coefficients show high correlation of the Word Recognition subtest with factors to which it is presumably not linked. The Word Recognition subtest is modeled as linked only to the Basic Reading factor, but its correlation (i.e., structure coefficient = .848) with Reading Comprehension is higher than the two indicators that are modeled as linked to that factor. The Written Expression factor also has indicators with high structure coefficients, including the Word Recognition subtest. However, in specifying a model in which the Word Recognition subtest was linked to more than one factor (i.e., it was cross-loaded), the estimated factor coefficients were not significantly different from zero.</p>
<table-wrap id="table4-0734282912439504" position="float">
<label>Table 4.</label>
<caption>
<p>Final Pattern and Structure Coefficients for Model 2A</p>
</caption>
<graphic alternate-form-of="table4-0734282912439504" xlink:href="10.1177_0734282912439504-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Basic Reading</th>
<th align="center">Reading Comprehension</th>
<th align="center">Math</th>
<th align="center">Written Expression</th>
<th align="center">Listening Comprehension</th>
</tr>
</thead>
<tbody>
<tr>
<td>Word recognition</td>
<td><italic>0.891</italic></td>
<td>0.848</td>
<td>0.686</td>
<td>0.848</td>
<td>0.587</td>
</tr>
<tr>
<td>Word Analysis Survey</td>
<td><italic>0.780</italic></td>
<td>0.742</td>
<td>0.600</td>
<td>0.742</td>
<td>0.513</td>
</tr>
<tr>
<td>Reading vocabulary comprehension</td>
<td>0.765</td>
<td><italic>0.804</italic></td>
<td>0.680</td>
<td>0.725</td>
<td>0.621</td>
</tr>
<tr>
<td>Comprehends passages</td>
<td>0.772</td>
<td><italic>0.811</italic></td>
<td>0.686</td>
<td>0.732</td>
<td>0.627</td>
</tr>
<tr>
<td>Computational skills</td>
<td>0.583</td>
<td>0.640</td>
<td><italic>0.756</italic></td>
<td>0.609</td>
<td>0.464</td>
</tr>
<tr>
<td>Problem solving</td>
<td>0.628</td>
<td>0.690</td>
<td><italic>0.816</italic></td>
<td>0.657</td>
<td>0.500</td>
</tr>
<tr>
<td>Spelling</td>
<td>0.817</td>
<td>0.775</td>
<td>0.691</td>
<td><italic>0.858</italic></td>
<td>0.534</td>
</tr>
<tr>
<td>Sentence writing</td>
<td>0.669</td>
<td>0.634</td>
<td>0.566</td>
<td><italic>0.703</italic></td>
<td>0.437</td>
</tr>
<tr>
<td>Listening vocabulary comprehension</td>
<td>0.623</td>
<td>0.730</td>
<td>0.580</td>
<td>0.589</td>
<td><italic>0.946</italic></td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0734282912439504">
<p>Note: Coefficients in italics are equal (within rounding error) to the estimated pattern coefficients. Values not in italics are structure coefficients.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table5-0734282912439504" position="float">
<label>Table 5.</label>
<caption>
<p>Final Completely Standardized Factor Correlations for Model 2A</p>
</caption>
<graphic alternate-form-of="table5-0734282912439504" xlink:href="10.1177_0734282912439504-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Basic Reading</th>
<th align="center">Reading Comprehension</th>
<th align="center">Math</th>
<th align="center">Written Expression</th>
<th align="center">Listening Comprehension</th>
</tr>
</thead>
<tbody>
<tr>
<td>Basic reading</td>
<td>1.000</td>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Reading comprehension</td>
<td>0.952</td>
<td>1.000</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>Math</td>
<td>0.770</td>
<td>0.846</td>
<td>1.000</td>
<td/>
<td/>
</tr>
<tr>
<td>Written expression</td>
<td>0.952</td>
<td>0.902</td>
<td>0.805</td>
<td>1.000</td>
<td/>
</tr>
<tr>
<td>Listening comprehension</td>
<td>0.659</td>
<td>0.772</td>
<td>0.613</td>
<td>0.623</td>
<td>1.000</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
</sec>
<sec id="section11-0734282912439504" sec-type="discussion">
<title>Discussion</title>
<p>In expressing the CIBS-II composite score structure, the test’s author implies that the subtests have a particular dimensional structure. Each subtest contributes to one composite score, with the implication that each subtest measures one dimension. This study supported this structure. With a slight model modification, better model fit was established and cross-validated across a random subgroup of the data. However, structure coefficients and interfactor correlations dampen the interpretation of the model and may indicate complex interactions among the subtests and latent constructs.</p>
<sec id="section12-0734282912439504">
<title>Internal Structure/CFA</title>
<p>Model 2 was a reflection of the composite score structure advocated by the test’s author and fit well. By including the covariance of errors in the Word Recognition and Spelling subtests (which created Model 2A), model fit was improved to a point that further modifications could no longer be justified, and other models considered as rivals to Model 2 and 2A did not result in acceptable fit. Statistical and substantive justification can be made for allowing estimation of error covariance. The error covariance adds to the model common variance between two indicators that could otherwise only be accounted for in the covariance of their respective factors. In Model 2, the structure coefficient between the Spelling subtest and the Basic Reading factor was .843, which suggests a relationship between the Spelling subtest and the Basic Reading factor.</p>
<p>We also argue on substantive grounds that these two subtests share variance that should be considered in the model. Although being able to spell words may be influenced primarily by a Written Expression factor and reading lists of words out of context may be influenced primarily by a Basic Reading factor, the two skills are both related to familiarity with common words and both require fluency with phonics concepts. From a practical standpoint, Model 2A did improve the fit over Model 2. However, Model 2 has sufficient support for the intended uses as enumerated in the technical manual. Analysis of Model 2A allows us to move forward with thinking about the theory underlying the structure and guiding future research.</p>
<p>High correlations between factors can suggest overlap in the latent constructs. A high factor correlation (&gt;.85) may indicate too many factors (<xref ref-type="bibr" rid="bibr6-0734282912439504">Brown, 2006</xref>). The reported factor correlations were above this threshold. However, results indicate the five-factor model appears optimal. The structure coefficients can help explain this apparent paradox. In a model with unidimensional specification and correlated factors, structure coefficients represent the correlation between an indicator and a factor. The Word Recognition subtest had high structure coefficients with the Basic Reading, Reading Comprehension, and Written Expression factors. The same pattern of high structure coefficients was seen with the Word Analysis, Reading Vocabulary, and Spelling subtests. The Listening Vocabulary subtest had a high structure coefficient with the Reading Comprehension factor. The high correlations of these subtests with the other factors may be evidence of multidimensionality of subtest scores. The results suggest that the composite score structure put forth by the test’s author is a valid interpretation of the scores (i.e., the internal structure supports such an interpretation); however, the details of the model hint that this structure may be a simpler model than what one would find in a full exploratory study, including full consideration of the content of the subtests and a deeper investigation of the dimensionality of the subtests. Assessing dimensionality through statistical investigations (e.g., DIMTEST) and through expert content reviews may give insight to any needed revisions.</p>
<p>A strikingly similar pattern of results has appeared with other achievement tests. In a CFA study of the TerraNova achievement test system (<xref ref-type="bibr" rid="bibr9-0734282912439504">CTB/McGraw Hill, 1997</xref>), although model fit was adequate, high interfactor correlations and high structure coefficients raised questions about the interpretability of the factor structure (Stevens &amp; Zvoch, 1997). Likewise, CFA results of the KeyMath Revised Normative Update (<xref ref-type="bibr" rid="bibr8-0734282912439504">Connolly, 1998</xref>) showed reasonable model fit, but high interfactor correlations led to an exploratory study that suggested a one-factor model (<xref ref-type="bibr" rid="bibr34-0734282912439504">Williams, Fall, Eaves, Darch, &amp; Woods-Groves, 2007</xref>). Researchers speculate about the presence of “common, non-achievement features of performance such as decoding or problem solving” (Stevens &amp; Zvock, 1997, p. 987). Such a common construct would be likely to manifest in each subtest as a secondary dimension. An explication of the theoretical underpinnings of the individual subtests, the manner in which they were combined into composite scores, or an examination of the basic process underlying responses would amplify evidence in this study. Some of the high correlations among factors, for instance, could be a result of narrow band abilities (e.g., phonology) that can underlie achievement domains (e.g., reading and math) when considered within the Cattell–Horn–Carroll cognitive-achievement relations framework (<xref ref-type="bibr" rid="bibr26-0734282912439504">McGrew &amp; Wendling, 2010</xref>).</p>
</sec>
</sec>
<sec id="section13-0734282912439504" sec-type="conclusions">
<title>Conclusion</title>
<p>Even though the results support the structure for CIBS-II, unqualified support was weakened slightly by high interfactor correlations and some unexpectedly high structure coefficients, which may indicate that the content of the subtests overlaps to a higher degree than intended or that the subtests measure an unidentified common construct. Composite scores from the CIBS-II appear to be suitable for such low-stakes uses as monitoring half-year to yearly student progress and identifying areas of strength and weakness. However, questions about the possible existence of more complex interpretations of subtest scores may complicate score interpretation by diagnosticians. The composite score structure should not be used in absence of other sources of information for making high-stakes decisions (e.g., placement in special education courses, accountability reporting).</p>
<p>In the unified view of validity, validation is an ongoing process. It is not a test or a test’s scores that are validated; it is a proposed interpretation of the scores that is validated (<xref ref-type="bibr" rid="bibr1-0734282912439504">AERA et al., 1999</xref>; <xref ref-type="bibr" rid="bibr21-0734282912439504">Kane, 2006</xref>). This study provides internal structure validity evidence. However, this evidence could be used to support a more complex interpretation involving other as yet unidentified constructs. Carefully designed studies may give insight into not only the test structure but, more important, the underlying basic processes used to solve the items. Historically, the CIBS test series has received little attention from researchers investigating validity. The results here represent a change from that historical pattern. This line of inquiry represents the kind of accumulation of evidence that characterizes modern notions of test validation. Such evidence will assist in supporting the work of multidisciplinary teams using a variety of information to make the best decisions about students so students can continue to make forward progress.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This research was a component of a large project that was funded by Curriculum Associates, Inc. Direct support for this study was not given.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0734282912439504">
<citation citation-type="book">
<collab>American Educational Research Association, American Psychological Association, &amp; National Council on Measurement in Education</collab>. (<year>1999</year>). <source>Standards for educational and psychological testing</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Educational Research Association</publisher-name>.</citation>
</ref>
<ref id="bibr2-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Comparative fit indices in structural models</article-title>. <source>Psychological Bulletin</source>, <volume>107</volume>, <fpage>238</fpage>-<lpage>246</lpage>.</citation>
</ref>
<ref id="bibr3-0734282912439504">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Bentler</surname><given-names>P.</given-names></name>
</person-group> (<year>1998</year>, <month>March</month> <day>10</day>). <source>Kurtosis, residuals, fit indices</source> (<comment>Message posted to SEMNET discussion list</comment>). <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://bama.ua.edu/cgi-bin/wa?A2=ind9803&amp;L=semnet&amp;T">http://bama.ua.edu/cgi-bin/wa?A2=ind9803&amp;L=semnet&amp;T</ext-link></comment> =0&amp;O=D&amp;P=20612</citation>
</ref>
<ref id="bibr4-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brigance</surname><given-names>A. H.</given-names></name>
</person-group> (<year>1998</year>). <source>Comprehensive Inventory of Basic Skills—revised</source>. <publisher-loc>North Billerica, MA</publisher-loc>: <publisher-name>Curriculum Associates</publisher-name>.</citation>
</ref>
<ref id="bibr5-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brigance</surname><given-names>A. H.</given-names></name>
</person-group> (<year>2010</year>). <source>Comprehensive Inventory of Basic Skills—II</source>. <publisher-loc>North Billerica, MA</publisher-loc>: <publisher-name>Curriculum Associates</publisher-name>.</citation>
</ref>
<ref id="bibr6-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brown</surname><given-names>T. A.</given-names></name>
</person-group> (<year>2006</year>). <source>Confirmatory factor analysis for applied research</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford</publisher-name>.</citation>
</ref>
<ref id="bibr7-0734282912439504">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Cizek</surname><given-names>G. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Test review of the CIBS-R. From B. S. Plake &amp; J. C. Impara (Eds.)</article-title>, <source>The fourteenth mental measurements yearbook</source>. Retrieved from the <comment><ext-link ext-link-type="uri" xlink:href="http://www.unl.edu/buros">http://www.unl.edu/buros</ext-link></comment></citation>
</ref>
<ref id="bibr8-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Connolly</surname><given-names>A. J.</given-names></name>
</person-group> (<year>1998</year>). <source>KeyMath—revised normative update: A diagnostic inventory of essential mathematics</source>. <publisher-loc>Circle Pines, MN</publisher-loc>: <publisher-name>American Guidance Service</publisher-name>.</citation>
</ref>
<ref id="bibr9-0734282912439504">
<citation citation-type="book">
<collab>CTB/McGraw-Hill</collab>. (<year>1997</year>). <source>TerraNova CTBS multiple assessments</source>. <publisher-loc>Monterey, CA</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr10-0734282912439504">
<citation citation-type="gov">
<collab>Department of Education, Institute of Education Sciences</collab>. (<year>2007</year>). <source>Common core of data, 2006-07</source> <comment>[Data file]. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://nces.ed.gov/ccd">http://nces.ed.gov/ccd</ext-link></comment></citation>
</ref>
<ref id="bibr11-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Erford</surname><given-names>B.</given-names></name>
<name><surname>Dutton</surname><given-names>J. L.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Technical analysis of the Slosson Phonics and Structural Analysis Test</article-title>. <source>Educational and Psychological Measurement</source>, <volume>65</volume>, <fpage>1011</fpage>-<lpage>1025</lpage>.</citation>
</ref>
<ref id="bibr12-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ferguson</surname><given-names>J.</given-names></name>
<name><surname>Kersting</surname><given-names>F.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Comparison of diagnostic inventories used in special education with state-approved essential skills tests (KEST)</article-title>. <source>Journal of Human Behavior &amp; Learning</source>, <volume>5</volume>, <fpage>39</fpage>-<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr13-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>French</surname><given-names>B. F.</given-names></name>
<name><surname>Finch</surname><given-names>W. H.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Confirmatory factor analytic procedures for the determination of measurement invariance</article-title>. <source>Structural Equation Modeling</source>, <volume>13</volume>, <fpage>378</fpage>-<lpage>402</lpage>.</citation>
</ref>
<ref id="bibr14-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>French</surname><given-names>B. F.</given-names></name>
<name><surname>Glascoe</surname><given-names>F. P.</given-names></name>
</person-group> (<year>2010</year>). <source>Comprehensive Inventory of Basic Skills-II standardization and validation manual</source>. <publisher-loc>North Billerica, MA</publisher-loc>: <publisher-name>Curriculum Associates</publisher-name>.</citation>
</ref>
<ref id="bibr15-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Glascoe</surname><given-names>F. P.</given-names></name>
</person-group> (<year>1999</year>). <source>Comprehensive Inventory of Basic Skills—revised standardization and validation manual</source>. <publisher-loc>North Billerica, MA</publisher-loc>: <publisher-name>Curriculum Associates</publisher-name>.</citation>
</ref>
<ref id="bibr16-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Green</surname><given-names>J. P.</given-names><suffix>Jr.</suffix></name>
</person-group> (<year>2007</year>). <source>Determining the reliability and validity of service quality scores in a public library context: A confirmatory approach</source>. <comment>PhD dissertation</comment>, <publisher-name>Capella University</publisher-name>, <publisher-loc>Minneapolis, MN</publisher-loc>. <comment>Retrieved from ProQuest Digital Dissertations database. (Publication No. AAT 3241793)</comment></citation>
</ref>
<ref id="bibr17-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hu</surname><given-names>L.</given-names></name>
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives</article-title>. <source>Structural Equation Modeling</source>, <volume>6</volume>, <fpage>1</fpage>-<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr18-0734282912439504">
<citation citation-type="gov">
<collab>Individuals With Disabilities Education Act</collab>. (<year>2004</year>). <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://idea.ed.gov/download/statute.html">http://idea.ed.gov/download/statute.html</ext-link></comment></citation>
</ref>
<ref id="bibr19-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Jöreskog</surname><given-names>K. G.</given-names></name>
<name><surname>Sörbom</surname><given-names>D.</given-names></name>
</person-group> (<year>1996</year>). <source>LISREL 8: User’s reference guide</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Scientific Software International</publisher-name>.</citation>
</ref>
<ref id="bibr20-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Jöreskog</surname><given-names>K. G.</given-names></name>
<name><surname>Sörbom</surname><given-names>D.</given-names></name>
</person-group> (<year>2006</year>). <article-title>LISREL 8.8</article-title>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Scientific Software International, Inc</publisher-name>.</citation>
</ref>
<ref id="bibr21-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kane</surname><given-names>M. T.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Validation</article-title>. In <person-group person-group-type="editor">
<name><surname>Brennan</surname><given-names>R. L.</given-names></name>
</person-group> (Ed.), <source>Educational measurement</source> (<edition>4th ed.</edition>, pp. <fpage>17</fpage>-<lpage>64</lpage>). <publisher-loc>Westport, CT</publisher-loc>: <publisher-name>Praeger</publisher-name>.</citation>
</ref>
<ref id="bibr22-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kline</surname><given-names>R. B.</given-names></name>
</person-group> (<year>2005</year>). <source>Principles and practice of structural equation modeling</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford</publisher-name>.</citation>
</ref>
<ref id="bibr23-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Koretz</surname><given-names>D. M.</given-names></name>
<name><surname>Hamilton</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Testing for accountability in K-12</article-title>. In <person-group person-group-type="editor">
<name><surname>Brennan</surname><given-names>R. L.</given-names></name>
</person-group> (Ed.), <source>Educational measurement</source> (<edition>4th ed.</edition>, pp. <fpage>531</fpage>-<lpage>578</lpage>). <publisher-loc>Westport, CT</publisher-loc>: <publisher-name>Praeger</publisher-name>.</citation>
</ref>
<ref id="bibr24-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Krawiec</surname><given-names>R. M.</given-names></name>
<name><surname>Spadafore</surname><given-names>G. J.</given-names></name>
</person-group> (<year>1983</year>). <article-title>Comparing the Brigance Diagnostic Inventory of Basic Skills and the Wide Range Achievement Test</article-title>. <source>Reading Improvement</source>, <volume>20</volume>, <fpage>230</fpage>-<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr25-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>MacCallum</surname><given-names>R. C.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Model specification: Procedures, strategies, and related issues</article-title>. In <person-group person-group-type="editor">
<name><surname>Hoyle</surname><given-names>R. H.</given-names></name>
</person-group> (Ed.), <source>Structural equation modeling: Concepts, issues, and applications</source> (pp. <fpage>16</fpage>-<lpage>36</lpage>). <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr26-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McGrew</surname><given-names>K. S.</given-names></name>
<name><surname>Wendling</surname><given-names>B. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Cattell-Horn-Carroll cognitive-achievement relations: What we have learned from the past 20 years of research</article-title>. <source>Psychology in the Schools</source>, <volume>47</volume>, <fpage>651</fpage>-<lpage>674</lpage>.</citation>
</ref>
<ref id="bibr27-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McLellan</surname><given-names>M. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Test review of the BRIGANCE Comprehensive Inventory of Basic Skills-R</article-title>. From <person-group person-group-type="editor">
<name><surname>Plake</surname><given-names>B. S.</given-names></name>
<name><surname>Impara</surname><given-names>J. C.</given-names></name>
</person-group> (Eds.), <source>The fourteenth mental measurements yearbook</source> (pp. <fpage>172</fpage>-<lpage>175</lpage>). <publisher-loc>Lincoln, NE</publisher-loc>: <publisher-name>Buros Institute</publisher-name>.</citation>
</ref>
<ref id="bibr28-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Messick</surname><given-names>S.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Validity</article-title>. In <person-group person-group-type="editor">
<name><surname>Linn</surname><given-names>R. L.</given-names></name>
</person-group> (Ed.), <source>Educational measurement</source> (<edition>3rd ed.</edition>, pp. <fpage>13</fpage>-<lpage>103</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Macmillan</publisher-name>.</citation>
</ref>
<ref id="bibr29-0734282912439504">
<citation citation-type="journal">
<collab>No Child Left Behind Act of 2001</collab>, <comment>Pub. L. No. 107-110, § 115 Stat. 1425</comment> (<year>2002</year>).</citation>
</ref>
<ref id="bibr30-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stevens</surname><given-names>J. J.</given-names></name>
<name><surname>Zvoch</surname><given-names>K.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Confirmatory factor analysis of the TerraNova Comprehensive Tests of Basic Skills/5</article-title>. <source>Educational and Psychological Measurement</source>, <volume>67</volume>, <fpage>976</fpage>-<lpage>989</lpage>.</citation>
</ref>
<ref id="bibr31-0734282912439504">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>B.</given-names></name>
</person-group> (<year>2004</year>). <source>Exploratory and confirmatory factor analysis: Understanding concepts and applications</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>.</citation>
</ref>
<ref id="bibr32-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>B.</given-names></name>
<name><surname>Daniel</surname><given-names>L. G.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Factor analytic evidence for the construct validity of scores: A historical overview and some guidelines</article-title>. <source>Educational and Psychological Measurement</source>, <volume>56</volume>, <fpage>197</fpage>-<lpage>208</lpage>.</citation>
</ref>
<ref id="bibr33-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tucker</surname><given-names>L. R.</given-names></name>
<name><surname>Lewis</surname><given-names>C.</given-names></name>
</person-group> (<year>1973</year>). <article-title>A reliability coefficient for maximum likelihood factor analysis</article-title>. <source>Psychometrika</source>, <volume>38</volume>, <fpage>1</fpage>-<lpage>10</lpage>.</citation>
</ref>
<ref id="bibr34-0734282912439504">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Williams</surname><given-names>T. O.</given-names><suffix>Jr.</suffix></name>
<name><surname>Fall</surname><given-names>A. M.</given-names></name>
<name><surname>Eaves</surname><given-names>R. C.</given-names></name>
<name><surname>Darch</surname><given-names>C.</given-names></name>
<name><surname>Woods-Groves</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Factor analysis of the KeyMath-Revised Normative Update Form A</article-title>. <source>Assessment for Effective Intervention</source>, <volume>32</volume>, <fpage>113</fpage>-<lpage>120</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>