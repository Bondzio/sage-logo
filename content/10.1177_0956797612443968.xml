<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSS</journal-id>
<journal-id journal-id-type="hwp">sppss</journal-id>
<journal-id journal-id-type="nlm-ta">Psychol Sci</journal-id>
<journal-title>Psychological Science</journal-title>
<journal-subtitle>Research, Theory, &amp; Application in Psychology and Related Sciences</journal-subtitle>
<issn pub-type="ppub">0956-7976</issn>
<issn pub-type="epub">1467-9280</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0956797612443968</article-id>
<article-id pub-id-type="publisher-id">10.1177_0956797612443968</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Reports</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Saved by a Log</article-title>
<subtitle>How Do Humans Perform Hybrid Visual and Memory Search?</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Wolfe</surname><given-names>Jeremy M.</given-names></name>
<aff id="aff1-0956797612443968">Brigham &amp; Women’s Hospital, Cambridge, Massachusetts, and Departments of Ophthalmology and Radiology, Harvard Medical School</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0956797612443968">Jeremy M. Wolfe, Visual Attention Lab, Department of Surgery, Brigham &amp; Women’s Hospital, 64 Sidney St., Suite 170, Cambridge, MA 02139-4170 E-mail: <email>wolfe@search.bwh.harvard.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2012</year>
</pub-date>
<volume>23</volume>
<issue>7</issue>
<fpage>698</fpage>
<lpage>703</lpage>
<history>
<date date-type="received">
<day>12</day>
<month>9</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>14</day>
<month>11</month>
<year>2011</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>Could you find 1 of your 1,000 Facebook friends in a crowd of 100? Even at a rate of 25 ms per comparison, determining that no friends were in the crowd would take more than 40 min if memory and visual search interacted linearly. In the experiment reported here, observers memorized pictures of 1 to 100 targets and then searched for any of these targets in visual displays of 1 to 16 objects. Response times varied linearly with visual set size but logarithmically with memory set size. Data from memory set sizes of 1 through 16 accurately predicted response times for different observers holding 100 objects in memory. The results would be consistent with a binary coding of visual objects in memory and are relevant to applied searches in which experts look for any of many items of interest (e.g., a radiologist running through a mental checklist of what might be wrong in a car-crash victim or an airport screener looking for any of a list of prohibited items in a carry-on bag).</p>
</abstract>
<kwd-group>
<kwd>attention</kwd>
<kwd>memory</kwd>
<kwd>visual memory</kwd>
<kwd>visual attention</kwd>
<kwd>visual search</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>How do we search for one of many different target items in a visual world filled with many other objects? Although there are large literatures on visual search (<xref ref-type="bibr" rid="bibr25-0956797612443968">Wolfe, 2010</xref>) and memory search (<xref ref-type="bibr" rid="bibr21-0956797612443968">Van Zandt &amp; Townsend, 1993</xref>), there has been much less work examining the interaction of these two search processes. The bulk of the work that does exist deals with search for members of small memory sets of letters or digits (or both) in relatively small visual displays (<xref ref-type="bibr" rid="bibr4-0956797612443968">Briggs &amp; Blaha, 1969</xref>; <xref ref-type="bibr" rid="bibr5-0956797612443968">Burrows &amp; Murdock, 1969</xref>; <xref ref-type="bibr" rid="bibr15-0956797612443968">Nickerson, 1966</xref>; <xref ref-type="bibr" rid="bibr18-0956797612443968">Schneider &amp; Shiffrin, 1977</xref>). For visual and memory set sizes in the range of 1 to 4 characters, search times are roughly linear with the product of the visual and memory set sizes (<xref ref-type="bibr" rid="bibr18-0956797612443968">Schneider &amp; Shiffrin, 1977</xref>). More recent work has painted a complicated picture of the effects of working memory loads on visual search (<xref ref-type="bibr" rid="bibr1-0956797612443968">Balani, Soto, &amp; Humphreys, 2010</xref>; <xref ref-type="bibr" rid="bibr7-0956797612443968">Downing &amp; Dodds, 2004</xref>; <xref ref-type="bibr" rid="bibr8-0956797612443968">Han &amp; Kim, 2004</xref>; <xref ref-type="bibr" rid="bibr16-0956797612443968">Olivers, Peters, Houtkamp, &amp; Roelfsema, 2011</xref>; <xref ref-type="bibr" rid="bibr26-0956797612443968">Woodman, Vogel, &amp; Luck, 2001</xref>), but as a general rule, these are studies in which working memory was pitted against search.</p>
<p>Researchers do not know how memory and vision work together when stimuli are drawn from the wide set of visual objects beyond alphanumeric characters, nor do they know what happens when the number of task-relevant items held in memory gets well beyond the limits of working memory. For example, how do we search a crowded pantry for the eight ingredients needed for dinner? How does an intelligence analyst search satellite imagery for any of many targets of interest? At the usual rates proposed for visual search (<xref ref-type="bibr" rid="bibr24-0956797612443968">Wolfe, 1998</xref>) and memory search (<xref ref-type="bibr" rid="bibr20-0956797612443968">Sternberg, 1966</xref>), a linear dependence on the product of visual and memory set sizes would become prohibitive once those set sizes become large. The experiments reported here show that the “solution” to this problem is logarithmic search through the memory set. Earlier examples of reaction times (RTs) increasing with the log of the number of alternatives can be found in <xref ref-type="bibr" rid="bibr6-0956797612443968">Burrows and Okada (1975)</xref> or in work on the Hick-Hyman law in motor response tasks (<xref ref-type="bibr" rid="bibr9-0956797612443968">Hick, 1952</xref>; <xref ref-type="bibr" rid="bibr12-0956797612443968">Hyman, 1953</xref>). Some work in the 1960s and 1970s addressed combined visual and memory search with as many as 8 well-learned alphanumeric stimuli as the memory set (<xref ref-type="bibr" rid="bibr14-0956797612443968">Neisser, 1974</xref>). No one has addressed the problem of visual search for arbitrary objects when the number of possible targets is far outside the limits of working memory.</p>
<sec id="section1-0956797612443968">
<title>Experiment 1</title>
<sec id="section2-0956797612443968">
<title>Method</title>
<p>In Experiment 1, 10 observers searched visual displays of 1, 2, 4, 8, or 16 photographs of objects for any of 1, 2, 4, 8, or 16 items held in memory. Every observer was tested on all five memory set sizes over five blocks of trials. All stimuli were photographs of isolated objects (provided by Talia Konkle). Stimuli were presented and responses collected on Macintosh computers running MATLAB and the Psychophysics Toolbox (<xref ref-type="bibr" rid="bibr3-0956797612443968">Brainard, 1997</xref>). All observers gave informed consent and were paid $10 per hour for their time.</p>
<p>In each memory block, the observers attempted to memorize a set of 1 to 16 items (<xref ref-type="fig" rid="fig1-0956797612443968">Fig. 1a</xref>) and were then given a recognition test before proceeding to the visual search for these targets. In order to proceed to the visual search trials, observers had to score above 80% correct on two successive tests of their recognition memory for the memory set. In practice, memory for visual objects is much better than memory for letters and digits (<xref ref-type="bibr" rid="bibr2-0956797612443968">Brady, Konkle, Alvarez, &amp; Oliva, 2008</xref>; <xref ref-type="bibr" rid="bibr13-0956797612443968">Konkle, Brady, Alvarez, &amp; Oliva, 2008</xref>), so recognizing up to 16 distinctive objects as members of a memory set is quite trivial. Hence, observers attained an average accuracy of 97%. Memorization and testing of that memory took no more than 5 min, with longer times required for the larger memory set sizes. The criterion meant that the minimum number of memory blocks for a given memory set was 2. In practice, the average number of blocks required rose from 2.7 at the memory set size of 1 to 3.4 at the memory set size of 16. The modal number of required blocks was 2 at all memory set sizes.</p>
<fig id="fig1-0956797612443968" position="float">
<label>Fig. 1.</label>
<caption>
<p>Example memory set of two items (a), example visual search display with a set size of 8 (b), and experimental results (c–f) for Experiments 1 and 2. Observers memorized a set of 1 to 16 objects in Experiment 1 and 100 objects in Experiment 2 (a). After they were tested to confirm that they retained these objects in memory, they performed a visual search task in which they indicated whether a display of 1 to 16 objects contained any memorized target (b). The first graph (c) shows reaction time (RT) on target-present trials in Experiment 1 as a function of visual set size for each of the five memory set sizes; the key lists the slope of the RT × Visual Set Size function for each memory set size. The second graph (d) presents the same data, but in this case, the RTs are plotted as a function of memory set size for each of the five visual set sizes. The final two graphs incorporate the data from Experiment 2, extending the results to a memory set size of 100; RT is plotted as a function of memory set size, separately for each visual set size, on (e) target-present trials and (f) target-absent trials. Note the logarithmic scale of the <italic>x</italic>-axes. Solid lines are the best-fit regression lines for the RT × log2(memory set size) function for the Experiment 1 data. Dashed lines are the extrapolation of those lines to the memory set size of 100. The solid data points at the set size of 100 show the results for the observers in Experiment 2, none of whom participated in Experiment 1. In all the graphs, solid symbols indicate the averages across 10 observers, and error bars represent ±1 <italic>SEM</italic>.</p>
</caption>
<graphic xlink:href="10.1177_0956797612443968-fig1.tif"/>
</fig>
<p>With the memory set encoded with good accuracy, observers proceeded to 500 trials of visual search through random arrays of objects (<xref ref-type="fig" rid="fig1-0956797612443968">Fig. 1b</xref>). One and only one of the remembered targets was present on 50% of the trials. No targets were present on the other 50%. Trials were randomly divided among the five visual set sizes (1, 2, 4, 8, and 16). Observers indicated by key press whether the target was present or absent, under instructions to be as quick and accurate as possible. They repeated the same process for each of the five memory set sizes.</p>
</sec>
<sec id="section3-0956797612443968">
<title>Results</title>
<p><xref ref-type="fig" rid="fig1-0956797612443968">Figure 1c</xref> shows mean RT on target-present trials as a function of visual set size, for each of the five memory set sizes. It is clear that the effects of visual set size were quite linear, as is typical in search for one object among many (<xref ref-type="bibr" rid="bibr22-0956797612443968">Vickery, King, &amp; Jiang, 2005</xref>). Larger memory set sizes produced progressively steeper, but still linear, visual-set-size functions. Data for the target-absent trials were comparable, with slopes about 2.5 times the target-present slopes. In contrast, as shown in <xref ref-type="fig" rid="fig1-0956797612443968">Figure 1d</xref>, mean RTs were decidedly not linear as a function of memory set size. (Note that the same RTs are plotted in <xref ref-type="fig" rid="fig1-0956797612443968">Figs. 1c</xref> and <xref ref-type="fig" rid="fig1-0956797612443968">1d</xref>, in one case as a function of visual set size and in the other case as a function of memory set size.) As shown in <xref ref-type="fig" rid="fig1-0956797612443968">Figures 1e</xref> and <xref ref-type="fig" rid="fig1-0956797612443968">1f</xref>, mean RTs on both target-present and target-absent trials appeared to be a linear function of the logarithm of memory set size. Regression coefficients were calculated for RT × Memory Set Size and RT × Log2(memory set size) functions; the fits were significantly better for the log2 function for visual set sizes of 1, 4, 8, and 16, <italic>t</italic>s(9) &gt; 2.3, <italic>p</italic>s &lt; .05; for the visual set size of 2, the log2 function was a marginally better fit, <italic>t</italic>(9) = 2.2, <italic>p</italic> = .058.</p>
</sec>
</sec>
<sec id="section4-0956797612443968">
<title>Experiment 2: Memorizing 100 Objects</title>
<p>People’s ability to remember large numbers of objects (<xref ref-type="bibr" rid="bibr2-0956797612443968">Brady et al., 2008</xref>; <xref ref-type="bibr" rid="bibr13-0956797612443968">Konkle et al., 2008</xref>) allows one to push this task far beyond anything attempted with alphanumeric characters. In Experiment 2, a new group of 10 observers committed 100 objects to memory. As in Experiment 1, they were required to pass two consecutive memory tests at greater than 80% correct. This portion of the experiment took approximately 10 to 15 min. One observer needed three blocks to meet the memory criterion. All others succeeded in the minimum of two. The mean accuracy on the last memory block was 93%. After reaching criterion, observers proceeded to perform 300 visual searches for any of the 100 objects in displays of 1, 2, 4, 8, or 16 items. More than 2,000 objects, sampled without replacement, were used as distractors. As in Experiment 1, a target was present on 50% of the trials.</p>
<p>The task was surprisingly easy. Miss error rates rose from 2% at the visual set size of 1 to 19% at the visual set size of 16. False alarms rose from 1% to 7%. The <italic>d</italic>′ statistic fell from 4.4 to 2.4. With a memory set size of 100, RT remained a linear function of visual set size, albeit with very steep slopes of 139 ms per visual item for target-present trials and 314 ms per item for target-absent trials.</p>
<p>Because just one memory set size was tested in Experiment 2, it is not possible to describe the shape of the RT × Memory Set Size function within this experiment. However, the data from Experiment 1 can be used to predict the RT for a memory set size of 100. <xref ref-type="fig" rid="fig1-0956797612443968">Figures 1e</xref> and <xref ref-type="fig" rid="fig1-0956797612443968">1f</xref> show the average RTs for Experiment 2 (solid data points at the memory set size of 100), along with the linear regression of RT on log2(memory set size) for the data of Experiment 1 (solid lines) and the extrapolation of the Experiment 1 data to the memory set size of 100 (dashed lines). It is clear that the logarithmic prediction is a remarkably good fit to the data. The average errors in prediction for target-present trials were −52, 1, 60, 68, and −74 ms for the visual set sizes of 1, 2, 4, 8, and 16, respectively (within 1%–5% of the average RT; see <xref ref-type="fig" rid="fig1-0956797612443968">Fig. 1e</xref>). By comparison, the data from Experiment 2 fell short of the predictions of a linear model by −1,156, −1,814, −2,505, −4,162, and −6,844 ms, respectively. The linear prediction was about 200% of the actual average RT. The predictions of the logarithmic model were comparably good for the target-absent trials (see <xref ref-type="fig" rid="fig1-0956797612443968">Fig. 1f</xref>).</p>
</sec>
<sec id="section5-0956797612443968">
<title>Experiment 3: Localizing the Target</title>
<p>One could argue that the departure from linearity in Experiment 1 reflected a speed-accuracy trade-off (<xref ref-type="bibr" rid="bibr19-0956797612443968">Shiffrin, 1988</xref>). Error rates rose with both visual and memory set sizes, both <italic>F</italic>s(1, 9) &gt; 9.4, both <italic>p</italic>s &lt; .0001, although they rose more markedly with memory set size. The maximum level of miss errors was 17% and occurred when the visual and memory set sizes were both 16. False alarm rates were low (&lt; 3% in all cells). Larger error rates could reflect earlier termination of search, and earlier termination of search could have depressed RTs at the larger set sizes, resulting in a compression of the RT × Set Size function. This hypothesis was tested by repeating Experiment 1 using a localization response, rather than a “present”/“absent” key-press response. Ten new observers were tested with memory set sizes of 1, 2, 4, 8, and 16 and visual set sizes of 2, 4, 8, and 16. As in Experiment 1, observers needed to pass the memory test for a given set size twice. The average number of blocks required rose from 2.2 at the memory set size of 1 to 4.2 at the memory set size of 16. The modal number of required blocks was 2 at all memory set sizes. Final accuracy was above 97%. This portion of the experiment took about 5 min (though somewhat longer for the observer who required 12 tries to get 16 items into memory!).</p>
<p>After reaching the memory criterion, observers were tested on 300 trials, with one target present on each trial. Response was a mouse click on the target. Use of a localization response reduced error rates to 2% or less in all cells, with the exception that the error rate was 8% when the visual and memory set sizes were both 16.</p>
<p><xref ref-type="fig" rid="fig2-0956797612443968">Figure 2</xref> shows the average RTs as a function of visual set size (<xref ref-type="fig" rid="fig2-0956797612443968">Fig. 2a</xref>) and memory set size (<xref ref-type="fig" rid="fig2-0956797612443968">Fig. 2b</xref>), with set size in each case plotted on a linear scale. The functions relating RT to visual set size remained linear. The functions relating RT to memory set size were clearly nonlinear. Just as the data for the memory set size of 100 (Experiment 2) were predicted with the data for set sizes of 1 through 16 (Experiment 1), RTs for the memory set size of 16 were predicted from RTs for the set sizes of 1 through 8 in this experiment. The predictions of a logarithmic model (open circles in <xref ref-type="fig" rid="fig2-0956797612443968">Fig. 2b</xref>) were close to the observed data, and we cannot reject this model, <italic>F</italic>(1, 9) = 0.21, <italic>p</italic> = .65, η<sub><italic>p</italic></sub><sup>2</sup> = .003. Note that the actual values were slightly lower than the values predicted by the logarithmic model, a result that may reflect a small speed-accuracy trade-off. In contrast, a linear extrapolation (asterisks in <xref ref-type="fig" rid="fig2-0956797612443968">Fig. 2b</xref>) was less successful in predicting results for the memory set size of 16, and this model can be rejected, <italic>F</italic>(1, 9) = 26.0, <italic>p</italic> = .0004, η<sub><italic>p</italic></sub><sup>2</sup> = .34.</p>
<fig id="fig2-0956797612443968" position="float">
<label>Fig. 2.</label>
<caption>
<p>Average reaction times (RTs) in Experiment 3, in which a target was present on each trial and observers localized the target with a mouse click. The graph in (a) shows RT as a function of visual set size, separately for each of the five memory set sizes; the key lists the slopes of the RT × Visual Set Size functions for the five memory set sizes. The graph in (b) shows RT as a function of memory set size, separately for each of the five visual set sizes. Open symbols show the predicted RTs for the memory set size of 16, extrapolated from memory set sizes 1 through 8, given a logarithmic relationship. Filled outline symbols show the much less successful predictions of a linear model. In both graphs, solid symbols indicate the averages across 10 observers, and error bars represent ±1 <italic>SEM</italic>.</p>
</caption>
<graphic xlink:href="10.1177_0956797612443968-fig2.tif"/>
</fig>
</sec>
<sec id="section6-0956797612443968" sec-type="discussion">
<title>General Discussion</title>
<p>Thus, visual searches for multiple targets held in memory are accomplished in a reasonable amount of time because memory search time increases with the log2 of the memory set size. A hypothetical search for any of 1,000 friends in a picture of a 100 people would take more than 40 min if memory search and visual search were both linear and each step in the search took 25 ms. With logarithmic memory search, that time drops to a more plausible 25 s. What does it mean for RTs to vary with log2 of the set size? This is the pattern that would be seen if half the items could be eliminated on the first step, another half on the next step, and so on. This could occur if objects were represented in the equivalent of a binary code in memory. When an observer attended to a visual object, its first “bit” of information could be compared to the first bits of items in memory. On average, half the items would match, and the other half could be eliminated. Another half could be rejected by examining the second bit, and so on, until one item was uniquely identified as belonging to the memory set of targets or all items were rejected as distractors. This account of logarithmic memory search is essentially the same as the information-theoretic account traditionally offered for the Hick-Hyman law (<xref ref-type="bibr" rid="bibr9-0956797612443968">Hick, 1952</xref>; <xref ref-type="bibr" rid="bibr12-0956797612443968">Hyman, 1953</xref>). Of course, the code might not be binary; the underlying function might be log3 or log<italic>N</italic>. Nor is it required that every item be coded with the same number of bits (e.g., Huffman coding; <xref ref-type="bibr" rid="bibr11-0956797612443968">Huffman, 1952</xref>). But our result illustrates a solution to the problem of joint visual and memory searches and raises interesting questions about the underlying neural representation of remembered items.</p>
<p>Visual search and memory search interact in real-world search tasks. Consider the airport screener, who searches through the visual set of objects in a bag for any members of the remembered set of “threats.” Such real-world searches are likely to be more complex than the search tasks employed in the present experiments because objects are represented at more than one level (<xref ref-type="bibr" rid="bibr17-0956797612443968">Rosch, 1973</xref>). Thus, a search for a robin, a wren, a blue jay, a sparrow, or a tiger might begin as a visual search for “birds” and “tigers”—a memory set size of 2. This might be followed by memory search to determine if a bird found in the display corresponds to one of the specific types of birds in the memory set. This memory set has a set size of 4, but is relevant only for birds. Search for threats might start with categories like “fluids” and “long metal objects,” with more detailed memory search performed only on items passing this first, categorical screen. Consider another interaction of memory and visual search. When a radiologist examines the whole-body scan of a patient who has been in a car crash, there is a very large set of remembered problems to search for. In this case, the memory set changes as a function of position in the image. For example, there is no point to searching for brain damage in the lower extremities. Again, the hybrid search will be a complex interplay of visual and memory search made more complicated if, as other evidence suggests, only one target “template” is active at any one moment (<xref ref-type="bibr" rid="bibr10-0956797612443968">Houtkamp &amp; Roelfsema, 2009</xref>; <xref ref-type="bibr" rid="bibr16-0956797612443968">Olivers et al., 2011</xref>).</p>
<p>In sum, when you search a photo for any of your many Facebook friends, your attention will be guided to humans and away from other objects (<xref ref-type="bibr" rid="bibr23-0956797612443968">Wolfe, 1994</xref>). Your search time will be a linear function of the number of humans in the visual scene and a logarithmic function of the number of friends held in memory.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author declared that he had no conflicts of interest with respect to his authorship or the publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Balani</surname><given-names>A. B.</given-names></name>
<name><surname>Soto</surname><given-names>D.</given-names></name>
<name><surname>Humphreys</surname><given-names>G. W.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Working memory and target-related distractor effects on visual search</article-title>. <source>Memory &amp; Cognition</source>, <volume>38</volume>, <fpage>1058</fpage>–<lpage>1076</lpage>.</citation>
</ref>
<ref id="bibr2-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brady</surname><given-names>T. F.</given-names></name>
<name><surname>Konkle</surname><given-names>T.</given-names></name>
<name><surname>Alvarez</surname><given-names>G. A.</given-names></name>
<name><surname>Oliva</surname><given-names>A.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Visual long-term memory has a massive storage capacity for object details</article-title>. <source>Proceedings of the National Academy of Sciences, USA</source>, <volume>105</volume>, <fpage>14325</fpage>–<lpage>14329</lpage>.</citation>
</ref>
<ref id="bibr3-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brainard</surname><given-names>D. H.</given-names></name>
</person-group> (<year>1997</year>). <article-title>The Psychophysics Toolbox</article-title>. <source>Spatial Vision</source>, <volume>10</volume>, <fpage>433</fpage>–<lpage>436</lpage>.</citation>
</ref>
<ref id="bibr4-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Briggs</surname><given-names>G. E.</given-names></name>
<name><surname>Blaha</surname><given-names>J.</given-names></name>
</person-group> (<year>1969</year>). <article-title>Memory retrieval and central comparison times in information processing</article-title>. <source>Journal of Experimental Psychology</source>, <volume>79</volume>(<issue>3, Pt. 1</issue>), <fpage>395</fpage>–<lpage>402</lpage>.</citation>
</ref>
<ref id="bibr5-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Burrows</surname><given-names>D.</given-names></name>
<name><surname>Murdock</surname><given-names>B. B.</given-names><suffix>Jr</suffix></name>
</person-group> (<year>1969</year>). <article-title>Effects of extended practice on high-speed scanning</article-title>. <source>Journal of Experimental Psychology</source>, <volume>82</volume>(<issue>2</issue>), <fpage>231</fpage>–<lpage>237</lpage>. doi:10.1037/h0028145<pub-id pub-id-type="doi">10.1037/h0028145</pub-id></citation>
</ref>
<ref id="bibr6-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Burrows</surname><given-names>D.</given-names></name>
<name><surname>Okada</surname><given-names>R.</given-names></name>
</person-group> (<year>1975</year>). <article-title>Memory retrieval from long and short lists</article-title>. <source>Science</source>, <volume>188</volume>, <fpage>1031</fpage>–<lpage>1033</lpage>.</citation>
</ref>
<ref id="bibr7-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Downing</surname><given-names>P.</given-names></name>
<name><surname>Dodds</surname><given-names>C.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Competition in visual working memory for control of search</article-title>. <source>Visual Cognition</source>, <volume>11</volume>, <fpage>689</fpage>–<lpage>703</lpage>.</citation>
</ref>
<ref id="bibr8-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Han</surname><given-names>S.-H.</given-names></name>
<name><surname>Kim</surname><given-names>M.-S.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Visual search does not remain efficient when executive working memory is working</article-title>. <source>Psychological Science</source>, <volume>15</volume>, <fpage>623</fpage>–<lpage>628</lpage>.</citation>
</ref>
<ref id="bibr9-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hick</surname><given-names>W. E.</given-names></name>
</person-group> (<year>1952</year>). <article-title>On the rate of gain of information</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>4</volume>, <fpage>11</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr10-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Houtkamp</surname><given-names>R.</given-names></name>
<name><surname>Roelfsema</surname><given-names>P. R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Matching of visual input to only one item at any one time</article-title>. <source>Psychological Research</source>, <volume>73</volume>, <fpage>317</fpage>–<lpage>326</lpage>. doi:10.1007/s00426-008-0157-3<pub-id pub-id-type="doi">10.1007/s00426-008-0157-3</pub-id></citation>
</ref>
<ref id="bibr11-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Huffman</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1952</year>). <article-title>A method for the construction of minimum-redundancy codes</article-title>. <source>Proceedings of the Institute of Radio Engineers</source>, <volume>40</volume>, <fpage>1098</fpage>–<lpage>1102</lpage>.</citation>
</ref>
<ref id="bibr12-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hyman</surname><given-names>R.</given-names></name>
</person-group> (<year>1953</year>). <article-title>Stimulus information as a determinant of reaction time</article-title>. <source>Journal of Experimental Psychology</source>, <volume>45</volume>(<issue>3</issue>), <fpage>188</fpage>–<lpage>196</lpage>.</citation>
</ref>
<ref id="bibr13-0956797612443968">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Konkle</surname><given-names>T.</given-names></name>
<name><surname>Brady</surname><given-names>T.</given-names></name>
<name><surname>Alvarez</surname><given-names>G.</given-names></name>
<name><surname>Oliva</surname><given-names>A.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Remembering thousands of objects with high fidelity</article-title>. <source>Journal of Vision</source>, <volume>8</volume>(<issue>6</issue>), <comment>Article 694</comment>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://journalofvision.org/8/6/694/">http://journalofvision.org/8/6/694/</ext-link></comment></citation>
</ref>
<ref id="bibr14-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Neisser</surname><given-names>U.</given-names></name>
</person-group> (<year>1974</year>). <article-title>Practiced card sorting for multiple targets</article-title>. <source>Memory &amp; Cognition</source>, <volume>2</volume>, <fpage>781</fpage>–<lpage>785</lpage>.</citation>
</ref>
<ref id="bibr15-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nickerson</surname><given-names>R. S.</given-names></name>
</person-group> (<year>1966</year>). <article-title>Response times with a memory-dependent decision task</article-title>. <source>Journal of Experimental Psychology</source>, <volume>72</volume>(<issue>5</issue>), <fpage>761</fpage>–<lpage>769</lpage>. doi:10.1037/h0023788<pub-id pub-id-type="doi">10.1037/h0023788</pub-id></citation>
</ref>
<ref id="bibr16-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Olivers</surname><given-names>C. N.</given-names></name>
<name><surname>Peters</surname><given-names>J.</given-names></name>
<name><surname>Houtkamp</surname><given-names>R.</given-names></name>
<name><surname>Roelfsema</surname><given-names>P. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Different states in visual working memory: When it guides attention and when it does not</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>15</volume>, <fpage>327</fpage>–<lpage>334</lpage>. doi:S1364-6613(11)00085-4 [pii] 10.1016/j.tics.2011.05.004<pub-id pub-id-type="doi">10.1016/j.tics.2011.05.004</pub-id></citation>
</ref>
<ref id="bibr17-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosch</surname><given-names>E. H.</given-names></name>
</person-group> (<year>1973</year>). <article-title>Natural categories</article-title>. <source>Cognitive Psychology</source>, <volume>4</volume>, <fpage>328</fpage>–<lpage>350</lpage>.</citation>
</ref>
<ref id="bibr18-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schneider</surname><given-names>W.</given-names></name>
<name><surname>Shiffrin</surname><given-names>R. M.</given-names></name>
</person-group> (<year>1977</year>). <article-title>Controlled and automatic human information processing: I. Detection, search, and attention</article-title>. <source>Psychological Review</source>, <volume>84</volume>, <fpage>1</fpage>–<lpage>66</lpage>.</citation>
</ref>
<ref id="bibr19-0956797612443968">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Shiffrin</surname><given-names>R. M.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Attention</article-title>. <italic>In</italic> <person-group person-group-type="editor">
<name><surname>Atkinson</surname><given-names>R.</given-names></name>
<name><surname>Herrnstein</surname><given-names>R. J.</given-names></name>
<name><surname>Lindzey</surname><given-names>G.</given-names></name>
<name><surname>Luce</surname><given-names>R. D.</given-names></name>
</person-group> (Eds.), <source>Stevens’ handbook of experimental psychology</source> (<edition>2nd ed.</edition>, <volume>Vol. 2</volume>, pp. <fpage>739</fpage>–<lpage>812</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr20-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sternberg</surname><given-names>S.</given-names></name>
</person-group> (<year>1966</year>). <article-title>High-speed scanning in human memory</article-title>. <source>Science</source>, <volume>153</volume>, <fpage>652</fpage>–<lpage>654</lpage>.</citation>
</ref>
<ref id="bibr21-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Van Zandt</surname><given-names>T.</given-names></name>
<name><surname>Townsend</surname><given-names>J. T.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Self-terminating versus exhaustive processes in rapid visual and memory search: An evaluative review</article-title>. <source>Perception &amp; Psychophysics</source>, <volume>53</volume>, <fpage>563</fpage>–<lpage>580</lpage>.</citation>
</ref>
<ref id="bibr22-0956797612443968">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Vickery</surname><given-names>T. J.</given-names></name>
<name><surname>King</surname><given-names>L.-W.</given-names></name>
<name><surname>Jiang</surname><given-names>Y.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Setting up the target template in visual search</article-title>. <source>Journal of Vision</source>, <volume>5</volume>(<issue>1</issue>), <comment>Article 8. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.journalofvision.org/content/5/1/8">http://www.journalofvision.org/content/5/1/8</ext-link></comment></citation>
</ref>
<ref id="bibr23-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolfe</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Guided Search 2.0: A revised model of visual search</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>1</volume>, <fpage>202</fpage>–<lpage>238</lpage>.</citation>
</ref>
<ref id="bibr24-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolfe</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1998</year>). <article-title>What do 1,000,000 trials tell us about visual search?</article-title> <source>Psychological Science</source>, <volume>9</volume>, <fpage>33</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr25-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolfe</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Visual search</article-title>. <source>Current Biology</source>, <volume>20</volume>, <fpage>R346</fpage>–<lpage>R349</lpage>. doi:10.1016/j.cub.2010.02.016<pub-id pub-id-type="doi">10.1016/j.cub.2010.02.016</pub-id></citation>
</ref>
<ref id="bibr26-0956797612443968">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Woodman</surname><given-names>G. F.</given-names></name>
<name><surname>Vogel</surname><given-names>E. K.</given-names></name>
<name><surname>Luck</surname><given-names>S. J.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Visual search remains efficient when visual working memory is full</article-title>. <source>Psychological Science</source>, <volume>12</volume>, <fpage>219</fpage>–<lpage>224</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>