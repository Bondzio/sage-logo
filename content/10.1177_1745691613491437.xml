<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PPS</journal-id>
<journal-id journal-id-type="hwp">sppps</journal-id>
<journal-id journal-id-type="nlm-ta">Perspect Psychol Sci</journal-id>
<journal-title>Perspectives on Psychological Science</journal-title>
<issn pub-type="ppub">1745-6916</issn>
<issn pub-type="epub">1745-6924</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1745691613491437</article-id>
<article-id pub-id-type="publisher-id">10.1177_1745691613491437</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Special Section on Advancing Science</subject>
</subj-group>
</article-categories>
<title-group>
<article-title><ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link></article-title>
<subtitle>Grassroots Support for Reforming Reporting Standards in Psychology</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>LeBel</surname><given-names>Etienne P.</given-names></name>
<xref ref-type="aff" rid="aff1-1745691613491437">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Borsboom</surname><given-names>Denny</given-names></name>
<xref ref-type="aff" rid="aff2-1745691613491437">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Giner-Sorolla</surname><given-names>Roger</given-names></name>
<xref ref-type="aff" rid="aff3-1745691613491437">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Hasselman</surname><given-names>Fred</given-names></name>
<xref ref-type="aff" rid="aff4-1745691613491437">4</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Peters</surname><given-names>Kurt R.</given-names></name>
<xref ref-type="aff" rid="aff5-1745691613491437">5</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Ratliff</surname><given-names>Kate A.</given-names></name>
<xref ref-type="aff" rid="aff6-1745691613491437">6</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Smith</surname><given-names>Colin Tucker</given-names></name>
<xref ref-type="aff" rid="aff6-1745691613491437">6</xref>
</contrib>
</contrib-group>
<aff id="aff1-1745691613491437"><label>1</label>Department of Psychology, University of Western Ontario</aff>
<aff id="aff2-1745691613491437"><label>2</label>Department of Psychology, University of Amsterdam</aff>
<aff id="aff3-1745691613491437"><label>3</label>School of Psychology, University of Kent</aff>
<aff id="aff4-1745691613491437"><label>4</label>Behavioural Science Institute, Radboud University Nijmegen</aff>
<aff id="aff5-1745691613491437"><label>5</label>ICF International, Fairfax, Virginia</aff>
<aff id="aff6-1745691613491437"><label>6</label>Department of Psychology, University of Florida</aff>
<author-notes>
<corresp id="corresp1-1745691613491437">Etienne P. LeBel, Social Science Centre, Department of Psychology, University of Western Ontario, London, Ontario N6A 5C2, Canada E-mail: <email>elebel@uwo.ca</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>8</volume>
<issue>4</issue>
<fpage>424</fpage>
<lpage>432</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>There is currently an unprecedented level of doubt regarding the reliability of research findings in psychology. Many recommendations have been made to improve the current situation. In this article, we report results from <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link>, a novel open-science initiative that provides a platform for authors of recently published articles to disclose four methodological design specification details that are not required to be disclosed under current reporting standards but that are critical for accurate interpretation and evaluation of reported findings. Grassroots sentiment—as manifested in the positive and appreciative response to our initiative—indicates that psychologists want to see changes made at the systemic level regarding disclosure of such methodological details. Almost 50% of contacted researchers disclosed the requested design specifications for the four methodological categories (excluded subjects, nonreported conditions and measures, and sample size determination). Disclosed information provided by participating authors also revealed several instances of questionable editorial practices, which need to be thoroughly examined and redressed. On the basis of these results, we argue that the time is now for mandatory methods disclosure statements for all psychology journals, which would be an important step forward in improving the reliability of findings in psychology.</p>
</abstract>
<kwd-group>
<kwd>reporting standards</kwd>
<kwd>disclosure</kwd>
<kwd>methodological design specifications</kwd>
<kwd>methodology</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>The goal of science is to amass cumulative knowledge about how the world works. In psychology, this means accruing cumulative knowledge regarding the prediction and explanation of human behavior. Recently, there has been a growing concern regarding the nonreplicability of research findings in psychology (<xref ref-type="bibr" rid="bibr15-1745691613491437">Ioannidis, 2012</xref>; <xref ref-type="bibr" rid="bibr28-1745691613491437">Pashler &amp; Harris, 2012</xref>) and neuroscience (<xref ref-type="bibr" rid="bibr4-1745691613491437">Button et al., 2013</xref>), with some even considering it a “crisis of confidence” (<xref ref-type="bibr" rid="bibr29-1745691613491437">Pashler &amp; Wagenmakers, 2012</xref>).<sup><xref ref-type="fn" rid="fn1-1745691613491437">1</xref></sup> Researchers have considered many factors contributing to replication difficulties in psychology, including the near-exclusive focus on publishing novel findings (<xref ref-type="bibr" rid="bibr14-1745691613491437">Giner-Sorolla, 2012</xref>; <xref ref-type="bibr" rid="bibr26-1745691613491437">Nosek, Spies, &amp; Motyl, 2012</xref>), an overemphasis on conceptual replications (<xref ref-type="bibr" rid="bibr20-1745691613491437">LeBel &amp; Peters, 2011</xref>), the use of unreliable measures (<xref ref-type="bibr" rid="bibr19-1745691613491437">LeBel &amp; Paunonen, 2011</xref>), and an extreme dearth of independent direct replications (i.e., less than 0.1% of published articles in the last 100 years; <xref ref-type="bibr" rid="bibr22-1745691613491437">Makel, Plucker, &amp; Hegarty, 2012</xref>). The use of questionable research practices—or <italic>researcher degrees of freedom</italic>—has also been highlighted as contributing to false-positive results in psychology (<xref ref-type="bibr" rid="bibr16-1745691613491437">John, Loewenstein, &amp; Prelec, 2012</xref>; <xref ref-type="bibr" rid="bibr31-1745691613491437">Simmons, Nelson, &amp; Simonsohn, 2011</xref>) and hence contributing to the nonreplicability of findings.</p>
<p>In the wake of this crisis, several initiatives and recommendations have been made to improve the reliability of psychological findings. One prominent example of such an initiative is a website (<ext-link ext-link-type="uri" xlink:href="http://PsychFileDrawer.org/">PsychFileDrawer.org/</ext-link>) where researchers can post failed (or successful) replications in an attempt to combat the oft-referenced file drawer problem in which nonsignificant (or redundant) findings typically fail to be published. Another example is a large-scale effort called the Reproducibility Project (<xref ref-type="bibr" rid="bibr27-1745691613491437">Open Science Collaboration, 2012</xref>), in which researchers are investigating factors that predict the reproducibility of psychological findings.<sup><xref ref-type="fn" rid="fn2-1745691613491437">2</xref></sup> The initiative described in the current work was inspired by these action-oriented approaches and by a recommendation that seemed of critical importance to us. Specifically, <xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons, Nelson, and Simonsohn (2012</xref>; see also <xref ref-type="bibr" rid="bibr31-1745691613491437">Simmons et al., 2011</xref>) recommended that authors submitting manuscripts include a 21-word disclosure statement stating that all exclusions, measures, experimental conditions, and sample size determination rules have been reported.<sup><xref ref-type="fn" rid="fn3-1745691613491437">3</xref></sup> This statement is intended to allow the reader (and reviewers) to rule out or account for researcher degrees of freedom that authors might have exploited to obtain the reported results. For instance, knowing that all measures/items were reported, readers and reviewers can assess the extent to which multiple testing contributed to achieving statistical significance of particular results. Likewise, by stating that data collection stopped once a predetermined sample size was reached, readers and reviewers can rule out that optional stopping was used (i.e., analyzing the data as they accumulate and halting the study whenever results reach statistical significance; <xref ref-type="bibr" rid="bibr2-1745691613491437">Armitage, McPherson, &amp; Rowe, 1969</xref>; <xref ref-type="bibr" rid="bibr10-1745691613491437">Feller, 1940</xref>).</p>
<sec id="section1-1745691613491437">
<title><ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link>: Nature and Aims</title>
<p>In line with these observations, and to further stimulate the realization of an open and honest research culture, we launched <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> on November 17, 2012. PsychDisclosure.org is a novel open science initiative intended to contribute to improving the reliability of psychological findings by providing a platform for authors to publicly disclose four categories of methodological design specifications (i.e., excluded subjects, non- reported conditions and measures, and sample size determination) that are not required to be disclosed under current reporting standards but that are essential for accurate interpretation and evaluation of research findings. We use the term <italic>design specification statements</italic> to refer to the additional information disclosed by participating authors. Another goal of the initiative is to investigate the extent to which psychological journals’ reporting standards might be suboptimal (i.e., to investigate the prevalence of important research design decisions not reported in actual publications). If such practices are indeed widespread, this suggests that disclosure statements—of the kind proposed by <xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons et al. (2012)</xref>—should in fact become a required component of the manuscript submission process. In the current article, we report the first results from the initiative, which unequivocally support a policy change for manuscript submissions.</p>
<sec id="section2-1745691613491437">
<title><ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link>: Authors contacted</title>
<p>Using a bottom-up, grassroots approach, we emailed a random 50% of all corresponding authors of articles published in 2012 and onward in the prominent journals <italic>Psychological Science</italic> (<italic>PS</italic>); <italic>Journal of Personality and Social Psychology</italic> (<italic>JPSP</italic>); <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition</italic> (<italic>JEP:LMC</italic>); and <italic>Journal of Experimental Psychology: General</italic> (<italic>JEP:G</italic>).<sup><xref ref-type="fn" rid="fn4-1745691613491437">4</xref></sup> We asked authors whether they were interested in publicly disclosing four details of the methods used to obtain findings for all studies reported (see the supplementary material at <ext-link ext-link-type="uri" xlink:href="http://pps.sagepub.com/supplemental">http://pps.sagepub.com/supplemental</ext-link> for the e-mail text). The content of their replies would then be posted on the PsychDisclosure.org website. Only a random 50% of corresponding authors in each issue were contacted for disclosure, to mitigate respondent and institutional concerns regarding the anonymity of nonrespondents. This way, readers viewing the disclosed information on PsychDisclosure.org have no way of knowing whether articles are absent because authors decided not to disclose the information or because authors were never invited.</p>
</sec>
<sec id="section3-1745691613491437">
<title><ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link>: Results</title>
<p>As of March 5, 2013, 46.4% (i.e., 161 of 347) of contacted authors have replied to our e-mail and publicly disclosed the requested information. As can be seen in <xref ref-type="table" rid="table1-1745691613491437">Table 1</xref>, the response rates were similar across the four journals, though slightly higher for <italic>JEP:LMC</italic> and <italic>JEP:G</italic>.</p>
<table-wrap id="table1-1745691613491437" position="float">
<label>Table 1.</label>
<caption><p>Response Rates to Our E-Mail and Reported Rates of Full Disclosure Within the Published Articles in Each Journal</p></caption>
<graphic alternate-form-of="table1-1745691613491437" xlink:href="10.1177_1745691613491437-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th/>
<th align="center" colspan="4">% full disclosure for methodological categories<hr/></th>
</tr>
<tr>
<th align="left">Journal</th>
<th align="center"><italic>N</italic></th>
<th align="center">Response rate (%)</th>
<th align="center">Exclusions</th>
<th align="center">Conditions</th>
<th align="center">Measures</th>
<th align="center">Sample size</th>
</tr>
</thead>
<tbody>
<tr>
<td><italic>Psychological Science</italic></td>
<td>131</td>
<td>45.8</td>
<td>88.3</td>
<td>88.3</td>
<td>46.7</td>
<td>15.0</td>
</tr>
<tr>
<td><italic>Journal of Personality and Social Psychology</italic></td>
<td>92</td>
<td>43.5</td>
<td>92.5</td>
<td>87.5</td>
<td>20.0</td>
<td>10.0</td>
</tr>
<tr>
<td><italic>Journal of Experimental Psychology: Learning, Memory, and Cognition</italic></td>
<td>79</td>
<td>49.4</td>
<td>84.6</td>
<td>84.6</td>
<td>87.2</td>
<td>5.1</td>
</tr>
<tr>
<td><italic>Journal of Experimental Psychology: General</italic></td>
<td>45</td>
<td>48.9</td>
<td>90.9</td>
<td>95.5</td>
<td>81.8</td>
<td>13.6</td>
</tr>
<tr>
<td> Overall</td>
<td>347</td>
<td>46.4</td>
<td>88.8</td>
<td>88.2</td>
<td>54.7</td>
<td>11.2</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1745691613491437">
<p>Note: All numbers represent percentages, except the <italic>N</italic> column, which indicates the number of articles for each journal selected for inclusion as of March 5, 2013. Full disclosure rates indicate the percentage of articles wherein authors answered “Yes,” indicating they had fully reported the respective methodological design specifications in the published article.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In the actual published articles, rates for fully disclosing the methodological design specifications varied widely across the four methodological categories. Overall, the vast majority of researchers stated that they had fully reported all excluded observations (88.8%) and fully reported all tested experimental conditions (88.2%). However, only 54.7% reported all assessed measures/items, and a mere 11.2% reported their data collection stopping rule. These full disclosure rates were similar across the four journals, except for the <italic>measures</italic> category, in which full disclosure rates were markedly higher for <italic>JEP:LMC</italic> and <italic>JEP:G</italic> (87.2% and 81.8%, respectively, vs. 46.7% and 20.0%; see <xref ref-type="table" rid="table1-1745691613491437">Table 1</xref>).</p>
<p>For methodological design specifications that had not been reported in the published article, the reasons for failing to disclose these details varied substantially across the four categories (see <xref ref-type="fig" rid="fig1-1745691613491437">Figure 1</xref>).<sup><xref ref-type="fn" rid="fn5-1745691613491437">5</xref></sup> Of particular note for conditions, 42% (8 out of 19) of the design specification statements stated that additional tested experimental conditions were not reported because statistically significant differences did not emerge in those conditions. Also, one participating author (5% of design specification statements in this category) stated that not all conditions were reported due to an editorial request because the data in those conditions revealed a more complex pattern. Even though this was found for only 1 out of 19 statements in this category, such editorial requests are striking given that they mischaracterize the evidence.</p>
<fig id="fig1-1745691613491437" position="float">
<label>Fig. 1.</label>
<caption>
<p>Reasons given for not including the methodological design specifications in the published article (later provided to <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link>). Within each disclosure category, totals are greater than 100% because more than one reason was sometimes mentioned. <italic>N</italic>s indicate the number of design specification statements the percentages are based on (out of the 347 possible articles).</p>
</caption>
<graphic xlink:href="10.1177_1745691613491437-fig1.tif"/></fig>
<p>For measures, it is noteworthy that 15% (11 of 73) of design specification statements mentioned that assessed measures went unreported because no statistically significant differences emerged on those measures, which is clear evidence of researcher degrees of freedom (<xref ref-type="bibr" rid="bibr16-1745691613491437">John et al., 2012</xref>; <xref ref-type="bibr" rid="bibr31-1745691613491437">Simmons et al., 2011</xref>). About 8% of design specification statements indicated that additional measures went unreported because of psychometric problems, which we thought was surprising given we expected this to be higher (<xref ref-type="bibr" rid="bibr20-1745691613491437">LeBel &amp; Peters, 2011</xref>). Approximately 5% went unreported because of editorial requests, which again we found striking given the clear suboptimality of such a practice.</p>
<p>Finally, for sample size, about 44% of design specification statements indicated that data collection halted once a predetermined sample size was reached, and about 4% (6 of 143) collected more data because of editorial requests. Of note, about 5% of our respondents stated they continued collecting data until the relevant patterns were clear, which is surprising given that these statements amount to public admissions of optional stopping.</p>
</sec></sec>
<sec id="section4-1745691613491437">
<title><ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> Benefits</title>
<p><ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> has benefits for both the researchers reporting their results and for the field in general.</p>
<sec id="section5-1745691613491437">
<title>Researcher benefits</title>
<p>The main benefit of researchers publicly disclosing the four methodological design specifications on <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> is to increase the information value of their published article. With the additional disclosed information, readers of the article in question can more accurately interpret the reported results in light of the claim that many researchers have engaged in so-called questionable research practices (<xref ref-type="bibr" rid="bibr16-1745691613491437">John et al., 2012</xref>). <xref ref-type="bibr" rid="bibr16-1745691613491437">John et al. (2012)</xref> found that the majority of researchers—in a sample of over 2,000 psychologists—admitted to not always reporting all of a study’s dependent measures or to deciding to collect more data after looking to see whether the results were statistically significant. When the four categories of methodological design specifications are disclosed, however, readers can (a) effectively rule out the possibility that reported results are partly due to unreported design specifications (in the case of full disclosure) or (b) arrive at a more nuanced interpretation of the findings given their judgment of the “principledness” of the reasons provided for not disclosing the methodological information in the published article. For example, if a corresponding author disclosed that all excluded observations, tested experimental conditions, and all assessed measures/items were reported in the published article and that data collection stopped once an a priori sample size was reached, then a reader can effectively rule out alternative hypotheses that may explain the results (e.g., selective reporting of measures/items, optional stopping). In short, clarifying that the methodology behind a finding was rigorous should justifiably increase confidence in that finding. Although the benefits of disclosing unreported methodological decisions might seem personally threatening to some researchers, we believe that doing so is actually compatible with self-interest. The disclosure in no way jeopardizes the published status of an article or its place on one’s curriculum vitae because it is not fair to blame authors for playing by the implicit rules of the game as they stood when the article was accepted. Moreover, as discussed later, these rules are sometimes enforced by reviewers and editors.</p>
<p>A second benefit for researchers of adopting our disclosure norms involves promoting and establishing more sensible publication criteria. It will likely become clear that many published findings that were subsequently replicated and extended had less-than-perfect support for the initially reported findings by today’s rigid significance standards. To reach back across the decades, one article that was apparently published under norms of full disclosure was <xref ref-type="bibr" rid="bibr11-1745691613491437">Festinger and Carlsmith’s (1959)</xref> classic induced-compliance experiment in support of cognitive dissonance theory. Under close examination, only one of its three relevant outcome measures yielded a statistically significant effect of condition, with the other two yielding marginal levels of statistical significance. Yet, as a result of further replications and modifications of this paradigm, the reality of induced compliance effects now stands beyond question.</p>
</sec>
<sec id="section6-1745691613491437">
<title>Benefits for the field</title>
<p>An important benefit of <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> for the field is that it contributes to a partial opening of the black box of peer review and sheds light on the questionable editorial practices (QEPs) that have recently been identified (<xref ref-type="bibr" rid="bibr21-1745691613491437">Levelt Committee, Noort Committee, &amp; Drenth Committee, 2012</xref>) as factors that contribute to the replicability problem in psychology. For example, it is now known that action editors and reviewers often require authors to selectively report experimental conditions, measures, or samples to “streamline” the article or to increase the compellingness of the story. (Indeed, this was the case in several of the design specification statements made by participating authors.) Given that most researchers will of course adhere to such QEPs, it is absolutely critical that such information be publicly disclosed and for awareness regarding QEPs to increase so that reforms in editorial practices can be implemented.</p>
<p>A second benefit of our initiative for the field is to raise awareness regarding ways in which our journals’ current reporting standards may be ineffective. At present, these standards do not require authors to disclose information concerning the aforementioned categories of important methodological design specifications. By continually contacting a randomly sampled 50% of corresponding authors of recently published articles in new issues of <italic>PS, JPSP, JEP:LMC</italic>, and <italic>JEP:G</italic>, our initiative is raising awareness among the community of psychologists about our journals’ ineffectual reporting standards. The ultimate goal is that this increased awareness among the community of psychologists motivates journal editors to change editorial policies, such that the four categories of methodological details disclosed on <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> become a required component for manuscript submission. Indeed, there is already evidence that our initiative is having an effect in this regard.</p>
</sec></sec>
<sec id="section7-1745691613491437">
<title>Normative Demand for Mandatory Disclosure Statements</title>
<p>Several aspects of the scientific community’s response and reaction to <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> suggest a strong normative demand for mandatory disclosure statements for journals in psychology. First, the current raw response rate of 46%, which is higher than we anticipated before the initiative was launched, clearly suggests that a large proportion of researchers believe such disclosure information to be important. It is crucial to note also that our response rate should be interpreted as a lower bound estimate (to the response rate anticipated if such disclosure was mandatory), given the total effort participating authors had to expend digging up methodological design specifications for all studies reported in the relevant article, in some cases involving studies run 4 to 5 years earlier.</p>
<p>As surprised as we were by the raw response rate, we were even more surprised by the positive and appreciative nature of the feedback we received from participating authors. A large number of respondents (more than 35) explicitly stated that (a) they fully supported our initiative, (b) this kind of initiative was long overdue, and (c) they were extremely grateful and appreciative for the important service we are providing to the field. Furthermore, the few negative reactions to our initiative involved concerns that journals, rather than an independent group of researchers, should be soliciting such information. Such researchers supported our cause but disagreed with the means. Also, several researchers disclosed the requested information but expressed concern that they were now in an unfair theoretical position whereby theoretical opponents could use some of their disclosed methodological details against them. These researchers felt strongly that we should have contacted 100%, rather than a random 50%, of corresponding authors—compelling evidence that these researchers believe such information needs to be disclosed for all published articles in psychology.</p>
<p>Taken together, we argue that the high response rate and the nature of the feedback to our initiative demonstrate that the community of psychologists desires the implementation (in some shape or form) of mandatory disclosure statements. Our results are consistent with a survey of over 1,200 psychologists (sent in December 2011) who overwhelmingly supported changes to improve research practices in psychology in relation to <xref ref-type="bibr" rid="bibr31-1745691613491437">Simmons et al.’s (2011)</xref> recommendations (<xref ref-type="bibr" rid="bibr13-1745691613491437">Fuchs, Jenny, &amp; Fiedler, 2012</xref>). The vast majority of psychologists responding to that survey agreed that researchers should report all assessed measures, tested experimental conditions, and their data collection termination rule. <xref ref-type="bibr" rid="bibr13-1745691613491437">Fuchs et al. (2012)</xref> also found that a near-majority of the psychologists agreed that it should be a <italic>publication condition</italic> that authors disclose eliminated observations (52% agreement), all tested experimental conditions (66%), all assessed measures (46%), and the data collection termination rule (46%). We believe our response rate and positive feedback provide stronger evidence than Fuchs et al.’s findings for requiring such information as a publication condition, given that researchers had to actively reply to our e-mail, find and collate the information, and agree to go on public record regarding the disclosure of the unreported methodological information. That is, the act of actually disclosing the information carries much more weight than simply saying that we should be doing this. After all, actions speak louder than words.</p>
</sec>
<sec id="section8-1745691613491437">
<title>Concerns Regarding Mandatory Disclosure Statements</title>
<p>We now address various concerns that have been raised regarding requiring disclosure of the four categories of methodological design specifications as a mandatory requirement for publication in psychology journals.</p>
<sec id="section9-1745691613491437">
<title>It will lead to unfair evaluations</title>
<p>Because of the highly competitive nature of peer-reviewed publishing, esthetics of data perfection often seem to prevail to the detriment of an overall view of the evidence (<xref ref-type="bibr" rid="bibr14-1745691613491437">Giner-Sorolla, 2012</xref>). One concern is that mandatory disclosure would lead to unfair evaluations of imperfect-looking findings, even if these are to be expected statistically when testing a true hypothesis; that the rigid standards applied now would be applied to more honest reporting and that more manuscripts would be rejected because of this. The obvious answer is for reviewers and editors to take a more comprehensive view of the evidence, and for authors to help this view along through meta-analytic or multivariate approaches showing an overall consistency of results, even if some, taken individually, are not statistically significant.</p>
<p>A related concern is that mandatory disclosure may hamper exploratory research. Researchers may fear that they will be penalized for including exploratory measures or manipulations. Here, we think an emphasis on disclosure will actually be fair, rather than unfair. It will be fair to authors who honestly distinguish between exploratory and confirmatory research stages in their writing, rather than pretending they knew it all along (e.g., <xref ref-type="bibr" rid="bibr18-1745691613491437">Kerr, 1998</xref>). It will be fair to authors who take the time and effort to choose confirmed, well-tested methods over improvised, ad hoc ones—including validated measures and manipulations, and high-powered sample sizes—because such methods increase the ability to interpret results, even null results. Combining these two standards, correctly applied disclosure standards will be fair to authors who follow-up exploratory work with principled validation. Authors must show that discarded methods have lost out because of independently verifiable issues with validity or reliability (as indicated in 6 of 73 design specification statements), rather than because of the circular reasoning that they happened to show no connection between predictor and outcome. For example, disclosing that two experimental conditions were dropped, because of independent evidence that most of their subjects failed to understand task instructions, would be a principled reason for exclusion.</p>
<p>In a final fairness concern, studies involving expensive and time-consuming designs or hard-to-reach populations—such as longitudinal, developmental, or cross-cultural research—often maximize the opportunity of data collection by testing many hypotheses at the same time. Would requiring authors to disclose all assessed measures lead to unfair evaluations of such designs—or, perhaps, to indigestible articles groaning with pages and pages of unrelated material? Again, the key to fairness is to avoid applying disclosure criteria mechanically but to see them as an opportunity for principled reasoning. For one, theoretically unrelated measures can be described in broad terms, and even in footnotes or supplementary materials, as long as editors and reviewers are convinced from this description that they bear no relevance to the question at hand and so do not present a validity problem for the conclusions of the article. Given the importance of research context, such inclusions deserve to be evaluated before publication in any case, without necessarily interrupting the flow of the final article’s argument. What would also be unfair (to science) is using the effortful nature of one’s research to justify drawing conclusions that are supported by only one out of five conceptually related measures included without mentioning the failures.</p>
<p>To strongly ensure that a focus on some measures/manipulations over others can be justified in any given write-up, researchers can honor and support particularly intensive studies by identifying focal, peripheral, exploratory, and confirmatory research hypotheses a priori (which can be done via preregistration; <xref ref-type="bibr" rid="bibr33-1745691613491437">Wagenmakers, Wetzels, Borsboom, van der Maas, &amp; Kievit, 2012</xref>). The effortful nature of a study’s data collection makes it even more important to make sure to construct each hypothesis so that an effect in either direction—or even a null effect (e.g., <xref ref-type="bibr" rid="bibr25-1745691613491437">Mehl, Vazire, Ramirez-Esparza, Slatcher, &amp; Pennebaker, 2007</xref>)—is theoretically interesting. The latter goal can be achieved by using methodologically sound manipulations and measures (<xref ref-type="bibr" rid="bibr20-1745691613491437">LeBel &amp; Peters, 2011</xref>) and stronger forms of hypothesis testing (<xref ref-type="bibr" rid="bibr12-1745691613491437">Fiedler, Kutzner, &amp; Krueger, 2012</xref>; <xref ref-type="bibr" rid="bibr23-1745691613491437">Meehl, 1967</xref>, <xref ref-type="bibr" rid="bibr24-1745691613491437">1978</xref>; <xref ref-type="bibr" rid="bibr30-1745691613491437">Platt, 1964</xref>).</p>
</sec>
<sec id="section10-1745691613491437">
<title>It will be ineffective, because of too many exceptions</title>
<p>Some are concerned that having rigid mandatory reporting requirements may not be effective given the wide variety of research designs and types of empirical investigations published in psychology journals. We agree that there will inevitably be challenges in implementing mandatory disclosure statements. For instance, standardized four- or five-category disclosure statements may not be completely relevant for all research designs. Also, standardized disclosure statements might not be able to rule out—for all kinds of empirical investigations—that questionable research practices were used to obtain the reported findings. We believe, however, that these situations will occur in the minority of cases (<xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons et al., 2012</xref>). More important, changes and improvement can (and inevitably will) be made over time to improve the mandatory disclosure statements so as to maximize their utility in promoting sounder research practices. As <xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons et al. (2012)</xref> pointed out by way of analogy, public health benefited immensely when U.S. politicians in 1906 implemented imperfect food regulations, such that all manufacturers were required to disclose the ingredients used in the production of all foods. By the same token, mandatory disclosure statements need not be perfect for real and substantial scientific benefits to be realized.</p>
</sec>
<sec id="section11-1745691613491437">
<title>People will lie</title>
<p>There likely will be a nonzero rate of lying in disclosure statements, just as there is a nonzero rate of data fabrication and falsification. However, we believe that lying will be rare in practice for the simple reason that there is a huge psychological difference between a sin of omission, which is not reporting such information, and a sin of commission, which entails making actual false statements regarding the methods used to obtain the reported results (<xref ref-type="bibr" rid="bibr7-1745691613491437">Cushman, Young, &amp; Hauser, 2006</xref>; <xref ref-type="bibr" rid="bibr9-1745691613491437">DeScioli, Christner, &amp; Kurzban, 2011</xref>). Indeed, a case can be made that making false statements in such disclosure statements would actually qualify as scientific fraud (<xref ref-type="bibr" rid="bibr1-1745691613491437">American Psychological Association, 2010</xref>).</p>
</sec>
<sec id="section12-1745691613491437">
<title>It will lengthen journal articles</title>
<p>Though this is technically true, making a disclosure statement and disclosing the recommended methodological information should take no more than a few sentences in the method section. For instance, <xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons et al.’s (2012)</xref> voluntary disclosure statement involves a brief 21-word sentence. And disclosing the additional methodological information (e.g., additional conditions, measures) should take no more than a few additional sentences because we are proposing only that the existence of additional measures and conditions be revealed, not that they be given a full statistical reporting. In the case in which numerous additional measures were assessed, these can be described in online supplementary materials.</p>
</sec>
<sec id="section13-1745691613491437">
<title>It is not feasible</title>
<p>A final and more general concern with having journals implement mandatory methodological disclosure statements is that it might impose overly burdensome infrastructure costs for journals. This is simply not the case given that journals could just request that authors include a version of <xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons et al.’s (2012)</xref> 21-word disclosure statement directly in their cover letters. Editors and reviewers could then confirm that all relevant methodological details were in fact disclosed in the manuscript or supplementary materials. As additional evidence supporting the feasibility of mandatory disclosure policies, we note that prominent journals in other areas have already implemented similar disclosure policies (e.g., the journals <italic>Management Science</italic> and <italic>Marketing Science</italic>; <xref ref-type="bibr" rid="bibr8-1745691613491437">Desai, 2013</xref>).<sup><xref ref-type="fn" rid="fn6-1745691613491437">6</xref></sup></p>
</sec></sec>
<sec id="section14-1745691613491437">
<title>A Push for More Openness</title>
<p>Another possible implication of our <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> results—especially given the high response rate and positive feedback—is that psychologists are ready for and desire scientific openness more broadly. This hunch is based on several aspects of the information voluntarily disclosed to us by corresponding authors. First, participating authors often disclosed more information than requested. For instance, many researchers provided very detailed methodological information even though we explicitly instructed them to provide brief design specification statements (with a few going as far as sending multiple-page documents as attachments with detailed information). Many authors also disclosed the actual names of each of the additional measures not reported in the original article (our request was simply whether they had reported all assessed measures and, if not, to provide the reasons for not reporting them). Most compellingly, 32% of authors (i.e., 6 out of 19 design specification statements in the conditions category) actually disclosed that additional studies were executed but not reported in the published article. This is surprising given we did not actually request this information.<sup><xref ref-type="fn" rid="fn7-1745691613491437">7</xref></sup> Taken together, these observations suggest that many researchers desire broader disclosure of the research process in general.</p>
<p>We see this potential development as very exciting and wish to comment briefly on existing infrastructure at <ext-link ext-link-type="uri" xlink:href="http://OpenScienceFramework.org">OpenScienceFramework.org</ext-link> (OSF) that will appeal to researchers interested in moving toward open science practices. The OSF is a website characterized by several important features that promote greater scientific openness, including preregistration of studies prior to data collection and the archiving of study materials, data, and syntax files to facilitate internal and external direct replications and meta-analytic efforts (for more details, see the supplementary materials at <ext-link ext-link-type="uri" xlink:href="http://pps.sagepub.com/supplemental">http://pps.sagepub.com/supplemental</ext-link>). We strongly encourage psychologists to consider using the OSF to facilitate broader disclosure and transparency, which we believe will go a long way in improving the reliability of findings in psychology.</p>
</sec>
<sec id="section15-1745691613491437">
<title>Conclusion</title>
<p>There is currently an unprecedented level of doubt regarding the reliability of research findings reported in psychology (<xref ref-type="bibr" rid="bibr29-1745691613491437">Pashler &amp; Wagenmakers, 2012</xref>) and neuroscience (<xref ref-type="bibr" rid="bibr4-1745691613491437">Button et al., 2013</xref>) journals, which has further tarnished the credibility of our field (<xref ref-type="bibr" rid="bibr6-1745691613491437">Carpenter, 2012</xref>; <xref ref-type="bibr" rid="bibr17-1745691613491437">Kahneman, 2012</xref>) and threatens to induce further cuts to funding for psychological research. Our position is that the reliability of findings in psychology can be improved by requiring the disclosure of four important methodological design specifications, which are required for accurate interpretation and evaluation of reported research findings. Indeed, our investigation revealed that such important methodological details were often not reported, particularly the data collection termination rule and whether additional measures/items were assessed. We argue that the time is now to make the disclosure of such information mandatory at submission given the positive grassroots sentiment reflected in the high response rate to our requests (almost 50%) and appreciative reaction by many to our initiative, which suggest that psychologists want to see editorial policy changes made in this regard at the systemic level. Our initiative also revealed several instances of QEPs, which need to be thoroughly examined and redressed. Open disclosure of the four targeted methodological categories will foster needed, action-oriented discussions regarding the soundness of various researcher and editorial practices. Ultimately—and ironically—it is our hope that this initiative, essential in the current climate, will eventually become unnecessary, being replaced by mandatory methods disclosure statements for all submissions to psychology journals.</p>
</sec>
</body>
<back>
<ack>
<p>We thank Brian Nosek and Jeffrey Spies for conceptual help with preliminary ideas that eventually led to the development of <ext-link ext-link-type="uri" xlink:href="http://PsychDisclosure.org">PsychDisclosure.org</ext-link> and Sampo Paunonen for help improving the disclosure questions and wording of the e-mail sent to corresponding authors. Thanks to Paul Conway and Sampo Paunonen for valuable feedback on an earlier version of the article. Thanks also to Christian Battista for technical help with Python coding and web development and Amanda Abado for administrative help corresponding with authors.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research was supported by a Social Science and Humanities Research Council postdoctoral fellowship to Etienne P. LeBel.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1745691613491437">
<label>1.</label>
<p>Following <xref ref-type="bibr" rid="bibr3-1745691613491437">Asendorpf et al. (2013)</xref>, we distinguish <italic>replicability</italic> (obtaining the same finding using the same methods with a different random sample) from <italic>reproducibility</italic> (obtaining the same result when executing the same analyses on the original data set).</p>
</fn>
<fn fn-type="other" id="fn2-1745691613491437">
<label>2.</label>
<p>A few journals now have mechanisms for incentivizing direct replications, including new preregistered replication manuscript categories at <italic>Perspectives on Psychological Science</italic> and <italic>Cortex</italic> and a special issue on direct replications of important findings in social psychology at <italic>Social Psychology</italic>.</p>
</fn>
<fn fn-type="other" id="fn3-1745691613491437">
<label>3.</label>
<p><xref ref-type="bibr" rid="bibr32-1745691613491437">Simmons et al.’s (2012)</xref> 21-word disclosure statement reads as follows: “We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study.”</p>
</fn>
<fn fn-type="other" id="fn4-1745691613491437">
<label>4.</label>
<p>We targeted these four journals because they represent prominent and widely read journals in psychology that publish findings that are generally considered important.</p>
</fn>
<fn fn-type="other" id="fn5-1745691613491437">
<label>5.</label>
<p>Disclosed information was coded into categories by three of the authors. Discrepancies were resolved verbally.</p>
</fn>
<fn fn-type="other" id="fn6-1745691613491437">
<label>6.</label>
<p>Notably, prominent journal <italic>Nature</italic> recently introduced editorial measures to improve the reliability of published findings by giving more space to method sections, requiring that key methodological details are disclosed, and encouraging authors to make their raw data available (<xref ref-type="bibr" rid="bibr5-1745691613491437">Campbell, 2013</xref>).</p>
</fn>
<fn fn-type="other" id="fn7-1745691613491437">
<label>7.</label>
<p>We considered requesting this information but decided against it thinking the task would be too onerous.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1745691613491437">
<citation citation-type="web"><collab>American Psychological Association</collab>. (<year>2010</year>). <source>American Psychological Association ethical principles of psychologists and code of conduct</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.apa.org/ethics/code/">http://www.apa.org/ethics/code/</ext-link></citation>
</ref>
<ref id="bibr2-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Armitage</surname><given-names>P.</given-names></name>
<name><surname>McPherson</surname><given-names>C. K.</given-names></name>
<name><surname>Rowe</surname><given-names>B. C.</given-names></name>
</person-group> (<year>1969</year>). <article-title>Repeated significance tests on accumulating data</article-title>. <source>Journal of the Royal Statistical Society. Series A (General)</source>, <volume>132</volume>, <fpage>235</fpage>–<lpage>244</lpage>.</citation>
</ref>
<ref id="bibr3-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Asendorpf</surname><given-names>J. B.</given-names></name>
<name><surname>Conner</surname><given-names>M.</given-names></name>
<name><surname>De Fruyt</surname><given-names>F.</given-names></name>
<name><surname>De Houwer</surname><given-names>J.</given-names></name>
<name><surname>Denissen</surname><given-names>J. J. A.</given-names></name>
<name><surname>Fiedler</surname><given-names>K.</given-names></name>
<name><surname>. . . Wicherts</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Recommendations for increasing replicability in psychology</article-title>. <source>European Journal of Personality</source>, <volume>27</volume>, <fpage>108</fpage>–<lpage>119</lpage>.</citation>
</ref>
<ref id="bibr4-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Button</surname><given-names>K. S.</given-names></name>
<name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name>
<name><surname>Mokrysz</surname><given-names>C.</given-names></name>
<name><surname>Nosek</surname><given-names>B. A.</given-names></name>
<name><surname>Flint</surname><given-names>J.</given-names></name>
<name><surname>Robinson</surname><given-names>E. S. J.</given-names></name>
<name><surname>Munafo</surname><given-names>M. R.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Power failure: Why small sample size undermines the reliability of neuroscience</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>14</volume>, <fpage>365</fpage>–<lpage>376</lpage>.</citation>
</ref>
<ref id="bibr5-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Campbell</surname><given-names>P.</given-names></name>
</person-group> (<year>2013</year>, <month>April</month> <day>24</day>). <article-title>Reducing our irreproducibility [Editorial]</article-title>. <source>Nature</source>, <volume>496</volume>, <fpage>398</fpage>.</citation>
</ref>
<ref id="bibr6-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Carpenter</surname><given-names>S.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Psychology’s bold initiative</article-title>. <source>Science</source>, <volume>335</volume>, <fpage>1558</fpage>–<lpage>1561</lpage>.</citation>
</ref>
<ref id="bibr7-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cushman</surname><given-names>F. A.</given-names></name>
<name><surname>Young</surname><given-names>L.</given-names></name>
<name><surname>Hauser</surname><given-names>M. D.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The role of reasoning and intuition in moral judgments: Testing three principles of harm</article-title>. <source>Psychological Science</source>, <volume>17</volume>, <fpage>1082</fpage>–<lpage>1089</lpage>.</citation>
</ref>
<ref id="bibr8-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Desai</surname><given-names>P. S.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Marketing science replication and disclosure policy</article-title>. <source>Marketing Science</source>, <volume>32</volume>, <fpage>1</fpage>–<lpage>3</lpage>.</citation>
</ref>
<ref id="bibr9-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeScioli</surname><given-names>P.</given-names></name>
<name><surname>Christner</surname><given-names>J.</given-names></name>
<name><surname>Kurzban</surname><given-names>R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The omission strategy</article-title>. <source>Psychological Science</source>, <volume>22</volume>, <fpage>442</fpage>–<lpage>446</lpage>.</citation>
</ref>
<ref id="bibr10-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Feller</surname><given-names>W.</given-names></name>
</person-group> (<year>1940</year>). <article-title>Statistical aspects of ESP</article-title>. <source>Journal of Parapsychology</source>, <volume>4</volume>, <fpage>271</fpage>–<lpage>298</lpage>.</citation>
</ref>
<ref id="bibr11-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Festinger</surname><given-names>L.</given-names></name>
<name><surname>Carlsmith</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1959</year>). <article-title>Cognitive consequences of forced compliance</article-title>. <source>Journal of Abnormal and Social Psychology</source>, <volume>58</volume>, <fpage>203</fpage>–<lpage>210</lpage>.</citation>
</ref>
<ref id="bibr12-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fiedler</surname><given-names>K.</given-names></name>
<name><surname>Kutzner</surname><given-names>F.</given-names></name>
<name><surname>Krueger</surname><given-names>J.</given-names></name>
</person-group> (<year>2012</year>). <article-title>The long way from alpha-control to validity proper: Problems with a shortsighted false-positive debate</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>661</fpage>–<lpage>669</lpage>.</citation>
</ref>
<ref id="bibr13-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fuchs</surname><given-names>H.</given-names></name>
<name><surname>Jenny</surname><given-names>M.</given-names></name>
<name><surname>Fiedler</surname><given-names>S.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Psychologists are open to change, yet wary of rules</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>634</fpage>–<lpage>637</lpage>.</citation>
</ref>
<ref id="bibr14-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Giner-Sorolla</surname><given-names>R.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Science or art? How esthetic standards grease the way through the publication bottleneck but undermine science</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>562</fpage>–<lpage>571</lpage>.</citation>
</ref>
<ref id="bibr15-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Why science is not necessarily self-correcting</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>645</fpage>– <lpage>654</lpage>.</citation>
</ref>
<ref id="bibr16-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>John</surname><given-names>L.</given-names></name>
<name><surname>Loewenstein</surname><given-names>G.</given-names></name>
<name><surname>Prelec</surname><given-names>D.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Measuring the prevalence of questionable research practices with incentives for truth-telling</article-title>. <source>Psychological Science</source>, <volume>23</volume>, <fpage>524</fpage>–<lpage>532</lpage>.</citation>
</ref>
<ref id="bibr17-1745691613491437">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Kahneman</surname><given-names>D.</given-names></name>
</person-group> (<year>2012</year>). <source>A proposal to deal with questions about priming effects</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/polopoly_fs/7.6716.1349271308!/suppinfoFile/Kahneman%20Letter.pdf">http://www.nature.com/polopoly_fs/7.6716.1349271308!/suppinfoFile/Kahneman%20Letter.pdf</ext-link></citation>
</ref>
<ref id="bibr18-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kerr</surname><given-names>N. L.</given-names></name>
</person-group> (<year>1998</year>). <article-title>HARKing: Hypothesizing after the results are known</article-title>. <source>Personality and Social Psychology Review</source>, <volume>2</volume>, <fpage>196</fpage>–<lpage>217</lpage>.</citation>
</ref>
<ref id="bibr19-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>LeBel</surname><given-names>E. P.</given-names></name>
<name><surname>Paunonen</surname><given-names>S. V.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Sexy but often unreliable: Impact of unreliability on the replicability of experimental findings involving implicit measures</article-title>. <source>Personality and Social Psychology Bulletin</source>, <volume>37</volume>, <fpage>570</fpage>–<lpage>583</lpage>.</citation>
</ref>
<ref id="bibr20-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>LeBel</surname><given-names>E. P.</given-names></name>
<name><surname>Peters</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Fearing the future of empirical psychology: Bem’s (2011) evidence of psi as a case study of deficiencies in modal research practice</article-title>. <source>Review of General Psychology</source>, <volume>15</volume>, <fpage>371</fpage>–<lpage>379</lpage>.</citation>
</ref>
<ref id="bibr21-1745691613491437">
<citation citation-type="web"><collab>Levelt Committee, Noort Committee, &amp; Drenth Committee</collab>. (<year>2012</year>). <source>Flawed science: The fraudulent research practices of social psychologist Diederik Stapel</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.tilburguniversity.edu/nl/nieuws-en-agenda/finalreportLevelt.pdf">http://www.tilburguniversity.edu/nl/nieuws-en-agenda/finalreportLevelt.pdf</ext-link></citation>
</ref>
<ref id="bibr22-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Makel</surname><given-names>M. C.</given-names></name>
<name><surname>Plucker</surname><given-names>J. A.</given-names></name>
<name><surname>Hegarty</surname><given-names>B.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Replications in psychology research: How often do they really occur?</article-title> <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>537</fpage>–<lpage>542</lpage>.</citation>
</ref>
<ref id="bibr23-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Meehl</surname><given-names>P. E.</given-names></name>
</person-group> (<year>1967</year>). <article-title>Theory testing in psychology and physics: A methodological paradox</article-title>. <source>Philosophy of Science</source>, <volume>34</volume>, <fpage>103</fpage>–<lpage>115</lpage>.</citation>
</ref>
<ref id="bibr24-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Meehl</surname><given-names>P. E.</given-names></name>
</person-group> (<year>1978</year>). <article-title>Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology</article-title>. <source>Journal of Consulting and Clinical Psychology</source>, <volume>46</volume>, <fpage>806</fpage>–<lpage>834</lpage>.</citation>
</ref>
<ref id="bibr25-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mehl</surname><given-names>M. R.</given-names></name>
<name><surname>Vazire</surname><given-names>S.</given-names></name>
<name><surname>Ramirez-Esparza</surname><given-names>N.</given-names></name>
<name><surname>Slatcher</surname><given-names>R. B.</given-names></name>
<name><surname>Pennebaker</surname><given-names>J. W.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Are women really more talkative than men?</article-title> <source>Science</source>, <volume>317</volume>, <fpage>82</fpage>.</citation>
</ref>
<ref id="bibr26-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nosek</surname><given-names>B. A.</given-names></name>
<name><surname>Spies</surname><given-names>J. R.</given-names></name>
<name><surname>Motyl</surname><given-names>M.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>615</fpage>–<lpage>631</lpage>.</citation>
</ref>
<ref id="bibr27-1745691613491437">
<citation citation-type="journal"><collab>Open Science Collaboration</collab>. (<year>2012</year>). <article-title>An open, large-scale, collaborative effort to estimate the reproducibility of psychological science</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>657</fpage>–<lpage>660</lpage>.</citation>
</ref>
<ref id="bibr28-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pashler</surname><given-names>H.</given-names></name>
<name><surname>Harris</surname><given-names>C. R.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Is the replicability crisis overblown? Three arguments examined</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>531</fpage>–<lpage>536</lpage>.</citation>
</ref>
<ref id="bibr29-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pashler</surname><given-names>H.</given-names></name>
<name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Editors’ introduction to the special section on replicability in psychological science: A crisis of confidence?</article-title> <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>528</fpage>–<lpage>530</lpage>.</citation>
</ref>
<ref id="bibr30-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Platt</surname><given-names>J. R.</given-names></name>
</person-group> (<year>1964</year>). <article-title>Strong inference</article-title>. <source>Science</source>, <volume>146</volume>, <fpage>347</fpage>–<lpage>353</lpage>.</citation>
</ref>
<ref id="bibr31-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simmons</surname><given-names>J. P.</given-names></name>
<name><surname>Nelson</surname><given-names>L. D.</given-names></name>
<name><surname>Simonsohn</surname><given-names>U.</given-names></name>
</person-group> (<year>2011</year>). <article-title>False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title>. <source>Psychological Science</source>, <volume>22</volume>, <fpage>1359</fpage>–<lpage>1366</lpage>.</citation>
</ref>
<ref id="bibr32-1745691613491437">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Simmons</surname><given-names>J. P.</given-names></name>
<name><surname>Nelson</surname><given-names>L. D.</given-names></name>
<name><surname>Simonsohn</surname><given-names>U.</given-names></name>
</person-group> (<year>2012</year>, <month>October</month> <day>14</day>). <source>A 21 word solution</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://ssrn.com/abstract=2160588">http://ssrn.com/abstract=2160588</ext-link></citation>
</ref>
<ref id="bibr33-1745691613491437">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name>
<name><surname>Wetzels</surname><given-names>R.</given-names></name>
<name><surname>Borsboom</surname><given-names>D.</given-names></name>
<name><surname>van der Maas</surname><given-names>H. L. J.</given-names></name>
<name><surname>Kievit</surname><given-names>R. A.</given-names></name>
</person-group> (<year>2012</year>). <article-title>An agenda for purely confirmatory research</article-title>. <source>Perspectives on Psychological Science</source>, <volume>7</volume>, <fpage>627</fpage>–<lpage>633</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>