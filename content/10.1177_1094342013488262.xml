<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">HPC</journal-id>
<journal-id journal-id-type="hwp">sphpc</journal-id>
<journal-title>The International Journal of High Performance Computing Applications</journal-title>
<issn pub-type="ppub">1094-3420</issn>
<issn pub-type="epub">1741-2846</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1094342013488262</article-id>
<article-id pub-id-type="publisher-id">10.1177_1094342013488262</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Special Issue Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Modeling synthetic aperture radar computation with Aspen</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Spafford</surname>
<given-names>Kyle</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488262">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Vetter</surname>
<given-names>Jeffrey S.</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342013488262">1</xref>
<xref ref-type="corresp" rid="corresp1-1094342013488262"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Benson</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff2-1094342013488262">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Parker</surname>
<given-names>Mike</given-names>
</name>
<xref ref-type="aff" rid="aff3-1094342013488262">3</xref>
</contrib>
<bio>
<title>Author biographies</title>
<p>
<italic>Kyle Spafford</italic> is a computer scientist in the Future Technologies Group at Oak Ridge National Laboratory where he explores the intersection of emerging architectures for high performance computing and performance analysis of large-scale scientific applications. Most recently, he has led the development of the Scalable Heterogeneous Computing (SHOC) benchmark suite and the Aspen language for analytical performance modeling. Prior to joining ORNL, Kyle received a M.S. in Computer Science from the Georgia Institute of Technology.</p>
<p>
<italic>Jeffrey S. Vetter</italic> holds a joint appointment between Oak Ridge National Laboratory (ORNL) and the Georgia Institute of Technology (GT). At ORNL, he is a Distinguished R&amp;D Staff Member, and the founding group leader of the Future Technologies Group in the Computer Science and Mathematics Division. At GT, he is a Joint Professor in the Computational Science and Engineering School of the College of Computing, the Principal Investigator and Project Director for the NSF Track 2D Experimental Computing Facility for large-scale heterogeneous computing using graphics processors, and the Director of the NVIDIA CUDA Center of Excellence. Professionally, he has published over 110 peer-reviewed papers; he has served on over 50 program committees, in leadership roles, including most recently as the SC12 Technical Papers Co-chair, and as an associate editor of IEEE Transactions on Computers. His papers have won awards at the International Parallel and Distributed Processing Symposium and EuroPar; he was awarded the ACM Gordon Bell Prize in 2010.</p>
<p>
<italic>Thomas Benson</italic> is a Research Engineer II within the Sensors and Electromagnetic Applications Laboratory at Georgia Tech Research Institute. He completed a Ph.D. in computer science at the University of Tennessee, Knoxville in 2006 and his current research focus areas include high-performance computing, large-scale distributed computing, embedded computing, radar signal processing, and computational imaging. He previously worked at GE Global Research in the area of X-ray CT imaging. He has over 25 conference and journal publications in the aforementioned research topics.</p>
<p>
<italic>Mike Parker</italic> joined NVIDIA in 2011 and is a Senior Research Scientist in the Architecture Research Group. His research focuses on energy efficient processors and systems for high-performance, mainstream, and embedded computing. Prior to joining NVIDIA, he was a Senior Hardware Architect at Cray, Inc. While at Cray, he architected a high-bandwidth DDR3 memory controller, researched high-radix interconnection topologies, worked on the architecture and microarchitecture of a high-radix router, defined an efficient interconnection network protocol, architected a table-driven static and adaptive routing mechanism for a high-radix topology, worked on several highly threaded, vector, and vector threaded processor architectures, defined an addressing architecture for a large-scale hybrid supercomputer, along with other system and processor architecture activities. Prior to Cray, he led the Impulse Memory System hardware implement team as full-time staff and architected and implemented pieces of the Avalanche scalable system as a graduate student at the University of Utah.</p>
</bio>
</contrib-group>
<aff id="aff1-1094342013488262">
<label>1</label>Oak Ridge National Laboratory, Oak Ridge, TN, USA</aff>
<aff id="aff2-1094342013488262">
<label>2</label>Georgia Tech Research Institute, Atlanta, GA, USA</aff>
<aff id="aff3-1094342013488262">
<label>3</label>NVIDIA, Santa Clara, CA, USA</aff>
<author-notes>
<corresp id="corresp1-1094342013488262">Jeffrey S. Vetter, Oak Ridge National Laboratory, 1 Bethel Valley Road, Oak Ridge, TN 37831, USA. Email: <email>vetter@ornl.gov</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2013</year>
</pub-date>
<volume>27</volume>
<issue>3</issue>
<issue-title>Special Issue section on CCDSC 2012 Workshop</issue-title>
<fpage>255</fpage>
<lpage>262</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>This case study presents an analytical performance model for the DARPA UHPC streaming sensor challenge problem developed using Aspen, a domain-specific language for performance modeling. The model focuses on the exploration of algorithmic tradeoffs, data structures and storage, and the impact of an important tiling factor in the image formation kernel of a synthetic aperture radar image-processing computation.</p>
</abstract>
<kwd-group>
<kwd>performance modeling</kwd>
<kwd>Aspen</kwd>
<kwd>workload characterization</kwd>
<kwd>Echelon</kwd>
<kwd>synthetic aperture radar</kwd>
<kwd>FFT</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1094342013488262">
<title>1. Introduction</title>
<p>As part of the performance modeling effort for the DARPA Ubiquitous High Performance Computing (UHPC) program, the NVIDIA-led Echelon (<xref ref-type="bibr" rid="bibr9-1094342013488262">Keckler, 2011</xref>; <xref ref-type="bibr" rid="bibr10-1094342013488262">Keckler et al., 2011</xref>) team has developed a model for the streaming sensor challenge problem (SSCP) (<xref ref-type="bibr" rid="bibr2-1094342013488262">Campbell et al., 2011</xref>) using Aspen (Abstract Scalable Performance Engineering Notation), a domain-specific language (DSL) for analytical performance modeling (<xref ref-type="bibr" rid="bibr13-1094342013488262">Spafford and Vetter, 2012</xref>). Aspen defines a systematic methodology including a formal grammar for describing analytical application and machine models. This approach is highly modular, captures control flow information, and preserves more algorithmic information than traditional frameworks such as BSP (<xref ref-type="bibr" rid="bibr14-1094342013488262">Valiant, 1990</xref>) and LogP variants (<xref ref-type="bibr" rid="bibr3-1094342013488262">Culler et al., 1993</xref>; <xref ref-type="bibr" rid="bibr1-1094342013488262">Alexandrov et al., 1995</xref>) which reduce machine specifications to a small set of parameters.</p>
<p>Aspen is complementary to other performance prediction techniques including simulation (<xref ref-type="bibr" rid="bibr7-1094342013488262">Janssen et al., 2011</xref>; <xref ref-type="bibr" rid="bibr12-1094342013488262">Rodrigues et al., 2011</xref>), emulation, or measurement on hardware prototypes. Compared with these techniques, Aspen’s analytical model is machine-independent, has fewer prerequisites (e.g. machine descriptions for simulation and source code), and it can produce answers without requiring large amounts of computation. This positions Aspen as a critical tool during the early phases in the modeling lifecycle, with continuing use as a high-level tool to guide detailed studies with simulators. Hence, the primary goal of Aspen is to facilitate coarse-grained algorithmic and architectural exploration.</p>
</sec>
<sec id="section1a-1094342013488262">
<title>2. SSCP introduction</title>
<p>We employ the Aspen language to construct a model for the requirements of a SSCP featuring synthetic aperture radar (SAR) processing. The scenario summarized herein is also described in a recent publication focused on optimizing a portion of the SAR processing on many-core architectures (<xref ref-type="bibr" rid="bibr11-1094342013488262">Park et al., 2012</xref>). In this scenario, continuous data from a radar onboard a platform orbiting about a fixed scene center is converted into a series of images of that scene over time. The radar data consists of signal returns that are collected from a series of pulses with many samples collected per pulse. The images generated from corresponding portions of the orbit at different times can thereby be compared to detect changes in the scene over time. The major operations in this process are image formation (converting data from the radar into an image representation), registration, and change detection. Of these operations, we focus on image formation as that process tends to dominate the operation counts as well as storage and bandwidth requirements. Image formation can be decomposed into two major phases, digital spotlighting (DS) and backprojection (BP), which are notionally depicted in <xref ref-type="fig" rid="fig1-1094342013488262">Figure 1</xref>. DS provides a means of reducing the computational loading of the BP operation, but the cost tradeoff of DS and BP must be carefully considered to minimize the total operation count. In particular, DS includes a tiling factor that increases the operation count for DS while decreasing the operation count for BP as the tiling factor increases.</p>
<fig id="fig1-1094342013488262" position="float">
<label>Figure 1.</label>
<caption>
<p>Tiled image formation. This figure shows a simplification of the general tiling scheme involved in image formation, using a tiling factor, <italic>tf</italic>, of two. Sensor data arrives as a matrix based on the number of SAR pulses and the samples per pulse. Then, during DS, each of <italic>tf</italic>
<sup>2</sup> (4) tiles is decimated or downsampled in both dimensions (i.e. in range and pulse). Finally, BP is applied to each tile to form the final image.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig1.tif"/>
</fig>
<p>The radar emits many pulses per second and, for each pulse, records many samples of the reflected data, with the latter samples corresponding to various time delays or ranges. This data set can be visualized as a matrix with each row containing the range samples for a given pulse. In order to obtain high resolution SAR images, a large radar aperture is synthesized by moving the platform and integrating contributions from pulses along the trajectory. Therefore, many pulses will be incorporated into a final image. In fact, if the desired image refresh rate exceeds the amount of data integrated into a single image, then one pulse will be used for many images. Rather than repeat the BP process using the same pulse for each associated image, we instead employ a buffering strategy to minimize the computational burden at the cost of increased memory capacity and bandwidth requirements. This process is described in more detail in Section 4.2.</p>
<p>All of these operations form a pipeline which is continuously fed from the input sensor. Images are ultimately compared with an image generated during a prior orbit using the corresponding portion of the platform trajectory as the current image. Thus, data from the prior orbit must be stored. Using Aspen, we modeled these data structures and their respective required capacity and bandwidth as well as the optimal DS tiling factor in Section 4.3. In particular, Aspen was used to investigate the following performance questions:
<list list-type="order">
<list-item>
<p>How much storage is required to hold an orbit set? How does this change based on image resolution and orbit time? Similarly, what are the bandwidth and storage requirements for the temporary images and buffers?</p>
</list-item>
<list-item>
<p>During image formation, which is known to dominate the total operation count, what is the precise relationship between the tiling factor and performance?</p>
</list-item>
</list>
</p>
</sec>
<sec id="section2-1094342013488262">
<title>3. Echelon System Overview</title>
<p>The SAR challenge problem was evaluated in the context of NVIDIA’s DARPA UHPC funded Echelon<sup>
<xref ref-type="fn" rid="fn1-1094342013488262">1</xref>
</sup> research architecture (<xref ref-type="bibr" rid="bibr10-1094342013488262">Keckler et al., 2011</xref>). Briefly, that architecture consists of a number of nodes connected via a system interconnect, where each node has 2048 throughput optimized cores and 8 latency optimized cores. These throughput cores realize a peak of 16 TF/s (double-precision) in the node. Assuming a ratio of 2 single-precision floating-point operations per double-precision floating-point operation, that implies a single-precision peak of 32 TF/s. Each node also has up to 32 GB of stacked DRAM at 2 TB/s bandwidth per node, an interface to external DRAM DIMMs, an I/O interface, and a configurable interface to external NVRAM. For this evaluation, we assume that the memory bandwidth to the external DRAM DIMMs is about 200 GB/s per node and that the external DRAM capacity is 512 GB, although an alternate approach might be to fix the number of nodes and then evaluate the DRAM capacity and bandwidth required for varying image sizes.</p>
</sec>
<sec id="section3-1094342013488262">
<title>4. SSCP modeling</title>
<p>An Aspen model for the SSCP imaging pipeline was constructed and validated against values produced using a conventional manual analysis. We present excerpts from that model and highlight how it was used to provide answers to the aforementioned performance questions. While this paper focuses on results specific to the SAR scenario, a full description of the syntax of these models is available online (<xref ref-type="bibr" rid="bibr13-1094342013488262">Spafford and Vetter, 2012</xref>). Further details on the scenario being modeled are available in prior publications as well (<xref ref-type="bibr" rid="bibr2-1094342013488262">Campbell et al., 2011</xref>; <xref ref-type="bibr" rid="bibr11-1094342013488262">Park et al., 2012</xref>). We will utilize many of the same scenario parameters for the present analysis. In particular, we consider images of 57,018 by 57,018 pixels produced at a rate of one per second with 2,809 pulses per second and 96,763 pulses per image. Thus, between <inline-formula id="inline-formula1-1094342013488262">
<mml:math id="mml-inline1-1094342013488262"><mml:mn>34</mml:mn></mml:math>
</inline-formula> and <inline-formula id="inline-formula2-1094342013488262">
<mml:math id="mml-inline2-1094342013488262"><mml:mn>35</mml:mn></mml:math>
</inline-formula> seconds of data is integrated into each fully formed image.</p>
<sec id="section4-1094342013488262">
<title>4.1. Fast Fourier transform analysis</title>
<p>In order to illustrate how Aspen works, consider the fast Fourier transform (FFT). The FFT is a common scientific kernel and plays an important role in the image formation phase of SSCP. Fortunately, FFT is also a well-studied algorithm, and tight bounds on the number of operations in an FFT are known.</p>
<p>For an <inline-formula id="inline-formula3-1094342013488262">
<mml:math id="mml-inline3-1094342013488262"><mml:mi>n</mml:mi></mml:math>
</inline-formula>-element Cooley–Tukey style one-dimensional (1D) FFT, the required number of floating point operations is bounded by <inline-formula id="inline-formula4-1094342013488262">
<mml:math id="mml-inline4-1094342013488262"><mml:mrow><mml:mi mathvariant="script">O</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:msub><mml:mrow><mml:mo form="prefix" movablelimits="false">log</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math>
</inline-formula> with a constant factor of 5. Some implementations only require 80% of this upper bound (<xref ref-type="bibr" rid="bibr8-1094342013488262">Johnson and Frigo, 2007</xref>). The number of cache misses has been bounded for any FFT in the I/O complexity literature (on any two-level memory hierarchy which meets the tall cache assumption (<xref ref-type="bibr" rid="bibr5-1094342013488262">Frigo et al., 1999</xref>)) as <inline-formula id="inline-formula5-1094342013488262">
<mml:math id="mml-inline5-1094342013488262"><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">+</mml:mo><mml:msub><mml:mrow><mml:mo form="prefix" movablelimits="false">log</mml:mo></mml:mrow><mml:mi>Z</mml:mi></mml:msub><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math>
</inline-formula>, where <inline-formula id="inline-formula6-1094342013488262">
<mml:math id="mml-inline6-1094342013488262"><mml:mi>L</mml:mi></mml:math>
</inline-formula> is the cache line size in words and <inline-formula id="inline-formula7-1094342013488262">
<mml:math id="mml-inline7-1094342013488262"><mml:mi>Z</mml:mi></mml:math>
</inline-formula> is the cache capacity in words. For sufficiently large <inline-formula id="inline-formula8-1094342013488262">
<mml:math id="mml-inline8-1094342013488262"><mml:mi>n</mml:mi></mml:math>
</inline-formula>, the number of cache misses, <inline-formula id="inline-formula9-1094342013488262">
<mml:math id="mml-inline9-1094342013488262"><mml:msub><mml:mi>N</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math>
</inline-formula>, approaches <inline-formula id="inline-formula10-1094342013488262">
<mml:math id="mml-inline10-1094342013488262"><mml:msub><mml:mi>N</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">=</mml:mo><mml:mi>A</mml:mi><mml:mi>n</mml:mi><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo form="prefix" movablelimits="false">log</mml:mo></mml:mrow><mml:mi>Z</mml:mi></mml:msub><mml:mi>n</mml:mi><mml:mo stretchy="false">,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math>
</inline-formula> where <inline-formula id="inline-formula11-1094342013488262">
<mml:math id="mml-inline11-1094342013488262"><mml:mi>A</mml:mi></mml:math>
</inline-formula> is a constant (<xref ref-type="bibr" rid="bibr4-1094342013488262">Czechowski et al., 2012</xref>; <xref ref-type="bibr" rid="bibr5-1094342013488262">Frigo et al., 1999</xref>) which translates the upper bound to an explicit count. Using the same variable names, these bounds roughly translate to Aspen kernel clauses, as shown in <xref ref-type="fig" rid="fig6-1094342013488262"/>Listing 1.</p>
<fig id="fig6-1094342013488262" position="float">
<label>Listing 1:</label>
<caption>
<p>Aspen kernel for 1D FFT.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig6.tif"/>
</fig>
<p>The listing also highlights the use of Aspen traits to add semantic information to specialize the flops (specifically that they are double precision, complex, and amenable to execution on SIMD FP units) and the reference to the data structure <monospace>fftVolume</monospace>.</p>
<p>The remaining piece of required information is the value for <inline-formula id="inline-formula12-1094342013488262">
<mml:math id="mml-inline12-1094342013488262"><mml:mi>A</mml:mi></mml:math>
</inline-formula>, a constant that arises from the nature of characterizing requirements by asymptotic bounds (e.g. <inline-formula id="inline-formula13-1094342013488262">
<mml:math id="mml-inline13-1094342013488262"><mml:mrow><mml:mi mathvariant="script">O</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math>
</inline-formula>) (<xref ref-type="bibr" rid="bibr5-1094342013488262">Frigo et al., 1999</xref>). Due to the complexity in modeling the memory hierarchy (e.g. from multi-level cache hierarchies, replacement policies) this type of constant is frequently measured using performance counters on an existing implementation of the algorithm to calibrate the model. It is a particularly common approach for characterizing memory traffic, even in the case of much simpler kernels, such as matrix multiplication (<xref ref-type="bibr" rid="bibr6-1094342013488262">Hoefler et al., 2011</xref>).</p>
<p>In order to measure the validity of the model, we compared the predicted and observed runtimes for FFT on several hardware platforms. In particular, performance was measured for FFT using optimized vendor libraries (CUFFT 4.1 and Intel MKL 12.1.2) on a recent GPU (the Tesla M2090, Fermi architecture) and CPU (Xeon X5660, Westmere architecture), shown in <xref ref-type="fig" rid="fig2-1094342013488262">Figure 2</xref>. While the model’s predictions are quite accurate, it should be noted that the complexity of FFT has been extensively studied, and the accuracy of the model can vary with the quality of the known bounds.</p>
<fig id="fig2-1094342013488262" position="float">
<label>Figure 2.</label>
<caption>
<p>The difference in predicted and observed runtime for a 1D complex, double precision FFT on the Westmere CPU and Fermi GPU. Predicted runtime is broken down into the time it takes to complete the flops and bytes (all memory traffic), which, in Aspen, is typically assumed to overlap.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig2.tif"/>
</fig>
</sec>
<sec id="section5-1094342013488262">
<title>4.2. Capacity and bandwidth requirements</title>
<p>We first present a notional framework for implementing the SSCP pipeline that aims to balance computational burden, memory storage, and memory bandwidth. Images from the previous orbit will ultimately be needed for change detection purposes, so either the images themselves or the raw data from which the images can be reformed must be stored. As mentioned previously, many seconds of data will be integrated into each image, although one image is formed per second.</p>
<p>One side effect of this data reuse is that the set of images from an orbit is considerably larger in terms of storage than the raw data from that same orbit. Thus, from a storage perspective, it would be more efficient to store the raw data and re-compute the images when they are needed for comparison. Unfortunately, the computational burden is already considerable and thus we will explore options for storing the images from the prior orbit in order to balance storage and computational requirements. An additional side effect of pulses being reused for <italic>N</italic> images (with <italic>N</italic> approximately <inline-formula id="inline-formula14-1094342013488262">
<mml:math id="mml-inline14-1094342013488262"><mml:mn>35</mml:mn></mml:math>
</inline-formula> in our case) is that most of the computation for a given image will be redundant. Specifically, only 1/<italic>N</italic> of the operations will be unique for each newly formed image.</p>
<p>Therefore, in addition to storing fully formed images from the prior orbit, we reduce computation by storing partially formed images in a ring buffer containing <italic>N</italic> image-sized data structures and form each final image as the sum of <italic>N</italic> such buffers. Unfortunately, the DRAM bandwidth required to accumulate <italic>N</italic> ring buffers per second would be considerable, approximately 1.7 TB/s for the accumulation alone in the scenario described. Thus, we model an additional accumulation buffer optimization to balance DRAM capacity and bandwidth requirements. In particular, we employ two accumulation buffers: one active buffer and one priming buffer. The active buffer contains a fully formed image at time step <inline-formula id="inline-formula15-1094342013488262">
<mml:math id="mml-inline15-1094342013488262"><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math>
</inline-formula>. At time step <inline-formula id="inline-formula16-1094342013488262">
<mml:math id="mml-inline16-1094342013488262"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
</inline-formula>, we subtract the contents of the oldest ring buffer and add the contents of the newest ring buffer to yield the fully formed image for time step <inline-formula id="inline-formula17-1094342013488262">
<mml:math id="mml-inline17-1094342013488262"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>
</inline-formula>.</p>
<p>While a single accumulation buffer is mathematically sufficient, it is possible that error would accumulate over time by continually adding and subtracting pulses due to the finite precision of the floating-point representation. Thus, the separate priming buffer contains only a partially formed image (i.e. it contains contributions from fewer than <inline-formula id="inline-formula18-1094342013488262">
<mml:math id="mml-inline18-1094342013488262"><mml:mi>N</mml:mi></mml:math>
</inline-formula> ring buffers) and at each time step the newest ring buffer is added to the priming buffer. Once the priming buffer contains <inline-formula id="inline-formula19-1094342013488262">
<mml:math id="mml-inline19-1094342013488262"><mml:mi>N</mml:mi></mml:math>
</inline-formula> contributions and is thus fully primed, the priming buffer becomes the active buffer and the active buffer is cleared and becomes the priming buffer. In this fashion, only three image-sized additions and subtractions are needed per time step rather than <inline-formula id="inline-formula20-1094342013488262">
<mml:math id="mml-inline20-1094342013488262"><mml:mi>N</mml:mi></mml:math>
</inline-formula> such operations.</p>
<p>The Aspen excerpt in <xref ref-type="fig" rid="fig7-1094342013488262"/>Listing 2 demonstrates the definition of the required data structures from which storage and bandwidth requirements can be derived. For concreteness, we have assumed a nominal orbit time of <inline-formula id="inline-formula21-1094342013488262">
<mml:math id="mml-inline21-1094342013488262"><mml:mn>15</mml:mn></mml:math>
</inline-formula> minutes.</p>
<fig id="fig7-1094342013488262" position="float">
<label>Listing 2:</label>
<caption>
<p>Annotated Aspen Statements for Data Structures.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig7.tif"/>
</fig>
<p>We have assumed that NVRAM will be used for storing the images from the previous orbit, although any technology with the appropriate capacity and bandwidth could be used. Based on the available DRAM and NVRAM capacities and bandwidths available on our notional nodes, Aspen can produce the chart shown in <xref ref-type="fig" rid="fig3-1094342013488262">Figure 3</xref>, which depicts the number of nodes required from a capacity and bandwidth perspective as application parameters vary. Since one image is added to the <monospace>orbitSet</monospace> each second, the value of <monospace>storedDataPerSecond</monospace> also provides a lower bound on the required NVRAM bandwidth (approximately 24.2 GiB/s/direction in this case).</p>
<fig id="fig3-1094342013488262" position="float">
<label>Figure 3.</label>
<caption>
<p>Requirements for data structures. (a) The size of the image volume (<monospace>orbitSet</monospace>) as a function of the orbit time and image dimensions. (b) The number of nodes required to meet DRAM bandwidth and capacity requirements as specified by the accumulation and ring buffer data structures, respectively, as a function of image width.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig3.tif"/>
</fig>
<p>Listing 2 also contains the description of the image ring buffer and accumulation buffer, which are involved in the processing pipeline and must be stored in DRAM. The accumulation buffers must be traversed each second, so their size is also a lower bound on the required DRAM bandwidth. Similar to the orbit set, Aspen can generate the required number of nodes (based on Echelon DRAM characteristics) to provide the capacity for the ring buffer and the bandwidth to process the accumulation buffer. This relationship is shown in <xref ref-type="fig" rid="fig3-1094342013488262">Figure 3</xref> as a function of the image width in pixels.</p>
</sec>
<sec id="section6-1094342013488262">
<title>4.3. Impact of the image tiling factor</title>
<p>One of the more sophisticated performance phenomena for the SAR image formation process is the relationship between tiling factor, <inline-formula id="inline-formula22-1094342013488262">
<mml:math id="mml-inline22-1094342013488262"><mml:mi>t</mml:mi><mml:mi>f</mml:mi></mml:math>
</inline-formula>, and performance. In particular, it is known that image formation’s two major kernels, DS and BP, favor different tiling factors. As tile factor increases, BP loading decreases, but DS loading increases.</p>
<p>DS is dominated by <inline-formula id="inline-formula23-1094342013488262">
<mml:math id="mml-inline23-1094342013488262"><mml:mi>t</mml:mi><mml:msup><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math>
</inline-formula> FFTs across each pulse while BP’s workload is influenced by a factor of <inline-formula id="inline-formula24-1094342013488262">
<mml:math id="mml-inline24-1094342013488262"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mi>f</mml:mi></mml:math>
</inline-formula>. An Aspen model was used to determine the optimal balance of <inline-formula id="inline-formula25-1094342013488262">
<mml:math id="mml-inline25-1094342013488262"><mml:mi>t</mml:mi><mml:mi>f</mml:mi></mml:math>
</inline-formula> for these kernels. This model describes the memory and FLOP operations in these two kernels as a function of the program parameters. The optimal setting is determined by finding the minimal operation count over a range of possible <inline-formula id="inline-formula26-1094342013488262">
<mml:math id="mml-inline26-1094342013488262"><mml:mi>t</mml:mi><mml:mi>f</mml:mi></mml:math>
</inline-formula> values.</p>
<p>Plotting the requirements for each kernel provides a clear picture of this tradeoff, shown in <xref ref-type="fig" rid="fig4-1094342013488262">Figure 4</xref>. Minimizing the total operation count for flops and loads/stores results in minima at tiling factors of 22 and 21, respectively. It is also worth noting that the <monospace>sincInterp</monospace> kernel contributes to workload at very small tiling factors, but is negligible in the range in <xref ref-type="fig" rid="fig4-1094342013488262">Figure 4</xref>. Since the arithmetic intensity of the image formation kernels indicates they will most likely be memory-bound (BP has the highest intensity, at 2.28 flops per byte), 21 is the optimal tiling factor.</p>
<fig id="fig4-1094342013488262" position="float">
<label>Figure 4.</label>
<caption>
<p>The tradeoff in resource requirements between BP and other image formation kernels as a function of the tiling factors. At small factors, BP is prohibitively expensive, while at larger factors, the FFT begins to dominate costs. Note that !<monospace>tf</monospace>! is always constrained to be an integer via a floor operation, resulting in curves that are not smooth. A marker has been placed at the minima for floating point workload and total memory traffic at 22 and 21, respectively.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig4.tif"/>
</fig>
<p>Two potential approaches for reducing the floating point workload include the implementation of a split-radix FFT, which reduces total FFT flop count by approximately 20% (<xref ref-type="bibr" rid="bibr8-1094342013488262">Johnson and Frigo, 2007</xref>) and incorporating faster, but potentially less accurate, intrinsics or approximations for the sine, cosine, and square root functions. While the first optimization involves altering the FFT model, the intrinsic or approximation operations involve modifying Aspen traits, which add specificity and rich semantics to standard algorithmic requirements. For instance, in the <monospace>phaseShift</monospace> kernel (a component of DS shown in <xref ref-type="fig" rid="fig8-1094342013488262"/>Listing 3), flops are specialized with traits like <monospace>simd, sqrt</monospace>, or <monospace>complex</monospace>.</p>
<fig id="fig8-1094342013488262" position="float">
<label>Listing 3:</label>
<caption>
<p>Aspen Statements for the phaseShift kernel (part of Image Formation).</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig8.tif"/>
</fig>
<p>The effect of these optimizations is shown in <xref ref-type="fig" rid="fig5-1094342013488262">Figure 5</xref>. The split-radix FFT, a four flop implementation of square root and an intrinsic for <italic>sincos</italic> (which reduces its cost to 18 scalar flops) result in an overall 19% decrease in image formation FP load. Most of the reduction comes from the optimized FFT. However, the decrease in floating point workload may not necessarily correspond to an increase in performance. The low arithmetic intensity of the kernels indicates they will be memory bound rather than compute bound. Hence, <monospace>tf</monospace> should be 21 (the factor that minimizes memory traffic) rather than 22 (the factor that minimizes total floating point workload).</p>
<fig id="fig5-1094342013488262" position="float">
<label>Figure 5.</label>
<caption>
<p>The reduction in floating point workload based on three optimizations, a split-radix FFT, faster square root operation, and a <inline-formula id="inline-formula27-1094342013488262">
<mml:math id="mml-inline27-1094342013488262"><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:math>
</inline-formula> intrinsic. Total operations reduced by 19%.</p>
</caption>
<graphic xlink:href="10.1177_1094342013488262-fig5.tif"/>
</fig>
</sec>
</sec>
<sec id="section7-1094342013488262">
<title>5. Conclusions</title>
<p>The Aspen performance model facilitated the exploration of tradeoffs between the capabilities of a notional Echelon node design and the algorithmic options inherent in the SSCP. Aspen also provided insight into what SSCP data structures are feasible given the constraints on the number of nodes. Three nodes were sufficient for DRAM storage of the 847.2 GiB SSCP <monospace>ringBuffer</monospace>, and, as image size increases, SSCP tends to be more constrained by capacity than bandwidth. Similarly, the 21.3 TiB <monospace>orbitSet</monospace> requires 6 nodes with 4 TiB NVRAM.</p>
<p>The image formation tiling factor strongly influences total workload, and factors of 21 and 22 are optimal for minimizing memory traffic and floating point workload, respectively. Based on a 39.4 TF total image formation workload and a sustained 50% of peak performance, roughly three nodes will be required. Aggressive floating point optimizations, including a split-radix FFT, reduce this workload to 31.7 TF, but are unlikely to substantially reduce node count. Furthermore, the low arithmetic intensity of the image formation kernels suggests that future optimizations minimizing data movement may be more beneficial than those that reduce the floating point workload.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This research is sponsored by the Office of Advanced Scientific Computing Research in the U.S. Department of Energy and DARPA (contract number HR0011-10-9-0008). The paper has been authored by Oak Ridge National Laboratory, which is managed by UT-Battelle, LLC under Contract DE-AC05- 00OR22725 to the U.S. Government. Accordingly, the U.S. Government retains a non-exclusive, royalty-free license to publish or reproduce the published form of this contribution, or allow others to do so, for U.S. Government purposes.</p>
</ack>
<notes>
<title>Note</title>
<fn-group>
<fn fn-type="other" id="fn1-1094342013488262">
<label>1</label>
<p>For more details on the Echelon architecture, including diagrams and design rationale, we refer the reader to the overview by <xref ref-type="bibr" rid="bibr10-1094342013488262">Keckler et al. (2011</xref>).</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Alexandrov</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Ionescu</surname>
<given-names>MF</given-names>
</name>
<name>
<surname>Schauser</surname>
<given-names>KE</given-names>
</name>
<name>
<surname>Scheiman</surname>
<given-names>C</given-names>
</name>
</person-group> (<year>1995</year>) <article-title>LogGP: incorporating long messages into the LogP model</article-title>. In: <source>Proceedings of the Seventh Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA ’95)</source>, pp. <fpage>95</fpage>–<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr2-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Campbell</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Cook</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Mulvaney</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>A streaming sensor challenge problem for ubiquitous high performance computing</article-title>. In: <source>Proceedings of Fifteenth Annual Workshop on High Performance Embedded Computing (HPEC ’11)</source>.</citation>
</ref>
<ref id="bibr3-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Culler</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Karp</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Patterson</surname>
<given-names>D</given-names>
</name>
<etal/>
</person-group>. (<year>1993</year>) <article-title>LogP: Towards a realistic model of parallel computation</article-title>. In: <source>Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP ’93)</source>, pp. <fpage>1</fpage>–<lpage>12</lpage>.</citation>
</ref>
<ref id="bibr4-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Czechowski</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Battaglino</surname>
<given-names>C</given-names>
</name>
<name>
<surname>McClanahan</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Iyer</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Yeung</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Vuduc</surname>
<given-names>R</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>On the communication complexity of 3D FFT and its implications for exascale</article-title>. In: <source>Proceedings of the 2012 International Conference on Supercomputing (ICS 2012)</source>.</citation>
</ref>
<ref id="bibr5-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Frigo</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Leiserson</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Prokop</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Ramachandran</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>1999</year>) <article-title>Cache-oblivious algorithms</article-title>. In: <source>40th Annual Symposium on Foundations of Computer Science</source>, pp. <fpage>285</fpage>–<lpage>297</lpage>.</citation>
</ref>
<ref id="bibr6-1094342013488262">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hoefler</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Gropp</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Kramer</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Snir</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Performance modeling for systematic performance tuning</article-title>. In: <source>State of the Practice Reports (SC ’11)</source>, pp. 6:<fpage>1</fpage>–<lpage>6</lpage>:12.</citation>
</ref>
<ref id="bibr7-1094342013488262">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Janssen</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Adalsteinsson</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Kenny</surname>
<given-names>JP</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Using simulation to design extremescale applications and architectures: Programming model exploration</article-title>. <source>SIGMETRICS Performance Evaluation Review</source> <volume>38</volume>(<issue>4</issue>): <fpage>4</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr8-1094342013488262">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Johnson</surname>
<given-names>SG</given-names>
</name>
<name>
<surname>Frigo</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>A modified split-radix FFT with fewer arithmetic operations</article-title>. <source>IEEE Transactions on Signal Processing</source> <volume>55</volume>(<issue>1</issue>): <fpage>111</fpage>–<lpage>119</lpage>.</citation>
</ref>
<ref id="bibr9-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Keckler</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>GPU computing and the road to extreme-scale parallel systems</article-title>. In: <source>IEEE International Symposium on Workload Characterization (IISWC ’11)</source>.</citation>
</ref>
<ref id="bibr10-1094342013488262">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Keckler</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Dally</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Khailany</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Garland</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Glasco</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>GPUs and the future of parallel computing</article-title>. <source>IEEE Micro</source> <volume>31</volume>(<issue>5</issue>): <fpage>7</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr11-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Park</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Tang</surname>
<given-names>PTP</given-names>
</name>
<name>
<surname>Smelyanskiy</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Benson</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>Efficient backprojection-based synthetic aperture radar computation with many-core processors</article-title>. In: <source>Proceedings of the ACM International Conference for High Performance Computing, Networking, Storage and Analysis (SC ’12)</source>.</citation>
</ref>
<ref id="bibr12-1094342013488262">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rodrigues</surname>
<given-names>AF</given-names>
</name>
<name>
<surname>Hemmert</surname>
<given-names>KS</given-names>
</name>
<name>
<surname>Barrett</surname>
<given-names>BW</given-names>
</name>
<etal/>
</person-group>. (<year>2011</year>) <article-title>The structural simulation toolkit</article-title>. <source>SIGMETRICS Performance Evaluation Review</source> <volume>38</volume>(<issue>4</issue>): <fpage>37</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr13-1094342013488262">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Spafford</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Vetter</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>Aspen: a domain specific language for performance modeling</article-title>. In: <source>Proceedings of the ACM International Conference for High Performance Computing, Networking, Storage and Analysis (SC ’12)</source>.</citation>
</ref>
<ref id="bibr14-1094342013488262">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Valiant</surname>
<given-names>LG</given-names>
</name>
</person-group> (<year>1990</year>) <article-title>A bridging model for parallel computation</article-title>. <source>Communications of the ACM</source> <volume>33</volume>(<issue>8</issue>): <fpage>103</fpage>–<lpage>111</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>