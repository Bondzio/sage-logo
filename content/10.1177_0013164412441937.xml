<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPM</journal-id>
<journal-id journal-id-type="hwp">spepm</journal-id>
<journal-title>Educational and Psychological Measurement</journal-title>
<issn pub-type="ppub">0013-1644</issn>
<issn pub-type="epub">1552-3888</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0013164412441937</article-id>
<article-id pub-id-type="publisher-id">10.1177_0013164412441937</article-id>
<title-group>
<article-title>Treatment of Not-Administered Items on Individually Administered Intelligence Tests</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>He</surname><given-names>Wei</given-names></name>
<xref ref-type="aff" rid="aff1-0013164412441937">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Wolfe</surname><given-names>Edward W.</given-names></name>
<xref ref-type="aff" rid="aff2-0013164412441937">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0013164412441937"><label>1</label>Northwest Evaluation Association, Portland, OR, USA</aff>
<aff id="aff2-0013164412441937"><label>2</label>Pearson, Iowa City, IA, USA</aff>
<author-notes>
<corresp id="corresp1-0013164412441937">Wei He, Northwest Evaluation Association (NWEA), 121 NW Everett Street, Portland, OR 97035, USA Email: <email>wei.he@nwea.org</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>72</volume>
<issue>5</issue>
<fpage>808</fpage>
<lpage>826</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>In administration of individually administered intelligence tests, items are commonly presented in a sequence of increasing difficulty, and test administration is terminated after a predetermined number of incorrect answers. This practice produces stochastically censored data, a form of nonignorable missing data. By manipulating four factors (i.e., treatment of nonresponses, ability estimation method, test length, and stopping rule), this study investigated how accurately ability parameters are recovered under these conditions. The results suggest that there might be a complex interaction among these manipulated factors with respect to parameter estimation bias. The worst estimates occur when nonadministered items are treated as incorrect. Treating nonadministered items as not presented or fractionally correct appears to produce more accurate ability estimates. Among the ability estimation methods examined in this study, the Expected A Posterior and Maximum A posteriori methods tend to produce less estimation error in the presence of censored data. The differences in missing data treatment methods tend to have greater impact on ability estimate under maximum likelihood estimation than Bayesian methods.</p>
</abstract>
<kwd-group>
<kwd>ability estimation</kwd>
<kwd>individually administered intelligence test</kwd>
<kwd>item response theory</kwd>
<kwd>missing data</kwd>
<kwd>nonresponses</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Items on individually administered intelligence tests are commonly presented in a sequence of increasing difficulty. To avoid examinee frustration and minimize the cost and time of individualized testing, the administration of these tests typically calls for the examiner to invoke a discontinuation rule; the test is discontinued after the examinee gives a predetermined number of consecutive incorrect responses. The Wechsler Adult Intelligence Test (WAIS-IV; <xref ref-type="bibr" rid="bibr21-0013164412441937">Wechsler, 2008</xref>) and the Kaufman Assessment Battery for Children (KABC-II; <xref ref-type="bibr" rid="bibr11-0013164412441937">Kaufman &amp; Kaufman, 2004</xref>) are examples of tests using these rules. Nonadministered items are then treated as incorrect (i.e., assigned a score of zero), as are items that are administered beyond the discontinuation rule. For example, the KABC-II manual states that
<disp-quote>
<p>each subtest has a rule for when to stop administering items. . . . For most subtests the rule is a specified number of consecutive item scores of 0. . . . Do not give credit for any items that have been administered beyond the stopping point indicated by the discontinue rule. (<xref ref-type="bibr" rid="bibr11-0013164412441937">Kaufman &amp; Kaufman, 2004</xref>, p. 22)</p>
</disp-quote></p>
<p>Several authors have explained the conditions under which missing data are ignorable with respect to direct likelihood or Bayesian parameter estimation procedures (<xref ref-type="bibr" rid="bibr12-0013164412441937">Little &amp; Rubin, 1987</xref>; <xref ref-type="bibr" rid="bibr15-0013164412441937">Mislevy &amp; Wu, 1988</xref>, <xref ref-type="bibr" rid="bibr16-0013164412441937">1996</xref>; <xref ref-type="bibr" rid="bibr19-0013164412441937">Rubin, 1987</xref>). Adopting the language used by these authors, data from individually administered intelligence tests constitute stochastically censored data, a form of nonignorable missing data, indicating that parameter estimates obtained under these conditions may be biased. <xref ref-type="bibr" rid="bibr14-0013164412441937">Ludlow and O’Leary (1999)</xref> identified several strategies for scoring data containing omitted and/or not-reached items with the Rasch model—primarily (a) treat them as having not been administered, (b) treat them as incorrect responses (the practice adopted by intelligence tests), and (c) a two-phase item response analysis in which item parameters are estimated with only valid response data and then ability parameters are estimated, anchoring item locations on the values from the first phase of analysis. Ludlow and O’Leary applied these scoring strategies to a single data set and found that the strategies produce different estimates of examinee abilities and item difficulties. Because their analyses were based on real data, they were unable to determine which of the results were the most accurate.</p>
<p>Several approaches to scoring omitted item response data have been evaluated using Monte Carlo studies (<xref ref-type="bibr" rid="bibr8-0013164412441937">DeAyala, 2003</xref>, <xref ref-type="bibr" rid="bibr9-0013164412441937">2006</xref>; <xref ref-type="bibr" rid="bibr10-0013164412441937">DeAyala, Plake, &amp; Impara, 2001</xref>). The omitted response data in these studies were regarded as a form of nonignorable missing data because they occurred when a respondent was presented an item, had ample time to answer the item, but decided not to respond. By modeling the dichotomous response data and treating the omits as incorrect and ignorable, <xref ref-type="bibr" rid="bibr10-0013164412441937">DeAyala et al. (2001)</xref> determined that the worst approach to scoring these data is to treat omitted responses as being incorrect and that substitution of 0.5 for omitted responses produces ability estimates that are almost as accurate as those using complete data when the Expected A Posteriori (EAP) parameter estimation method is used. The results of <xref ref-type="bibr" rid="bibr8-0013164412441937">DeAyala (2003</xref>, <xref ref-type="bibr" rid="bibr9-0013164412441937">2006</xref>) suggest that omits should not be ignored or treated as missing in contexts involving nonignorable missing data. When estimating a respondent’s ability using data generated from <xref ref-type="bibr" rid="bibr1-0013164412441937">Andrich’s rating scale model (1978)</xref>, hot-decking imputation method performs the best of methods examined under maximum likelihood estimation (MLE) method (<xref ref-type="bibr" rid="bibr8-0013164412441937">DeAyala, 2003</xref>). However, in the case of partial credit data, the most favorable results were obtained using midpoint and likelihood approaches under EAP parameter estimation method (<xref ref-type="bibr" rid="bibr9-0013164412441937">DeAyala, 2006</xref>).</p>
<p>Simulating data with omits under a missing completely at random (MCAR) design, <xref ref-type="bibr" rid="bibr23-0013164412441937">Zhang and Walker (2008)</xref> investigated the impact of missing data on person-model fit and person trait estimation. By means of a crossed factorial experimental design involving three test lengths, three sample sizes, and four missing data treatment methods (i.e., pairwise deletion, treating missing responses as incorrect, hotdeck imputation, and model-based imputation), their results did not support the practice of recoding missing responses as incorrect. Rather, their results suggested that the best way to recover person ability parameter is to treat items with missing responses as not-administered under marginal MLE method implemented by the MULTILOG computer program.</p>
<p>Similarly, <xref ref-type="bibr" rid="bibr18-0013164412441937">Rose, von Davier, and Xu (2010)</xref> suggested that scoring nonignorable missing data in large-scale surveys scaled with item response theory (IRT) models as incorrect is the least desirable option. Their study also suggested that, when a Rasch model is adopted in the presence of a moderate proportion of missing data (30%), treating missing responses as not-administered under EAP can produce reasonably accurate person and item parameter estimates. In the case of a high proportion of missing data (50%), however, model-based approaches that use multidimensional IRT model or multidimensional multiple-group IRT models by incorporating a variable depicting response type seems to provide a more appropriate way to account for nonignorable missing data.</p>
<p>However, as Zhang and Walker acknowledged, the greatest limitation of their study was that the missing mechanism was assumed to be MCAR and performance of the four missing data treatment methods might be different if the missing data mechanism was not MCAR. It is also worth noting that both of the studies (<xref ref-type="bibr" rid="bibr18-0013164412441937">Rose et al., 2010</xref>; <xref ref-type="bibr" rid="bibr23-0013164412441937">Zhang &amp; Walker, 2008</xref>) considered only one trait estimation method: Zhang and Walker used marginal MLE using the expectation-maximization algorithm implemented by the MULTILOG, whereas Rose et al. used the EAP method implemented in the ConQuest software. As different ability estimation methods have their own strengths and weaknesses, practical guidelines provided by these studies may be limited. Moreover, running only one single simulation trial in the study by <xref ref-type="bibr" rid="bibr18-0013164412441937">Rose et al. (2010)</xref>, as the researchers acknowledged, is not sufficient for making a decision about which missing response treatment method to use.</p>
<p>Hence, a study is needed that investigates which of the procedures for handling missing data are most appropriate for handling stochastic censored data within an IRT framework, such as that observed in many individually administered intelligence tests. As such, we conducted a Monte Carlo simulation study to compare parameter recovery of several methods for estimating examinee ability under the conditions employed in individually administered intelligence tests. In addition, we also analyzed empirical data following the same procedures used in the simulation study. Specifically, in the simulation study we examined the impact of the manner in which not-administered items were treated on the bias, error, and fidelity of examinee parameter estimates, while attending to the number of items on the test, the number of consecutive incorrect answers on which the examination was discontinued, and the parameter estimation method used when scoring data with a latent trait model. The simulation study was designed to produce data comparable to a particular instrument in which test administration was discontinued when the examinee answered four consecutive items incorrectly. This particular instrument did not employ a basal rule, as is sometimes used in individually administered intelligence tests, which would create missing data both early and late in the test administration process. Rather, we investigated a situation in which data were only missing on items that were generally too difficult for a particular examinee.</p>
<p>Prior studies suggested that the <italic>treatment of nonresponses</italic> and <italic>ability estimation method</italic> should both influence the accuracy of the parameter estimates. Similarly, one would expect the <italic>test length</italic> and the adopted <italic>stopping rule</italic> (i.e., the number of consecutive incorrect responses required before examination administration is terminated) to influence the accuracy of parameter estimates. What is more, it is also expected that the magnitude of any one of these factors may be likely to depend on its interaction with other factors.</p>
<sec id="section1-0013164412441937" sec-type="methods">
<title>Method</title>
<sec id="section2-0013164412441937">
<title>Simulation Study</title>
<p>Four factors were manipulated in this study: (a) <italic>test lengths</italic> of 40 and 60 items, each being “presented” in sequence of increasing difficulty as is typical of individually administered intelligence tests; (b) <italic>ability estimation method</italic> includes MLE, Expected A Posteriori (Bayes) Estimation, and Maximum A Posteriori (Bayes) Estimation (MAP); (c) <italic>stopping rule</italic> includes 4 or 6 consecutive incorrect responses; and (d) <italic>treatment of nonresponses</italic> includes scoring all nonresponses as <italic>incorrect</italic>, treating all nonresponses as <italic>not presented</italic>, substituting not-administered items with <italic>randomly correct</italic> responses, and <italic>fractionally correct</italic> responses, forming a 2 × 3 × 2 × 4 crossed factorial design. Randomly correct responses were generated by scoring not-administered items as having been “correct” when a Uniform (0, 1) random variable that was generated for each not-administered response was greater or equal to 0.5—otherwise, the not-administered item was scored as incorrect. The approach to substituting the nonresponses with fractionally correct responses was based on <xref ref-type="bibr" rid="bibr13-0013164412441937">Lord’s strategy (1974)</xref> of assigning the not-administered response the reciprocal of the number of item options on a multiple choice item, and in our study this approach was implemented by BILOG-MG (<xref ref-type="bibr" rid="bibr24-0013164412441937">Zimowski, Muraki, Mislevy, &amp; Bock, 1996</xref>).</p>
<sec id="section3-0013164412441937">
<title>Data generation</title>
<p>Routines were written for SAS and designed to produce data according to a three-parameter logistic item response theory (3PL IRT) model. Item parameter distributions followed those used in a study conducted by <xref ref-type="bibr" rid="bibr17-0013164412441937">Oshima (1994)</xref>. Item slope parameters were randomly selected from a Lognormal (1.13, 0.63) distribution. Item location parameters were randomly selected from a Normal (0, 1) distribution, and lower asymptote parameters were randomly selected from a Normal (0.25, 0.05) distribution. Examinee ability parameters were randomly generated for 1,000 examinees from a Normal (0, 1) distribution. For each simulated examinee, the probability of a correct response was calculated based on the 3PL IRT model given the generating parameters and that probability was compared with a random Uniform (0, 1) variable and converted to a correct/incorrect (1/0) score. Response strings were then converted to each of the <italic>treatment of response</italic> methods for each <italic>stopping rule</italic>. Parameter estimation was carried out using BILOG-MG using the default specifications except as required for treatment of response and parameter estimation method. Note that NALT = 4 was specified when scoring the not-administered items fractionally correct. In other words, not-administered responses were assigned a score of 0.25. Fifty replications were conducted for each condition.</p>
<p>The dependent variables focused on how well ability parameters were recovered under these conditions, and they included the following: (a) <italic>bias</italic>, (b) <italic>root mean squared error</italic> (RMSE), and (c) <italic>fidelity</italic> (i.e., correlation between estimated and generating examinee ability parameters). Bias and RMSE for each replication were calculated as follows:</p>
<p><disp-formula id="disp-formula1-0013164412441937">
<mml:math display="block" id="math1-0013164412441937">
<mml:mrow>
<mml:mtext>Bias</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>N</mml:mi>
</mml:mfrac>
<mml:mstyle displaystyle="true">
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>θ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mstyle>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0013164412441937" xlink:href="10.1177_0013164412441937-eq1.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula2-0013164412441937">
<mml:math display="block" id="math2-0013164412441937">
<mml:mrow>
<mml:mtext>RMSE</mml:mtext>
<mml:mo>=</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>N</mml:mi>
</mml:mfrac>
<mml:mstyle displaystyle="true">
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>θ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:msqrt>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0013164412441937" xlink:href="10.1177_0013164412441937-eq2.tif"/>
</disp-formula></p>
<p>where <italic>N</italic> is the total number of the examinees (i.e., 1,000) in each replication and <inline-formula id="inline-formula1-0013164412441937">
<mml:math display="inline" id="math3-0013164412441937">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and θ<sub><italic>i</italic></sub> are the estimated and true ability of the <italic>i</italic>th examinee in each replication, respectively.</p>
</sec>
<sec id="section4-0013164412441937">
<title>Simulation analysis</title>
<p>For the simulated data, the manner in which each independent variable affected the precision of the ability estimates was investigated in two stages. First, the dependent variables were computed for each replication within each cell, and the means and standard deviations (i.e., the standard error for each dependent variable) were computed across the 50 replications within each cell. Second, an analysis of variance (ANOVA) test was performed for each dependent variable to investigate both main and interaction effects, and the magnitudes of the effect sizes were estimated using Omega square (ω<sup>2</sup>). Following <xref ref-type="bibr" rid="bibr7-0013164412441937">Cohen’s guideline (1988)</xref>, values of ω<sup>2</sup> greater than .15 were defined to be “large” effects, values between .06 and .15 were defined to be “medium” in size, and the remaining values were defined to be “small.”</p>
</sec>
</sec>
<sec id="section5-0013164412441937">
<title>Empirical Data</title>
<p>The empirical data set came from an international study of preschool children (<xref ref-type="bibr" rid="bibr6-0013164412441937">Claxton, 2007</xref>; <xref ref-type="bibr" rid="bibr22-0013164412441937">Wolfe &amp; Manalo, 2007</xref>). In that study, 1,419 four-year-old children were administered a test of cognitive development status that consisted of 56 items requiring the child to perform a variety of cognitive functioning tasks, typically by pointing to the “correct” picture or object when being presented with a series of options (typically four). A test was terminated when four consecutive items were answered incorrectly. Items on this test were adapted from three existing published measures of cognitive development (<xref ref-type="bibr" rid="bibr2-0013164412441937">Bate &amp; Smith, 1978</xref>; <xref ref-type="bibr" rid="bibr3-0013164412441937">Boehm, 1969</xref>; <xref ref-type="bibr" rid="bibr5-0013164412441937">Bracken, 1984</xref>). <xref ref-type="table" rid="table1-0013164412441937">Table 1</xref> presents the number and percentage of examinees and items with different levels of missing data in the empirical data set. With respect to missing responses on examinees’ side, for example, only 233 (16%) out of 1,419 examinees were administered the full-length test and 363 (25%) examinees were administered their tests with at least 60% omits, meaning their tests contained less than 22 items. With respect to missing responses on items’ side, only 4 (7%) out 56 items did not have any missing responses.</p>
<table-wrap id="table1-0013164412441937" position="float">
<label>Table 1.</label>
<caption><p>Number and Percentage of Examinees and Items by Proportion of Missing Responses</p></caption>
<graphic alternate-form-of="table1-0013164412441937" xlink:href="10.1177_0013164412441937-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Proportion of Missing Responses</th>
<th align="center">0</th>
<th align="center">(0, .2)</th>
<th align="center">[.2, .4)</th>
<th align="center">[.4, .6)</th>
<th align="center">[.6, .8)</th>
<th align="center">[.8, 1]</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>Number of examinees</td>
<td>233</td>
<td>584</td>
<td>147</td>
<td>92</td>
<td>331</td>
<td>32</td>
<td>1419</td>
</tr>
<tr>
<td>Percentage of examinees</td>
<td>16</td>
<td>41</td>
<td>10</td>
<td>6</td>
<td>23</td>
<td>2</td>
<td>100</td>
</tr>
<tr>
<td>Number of items</td>
<td>4</td>
<td>11</td>
<td>29</td>
<td>4</td>
<td>6</td>
<td>2</td>
<td>56</td>
</tr>
<tr>
<td>Percentage of items</td>
<td>7</td>
<td>20</td>
<td>52</td>
<td>7</td>
<td>11</td>
<td>4</td>
<td>100</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0013164412441937">
<p><italic>Note</italic>. “(“ indicates an open interval; “[“ or “]” indicates a close interval.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Empirical data were also calibrated for person traits with BILOG-MG by treating missing responses with the four missing data treatment techniques and three parameter estimation methods using the default specifications except as described in the simulation description. Note that when the missing data treatment technique was specified as randomly correct, those omits were first imputed with either a 0 or 1 based on the method described in the <italic>Data Generation</italic> section. The imputed data was then submitted to BILOG-MG for calibration subject to different ability estimation methods. The combination of four missing data treatment techniques and three parameter estimation methods should have yielded 12 sets of ability estimates. However, due to the problem of nonconvergence when missing data were treated as randomly correct, only nine sets of ability estimates were obtained for further analysis.</p>
</sec>
</sec>
<sec id="section6-0013164412441937" sec-type="results">
<title>Results</title>
<sec id="section7-0013164412441937">
<title>Simulation Study</title>
<p><xref ref-type="table" rid="table2-0013164412441937">Table 2</xref> provides descriptive statistics for two simulated tests along with an indication of the “distances” between the difficulties of consecutive items (denoted by Δ<italic>b</italic>). In comparison, the shorter test was more difficult but had less variation of item difficulty than the longer one with regard to item difficulty parameters. The average distances between item difficulties for two tests were very close to each other with those for the longer test exhibiting slightly higher variation. <xref ref-type="fig" rid="fig1-0013164412441937">Figure 1</xref> shows how the two item difficulty distributions are aligned with the corresponding ability distribution. This figure reveals that a large proportion of the items had difficulties targeted to the middle of the examinee distribution whereas a small proportion of the items were targeted to the tails of the ability distribution.</p>
<table-wrap id="table2-0013164412441937" position="float">
<label>Table 2.</label>
<caption><p>Descriptive Statistics for Two Simulated Tests</p></caption>
<graphic alternate-form-of="table2-0013164412441937" xlink:href="10.1177_0013164412441937-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Test Length = 40<hr/></th>
<th align="center" colspan="4">Test Length = 60<hr/></th>
</tr>
<tr>
<th/>
<th align="center"><italic>a</italic></th>
<th align="center"><italic>b</italic></th>
<th align="center">Δ<italic>b</italic></th>
<th align="center"><italic>c</italic></th>
<th align="center"><italic>a</italic></th>
<th align="center"><italic>b</italic></th>
<th align="center">Δ<italic>b</italic></th>
<th align="center"><italic>c</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Mean</td>
<td>1.028</td>
<td>0.151</td>
<td>0.088</td>
<td>0.258</td>
<td>1.076</td>
<td>−0.154</td>
<td>0.085</td>
<td>0.253</td>
</tr>
<tr>
<td>Standard</td>
<td>0.483</td>
<td>0.955</td>
<td>0.082</td>
<td>0.048</td>
<td>0.535</td>
<td>1.071</td>
<td>0.121</td>
<td>0.044</td>
</tr>
<tr>
<td>Minimum</td>
<td>0.330</td>
<td>−1.505</td>
<td>0.000</td>
<td>0.149</td>
<td>0.276</td>
<td>−2.818</td>
<td>0.000</td>
<td>0.160</td>
</tr>
<tr>
<td>Maximum</td>
<td>2.009</td>
<td>1.914</td>
<td>0.437</td>
<td>0.357</td>
<td>2.522</td>
<td>2.213</td>
<td>0.495</td>
<td>0.346</td>
</tr>
<tr>
<td>Median</td>
<td>0.910</td>
<td>0.280</td>
<td>0.072</td>
<td>0.266</td>
<td>1.027</td>
<td>−0.184</td>
<td>0.038</td>
<td>0.258</td>
</tr>
</tbody>
</table>
</table-wrap>
<fig id="fig1-0013164412441937" position="float">
<label>Figure 1.</label>
<caption><p>An example of overlay of ability distribution on item difficulty distributions</p></caption>
<graphic xlink:href="10.1177_0013164412441937-fig1.tif"/>
</fig>
<p><xref ref-type="table" rid="table3-0013164412441937">Table 3</xref> summarizes the results of the ANOVAs for each dependent variable in this simulation study. Normality of each dependent variable was first checked via Q-Q plot and three statistical analyses including Kolmogorov–Smirnov, Cramer–von Mises, and Anderson–Darling as implemented in SAS. The results confirmed the normality of bias but not RMSE and Fidelity. Transformation of these two nonnormal variables was then conducted using natural logarithm and Fisher’s <italic>z</italic> transformation methods, respectively, which caused no significant changes to the ANOVA results.</p>
<table-wrap id="table3-0013164412441937" position="float">
<label>Table 3.</label>
<caption><p>ANOVA Results of Bias, RMSE, and Fidelity</p></caption>
<graphic alternate-form-of="table3-0013164412441937" xlink:href="10.1177_0013164412441937-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="5">Bias<hr/></th>
<th align="center" colspan="4">RMSE<hr/></th>
<th align="center" colspan="4">Fidelity<hr/></th>
</tr>
<tr>
<th/>
<th align="center"><italic>df</italic></th>
<th align="center"><italic>SS</italic></th>
<th align="center"><italic>F</italic></th>
<th align="center"><italic>p</italic></th>
<th align="center">ω<sup>2</sup></th>
<th align="center"><italic>SS</italic></th>
<th align="center"><italic>F</italic></th>
<th align="center"><italic>p</italic></th>
<th align="center">ω<sup>2</sup></th>
<th align="center"><italic>SS</italic></th>
<th align="center"><italic>F</italic></th>
<th align="center"><italic>p</italic></th>
<th align="center">ω<sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="14">Main effect</td>
</tr>
<tr>
<td> TL</td>
<td>1</td>
<td>0.003</td>
<td>3.409</td>
<td>.065</td>
<td>0.000</td>
<td>5.569</td>
<td>18656.95</td>
<td>.000</td>
<td>0.212</td>
<td>1.148</td>
<td>12586.59</td>
<td>.000</td>
<td>0.193</td>
</tr>
<tr>
<td> AE</td>
<td>2</td>
<td>1.059</td>
<td>515.95</td>
<td>.000</td>
<td>0.249</td>
<td>5.696</td>
<td>9541.178</td>
<td>.000</td>
<td>0.217</td>
<td>0.116</td>
<td>633.681</td>
<td>.000</td>
<td>0.019</td>
</tr>
<tr>
<td> SR</td>
<td>1</td>
<td>0.001</td>
<td>0.786</td>
<td>.375</td>
<td>0.000</td>
<td>3.839</td>
<td>12860.21</td>
<td>.000</td>
<td>0.146</td>
<td>1.543</td>
<td>16926.11</td>
<td>.000</td>
<td>0.259</td>
</tr>
<tr>
<td> TR</td>
<td>3</td>
<td>0.138</td>
<td>44.755</td>
<td>.000</td>
<td>0.032</td>
<td>7.248</td>
<td>8092.869</td>
<td>.000</td>
<td>0.276</td>
<td>2.398</td>
<td>8766.864</td>
<td>.000</td>
<td>0.403</td>
</tr>
<tr>
<td colspan="14">Interaction effect</td>
</tr>
<tr>
<td> TL* SR</td>
<td>1</td>
<td>0.001</td>
<td>1.089</td>
<td>.297</td>
<td>0.000</td>
<td>0.049</td>
<td>165.616</td>
<td>.000</td>
<td>0.002</td>
<td>0.000</td>
<td>0.417</td>
<td>.126</td>
<td>0.000</td>
</tr>
<tr>
<td> TL* AE</td>
<td>2</td>
<td>0.158</td>
<td>76.811</td>
<td>.000</td>
<td>0.037</td>
<td>0.808</td>
<td>1352.624</td>
<td>.000</td>
<td>0.031</td>
<td>0.024</td>
<td>133.604</td>
<td>.000</td>
<td>0.004</td>
</tr>
<tr>
<td> TL* TR</td>
<td>3</td>
<td>0.015</td>
<td>5.010</td>
<td>.002</td>
<td>0.003</td>
<td>0.723</td>
<td>806.775</td>
<td>.000</td>
<td>0.027</td>
<td>0.181</td>
<td>662.48</td>
<td>.000</td>
<td>0.030</td>
</tr>
<tr>
<td> SR* AE</td>
<td>2</td>
<td>0.057</td>
<td>27.625</td>
<td>.000</td>
<td>0.013</td>
<td>0.435</td>
<td>729.205</td>
<td>.000</td>
<td>0.017</td>
<td>0.012</td>
<td>63.351</td>
<td>.000</td>
<td>0.002</td>
</tr>
<tr>
<td> SR* TR</td>
<td>3</td>
<td>0.070</td>
<td>22.836</td>
<td>.000</td>
<td>0.016</td>
<td>0.371</td>
<td>414.269</td>
<td>.000</td>
<td>0.014</td>
<td>0.234</td>
<td>856.48</td>
<td>.000</td>
<td>0.039</td>
</tr>
<tr>
<td> AE* TR</td>
<td>6</td>
<td>0.091</td>
<td>14.825</td>
<td>.000</td>
<td>0.020</td>
<td>0.065</td>
<td>36.082</td>
<td>.000</td>
<td>0.002</td>
<td>0.009</td>
<td>16.666</td>
<td>.000</td>
<td>0.001</td>
</tr>
<tr>
<td> TL* SR* AE</td>
<td>2</td>
<td>0.002</td>
<td>0.757</td>
<td>.469</td>
<td>0.000</td>
<td>0.014</td>
<td>23.118</td>
<td>.000</td>
<td>0.001</td>
<td>0.001</td>
<td>3.452</td>
<td>.032</td>
<td>0.000</td>
</tr>
<tr>
<td> TL* SR* TR</td>
<td>3</td>
<td>0.003</td>
<td>0.827</td>
<td>.479</td>
<td>0.000</td>
<td>0.044</td>
<td>48.797</td>
<td>.000</td>
<td>0.002</td>
<td>0.027</td>
<td>98.162</td>
<td>.000</td>
<td>0.004</td>
</tr>
<tr>
<td> TL* AE* TR</td>
<td>6</td>
<td>0.010</td>
<td>1.603</td>
<td>.142</td>
<td>0.001</td>
<td>0.016</td>
<td>8.907</td>
<td>.000</td>
<td>0.001</td>
<td>0.001</td>
<td>2.338</td>
<td>.006</td>
<td>0.000</td>
</tr>
<tr>
<td> SR* AE* TR</td>
<td>6</td>
<td>0.220</td>
<td>35.807</td>
<td>.000</td>
<td>0.050</td>
<td>0.606</td>
<td>338.082</td>
<td>.000</td>
<td>0.023</td>
<td>0.018</td>
<td>32.948</td>
<td>.000</td>
<td>0.003</td>
</tr>
<tr>
<td> TL* SR* AE* TR</td>
<td>6</td>
<td>0.022</td>
<td>4.542</td>
<td>.002</td>
<td>0.004</td>
<td>0.05</td>
<td>27.768</td>
<td>.000</td>
<td>0.002</td>
<td>0.002</td>
<td>3.651</td>
<td>.001</td>
<td>0.000</td>
</tr>
<tr>
<td>Error</td>
<td align="center">2,326</td>
<td>2.386</td>
<td/>
<td/>
<td/>
<td>0.694</td>
<td/>
<td/>
<td/>
<td>0.212</td>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0013164412441937">
<p><italic>Note</italic>. TL = Test Length; AE = Ability Estimation; SR = Stopping Rule; TR = Treatment of Not-administered Items.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Concerning bias, the three-way interaction between stopping rule, ability estimation, and treatment of not-administered items produced an effect size that bordered on being moderate in strength (ω<sup>2</sup> = .05). In addition, the ability estimation main effect produced a large effect size for bias. Concerning error (RMSE), all four main effects produced large effect size measures, and there were no meaningfully large interaction effects. Test length, stopping rule, and treatment of not-administered items produced large main effect sizes on the fidelity dependant variable, and there were no meaningfully large interaction effects.</p>
<p><xref ref-type="table" rid="table4-0013164412441937">Table 4</xref> presents means and standard errors of the bias values for each cell in the three-way bias interaction, and <xref ref-type="fig" rid="fig2-0013164412441937">Figure 2</xref> provides a graphical representation of these interactions. In general, changing the stopping rule from 4 to 6 consecutive incorrect responses tended to reduce the magnitude of average bias across different missing response treatment techniques and ability estimation methods. The exception to this was when not-administered items were treated as incorrect under MLE, changing the stopping rule from 4 to 6 increased the magnitude of average bias and reversed its sign from positive to negative. Among all three ability estimation methods, EAP produced the least biased average ability estimates, particularly for the longer stopping rule. MAP consistently resulted in overestimates of abilities across different stopping rules. MLE tended to result in similar underestimation of abilities under each stopping rules, especially when missing responses were treated as fractionally correct and not presented. In comparison with other missing response treatment methods, randomly correct was least affected by lengthening stopping rule. Treating missing response as not presented and fractionally correct yielded very similar results under each ability estimation method. It is worth noting that, when not-administered items were treated as randomly correct, we observed parameter estimation nonconvergence. Specifically, when the stopping rule was set as 4 items and the test length was set as 60, there were 5 cases of nonconvergence (out of the 50 replications—10%) under MLE, 8 cases under EAP (16%), and 11 cases under MAP (22%).</p>
<table-wrap id="table4-0013164412441937" position="float">
<label>Table 4.</label>
<caption><p>Means and Standard Errors of Bias for AE × SR × TR Interaction</p></caption>
<graphic alternate-form-of="table4-0013164412441937" xlink:href="10.1177_0013164412441937-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th/>
<th align="center" colspan="2">Bias<hr/></th>
</tr>
<tr>
<th align="left">Ability Estimation</th>
<th align="center">Treatment of Not-Administered Items</th>
<th align="center">Stopping Rule</th>
<th align="center">Mean</th>
<th align="center"><italic>SE</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>EAP</td>
<td>Fractionally correct</td>
<td>4</td>
<td>−0.007</td>
<td>0.032</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.002</td>
<td>0.032</td>
</tr>
<tr>
<td/>
<td>Incorrect</td>
<td>4</td>
<td>−0.027</td>
<td>0.035</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.007</td>
<td>0.029</td>
</tr>
<tr>
<td/>
<td>Randomly correct</td>
<td>4</td>
<td>−0.002</td>
<td>0.033</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>−0.001</td>
<td>0.029</td>
</tr>
<tr>
<td/>
<td>Not presented</td>
<td>4</td>
<td>−0.007</td>
<td>0.031</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>−0.001</td>
<td>0.031</td>
</tr>
<tr>
<td>MAP</td>
<td>Fractionally correct</td>
<td>4</td>
<td>0.032</td>
<td>0.036</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.023</td>
<td>0.036</td>
</tr>
<tr>
<td/>
<td>Incorrect</td>
<td>4</td>
<td>0.037</td>
<td>0.033</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.013</td>
<td>0.033</td>
</tr>
<tr>
<td/>
<td>Randomly correct</td>
<td>4</td>
<td>0.043</td>
<td>0.033</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.041</td>
<td>0.035</td>
</tr>
<tr>
<td/>
<td>Not presented</td>
<td>4</td>
<td>0.024</td>
<td>0.034</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.028</td>
<td>0.037</td>
</tr>
<tr>
<td>MLE</td>
<td>Fractionally correct</td>
<td>4</td>
<td>−0.041</td>
<td>0.034</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>−0.022</td>
<td>0.029</td>
</tr>
<tr>
<td/>
<td>Incorrect</td>
<td>4</td>
<td>0.012</td>
<td>0.034</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>−0.054</td>
<td>0.030</td>
</tr>
<tr>
<td/>
<td>Randomly correct</td>
<td>4</td>
<td>0.005</td>
<td>0.028</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>0.004</td>
<td>0.029</td>
</tr>
<tr>
<td/>
<td>Not presented</td>
<td>4</td>
<td>−0.043</td>
<td>0.036</td>
</tr>
<tr>
<td/>
<td/>
<td>6</td>
<td>−0.028</td>
<td>0.026</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0013164412441937">
<p><italic>Note</italic>. EAP = Expected A Posteriori; MAP = Maximum A Posteriori; MLE = maximum likelihood estimation. The <italic>SE</italic>s shown in this table were computed as the square root of the pooled within-cell variances across the levels of test length.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig2-0013164412441937" position="float">
<label>Figure 2.</label>
<caption><p><italic>Stopping Rule</italic> × <italic>Ability Estimation</italic> × <italic>Treatment of Not-administered Items</italic> bias interaction</p></caption>
<graphic xlink:href="10.1177_0013164412441937-fig2.tif"/>
</fig>
<p>The reason for nonconvergence can be attributed to the discrepancy in responses imputed by randomly correct treatment method and predicted based on the IRT model. According to the explanation in the <italic>Simulation Study</italic>, randomly correct responses were generated by scoring not-administered items as having been “correct” when a Uniform (0, 1) random variable that was generated for each not-administered response was greater or equal to 0.5—otherwise, the not-administered item was scored as incorrect. As the simulated test was administered in the sequence of increasing item difficulty, this treatment may introduce more misfit at locations with missing responses to the point of causing nonconvergence, in particular, for tests that are long but adopting a shorter stopping rule. The observation in this study in which only tests adopting test length as 60 and stopping rule as 4 encountered the nonconvergence issue fit this expectation.</p>
<p>To better understand how bias varied across different ability levels, conditional biases<sup>
<xref ref-type="fn" rid="fn1-0013164412441937">1</xref>
</sup> in these three-way interactions were calculated, and those results are portrayed in <xref ref-type="fig" rid="fig3-0013164412441937">Figure 3</xref>. In contrast with <xref ref-type="fig" rid="fig2-0013164412441937">Figure 2</xref>, which indicates EAP yields the least biased overall ability estimates (i.e., averaged across ability levels), <xref ref-type="fig" rid="fig3-0013164412441937">Figure 3</xref> suggests that, at the tails of ability scale, MLE in general yields more accurate ability estimates than the Bayesian methods, other things being equal. That is, the Bayesian methods resulted in a greater conditional bias at the tails of the ability distribution. This seemingly contradictory result can be attributed to the trends of bias given by the Bayesian and MLE estimation methods. Under EAP and MAP, the abilities of examinees at the low-end of the scale were overestimated, whereas the abilities of examinees at the high-end of the scale were underestimated. As the magnitudes of overestimates and underestimates were very similar, cancelling out both positive and negative biases can render almost unbiased overall ability estimates. Under MLE, however, a wide range of abilities tended to be underestimated, thus causing overall ability estimates to be negative but greater in magnitude than that given by EAP or MAP. In addition, <xref ref-type="fig" rid="fig3-0013164412441937">Figure 3</xref> also suggests that Bayesian ability estimation methods—EAP and MAP—yield very similar patterns of conditional bias across different stopping rules. Under MLE, however, a significant interaction was observed between missing response treatment methods and stopping rules. Consistent with what <xref ref-type="fig" rid="fig2-0013164412441937">Figure 2</xref> indicates, changing stopping rule from 4 to 6 in general resulted in the reduction of conditional bias and alleviated the differences of conditional biases from different missing response treatment techniques. This impact was considerably more conspicuous under MLE than under Bayesian methods. Treatment of missing responses as incorrect in general performed the worst regardless of different stopping rules. In particular, this treatment yielded the worst ability estimates throughout the whole scale under MLE.</p>
<fig id="fig3-0013164412441937" position="float">
<label>Figure 3.</label>
<caption><p>Conditional bias for <italic>Stopping Rule</italic> × <italic>Ability Estimation</italic> × <italic>Treatment of Not-administered Items</italic> interaction</p>
<p><italic>Note</italic>. 1 = [−3, −2.5), 2 = [−2.5, −2), 3 = [−2, −1.5), 4 = [−1.5, −1), 5 = [−1, −.5), 6 = [−.5, 0), 7 = [0, .5), 8 = [.5, 1), 9 = [1, 1.5), 10 = [1.5, 2), 11 = [2, 2.5), 12 = [2.5, 3).</p></caption>
<graphic xlink:href="10.1177_0013164412441937-fig3.tif"/>
</fig>
<p><xref ref-type="table" rid="table5-0013164412441937">Table 5</xref> displays the averaged RMSE and Fidelity values for the relevant main effects. These results indicate that error was maximized when not-administered items were treated as incorrect. MAP estimation produced slightly less error than did EAP, and both MAP and EAP produced less error than MLE. It is not surprising that error decreased as test length increased and consistency between estimated and true ability estimates improved as stopping rule was lengthened. It is also clear that treating not-administered items as incorrect produced the lowest level of fidelity.</p>
<table-wrap id="table5-0013164412441937" position="float">
<label>Table 5.</label>
<caption><p>Means and Standard Errors of RMSE and Fidelity for Main Effects</p></caption>
<graphic alternate-form-of="table5-0013164412441937" xlink:href="10.1177_0013164412441937-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="2">RMSE<hr/></th>
<th align="center" colspan="2">Fidelity<hr/></th>
</tr>
<tr>
<th align="left">Variable</th>
<th align="center">Level</th>
<th align="center">Mean</th>
<th align="center"><italic>SE</italic></th>
<th align="center">Mean</th>
<th align="center"><italic>SE</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>Treatment of not-administered items</td>
<td>Incorrect</td>
<td>0.630</td>
<td>0.020</td>
<td>0.805</td>
<td>0.012</td>
</tr>
<tr>
<td/>
<td>Randomly correct</td>
<td>0.477</td>
<td>0.014</td>
<td>0.894</td>
<td>0.007</td>
</tr>
<tr>
<td/>
<td>Not presented</td>
<td>0.561</td>
<td>0.017</td>
<td>0.849</td>
<td>0.010</td>
</tr>
<tr>
<td/>
<td>Fractionally correct</td>
<td>0.532</td>
<td>0.018</td>
<td>0.863</td>
<td>0.009</td>
</tr>
<tr>
<td>Test length</td>
<td>40</td>
<td>0.598</td>
<td>0.016</td>
<td>0.831</td>
<td>0.011</td>
</tr>
<tr>
<td/>
<td>60</td>
<td>0.502</td>
<td>0.016</td>
<td>0.874</td>
<td>0.009</td>
</tr>
<tr>
<td>Ability estimation method</td>
<td>MLE</td>
<td>0.619</td>
<td>0.022</td>
<td>0.843</td>
<td>0.011</td>
</tr>
<tr>
<td/>
<td>EAP</td>
<td>0.521</td>
<td>0.015</td>
<td>0.856</td>
<td>0.009</td>
</tr>
<tr>
<td/>
<td>MAP</td>
<td>0.511</td>
<td>0.015</td>
<td>0.858</td>
<td>0.009</td>
</tr>
<tr>
<td>Stopping rule</td>
<td>4</td>
<td>0.593</td>
<td>0.018</td>
<td>0.826</td>
<td>0.011</td>
</tr>
<tr>
<td/>
<td>6</td>
<td>0.509</td>
<td>0.017</td>
<td>0.879</td>
<td>0.008</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0013164412441937">
<p><italic>Note</italic>. RMSE = root mean squared error; EAP = Expected A Posteriori; MAP = Maximum A Posteriori; MLE = maximum likelihood estimation. The <italic>SE</italic>s shown in this table were computed as the square root of the pooled within-cell variances across the remaining main effects.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section8-0013164412441937">
<title>Empirical Data Analysis</title>
<p>As mentioned in the Empirical Data, only nine sets of ability estimates were produced for the empirical data because of the nonconvergence issue when missing responses were treated as randomly correct. The overlay of the ability distribution on the item distribution for these nine sets of estimates is portrayed in <xref ref-type="fig" rid="fig4-0013164412441937">Figure 4</xref>, which indicates a large overlapping area between ability and item distributions in each set of estimates.</p>
<fig id="fig4-0013164412441937" position="float">
<label>Figure 4.</label>
<caption><p>Overlay of the ability distribution on the item difficulty distribution for the empirical data</p></caption>
<graphic xlink:href="10.1177_0013164412441937-fig4.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig5-0013164412441937">Figures 5</xref> and <xref ref-type="fig" rid="fig6-0013164412441937">6</xref> portray means and standard deviations of ability estimates produced by missing data treatment techniques across different ability estimation methods. These figures suggest the following. First, consistent with simulation study results, MLE tended to produce much lower ability estimates but higher standard deviation of the ability estimates, and vice versa for the Bayes methods. In particular, MAP method produced the highest average ability estimate and the lowest standard deviation across all missing data treatment methods. Second, among all missing response treatment techniques, not presented seemed to be more sensitive to the difference in ability estimation methods—MLE versus Bayes—than others. In contrast, treating missing responses as incorrect did not display this pattern. Rather, this treatment produced very similar ability estimates under MLE and EAP.</p>
<fig id="fig5-0013164412441937" position="float">
<label>Figure 5.</label>
<caption><p>Average ability estimates by <italic>Ability Estimation</italic> × <italic>Treatment of Not-administered Items</italic> for the real data</p>
<p><italic>Note</italic>. INC = Incorrect; NP = Not presented; FC = Fractionally correct.</p></caption>
<graphic xlink:href="10.1177_0013164412441937-fig5.tif"/>
</fig>
<fig id="fig6-0013164412441937" position="float">
<label>Figure 6.</label>
<caption><p>Standard deviations of ability estimates by <italic>Ability Estimation</italic> × <italic>Treatment of Not-administered Items</italic> for the real data</p>
<p><italic>Note</italic>. INC = Incorrect; NP = Not presented; FC = Fractionally correct.</p></caption>
<graphic xlink:href="10.1177_0013164412441937-fig6.tif"/>
</fig>
</sec>
</sec>
<sec id="section9-0013164412441937" sec-type="discussion">
<title>Summary and Discussion</title>
<p>In some operational settings, items may be presented in a sequence of increasing difficulty and test administration is terminated after a predetermined number of incorrect answers. By modeling censored item responses present in the IRT framework, our study investigated how accurately ability parameters were recovered under a combination of conditions including test length, stopping rule, missing response treatment method, and ability estimation method.</p>
<p>Some of our research findings were consistent with the outcomes obtained in prior studies such as <xref ref-type="bibr" rid="bibr8-0013164412441937">DeAyala (2003</xref>, <xref ref-type="bibr" rid="bibr9-0013164412441937">2006</xref>) <xref ref-type="bibr" rid="bibr23-0013164412441937">Zhang and Walker (2008)</xref>, and <xref ref-type="bibr" rid="bibr18-0013164412441937">Rose et al. (2010)</xref>. Specifically, (a) scoring missing responses as incorrect in general yielded the largest amount of estimation error and (b) Bayes methods tended to produce more precise estimates, that is, less estimation error, than MLE. As this study investigated a situation in which missing responses occurred as a function of examinees’ ability and test administration rule (including presenting items in a sequence of increasing difficulty and terminating test at a row of consecutive incorrect responses), these results extend our understanding of how ability estimates are affected by relevant factors, some of which have never been examined in the literature. In general, the results revealed the following things about recovery of examinee ability under such conditions.</p>
<p>First, there may be complex interactions between parameter estimation methods, stopping rule lengths, and missing data treatment techniques with respect to their impact on parameter estimation bias. MLE, in comparison with Bayes methods, tended to affect ability estimates differently given different stopping rules and missing response treatment techniques. As <xref ref-type="fig" rid="fig3-0013164412441937">Figure 3</xref> suggests, the differences in ability estimates given different missing response treatment methods under MLE are greater than those under EAP or MAP. When the test stopping rule was changed from 4 to 6, we observed significant changes in conditional bias for both low- and high-ability examinees under MLE. In particular, for low-ability examinees (i.e., mostly those with true abilities lower than −2), we observed a reversal of the sign in bias from positive to negative. <xref ref-type="fig" rid="fig2-0013164412441937">Figure 2</xref> also exhibits the same phenomenon, in which when missing responses are treated as incorrect, extending stopping rule increases the magnitude of bias and the direction of bias is reversed from positive to negative. In comparison, under Bayes estimation methods, ability estimates—particularly conditional ones—did not undergo significant changes from the application of different stopping rules and missing response treatment methods. It is also worth noting that under the situations studied in this article MLE tends to generate more accurate ability estimates than the Bayesian methods for examinees at the tails of the scale.</p>
<p>Second, with regard to missing data treatment technique, <xref ref-type="fig" rid="fig2-0013164412441937">Figures 2</xref> and <xref ref-type="fig" rid="fig3-0013164412441937">3</xref> suggest that treating missing response as incorrect tends to be more easily affected by different stopping rules, in particular under MLE. In addition, this treatment is shown in <xref ref-type="fig" rid="fig3-0013164412441937">Figure 3</xref> to produce the worst conditional bias across the whole scale when MLE is used as estimation method. <xref ref-type="table" rid="table5-0013164412441937">Table 5</xref> echoes this finding by demonstrating that this particular treatment produces the worst estimation error and fidelity. In contrast, treating missing responses as randomly correct tended to be least affected by different stopping rules and ability estimation methods, as indicated in both <xref ref-type="fig" rid="fig2-0013164412441937">Figures 2</xref> and <xref ref-type="fig" rid="fig3-0013164412441937">3</xref>. The reason might be that responses—correct or incorrect—assigned in a random manner may not add meaningful information to the data. As only two more item responses are obtained when the stopping rule is extended from 4 to 6, significant changes in ability estimation is less likely to occur as a result of adding these randomly correct and/or incorrect responses. Surprisingly, this treatment technique, as indicated in <xref ref-type="table" rid="table5-0013164412441937">Table 5</xref>, can best minimize error and maximize parameter estimate fidelity. As noted before, however, this treatment tended to cause nonconvergence in estimation; and our empirical data analysis also encountered the same problem. As to the treatment of missing data as not presented and fractionally correct, these methods seemed to yield similar performance in terms of producing comparable bias under each ability estimation method and comparable RMSE and fidelity. The reason might be the use of three-parameter IRT model in this study, and this fractionally correct treatment technique models guessing behavior to some degree.</p>
<p>Third, all other things being equal, extending the stopping rule from 4 to 6 items minimized bias and improved ability estimation precision and parameter fidelity, as illustrated in <xref ref-type="fig" rid="fig2-0013164412441937">Figures 2</xref> and <xref ref-type="fig" rid="fig3-0013164412441937">3</xref> and <xref ref-type="table" rid="table5-0013164412441937">Table 5</xref>. It is anticipated that a stretch of the stopping rule beyond what the current study investigated further minimize bias and improve ability estimation precision for the reason that data sparseness rate is reduced as the result of the extension of the stopping rule. It is also anticipated that an extension of stopping rule beyond what the current study investigated affect Bayesian ability estimates less than MLE estimates, all other things being equal.</p>
<p>With these findings, taken together with the results of previous relevant studies, useful guidelines for practitioners can be suggested concerning how to appropriately treat missing data that are nonignorable due to the context simulated in this study. Specifically, missing responses should not be treated as incorrect especially under MLE or as randomly correct. Rather, treatment of missing responses as not presented or fractionally correct (in the case of using three-parameter IRT model) may appear to be a viable alternative. As <xref ref-type="bibr" rid="bibr23-0013164412441937">Zhang and Walker (2008)</xref> mentioned, this not presented treatment is preferable from practical point of view, as it does not require any special treatment of the missing data. In addition, this study suggests that the differences in missing data treatment methods tend to have greater impacts on ability estimate under MLE than under EAP or MAP.</p>
<p>The findings from this study can also shed light on situations in which missing responses tend to occur near the end of the test because of test speededness, which tend to produce omits near the end of the test because examinees lack enough time. As mentioned previously, missing responses that occur in the context of the current study come as a result of examinee’s ability in junction with test administration rule, in that examinees, especially those at the low-end of the scale, lack ability to correctly respond to questions presented in a sequence of increasing difficulty. Once a test terminates, missing responses occur from where the test stops to the end. In the situation of test speededness, one can argue that test speededness is more or less related to examinee’s ability. For example, high-ability examinees may be less likely to stumble themselves over the hard items positioned at the early stage of the test so that they are more likely to finish the test within the specified time. In fact, a study by <xref ref-type="bibr" rid="bibr4-0013164412441937">Bolt, Cohen, and Wollack (2002)</xref> provided the evidence that non-speeded group, that is, the group consisting of examinees without any missing responses at end-of-test items, had a higher average ability than speeded group, that is, the group composed of examinees with missing responses at end-of-test items. As such, researchers argued that omits that occurred because of test speededness may not be missing at random (<xref ref-type="bibr" rid="bibr20-0013164412441937">Suh, Kang, Wollack, &amp; Kim, 2006</xref>). Relevant test speededness studies such as <xref ref-type="bibr" rid="bibr20-0013164412441937">Suh et al. (2006)</xref> did not support the practice of treating missing data as incorrect in the presence of test speededness, no matter whether a traditional or mixture item response model was used. Our study corroborated their finding, suggesting that a feasible option to yield reasonably reliable ability estimates is to treat omits at end-of-test items as either not presented or fractionally correct (given the use of the 3PL model).</p>
<p>It is important to mention that the results of this study may, to a certain extent, be limited to assessments adopting a stopping rule only. In many cognitive or achievement assessments, not only is a stopping rule adopted, but also examinees begin the test at a different location because of variables such as age or grade level. In a test with a starting rule, missing responses will occur at the beginning of the test. Our study considered only a stopping rule because that was a feature of the empirical test on which our simulation was based. However, because a starting rule also results in missing data, additional research would be needed to determine whether our results can be extended to such an application. Also, the test termination rule that this study adopted (again, based on an empirical test) may limit the generalizability of our results. Future study could consider adopting more sophisticated stopping rules that may work better or create tests with items ordered in a way that a missing response can be better interpreted as a lack of sufficient ability to continue administering the test. Incorporating model-based nonresponse data treatment methods also merits further research.</p>
</sec>
</body>
<back>
<ack><p>The authors thank the editor, two anonymous reviewers, and Dr. Carl Hauser for their valuable comments and suggestions on earlier version of this article.</p></ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0013164412441937">
<label>1.</label>
<p>Conditional bias for each cell was calculated by classifying examinees in each replication within each cell of the experimental design into different ability groups. Twelve ability groups were used for examinees in each cell, each with an interval of 0.5. Examinees with generated abilities, that is, true abilities greater than 3 in absolute value, were excluded from the analyses because of the few observations in these ranges. Sample sizes for each ability group ranged from 230 to 10,000. For each ability group, bias was calculated using <xref ref-type="disp-formula" rid="disp-formula1-0013164412441937">Equation (1)</xref>.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Andrich</surname><given-names>D.</given-names></name>
</person-group> (<year>1978</year>). <article-title>A rating formulation for ordered response categories</article-title>. <source>Psychometrika</source>, <volume>43</volume>, <fpage>561</fpage>-<lpage>573</lpage>.</citation>
</ref>
<ref id="bibr2-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bate</surname><given-names>M. S.</given-names></name>
<name><surname>Smith</surname><given-names>M.</given-names></name>
</person-group> (<year>1978</year>). <source>Assessment in nursery education</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>GL Assessment</publisher-name>.</citation>
</ref>
<ref id="bibr3-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Boehm</surname><given-names>A.</given-names></name>
</person-group> (<year>1969</year>). <source>Boehm test of basic concepts</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Psychological Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr4-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bolt</surname><given-names>D. M.</given-names></name>
<name><surname>Cohen</surname><given-names>A. S.</given-names></name>
<name><surname>Wollack</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Item parameter estimation under conditions of test speededness: Application of a mixture Rasch model with ordinal constraints</article-title>. <source>Journal of Educational Measurement</source>, <volume>39</volume>, <fpage>331</fpage>-<lpage>348</lpage>.</citation>
</ref>
<ref id="bibr5-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bracken</surname><given-names>B. A.</given-names></name>
</person-group> (<year>1984</year>). <source>Bracken Basic Concept Scale</source>. <publisher-loc>San Antonio, TX</publisher-loc>: <publisher-name>Psychological Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr6-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Claxton</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Sampling, instrumentation, and data collection</article-title>. In <person-group person-group-type="editor">
<name><surname>Montie</surname><given-names>J. E.</given-names></name>
<name><surname>Xiang</surname><given-names>Z.</given-names></name>
<name><surname>Schweinhart</surname><given-names>L. J.</given-names></name>
</person-group> (Eds.), <source>The role of preschool experience in children’s development: Longitudinal findings from 10 countries</source> (pp. <fpage>27</fpage>-<lpage>42</lpage>). <publisher-loc>Ypsilanti, MI</publisher-loc>: <publisher-name>High/Scope Press</publisher-name>.</citation>
</ref>
<ref id="bibr7-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cohen</surname><given-names>J.</given-names></name>
</person-group> (<year>1988</year>). <source>Statistical power analysis for the behavioral science</source> (<edition>2nd ed.</edition>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr8-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeAyala</surname><given-names>R.J.</given-names></name>
</person-group> (<year>2003</year>). <article-title>The effect of missing data on estimating a respondent’s location using ratings data</article-title>. <source>Journal of Applied Measurement</source>, <volume>4</volume>, <fpage>1</fpage>-<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr9-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeAyala</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Estimating person measures from partial credit responses containing missing data</article-title>. <source>Journal of Applied Measurement</source>, <volume>7</volume>, <fpage>278</fpage>-<lpage>291</lpage>.</citation>
</ref>
<ref id="bibr10-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeAyala</surname><given-names>R. J.</given-names></name>
<name><surname>Plake</surname><given-names>B. S.</given-names></name>
<name><surname>Impara</surname><given-names>J. C.</given-names></name>
</person-group> (<year>2001</year>). <article-title>The impact of omitted responses on the accuracy of ability estimation in item response theory</article-title>. <source>Journal of Educational Measurement</source>, <volume>38</volume>, <fpage>213</fpage>-<lpage>234</lpage>.</citation>
</ref>
<ref id="bibr11-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kaufman</surname><given-names>A. S.</given-names></name>
<name><surname>Kaufman</surname><given-names>N. L.</given-names></name>
</person-group> (<year>2004</year>). <source>Manual: Kaufman Assessment Battery for Children</source> (<edition>2nd ed.</edition>). <publisher-loc>Circle Pines, MN</publisher-loc>: <publisher-name>AGS Publishing</publisher-name>.</citation>
</ref>
<ref id="bibr12-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Little</surname><given-names>R. J. A.</given-names></name>
<name><surname>Rubin</surname><given-names>D. B.</given-names></name>
</person-group> (<year>1987</year>). <source>Statistical analysis with missing data</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr13-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lord</surname><given-names>F. M.</given-names></name>
</person-group> (<year>1974</year>). <article-title>Estimation of latent ability and item parameters when there are omitted responses</article-title>. <source>Psychometrika</source>, <volume>39</volume>, <fpage>247</fpage>-<lpage>264</lpage>.</citation>
</ref>
<ref id="bibr14-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ludlow</surname><given-names>L. H.</given-names></name>
<name><surname>O’Leary</surname><given-names>M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Scoring omitted and not-reached items: Practical data analysis implications</article-title>. <source>Educational and Psychological Measurement</source>, <volume>59</volume>, <fpage>615</fpage>-<lpage>630</lpage>.</citation>
</ref>
<ref id="bibr15-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mislevy</surname><given-names>R. J.</given-names></name>
<name><surname>Wu</surname><given-names>P.K.</given-names></name>
</person-group> (<year>1988</year>). <source>Inferring examinee ability when some item responses are missing</source> (<comment>ETS RR 88-48</comment>). <publisher-loc>Princeton</publisher-loc>: <publisher-name>Educational Testing Service</publisher-name>.</citation>
</ref>
<ref id="bibr16-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mislevy</surname><given-names>R. J.</given-names></name>
<name><surname>Wu</surname><given-names>P.K.</given-names></name>
</person-group> (<year>1996</year>). <source>Missing responses and IRT ability estimation: Omits, choice, time, limits, and adaptive testing</source> (<comment>ETS RR 96-30</comment>). <publisher-loc>Princeton</publisher-loc>: <publisher-name>Educational Testing Service</publisher-name>.</citation>
</ref>
<ref id="bibr17-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Oshima</surname><given-names>T. C.</given-names></name>
</person-group> (<year>1994</year>). <article-title>The effect of speedness on parameter estimation in item response theory</article-title>. <source>Journal of Educational Measurement</source>, <volume>31</volume>, <fpage>200</fpage>-<lpage>219</lpage>.</citation>
</ref>
<ref id="bibr18-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rose</surname><given-names>N.</given-names></name>
<name><surname>von Davier</surname><given-names>M.</given-names></name>
<name><surname>Xu</surname><given-names>X.</given-names></name>
</person-group> (<year>2010</year>). <source>Modeling nonignorable missing data with item response theory</source> (<comment>IRT; ETS RR-10-11</comment>). <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Educational Testing Service</publisher-name>.</citation>
</ref>
<ref id="bibr19-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rubin</surname><given-names>D. B.</given-names></name>
</person-group> (<year>1987</year>). <source>Multiple imputation for nonresponse in surveys</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr20-0013164412441937">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Su</surname><given-names>Y.</given-names></name>
<name><surname>Kang</surname><given-names>T.</given-names></name>
<name><surname>Wollack</surname><given-names>J. A.</given-names></name>
<name><surname>Kim</surname><given-names>S.</given-names></name>
</person-group> (<year>2006</year>). <source>A comparison of test scoring methods in the presence of test speededness</source>. <conf-name>Paper presented at the annual meeting of National Council on Measurement in Education conference</conf-name>, <conf-loc>San Francisco, CA</conf-loc>.</citation>
</ref>
<ref id="bibr21-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wechsler</surname><given-names>D.</given-names></name>
</person-group> (<year>2008</year>). <source>Wechsler Adult Intelligence Scale: Technical and interpretive manual</source> (<edition>4th ed.</edition>). <publisher-loc>San Antonio, TX</publisher-loc>: <publisher-name>Pearson</publisher-name>.</citation>
</ref>
<ref id="bibr22-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wolfe</surname><given-names>E. W.</given-names></name>
<name><surname>Manalo</surname><given-names>J. R.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Scaling of the Phase 2 and Phase 3 cognitive and language developmental status measures</article-title>. In <person-group person-group-type="editor">
<name><surname>Montie</surname><given-names>J. E.</given-names></name>
<name><surname>Xiang</surname><given-names>Z.</given-names></name>
<name><surname>Schweinhart</surname><given-names>L. J.</given-names></name>
</person-group> (Eds.), <source>The role of preschool experience in children’s development: Longitudinal findings from 10 countries</source> (pp. <fpage>43</fpage>-<lpage>52</lpage>). <publisher-loc>Ypsilanti, MI</publisher-loc>: <publisher-name>High/Scope</publisher-name>.</citation>
</ref>
<ref id="bibr23-0013164412441937">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>B.</given-names></name>
<name><surname>Walker</surname><given-names>C. M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Impact of missing data on person model fit and person trait estimation</article-title>. <source>Applied Psychological Measuremen</source>t, <volume>32</volume>, <fpage>466</fpage>-<lpage>479</lpage>.</citation>
</ref>
<ref id="bibr24-0013164412441937">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Zimowski</surname><given-names>M. F.</given-names></name>
<name><surname>Muraki</surname><given-names>E.</given-names></name>
<name><surname>Mislevy</surname><given-names>R. J.</given-names></name>
<name><surname>Bock</surname><given-names>R. D.</given-names></name>
</person-group> (<year>1996</year>). <article-title>BILOG-MG: Multiple-group IRT analysis and test maintenance for binary items [Computer software]</article-title>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Scientific Software International</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>