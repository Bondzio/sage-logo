<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">APM</journal-id>
<journal-id journal-id-type="hwp">spapm</journal-id>
<journal-title>Applied Psychological Measurement</journal-title>
<issn pub-type="ppub">0146-6216</issn>
<issn pub-type="epub">1552-3497</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0146621612437403</article-id>
<article-id pub-id-type="publisher-id">10.1177_0146621612437403</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Confirming Testlet Effects</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>DeMars</surname><given-names>Christine E.</given-names></name>
<xref ref-type="aff" rid="aff1-0146621612437403">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0146621612437403"><label>1</label>James Madison University, Harrisonburg, VA, USA</aff>
<author-notes>
<corresp id="corresp1-0146621612437403">Christine E. DeMars, Center for Assessment and Research Studies, MSC 6806, James Madison University, Harrisonburg, VA 22807, USA Email: <email>demarsce@jmu.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2012</year>
</pub-date>
<volume>36</volume>
<issue>2</issue>
<fpage>104</fpage>
<lpage>121</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>A testlet is a cluster of items that share a common passage, scenario, or other context. These items might measure something in common beyond the trait measured by the test as a whole; if so, the model for the item responses should allow for this testlet trait. But modeling testlet effects that are negligible makes the model unnecessarily complicated and risks capitalization on chance, increasing the error in parameter estimates. Checking each testlet to see if the items within the testlet share something beyond the primary trait could therefore be useful. This study included (a) comparison between a model with no testlets and a model with testlet <italic>g</italic>, (b) comparison between a model with all suspected testlets and a model with all suspected testlets <italic>except</italic> testlet <italic>g</italic>, and (c) a test of essential unidimensionality. Overall, Comparison b was most useful for detecting testlet effects. Model comparisons based on information criteria, specifically the sample-size adjusted Bayesian Information Criteria (SSA-BIC) and BIC, resulted in fewer false alarms than statistical significance tests. The test of essential unidimensionality had true hit rates and false alarm rates similar to the SSA-BIC when the testlet effect was zero for all testlets except the studied testlet. But the presence of additional testlet effects in the partitioning test led to higher false alarm rates for the test of essential unidimensionality.</p>
</abstract>
<kwd-group>
<kwd>testlets</kwd>
<kwd>bifactor</kwd>
<kwd>dimensionality</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0146621612437403">
<title>Detecting Testlet Effects</title>
<p>Test items are sometimes grouped into sets, or testlets, that share a common scenario or reading passage. This saves testing time, as the examinees only have to consider the scenario once and then can use information from it for several items. This might also increase the authenticity of the task as it adds more context. However, it could potentially introduce additional sources of variance, additional factors due to the testlets. These testlet factors would be considered random nuisance factors and not be of interest in themselves. However, ignoring the testlet factors could lead to incorrect estimation of the reliability or standard error of the primary trait measured by the test as a whole (<xref ref-type="bibr" rid="bibr9-0146621612437403">Bradlow, Wainer, &amp; Wang, 1999</xref>; <xref ref-type="bibr" rid="bibr31-0146621612437403">Marais &amp; Andrich, 2008a</xref>; <xref ref-type="bibr" rid="bibr41-0146621612437403">Sireci, Thissen, &amp; Wainer, 1991</xref>; <xref ref-type="bibr" rid="bibr48-0146621612437403">Wainer &amp; Wang, 2000</xref>; <xref ref-type="bibr" rid="bibr53-0146621612437403">Yen, 1993</xref>). In addition, ignoring the testlet factors can lead to errors in equating/scaling (<xref ref-type="bibr" rid="bibr5-0146621612437403">Bishop &amp; Omar, 2002</xref>; <xref ref-type="bibr" rid="bibr26-0146621612437403">Lee, Kolen, Frisbie, &amp; Ankenmann, 2002</xref>; Y. <xref ref-type="bibr" rid="bibr28-0146621612437403">Li, Bolt, &amp; Fu, 2005</xref>), misestimation of item discrimination parameters (<xref ref-type="bibr" rid="bibr1-0146621612437403">Ackerman, 1987</xref>; <xref ref-type="bibr" rid="bibr9-0146621612437403">Bradlow et al., 1999</xref>; <xref ref-type="bibr" rid="bibr48-0146621612437403">Wainer &amp; Wang, 2000</xref>), and item misfit (<xref ref-type="bibr" rid="bibr31-0146621612437403">Marais &amp; Andrich, 2008a</xref>). Even if the item parameter estimates from a model ignoring the testlets were the same as those from a model incorporating the testlet factors, the information function from the unidimensional model would be inaccurate because it should be averaged over the distribution of the testlet factor (<xref ref-type="bibr" rid="bibr20-0146621612437403">Ip, 2010b</xref>; <xref ref-type="bibr" rid="bibr48-0146621612437403">Wainer &amp; Wang, 2000</xref>).</p>
<p>Two general conceptions may be used to model the testlet factors: local item dependency and multidimensionality. Defining local dependence in terms of nonzero covariances among the observed item responses after controlling the primary trait, <xref ref-type="bibr" rid="bibr19-0146621612437403">Ip (2010a)</xref>, showed that multidimensional and locally dependent unidimensional models yield identical covariance matrices for the observed (manifest) item responses. Local dependence can also be defined in terms of dependence of the response function for one item on the <italic>observed</italic> response to another item (<xref ref-type="bibr" rid="bibr3-0146621612437403">Andrich &amp; Kreiner, 2010</xref>; <xref ref-type="bibr" rid="bibr31-0146621612437403">Marais &amp; Andrich, 2008a</xref>, <xref ref-type="bibr" rid="bibr32-0146621612437403">2008b</xref>). This type of local dependency cannot be captured by a multidimensional item response theory (IRT) model. Dependency on the observed response might be most likely when the response to one item depends directly on the correctness of another item; for example, in a testlet linked to a graph of the results of a lab experiment, one item might ask examinees <italic>what</italic> occurred in the graph, followed by an item asking <italic>why</italic> it occurred. Multidimensionality might seem more reasonable when there are multiple items linked to a context but they do not build directly off of each other.</p>
<p>From the multidimensional perspective, the bifactor model or a random-effects model (<xref ref-type="bibr" rid="bibr9-0146621612437403">Bradlow et al., 1999</xref>) can be used to model the testlet factors, as nuisance parameters, along with the primary trait. However, if one of the testlets does not measure a secondary factor, the bifactor model will merely capitalize on chance for that testlet, producing larger standard errors of the estimated item parameters (<xref ref-type="bibr" rid="bibr14-0146621612437403">DeMars, 2006</xref>). Content specialists may also waste time speculating on why some items within the testlet loaded more highly than did others on the nonexistent secondary factor. It would therefore be useful to have a method for testing each testlet to see if it significantly measures a secondary factor. This study examines two possible sets of procedures, one based on model fit in Testfact (<xref ref-type="bibr" rid="bibr7-0146621612437403">Bock et al., 2003</xref>) and the other based on a confirmatory test in Dimtest (<xref ref-type="bibr" rid="bibr43-0146621612437403">Stout, 2005</xref>).</p>
<sec id="section2-0146621612437403">
<title>Bifactor Model</title>
<p>In the bifactor model (<xref ref-type="bibr" rid="bibr16-0146621612437403">Gibbons &amp; Hedeker, 1992</xref>), each item response is a function of the primary trait θ<sub>P</sub> and possibly one testlet trait,<sup><xref ref-type="fn" rid="fn1-0146621612437403">1</xref></sup> θ<sub>T</sub><italic><sub>g</sub></italic>, where <italic>g</italic> is the testlet to which the item belongs. To identify the model, typically the mean and variance are set to 0 and 1 for each trait. All traits or dimensions in the model are orthogonal and thus θ<sub>T</sub><italic><sub>g</sub></italic> is some variance that the items within testlet <italic>g</italic> share above and beyond the primary factor. In addition, responses to items that are independent of any testlets can be modeled as a function of only θ<sub>P</sub>. For dichotomous testlet items, the 3-parameter bifactor model is</p>
<p>
<disp-formula id="disp-formula1-0146621612437403">
<mml:math display="block" id="math1-0146621612437403">
<mml:mrow>
<mml:mtext>P</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>r</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi mathvariant="bold">θ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>Φ</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>Pi</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>P</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mi mathvariant="bold">a</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo>′</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mtext>Ti</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>T</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0146621612437403" xlink:href="10.1177_0146621612437403-eq1.tif"/>
</disp-formula>
</p>
<p>where Pr<italic><sub>i</sub></italic>(<bold>θ</bold>) is the probability of correct response on item <italic>i</italic> given the item parameters and <bold>θ</bold> (composed of θ<italic><sub>P</sub></italic> and the vector θ<sub>T</sub> of the testlet traits), <italic>c<sub>i</sub></italic> is the lower asymptote, <italic>a</italic><sub>P<italic>i</italic></sub> is the item discrimination on the primary trait, <bold>a<sub>T</sub><sub>i</sub></bold> is a vector of testlet discrimination parameters for item <italic>i</italic>, and <italic>d<sub>i</sub></italic> is the item difficulty. The symbol Φ indicates integration over the normal curve up to <inline-formula id="inline-formula1-0146621612437403">
<mml:math display="inline" id="math2-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>P</mml:mtext>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mtext>θ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>P</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mi mathvariant="bold">a</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo>′</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mtext>Ti</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>T</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>. For any item <italic>i</italic>, all but one of the testlet <italic>a</italic>’s is equal to zero, and thus only one element of θ<sub>T</sub> has an impact on the function. For brevity, <italic>a</italic><sub>T</sub> will refer to the nonzero element of <bold>a<sub>Ti</sub></bold> (for item <italic>i</italic> within testlet <italic>g</italic>, this would more formally be <bold>a<sub>T</sub></bold><sub>i(</sub><italic><sub>g</sub></italic><sub>)</sub>). Similarly, θ<sub>T</sub> will indicate the element of <bold>θ</bold><sub>T</sub> that is relevant for a given testlet. The subscript <italic>i</italic> will also be dropped from <italic>a</italic><sub>P</sub><italic><sub>i</sub></italic> and <italic>d<sub>i</sub></italic> for readability.</p>
<p>The random-effects testlet model (<xref ref-type="bibr" rid="bibr9-0146621612437403">Bradlow et al., 1999</xref>; <xref ref-type="bibr" rid="bibr47-0146621612437403">Wainer, Bradlow, &amp; Wang, 2007</xref>) can be shown to be a constrained reparameterized version of the bifactor model (<xref ref-type="bibr" rid="bibr14-0146621612437403">DeMars, 2006</xref>; <xref ref-type="bibr" rid="bibr29-0146621612437403">Li, Bolt, &amp; Fu, 2006</xref>).This model is typically parameterized as</p>
<p>
<disp-formula id="disp-formula2-0146621612437403">
<mml:math display="block" id="math3-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mtext>Pr</mml:mtext>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>θ</mml:mtext>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mtext>e</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>θ</mml:mtext>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>γ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mtext>e</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>i</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>θ</mml:mtext>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mtext>γ</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0146621612437403" xlink:href="10.1177_0146621612437403-eq2.tif"/>
</disp-formula>
</p>
<p>Essentially, in the random-effects testlet model, <italic>a<sub>Pi</sub></italic> is outside of the parentheses and thus applies to the testlet trait as well as the primary trait and thus no longer needs the subscript <italic>P</italic>. In addition, <italic>a</italic><sub>i</sub> will be approximately 1.7 times <italic>a<sub>Pi</sub></italic> because <xref ref-type="disp-formula" rid="disp-formula1-0146621612437403">Equation 1</xref> is in the normal metric and <xref ref-type="disp-formula" rid="disp-formula2-0146621612437403">Equation 2</xref> is in the logistic metric. The item difficulty, <italic>b<sub>i</sub></italic>, equals <italic>d<sub>i</sub></italic>/<italic>a<sub>i</sub></italic> from <xref ref-type="disp-formula" rid="disp-formula1-0146621612437403">Equation 1</xref>. The testlet trait for testlet <italic>g</italic>, of which item <italic>i</italic> is a member, is symbolized as γ<italic><sub>g</sub></italic><sub>(</sub><italic><sub>i</sub></italic><sub>)</sub> (instead of θ<sub>T</sub>), and its coefficient is fixed to one so that the variance of γ is a free parameter. The product of the <italic>a</italic><sub>P</sub> and the standard deviation of γ thus equals <italic>a</italic><sub>T</sub> in the bifactor model. A larger variance of γ, corresponding to a larger testlet <italic>a</italic>-parameter in the bifactor model, indicates a greater testlet effect. The key difference from the bifactor model is that all items in the same testlet have the same <italic>a</italic><sub>P</sub>/<italic>a</italic><sub>T</sub> ratio, equal to the standard deviation of γ.</p>
<p>The random-effects testlet model is also equivalent to a higher order model with one higher order factor and a second-order factor for each testlet (<xref ref-type="bibr" rid="bibr36-0146621612437403">Rijmen, 2010</xref>). The <italic>a<sub>i</sub></italic> of the random-effects testlet model is equivalent to the product of the loading of item <italic>i</italic> on the testlet second-order factor times the loading for the testlet second-order factor on the first-order factor. The standard deviation of γ in the random-effects testlet model is equivalent to the loading of item <italic>i</italic> on the testlet second-order factor.</p>
</sec>
<sec id="section3-0146621612437403">
<title>Testfact and the −2 Log-Likelihood (−2LL) Difference Test</title>
<p>Testfact (<xref ref-type="bibr" rid="bibr7-0146621612437403">Bock et al., 2003</xref>) can be used to estimate the parameters of the bifactor model. Thus, it seems reasonable, when using Testfact to estimate the parameters, to use Testfact to test model fit for each testlet. The estimation method in Testfact is marginal maximum likelihood (MML). After the final iteration of the item parameter estimation, the LL of each response pattern, given the parameter estimates, is calculated as a function of θ. The model LL is the sum across examinees. The better the model fit, the higher the LL or the lower the −2LL.</p>
<p>When comparing nested models, where one model is a more constrained version of the other model, the difference in the −2LL should be distributed as χ<sup>2</sup> with degrees of freedom equal to the number of additional free parameters. This test is also labeled the likelihood ratio test (LRT) because the difference in the LLs is the log of the ratio of the likelihoods. When a unidimensional model is compared with a model with one testlet, the number of parameters increases by the number of items in testlet <italic>g</italic>. This test is illustrated for the bifactor model, testing multiple secondary factors simultaneously against a unidimensional model, in the Testfact manual (<xref ref-type="bibr" rid="bibr15-0146621612437403">duToit, 2003</xref>) and other sources (<xref ref-type="bibr" rid="bibr6-0146621612437403">Bock &amp; Gibbons, 2010</xref>; <xref ref-type="bibr" rid="bibr10-0146621612437403">Cai, 2010</xref>; <xref ref-type="bibr" rid="bibr16-0146621612437403">Gibbons &amp; Hedeker, 1992</xref>). Two possible model comparisons could be conducted to test an individual testlet. If one ignores the possibility of testlet traits for testlets other than testlet <italic>g</italic>, a bifactor model could be compared with a unidimensional model. In the unidimensional model, all testlet discriminations are fixed to zero, and in the bifactor model considered here, labeled the <italic>single-testlet</italic> model, the testlet discriminations for testlet <italic>g</italic> are free. Thus, the unidimensional model is nested within the single-testlet bifactor model. A rejection of the null hypothesis supports the presence of a significant testlet factor for testlet <italic>g</italic>. An alternative model comparison, between a <italic>complete</italic> bifactor model and an <italic>all-but-one</italic> bifactor model, could take into account that other testlets may be present. In the complete bifactor model, testlet discriminations are freed for each possible testlet. In the all-but-one model the testlet discriminations for testlet <italic>g</italic> are fixed to zero and the items within testlet <italic>g</italic> load only on the primary trait. The all-but-one model is nested within the complete model, so again the difference in the −2LL should be distributed as χ<sup>2</sup> with degrees of freedom equal to the number of additional freed parameters (the number of items in testlet <italic>g</italic>). The comparison between the unidimensional and the single-testlet model is appropriate if the null hypothesis is completely true or if testlet <italic>g</italic> is the only testlet significantly influenced by a testlet trait. This comparison avoids capitalizing on chance and wasting degrees of freedom on the other testlets in which there is no true testlet effect. However, it might be problematic in cases where there are significant testlet effects for testlets other than testlet <italic>g</italic>—the comparison of the complete versus the all-but-one models would then be more appropriate.</p>
<p>When Testfact is used for exploratory models, in which the second factor is not based on testlet structure or any other theoretical reason but is instead chosen mathematically to explain the greatest amount of residual variance, the difference in −2LL sometimes has been shown to have an extremely high Type I error rate (<xref ref-type="bibr" rid="bibr12-0146621612437403">De Champlain &amp; Gessaroli, 1998</xref>; <xref ref-type="bibr" rid="bibr13-0146621612437403">DeMars, 2003</xref>), particularly for less discriminating items (<xref ref-type="bibr" rid="bibr4-0146621612437403">Berger &amp; Knol, 1990</xref>), although this finding has not been universal (<xref ref-type="bibr" rid="bibr45-0146621612437403">Tate, 2003</xref>). <xref ref-type="bibr" rid="bibr18-0146621612437403">Hayashi, Bentler, and Yuan (2007)</xref>, in the context of direct maximum likelihood estimation of linear models, explained that this was due to rank deficiency in the more complex model because one column of factor loadings is actually zero. This causes the distribution of the −2LL difference to be shifted to the right of the assumed χ<sup>2</sup>. Rank deficiency should also be a problem for the bifactor model when the true loadings on the testlet factor are all zero. Nevertheless, because the difference test is recommended for the bifactor model in the software guide and other recent sources (<xref ref-type="bibr" rid="bibr6-0146621612437403">Bock &amp; Gibbons, 2010</xref>; <xref ref-type="bibr" rid="bibr10-0146621612437403">Cai, 2010</xref>; <xref ref-type="bibr" rid="bibr16-0146621612437403">Gibbons &amp; Hedeker, 1992</xref>), it was included in this study to assess how badly the difference in −2LL might depart from the χ<sup>2</sup> distribution.</p>
</sec>
<sec id="section4-0146621612437403">
<title>Testfact and Information Criteria for Model Selection</title>
<p>In addition to statistical significance testing, the models can be compared based on information criteria, including Akaike’s Information Criterion (AIC; <xref ref-type="bibr" rid="bibr2-0146621612437403">Akaike, 1987</xref>), Bayesian Information Criterion (BIC; <xref ref-type="bibr" rid="bibr38-0146621612437403">Schwarz, 1978</xref>), and the sample-size adjusted BIC (SSA-BIC; <xref ref-type="bibr" rid="bibr39-0146621612437403">Sclove, 1987</xref>). Instead of testing whether the more complex model fits <italic>significantly</italic> better, these indices compare which model fits better, after a penalty for the number of parameters (<italic>p</italic>) estimated, with no statistical significance test:</p>
<p>
<disp-formula id="disp-formula3-0146621612437403">
<mml:math display="block" id="math4-0146621612437403">
<mml:mrow>
<mml:mtext>AIC</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mtext>LL</mml:mtext>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:mi>p</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0146621612437403" xlink:href="10.1177_0146621612437403-eq3.tif"/>
</disp-formula>
</p>
<p>The AIC is not asymptotically consistent (<xref ref-type="bibr" rid="bibr8-0146621612437403">Bozdogan, 1987</xref>; <xref ref-type="bibr" rid="bibr49-0146621612437403">Woodroofe, 1982</xref>); it does not take the sample size (<italic>N</italic>) into account and thus does <italic>not</italic> become increasingly accurate with sample size. Instead, it tends to favor more complex models with larger sample sizes. To address this issue, with the BIC and SSA-BIC, the penalty for model complexity increases for large samples:</p>
<p>
<disp-formula id="disp-formula4-0146621612437403">
<mml:math display="block" id="math5-0146621612437403">
<mml:mrow>
<mml:mtext>BIC</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mtext>LL</mml:mtext>
<mml:mo>+</mml:mo>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>ln</mml:mtext>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0146621612437403" xlink:href="10.1177_0146621612437403-eq4.tif"/>
</disp-formula>
</p>
<p>The BIC is asymptotically consistent (<xref ref-type="bibr" rid="bibr17-0146621612437403">Haughton, 1988</xref>; <xref ref-type="bibr" rid="bibr38-0146621612437403">Schwarz, 1978</xref>; <xref ref-type="bibr" rid="bibr49-0146621612437403">Woodroofe, 1982</xref>). In the SSA-BIC, <italic>N</italic> is replaced with (<italic>N</italic>+ 2)/24, so the sample-size adjustment is less severe. The AIC, BIC, and SSA-BIC are transformations of the −2LL, so lower values indicate better fit. When using these model comparison indices, the model with the lowest value is selected—there is no statistical significance test. These indices are not included in the Testfact output but can easily be calculated from the −2LL.</p>
<p>The information-criterion indices can be used to compare any models estimated by maximum likelihood. One study specifically used information-based indices with the bifactor model: Y. <xref ref-type="bibr" rid="bibr30-0146621612437403">Li and Rupp (2011)</xref> found that the mean AIC and BIC were both lower (better) for the bifactor model than the unidimensional model when the data were generated from a bifactor model. They did not report the percentage of data sets for which the AIC and BIC were lower.</p>
<p>Several other researchers have applied the AIC and BIC in other IRT contexts, although not specifically for the bifactor model. <xref ref-type="bibr" rid="bibr33-0146621612437403">McKinley (1989)</xref> studied the AIC and the consistent AIC (CAIC, similar to the BIC) for selecting multidimensional models. For a unidimensional data set, the AIC was lower for a more complex model, and for a three-dimensional data set both indices chose the correct model. <xref ref-type="bibr" rid="bibr23-0146621612437403">Kang and Cohen (2007)</xref> compared 1 parameter logistic (1PL), 2PL, and 3PL unidimensional models. Both AIC and BIC were effective when the true model was the 1PL or 2PL. But when data followed a 3PL model, the BIC always erroneously preferred the 1PL or 2PL, and the AIC also tended to choose the 2PL when the test was easy and had few examinees near the lower asymptote. <xref ref-type="bibr" rid="bibr24-0146621612437403">Kang, Cohen, and Sung (2009)</xref> used the AIC and BIC to compare polytomous IRT models; the BIC was more accurate. F. <xref ref-type="bibr" rid="bibr27-0146621612437403">Li, Cohen, Kim, and Cho (2009)</xref> compared the AIC and BIC, as well as several Bayesian indices, for selecting IRT mixture models. BIC was generally most accurate; as sample size increased, AIC tended to favor more complex models.</p>
<p>The information-criterion indices have also been applied with real data to choose among IRT models. <xref ref-type="bibr" rid="bibr34-0146621612437403">McKinley and Way (1992)</xref> used the AIC and the CAIC to compare multidimensional models for data from an English language test. <xref ref-type="bibr" rid="bibr22-0146621612437403">Janssen and De Boeck (1999)</xref> compared multidimensional IRT models for tests of synonyms with the AIC and CAIC. <xref ref-type="bibr" rid="bibr40-0146621612437403">Semmes, Davison, and Close (2011)</xref> used the AIC and BIC to compare a model with a random effect for ability to a model with an additional fixed effect for speed and a model with random effects for both ability and speed.</p>
<p>The SSA-BIC has not seen widespread use in IRT, but it appears to be reasonably effective in selecting the number of latent classes in mixture modeling or latent class analysis (<xref ref-type="bibr" rid="bibr35-0146621612437403">Nylund, Asparouhov, &amp; Muthén, 2007</xref>; <xref ref-type="bibr" rid="bibr50-0146621612437403">Yang, 2006</xref>; <xref ref-type="bibr" rid="bibr51-0146621612437403">Yang &amp; Yang, 2007</xref>). The SSA-BIC penalty for estimating additional parameters is greater than the AIC penalty but less than the BIC penalty. Thus, the SSA-BIC is less likely than the AIC, but more likely than the BIC, to choose the more complex model with increasing sample size. <xref ref-type="bibr" rid="bibr50-0146621612437403">Yang (2006)</xref> found the BIC and SSA-BIC were comparable at sample sizes of 1,000, but the SSA-BIC was more accurate at sample sizes of 500, where the BIC tended to choose the model with fewer parameters. In Nylund et al., the BIC and SSA-BIC were very accurate with samples of 500 or 1,000, but with samples of 200 the SSA-BIC showed a tendency to erroneously pick more complex models, although to a lesser extent than the AIC.</p>
</sec>
<sec id="section5-0146621612437403">
<title>Dimtest and Essential Unidimensionality</title>
<p>Bifactor models are not the only approach for modeling testlets. Sometimes polytomous IRT models are used (<xref ref-type="bibr" rid="bibr5-0146621612437403">Bishop &amp; Omar, 2002</xref>; <xref ref-type="bibr" rid="bibr31-0146621612437403">Marais &amp; Andrich, 2008a</xref>; <xref ref-type="bibr" rid="bibr41-0146621612437403">Sireci et al., 1991</xref>; <xref ref-type="bibr" rid="bibr54-0146621612437403">Zenisky, Hambleton, &amp; Sireci, 2002</xref>), with all items in the testlet treated as a single item. Either the items are summed so an ordinal model may be used or each response pattern within the testlet is treated as a separate item response for a nominal model. This approach is more consistent with the conceptualization of the correlations as local dependence. Yet another approach is to use observed number-correct scores and adjust the reliability estimate for the dependency (<xref ref-type="bibr" rid="bibr41-0146621612437403">Sireci et al., 1991</xref>). If one plans to use either polytomous IRT or number-correct scoring, the testlet effects could be assessed by a test for essential unidimensionality. <xref ref-type="bibr" rid="bibr21-0146621612437403">Jang and Roussos (2007)</xref> used this approach to check each of the passage-based testlets on a reading comprehension test.</p>
<p><xref ref-type="bibr" rid="bibr42-0146621612437403">Stout (1987)</xref> used the term <italic>essential unidimensionality</italic> to indicate zero mean covariances among the responses, conditional on the primary trait. This is a necessary, but not sufficient, condition for strict conditional independence. Dimtest (<xref ref-type="bibr" rid="bibr43-0146621612437403">Stout, 2005</xref>) tests whether the average interitem covariance for items within the assessment test differs from zero after controlling for scores on the partitioning test. The assessment test is the cluster of items suspected of measuring a secondary dimension; in this context, a testlet would comprise an assessment test. The partitioning test is either the remaining items or a designated group of items believed to be unidimensional. Calculation of Stout’s <italic>T</italic> begins by segmenting the examinees by their score on all items except the items in testlet <italic>g</italic>. Within each score group <italic>k</italic>, <inline-formula id="inline-formula2-0146621612437403">
<mml:math display="inline" id="math6-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>T<sub>L,k</sub></italic> is the sum of the interitem covariances for testlet <italic>g</italic> within score group <italic>k</italic>, calculated as the difference between <inline-formula id="inline-formula3-0146621612437403">
<mml:math display="inline" id="math7-0146621612437403">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>, the variance of the testlet <italic>g</italic> scores, and <inline-formula id="inline-formula4-0146621612437403">
<mml:math display="inline" id="math8-0146621612437403">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>, the sum of the item variances for group <italic>k</italic> for the items within testlet <italic>g</italic>. These covariance sums are averaged across the <italic>K</italic> score groups: <inline-formula id="inline-formula5-0146621612437403">
<mml:math display="inline" id="math9-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mrow>
<mml:mo>/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>S<sub>k</sub></italic> is the standard deviation of <italic>T<sub>L,k</sub></italic> (see <xref ref-type="bibr" rid="bibr44-0146621612437403">Stout, Froelich, &amp; Gao, 2001</xref>, for the calculation of the standard deviation). For short tests, <italic>T<sub>L</sub></italic> is positively biased. A bias correction, <inline-formula id="inline-formula6-0146621612437403">
<mml:math display="inline" id="math10-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, is calculated using simulation methods (<xref ref-type="bibr" rid="bibr44-0146621612437403">Stout et al., 2001</xref>). The test statistic is <inline-formula id="inline-formula7-0146621612437403">
<mml:math display="inline" id="math11-0146621612437403">
<mml:mrow>
<mml:mi>T</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mo>¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>G</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>/</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:mrow>
</mml:math>
</inline-formula>, where <italic>N</italic> is the number of examinees. After this bias correction, Stout’s <italic>T</italic> approximates a <italic>Z</italic> distribution when the null hypothesis is true.</p>
</sec>
<sec id="section6-0146621612437403">
<title>Other Methods for Assessing Testlet Dependency</title>
<p>Testlets have also been approached by examining the dependence of pairs of items within the testlet. <xref ref-type="bibr" rid="bibr52-0146621612437403">Yen (1984</xref>, <xref ref-type="bibr" rid="bibr53-0146621612437403">1993)</xref> proposed <italic>Q</italic><sub>3</sub> as an index of whether a pair of items was locally dependent. <italic>Q</italic><sub>3</sub> is simply the linear correlation between the residuals for item <italic>i</italic> and item <italic>j</italic>. <xref ref-type="bibr" rid="bibr3-0146621612437403">Andrich and Kreiner (2010)</xref> developed another pairwise index of local dependence: the difference in the difficulty parameter of item <italic>j</italic> for those who answered item <italic>i</italic> correctly compared with those who answered item <italic>i</italic> incorrectly. Alternative pairwise indices have also been described in <xref ref-type="bibr" rid="bibr11-0146621612437403">Chen and Thissen (1997)</xref>; in <xref ref-type="bibr" rid="bibr25-0146621612437403">Kim, De Ayala, Ferdous, and Nering (2011)</xref>; and in <xref ref-type="bibr" rid="bibr37-0146621612437403">Rosenbaum (1988)</xref>. Pairwise indices will not be considered further here; instead, the focus is on the testlet level for testlets containing more than two items.</p>
</sec>
</sec>
<sec id="section7-0146621612437403" sec-type="methods">
<title>Method</title>
<sec id="section8-0146621612437403">
<title>Data Simulation</title>
<p>Three test forms were simulated: a 25-item test with 5 items within each of 5 testlets, a 50-item test, with 5 items within each of 10 testlets, and a 50-item test with 10 items within each of 5 testlets. The two 50-item conditions allowed the exploration of increasing the number of testlets compared with increasing the number of items within testlets. Item responses followed the bifactor model as specified in <xref ref-type="disp-formula" rid="disp-formula1-0146621612437403">Equation 1</xref>. Different item parameters were randomly selected for each replication. The <italic>d</italic>-parameters were randomly selected from a normal distribution with mean equal to 0 and standard deviation equal to 1, restricted to the range −3 to 3. All <italic>c</italic>-parameters were given a value of 0.2. The natural logs of the <italic>a</italic><sub>P</sub>-parameters were randomly selected from a normal distribution with mean equal to 0 and standard deviation equal to 0.5, with the resulting <italic>a</italic><sub>P</sub>-parameters restricted to the range 0.5 to 2.0.</p>
<p>The ratio <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> was set to a constant within each testlet, to make it simple to quantify the extent of the testlet effect. This made the bifactor model equivalent to the random-effects testlet model (standard deviation of γ = <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub>, <italic>b</italic> = <italic>d</italic>/<italic>a</italic><sub>P</sub>). The ratios were (0.0, 0.3, 0.6, 0.9, 1.2). When there were 10 testlets, 2 testlets had the same ratio, for convenience in summarizing the results, but they were related to independent θ<sub>T</sub>. These ratios were within the ranges reported in the literature. For example, on an analytical reasoning test, Y. <xref ref-type="bibr" rid="bibr29-0146621612437403">Li et al. (2006)</xref> reported γ variances of 1.27, 0.75, 0.82, and 2.10, equivalent to <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 1.13, 0.87, 0.91, and 1.45. On two verbal tests, <xref ref-type="bibr" rid="bibr46-0146621612437403">Wainer, Bradlow, and Du (2000)</xref> reported estimated γ variances ranging from 0.11 to 0.96, corresponding to <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ranging from 0.33 to 0.98. A ratio of 0 indicates that the items within the testlet share no variance beyond that attributable to the primary factor, and a ratio greater than 1 indicates that the testlet trait has more influence on the response than the primary trait.</p>
<p>First, to assess the Type I error rate for the significance tests and the false alarm rate for the information-criterion indices, all <italic>a</italic><sub>T</sub> were set to zero for all 5 or 10 testlets. Next, in one set of the studies, only one of the 5 or 10 testlets at a time had nonzero <italic>a</italic><sub>T</sub>. For one set of replications, <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 0.3 for one testlet while <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 0 for the other testlets, followed by another set of replications where <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 0.6 for one testlet while <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 0 for the other testlets, and so on. This methodology is analogous to testing an item for differential item functioning (DIF) when all other items are DIF free. Finally, in another set of studies, each testlet had a different <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> at the same time. This more realistic set allowed for testing each testlet effect in the presence of effects in other testlets.</p>
<p>Data for 2,000 examinees was simulated 1,000 times for each of the conditions. For each simulee, θ<sub>P</sub> and each element of the vector θ<sub>T</sub> were drawn from independent distributions, <italic>N</italic>(0, 1). Probability of correct response was calculated from θ<sub>P</sub>, θ<sub>T</sub>, <italic>a</italic><sub>T</sub>, <italic>a</italic><sub>P</sub>, and <italic>d</italic>, and the simulated response was coded correct if the probability was greater than a random draw from a uniform (0, 1) distribution.</p>
</sec>
<sec id="section9-0146621612437403">
<title>Testfact and −2LL</title>
<p>Two pairs of models were run for each of the data sets: the unidimensional model versus the single-testlet bifactor model and the all-but-one bifactor model versus the complete bifactor model.</p>
<p>Default prior distributions and starting values were used for the <italic>a<sub>P</sub></italic>, <italic>a</italic><sub>T</sub>, and <italic>d</italic>-parameters. Although the data were simulated with a constant within-testlet <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio, the ratio was not fixed in the estimation. In real data, a constant <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio may not fit well (Y. <xref ref-type="bibr" rid="bibr29-0146621612437403">Li et al., 2006</xref>; <xref ref-type="bibr" rid="bibr36-0146621612437403">Rijmen, 2010</xref>); it was only fixed in the generation of the data so that the extent of the testlet effect could systematically vary over testlets. The <italic>c</italic>-parameters were fixed to the true value of 0.2. The maximum number of expectation-maximization (EM) cycles was increased to 100, with a stopping criterion of .005. Nine quadrature points were used for each dimension (81 points in total because no item loaded on more than two dimensions).</p>
<p>Statistical significance was tested with the difference between the models in −2LL, at α = .01. The null hypothesis was as follows:</p>
<p>
<disp-formula id="disp-formula5-0146621612437403">
<mml:math display="block" id="math12-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>H</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>:</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mtext>L</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>L</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>reduced</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mtext>L</mml:mtext>
<mml:msub>
<mml:mrow>
<mml:mtext>L</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mtext>full</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0146621612437403" xlink:href="10.1177_0146621612437403-eq5.tif"/>
</disp-formula>
</p>
<p>In the single-testlet conditions, the reduced model was the unidimensional model and the full model was a bifactor model with all items loading on the primary factor and the items for the studied testlet additionally loading on a secondary factor. In the all-but-one conditions, the reduced model was a bifactor model with a secondary factor for each testlet <italic>except</italic> the studied testlet, whose items loaded only on the primary factor. The full model included secondary factors for every testlet. The difference was compared to a χ<sup>2</sup> distribution, with degrees of freedom equal to 5 or 10, the testlet length.</p>
<p>In addition, the same full and reduced models were compared using the AIC, BIC, and SSA-BIC, calculated from the −2LL. For each index, the model with the lower value had better fit. These model comparisons do not involve statistical significance testing.</p>
</sec>
<sec id="section10-0146621612437403">
<title>Dimtest’s Test of Essential Unidimensionality</title>
<p>As in Testfact, each testlet was tested separately in Dimtest. The studied testlet was used as the assessment test and all other items comprised the partitioning test, with a minimum cell size of two. The true <italic>c</italic> of 0.2 was specified. For the bias correction, 50 kernel-smoothing points and 100 replications were used. Stout’s <italic>T</italic> statistic, as printed in the output, was used to compute Type I error or power, at α = .01. A total of 5 or 10 comparisons, one for each testlet, were conducted for each replication of each condition.</p>
<p>Conceptually, the null hypothesis corresponding to <italic>T</italic> = 0 is</p>
<p>
<disp-formula id="disp-formula6-0146621612437403">
<mml:math display="block" id="math13-0146621612437403">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mtext>H</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>:</mml:mo>
<mml:mi>Σ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>PT</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0146621612437403" xlink:href="10.1177_0146621612437403-eq6.tif"/>
</disp-formula>
</p>
<p>where <italic>PT</italic> is the true score on the partitioning test and the mean conditional covariance is taken over all items <italic>i</italic> and <italic>j</italic> within testlet <italic>g</italic>, and integrated (averaged) over all values of <italic>PT</italic>. <italic>T</italic> is approximately normally distributed under the null hypothesis.</p>
</sec>
</sec>
<sec id="section11-0146621612437403" sec-type="results">
<title>Results</title>
<sec id="section12-0146621612437403">
<title>False Alarm Rates When No Testlet Had Nonzero <italic>a</italic>-Parameters</title>
<p>The hit rate for this study was defined as the proportion of times that the more complex model was selected. This selection was through the statistical significance test for the −2LL difference and for the Dimtest statistic. For the AIC, SSA-BIC, and BIC, the model with the lowest value was selected. The terms <italic>Type I error</italic> and <italic>power</italic> do not strictly apply to these latter comparisons; the more generic terms <italic>false alarm rate</italic> and <italic>true hit rate</italic> would be more correct. However, for clarity, the term <italic>power</italic> is sometimes used here for the true hit rate. When the <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio was 0, selection of the more complex model was termed a false alarm (false positive, false hit). For the other <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratios, this was termed a true hit.</p>
<p>First, the false alarm rates or Type I error rates were calculated for conditions where the data were unidimensional. <xref ref-type="table" rid="table1-0146621612437403">Table 1</xref> shows these false alarm rates. In the case of the test of the difference in −2LL and Stout’s <italic>T</italic> in Dimtest, which are statistical significance tests, this is the empirical Type I error rate. The nominal Type I error rate was .01. The Testfact difference in −2LL test was liberal, and was similar for the two pairs of models (unidimensional vs. one testlet, all-but-one vs. complete). It became more liberal when the test length increased, and it was worse with 5 testlets of 10 items than with 10 testlets of 5 items. There was more capitalization on chance for longer testlets. For Dimtest, the Type I error rate was lower than the nominal rate for all three test forms. The AIC erroneously accepted the more complex model far too frequently, following the same pattern as the difference in −2LL test. Use of the BIC and SSA-BIC seldom led to false selection of the more complex model.</p>
<table-wrap id="table1-0146621612437403" position="float">
<label>Table 1.</label>
<caption>
<p>False Alarm Rate When No Testlet Has Nonzero <italic>a</italic><sub>T</sub> / <italic>a</italic><sub>P</sub></p>
</caption>
<graphic alternate-form-of="table1-0146621612437403" xlink:href="10.1177_0146621612437403-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="9">Index</th>
</tr>
<tr>
<th/>
<th align="center" colspan="8">Testfact</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="4">Unidimensional–single testlet</th>
<th align="center" colspan="4">All-but-one–complete</th>
<th align="center">Dimtest</th>
</tr>
<tr>
<th/>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn2-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn2-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center"><italic>T<sup><xref ref-type="table-fn" rid="table-fn2-0146621612437403">a</xref></sup></italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>25 items: 5 testlets</td>
<td>.024</td>
<td>.142</td>
<td>.000</td>
<td>.000</td>
<td>.027</td>
<td>.150</td>
<td>.000</td>
<td>.001</td>
<td>.007</td>
</tr>
<tr>
<td>50 items: 10 testlets (5 items per testlet)</td>
<td>.049</td>
<td>.220</td>
<td>.001</td>
<td>.006</td>
<td>.036</td>
<td>.174</td>
<td>.000</td>
<td>.003</td>
<td>.003</td>
</tr>
<tr>
<td>50 items: 5 testlets (10 items per testlet)</td>
<td>.210</td>
<td>.347</td>
<td>.000</td>
<td>.001</td>
<td>.173</td>
<td>.295</td>
<td>.000</td>
<td>.000</td>
<td>.000</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0146621612437403">
<p>Note: LL = log likelihood; AIC = Akaike’s Information Criterion; BIC = Bayesian Information Criterion; SSA-BIC = sample-size adjusted BIC.</p>
</fn>
<fn id="table-fn2-0146621612437403">
<label>a</label>
<p>The false alarm rate is the Type I error rate for the −2LL difference test and for Stout’s <italic>T</italic>, with nominal α = .01.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The −2LL difference test is purported to follow a χ<sup>2</sup> distribution, and the Dimtest <italic>T</italic> is tested against a <italic>Z</italic> distribution. The values in <xref ref-type="table" rid="table1-0146621612437403">Table 1</xref> only provide information about the tail of the test statistic distribution. <xref ref-type="fig" rid="fig1-0146621612437403">Figure 1</xref> compares the empirical distribution of the −2LL difference test to a χ<sup>2</sup> distribution with 5 or 10 degrees of freedom as appropriate. When there were 25 items in 5 testlets, the −2LL was a bit less skewed than the χ<sup>2</sup> distribution, pulling more of the distribution into the rejection range in the right tail. This effect became somewhat worse when the test length was increased by adding more testlets (50 items, 10 testlets), but it became much worse when the test length was increased by adding more items per testlet (50 items, 5 testlets). For longer testlets with 10 items, the distribution did not remotely follow a χ<sup>2</sup> distribution with 10 degrees of freedom.</p>
<fig id="fig1-0146621612437403" position="float">
<label>Figure 1.</label>
<caption>
<p>Distribution of the difference in −2 log likelihood (−2LL) when <italic>a</italic><sub>T</sub> = 0 for all items in all testlets</p>
<p>Note: In the left panels, a unidimensional model is compared with a model with <italic>a</italic><sub>T</sub> for items in one testlet. In the right panels, a model with <italic>a</italic><sub>T</sub> for all items except those in the studied testlet is compared with a model with <italic>a</italic><sub>T</sub> for all items.</p>
</caption>
<graphic xlink:href="10.1177_0146621612437403-fig1.tif"/>
</fig>
<p>The left panel of <xref ref-type="fig" rid="fig2-0146621612437403">Figure 2</xref> shows comparable information for Dimtest. Stout’s <italic>T</italic> was slightly more leptokurtic than <italic>Z</italic>, so fewer replications fell in the rejection range. With the 25-item, five-testlet form, however, this was counteracted because the empirical distribution was slightly off-center, providing a good match in the right tail.</p>
<fig id="fig2-0146621612437403" position="float">
<label>Figure 2.</label>
<caption>
<p>Distribution of the test statistic for Dimtest</p>
<p>Note: In the left panel, none of the testlets have <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> &gt; 0. In the right panel, the studied testlet has <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 0, but the other testlets have <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> &gt; 0.</p>
</caption>
<graphic xlink:href="10.1177_0146621612437403-fig2.tif"/>
</fig>
</sec>
<sec id="section13-0146621612437403">
<title>Power Rates When Only One Testlet Per Form Had Nonzero <italic>a</italic>-Parameters</title>
<p><xref ref-type="table" rid="table2-0146621612437403">Table 2</xref> shows the hit rates, or power rates, for the test forms in which all testlets except the studied testlet had testlet <italic>a</italic>-parameters of zero. The studied testlet had an <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio ranging from 0.3 (a small testlet effect) to 1.2 (true testlet discriminations were higher than true primary discriminations—a large testlet effect). Within each test form, <italic>a</italic><sub>T</sub> was 0 for all testlets except the studied testlet, with different data sets generated for studying each testlet in turn. All cells in the conditions with five testlets were based on 1,000 replications; cells in the conditions with 10 testlets were based on 2,000 replications because results were combined for the testlets with the same <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio.</p>
<table-wrap id="table2-0146621612437403" position="float">
<label>Table 2.</label>
<caption>
<p>Hit Rate (Power) When Only the Studied Testlet Has Nonzero <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub></p>
</caption>
<graphic alternate-form-of="table2-0146621612437403" xlink:href="10.1177_0146621612437403-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="9">Index</th>
</tr>
<tr>
<th/>
<th align="center" colspan="8">Testfact</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="4">Unidimensional–single testlet</th>
<th align="center" colspan="4">All-but-one–complete</th>
<th align="center">Dimtest</th>
</tr>
<tr>
<th align="left"><italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> for studied testlet</th>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn4-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn4-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center"><italic>T<sup><xref ref-type="table-fn" rid="table-fn4-0146621612437403">a</xref></sup></italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="10">25 items: 5 testlets</td>
</tr>
<tr>
<td> 0.3</td>
<td>0.440</td>
<td>0.671</td>
<td>0.016</td>
<td>0.189</td>
<td>0.413</td>
<td>0.661</td>
<td>0.016</td>
<td>0.168</td>
<td>0.158</td>
</tr>
<tr>
<td> 0.6</td>
<td>0.995</td>
<td>0.999</td>
<td>0.919</td>
<td>0.980</td>
<td>0.995</td>
<td>0.998</td>
<td>0.913</td>
<td>0.977</td>
<td>0.912</td>
</tr>
<tr>
<td> 0.9</td>
<td>1.000</td>
<td>1.000</td>
<td>0.999</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>.999</td>
<td>1.000</td>
<td>0.997</td>
</tr>
<tr>
<td> 1.2</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td colspan="10">50 items: 10 testlets (5 items per testlet)</td>
</tr>
<tr>
<td> 0.3</td>
<td>0.604</td>
<td>0.821</td>
<td>0.072</td>
<td>0.364</td>
<td>0.561</td>
<td>0.788</td>
<td>0.059</td>
<td>0.331</td>
<td>0.224</td>
</tr>
<tr>
<td> 0.6</td>
<td>0.999</td>
<td>1.000</td>
<td>0.949</td>
<td>0.992</td>
<td>0.999</td>
<td>1.000</td>
<td>0.942</td>
<td>0.990</td>
<td>0.969</td>
</tr>
<tr>
<td> 0.9</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td> 1.2</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td colspan="10">50 items: 5 testlets (10 items per testlet)</td>
</tr>
<tr>
<td> 0.3</td>
<td>0.979</td>
<td>0.989</td>
<td>0.261</td>
<td>0.762</td>
<td>0.973</td>
<td>0.982</td>
<td>0.206</td>
<td>0.708</td>
<td>0.654</td>
</tr>
<tr>
<td> 0.6</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td> 0.9</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td> 1.2</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0146621612437403">
<p>Note: LL = log likelihood; AIC = Akaike’s Information Criterion; BIC = Bayesian Information Criterion; SSA-BIC = sample-size adjusted BIC.</p>
</fn>
<fn id="table-fn4-0146621612437403">
<label>a</label>
<p>Nominal α = .01 for −2LL difference test and for Stout’s <italic>T</italic>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Hit rates should increase as the <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio increases. Power was very high for all indices when the <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio was 0.6 or higher. For the smallest <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio of 0.3, the AIC was the most powerful but it should not be trusted due to its high false alarm rate. The −2LL difference test had the next highest power, but again it was too liberal in the null condition, especially with longer testlets, so the power rate is misleading. SSA-BIC and Dimtest had roughly comparable power for the ratio of 0.3, much higher than BIC.</p>
</sec>
<sec id="section14-0146621612437403">
<title>False Alarm Rates When Other Testlets Had Nonzero <italic>a</italic>-Parameters</title>
<p>In <xref ref-type="table" rid="table3-0146621612437403">Table 3</xref>, <italic>a</italic><sub>T</sub> = 0 for the studied testlet, but it ranged from 0.3 to 1.2 for the other testlets in the same data set. This is somewhat like testing for DIF when the total score is contaminated by other DIF items. For the test of the all-but-one model versus the complete model, the false alarm rates for the −2LL difference test and the information criteria were similar to the false alarm rates in <xref ref-type="table" rid="table1-0146621612437403">Table 1</xref>. But the false alarm rates for the unidimensional model versus the single testlet model, and for Dimtest, were much larger than those in <xref ref-type="table" rid="table1-0146621612437403">Table 1</xref>. <xref ref-type="fig" rid="fig3-0146621612437403">Figure 3</xref> shows the empirical distribution of the −2LL difference test for the testlets with <italic>a</italic><sub>T</sub> = 0. In the left panel, the distributions for the unidimensional model versus the single testlet model are clearly quite far from the χ<sup>2</sup> distribution. In the right panel, the distribution for the all-but-one-testlet versus complete testlet model is similar to <xref ref-type="fig" rid="fig1-0146621612437403">Figure 1</xref>. The right panel of <xref ref-type="fig" rid="fig2-0146621612437403">Figure 2</xref> shows the empirical distribution of Stout’s <italic>T</italic> for the testlets with <italic>a</italic><sub>T</sub> = 0. The distribution is pulled to the right, and the effect is worse with fewer but longer testlets.</p>
<table-wrap id="table3-0146621612437403" position="float">
<label>Table 3.</label>
<caption>
<p>False Alarm Rate When <italic>a</italic><sub>T</sub> = 0 for the Studied Testlet but Other Testlets Have Nonzero <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub></p>
</caption>
<graphic alternate-form-of="table3-0146621612437403" xlink:href="10.1177_0146621612437403-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="9">Index</th>
</tr>
<tr>
<th/>
<th align="center" colspan="8">Testfact</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="4">Unidimensional–single testlet</th>
<th align="center" colspan="4">All-but-one–complete</th>
<th align="center">Dimtest</th>
</tr>
<tr>
<th/>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn6-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn6-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center"><italic>T</italic><sup><xref ref-type="table-fn" rid="table-fn6-0146621612437403">a</xref></sup></th>
</tr>
</thead>
<tbody>
<tr>
<td>25 items: 5 testlets</td>
<td>.491</td>
<td>.722</td>
<td>.050</td>
<td>.277</td>
<td>.021</td>
<td>.110</td>
<td>.000</td>
<td>.000</td>
<td>.252</td>
</tr>
<tr>
<td>50 items: 10 testlets (5 items per testlet)</td>
<td>.163</td>
<td>.421</td>
<td>.001</td>
<td>.048</td>
<td>.037</td>
<td>.150</td>
<td>.000</td>
<td>.003</td>
<td>.044</td>
</tr>
<tr>
<td>50 items: 5 testlets (10 items per testlet)</td>
<td>.993</td>
<td>.997</td>
<td>.491</td>
<td>.909</td>
<td>.136</td>
<td>.267</td>
<td>.000</td>
<td>.001</td>
<td>.871</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0146621612437403">
<p>Note: LL = log likelihood; AIC = Akaike’s Information Criterion; BIC = Bayesian Information Criterion; SSA-BIC = sample-size adjusted BIC.</p>
</fn>
<fn id="table-fn6-0146621612437403">
<label>a</label>
<p>Nominal α = .01 for −2LL difference test and for Stout’s <italic>T</italic>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig3-0146621612437403" position="float">
<label>Figure 3.</label>
<caption>
<p>Distribution of the difference in −2LL when <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> &gt; 0 in all testlets except the studied testlet</p>
<p>Note: In the left panels, a unidimensional model is compared with a model with <italic>a</italic><sub>T</sub> for items in one testlet. In the right panels, a model with <italic>a</italic><sub>T</sub> for all items except those in the studied testlet is compared with a model with <italic>a</italic><sub>T</sub> for all items.</p>
</caption>
<graphic xlink:href="10.1177_0146621612437403-fig3.tif"/>
</fig>
<p>The problem with all of the model comparisons of the unidimensional model to a single testlet is that, if some of the other testlets have nonzero <italic>a</italic><sub>T</sub>, the θ measured by the unidimensional model is not the θ<sub>P</sub> used to generate the data. Instead, θ from the unidimensional model is a composite of θ<sub>P</sub> and the vector of θ<sub>T</sub>. The unidimensional composite measured mostly in the direction of θ<sub>P</sub> but was somewhat deflected toward the testlets with higher <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratios. This effect was stronger when each testlet contained 20% of the total test items, compared with 10% of the items.<sup><xref ref-type="fn" rid="fn2-0146621612437403">2</xref></sup> All shared variance among the items in the testlet with <italic>a</italic><sub>T</sub> = 0 was due to θ<sub>P</sub>, but because the unidimensional θ was not completely aligned with θ<sub>P</sub>, the responses to the items in the testlet had a small amount of shared variance not explained by the estimated unidimensional θ. The same phenomenon occurs in Dimtest. The observed score on the partitioning test measures a composite of the primary trait and the other testlet traits, so the items measuring only the primary trait have some covariance after controlling for the partitioning test score. This could be avoided by including only one item from each suspected testlet on the partitioning test, but in this context that would mean only four items could compose the partitioning test in the five testlet conditions. The partitioning test would become a purer measure of the primary trait as either the number of testlets increased, the number of items per testlet decreased, or the maximum <italic>a</italic><sub>T</sub> decreased.</p>
</sec>
<sec id="section15-0146621612437403">
<title>Power Rates When Multiple Testlets Had Nonzero <italic>a</italic>-Parameters</title>
<p>The true hit rate, or power, is reported in <xref ref-type="table" rid="table4-0146621612437403">Table 4</xref> for each testlet when tested in the presence of other testlet effects. Again, within each test form, each testlet had a different <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio; power should increase as the ratio increases. However, these power rates could be spurious for any index which showed an inflated false alarm rate in <xref ref-type="table" rid="table3-0146621612437403">Table 3</xref>. Only the BIC and SSA-BIC when used with the all-but-one model versus the complete model had acceptable false alarm rates. These indices had high power when the <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> ratio was 0.6 or higher. For <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub> = 0.3, the power for these indices appeared to be somewhat lower than it was when only the studied testlet has nonzero <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub>.</p>
<table-wrap id="table4-0146621612437403" position="float">
<label>Table 4.</label>
<caption>
<p>Hit Rate (Power) When Each Testlet Within the Test Form Has a Different <italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub></p>
</caption>
<graphic alternate-form-of="table4-0146621612437403" xlink:href="10.1177_0146621612437403-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="9">Index</th>
</tr>
<tr>
<th/>
<th align="center" colspan="8">Testfact</th>
<th/>
</tr>
<tr>
<th/>
<th align="center" colspan="4">Unidimensional–single testlet</th>
<th align="center" colspan="4">All-but-one–complete</th>
<th align="center">Dimtest</th>
</tr>
<tr>
<th align="left"><italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub></th>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn8-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center">−2LL diff<sup><xref ref-type="table-fn" rid="table-fn8-0146621612437403">a</xref></sup></th>
<th align="center">AIC</th>
<th align="center">BIC</th>
<th align="center">SSA-BIC</th>
<th align="center"><italic>T</italic><sup><xref ref-type="table-fn" rid="table-fn8-0146621612437403">a</xref></sup></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="10">25 items: 5 testlets</td>
</tr>
<tr>
<td> 0.3</td>
<td>0.904</td>
<td>0.956</td>
<td>0.395</td>
<td>0.764</td>
<td>0.258</td>
<td>0.537</td>
<td>0.004</td>
<td>0.068</td>
<td>0.549</td>
</tr>
<tr>
<td> 0.6</td>
<td>0.999</td>
<td>1.000</td>
<td>0.968</td>
<td>0.993</td>
<td>0.989</td>
<td>0.999</td>
<td>0.852</td>
<td>0.966</td>
<td>0.951</td>
</tr>
<tr>
<td> 0.9</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>0.999</td>
<td>1.000</td>
<td>0.993</td>
</tr>
<tr>
<td> 1.2</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td colspan="10">50 items: 10 testlets (5 items per testlet)</td>
</tr>
<tr>
<td> 0.3</td>
<td>0.756</td>
<td>0.903</td>
<td>0.178</td>
<td>0.532</td>
<td>0.461</td>
<td>0.700</td>
<td>0.026</td>
<td>0.223</td>
<td>0.435</td>
</tr>
<tr>
<td> 0.6</td>
<td>1.000</td>
<td>1.000</td>
<td>0.968</td>
<td>0.995</td>
<td>0.997</td>
<td>1.000</td>
<td>0.939</td>
<td>0.990</td>
<td>0.981</td>
</tr>
<tr>
<td> 0.9</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td> 1.2</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td colspan="10">50 items: 5 testlets (10 items per testlet)</td>
</tr>
<tr>
<td> 0.3</td>
<td>1.000</td>
<td>1.000</td>
<td>0.956</td>
<td>0.996</td>
<td>0.873</td>
<td>0.930</td>
<td>0.025</td>
<td>0.343</td>
<td>0.995</td>
</tr>
<tr>
<td> 0.6</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>0.998</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td> 0.9</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
<tr>
<td> 1.2</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn7-0146621612437403">
<p>Note: LL = log likelihood; AIC = Akaike’s Information Criterion; BIC = Bayesian Information Criterion; SSA-BIC = sample-size adjusted BIC.</p>
</fn>
<fn id="table-fn8-0146621612437403">
<label>a</label>
<p>Nominal α = .01 for −2LL difference test and for Stout’s <italic>T</italic>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section16-0146621612437403" sec-type="discussion|conclusions">
<title>Discussion and Conclusion</title>
<p>Due to the complexity of the model, a relatively large sample size (<italic>N</italic> = 2,000) was used. The intent was to explore the procedures with a sample large enough to be realistic for multidimensional IRT so that model estimation difficulties would not be confounded with the accuracy of detecting the testlet trait. Further research is needed to assess performance with smaller samples that might be encountered in research or in certification testing, or with larger samples that might be available in large-scale settings. The BIC and SSA-BIC penalties for sample size might not be equally appropriate for much larger or smaller samples.</p>
<p>Additional testlet configurations also merit further consideration. Some possibilities include shorter testlets or testlets in which some items have zero <italic>a</italic><sub>T</sub> and others have high <italic>a</italic><sub>T</sub> independent of the <italic>a</italic><sub>P</sub>. The test could additionally include independent items not located in testlets and testlets of varying lengths.</p>
<p>Overall, the use of the SSA-BIC with the comparison of the all-but-one model versus the complete model was most accurate. For all of the indices, power or true hit rate was high for detecting testlets in which the testlet discrimination was at least moderately large relative to the primary discrimination (<italic>a</italic><sub>T</sub>/<italic>a</italic><sub>P</sub>≥ 0.6). Thus, failure to reject the null hypothesis, or a lower value of the information-criterion indices for the reduced model, would support a conclusion that the testlet factor was relatively small or nonexistent and the items could be treated as independent items.</p>
<p>In contrast, interpretation of a rejected null, or a lower value of the information-criterion indices for the more complex model, is more problematic. For the unidimensional model versus the single-testlet model in Testfact, and for Dimtest, the null may be rejected either due to a testlet factor in the testlet under consideration, or it may be due to the effects of other testlets distorting the unidimensional θ composite/partitioning test. The test of the all-but-one model versus the complete model purifies θ<sub>P</sub> and thus is not susceptible to this problem. However, the statistical significance test of this model comparison has inflated Type I error, consistent with the explanation in <xref ref-type="bibr" rid="bibr18-0146621612437403">Hayashi et al. (2007)</xref>. The SSA-BIC for this model comparison has both a low false alarm rate and a high true hit rate. Thus, this index appears most promising. However, the SSA-BIC needs to be explored more for the bifactor model or other IRT models before definitive recommendation, as it has not been widely used outside of mixture modeling. If one prefers to err on the side of the less complex model (lower power, essentially), the BIC would be a good choice and has been more widely studied. For both the SSA-BIC and BIC, the magnitude of the penalty for model complexity may not always be appropriate in this context of rank insufficiency when all loadings on the secondary factor are zero, although they did seem to work well in this study.</p>
<p>The need for the study was framed in terms of the bifactor model. An alternative is to treat each testlet as a polytomous item and apply a unidimensional polytomous model (<xref ref-type="bibr" rid="bibr5-0146621612437403">Bishop &amp; Omar, 2002</xref>; <xref ref-type="bibr" rid="bibr31-0146621612437403">Marais &amp; Andrich, 2008a</xref>; <xref ref-type="bibr" rid="bibr41-0146621612437403">Sireci et al., 1991</xref>; <xref ref-type="bibr" rid="bibr54-0146621612437403">Zenisky et al., 2002</xref>). Typically, to use a polytomous model, the item scores are summed within the testlet. When there is no testlet effect, this summation results in a loss of information because the particular pattern of rights and wrongs within the testlet is lost (<xref ref-type="bibr" rid="bibr53-0146621612437403">Yen, 1993</xref>). Although the loss in information from summation will generally be small compared with the spurious inflation of information when ignoring the testlet effect if it exists, it is worthwhile to first test each testlet for dependency before scoring it polytomously. The procedures described here thus could also be used as preliminary to polytomous models with items summed within testlets. Again, because the SSA-BIC for the comparison of the all-but-one model versus the complete model was powerful while controlling false alarms, this index is recommended, with the caution that it has not been widely studied except in the context of mixture modeling.</p>
<p>In some cases, analysts may prefer to model the testlet discriminations (or form summed items) for all testlets if any of the testlet factors are significant. Although this allows for greater capitalization on chance, it is easier to explain conceptually. Dimtest would be an appropriate choice in this situation. It has good power, and when none of the testlets have large effects, the Type I error is well controlled. Alternatively, one could use the SSA-BIC or BIC to compare a unidimensional model with a complete testlet model, instead of testing individual testlets.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0146621612437403">
<label>1.</label>
<p>This model was not developed specifically for testlets. <italic>Testlet trait</italic> is used here instead of Gibbons and Hedecker’s term <italic>group factor</italic> in keeping with the present context.</p>
</fn>
<fn fn-type="other" id="fn2-0146621612437403">
<label>2.</label>
<p>An angle of 0° with θ<sub>P</sub> and 90° with each θ<sub>T</sub> would indicate the composite measured only the primary trait. For the 25-item test and the 50-item test with 5 testlets and 10 items per testlet, the theoretical angle of the composite was 20° with θ<sub>P</sub>, and (90°, 87°, 84°, 80°, 74°) for the θ<sub>T</sub> vector. For the 50-item test with 10 testlets and 5 items per testlet, the angle of the composite was 14° with θ<sub>P</sub>, and (90°, 89°, 87°, 85°, 83°, 90°, 89°, 87°, 85°, 83°) for the θ<sub>T</sub> vector.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0146621612437403">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ackerman</surname><given-names>T. A.</given-names></name>
</person-group> (<year>1987, April</year>). <article-title>The robustness of LOGIST and BILOG IRT estimation programs to violations of local independence</article-title>. <conf-name>Paper presented at the annual meeting of the American Educational Research Association</conf-name>, <conf-loc>Washington, DC</conf-loc>.</citation>
</ref>
<ref id="bibr2-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Akaike</surname><given-names>H.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Factor analysis and AIC</article-title>. <source>Psychometrika</source>, <volume>52</volume>, <fpage>317</fpage>-<lpage>332</lpage>.</citation>
</ref>
<ref id="bibr3-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Andrich</surname><given-names>D.</given-names></name>
<name><surname>Kreiner</surname><given-names>S.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Quantifying response dependence between two dichotomous items using the Rasch model</article-title>. <source>Applied Psychological Measurement</source>, <volume>34</volume>, <fpage>181</fpage>-<lpage>192</lpage>.</citation>
</ref>
<ref id="bibr4-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Berger</surname><given-names>M. P. F.</given-names></name>
<name><surname>Knol</surname><given-names>D. L.</given-names></name>
</person-group> (<year>1990</year>). <source>On the assessment of dimensionality in multidimensional item response theory models</source>. <publisher-loc>Enschede, Netherlands</publisher-loc>: <publisher-name>University of Twente</publisher-name>.</citation>
</ref>
<ref id="bibr5-0146621612437403">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Bishop</surname><given-names>N. S.</given-names></name>
<name><surname>Omar</surname><given-names>M. H.</given-names></name>
</person-group> (<year>2002, April</year>). <article-title>Comparing vertical scales derived from dichotomous and polytomous IRT models for a test composed of testlets</article-title>. <conf-name>Paper presented at the annual meeting of the American Educational Research Association</conf-name>, <conf-loc>New Orleans, LA</conf-loc>.</citation>
</ref>
<ref id="bibr6-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bock</surname><given-names>R. D.</given-names></name>
<name><surname>Gibbons</surname><given-names>R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Factor analysis of categorical item responses</article-title>. In <person-group person-group-type="editor">
<name><surname>Nering</surname><given-names>M. L.</given-names></name>
<name><surname>Ostini</surname><given-names>R.</given-names></name>
</person-group> (Eds.), <source>Handbook of polytomous item response theory models</source> (pp. <fpage>155</fpage>-<lpage>184</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr7-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bock</surname><given-names>R. D.</given-names></name>
<name><surname>Gibbons</surname><given-names>R.</given-names></name>
<name><surname>Schilling</surname><given-names>S. G.</given-names></name>
<name><surname>Muraki</surname><given-names>E.</given-names></name>
<name><surname>Wilson</surname><given-names>D. T.</given-names></name>
<name><surname>Wood</surname><given-names>R.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Testfact (Version 4.0) [Computer software and manual]</article-title>. <publisher-loc>Lincolnwood, IL</publisher-loc>: <publisher-name>Scientific Software International</publisher-name>.</citation>
</ref>
<ref id="bibr8-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bozdogan</surname><given-names>H.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Model selection and Akaike’s information criterion (AIC): The general theory and its analytical extensions</article-title>. <source>Psychometrika</source>, <volume>52</volume>, <fpage>345</fpage>-<lpage>370</lpage>.</citation>
</ref>
<ref id="bibr9-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradlow</surname><given-names>E. T.</given-names></name>
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group> (<year>1999</year>). <article-title>A Bayesian random effects model for testlets</article-title>. <source>Psychometrika</source>, <volume>64</volume>, <fpage>153</fpage>-<lpage>168</lpage>.</citation>
</ref>
<ref id="bibr10-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cai</surname><given-names>L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A two-tier full-information item factor analysis model with applications</article-title>. <source>Psychometrika</source>, <volume>75</volume>, <fpage>581</fpage>-<lpage>612</lpage>.</citation>
</ref>
<ref id="bibr11-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>W.-H.</given-names></name>
<name><surname>Thissen</surname><given-names>D.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Local dependence indexes for item pairs using item response theory</article-title>. <source>Journal of Educational and Behavioral Statistics</source>, <volume>22</volume>, <fpage>265</fpage>-<lpage>289</lpage>.</citation>
</ref>
<ref id="bibr12-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>De Champlain</surname><given-names>A.</given-names></name>
<name><surname>Gessaroli</surname><given-names>M. E.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Assessing the dimensionality of item response matrices with small sample sizes and short test lengths</article-title>. <source>Applied Measurement in Education</source>, <volume>11</volume>, <fpage>231</fpage>-<lpage>253</lpage>.</citation>
</ref>
<ref id="bibr13-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeMars</surname><given-names>C. E.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Detecting multidimensionality due to curricular differences</article-title>. <source>Journal of Educational Measurement</source>, <volume>40</volume>, <fpage>29</fpage>-<lpage>51</lpage>.</citation>
</ref>
<ref id="bibr14-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeMars</surname><given-names>C. E.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Application of the bi-factor multidimensional item response theory model to testlet-based tests</article-title>. <source>Journal of Educational Measurement</source>, <volume>43</volume>, <fpage>145</fpage>-<lpage>168</lpage>.</citation>
</ref>
<ref id="bibr15-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="editor">
<name><surname>duToit</surname><given-names>M.</given-names></name>
</person-group> (Ed.). (<year>2003</year>). <source>IRT from SSI: BILOG-MG, MULTILOG, PARSCALE, TESTFACT</source>. <publisher-loc>Lincolnwood, IL</publisher-loc>: <publisher-name>Scientific Software International</publisher-name>.</citation>
</ref>
<ref id="bibr16-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gibbons</surname><given-names>R. D.</given-names></name>
<name><surname>Hedeker</surname><given-names>D. R.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Full-information bi-factor analysis</article-title>. <source>Psychometrika</source>, <volume>57</volume>, <fpage>423</fpage>-<lpage>436</lpage>.</citation>
</ref>
<ref id="bibr17-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haughton</surname><given-names>D. M. A.</given-names></name>
</person-group> (<year>1988</year>). <article-title>On the choice of a model to fit data from an exponential family</article-title>. <source>Annals of Statistics</source>, <volume>16</volume>, <fpage>342</fpage>-<lpage>355</lpage>.</citation>
</ref>
<ref id="bibr18-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hayashi</surname><given-names>K.</given-names></name>
<name><surname>Bentler</surname><given-names>P. M.</given-names></name>
<name><surname>Yuan</surname><given-names>K.-H.</given-names></name>
</person-group> (<year>2007</year>). <article-title>On the likelihood ratio test for the number of factors in exploratory factor analysis</article-title>. <source>Structural Equation Modeling</source>, <volume>14</volume>, <fpage>505</fpage>-<lpage>526</lpage>.</citation>
</ref>
<ref id="bibr19-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ip</surname><given-names>E. H.</given-names></name>
</person-group> (<year>2010a</year>). <article-title>Empirically indistinguishable multidimensional IRT and locally dependent unidimensional item response models</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>63</volume>, <fpage>395</fpage>-<lpage>416</lpage>.</citation>
</ref>
<ref id="bibr20-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ip</surname><given-names>E. H.</given-names></name>
</person-group> (<year>2010b</year>). <article-title>Interpretation of the three-parameter testlet response model and information function</article-title>. <source>Applied Psychological Measurement</source>, <volume>34</volume>, <fpage>467</fpage>-<lpage>482</lpage>.</citation>
</ref>
<ref id="bibr21-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jang</surname><given-names>E. E.</given-names></name>
<name><surname>Roussos</surname><given-names>L.</given-names></name>
</person-group> (<year>2007</year>). <article-title>An investigation into the dimensionality of TOEFL using conditional covariance-based nonparametric approach</article-title>. <source>Journal of Educational Measurement</source>, <volume>44</volume>, <fpage>1</fpage>-<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr22-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Janssen</surname><given-names>R.</given-names></name>
<name><surname>De Boeck</surname><given-names>P.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Confirmatory analyses of componential test structure using multidimensional item response theory</article-title>. <source>Multivariate Behavioral Research</source>, <volume>34</volume>, <fpage>245</fpage>-<lpage>268</lpage>.</citation>
</ref>
<ref id="bibr23-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kang</surname><given-names>T.</given-names></name>
<name><surname>Cohen</surname><given-names>A. S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>IRT model selection methods for dichotomous items</article-title>. <source>Applied Psychological Measurement</source>, <volume>31</volume>, <fpage>331</fpage>-<lpage>358</lpage>.</citation>
</ref>
<ref id="bibr24-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kang</surname><given-names>T.</given-names></name>
<name><surname>Cohen</surname><given-names>A. S.</given-names></name>
<name><surname>Sung</surname><given-names>H.-J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Model selection indices for polytomous items</article-title>. <source>Applied Psychological Measurement</source>, <volume>33</volume>, <fpage>499</fpage>-<lpage>518</lpage>.</citation>
</ref>
<ref id="bibr25-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kim</surname><given-names>D.</given-names></name>
<name><surname>De Ayala</surname><given-names>R. J.</given-names></name>
<name><surname>Ferdous</surname><given-names>A. A.</given-names></name>
<name><surname>Nering</surname><given-names>M. L.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The comparative performance of conditional independence indices</article-title>. <source>Applied Psychological Measurement</source>, <volume>35</volume>, <fpage>447</fpage>-<lpage>471</lpage>.</citation>
</ref>
<ref id="bibr26-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>G.</given-names></name>
<name><surname>Kolen</surname><given-names>M. J.</given-names></name>
<name><surname>Frisbie</surname><given-names>D. A.</given-names></name>
<name><surname>Ankenmann</surname><given-names>R. D.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Comparison of dichotomous and polytomous item response models in equating scores from tests composed of testlets</article-title>. <source>Applied Psychological Measurement</source>, <volume>25</volume>, <fpage>357</fpage>-<lpage>372</lpage>.</citation>
</ref>
<ref id="bibr27-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>F.</given-names></name>
<name><surname>Cohen</surname><given-names>A. S.</given-names></name>
<name><surname>Kim</surname><given-names>S.-H.</given-names></name>
<name><surname>Cho</surname><given-names>S.-J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Model selection methods for mixture dichotomous IRT models</article-title>. <source>Applied Psychological Measurement</source>, <volume>33</volume>, <fpage>353</fpage>-<lpage>373</lpage>.</citation>
</ref>
<ref id="bibr28-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Bolt</surname><given-names>D. M.</given-names></name>
<name><surname>Fu</surname><given-names>J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>A test characteristic curve linking method for the testlet model</article-title>. <source>Applied Psychological Measurement</source>, <volume>29</volume>, <fpage>340</fpage>-<lpage>356</lpage>.</citation>
</ref>
<ref id="bibr29-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Bolt</surname><given-names>D. M.</given-names></name>
<name><surname>Fu</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>A comparison of alternative models for testlets</article-title>. <source>Applied Psychological Measurement</source>, <volume>30</volume>, <fpage>3</fpage>-<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr30-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Rupp</surname><given-names>A. A.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Performance of the S-χ<sup>2</sup> statistic for full-information bifactor models</article-title>. <source>Educational and Psychological Measurement</source>, <volume>71</volume>, <fpage>986</fpage>-<lpage>1005</lpage>.</citation>
</ref>
<ref id="bibr31-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marais</surname><given-names>I. D.</given-names></name>
<name><surname>Andrich</surname><given-names>D.</given-names></name>
</person-group> (<year>2008a</year>). <article-title>Effects of varying magnitude and patterns of local dependence in the unidimensional Rasch model</article-title>. <source>Journal of Applied Measurement</source>, <volume>9</volume>, <fpage>105</fpage>-<lpage>124</lpage>.</citation>
</ref>
<ref id="bibr32-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marais</surname><given-names>I. D.</given-names></name>
<name><surname>Andrich</surname><given-names>D.</given-names></name>
</person-group> (<year>2008b</year>). <article-title>Formalising dimension and response violations of local independence in the unidimensional Rasch model</article-title>. <source>Journal of Applied Measurement</source>, <volume>9</volume>, <fpage>200</fpage>-<lpage>215</lpage>.</citation>
</ref>
<ref id="bibr33-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McKinley</surname><given-names>R. L.</given-names></name>
</person-group> (<year>1989</year>). <source>Confirmatory analysis of test structure using multidimensional item response theory (ETS-RR-89-31)</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>ETS</publisher-name>.</citation>
</ref>
<ref id="bibr34-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McKinley</surname><given-names>R. L.</given-names></name>
<name><surname>Way</surname><given-names>W. D.</given-names></name>
</person-group> (<year>1992</year>). <source>The feasibility of modeling secondary TOEFL ability dimensions using multidimensional IRT models (ETS-RR-92–16)</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>ETS</publisher-name>.</citation>
</ref>
<ref id="bibr35-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nylund</surname><given-names>K. L.</given-names></name>
<name><surname>Asparouhov</surname><given-names>T.</given-names></name>
<name><surname>Muthén</surname><given-names>B. O.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Deciding on the number of classes in latent class analysis and growth mixture modeling: A Monte Carlo simulation study</article-title>. <source>Structural Equation Modeling</source>, <volume>14</volume>, <fpage>535</fpage>-<lpage>569</lpage>.</citation>
</ref>
<ref id="bibr36-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rijmen</surname><given-names>F.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Formal relations and an empirical comparison among the bi-factor, the testlet, and a second-order multidimensional IRT model</article-title>. <source>Journal of Educational Measurement</source>, <volume>47</volume>, <fpage>361</fpage>-<lpage>372</lpage>.</citation>
</ref>
<ref id="bibr37-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosenbaum</surname><given-names>P. R.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Item bundles</article-title>. <source>Psychometrika</source>, <volume>53</volume>, <fpage>349</fpage>-<lpage>359</lpage>.</citation>
</ref>
<ref id="bibr38-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schwarz</surname><given-names>G.</given-names></name>
</person-group> (<year>1978</year>). <article-title>Estimating the dimension of a model</article-title>. <source>Annals of Statistics</source>, <volume>6</volume>, <fpage>461</fpage>-<lpage>464</lpage>.</citation>
</ref>
<ref id="bibr39-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sclove</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Application of model-selection criteria to some problems in multivariate analysis</article-title>. <source>Psychometrika</source>, <volume>52</volume>, <fpage>333</fpage>-<lpage>343</lpage>.</citation>
</ref>
<ref id="bibr40-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Semmes</surname><given-names>R.</given-names></name>
<name><surname>Davison</surname><given-names>M. L.</given-names></name>
<name><surname>Close</surname><given-names>C.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Modeling individual differences in numerical reasoning speed as a random effect of response time limits</article-title>. <source>Applied Psychological Measurement</source>, <volume>35</volume>, <fpage>433</fpage>-<lpage>446</lpage>.</citation>
</ref>
<ref id="bibr41-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sireci</surname><given-names>S. G.</given-names></name>
<name><surname>Thissen</surname><given-names>D.</given-names></name>
<name><surname>Wainer</surname><given-names>H.</given-names></name>
</person-group> (<year>1991</year>). <article-title>On the reliability of testlet-based tests</article-title>. <source>Journal of Educational Measurement</source>, <volume>28</volume>, <fpage>237</fpage>-<lpage>247</lpage>.</citation>
</ref>
<ref id="bibr42-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stout</surname><given-names>W.</given-names></name>
</person-group> (<year>1987</year>). <article-title>A nonparametric approach for assessing latent trait unidimensionality</article-title>. <source>Psychometrika</source>, <volume>52</volume>, <fpage>589</fpage>-<lpage>617</lpage>.</citation>
</ref>
<ref id="bibr43-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stout</surname><given-names>W.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Dimtest (Version 2.0) [Computer software]</article-title>. <publisher-loc>Champaign, IL</publisher-loc>: <publisher-name>William Stout Institute for Measurement</publisher-name>.</citation>
</ref>
<ref id="bibr44-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stout</surname><given-names>W.</given-names></name>
<name><surname>Froelich</surname><given-names>A.</given-names></name>
<name><surname>Gao</surname><given-names>F.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Using resampling methods to produce an improved DIMTEST procedure</article-title>. In <person-group person-group-type="editor">
<name><surname>Boomsma</surname><given-names>A.</given-names></name>
<name><surname>van Duijn</surname><given-names>M. A. J.</given-names></name>
<name><surname>Snijders</surname><given-names>T. A. B.</given-names></name>
</person-group> (Eds.), <source>Essays on item response theory</source> (pp. <fpage>357</fpage>-<lpage>375</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>.</citation>
</ref>
<ref id="bibr45-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tate</surname><given-names>T.</given-names></name>
</person-group> (<year>2003</year>). <article-title>A comparison of selected empirical methods for assessing the structure of responses to test items</article-title>. <source>Applied Psychological Measurement</source>, <volume>27</volume>, <fpage>159</fpage>-<lpage>203</lpage>.</citation>
</ref>
<ref id="bibr46-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Bradlow</surname><given-names>E. T.</given-names></name>
<name><surname>Du</surname><given-names>Z.</given-names></name>
</person-group> (<year>2000</year>).<article-title>Testlet response theory: An analog for the 3PL model useful in testlet-based adaptive testing</article-title>. In <person-group person-group-type="editor">
<name><surname>van der Linden</surname><given-names>W. J.</given-names></name>
<name><surname>Glas</surname><given-names>C. A. W.</given-names></name>
</person-group> (Eds.), <source>Computerized adaptive testing: Theory and practice</source> (pp. <fpage>245</fpage>-<lpage>269</lpage>). <publisher-loc>Dordrecht, Netherlands</publisher-loc>: <publisher-name>Kluwer</publisher-name>.</citation>
</ref>
<ref id="bibr47-0146621612437403">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Bradlow</surname><given-names>E. T.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group> (<year>2007</year>). <source>Testlet response theory and its applications</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr48-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Wang</surname><given-names>C.</given-names></name>
</person-group> (<year>2000</year>).<article-title>Using a new statistical model for testlets to score TOEFL</article-title>. <source>Journal of Educational Measurement</source>, <volume>37</volume>, <fpage>203</fpage>-<lpage>220</lpage>.</citation>
</ref>
<ref id="bibr49-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Woodroofe</surname><given-names>M.</given-names></name>
</person-group> (<year>1982</year>). <article-title>On model selection and the arc sine laws</article-title>. <source>Annals of Statistics</source>, <volume>10</volume>, <fpage>1182</fpage>-<lpage>1194</lpage>.</citation>
</ref>
<ref id="bibr50-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yang</surname><given-names>C.-C.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Evaluating latent class analysis models in qualitative phenotype identification</article-title>. <source>Computational Statistics &amp; Data Analysis</source>, <volume>50</volume>, <fpage>1090</fpage>-<lpage>1104</lpage>.</citation>
</ref>
<ref id="bibr51-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yang</surname><given-names>C.-C.</given-names></name>
<name><surname>Yang</surname><given-names>C.-C.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Separating latent classes by information criteria</article-title>. <source>Journal of Classification</source>, <volume>24</volume>, <fpage>183</fpage>-<lpage>203</lpage>.</citation>
</ref>
<ref id="bibr52-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yen</surname><given-names>W. M.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Effects of local item dependence on the fit and equating performance of the three-parameter logistic model</article-title>. <source>Applied Psychological Measurement</source>, <volume>8</volume>, <fpage>125</fpage>-<lpage>145</lpage>.</citation>
</ref>
<ref id="bibr53-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yen</surname><given-names>W. M.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Scaling performance assessments: Strategies for managing local item dependence</article-title>. <source>Journal of Educational Measurement</source>, <volume>30</volume>, <fpage>187</fpage>-<lpage>213</lpage>.</citation>
</ref>
<ref id="bibr54-0146621612437403">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zenisky</surname><given-names>A.</given-names></name>
<name><surname>Hambleton</surname><given-names>R. K. L.</given-names></name>
<name><surname>Sireci</surname><given-names>S. G.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Identification and evaluation of local item dependencies in the Medical College Admissions Test</article-title>. <source>Journal of Educational Measurement</source>, <volume>39</volume>, <fpage>291</fpage>-<lpage>309</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>