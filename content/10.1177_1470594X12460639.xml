<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PPE</journal-id>
<journal-id journal-id-type="hwp">spppe</journal-id>
<journal-title>Politics, Philosophy &amp; Economics</journal-title>
<issn pub-type="ppub">1470-594X</issn>
<issn pub-type="epub">1741-3060</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1470594X12460639</article-id>
<article-id pub-id-type="publisher-id">10.1177_1470594X12460639</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Contractarian ethics and Harsanyi’s two justifications of utilitarianism</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Moehler</surname>
<given-names>Michael</given-names>
</name>
<aff id="aff1-1470594X12460639">Virginia Tech, USA</aff>
<xref ref-type="corresp" rid="corresp1-1470594X12460639"/>
</contrib>
<bio>
<title>About the Author</title>
<p>
<bold>Michael Moehler</bold> is an Assistant Professor in the Department of Philosophy at Virginia Tech. His main research interests lie in moral and political philosophy, with a special focus on the contractarian tradition and topics at the intersection of philosophy, politics, and economics.</p></bio>
</contrib-group>
<author-notes>
<corresp id="corresp1-1470594X12460639">Michael Moehler, Department of Philosophy, Virginia Tech, 229 Major Williams Hall, Blacksburg, VA 24061, USA Email: <email>moehler@vt.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2013</year>
</pub-date>
<volume>12</volume>
<issue>1</issue>
<fpage>24</fpage>
<lpage>47</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Harsanyi defends utilitarianism by means of an axiomatic proof and by what he calls the ‘equiprobability model’. Both justifications of utilitarianism aim to show that utilitarian ethics can be derived from Bayesian rationality and some weak moral constraints on the reasoning of rational agents. I argue that, from the perspective of Bayesian agents, one of these constraints, the impersonality constraint, is not weak at all if its meaning is made precise and that generally it even contradicts individual rational agency. Without the impersonality constraint, Harsanyi’s two justifications of utilitarianism on the grounds of Bayesian rationality fail. As an alternative, I develop a contractarian framework that is compatible with individual rational agency and Harsanyi’s central assumptions, and that allows the derivation of moral conclusions on the grounds of Bayesian rationality. The developed framework offers a novel justification of contractarian ethics and may best be described as a combined version of Harsanyi’s equiprobability model and Rawls’s original position.</p>
</abstract>
<kwd-group>
<kwd>Bayesian rationality</kwd>
<kwd>utilitarianism</kwd>
<kwd>contractarian ethics</kwd>
<kwd>equiprobability model</kwd>
<kwd>original position</kwd>
<kwd>impartiality</kwd>
<kwd>impersonality</kwd>
<kwd>equality</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1470594X12460639">
<title>1. Introduction</title>
<p>John Harsanyi, in a series of contributions (1953, 1955, 1977a, 1978, 1979, 1982), offers two independent justifications of utilitarianism. He defends utilitarianism by means of an axiomatic proof and by what he calls the ‘equiprobability model’. Both justifications of utilitarianism aim to show that utilitarian ethics can be derived from Bayesian rationality by imposing some weak moral constraints, in particular the impartiality and impersonality constraints, on the reasoning of rational agents. However, from the perspective of Bayesian agents, the impersonality constraint is not weak at all if its meaning is made precise, or so I argue, and generally it even contradicts individual rational agency because it demands that individuals neglect conceptually their existence as separate agents who behave as if they were to maximize their expected individual utility.</p>
<p>Without the impersonality constraint, Harsanyi’s two justifications of utilitarianism on the grounds of Bayesian rationality fail. In response to this consideration, I develop a contractarian framework that is compatible with individual rational agency and Harsanyi’s central assumptions, and that may best be described as a combined version of Harsanyi’s equiprobability model and Rawls’s original position. The developed framework allows agents to behave as if they were to maximize their expected individual utility subject to the side constraint of securing individual rational agency and to maximize the group utility as a result of such individual utility-maximizing behavior. The argument shows that a contractarian approach is methodologically more appropriate for the derivation of moral conclusions on the grounds of Bayesian rationality than a utilitarian approach and, as such, the argument offers a novel justification of contractarian ethics.</p>
<p>The article is organized as follows. In Section 2, I assess the moral dimensions and conceptual implications of Harsanyi’s axiomatic proof of utilitarianism. In particular, I discuss the impersonality constraint as an essential premise of Harsanyi’s proof and its tension with individual rational agency. In Section 3, I address Harsanyi’s non-axiomatic justification of utilitarianism by means of the equiprobability model, and indirectly by Rawls’s original position, to show that Harsanyi’s alternative defense of utilitarianism suffers from similar deficiencies as his axiomatic proof. In section 4, I argue that, if the impersonality constraint is rejected in its utilitarian interpretation, and if another assumption of Harsanyi's proof, the equal-treatment-of-all-individuals axiom, is reinterpreted so that it is compatible with individual rational agency, then Bayesian agents will agree on a contractarian moral conclusion. The specific moral principle that I derive is supported by my earlier work on contractarian moral and political theory (see <xref ref-type="bibr" rid="bibr46-1470594X12460639">Moehler, 2010</xref>, <xref ref-type="bibr" rid="bibr47-1470594X12460639">2012</xref>).</p>
</sec>
<sec id="section2-1470594X12460639">
<title>2. Harsanyi’s axiomatic proof of utilitarianism</title>
<p>Harsanyi’s axiomatic ‘proof’ of utilitarianism,<sup>
<xref ref-type="fn" rid="fn1-1470594X12460639">1</xref>
</sup> as originally stated, is considered to be problematic in at least two ways. First, depending on the particular interpretation of Harsanyi’s axioms and theorems, the proof is considered to be mathematically imprecise or incomplete or incorrect.<sup>
<xref ref-type="fn" rid="fn2-1470594X12460639">2</xref>
</sup> Second, it is argued that the proof cannot be viewed as a meaningful statement of (classical) utilitarianism because it is not sufficiently general and its preference-based concept of utility cannot adequately measure and compare individuals’ well-being as commonly conceived by utilitarianism.<sup>
<xref ref-type="fn" rid="fn3-1470594X12460639">3</xref>
</sup>
</p>
<p>Despite these potential problems with Harsanyi’s axiomatic proof of utilitarianism, I base my argument on Harsanyi’s most recent and almost identical statements of his proof published in 1978 and 1979, and, when necessary, add clarification, because neither do I aim to show that Harsanyi’s proof is mathematically incorrect or misguided in its understanding of utilitarianism nor do I aim to provide a conclusive summary of Harsanyi’s proof and its reception in the literature. Instead, I aim to reveal a more fundamental flaw in Harsanyi’s attempt to derive utilitarian ethics on the grounds of Bayesian rationality and to clarify the moral equivalence of Harsanyi’s axiomatic proof of utilitarianism and his equiprobability model, which I will present in the next section.</p>
<p>To this end, discussion in this section focuses primarily on the moral dimensions and conceptual implications of Harsanyi’s axiomatic proof of utilitarianism. Harsanyi’s proof consists essentially of four axioms that concern (1) the rationality of individual agents, (2) the rationality of moral preferences, (3) Pareto optimality, and (4) the equal treatment of all individuals. The first two axioms define conditions for individual rational agency and the other two axioms define conditions for the social aggregation process that is expressed by Harsanyi’s axiomatic proof of utilitarianism. I will discuss the meaning of Harsanyi’s four axioms in the order given.<sup>
<xref ref-type="fn" rid="fn4-1470594X12460639">4</xref>
</sup>
</p>
<p>Concerning the rationality of individual agents, Harsanyi’s axiomatic proof of utilitarianism demands that agents’ personal preferences satisfy certain Bayesian rationality postulates that allow the agents’ preferences to be represented by Von Neumann–Morgenstern utility functions.<sup>
<xref ref-type="fn" rid="fn5-1470594X12460639">5</xref>
</sup> Bayesian rationality, as defined by Harsanyi, employs an entirely formal notion of utility. It demands only that agents’ preference orderings fulfill the consistency requirements of Von Neumann–Morgenstern utility functions, independent of the content and motivation of agents’ preferences. That is, agents’ preferences can be self- or other-regarding.</p>
<p>According to Harsanyi, Bayesian agents assign subjective or objective probabilities, depending on their evidential basis and whether their choices occur under risk or uncertainty, to possible outcomes in decision situations, and then maximize the expected value of a Von Neumann–Morgenstern utility function.<sup>
<xref ref-type="fn" rid="fn6-1470594X12460639">6</xref>
</sup> Bayesian agents behave as if they were to maximize their expected <italic>individual</italic> utility, as expressed by the first axiom of Harsanyi’s proof. As a consequence, Bayesian agents are not interested directly in maximizing the overall utility of society.<sup>
<xref ref-type="fn" rid="fn7-1470594X12460639">7</xref>
</sup> Instead, the group utility is relevant to them only to the extent that it affects their individual utility. For Bayesian agents, individual utility has priority over group utility. Individual agency has priority over collective agency.</p>
<p>Nevertheless, Harsanyi argues that if the reasoning and consequent behavior of Bayesian agents are limited by certain weak moral constraints, then Bayesian agents will favor the group utility over their individual utility, and consequently will behave as if they were utilitarians. To this end, the agents’ reasoning and consequent behavior must be guided particularly by ‘impartial and impersonal’ considerations (<xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi, 1978</xref>: 226). According to Harsanyi, the ideals of impartiality and impersonality are essential for moral decision-making. These two ideals guide rational agents from their personal preferences to their moral preferences. Harsanyi assumes that agents’ moral preferences satisfy the same formal requirements as their personal preferences. This assumption is expressed by the second axiom of Harsanyi’s proof of utilitarianism (<xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi, 1978</xref>: 226).<sup>
<xref ref-type="fn" rid="fn8-1470594X12460639">8</xref>
</sup>
</p>
<p>In the utilitarian literature, the demand that agents’ personal preferences must be restricted in certain ways in moral decision-making is often expressed by the notion of an impartial observer.<sup>
<xref ref-type="fn" rid="fn9-1470594X12460639">9</xref>
</sup> According to utilitarianism, in moral decision situations agents must imagine that they are in an idealized deliberative state in which they are informed about all morally relevant aspects of their decisions and their reasoning is guided by adequate moral considerations. Both Harsanyi’s axiomatic proof of utilitarianism and his equiprobability model can be seen as formalizations of Harsanyi’s idea of such an impartial and impersonal moral observer.<sup>
<xref ref-type="fn" rid="fn10-1470594X12460639">10</xref>
</sup>
</p>
<p>In the context discussed by Harsanyi, the moral ideal of impartiality demands that, in making moral decisions, agents do not unjustifiably favor, for self- or other-regarding reasons, their own positions in society or the positions of anybody else. The moral ideal of impersonality demands that agents do not base moral decisions on their self- or other-regarding personal interests, but only on the public interest. From Harsanyi’s own writings it is not entirely clear whether he conceived the distinction between impartiality and impersonality in precisely these terms or whether he sometimes uses these two terms interchangeably. From Harsanyi’s axiomatic proof of utilitarianism, however, it becomes clear that both moral ideals are essential to his justification of utilitarianism. Formally, the two moral ideals are primarily expressed by the Pareto-optimality condition and the equal-consideration-of-all-individuals axiom of Harsanyi’s proof (1955: 316; 1978: 226–7). Harsanyi argues that if Bayesian agents accept these two axioms in addition to the previous two axioms, then they will become utilitarians.</p>
<p>The Pareto-optimality condition demands that if at least one member of society personally prefers social situation <italic>A</italic> over social situation <italic>B</italic>, and no other group member prefers <italic>B</italic> over <italic>A</italic>, then all group members must morally prefer <italic>A</italic> over <italic>B</italic>. <xref ref-type="bibr" rid="bibr34-1470594X12460639">Harsanyi (1979</xref>: 294) regards the Pareto-optimality condition as an uncontroversial moral assumption.<sup>
<xref ref-type="fn" rid="fn11-1470594X12460639">11</xref>
</sup> The Pareto-optimality condition demands that agents are impartial in the social aggregation process in that if one member of society can be made better off without anyone else being made worse off, then all group members must agree with the social state that improves the situation of the one individual. Further, although agents may discount other individuals’ utility in the social aggregation process based on their own value judgments, agents are not allowed to disregard entirely the utility of others. According to Harsanyi, no member of society is to be excluded from the social aggregation process. I make this assumption that is implied by the Pareto-optimality condition explicit by calling it the ‘non-exclusion condition’.<sup>
<xref ref-type="fn" rid="fn12-1470594X12460639">12</xref>
</sup>
</p>
<p>If Bayesian agents accept the Pareto-optimality condition and the non-exclusion condition implied by it as constraints on the social aggregation process that is captured by Harsanyi’s axiomatic proof of utilitarianism, then they will agree with weighted utilitarianism.<sup>
<xref ref-type="fn" rid="fn13-1470594X12460639">13</xref>
</sup> If, in addition, Bayesian agents accept Harsanyi’s equal-treatment-of-all-individuals axiom, then, according to <xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi (1978</xref>: 227; 1979: 294), utilitarianism in its typical formulation is justified. The equal-treatment-of-all-individuals axiom demands that agents assign equal weight to the utility functions of all group members in the social aggregation process, if the group members’ utility functions are expressed in equal utility units, which can be judged only by interpersonal utility comparisons among the members of society. The equal-treatment-of-all-individuals axiom imposes the moral ideal of equality and, indirectly and partially, the moral ideal of impersonality on the social aggregation process, as I will clarify in detail shortly.</p>
<p>In sum, if Bayesian agents accept the described restrictions on their reasoning and consequent behavior, then they will behave as if they were to maximize the aggregate utility of society. Bayesian agents will behave as if they were utilitarians. In practice, Bayesian agents do not always need to behave as if they were utilitarians, of course. Instead, they must do so only in morally relevant social interactions. Further, in practice, agents usually install a government that arranges the basic institutions of their society according to their ideals, and thus only the social regulating institutions must be strictly utilitarian. The members of society need only to follow the policies enacted. Nevertheless, the primary objective of Harsanyi’s axiomatic proof of utilitarianism is to provide Bayesian agents with compelling reasons to accept utilitarianism as a moral doctrine. Harsanyi’s axiomatic proof of utilitarianism serves a justificatory function.</p>
<p>My criticism of Harsanyi’s axiomatic proof of utilitarianism is directed against neither the Pareto-optimality condition nor the non-exclusion condition that together essentially enforce the moral ideal of impartiality for Harsanyi’s proof, because the moral ideal of impartiality respects, from the perspective of Bayesian agents, individual rational agency. The impartiality constraint, as expressed by the Pareto-optimality condition and the non-exclusion condition, respects the boundaries of individuals as separate agents who aim to maximize their expected individual utility, although the impartiality constraint limits agents’ attempts to favor their own positions in society. Rather, my criticism of Harsanyi’s axiomatic proof of utilitarianism is directed against the impersonality constraint that is expressed by Harsanyi’s proof.</p>
<p>As indicated, the impersonality constraint demands, according to Harsanyi, that agents do not base moral decisions on their self- or other-regarding personal interests, but only on the public interest. At first glance, this condition seems plausible as a constraint on moral decision-making, in particular, if agents, in the role of public officials, decide on policies that affect society as a whole. However, the precise meaning of the impersonality constraint in the context of Harsanyi’s axiomatic proof of utilitarianism becomes clear only through close analysis of the other remaining conditions of the social aggregation process that underlies Harsanyi’s axiomatic proof of utilitarianism.</p>
<p>The most important condition for this process is, from a moral perspective, the equal-treatment-of-all-individuals axiom that imposes, <italic>inter alia</italic>, the moral ideal of equality on the social aggregation process. Harsanyi’s labeling of the equal-treatment-of-all-individuals axiom is misleading, however, because the axiom does not demand equal treatment of all <italic>individuals</italic>, seen as separate entities in the social aggregation process, but equal treatment only of their <italic>utility functions</italic>. The axiom demands that each individual is treated equally with regard to her capacity to generate utility, and thus that each unit of utility generated, if measured in equal utility units, is considered equally in the social aggregation process, irrespective of who produces it.</p>
<p>The equal-treatment-of-all-individuals axiom, together with the other general conditions of the social aggregation process that underlies Harsanyi’s axiomatic proof of utilitarianism, such as aggregation by the summation of individual utilities, ensures that agents cannot favor their personal or individual utility, or the individual utility of anyone else in society, over the impersonal aggregate utility of society, because agents must consider equally, if measured in equal utility terms, each unit of utility that is generated in society in the social aggregation process. The conditions enforce the impersonality constraint. The impersonality constraint essentially transforms individual utility maximizers into utilitarians because it demands that agents do not favor their individual good over the socially constructed public good, as determined by the social aggregation process. The impersonality constraint imposes the core defining feature of utilitarianism on Bayesian agents. Harsanyi is able to disguise this strong utilitarian content of the impersonality constraint mainly by mislabeling the equal-treatment-of-all-individuals axiom, as previously indicated.</p>
<p>The core feature of utilitarianism to prioritize group utility over individual utility has been widely criticized in moral philosophy because it may severely restrict agents’ ability to advance their personal, or individual, interests and, as a consequence, may impose high moral demands on agents.<sup>
<xref ref-type="fn" rid="fn14-1470594X12460639">14</xref>
</sup> The impersonality constraint may compromise the integrity, or personal autonomy, of individual agents and, in certain situations, may even demand that the lives of particular members of society are sacrificed if such actions maximize the group utility. Some moral philosophers, in particular deontologists, argue that the mere possibility of such outcomes shows the inadequacy of utilitarianism as a moral theory. In other words, according to some moral philosophers, the impersonality constraint is not merely a weak moral constraint that is imposed on agents, as Harsanyi claims, but a strong moral assumption.</p>
<p>My following criticism of the impersonality constraint as an essential premise of Harsanyi’s axiomatic proof of utilitarianism reveals, in addition to these <italic>moral</italic> concerns, a <italic>conceptual</italic> problem that arises from Harsanyi’s attempt to derive utilitarian ethics on the grounds of Bayesian rationality. I argue that the impersonality constraint represents a strong conceptual constraint for Bayesian agents who aim to maximize their expected individual utility. The impersonality constraint, as expressed by Harsanyi’s axiomatic proof of utilitarianism, generally is conceptually incompatible with Bayesian rationality because the impersonality constraint demands that individuals neglect conceptually their existence as separate agents who aim to maximize their expected individual utility.</p>
<p>To clarify, the impersonality constraint, as expressed by the social aggregation process that underlies Harsanyi’s axiomatic proof of utilitarianism, reduces agents to their utility functions, as if utility functions could exist independently of the individuals whose preferences they represent, and it forbids agents to prioritize their individual utility over the group utility. In doing so, the impersonality constraint conceptually merges all members of society into one abstract entity that orders its various ends across the boundaries of different agents, as Rawls (1999: 19–24) points out in his criticism of utilitarianism.<sup>
<xref ref-type="fn" rid="fn15-1470594X12460639">15</xref>
</sup> Rawls argues that utilitarianism does not take seriously the ‘distinction between persons’, and because he regards this feature of utilitarianism to be morally objectionable Rawls rejects utilitarianism on moral grounds.</p>
<p>Irrespective of whether Rawls’s moral criticism of utilitarianism is defensible, his criticism, if made precise, shows that although the impersonality constraint, as expressed by Harsanyi’s axiomatic proof of utilitarianism, recognizes individuals as separate sources of utility, it licenses that the utility generated by different individuals is compared and traded against each other, as if only one single abstract entity exists that pursues the collective good that is expressed by the aggregate social utility. As indicated, this abstract entity often is called an ‘<italic>impartial</italic>’ observer, although the discussion shows that it would be more appropriate to speak of an <italic>impersonal</italic> observer, because the ideal of impersonality is the core moral ideal that justifies utilitarianism. As Rawls (1999: 166) aptly puts it in his criticism of utilitarianism: ‘The fault of the utilitarian doctrine is that it mistakes impersonality for impartiality.’</p>
<p>The impersonality constraint dissolves the boundaries among agents by licensing interpersonal utility aggregations. In this sense, the impersonality constraint does not respect individuals as separate agents, and individual rational agency. Bayesian agents, however, exist as separate agents with full authority over their individual utility. In fact, for Bayesian agents, all that matters is their individual utility, and not the group utility. Because individuals do not exist conceptually as separate agents, in the sense described, under Harsanyi’s ‘veil of impersonality’ that is imposed on agents by the conditions of Harsanyi’s axiomatic proof of utilitarianism, but only as a single, abstract collective entity that orders its ends across the boundaries of different agents, Bayesian agents generally cannot comprehend the conclusions that are reached under the utilitarian veil of impersonality. Stated differently, the impersonality constraint changes the concept of rationality by which agents are assumed to be guided. It <italic>erases</italic> the identity of Bayesian agents as individual utility maximizers by demanding that agents maximize the aggregate group utility. If, however, Bayesian agents are required to favor the aggregate utility of society over their individual utility, then they are no longer Bayesian agents, but utilitarians.</p>
<p>This line of reasoning reveals a fundamental problem with Harsanyi’s axiomatic proof of utilitarianism that combines Bayesian rationality with the moral ideal of impersonality. The main problem with Harsanyi’s axiomatic proof of utilitarianism is not that the impersonality constraint may be rejected on moral grounds, as Rawls argues. In fact, certain types of agent, such as utilitarians, accept the impersonality constraint as a moral restriction on their behavior, and even Bayesian agents may accept the impersonality constraint as a behavioral restriction in certain specific types of interaction in which maximizing their expected individual utility also maximizes the group utility. Nor is the main problem with Harsanyi’s axiomatic proof of utilitarianism its reliance on the impersonality constraint as an essential premise for justifying utilitarian ethics on the grounds of Bayesian rationality and that the proof is, in this sense, circular. That is, Harsanyi’s axiomatic proof of utilitarianism does not justify utilitarian ethics on individual utility-maximizing grounds, but it <italic>assumes</italic> utilitarian ethics because the impersonality constraint, which is an essential premise of Harsanyi’s axiomatic proof, transforms individual utility maximizers into utilitarians.<sup>
<xref ref-type="fn" rid="fn16-1470594X12460639">16</xref>
</sup>
</p>
<p>Rather, the main problem with Harsanyi’s axiomatic proof of utilitarianism is that the proof demands, as a result of the impersonality constraint, that Bayesian agents change, de facto, their concept of rationality from maximizing their individual utility to maximizing the group utility. The impersonality constraint is not merely a weak moral constraint that is imposed on the reasoning and consequent behavior of Bayesian agents, as Harsanyi suggests, but is a strong conceptual assumption for Bayesian agents because the impersonality constraint demands that Bayesian agents give up their identity as individual utility maximizers, and thus their identity as Bayesian agents, in order to reach a utilitarian conclusion. In this sense, the impersonality constraint generally is conceptually incompatible with Bayesian rationality, and Harsanyi’s axiomatic proof of utilitarianism cannot justify utilitarian ethics to Bayesian agents.</p>
<p>Stated differently, Harsanyi’s axiomatic proof of utilitarianism, if correct, defines the moral constraints that are necessary to transform Bayesian agents into utilitarians. However, Harsanyi’s proof does not have any justificatory power for Bayesian agents because it does not merely restrict the agents’ individual utility-maximizing behavior in order to justify utilitarianism. Instead, it demands, as a consequence of the impersonality constraint, that Bayesian agents reject their own concept of rationality in order to justify utilitarianism. Bayesian rationality is not as closely linked to utilitarian ethics as Harsanyi suggests. In general, one cannot be a Bayesian agent, as defined by Harsanyi, and a utilitarian, although in certain specific situations of interaction the behavior of these two types of agent may be identical, as a discussion of Harsanyi’s equiprobability model further clarifies.</p>
</sec>
<sec id="section3-1470594X12460639">
<title>3. Harsanyi’s equiprobability model</title>
<p>Harsanyi’s non-axiomatic justification of utilitarianism, or more precisely, his justification of the <italic>average</italic> utility principle by means of the equiprobability model and indirectly by Rawls’s original position (see <xref ref-type="bibr" rid="bibr30-1470594X12460639">Harsanyi, 1975b</xref>: 598; 1978: 227–8; 1979: 294–5), is from a moral perspective equivalent to Harsanyi’s axiomatic proof of utilitarianism, because Harsanyi’s equiprobability model imposes the same moral constraints on Bayesian agents as his axiomatic proof imposes on them.<sup>
<xref ref-type="fn" rid="fn17-1470594X12460639">17</xref>
</sup> As a consequence, Harsanyi’s justification of the average utility principle via the equiprobability model faces similar criticism as his axiomatic proof of utilitarianism. In order to clarify this point, it is helpful to explain, first, the differences between Harsanyi’s equiprobability model and Rawls’s original position.<sup>
<xref ref-type="fn" rid="fn18-1470594X12460639">18</xref>
</sup>
</p>
<p>Both Harsanyi’s equiprobability model and Rawls’s original position place rational agents in a moral decision situation in which they must decide on principles of justice in a situation of uncertainty.<sup>
<xref ref-type="fn" rid="fn19-1470594X12460639">19</xref>
</sup> The main difference between Harsanyi’s and Rawls’s moral decision situations is that Harsanyi’s equiprobability model assumes a thin veil of ignorance under which agents are assumed to know the specific circumstances of their society and the existing social positions, including the preference profiles of all group members with regard to possible social outcomes, apart from their own positions (see <xref ref-type="bibr" rid="bibr27-1470594X12460639">Harsanyi, 1955</xref>: 316). Further, agents in the equiprobability model are assumed to have an equal chance of occupying any of the existing social positions. Under these conditions, Bayesian agents maximize their expected individual utility by maximizing the average utility of society, because, as a result of the equiprobability assumption and the ideal of expected individual utility maximization, agents in the equiprobability model must assume that they occupy, in a mathematical sense, the ‘average’ social position in real life.</p>
<p>Rawls’s original position (1999: 118–23), by contrast, assumes a thick veil of ignorance that, in addition to the informational restrictions imposed on agents by Harsanyi’s thin veil of ignorance, renders agents ignorant of the precise social and economic circumstances of their society and the existing social positions. Further, Rawls demands that agents’ choices in the original position are not to be guided by specific subjective or objective probability assignments with regard to outcomes, for reasons that will shortly become clear. As a consequence, agents in the original position cannot assume that they occupy any of the existing social positions with equal probability, and more generally, they cannot rely on specific expected-utility calculations for their choices in the original position.<sup>
<xref ref-type="fn" rid="fn20-1470594X12460639">20</xref>
</sup> Rawls argues that, under these conditions, rational individuals would apply the maximin decision rule, which would lead them to the difference principle as a principle of distributive justice.</p>
<p>
<xref ref-type="bibr" rid="bibr30-1470594X12460639">Harsanyi (1975b</xref>: 598–600) is unimpressed by Rawls’s argument.<sup>
<xref ref-type="fn" rid="fn21-1470594X12460639">21</xref>
</sup> He argues that in both the equiprobability model and Rawls’s original position rational individuals would choose the average utility principle as a principle of justice because rational individuals cannot help but assign, at least implicitly, specific subjective probabilities to outcomes under the veil of ignorance. According to Harsanyi, no matter which principle of justice individuals choose under the veil of ignorance, their choice will reflect specific subjective probability assignments with regard to outcomes. If individuals choose the difference principle, then they must have assigned implicitly a very high probability to being in the worst-off position in society in their endeavor to maximize their expected individual utility under the veil of ignorance. If individuals choose the average utility principle, then they must have assigned implicitly equal probabilities to all possible outcomes under the veil of ignorance, which Harsanyi suggests is rational in Rawls’s original position.</p>
<p>Harsanyi’s argument for the average utility principle is conclusive if individuals under the veil of ignorance, thick or thin, must assume that they occupy any of the existing social positions with equal probability, because in this <italic>specific</italic> case, Bayesian agents maximize their expected <italic>individual</italic> utility under the veil of ignorance by maximizing the <italic>average</italic> social utility. The essential question is whether the use of the equiprobability assumption is justified under the veil of ignorance, either on nonmoral grounds or on moral grounds. I will first address the potential justification of the equiprobability assumption on nonmoral grounds. I will first address the potential justification of the equiprobability assumption on nonmoral grounds.</p>
<p>
<xref ref-type="bibr" rid="bibr30-1470594X12460639">Harsanyi (1975b</xref>) argues that in situations of uncertainty in which agents have no information whatsoever about the likelihood of possible outcomes in decision situations, Bayesian agents will apply a version of the principle of insufficient reason and, consequently, will assign equal probabilities to all possible outcomes. In his later writings, however, Harsanyi recognizes that, in its general formulation, the principle of insufficient reason is ‘open to the important logical objection that it attempts to draw a positive conclusion (that of equal probabilities) from mere ignorance (from absence of information favoring any specific outcome) – an attempt that cannot possibly succeed’ (1983: 352). In response to this consideration, Harsanyi develops a more defensible version of the principle of insufficient reason, which he calls the ‘principle of <italic>positively supported</italic> indifference’ (1983: 353). This principle justifies the assignment of equal probabilities to all possible outcomes only in decision situations with symmetrical outcome spaces and no hidden asymmetries.</p>
<p>In Rawls’s original position, which imposes a thick veil of ignorance on agents, agents do not know the specific structure of their society, such as whether social positions are distributed evenly across the social spectrum of their society. As such, agents in Rawls’s original position do not know whether the outcome space of their decision situation is symmetrical in the relevant sense. By contrast, in Harsanyi’s equiprobability model, which imposes only a thin veil of ignorance on agents, agents are assumed to know the specific circumstances of their society and the distribution of social positions. However, if one realistically assumes any currently existing society, then it is unlikely that the outcome space is symmetrical in the relevant sense. As such, the application of Harsanyi’s principle of positively supported indifference seems to be unwarranted in both Harsanyi’s and Rawls’s moral decision situations, and thus the use of the equiprobability assumption under the veil of ignorance. The equiprobability assumption cannot be justified on nonmoral grounds under the veil of ignorance, thick or thin, in the circumstances described.<sup>
<xref ref-type="fn" rid="fn22-1470594X12460639">22</xref>
</sup>
</p>
<p>Whether the equiprobability assumption can be justified on moral grounds under the veil of ignorance depends on the adequacy of the equiprobability assumption as a means to model the moral ideals of impartiality and impersonality, and the impersonal form of equality associated with the latter in the context of Harsanyi’s axiomatic proof of utilitarianism, as expressed by Harsanyi’s equal-treatment-of-all-individuals axiom. <xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi (1978</xref>: 227; 1979: 295) argues that the equiprobability assumption expresses these moral ideals adequately, and therefore, the equiprobability model indirectly confirms the result of his axiomatic proof of utilitarianism, because the two methods of justification rely on the same moral ideals.</p>
<p>The moral ideal of impersonality, and the impersonal form of equality associated with it in the context of Harsanyi’s axiomatic proof of utilitarianism, is modeled adequately by the equiprobability assumption because individuals under the veil of ignorance cannot choose a moral principle that allows them to favor their personal (that is, individual) utility in the decision-making process. Instead, individuals must equally consider, if measured in equal utility terms, all units of utility that are generated in society, and consequently maximize the impersonal aggregate utility of society, as expressed by the average social position, because as a result of the equiprobability assumption and the ideal of expected individual utility maximization, individuals under the veil of ignorance must assume that they occupy, in a mathematical sense, the ‘average’ social position in real life. The equiprobability assumption ensures that individuals under the veil of ignorance cannot select a principle of justice that favors the fulfillment of their personal individual interests in real life, but only a principle that advances the fulfillment of the impersonal public interest, as expressed by the average social position.<sup>
<xref ref-type="fn" rid="fn23-1470594X12460639">23</xref>
</sup>
</p>
<p>The problem with Harsanyi’s argument is that the moral ideal of impersonality that is modeled by the equiprobability assumption, and the impersonal form of equality associated with it, will be rejected by Bayesian agents as a general constraint on their decision-making and consequent behavior because the moral ideal of impersonality demands that agents give up their identity as individual utility maximizers in order to maximize the group utility. The impersonality constraint generally is conceptually incompatible with Bayesian rationality, as clarified in the previous section.</p>
<p>As such, Harsanyi’s non-axiomatic justification of the average utility principle suffers from a similar problem as his axiomatic proof of utilitarianism. One may argue that this problem is precisely the reason that Rawls rejects the use of the equiprobability assumption in the original position. The equiprobability assumption enforces the moral ideal of impersonality and the impersonal form of equality associated with it and, as a consequence, cannot necessarily sufficiently protect the distinctness of persons. The use of the equiprobability assumption does not sufficiently protect individual rational agency as demanded by Bayesian rationality. Moreover, there is a second related reason that Bayesian agents will reject the equiprobability assumption.</p>
<p>Although the moral ideal of impartiality is compatible with Bayesian rationality because it respects individual rational agency, the equiprobability assumption does not model adequately the moral ideal of impartiality. As indicated, the moral ideal of impartiality demands that individuals’ choices are unbiased and unprejudiced. This demand is met by placing individuals under the veil of ignorance, thick or thin, where they do not know in which position within society they will be. The moral ideal of impartiality does not, however, necessarily demand equal treatment of all individuals, because some individuals may justifiably be treated differently.<sup>
<xref ref-type="fn" rid="fn24-1470594X12460639">24</xref>
</sup> As such, the moral ideal of impartiality does not necessarily demand the assignment of equal probabilities to all possible outcomes under the veil of ignorance, as the equiprobability model demands. In fact, assigning equal probabilities to all possible outcomes reflects a particular bias in the decision-making process, namely, a bias to treat all positions in society equally even if they may deserve unequal treatment.<sup>
<xref ref-type="fn" rid="fn25-1470594X12460639">25</xref>
</sup>
</p>
<p>Harsanyi may respond to this criticism by arguing that in the moral decision situation that he describes individuals do not have the information that is necessary to treat any of the social positions differently. If this is so, however, then it is more plausible to demand that individuals do not, implicitly or explicitly, assign any specific probabilities to outcomes in the moral decision situation, and instead choose <italic>independently</italic> of such probability considerations, as Rawls demands for the original position. Only this assumption guarantees an impartial choice, because assigning equal probabilities to all possible outcomes under the veil of ignorance attaches, unjustifiably, a particular weight to the average social position. The equiprobability assumption favors the average social position. It demands that all agents suspend their individual utility-maximizing behavior to the extent that is necessary to maximize the average social utility, even if no agent occupies the arithmetic mean of society after the veil of ignorance is lifted.</p>
<p>In sum, the equiprobability assumption will be rejected by Bayesian agents under the veil of ignorance as a general restriction on their reasoning and consequent behavior because the assumption enforces the moral ideal of impersonality and the impersonal form of equality associated with it in the context of Harsanyi’s justification of utilitarianism, and it does not model adequately the moral ideal of impartiality. Without the equiprobability assumption, Harsanyi’s justification of the average utility principle by means of the equiprobability model, and indirectly by Rawls’s original position, fails.</p>
<p>Further, the discussion shows that an analytical device that aims to derive moral conclusions on the grounds of Bayesian rationality must conceptually ensure individual rational agency and, in this sense, be compatible with Bayesian rationality, and it must respect the priority of individual agency over collective agency in order for Bayesian agents generally to accept the moral conclusions reached by the device. It is not sufficient that individual agency is protected as a result of the application of the utility principle, as is sometimes argued with regard to the average utility principle subject to a social minimum.</p>
<p>To clarify, utilitarians sometimes defend the introduction of a social minimum as a consequence of the application of the utility principle to the conditions under which human beings live in this world. A social minimum allows agents to satisfy their basic needs, and because agents usually gain high utility from satisfying their basic needs compared to the fulfillment of other needs, the introduction of a social minimum usually helps to maximize the aggregate social utility.<sup>
<xref ref-type="fn" rid="fn26-1470594X12460639">26</xref>
</sup> If, however, individual rational agency is protected only as a result of the application of the utility principle, then utilitarian ethics is not derived on individual utility-maximizing grounds, but it is assumed, and individual rational agency is not protected absolutely. The same problem arises if utilitarians aim to secure individual rational agency by appeal to rule utilitarianism instead of act utilitarianism, as <xref ref-type="bibr" rid="bibr32-1470594X12460639">Harsanyi (1977b</xref>, <xref ref-type="bibr" rid="bibr35-1470594X12460639">1980</xref>, 1982, <xref ref-type="bibr" rid="bibr38-1470594X12460639">1985a</xref>, <xref ref-type="bibr" rid="bibr39-1470594X12460639">1985b</xref>) does. Such an appeal to rule utilitarianism can justify only a specific version of utilitarianism within the utilitarian spectrum. It cannot, however, ultimately justify the utility principle as a moral principle on the grounds of Bayesian rationality, and it cannot absolutely protect individual rational agency.</p>
<p>An analytical framework that aims to derive moral conclusions on the grounds of Bayesian rationality must conceptually ensure individual rational agency and its priority over collective agency. The framework must guarantee individual rational agency as a <italic>side constraint</italic> for social decision-making.<sup>
<xref ref-type="fn" rid="fn27-1470594X12460639">27</xref>
</sup> Utilitarian theories do not provide such absolute protection of individual rational agency because they rely on the impersonality constraint as a core moral ideal, and thus assign priority to collective agency. Utilitarian theories secure individual rational agency only if such protection maximizes the group utility. Contractarian moral theories, by contrast, assign priority to individual agency and, as such, they are methodologically more appropriate for Bayesian ethics than utilitarian theories.</p>
</sec>
<sec id="section4-1470594X12460639">
<title>4. Bayesian agents and contractarian ethics</title>
<p>Contractarian moral theories justify moral conclusions based on agreement among <italic>individuals</italic> who are affected by the moral conclusions. Contractarian theories assign individuals autonomy to legislate the moral rules by which they are governed and, in this sense, contractarian theories respect individual agency. Two major types of contract theory are defended in the literature: <italic>contractarianism</italic> and <italic>contractualism</italic>.<sup>
<xref ref-type="fn" rid="fn28-1470594X12460639">28</xref>
</sup> The former position assumes, <italic>inter alia</italic>, natural equality among agents and the latter position assumes moral equality among agents. Although Bayesian rationality may seem closer to the position of moral contractarianism than to moral contractualism, the assumptions that underlie Harsanyi’s justifications of utilitarianism lead to a contractualist framework, as reflected by Harsanyi’s equiprobability model and Rawls’s original position, because the assumptions include the moral ideal of equality in some form.</p>
<p>Assume a society of Bayesian agents in Harsanyi’s sense. The agents’ individual preferences can be represented by Von Neumann–Morgenstern utility functions, and agents consequently behave as if they were to maximize their expected individual utility in the world in which they live. Due to scarcity of resources and competition, the agents cannot necessarily fulfill all of their individual preferences in their world, which leads to conflicts. How do Bayesian agents resolve such conflicts if their behavior is morally unrestricted?</p>
<p>I argue elsewhere (<xref ref-type="bibr" rid="bibr46-1470594X12460639">Moehler, 2010</xref>: 453–4) that rational individuals, or more specifically, two rational individuals who behave as if they were to maximize their expected individual utility, as demanded by Bayesian rationality, will agree with the Nash bargaining solution as an outcome in conflict situations in which their behavior is morally unrestricted.<sup>
<xref ref-type="fn" rid="fn29-1470594X12460639">29</xref>
</sup> The reason that they will do so is that Bayesian rationality requires agents to use their unrestricted bargaining power to defend their individual preferences, because only then do agents behave as if they were to maximize their expected individual utility. As a result, Bayesian agents will accept only a bargaining outcome that assigns them a share of the goods that are in dispute that is proportional to their actual relative bargaining power. This condition, compared with other bargaining solutions, is best fulfilled by the Nash bargaining solution that allows agents to receive what they can expect to gain according to their actual relative bargaining power.<sup>
<xref ref-type="fn" rid="fn30-1470594X12460639">30</xref>
</sup>
</p>
<p>Further, Bayesian rationality demands that agents fulfill their individual preferences in conflict situations as much as possible based on their actual bargaining capacities. This demand is fulfilled by the Nash bargaining solution because only if all parties to a conflict are allowed to satisfy their individual preferences as much as possible based on their actual bargaining power will the Nash product be maximal. In formal terms, the Nash bargaining solution fulfills, like Harsanyi’s social aggregation process, the Pareto-optimality condition. In contrast to Harsanyi’s justification of utilitarianism, however, in the case of the Nash bargaining solution the Pareto-optimality condition does not represent a constraint on the social aggregation process, but it is a feature of the social outcome. In the context of the Nash bargaining solution, the Pareto-optimality condition demands that if more than one potential bargaining outcome exists and one of the outcomes allows at least one of the conflicting parties to improve her situation without making anyone else worse off, then the parties to a conflict must agree with that bargaining outcome.<sup>
<xref ref-type="fn" rid="fn31-1470594X12460639">31</xref>
</sup>
</p>
<p>In sum, the Nash bargaining solution represents a natural agreement point for Bayesian agents in conflict situations in which their bargaining process is morally unrestricted and independent of controversial ethical considerations, such as interpersonal utility comparisons.<sup>
<xref ref-type="fn" rid="fn32-1470594X12460639">32</xref>
</sup> In contrast to the average utility principle, the Nash bargaining solution does not rely on interpersonal utility comparisons, but only on comparisons of differences of intrapersonally determined utility ratios.<sup>
<xref ref-type="fn" rid="fn33-1470594X12460639">33</xref>
</sup> The Nash bargaining solution represents a morally neutral mechanism of conflict resolution for Bayesian agents because the Nash bargaining solution does not rely on controversial ethical concepts and does not favor any party to a conflict from the perspective of Bayesian agents. Instead, the Nash bargaining solution assigns each party to a conflict the share of the goods that are in dispute that she can expect to gain according to her actual relative bargaining power. As <xref ref-type="bibr" rid="bibr8-1470594X12460639">Binmore (2005</xref>: 26) puts it:</p>
<disp-quote>
<p>The Nash bargaining solution is game theory’s best shot at predicting the agreement that will be reached when two rational players with equal bargaining power negotiate face-to-face without any appeals to fairness being made. It has rivals, like the version of the Kalai-Smorodinsky bargaining solution reinvented by David Gauthier in his <italic>Morals by Agreement</italic>, but none of these rivals allow the same defense in depth as the Nash bargaining solution.<sup>
<xref ref-type="fn" rid="fn34-1470594X12460639">34</xref>
</sup>
</p>
</disp-quote>
<p>In order to determine the <italic>moral</italic> preferences of Bayesian agents, the agents’ reasoning and consequent behavior must be morally restricted, such as by the impartiality and impersonality constraints, as Harsanyi suggests. As clarified, however, Bayesian agents will not accept the impersonality constraint and the impersonal form of equality associated with it in the context of Harsanyi’s justifications of utilitarianism as general moral restrictions on their decision-making and consequent behavior because the impersonality constraint generally is conceptually incompatible with Bayesian rationality. From the moral ideals that Harsanyi employs for his justifications of utilitarianism, Bayesian agents will only accept the impartiality constraint and the moral ideal of equality as general restrictions on their reasoning and consequent behavior if the latter is interpreted in a way that is compatible with individual rational agency. In the following, I present a moral decision situation that closely follows the main assumptions of Harsanyi’s two justifications of utilitarianism, but that guarantees individual rational agency. The moral decision situation may best be described as a combined version of Harsanyi’s equiprobability model and Rawls’s original position.</p>
<p>The moral ideal of impartiality is best modeled by placing Bayesian agents in a situation of uncertainty in which they decide on a principle of conflict resolution without knowing in which position within society they will be. Like Harsanyi, I assume that agents in the moral decision situation are covered by a thin veil of ignorance that renders them ignorant of their own positions in society, but not of the existing social positions and the general circumstances of their society. In contrast to Harsanyi, agents in the moral decision situation cannot assume that they end up with equal probabilities in all positions of society either on nonmoral grounds, because in most existing societies social positions are distributed unevenly across the social spectrum, or on moral grounds, because the equiprobability assumption enforces the moral ideal of impersonality and it does not model adequately the moral ideal of impartiality. An adequate way to model only the moral ideal of impartiality and not the moral ideal of impersonality is to make agents’ choices in the moral decision situation independent of specific probability assignments with regard to outcomes, as Rawls demands for the original position, because in this case no social position is favored probabilistically.<sup>
<xref ref-type="fn" rid="fn35-1470594X12460639">35</xref>
</sup>
</p>
<p>In the moral decision situation, all members of society, strong or weak, are assumed to have a say in the decision-making process regarding the principle of conflict resolution. The decision-making process fulfills the non-exclusion condition and, in this sense, respects the autonomy of all group members. More precisely, all members of society are assumed to have an <italic>equal</italic> say in the decision-making process. This demand can be seen as a literal interpretation of Harsanyi’s equal-treatment-of-all-individuals axiom that is compatible with individual rational agency because it does not enforce the moral ideal of impersonality. Instead, as in Rawls’s original position, all <italic>individuals</italic> are treated equally in the social decision-making process, and not only individuals’ capacities to generate utility, as demanded by Harsanyi’s two justifications of utilitarianism. Which principle of conflict resolution would Bayesian agents choose in the described moral decision situation?</p>
<p>Bayesian agents make choices on the basis of their preferences over outcomes that capture their desires. The probabilities that agents assign to possible outcomes in a decision situation reflect their state of knowledge about the world. As previously indicated, if Bayesian agents face a situation of uncertainty in which they have no information whatsoever about the likelihood of possible outcomes, then they will usually apply a version of the principle of insufficient reason and assign equal probabilities to all possible outcomes. In the described moral decision situation, however, agents’ choices must be independent of such probability assignments with regard to outcomes, and thus agents cannot rely on specific expected utility calculations under the veil of ignorance.</p>
<p>However, that Bayesian agents cannot assign <italic>specific</italic> probabilities to outcomes in the described moral decision situation does not mean that they cannot make a choice at all. Instead, under the circumstances described, Bayesian agents will choose a meta-principle that <italic>generally</italic> allows them to assign probabilities to outcomes as a basis for decision-making and thereby implements the Bayesian mode of thinking and acting. In the described moral decision situation, Bayesian agents will choose a principle that generally allows them to exercise their Bayesian rationality because this choice is the only one that is consistent with the agents’ rationality under the veil of ignorance.</p>
<p>Stated more precisely, in the described moral decision situation Bayesian agents will choose a principle of conflict resolution that allows them to satisfy their individual preferences in conflict situations as much as possible based on their actual capacities in the world in which they live <italic>independently</italic> of their precise social positions and the precise constitution of their society because this is the only choice under the veil of ignorance that guarantees Bayesian agency and does not rely on specific probability assignments with regard to outcomes, and thus does not favor any particular position in society probabilistically. Under the circumstances described, Bayesian agents will choose a principle of conflict resolution that best allows them to behave as if they were to maximize their expected individual utility, as demanded by Bayesian rationality, in whatever position of society they will be and independent of the precise social structure of their society.</p>
<p>In order to determine the principle of conflict resolution that best fulfills this demand, agents in the moral decision situation must imagine that they occupy, hypothetically and consecutively, all existing positions of society, and they must then evaluate which principle allows them to maximize their expected individual utility based on their actual capacities in all of these positions.<sup>
<xref ref-type="fn" rid="fn36-1470594X12460639">36</xref>
</sup> The Nash bargaining solution, in contrast to the average utility principle, fulfills this demand because independent of the actual positions in which individuals are after they leave the moral decision situation, the Nash bargaining solution allows agents to maximize their expected individual utility as much as possible based on their actual capacities in the world in which they live, as required by Bayesian rationality. The Nash bargaining solution allows, in contrast to the average utility principle, individual utility-maximizing behavior independently of the state of the world that is realized after agents leave the moral decision situation.</p>
<p>This line of reasoning shows that Harsanyi’s claim that rational individuals cannot make a choice under the veil of ignorance that does not, at least implicitly, reflect specific subjective probability assignments with regard to outcomes is wrong. The choice of the average utility principle and the choice of the difference principle reflect specific probability assignments with regard to outcomes under the veil of ignorance, namely, the assignment of equal probabilities to all possible outcomes and the assignment of a very high probability to the worst outcome, respectively. The choice of the Nash bargaining solution, by contrast, does not rely on such probability considerations and, in this sense, represents an impartial choice. The Nash bargaining solution does not favor any particular position in society, and thus can be justified as a principle of conflict resolution to all rational individuals in the described moral decision situation.</p>
<p>However, the Nash bargaining solution does not necessarily protect individual rational agency, because it allows the strong party to a conflict not only to gain more than an equal share of the goods that are in dispute, but also to take the life of her opponent, if such behavior maximizes the agent's expected individual utility. Because individuals in the moral decision situation do not know in which position in society they will be after the veil of ignorance is lifted and whether they will always be strong enough to protect their individual agency in conflict situations, assuming natural equality among agents in the real world, rational individuals will demand that a potential principle of conflict resolution guarantees at least their existence as separate agents because only then can agents function as sources of individual utility. Bayesian agents will demand, at the very least, that their physical integrity and their existence as separate agents is secured, and thus that they are always granted at least the means that they need to survive as a basis for conflict resolution, if the goods that are in dispute permit it.</p>
<p>This demand is a consequence of the features of the impersonality constraint, as discussed in Section 2. Bayesian agents reject the impersonality constraint as a general restriction on their reasoning and consequent behavior because the impersonality constraint does not guarantee, conceptually and in the real world, the existence of agents as individual utility maximizers, and thus their existence as Bayesian agents. As a consequence, in order to guarantee their agency, Bayesian agents will demand that a principle of conflict resolution protects at least their physical integrity and guarantees at least a level of well-being that allows agents to sustain their separate existence in the world in which they live.<sup>
<xref ref-type="fn" rid="fn37-1470594X12460639">37</xref>
</sup> In short, I say that a principle of conflict resolution must allow agents to reach at least their <italic>minimum standards of living</italic> as a basis for conflict resolution, if the goods that are in dispute permit it.<sup>
<xref ref-type="fn" rid="fn38-1470594X12460639">38</xref>
</sup>
</p>
<p>The standard Nash bargaining solution does not necessarily fulfill this demand, and thus does not necessarily secure individual agency as required by Bayesian rationality. As such, this second condition must be added to the demands of the standard Nash bargaining solution as a side constraint in order to secure stable long-term cooperation among rational agents.<sup>
<xref ref-type="fn" rid="fn39-1470594X12460639">39</xref>
</sup> Elsewhere, I have called the resulting principle the ‘stabilized Nash bargaining solution’<sup>
<xref ref-type="fn" rid="fn40-1470594X12460639">40</xref>
</sup> and its generalized and universalized version the ‘weak principle of universalization’.<sup>
<xref ref-type="fn" rid="fn41-1470594X12460639">41</xref>
</sup> The weak principle of universalization reads as follows (Moehler 2012: 100).</p>
<disp-quote>
<p>In cases of conflict, only pursue your interests subject to the side constraints that your opponents can (i) enter the process of conflict resolution at least from their minimum standards of living, if the goods that are in dispute permit it, and (ii) fulfill their interests above this level according to their relative bargaining power.</p>
</disp-quote>
<p>The weak principle of universalization renders agents’ bargaining power partly dependent on the standards of living that they, and their opponents in cases of conflict, have reached. It allows the strong parties to a conflict to gain more in the process of conflict resolution if all parties to a conflict are above their minimum standards of living with regard to the goods that are in dispute at the beginning of the process of conflict resolution. The weak principle of universalization restricts the bargaining power of the strong parties to a conflict if the weak parties fall below their minimum standards of living and the goods that are in dispute allow the weak parties to reach their minimum standards of living as a basis for conflict resolution. According to the weak principle of universalization, the lowest defensible disagreement point for bargaining processes in cases of conflict is an agent’s minimum standard of living in the minimal sense defined.<sup>
<xref ref-type="fn" rid="fn42-1470594X12460639">42</xref>
</sup>
</p>
<p>The weak principle of universalization will be accepted by Bayesian agents who choose a principle of conflict resolution in a hypothetical decision situation that enforces the moral ideals of autonomy, impartiality, and equality in the sense described. The specific design of the moral decision situation developed in this article leads Bayesian agents to agree on a principle of conflict resolution that protects not only their own existence, but also the existence of all other members of society, and otherwise allows agents to behave as if they were to maximize their expected individual utility based on their actual capacities in the world in which they live.<sup>
<xref ref-type="fn" rid="fn43-1470594X12460639">43</xref>
</sup>
</p>
</sec>
<sec id="section5-1470594X12460639">
<title>5. Conclusion</title>
<p>Harsanyi’s axiomatic proof of utilitarianism on the grounds of Bayesian rationality relies essentially on the impersonality constraint. I have argued that the impersonality constraint, as expressed by the social aggregation process that underlies Harsanyi’s axiomatic proof of utilitarianism, generally is conceptually incompatible with Bayesian rationality because it demands that individuals neglect conceptually their existence as separate agents who behave as if they were to maximize their expected individual utility. As a consequence, Bayesian agents will reject the impersonality constraint, and the impersonal form of equality expressed by Harsanyi’s equal-treatment-of-all-individuals axiom, as a general restriction on their reasoning and consequent behavior. Without the impersonality constraint, Harsanyi’s axiomatic proof of utilitarianism fails. Further, Harsanyi’s non-axiomatic justification of utilitarianism by means of the equiprobability model, and indirectly by Rawls’s original position, also fails, because the equiprobability assumption, which is central to Harsanyi’s equiprobability model and his understanding of Rawls’s original position, together with Harsanyi’s thin veil of ignorance, imposes the same moral constraints on Bayesian agents as Harsanyi’s axiomatic proof of utilitarianism.</p>
<p>If the impersonality constraint is eliminated from Harsanyi’s two justifications of utilitarianism, and Harsanyi’s equal-treatment-of-all-individuals axiom is taken literally so that it is compatible with individual rational agency, then Bayesian agents will reach a contractarian moral conclusion. More precisely, Bayesian agents will agree with the weak principle of universalization if they choose a principle of conflict resolution in a moral decision situation that (1) respects individual autonomy by including all members of society in the decision-making process (non-exclusion condition), (2) treats all members of society equally by assigning all individuals equal say in the decision-making process (equal-treatment-of-all-individuals axiom), and (3) enforces an impartial choice on a social outcome that fulfills the Pareto-optimality condition.</p>
<p>In more general terms, the discussion in this article shows that one essential difference between utilitarian ethics and contractarian ethics is the significance that the two different types of moral theory assign to individual agency. Contractarian moral theories assign priority to individual agency and protect individual agency by restricting interpersonal utility aggregations to the extent that interpersonal welfare comparisons are rejected by individual agents.<sup>
<xref ref-type="fn" rid="fn44-1470594X12460639">44</xref>
</sup> Utilitarian theories, by contrast, assign priority to the impersonal group utility and license interpersonal utility aggregations. As a consequence, utilitarian ethics may be very demanding on individual agents because it may not sufficiently protect individual agency.<sup>
<xref ref-type="fn" rid="fn45-1470594X12460639">45</xref>
</sup> For this reason, contractarian ethics is more attractive than utilitarian ethics for Bayesian agents who, by definition, behave as if they were to maximize their expected individual utility.</p>
<p>On reflection, Harsanyi seems to have realized the closeness of Bayesian rationality and contractarian ethics with his use of the equiprobability model and his later reference to Rawls’s original position for his justification of moral conclusions on the grounds of Bayesian rationality. For this reason, Harsanyi is sometimes called a ‘contractualist rule utilitarian’ (see, for example, Ashford, 2003: 295). However, Harsanyi is misled in his reasoning when he includes the impersonality constraint as a premise for the derivation of moral conclusions on the grounds of Bayesian rationality, because the impersonality constraint, in the sense described in this article, generally is conceptually incompatible with Bayesian rationality.</p>
</sec>
</body>
<back>
<notes>
<title>Notes</title>
<fn-group>
<fn fn-type="other" id="fn1-1470594X12460639">
<label>1.</label>
<p>The term ‘proof’ is used with reference to Harsanyi’s axiomatic justification of utilitarianism because <xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi (1978</xref>: 223, 226) argues that the Bayesian concept of rationality, together with some weak moral constraints, entails utilitarian ethics ‘logically’ or as a matter of ‘mathematical necessity’.</p>
</fn>
<fn fn-type="other" id="fn2-1470594X12460639">
<label>2.</label>
<p>For further discussion of Harsanyi’s proof and alternative versions of his representation theorem, see, in particular, <xref ref-type="bibr" rid="bibr18-1470594X12460639">Domotor (1979)</xref>, <xref ref-type="bibr" rid="bibr58-1470594X12460639">Resnik (1983)</xref>, <xref ref-type="bibr" rid="bibr19-1470594X12460639">Fishburn (1984)</xref>, <xref ref-type="bibr" rid="bibr10-1470594X12460639">Border (1985)</xref>, <xref ref-type="bibr" rid="bibr16-1470594X12460639">Coulhon and Mongin (1989)</xref>, <xref ref-type="bibr" rid="bibr13-1470594X12460639">Broome (1987</xref>, <xref ref-type="bibr" rid="bibr14-1470594X12460639">1991</xref>), <xref ref-type="bibr" rid="bibr25-1470594X12460639">Hammond (1992)</xref>, <xref ref-type="bibr" rid="bibr74-1470594X12460639">Weymark (1993</xref>, <xref ref-type="bibr" rid="bibr75-1470594X12460639">1995</xref>), and <xref ref-type="bibr" rid="bibr48-1470594X12460639">Mongin (2001)</xref>.</p>
</fn>
<fn fn-type="other" id="fn3-1470594X12460639">
<label>3.</label>
<p>For such criticism, see <xref ref-type="bibr" rid="bibr65-1470594X12460639">Sen (1970a</xref>, <xref ref-type="bibr" rid="bibr67-1470594X12460639">1976</xref>, <xref ref-type="bibr" rid="bibr68-1470594X12460639">1977</xref>), <xref ref-type="bibr" rid="bibr73-1470594X12460639">Weymark (1991)</xref>, and <xref ref-type="bibr" rid="bibr60-1470594X12460639">Roemer (1996</xref>, <xref ref-type="bibr" rid="bibr61-1470594X12460639">2008</xref>). For a defense of Harsanyi’s utilitarian theorem, although with qualifications, see <xref ref-type="bibr" rid="bibr59-1470594X12460639">Risse (2002)</xref>.</p>
</fn>
<fn fn-type="other" id="fn4-1470594X12460639">
<label>4.</label>
<p>For a formal and comprehensive statement of Harsanyi’s axiomatic proof of utilitarianism, see <xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi (1978</xref>: 226–7).</p>
</fn>
<fn fn-type="other" id="fn5-1470594X12460639">
<label>5.</label>
<p>For a precise statement of these rationality postulates, see <xref ref-type="bibr" rid="bibr33-1470594X12460639">Harsanyi (1978</xref>: 223–5).</p>
</fn>
<fn fn-type="other" id="fn6-1470594X12460639">
<label>6.</label>
<p>For further discussion of Harsanyi’s understanding of Bayesianism, see <xref ref-type="bibr" rid="bibr37-1470594X12460639">Harsanyi (1983)</xref>.</p>
</fn>
<fn fn-type="other" id="fn7-1470594X12460639">
<label>7.</label>
<p>Throughout this article, society is assumed to consist of a fixed and finite number of Bayesian agents.</p>
</fn>
<fn fn-type="other" id="fn8-1470594X12460639">
<label>8.</label>
<p>
<xref ref-type="bibr" rid="bibr17-1470594X12460639">Diamond (1967)</xref> questions the reasonableness of this assumption on moral grounds. For Harsanyi’s response to Diamond’s criticism, see <xref ref-type="bibr" rid="bibr29-1470594X12460639">Harsanyi (1975a</xref>).</p>
</fn>
<fn fn-type="other" id="fn9-1470594X12460639">
<label>9.</label>
<p>
<xref ref-type="bibr" rid="bibr31-1470594X12460639">Harsanyi (1977a</xref>: 48–9), for example, repeatedly refers to Adam Smith’s notion of an ‘impartial spectator’ in his discussion of utilitarianism, although Smith is not a utilitarian in any meaningful sense, as <xref ref-type="bibr" rid="bibr69-1470594X12460639">Sen (2009</xref>: 70) points out.</p>
</fn>
<fn fn-type="other" id="fn10-1470594X12460639">
<label>10.</label>
<p>For a more detailed discussion of the impartial observer theorem, see <xref ref-type="bibr" rid="bibr48-1470594X12460639">Mongin (2001)</xref>.</p>
</fn>
<fn fn-type="other" id="fn11-1470594X12460639">
<label>11.</label>
<p>For a critical discussion of the Pareto-optimality condition in the context of social choice theory, see <xref ref-type="bibr" rid="bibr66-1470594X12460639">Sen (1970b</xref>), for example.</p>
</fn>
<fn fn-type="other" id="fn12-1470594X12460639">
<label>12.</label>
<p>The non-exclusion condition is expressed formally by theorem 3, equation 2.1 of Harsanyi’s proof. See <xref ref-type="bibr" rid="bibr34-1470594X12460639">Harsanyi (1979</xref>: 294).</p>
</fn>
<fn fn-type="other" id="fn13-1470594X12460639">
<label>13.</label>
<p>Weighted utilitarianism, as presented by Harsanyi, does not require interpersonal utility comparisons, and thus may not necessarily be considered as a genuinely utilitarian position.</p>
</fn>
<fn fn-type="other" id="fn14-1470594X12460639">
<label>14.</label>
<p>The most influential criticism of this feature of utilitarianism goes back to <xref ref-type="bibr" rid="bibr76-1470594X12460639">Williams (1973)</xref>. For a recent, more general discussion of the demandingness of utilitarianism, see <xref ref-type="bibr" rid="bibr40-1470594X12460639">Hills (2010)</xref>. For a defense of utilitarianism despite its potential moral demandingness, see <xref ref-type="bibr" rid="bibr70-1470594X12460639">Singer (1972</xref>, <xref ref-type="bibr" rid="bibr71-1470594X12460639">2009</xref>), <xref ref-type="bibr" rid="bibr42-1470594X12460639">Kagan (1989)</xref>, and <xref ref-type="bibr" rid="bibr1-1470594X12460639">Ashford (2000</xref>, <xref ref-type="bibr" rid="bibr2-1470594X12460639">2003</xref>). For arguments that aim to show that utilitarianism, properly understood, is not as demanding as it might first appear, see <xref ref-type="bibr" rid="bibr50-1470594X12460639">Murphy (2000)</xref> and <xref ref-type="bibr" rid="bibr49-1470594X12460639">Muligan (2001)</xref>.</p>
</fn>
<fn fn-type="other" id="fn15-1470594X12460639">
<label>15.</label>
<p>A similar criticism was made earlier by Gauthier (1963: 123–7) and Nagel (1970: 138), and later by Nozick (1974: 33). Since then, many others have commented on this issue. See, for example, <xref ref-type="bibr" rid="bibr45-1470594X12460639">McKerlie (1988)</xref>, <xref ref-type="bibr" rid="bibr12-1470594X12460639">Brink (1993)</xref>, and <xref ref-type="bibr" rid="bibr78-1470594X12460639">Zwolinski (2008)</xref>.</p>
</fn>
<fn fn-type="other" id="fn16-1470594X12460639">
<label>16.</label>
<p>
<xref ref-type="bibr" rid="bibr7-1470594X12460639">Binmore (1998</xref>: 154–6, 523–9), in effect, presents such a criticism against Harsanyi.</p>
</fn>
<fn fn-type="other" id="fn17-1470594X12460639">
<label>17.</label>
<p>See Harsanyi (1978: 227; 1979: 295). To be precise, Harsanyi (1978: 227) argues that the equiprobability model requires ‘somewhat stronger philosophical commitments’ because the equiprobability model aims to justify the average utility principle and not merely sum-total utilitarianism, as Harsanyi's axiomatic proof of utilitarianism.</p>
</fn>
<fn fn-type="other" id="fn18-1470594X12460639">
<label>18.</label>
<p>For related discussion, see <xref ref-type="bibr" rid="bibr46-1470594X12460639">Moehler (2010</xref>: 456–8).</p>
</fn>
<fn fn-type="other" id="fn19-1470594X12460639">
<label>19.</label>
<p>For simplicity, I speak only of <italic>agents</italic> with regard to Rawls’s original position, and not of representatives of agents or representatives of groups of agents.</p>
</fn>
<fn fn-type="other" id="fn20-1470594X12460639">
<label>20.</label>
<p>As <xref ref-type="bibr" rid="bibr30-1470594X12460639">Harsanyi (1975b</xref>: 598) notes: ‘[Rawls] does not object to the equiprobability assumption as such <italic>if</italic> probabilities are to be used at all … What he objects to is the very use of probabilities in the original position.’</p>
</fn>
<fn fn-type="other" id="fn21-1470594X12460639">
<label>21.</label>
<p>See also <xref ref-type="bibr" rid="bibr6-1470594X12460639">Binmore (1994</xref>: 327–9).</p>
</fn>
<fn fn-type="other" id="fn22-1470594X12460639">
<label>22.</label>
<p>For further discussion of rational behavior in situations of uncertainty, see <xref ref-type="bibr" rid="bibr9-1470594X12460639">Binmore (2009</xref>: 154–74).</p>
</fn>
<fn fn-type="other" id="fn23-1470594X12460639">
<label>23.</label>
<p>As <xref ref-type="bibr" rid="bibr27-1470594X12460639">Harsanyi (1955</xref>: 316) puts it: ‘I have argued … that an individual’s preferences satisfy this requirement of impersonality if they indicate what social situation he would choose if he did not know what his personal position would be in the new situation chosen (and in any of its alternatives) but rather had an <italic>equal</italic> chance of obtaining any of the social positions existing in this situation, from the highest down to the lowest.’</p>
</fn>
<fn fn-type="other" id="fn24-1470594X12460639">
<label>24.</label>
<p>Some moral and political philosophers, such as <xref ref-type="bibr" rid="bibr4-1470594X12460639">Barry (1995)</xref>, argue for a more substantive notion of impartiality that seems to equate the moral ideals of impartiality and equality. Such a use of the notion of impartiality is unfortunate, however, because it conflates two moral ideals with very different demands, although in <italic>certa</italic>in situations impartiality may demand equal treatment, in some sense, of all parties concerned. As <xref ref-type="bibr" rid="bibr52-1470594X12460639">Nagel (1987</xref>: 215) correctly puts it, ‘the requirement of impartiality … usually involves treating or counting everyone equally in some respect’. But it does not always do so, because otherwise the moral ideal of impartiality would be redundant.</p>
</fn>
<fn fn-type="other" id="fn25-1470594X12460639">
<label>25.</label>
<p>Rawls (1999: 65–70), for example, thinks that the worst-off position in society should receive special treatment, as his defense of the difference principle shows. Rawls’s notion of impartiality does not necessarily demand equal treatment of all parties concerned, although all members of society are assumed to have an equal say in the decision-making process that leads to Rawls’s two principles of justice.</p>
</fn>
<fn fn-type="other" id="fn26-1470594X12460639">
<label>26.</label>
<p>
<xref ref-type="bibr" rid="bibr1-1470594X12460639">Ashford (2000</xref>: 438) implicitly presents such an argument in her response to Williams’s criticism of utilitarianism.</p>
</fn>
<fn fn-type="other" id="fn27-1470594X12460639">
<label>27.</label>
<p>I use the term ‘side constraint’ in Nozick’s sense here. According to <xref ref-type="bibr" rid="bibr55-1470594X12460639">Nozick (1974</xref>: 29), a side constraint is a categorical restriction on behavior that cannot be overridden by consequentialist considerations.</p>
</fn>
<fn fn-type="other" id="fn28-1470594X12460639">
<label>28.</label>
<p>The position of contractarianism is linked closely with Hobbes’s notion of the social contract (1996). The most widely discussed modern contractarian moral and political theories in the tradition of Hobbes are defended by <xref ref-type="bibr" rid="bibr15-1470594X12460639">Buchanan (1975)</xref> and <xref ref-type="bibr" rid="bibr22-1470594X12460639">Gauthier (1986)</xref>. The position of contractualism is linked closely with Kant’s notion of the social contract (1998). The most widely discussed modern contractualist moral and political theories are defended by Rawls (1999) and <xref ref-type="bibr" rid="bibr63-1470594X12460639">Scanlon (1998)</xref>.</p>
</fn>
<fn fn-type="other" id="fn29-1470594X12460639">
<label>29.</label>
<p>For the Nash bargaining solution, see <xref ref-type="bibr" rid="bibr53-1470594X12460639">Nash (1950</xref>, <xref ref-type="bibr" rid="bibr54-1470594X12460639">1953</xref>).</p>
</fn>
<fn fn-type="other" id="fn30-1470594X12460639">
<label>30.</label>
<p>The Nash bargaining solution is grounded securely in noncooperative game theory. It is supported by the noncooperative bargaining solutions of <xref ref-type="bibr" rid="bibr77-1470594X12460639">Zeuthen (1930</xref>: Ch. 4), <xref ref-type="bibr" rid="bibr28-1470594X12460639">Harsanyi (1956</xref>: 144–57; 1977a: 141–66), and <xref ref-type="bibr" rid="bibr62-1470594X12460639">Rubinstein (1982)</xref>.</p>
</fn>
<fn fn-type="other" id="fn31-1470594X12460639">
<label>31.</label>
<p>For a discussion of the Pareto-optimality condition, see <xref ref-type="bibr" rid="bibr53-1470594X12460639">Nash (1950</xref>, <xref ref-type="bibr" rid="bibr54-1470594X12460639">1953</xref>).</p>
</fn>
<fn fn-type="other" id="fn32-1470594X12460639">
<label>32.</label>
<p>The best known bargaining solution that relies on interpersonal utility comparisons is the egalitarian bargaining solution. See, in particular, <xref ref-type="bibr" rid="bibr43-1470594X12460639">Kalai (1977)</xref>. <xref ref-type="bibr" rid="bibr7-1470594X12460639">Binmore (1998</xref>: 393–5) also defends such a proportional bargaining solution as an ethical solution concept in the context of his social contract theory. Other explicitly ethical bargaining solutions are defended by so-called arbitration models that specify bargaining outcomes that satisfy certain moral or fairness criteria. See, for example, <xref ref-type="bibr" rid="bibr11-1470594X12460639">Braithwaite (1955)</xref>.</p>
</fn>
<fn fn-type="other" id="fn33-1470594X12460639">
<label>33.</label>
<p>For a discussion of this point, see, for example, <xref ref-type="bibr" rid="bibr31-1470594X12460639">Harsanyi (1977a</xref>: 192–5).</p>
</fn>
<fn fn-type="other" id="fn34-1470594X12460639">
<label>34.</label>
<p>Due to the nature of his project, Binmore restricts discussion of the Nash bargaining solution to the special case in which the parties to a conflict have equal bargaining power. For further support of the Nash bargaining solution in the discussed context, see, for example, <xref ref-type="bibr" rid="bibr5-1470594X12460639">Binmore (1993</xref>: 131–56; 1994: 80–84; 1998: 77–95), <xref ref-type="bibr" rid="bibr3-1470594X12460639">Barry (1989</xref>: 22–4), and <xref ref-type="bibr" rid="bibr72-1470594X12460639">Skyrms (1996</xref>: 107). It is also telling that the later <xref ref-type="bibr" rid="bibr23-1470594X12460639">Gauthier (1993</xref>: 176–9), including in a paper that he presented as the keynote address at a conference commemorating the 25th anniversary of <italic>Morals by Agreement</italic> at York University in May 2011, rejects his own bargaining solution in favor of the Nash bargaining solution – although now Gauthier seems to reject bargaining approaches entirely in the context of the social contract.</p>
</fn>
<fn fn-type="other" id="fn35-1470594X12460639">
<label>35.</label>
<p>For further discussion of the relationship between the moral ideal of impartiality and probability assignments, see <xref ref-type="bibr" rid="bibr20-1470594X12460639">Gajdos and Kandil (2008)</xref>.</p>
</fn>
<fn fn-type="other" id="fn36-1470594X12460639">
<label>36.</label>
<p>For a somewhat similar procedure, see <xref ref-type="bibr" rid="bibr51-1470594X12460639">Nagel (1970</xref>: 140–2).</p>
</fn>
<fn fn-type="other" id="fn37-1470594X12460639">
<label>37.</label>
<p>More generally, one may describe these demands as necessary conditions for individual rational agency. For a similar argument in a slightly different context, see <xref ref-type="bibr" rid="bibr24-1470594X12460639">Gewirth (1978</xref>: 53–63), in particular Gewirth’s discussion of what he calls ‘basic goods’.</p>
</fn>
<fn fn-type="other" id="fn38-1470594X12460639">
<label>38.</label>
<p>For the purpose of this article, I assume that the members of society come to an agreement on the determinants that define an individual’s minimum standard of living and on a way to measure this.</p>
</fn>
<fn fn-type="other" id="fn39-1470594X12460639">
<label>39.</label>
<p>For further discussion of this point, see <xref ref-type="bibr" rid="bibr46-1470594X12460639">Moehler (2010</xref>: 451–2).</p>
</fn>
<fn fn-type="other" id="fn40-1470594X12460639">
<label>40.</label>
<p>See <xref ref-type="bibr" rid="bibr46-1470594X12460639">Moehler (2010</xref>: 455). For a formal discussion of the precise properties of the stabilized Nash bargaining solution, see the appendix to that article.</p>
</fn>
<fn fn-type="other" id="fn41-1470594X12460639">
<label>41.</label>
<p>See <xref ref-type="bibr" rid="bibr47-1470594X12460639">Moehler (2012)</xref>. In contrast to the justification of the weak principle of universalization presented in that article, I follow here Harsanyi’s two justifications of utilitarianism, and thus simply impose certain moral constraints on rational agents by placing them in a suitably tailored moral decision situation that reflects Harsanyi’s assumptions as closely as possible.</p>
</fn>
<fn fn-type="other" id="fn42-1470594X12460639">
<label>42.</label>
<p>If the goods that are in dispute do not allow all parties to a conflict to reach or maintain at least their minimum standards of living as a starting point for the process of conflict resolution, then the weak principle of universalization does not apply.</p>
</fn>
<fn fn-type="other" id="fn43-1470594X12460639">
<label>43.</label>
<p>For the application of the weak principle of universalization, agents must consider their own holdings and the holdings of their conflict partners to be justified, because these holdings determine the agents’ relative bargaining power. In other words, the status quo must be justified before the weak principle of universalization can be fully applied in practice.</p>
</fn>
<fn fn-type="other" id="fn44-1470594X12460639">
<label>44.</label>
<p>Scanlon’s contractualist moral theory (1998), for example, allows interpersonal comparisons of well-being to the extent that reasonable agents could not object to those comparisons, and thus could not reject a social state that is judged to be superior on the basis of such comparisons. Bayesian agents, by contrast, are rational and not reasonable, and therefore reject any interpersonal utility comparisons, if such comparisons do not allow the agents to improve their <italic>individual</italic> positions.</p>
</fn>
<fn fn-type="other" id="fn45-1470594X12460639">
<label>45.</label>
<p>In response to such criticism, more sophisticated versions of utilitarianism, and consequentialist moral theories more generally, have been developed, as well as moral theories that combine consequentialist and non-consequentialist considerations. See, for example, <xref ref-type="bibr" rid="bibr56-1470594X12460639">Railton (1984)</xref> and <xref ref-type="bibr" rid="bibr64-1470594X12460639">Scheffler (1994)</xref>.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ashford</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2000</year>) <article-title>Utilitarianism, integrity, and impartiality</article-title>. <source>Journal of Philosophy</source> <volume>97</volume>: <fpage>421</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr2-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ashford</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2003</year>) <article-title>The demandingness of Scanlon’s contractualism</article-title>. <source>Ethics</source> <volume>113</volume>: <fpage>273</fpage>–<lpage>302</lpage>.</citation>
</ref>
<ref id="bibr3-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Barry</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>1989</year>) <source>Theories of Justice</source>. <publisher-loc>Berkeley</publisher-loc>: <publisher-name>University of California Press</publisher-name>.</citation>
</ref>
<ref id="bibr4-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Barry</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>1995</year>) <source>Justice as Impartiality</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</citation>
</ref>
<ref id="bibr5-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Binmore</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>1993</year>) <article-title>Bargaining and morality</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Gauthier</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Sugden</surname>
<given-names>R</given-names>
</name>
</person-group> (eds) <source>Rationality, Justice and the Social Contract</source>. <publisher-loc>Ann Arbor</publisher-loc>: <publisher-name>Michigan University Press</publisher-name>.</citation>
</ref>
<ref id="bibr6-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Binmore</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>1994</year>) <source>Game Theory and the Social Contract, Volume 1: Playing Fair</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr7-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Binmore</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>1998</year>) <source>Game Theory and the Social Contract, Volume 2: Just Playing</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr8-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Binmore</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>2005</year>) <source>Natural Justice</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr9-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Binmore</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>2009</year>) <source>Rational Decisions</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Border</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>1985</year>) <article-title>More on Harsanyi’s utilitarian cardinal welfare theorem</article-title>. <source>Social Choice and Welfare</source> <volume>1</volume>: <fpage>279</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr11-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Braithwaite</surname>
<given-names>R</given-names>
</name>
</person-group> (<year>1955</year>) <source>Theory of Games as a Tool for the Moral Philosopher</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr12-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Brink</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1993</year>) <article-title>The separateness of persons, distributive norms, and moral theory</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Frey</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Morris</surname>
<given-names>C</given-names>
</name>
</person-group> (eds) <source>Value, Welfare and Morality</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr13-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Broome</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1987</year>) <article-title>Utilitarianism and expected utility</article-title>. <source>Journal of Philosophy</source> <volume>84</volume>: <fpage>405</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr14-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Broome</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1991</year>) <source>Weighing Goods</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Basil Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr15-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Buchanan</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1975</year>) <source>The Limits of Liberty</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr16-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Coulhon</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Mongin</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1989</year>) <article-title>Social choice theory in the case of Von Neumann–Morgenstern utilities</article-title>. <source>Social Choice and Welfare</source> <volume>6</volume>: <fpage>175</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr17-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Diamond</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1967</year>) <article-title>Cardinal welfare, individualistic ethics, and interpersonal comparisons of utility: Comment</article-title>. <source>Journal of Political Economy</source> <volume>75</volume>: <fpage>765</fpage>–<lpage>6</lpage>.</citation>
</ref>
<ref id="bibr18-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Domotor</surname>
<given-names>Z</given-names>
</name>
</person-group> (<year>1979</year>) <article-title>Ordered sum and tensor product of linear utility structures</article-title>. <source>Theory and Decision</source> <volume>11</volume>: <fpage>375</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr19-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fishburn</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1984</year>) <article-title>On Harsanyi’s utilitarian cardinal welfare theorem</article-title>. <source>Theory and Decision</source> <volume>17</volume>: <fpage>21</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr20-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gajdos</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Kandil</surname>
<given-names>F</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>The ignorant observer</article-title>. <source>Social Choice and Welfare</source> <volume>31</volume>: <fpage>193</fpage>–<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr21-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gauthier</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1963</year>) <source>Practical Reasoning</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gauthier</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1986</year>) <source>Morals by Agreement</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</citation>
</ref>
<ref id="bibr23-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gauthier</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1993</year>) <article-title>Uniting separate persons</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Gauthier</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Sugden</surname>
<given-names>R</given-names>
</name>
</person-group> (eds) <source>Rationality, Justice and the Social Contract</source>. <publisher-loc>Ann Arbor</publisher-loc>: <publisher-name>Michigan University Press</publisher-name>.</citation>
</ref>
<ref id="bibr24-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gewirth</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>1978</year>) <source>Reason and Morality</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr25-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hammond</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1992</year>) <article-title>Harsanyi’s utilitarian theorem: A simpler proof and some ethical considerations</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Selten</surname>
<given-names>R</given-names>
</name>
</person-group> (ed.) <source>Rational Interaction: Essays in Honor of John C. Harsanyi</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr26-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1953</year>) <article-title>Cardinal utility in welfare economics and in the theory of risk-taking</article-title>. <source>Journal of Political Economy</source> <volume>61</volume>: <fpage>434</fpage>–<lpage>5</lpage>.</citation>
</ref>
<ref id="bibr27-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1955</year>) <article-title>Cardinal welfare, individualistic ethics, and interpersonal comparisons of utility</article-title>. <source>Journal of Political Economy</source> <volume>63</volume>: <fpage>309</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr28-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1956</year>) <article-title>Approaches to the bargaining problem before and after the theory of games: A critical discussion of Zeuthen’s, Hicks’, and Nash’s theories</article-title>. <source>Econometrica</source> <volume>24</volume>: <fpage>144</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr29-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1975a</year>) <article-title>Nonlinear social welfare functions</article-title>. <source>Theory and Decision</source> <volume>6</volume>: <fpage>311</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr30-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1975b</year>) <article-title>Can the maximin principle serve as a basis for morality? A critique of John Rawls’s theory</article-title>. <source>American Political Science Review</source> <volume>69</volume>: <fpage>594</fpage>–<lpage>606</lpage>.</citation>
</ref>
<ref id="bibr31-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1977a</year>) <source>Rational Behavior and Bargaining Equilibrium in Games and Social Situations</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr32-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1977b</year>) <article-title>Rule utilitarianism and decision theory</article-title>. <source>Erkenntnis</source> <volume>11</volume>: <fpage>25</fpage>–<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr33-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1978</year>) <article-title>Bayesian decision theory and utilitarian ethics</article-title>. <source>American Economic Review</source> <volume>68</volume>: <fpage>223</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr34-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1979</year>) <article-title>Bayesian decision theory, rule utilitarianism, and Arrow’s impossibility theorem</article-title>. <source>Theory and Decision</source> <volume>11</volume>: <fpage>289</fpage>–<lpage>317</lpage>.</citation>
</ref>
<ref id="bibr35-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1980</year>) <article-title>Rule utilitarianism, rights, obligations and the theory of rational behavior</article-title>. <source>Theory and Decision</source> <volume>12</volume>: <fpage>115</fpage>–<lpage>33</lpage>.</citation>
</ref>
<ref id="bibr36-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1982 [1977]</year>) <article-title>Morality and the theory of rational behaviour</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Sen</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>B</given-names>
</name>
</person-group> (eds) <source>Utilitarianism and Beyond</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr37-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1983</year>) <article-title>Bayesian decision theory, subjective and objective probabilities, and acceptance of hypothetical hypotheses</article-title>. <source>Synthese</source> <volume>57</volume>: <fpage>341</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr38-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1985a</year>) <article-title>Does reason tell us what moral code to follow and, indeed, to follow any moral code at all?</article-title> <source>Ethics</source> <volume>96</volume>: <fpage>42</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr39-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harsanyi</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1985b</year>) <article-title>Rule utilitarianism, equality, and justice</article-title>. <source>Social Philosophy and Policy</source> <volume>2</volume>: <fpage>115</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr40-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hills</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Utilitarianism, contractualism, and demandingness</article-title>. <source>Philosophical Quarterly</source> <volume>60</volume>: <fpage>225</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr41-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hobbes</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>1996 [1651]</year>) <source>Leviathan</source>. <person-group person-group-type="editor">
<name>
<surname>Tuck</surname>
<given-names>R</given-names>
</name>
</person-group> (ed.). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr42-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kagan</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>1989</year>) <source>The Limits of Morality</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr43-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kalai</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>1977</year>) <article-title>Proportional solutions to bargaining situations: Interpersonal utility comparisons</article-title>. <source>Econometrica</source> <volume>45</volume>: <fpage>1623</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr44-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kant</surname>
<given-names>I</given-names>
</name>
</person-group> (<year>1998 [1785]</year>) <source>Groundwork of the Metaphysics of Morals</source>. <person-group person-group-type="editor"><name><surname>Gregor</surname><given-names>M</given-names></name></person-group> (ed.). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr45-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>McKerlie</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1988</year>) <article-title>Egalitarianism and the separateness of persons</article-title>. <source>Canadian Journal of Philosophy</source> <volume>18</volume>: <fpage>205</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr46-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Moehler</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>The (stabilized) Nash bargaining solution as a principle of distributive justice</article-title>. <source>Utilitas</source> <volume>22</volume>: <fpage>447</fpage>–<lpage>73</lpage>.</citation>
</ref>
<ref id="bibr47-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Moehler</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2012</year>) <article-title>A Hobbesian derivation of the principle of universalization</article-title>. <source>Philosophical Studies</source> <volume>158</volume>: <fpage>83</fpage>–<lpage>107</lpage>.</citation>
</ref>
<ref id="bibr48-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mongin</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2001</year>) <article-title>The impartial observer theorem of social ethics</article-title>. <source>Economics and Philosophy</source> <volume>17</volume>: <fpage>147</fpage>–<lpage>79</lpage>.</citation>
</ref>
<ref id="bibr49-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Muligan</surname>
<given-names>I</given-names>
</name>
</person-group> (<year>2001</year>) <source>The Demands of Consequentialism</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr50-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Murphy</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>2000</year>) <source>Moral Demands in Nonideal Theory</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr51-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Nagel</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>1970</year>) <source>The Possibility of Altruism</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</citation>
</ref>
<ref id="bibr52-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nagel</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>1987</year>) <article-title>Moral conflict and political legitimacy</article-title>. <source>Philosophy and Public Affairs</source> <volume>16</volume>: <fpage>215</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr53-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nash</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1950</year>) <article-title>The bargaining problem</article-title>. <source>Econometrica</source> <volume>18</volume>: <fpage>155</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr54-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nash</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1953</year>) <article-title>Two-person cooperative games</article-title>. <source>Econometrica</source> <volume>21</volume>: <fpage>128</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr55-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Nozick</surname>
<given-names>R</given-names>
</name>
</person-group> (<year>1974</year>) <source>Anarchy, State, and Utopia</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</citation>
</ref>
<ref id="bibr56-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Railton</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1984</year>) <article-title>Alienation, consequentialism, and the demands of morality</article-title>. <source>Philosophy and Public Affairs</source> <volume>13</volume>: <fpage>134</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr57-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Rawls</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1999 [1971]</year>) <source>A Theory of Justice</source>, <edition>revised edn</edition>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr58-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Resnik</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>1983</year>) <article-title>A restriction on a theorem of Harsanyi</article-title>. <source>Theory and Decision</source> <volume>15</volume>: <fpage>309</fpage>–<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr59-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Risse</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>Harsanyi’s ‘utilitarian theorem’ and utilitarianism</article-title>. <source>Noûs</source> <volume>36</volume>: <fpage>550</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr60-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Roemer</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1996</year>) <source>Theories of Distributive Justice</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr61-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Roemer</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Harsanyi’s impartial observer is <italic>not</italic> a utilitarian</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Fleurbaey</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Salles</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Weymark</surname>
<given-names>J</given-names>
</name>
</person-group> (eds) <source>Justice, Political Liberalism, and Utilitarianism</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr62-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubinstein</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>1982</year>) <article-title>Perfect equilibrium in a bargaining model</article-title>. <source>Econometrica</source> <volume>50</volume>: <fpage>97</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr63-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Scanlon</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>1998</year>) <source>What We Owe to Each Other</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr64-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Scheffler</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>1994</year>) <source>The Rejection of Consequentialism</source>, <edition>revised edn</edition>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</citation>
</ref>
<ref id="bibr65-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sen</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>1970a</year>) <source>Collective Choice and Social Welfare</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Holden-Day</publisher-name>.</citation>
</ref>
<ref id="bibr66-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sen</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>1970b</year>) <article-title>The impossibility of a Paretian liberal</article-title>. <source>Journal of Political Economy</source> <volume>78</volume>: <fpage>152</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr67-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sen</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>1976</year>) <article-title>Welfare inequalities and Rawlsian axiomatics</article-title>. <source>Theory and Decision</source> <volume>7</volume>: <fpage>243</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr68-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sen</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>1977</year>) <article-title>Non-linear social welfare functions: A reply to Professor Harsanyi</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Butts</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Hinitikka</surname>
<given-names>J</given-names>
</name>
</person-group> (eds) <source>Foundational Problems in the Special Sciences</source>. <publisher-loc>Dordrecht</publisher-loc>: <publisher-name>Reidel</publisher-name>.</citation>
</ref>
<ref id="bibr69-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sen</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>2009</year>) <source>The Idea of Justice</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Belknap Press</publisher-name>.</citation>
</ref>
<ref id="bibr70-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Singer</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1972</year>) <article-title>Famine, affluence, and morality</article-title>. <source>Philosophy and Public Affairs</source> <volume>1</volume>: <fpage>229</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr71-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Singer</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2009</year>) <source>The Life You Can Save</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Random House</publisher-name>.</citation>
</ref>
<ref id="bibr72-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Skyrms</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>1996</year>) <source>Evolution of the Social Contract</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr73-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Weymark</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1991</year>) <article-title>A reconsideration of the Harsanyi–Sen debate on utilitarianism</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Elster</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Roemer</surname>
<given-names>J</given-names>
</name>
</person-group> (eds) <source>Interpersonal Comparisons of Well-Being</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr74-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Weymark</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1993</year>) <article-title>Harsanyi’s social aggregation theorem and the weak Pareto principle</article-title>. <source>Social Choice and Welfare</source> <volume>10</volume>: <fpage>209</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr75-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Weymark</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1995</year>) <article-title>Further remarks on Harsanyi’s social aggregation theorem and the weak Pareto principle</article-title>. <source>Social Choice and Welfare</source> <volume>12</volume>: <fpage>87</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr76-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Williams</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>1973</year>) <article-title>A critique of utilitarianism</article-title>. In: <person-group person-group-type="editor">
<name>
<surname>Smart</surname>
<given-names>JJC</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>B</given-names>
</name>
</person-group> (eds) <source>Utilitarianism For and Against</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr77-1470594X12460639">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Zeuthen</surname>
<given-names>F</given-names>
</name>
</person-group> (<year>1930</year>) <source>Problems of Monopoly and Economic Warfare</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Routledge and Kegan Paul</publisher-name>.</citation>
</ref>
<ref id="bibr78-1470594X12460639">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zwolinski</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>The separateness of persons and liberal theory</article-title>. <source>Journal of Value Inquiry</source> <volume>42</volume>: <fpage>147</fpage>–<lpage>65</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>