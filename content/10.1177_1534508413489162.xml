<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">AEI</journal-id>
<journal-id journal-id-type="hwp">spaei</journal-id>
<journal-title>Assessment for Effective Intervention</journal-title>
<issn pub-type="ppub">1534-5084</issn>
<issn pub-type="epub">1938-7458</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1534508413489162</article-id>
<article-id pub-id-type="publisher-id">10.1177_1534508413489162</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Social Studies Progress Monitoring and Intervention for Middle School Students</article-title>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Lembke</surname><given-names>Erica S.</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Beyers</surname><given-names>Sarah J.</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508413489162">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Lembke</surname><given-names>Erica S.</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508413489162">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Curs</surname><given-names>Bradley</given-names></name>
<degrees>PhD</degrees>
<xref ref-type="aff" rid="aff1-1534508413489162">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1534508413489162"><label>1</label>University of Missouri, Columbia, USA</aff>
<author-notes>
<corresp id="corresp1-1534508413489162">Erica S. Lembke, University of Missouri, 311 J Townsend Hall, Columbia, MO 65211, USA. Email: <email>lembkee@missouri.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2013</year>
</pub-date>
<volume>38</volume>
<issue>4</issue>
<issue-title>Special Series: Content Area Measurement Using Curriculum-Based Measurement</issue-title>
<fpage>224</fpage>
<lpage>235</lpage>
<permissions>
<copyright-statement>© Hammill Institute on Disabilities 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="other">Hammill Institute on Disabilities</copyright-holder>
</permissions>
<abstract>
<p>This study examined the technical adequacy of vocabulary-matching curriculum-based measurement (CBM) to identify and monitor the progress of 148 middle school students in social studies. In addition, the effectiveness of a reading comprehension intervention, Collaborative Strategic Reading (Klingner, Vaughn, Dimino, Schumm, &amp; Bryant, 2001), was examined across 8 weeks with 15 low-achieving middle school readers who were monitored with content-area reading passages. Results indicated vocabulary-matching CBMs are valid and reliable indicators of performance in social studies. Significant differences were found for the intervention group on performance on pre to post vocabulary-matching CBM scores. Difference-in-Differences regression models were used to examine differences between groups on pre–post measures. No significant differences were found between groups in weekly change in scores or trend in performance on vocabulary-matching CBM.</p>
</abstract>
<kwd-group>
<kwd>content-area assessment</kwd>
<kwd>curriculum-based measurement</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>While much attention has been given to improving reading achievement in elementary and early childhood settings, there have been limited resources dedicated to improving reading proficiencies of students in Grades 5 to 12 (<xref ref-type="bibr" rid="bibr1-1534508413489162">Allington, 2002</xref>). According to the <xref ref-type="bibr" rid="bibr30-1534508413489162">National Center for Educational Statistics (NCES, 2011)</xref>, for students in Grades 4 and 8, there have been no significant changes in reading scores from 2009 until 2011.</p>
<p>Transitioning from an elementary to a secondary setting can be difficult for a number of students. These difficulties are often attributed to a shift in learning demands because students are expected to have proficient reading skills (<xref ref-type="bibr" rid="bibr6-1534508413489162">Busch &amp; Espin, 2003</xref>). <xref ref-type="bibr" rid="bibr8-1534508413489162">Edmonds et al. (2009)</xref> explain that secondary student expectations include being able to learn at a more rapid pace and having the ability to consume more complex content. Edmonds and her colleagues discuss that secondary students are expected to be able to decode and comprehend text; however, there is infrequent instruction on these skills once students leave elementary school.</p>
<p>In addition, <xref ref-type="bibr" rid="bibr19-1534508413489162">Katims and Harmon (2000)</xref> further suggest that even the simple transition to the use of textbooks increases the literacy demands for students in middle schools. <xref ref-type="bibr" rid="bibr8-1534508413489162">Edmunds et al. (2009)</xref> explain that the readability of textbooks at the secondary level is often too high and poses challenges in comprehension for many students but especially those reading below grade level. For some students, comprehension difficulties are more pronounced in content-specific texts due to the expectation that the student can adequately read and understand textbooks (<xref ref-type="bibr" rid="bibr1-1534508413489162">Allington, 2002</xref>; <xref ref-type="bibr" rid="bibr6-1534508413489162">Busch &amp; Espin, 2003</xref>).</p>
<p>In content-specific classrooms, teachers often neglect to teach students how to read to better understand content (<xref ref-type="bibr" rid="bibr6-1534508413489162">Busch &amp; Espin, 2003</xref>). There appears to be an assumption that if students are able to read text, they will merely learn by reading (<xref ref-type="bibr" rid="bibr8-1534508413489162">Edmonds et al., 2009</xref>). However, students with minimal word decoding skills also demonstrate limited vocabularies, thus making students more prone to failure in content areas that require a student to learn new terminology (<xref ref-type="bibr" rid="bibr15-1534508413489162">Harmon, Hedrick, &amp;Wood, 2005</xref>). <xref ref-type="bibr" rid="bibr6-1534508413489162">Busch and Espin (2003)</xref> discuss that vocabulary is also connected to comprehension. They emphasize that the interdependence between comprehension and vocabulary knowledge becomes greater as students advance through their academic careers, especially in content-area classes. In addition, the NCES found that 4th, 8th, and 12th graders obtaining higher scores on vocabulary questions also obtained high scores on reading comprehension questions (<xref ref-type="bibr" rid="bibr31-1534508413489162">NCES, 2012</xref>).</p>
<p>There has been a recent emphasis on student achievement in content areas such as social studies and science, which require learning and understanding new vocabulary (<xref ref-type="bibr" rid="bibr35-1534508413489162">Vannest, Parker, &amp; Dyer, 2011</xref>). To improve the learning of low-achieving students in secondary content areas, instructional data-based decision making is warranted (<xref ref-type="bibr" rid="bibr5-1534508413489162">Burns, 2008</xref>) including screening to identify students at risk, progress monitoring of these students, and evidence-based intervention options when instruction is not successful.</p>
<sec id="section1-1534508413489162">
<title>Intervention</title>
<p>Seventy percent of secondary students require some type of reading remediation (<xref ref-type="bibr" rid="bibr2-1534508413489162">Biancarosa &amp; Snow, 2004</xref>). Because many students who exhibit reading difficulties are not identified as having a learning disability, it is necessary to determine the best practices for providing reading instruction to those students who do not qualify for special education services but are still low achieving (<xref ref-type="bibr" rid="bibr8-1534508413489162">Edmonds et al., 2009</xref>). Despite low reaching achievement in middle schools, <xref ref-type="bibr" rid="bibr37-1534508413489162">Vaughn et al. (2013)</xref> indicate that most teachers at the middle school level are not equipped or do not feel responsible to provide the level of intense instruction needed to assist poor readers as they access content-level text. With many demands on teachers to cover large amounts of content for state standardized assessments and limited time for remedial reading instruction, it is logical that interventions targeting comprehension strategies be provided to students while they learn content-area concepts and knowledge (<xref ref-type="bibr" rid="bibr6-1534508413489162">Busch &amp; Espin, 2003</xref>; <xref ref-type="bibr" rid="bibr8-1534508413489162">Edmonds et al., 2009</xref>; Katims &amp; <xref ref-type="bibr" rid="bibr15-1534508413489162">Harmon, 2005</xref>; <xref ref-type="bibr" rid="bibr37-1534508413489162">Vaughn et al., 2013</xref>).</p>
<p>Therefore, is it important to examine the effectiveness of reading comprehension interventions that can be provided during content-area instruction to all types of learners. Collaborative Strategic Reading (CSR) is a research-based intervention that has the ability to be used within any content materials from grade levels 4 to 12 (<xref ref-type="bibr" rid="bibr23-1534508413489162">Klingner, Vaughn, Boardman, &amp; Swanson, 2012</xref>). With roots in reciprocal teaching, this intervention combines direct instruction of comprehension strategies and cooperative learning (<xref ref-type="bibr" rid="bibr23-1534508413489162">Klingner et al., 2012</xref>). CSR focuses on providing a procedure for comprehending texts while students work in collaborative groups to increase the use of four metacognitive strategies: Preview, Click and Clunk, Get the Gist, and Wrap Up. Before reading, students brainstorm and predict what is about to be read (Preview). During reading, students identify unknown vocabulary and use “fix-up” strategies, such as re-reading sentences to look for key ideas (Click and Clunk). Next, students detect the main idea of each section of text in their own words in 10 words or less (Get the Gist). After reading, students write down the most important concepts in a CSR learning log and ask peers questions to check for understanding to aid in mentally organizing information and transferring it to memory (Wrap Up; <xref ref-type="bibr" rid="bibr23-1534508413489162">Klingner et al., 2012</xref>).</p>
<p>CSR has been used in many different types of subjects including language arts, social studies, and science at the elementary and middle school levels (<xref ref-type="bibr" rid="bibr4-1534508413489162">Bryant et al., 2000</xref>; <xref ref-type="bibr" rid="bibr16-1534508413489162">Hitchcock, Dimino, Kurki, Wilkins, &amp; Gersten, 2010</xref>; <xref ref-type="bibr" rid="bibr21-1534508413489162">Klingner &amp; Vaughn, 2000</xref>; <xref ref-type="bibr" rid="bibr22-1534508413489162">Klingner, Vaughn, Argüelles, Hughes, &amp; Ahwee, 2004</xref>; <xref ref-type="bibr" rid="bibr25-1534508413489162">Klingner, Vaughn, &amp; Schumm, 1998</xref>; <xref ref-type="bibr" rid="bibr36-1534508413489162">Vaughn et al., 2011</xref>).Thus, it appears it is an appropriate intervention to bolster comprehension while helping students to access social studies content. While CSR has demonstrated increased reading and comprehension outcomes, continued research is needed surrounding CSR’s effectiveness with struggling students who are not identified as learning disabled in general education classes (<xref ref-type="bibr" rid="bibr22-1534508413489162">Klingner et al., 2004</xref>; <xref ref-type="bibr" rid="bibr36-1534508413489162">Vaughn et al., 2011</xref>).</p>
<p>In addition, much of the previous literature focuses on pre–post measurement of student outcomes from the intervention and control groups in CSR studies. Screening to determine students needing this intervention and progress-monitoring tools to monitor student progress while implementing the CSR intervention have yet to be identified. Practitioners need appropriate measures to monitor student progress throughout interventions to make necessary modifications to meet a student’s learning needs (<xref ref-type="bibr" rid="bibr7-1534508413489162">Deno, 1985</xref>).</p>
</sec>
<sec id="section2-1534508413489162">
<title>Screening and Progress Monitoring in Content Areas</title>
<p>To identify students and enhance instruction, measures are needed for student screening. Screening involves administering measures to students in the fall, winter, and spring, used as a checkpoint for average achieving students and to identify those needing more assistance (<xref ref-type="bibr" rid="bibr26-1534508413489162">Lembke &amp; Stecker, 2007</xref>). Specific to secondary settings, three types of curriculum-based measurement (CBM; <xref ref-type="bibr" rid="bibr7-1534508413489162">Deno, 1985</xref>) screening tools have been researched: Oral Reading Fluency (ORF), Maze, and Vocabulary-Matching (<xref ref-type="bibr" rid="bibr10-1534508413489162">Espin &amp; Deno, 1993</xref>, <xref ref-type="bibr" rid="bibr11-1534508413489162">1995</xref>; <xref ref-type="bibr" rid="bibr12-1534508413489162">Espin &amp; Foegen, 1996</xref>).</p>
<p>From these studies, it was suggested vocabulary-matching CBM might be the best predictor of student performance in secondary content areas, compared with the Maze comprehension and ORF probes (<xref ref-type="bibr" rid="bibr11-1534508413489162">Espin &amp; Deno, 1995</xref>; <xref ref-type="bibr" rid="bibr12-1534508413489162">Espin &amp; Foegen, 1996</xref>). <xref ref-type="bibr" rid="bibr9-1534508413489162">Espin, Busch, Shin and Kruschwitz (2001)</xref> and <xref ref-type="bibr" rid="bibr13-1534508413489162">Espin, Shin and Busch (2005)</xref> examined the technical adequacy of vocabulary measures as a screening and progress-monitoring tool with middle school students. Results indicated moderate to strong validity correlations with standardized criterion measures (<italic>r</italic> =.64–.87), acceptable alternate-form reliability ranges <italic>(r</italic> =.58–.81), and an overall growth rate of .65 correct matches per week for student-read probes. To further provide teachers with appropriate formative assessment and advance the field of content-area CBM, there is a need for additional evidence that vocabulary-matching CBM can affect student achievement and reliably predict content-area performance (<xref ref-type="bibr" rid="bibr3-1534508413489162">Borsuk, 2010</xref>; <xref ref-type="bibr" rid="bibr13-1534508413489162">Espin et al., 2005</xref>; <xref ref-type="bibr" rid="bibr27-1534508413489162">Mooney, McCarter, Schraven, &amp; Haydel, 2010</xref>; <xref ref-type="bibr" rid="bibr28-1534508413489162">Mooney, Schraven, &amp; Cox, 2010</xref>; <xref ref-type="bibr" rid="bibr35-1534508413489162">Vannest et al., 2011</xref>).At this time, only two studies have examined vocabulary-matching CBM as a means to monitor progress in content classes over multiple weeks (<xref ref-type="bibr" rid="bibr13-1534508413489162">Espin et al., 2005</xref>; <xref ref-type="bibr" rid="bibr35-1534508413489162">Vannest et al., 2011</xref>). Further support is needed for the use of vocabulary-matching CBM to monitor student growth across time during classroom instruction and intervention.</p>
<p>Given the need for high-quality instructional tools in content-area subjects at the secondary level, coupled with the need to identify reliable and valid screening and progress-monitoring measures in content-area subjects, the present study examined the use of vocabulary-matching CBM to screen and monitor progress of students who may be at risk of difficulties in middle school social studies, while assessing the effectiveness of a reading intervention (CSR). Three general research questions were investigated:</p>
<list id="list1-1534508413489162" list-type="simple">
<list-item><p><italic>Research Question 1</italic>: Are vocabulary-matching measures a valid and reliable indicator of performance and progress of student learning in social studies?</p></list-item>
<list-item><p><italic>Research Question 2</italic>: Does a reading comprehension intervention increase the level of performance on vocabulary-matching measures and a standardized state social studies test compared with a control group?</p></list-item>
<list-item><p><italic>Research Question 3</italic>: Does a reading comprehension intervention increase the trend of weekly student performance on vocabulary-matching measures compared with a control group?</p></list-item>
</list>
</sec>
<sec id="section3-1534508413489162" sec-type="methods">
<title>Method</title>
<sec id="section4-1534508413489162">
<title>Participants</title>
<p>The study was conducted in two sixth-grade social studies classrooms in a suburban school district in the Midwest. District statistics indicated that overall middle school enrollment was 781 students consisting mostly of White students (52%) with 57% of students qualifying for free and reduced lunch. The overall sample consisted of 148 consented students and two White female social studies teachers. The student sample included 60 males and 88 females. Student ethnicities included 62% White, 23% African American, 9% Multiracial, 4% Hispanic, 1% Asian, and 1% American Indian. Eleven students qualified for special education services.</p>
<p>For the intervention portion of the study, a subsample of 32 students was selected including 19 females and 13 males who were 66% White, 28% African American, and 6% Hispanic. During the course of the intervention, one student dropped and her control group counterpart was also dropped from the study. Two undergraduate pre-service teachers and one graduate student were trained to implement the four CSR strategies: Preview, Click and Clunk, Get the Gist, and Wrap Up. An 8-hr training was completed with training materials obtained from CSR developers (the why and how behind CSR) as well as websites dedicated to professional development such as the IRIS center (<ext-link ext-link-type="uri" xlink:href="http://iris.peabody.vanderbilt.edu/">http://iris.peabody.vanderbilt.edu/</ext-link>). Instructional videos modeled strategies and direct instruction for the interventionists, and each interventionist engaged in a 2-hr hands-on practice implementing lesson plans with each other during the training. Modeling of lessons was provided by the researcher for all interventionists during the initial teaching/modeling lesson of each CSR strategy (Session 1 each week). Coaching was provided to interventionists during the first 3 weeks of implementation (by attending each session). Additional ongoing support was provided through fidelity checks completed by the second author.</p>
</sec>
<sec id="section5-1534508413489162">
<title>Measures</title>
<sec id="section6-1534508413489162">
<title>Vocabulary-matching CBM probes</title>
<p>Following guidelines established in previous studies (<xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al., 2001</xref>; <xref ref-type="bibr" rid="bibr13-1534508413489162">Espin et al., 2005</xref>; <xref ref-type="bibr" rid="bibr28-1534508413489162">Mooney, Schraven, et al., 2010</xref>), vocabulary-matching probes consisted of 20 vocabulary terms randomly selected from social studies content material covered during the course of the year, and 22 definitions (including 2 distracters). Content was chosen based on the current curriculum such as teacher lecture notes, textbook chapters, and end of unit assessments. The social studies teachers initially selected 265 terms. Each term and definition was added into a Microsoft Excel database 3 times, for a total of 795 terms/definitions. Then, 95 of the terms/definitions were removed at random because only 700 total terms/definitions were needed to create 35 weeks of probes. This final list of 700 was then randomized and 20 terms and definitions were selected for each weekly probe. Once terms were randomly sorted into weekly probe lists, terms were manually searched and reassigned to ensure identical terms were not included on the same probe or on sequential probes.</p>
<p>Probes included terms listed down the left side of the page and definitions randomly ordered were listed down the right side of the page along with two distracter items from previous weekly probes. Definitions were then edited for length or clarity by the researcher. Vocabulary definitions were kept to 16 words or less. After editing, vocabulary terms and definitions were reviewed by a second reader for length and clarity prior to administration. The vocabulary-matching probes were group administered weekly, for 5 min, by the social studies teachers using standard directions. Teachers were observed during Weeks 1, 11, and 22 by the researcher during probe administration to ensure reliability of standardized directions.</p>
</sec>
<sec id="section7-1534508413489162">
<title>New York State Testing Program (NYSTP): Social Studies</title>
<p>All students were administered the NYSTP: Social Studies for fifth-grade students (<xref ref-type="bibr" rid="bibr34-1534508413489162">The University of the State of New York, 2009</xref>) prior to and following the 8-week intervention period during a class period. This assessment was used as the social studies criterion measure to examine the technical adequacy of the vocabulary CBM as well as criterion measurement of student performance pre–post for the intervention sample.</p>
<p>The NYSTP social studies consists of two parts; Part 1 is a 35 multiple-choice portion followed by Part 2, a short answer and essay portion. For the purposes of this study, only Part 1 was used. The NYSTP provided a mix of questions that required students to choose the appropriate vocabulary term related to the definition but also provided applied questions that required students to demonstrate social learning (i.e., using maps skills, using pictures of ancient tools, timelines). Standardized directions were developed based on directions included with the NYSTP and given to the teachers to increase reliability of administration. The researcher calculated raw scores by adding the number of correct responses out of 35 multiple-choice questions and a subsample of 10% of the assessments were scored by an outside researcher with interscorer reliability falling between 98% and 100%.</p>
</sec>
</sec>
<sec id="section8-1534508413489162">
<title>Procedures</title>
<sec id="section9-1534508413489162">
<title>Vocabulary-matching CBM</title>
<p>Each teacher administered vocabulary probes weekly for 22 weeks throughout the school year. Measures were collected from teachers each week, de-identified, and scored. The first 11 weeks of data created a baseline trend to compare the intervention and control group pre–post intervention. During the 22 weeks of data collection, neither teachers nor the students were given access to the data. Scoring reliability checks were conducted on 10% of the overall sample for 22 weekly probes. Interscorer reliability ranged between 98% and 100%.</p>
</sec>
<sec id="section10-1534508413489162">
<title>Description of intervention</title>
<p>CSR groups met for 30 min twice a week during Core Plus intervention block. Trained interventionists provided CSR lessons for 8 weeks for a total of 16 lessons. Reading materials used for the first 14 CSR sessions were retrieved from current events websites for students (i.e., <ext-link ext-link-type="uri" xlink:href="http://timeforkids.com">timeforkids.com</ext-link>) to provide motivational topics and because students rarely read textbooks in class. For the final two CSR lessons, the students were given a retired reading item of the Missouri Assessment Program (MAP) Social Studies subtest as well as their social studies textbook to help students to generalize the CSR strategies to tests and the classroom.</p>
<p>CSR groups followed the standard protocol provided by <xref ref-type="bibr" rid="bibr24-1534508413489162">Klingner et al. (2001)</xref>. Each CSR strategy was presented in three phases: modeling, teacher assisted, and independent. As each interventionist only met with CSR groups twice a week, the modeling and teacher-assisted phases were combined into one lesson. Over the 8 weeks of intervention, Weeks 1 to 4 focused on teaching each of the four CSR strategies each week (Preview, Click and Clunk, Get the Gist, and Wrap Up). Weeks 5 to 7 focused more on using the strategies in a collaborative group with each student practicing group roles (Leader, Encourager, Timekeeper, Announcer, Clunk Expert, Gist Expert). The second author conducted fidelity checks 4 times during the treatment, with assessments of teacher and student behaviors, as well as an engaged classroom atmosphere included and fidelity ranged from 90% to 99% at observed sessions for each interventionist.</p>
</sec>
<sec id="section11-1534508413489162">
<title>Experimental design</title>
<p>A quasiexperimental pretest–posttest control group design was used to examine the effectiveness of the CSR intervention. Students were identified for the intervention based on several inclusionary and exclusionary criteria. The median score from three CBM probes (Weeks 7, 8, and 9) and the NYSTP scores were translated into standardized <italic>Z</italic> scores and summed to create a standard social studies performance score for each student ranging from −3.55 to 4.17. Students at or below a standard social studies performance score of .49 were considered for intervention with the purpose of oversampling based on more than half of the overall sample of students receiving negative scores. This subsample consisted of 87 students. Students were then excluded from the intervention portion of the study if they received (a) special education services in the area of reading, (b) other reading intervention services, or (c) a proficient or advanced reading score on the Spring 2011 MAP Communication Arts subtest.</p>
<p>As a result, 56 students were given a second informed consent to participate in the intervention portion of the study and consent was obtained for 32 students. These students were randomly assigned to an intervention or control condition using a matched design based on the following variables: (a) the student’s teacher, (b) Core Plus Block Schedule (A or B day), and (c) the student’s standardized social studies performance score. There were no significant differences in intervention and control group performance at the time of group assignment based on standardized social studies performance scores. Three intervention groups were created and group size was kept at six or fewer students. For each intervention group, there was an equal-sized control group with the same teacher.</p>
</sec>
</sec>
<sec id="section12-1534508413489162">
<title>Data Analysis</title>
<sec id="section13-1534508413489162">
<title>Overall sample</title>
<p>Correlational analysis was used to examine alternate-form reliability and criterion validity between the vocabulary-matching CBM and the NYSTP. Alternate-form reliability consisted of correlated adjacent forms (Week 1 with Week 2, etc). Also, combined adjacent forms were calculated (Week 1 added to Week 2) to see if more than one form increased the stability of measures. To examine the criterion validity, in addition to the median pre (Weeks 7, 8, 9) and post (Weeks 20, 21, 22) CBM scores, mean pre- and post-CBM scores were calculated for Weeks 8 and 9 (pre) and Weeks 21 and 22 (post).This is a similar procedure for creating pre–post scores using CBM in previous content-area CBM research (<xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al., 2001</xref>; <xref ref-type="bibr" rid="bibr13-1534508413489162">Espin et al. 2005</xref>).Finally, ordinary least squares (OLS) regression was also used to determine the amount of growth on CBM measure per week for the entire sample.</p>
</sec>
<sec id="section14-1534508413489162">
<title>Intervention sample</title>
<p>A <italic>t</italic>-test analysis was used to determine whether student mean performance differed for the intervention and control groups on vocabulary-matching pre–post assessment scores, and the NYSTP pre–post assessment scores. To examine the differences between the intervention and control groups on weekly CBM scores, Difference in Differences (DID) regression analysis was used. DID calculates a double difference by examining the difference across groups (intervention and control group) and over time (before and after the intervention; <xref ref-type="bibr" rid="bibr14-1534508413489162">European Commission, 2009</xref>). In contrast to <italic>t</italic>-test analysis that only examines differences within or between groups during one period of time (pre to post), DID creates an estimator of impact of the intervention that simultaneously examines difference across subjects over both pre- and post intervention. DID further controls for selection bias by accounting for small differences between groups at both pre and post that may have occurred despite random assignment and calculates a more isolated and likely estimate of the effect of the intervention (<xref ref-type="bibr" rid="bibr14-1534508413489162">European Commission, 2009</xref>). For an example of how a DID estimate is calculated, see <xref ref-type="table" rid="table1-1534508413489162">Table 1</xref>.</p>
<table-wrap id="table1-1534508413489162" position="float">
<label>Table 1.</label>
<caption>
<p>Example of the Calculation of DID Estimate.</p>
</caption>
<graphic alternate-form-of="table1-1534508413489162" xlink:href="10.1177_1534508413489162-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Groups</th>
<th align="center">Pretest (Weeks 1–11)</th>
<th align="center">Posttest (Weeks 12–20)</th>
<th align="center">Change Between Pre and Post</th>
</tr>
</thead>
<tbody>
<tr>
<td>Intervention group</td>
<td>a</td>
<td>c</td>
<td>a−c = <italic>x</italic><sub>1</sub></td>
</tr>
<tr>
<td>Control group</td>
<td>b</td>
<td>d</td>
<td>b−d = <italic>x</italic><sub>2</sub></td>
</tr>
<tr>
<td>Change between groups</td>
<td>a−b = <italic>y</italic><sub>1</sub></td>
<td>c−d = <italic>y</italic><sub>2</sub></td>
<td>DID estimate (<italic>x</italic><sub>1</sub>−<italic>x</italic><sub>2</sub>) = (<italic>y</italic><sub>1</sub>−<italic>y</italic><sub>2</sub>)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1534508413489162">
<p><italic>Note</italic>. DID = Difference in Differences.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>While hierarchical linear model (HLM) analysis has been used in previous studies investigating CBM growth rates, DID was chosen as a more simplified method to investigate two comparison groups versus nested groups. In the context of this study, students are only nested into two groups, treatment and control. The DID is ideally situated to compare the differences between two groups as opposed to HLM, which ideally needs larger group numbers (<xref ref-type="bibr" rid="bibr29-1534508413489162">Murnane &amp; Willett, 2011</xref>). The fixed-effects version of the DID also controls for all individual time-invariant heterogeneity, allowing the interpretation of the intervention effect to be identified based on changes within subjects due to the intervention.</p>
<p>DID was used to examine change in level of performance on CBM measures scores and change in slope on CBM measure trends for students in the 8-week intervention, and whether the changes in weekly student performance scores post intervention were different compared with the control group. The groups were defined as intervention and control groups. The first 11 weeks of vocabulary CBM were considered the preintervention time period and Weeks 12 through 20 were considered the postintervention time period (see <xref ref-type="table" rid="table1-1534508413489162">Table 1</xref>). Two types of models of DID were used, first OLS regression and next a fixed-effects model.</p>
</sec>
<sec id="section15-1534508413489162">
<title>Change in level of performance</title>
<p>An OLS model was used to calculate the DID estimate as a beta coefficient in the following equation: <italic>Y<sub>i</sub></italic> = α + βTR<sub><italic>i</italic></sub> + βAfter<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × After<sub><italic>t</italic></sub> + βWeek<sub><italic>t</italic></sub> + Error. The OLS regression equation calculates the change in performance by using the following variables for each student: overall average performance (α), whether a student was included in the intervention or treatment (TR), whether the intervention had started (After), the interaction between the treatment and after variable (TR × After), and a week specific time trend (Week) to account for overall learning. The coefficient β on the interaction of the treatment and intervention indicators (TR × After) represents the DID estimate of the effect of the intervention.</p>
<p>As the OLS equation gives a more equally distributed view of the student performance, a fixed-effects regression model was also used. This additional step examines the difference between groups while controlling for all constant variables representing a student such as gender, ethnicity, socioeconomic status, and teacher instruction. Using a fixed-effects estimator, the DID estimate as a beta coefficient is estimated in the following equation: Y<sub><italic>it</italic></sub> = α<sub><italic>i</italic></sub> + βAfter<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × After<sub><italic>t</italic></sub> + βWeek<sub><italic>t</italic></sub> + Error. This equation omits the treatment variable, because for the fixed-effects model, each individual student is given its own intercept. This individualized change variable is represented by the alpha symbol (α<sub><italic>i</italic></sub>). Again, the coefficient β on the interaction of the treatment and intervention indicators (TR × After) represents the DID estimate of the effect of the intervention.</p>
</sec>
<sec id="section16-1534508413489162">
<title>Change in slope on CBM trend</title>
<p>Similar to the change in level analysis procedures, OLS and DID models were used. However, it should be noted that the equations used are slightly more complex to allow for an analysis of change in slope between the two groups (intervention and control) at pre- and post intervention. The equation used for the OLS regression specific to change in slope is as follows: Y<sub><italic>i</italic></sub> = α + βWeek<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> + βAfter<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × Week<sub><italic>t</italic></sub> + βAfter<sub><italic>t</italic></sub> × Week<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × After<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × After<sub><italic>t</italic></sub> × Week<sub><italic>t</italic></sub> + Error. The Week variable in this equation is not present to provide an average, as in the previous OLS equation. The Week variable is included in the analysis to determine how weekly growth changed based on a student’s inclusion in the intervention. It is then also placed in interactions with TR and After variables. Finally, all three variables (Week, After, and TR) are multiplied by each other in this equation.</p>
<p>A fixed-effects DID model was also used to control for student variables that did not change during the course of the intervention. The fixed-effects equation used to examine changes in slope is as follows: Y<sub><italic>it</italic></sub> = α<sub><italic>i</italic></sub> + βWeek<sub><italic>t</italic></sub> + βAfter<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × Week<sub><italic>t</italic></sub> + βAfter<sub><italic>t</italic></sub> × Week<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × After<sub><italic>t</italic></sub> + βTR<sub><italic>i</italic></sub> × After<sub><italic>t</italic></sub> × Week<sub><italic>t</italic></sub> + Error. Once again, this equation omits the treatment variable because for the fixed-effects model, each individual student is given his or her own change variable represented in the alpha symbol (α<sub><italic>i</italic></sub>).</p>
</sec>
</sec>
</sec>
<sec id="section17-1534508413489162" sec-type="results">
<title>Results</title>
<sec id="section18-1534508413489162">
<title>Descriptive Statistics</title>
<p>Descriptive statistical analyses were conducted to derive the mean score, standard deviation, and the range for each weekly Vocabulary CBM measure for Weeks 1 to 22. Means, standard deviations, and range are presented for each measure in <xref ref-type="table" rid="table2-1534508413489162">Table 2</xref>. When examining the vocabulary-matching measures, the standard deviations were considerable (ranging from 2.99 to 6.02) among participants across the 22 weeks. This indicates a large distribution of student scores for each measure. The ranges imply that there were floor effects each week. Across the 22 weeks on average 8 or 5% of the sample obtained a score of 0 out of 20 on the weekly probes. There was a ceiling effect for 5 weeks (Probes 10, 11, 14, 19, 21, 22) with an average of 2% to 5% of the sample making all correct matches. On average, during these 5 weeks, there was at least 1 student who received a score of 20.</p>
<table-wrap id="table2-1534508413489162" position="float">
<label>Table 2.</label>
<caption>
<p>Means, Standard Deviation, and Range for Vocabulary Curriculum-Based Measurement Probes.</p>
</caption>
<graphic alternate-form-of="table2-1534508413489162" xlink:href="10.1177_1534508413489162-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Probes</th>
<th align="center"><italic>n</italic></th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Minimum</th>
<th align="center">Maximum</th>
<th align="center">Skewness</th>
<th align="center">Kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>Probe 1</td>
<td>142</td>
<td>3.73</td>
<td>3.29</td>
<td>0</td>
<td>15</td>
<td>1.29</td>
<td>1.57</td>
</tr>
<tr>
<td>Probe 2</td>
<td>142</td>
<td>3.65</td>
<td>2.99</td>
<td>0</td>
<td>16</td>
<td>1.65</td>
<td>3.21</td>
</tr>
<tr>
<td>Probe 3</td>
<td>138</td>
<td>6.21</td>
<td>4.43</td>
<td>0</td>
<td>18</td>
<td>0.59</td>
<td>−0.51</td>
</tr>
<tr>
<td>Probe 4</td>
<td>143</td>
<td>7.43</td>
<td>4.42</td>
<td>0</td>
<td>18</td>
<td>0.50</td>
<td>−0.54</td>
</tr>
<tr>
<td>Probe 5</td>
<td>138</td>
<td>7.28</td>
<td>4.70</td>
<td>0</td>
<td>19</td>
<td>0.43</td>
<td>−0.57</td>
</tr>
<tr>
<td>Probe 6</td>
<td>139</td>
<td>6.58</td>
<td>4.18</td>
<td>0</td>
<td>16</td>
<td>0.31</td>
<td>−0.71</td>
</tr>
<tr>
<td>Probe 7</td>
<td>142</td>
<td>4.35</td>
<td>3.55</td>
<td>0</td>
<td>17</td>
<td>1.27</td>
<td>1.47</td>
</tr>
<tr>
<td>Probe 8</td>
<td>145</td>
<td>7.89</td>
<td>5.33</td>
<td>0</td>
<td>19</td>
<td>0.44</td>
<td>−0.86</td>
</tr>
<tr>
<td>Probe 9</td>
<td>146</td>
<td>5.83</td>
<td>4.15</td>
<td>0</td>
<td>18</td>
<td>0.57</td>
<td>−0.36</td>
</tr>
<tr>
<td>Probe 10</td>
<td>145</td>
<td>7.01</td>
<td>5.39</td>
<td>0</td>
<td>20</td>
<td>0.66</td>
<td>−0.58</td>
</tr>
<tr>
<td>Probe 11</td>
<td>142</td>
<td>8.93</td>
<td>5.92</td>
<td>0</td>
<td>20</td>
<td>0.36</td>
<td>−1.06</td>
</tr>
<tr>
<td>Probe 12</td>
<td>141</td>
<td>5.49</td>
<td>4.02</td>
<td>0</td>
<td>17</td>
<td>0.65</td>
<td>−0.30</td>
</tr>
<tr>
<td>Probe 13</td>
<td>144</td>
<td>6.26</td>
<td>4.07</td>
<td>0</td>
<td>16</td>
<td>0.34</td>
<td>−0.91</td>
</tr>
<tr>
<td>Probe 14</td>
<td>132</td>
<td>7.81</td>
<td>5.39</td>
<td>0</td>
<td>20</td>
<td>0.45</td>
<td>−0.74</td>
</tr>
<tr>
<td>Probe 15</td>
<td>140</td>
<td>9.30</td>
<td>4.46</td>
<td>0</td>
<td>18</td>
<td>0.56</td>
<td>−0.62</td>
</tr>
<tr>
<td>Probe 16</td>
<td>131</td>
<td>6.62</td>
<td>4.47</td>
<td>0</td>
<td>18</td>
<td>0.35</td>
<td>−0.76</td>
</tr>
<tr>
<td>Probe 17</td>
<td>135</td>
<td>10.67</td>
<td>5.06</td>
<td>0</td>
<td>19</td>
<td>−0.02</td>
<td>−1.02</td>
</tr>
<tr>
<td>Probe 18</td>
<td>138</td>
<td>6.80</td>
<td>4.36</td>
<td>0</td>
<td>17</td>
<td>0.35</td>
<td>−0.68</td>
</tr>
<tr>
<td>Probe 19</td>
<td>138</td>
<td>8.11</td>
<td>6.02</td>
<td>0</td>
<td>20</td>
<td>−0.12</td>
<td>−1.32</td>
</tr>
<tr>
<td>Probe 20</td>
<td>136</td>
<td>8.96</td>
<td>5.34</td>
<td>0</td>
<td>18</td>
<td>0.37</td>
<td>−1.17</td>
</tr>
<tr>
<td>Probe 21</td>
<td>139</td>
<td>8.11</td>
<td>4.57</td>
<td>0</td>
<td>20</td>
<td>0.18</td>
<td>−0.45</td>
</tr>
<tr>
<td>Probe 22</td>
<td>135</td>
<td>8.96</td>
<td>5.51</td>
<td>0</td>
<td>20</td>
<td>0.09</td>
<td>−1.04</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>When examining the overall sample, means for all measures were higher for the posttest compared with the pretest. Means and standard deviations appear to increase in CBM scores from pre (<italic>M =</italic> 5.92, <italic>SD =</italic> 4.32<italic>)</italic> to post (<italic>M =</italic> 7.77, <italic>SD =</italic> 4.97) as well as the NYSTP scores from pre (<italic>M =</italic> 21.89, <italic>SD</italic> = 6.68) to post (<italic>M =</italic> 22.75, <italic>SD =</italic> 6.32). Means and standard deviations for CBM pre–post, and NYSTP between the intervention and control groups were also examined. When compared with the control group, mean scores on the vocabulary CBM (<italic>M =</italic> 3.18, <italic>SD =</italic> 1.68) and the NYSTP (<italic>M =</italic> 19.79, <italic>SD</italic> = 2.94), it appears that the intervention group obtained lower means on the vocabulary CBM (<italic>M =</italic> 2.78, <italic>SD</italic> = 1.70) and NYSTP (<italic>M =</italic> 19.07, <italic>SD</italic> = 5.11). However, on the posttest measures, the intervention group obtained higher scores on the vocabulary CBM (<italic>M</italic> = 4.97, <italic>SD</italic> = 2.57) and NYSTP (<italic>M</italic> = 21.60, <italic>SD</italic> = 4.69) than the control’s vocabulary CBM (<italic>M</italic> = 4.54, <italic>SD</italic> = 3.51) and NYSTP (<italic>M</italic> = 19.00, <italic>SD</italic> = 5.76).</p>
<sec id="section19-1534508413489162">
<title>Criterion validity</title>
<p>Criterion validity was examined between the NYSTP and the median and mean vocabulary CBM scores. Correlation coefficients are reported in <xref ref-type="table" rid="table3-1534508413489162">Table 3</xref>. Results revealed moderately strong correlations between the NYSTP and the median vocabulary CBM pre or post. Correlation coefficients ranged from <italic>r</italic> = .66 to .81. It appears that coefficients were moderately strong between the vocabulary-matching and the NYSTP pretests, <italic>r</italic> = .69. Coefficients between the median vocabulary-matching pretest and NYSTP posttest were strong, <italic>r</italic> = .70, suggesting that the median of three vocabulary probes was accurate in predicting future student performance.</p>
<table-wrap id="table3-1534508413489162" position="float">
<label>Table 3.</label>
<caption>
<p>Pearson Correlations Between Pre–Post Criterion Measures (<italic>n</italic> = 148).</p>
</caption>
<graphic alternate-form-of="table3-1534508413489162" xlink:href="10.1177_1534508413489162-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">NYSTP<hr/></th>
<th align="center" colspan="2">Vocabulary CBM: Mean of 2<hr/></th>
<th align="center" colspan="2">Vocabulary CBM: Median of 3<hr/></th>
</tr>
<tr>
<th align="left">Measures</th>
<th align="center">Pretest</th>
<th align="center">Posttest</th>
<th align="center">Pretest</th>
<th align="center">Posttest</th>
<th align="center">Pretest</th>
<th align="center">Posttest</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="7">NYSTP</td>
</tr>
<tr>
<td> Pretest</td>
<td>1</td>
<td>.71</td>
<td>.66</td>
<td>.70</td>
<td>.69</td>
<td>.66</td>
</tr>
<tr>
<td> Posttest</td>
<td/>
<td>1</td>
<td>.68</td>
<td>.69</td>
<td>.70</td>
<td>.67</td>
</tr>
<tr>
<td colspan="7">Mean of 2</td>
</tr>
<tr>
<td> CBM pretest</td>
<td/>
<td/>
<td>1</td>
<td>.87</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td> CBM posttest</td>
<td/>
<td/>
<td/>
<td>1</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td colspan="7">Median of 3</td>
</tr>
<tr>
<td> CBM pretest</td>
<td/>
<td/>
<td/>
<td/>
<td>1</td>
<td>.81</td>
</tr>
<tr>
<td> CBM posttest</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td>1</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1534508413489162">
<p><italic>Note</italic>. NYSTP = New York State Testing Program; CBM = curriculum-based measurement. All correlations are statistically significant at <italic>p</italic> &lt; .01.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>For the mean of two measures, results revealed moderate to strong correlations between the NYSTP and the mean vocabulary CBM pre or post. Coefficients ranged from <italic>r</italic> = .66 to .87. Coefficients between the vocabulary-matching pretest and NYSTP posttest was moderately strong, <italic>r</italic> = .68, suggesting that the mean of two vocabulary probes were almost as strong at predicting future student performance as the median of three vocabulary probes.</p>
</sec>
<sec id="section20-1534508413489162">
<title>Alternate-form reliability</title>
<p>Alternate-form reliability was calculated by correlating adjacent probes and combined adjacent probes. Results from calculation of alternate-form coefficients of the adjacent probes revealed that coefficients ranged from <italic>r</italic> = .62 to .80, with a mean score of <italic>r</italic> = .75. Results from calculation for the means of the combined adjacent probes revealed that alternate-form reliabilities ranged from <italic>r</italic> = .81 to .87, with a mean score of <italic>r</italic> = .84, demonstrating stronger coefficients for the mean of two forms than the use of just one form for alternate-form reliability.</p>
</sec>
<sec id="section21-1534508413489162">
<title>Weekly growth</title>
<p>An OLS regression was used to calculate the average rate of growth on vocabulary-matching CBM for the entire sample. Results indicated a positive trend, in that on average each student’s score improved 0.15 correct matches per week <italic>t</italic>(2,805) = 10.33, <italic>p</italic> &lt; .001. Specific to the intervention subsample, an OLS regression was used to calculate the average rate of growth on vocabulary-matching CBM for each group. It appears that during the intervention period (Weeks 12–20), the average weekly growth for the intervention group was .39 correct matches per week, while the control group’s weekly growth was only .14 correct matches. While the intervention group appears to demonstrate more correct matches per week, no significant differences were found between the two groups, <italic>t</italic>(492) = −0.58, <italic>p</italic> = .560.</p>
</sec>
<sec id="section22-1534508413489162">
<title><italic>t</italic>-Test analysis</title>
<p>Two paired sample <italic>t</italic> tests were conducted to compare the pre–post assessment of the vocabulary CBM and NYSTP within each group. First, in the intervention group, the paired sample <italic>t</italic> test indicated that vocabulary CBM pretest scores (<italic>M</italic> = 2.77, <italic>SD</italic> = 1.70) were significantly different from the CBM posttest scores (<italic>M</italic> = 4.98, <italic>SD</italic> = 2.57), <italic>t</italic>(14) = 5.32, <italic>p</italic> ≤ .001. However, there were no significant differences between the pretest scores (<italic>M</italic> = 19.07, <italic>SD</italic> = 5.11) and the NYSTP posttest scores (<italic>M</italic> = 21.60, <italic>SD</italic> = 4.69), <italic>t</italic>(14) = 5.321, <italic>p</italic> = .148. For the control group, a paired sample <italic>t</italic> test indicated that there were no significant differences between vocabulary CBM pretest scores (<italic>M</italic> = 3.18, <italic>SD</italic> = 1.68) and CBM posttest scores (<italic>M</italic> = 4.53, <italic>SD</italic> = 3.51), <italic>t</italic>(13) = 1.96, <italic>p</italic> = .072. There were also no significant differences between the pretest scores (<italic>M</italic> = 19.79, <italic>SD</italic> = 2.94) and the NYSTP posttest scores (<italic>M</italic> = 19.00, <italic>SD</italic> = 5.58), <italic>t</italic>(13) = −0.60, <italic>p</italic> = .559.</p>
<p>These results suggest that the intervention group achieved significantly higher scores on the vocabulary CBM after the completion of the intervention period. In contrast, there were no significant changes on CBM pre to post for the control group. It appears that scores on the NYSTP did not significantly change for either the intervention or control groups.</p>
</sec>
</sec>
<sec id="section23-1534508413489162">
<title>DID Analysis</title>
<p>The results of the DID for change in level of CBM score are presented in <xref ref-type="table" rid="table4-1534508413489162">Table 4</xref>. The DID estimate for change in CBM score is not significant in the OLS model (β = .721, <italic>p</italic> = .199).The results of the DID for slope are also present in <xref ref-type="table" rid="table4-1534508413489162">Table 4</xref>. The DID estimate for slope is also not significant for OLS model (β = .0318, <italic>p</italic> = .259). These results suggest that there were no statistically significant differences between the intervention and control groups on weekly vocabulary CBM measures in level of score and weekly growth after the beginning of the intervention, even when their differences preintervention were taken into account.</p>
<table-wrap id="table4-1534508413489162" position="float">
<label>Table 4.</label>
<caption>
<p>Difference in Differences Models Between Intervention and Control Groups.</p>
</caption>
<graphic alternate-form-of="table4-1534508413489162" xlink:href="10.1177_1534508413489162-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">Regression Model<hr/></th>
</tr>
<tr>
<th/>
<th align="center" colspan="3">OLS<hr/></th>
<th align="center" colspan="3">Fixed Effects<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center">β</th>
<th align="center"><italic>SE</italic></th>
<th align="center"><italic>p</italic></th>
<th align="center">β</th>
<th align="center"><italic>SE</italic></th>
<th align="center"><italic>p</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="7">Change in level</td>
</tr>
<tr>
<td> Week</td>
<td>0.161</td>
<td>0.048</td>
<td>0.001</td>
<td>0.152</td>
<td>0.035</td>
<td>0.000</td>
</tr>
<tr>
<td> Treatment</td>
<td>−0.381</td>
<td>0.332</td>
<td>0.251</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td> After</td>
<td>−0.892</td>
<td>0.610</td>
<td>0.144</td>
<td>−0.061</td>
<td>0.446</td>
<td>0.179</td>
</tr>
<tr>
<td> Treatment × After</td>
<td>0.721</td>
<td>0.560</td>
<td>0.199</td>
<td>0.588</td>
<td>0.41</td>
<td>0.152</td>
</tr>
<tr>
<td><italic> Difference in Difference estimate</italic></td>
<td>0.721</td>
<td>0.560</td>
<td>0.199</td>
<td>0.588</td>
<td>0.41</td>
<td>0.152</td>
</tr>
<tr>
<td colspan="7">Change in slope</td>
</tr>
<tr>
<td> Week</td>
<td>0.177</td>
<td>0.075</td>
<td>0.019</td>
<td>0.157</td>
<td>0.055</td>
<td>0.004</td>
</tr>
<tr>
<td> Treatment</td>
<td>−0.018</td>
<td>0.707</td>
<td>0.979</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td> After</td>
<td>−0.221</td>
<td>2.965</td>
<td>0.940</td>
<td>−1.272</td>
<td>2.169</td>
<td>0.558</td>
</tr>
<tr>
<td> Treatment × Week</td>
<td>−0.061</td>
<td>0.104</td>
<td>0.560</td>
<td>−0.048</td>
<td>0.076</td>
<td>0.529</td>
</tr>
<tr>
<td> After × Week</td>
<td>−0.053</td>
<td>0.202</td>
<td>0.792</td>
<td>0.041</td>
<td>0.148</td>
<td>0.784</td>
</tr>
<tr>
<td> Treatment × After</td>
<td>−3.630</td>
<td>4.138</td>
<td>0.380</td>
<td>−2.179</td>
<td>3.024</td>
<td>0.471</td>
</tr>
<tr>
<td> Treatment × After × Week</td>
<td>0.318</td>
<td>0.282</td>
<td>0.259</td>
<td>0.207</td>
<td>0.206</td>
<td>0.314</td>
</tr>
<tr>
<td><italic> Difference in Difference estimate</italic></td>
<td>0.318</td>
<td>0.282</td>
<td>0.259</td>
<td>0.207</td>
<td>0.258</td>
<td>0.314</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1534508413489162">
<p><italic>Note</italic>. OLS = ordinary least squares.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>There were also no significant differences using a DID fixed-effects model for change in scores (β = .588, <italic>p</italic> = .152) or slope model (β = .207, <italic>p</italic> = .314). It appears that even when controlling for individual constant characteristics of students, there were no substantial change in weekly vocabulary CBM scores or trend between the intervention and control groups. Although not significant, a positive effect size of .60 was found between groups for change in CBM scores after the intervention.</p>
<p>The differences between pre–post intervention on the change in slopes between the treatment and control groups for the fixed-effects model pre- and post intervention are illustrated in <xref ref-type="fig" rid="fig1-1534508413489162">Figure 1</xref>. This visual representation shows that during baseline performance, the two slopes are parallel but at different levels of performance on the vocabulary-matching CBM. After the beginning of intervention, the intervention group started below the control group, but their rate of learning on the vocabulary-matching CBM increased more dramatically to surpass the control group.</p>
<fig id="fig1-1534508413489162" position="float">
<label>Figure 1.</label>
<caption>
<p>Difference-in-Difference Fixed-Effects Model for Change in Slope.</p>
</caption>
<graphic xlink:href="10.1177_1534508413489162-fig1.tif"/>
</fig>
</sec>
</sec>
<sec id="section24-1534508413489162" sec-type="discussion">
<title>Discussion</title>
<p>The present study examined the criterion validity and alternate-form reliability of vocabulary-matching CBM as an indicator of performance and progress of student learning in social studies. Also, the effect of the reading intervention CSR on the reading performance of low readers using CBM as a weekly monitoring tool was investigated. Means and standard deviations for each weekly administered vocabulary CBM revealed that all measures resulted in a wide dispersion of participant scores. It appears that students had varying levels of vocabulary knowledge. While there appeared to be a positive trend in growth, mean scores did not appear to increase consistently across the 22 weeks of administration. These results are consistent with findings from <xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al. (2001)</xref>, who found slightly higher means ranging on student-read measures over 11 weeks.</p>
<p>To determine the level of difficulty of the vocabulary CBM, the range of scores revealed a floor effect on all measures and a ceiling effect on five measures. The ceiling was most likely obtained as vocabulary terms were randomly selected from the entire social studies curriculum, and as the year progressed, students became more familiar with terms. However, on average only one student received a perfect score; therefore, the difficulty level seems to be appropriate. For the floor effects, across the 22 weeks, 5% of the sample received a score of 0 out of 20.These results suggest that the measures may have been too difficult or student motivation and attention to task may not have been consistent across weeks.</p>
<sec id="section25-1534508413489162">
<title>Criterion Validity</title>
<p>The vocabulary measures demonstrated positive moderately strong correlations with the NYSTP, thus implying that the median vocabulary CBM scores are a valid indicator of general social studies knowledge. This was consistent with the <xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al. (2001)</xref> findings in that vocabulary CBM post scores were strongly correlated with criterion measures that included a knowledge assessment and a state standardized social studies assessment. Furthermore, <xref ref-type="bibr" rid="bibr27-1534508413489162">Mooney, McCarter, et al. (2010)</xref> found vocabulary CBM to strongly correlate with the Louisiana state standardized assessment (.70). However, the median vocabulary CBM pre score demonstrated the strongest correlations with the NYSTP post score and vocabulary CBM post score, suggesting that the median of three vocabulary measures may be a valid indicator of future performance. This finding is also consistent with <xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al. (2001)</xref> in which the vocabulary CBM pre score was highly correlated with future achievement.</p>
<p>In addition, <xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al. (2001)</xref> urged that future research examine whether the mean of two forms may be more appropriate for screening or monitoring progress. The results of the present study found the NYSTP pre- and post scores similarly related to either the mean or the median of the vocabulary CBM scores. The coefficient between the mean vocabulary CBM pre scores and the NYSTP post score was slightly lower (.68) in comparison with the median vocabulary pre and NYSTP post score (.70). Based on the present data, it could be assumed that the median of three or the mean of two vocabulary CBM probes may be a valid predictor of future performance on a standardized social studies measure.</p>
</sec>
<sec id="section26-1534508413489162">
<title>Alternate-Form Reliability</title>
<p>Alternate-form reliability assists with determining whether different test forms are equivalent and it also examines the stability of the measure over time (<xref ref-type="bibr" rid="bibr33-1534508413489162">Shin, Deno, &amp; Espin, 2000</xref>). The results found in this study suggest that the alternative-form reliability coefficients were somewhat low. Consistent with <xref ref-type="bibr" rid="bibr9-1534508413489162">Espin et al. (2001)</xref>, the present study found reliability coefficients ranging from .62 to .80, and a mean score of .75. The replication of lower reliability scores indicates that more than one probe may be needed to increase reliability scores. For alternate-form reliability, .80 and above is recommended because the stronger the correlations, the more reliable the measures at detecting growth from week to week. The combined adjacent measures demonstrated more acceptable reliability coefficients (.81 to .87, mean of .84), thus implying that taking the mean of 2 weeks’ worth of probes may be more suitable and stable for monitoring student growth over time.</p>
</sec>
<sec id="section27-1534508413489162">
<title>Growth Rates</title>
<p>A positive trend was found in student growth on vocabulary CBM across the 22 weeks. In the overall sample that included students in general and special education, individuals grew .15 correct matches per week, much lower than mean growth rate of .65 that was reported in <xref ref-type="bibr" rid="bibr13-1534508413489162">Espin et al. (2005)</xref>. This suggests that students grew on average one match in approximately 7 weeks compared with every 2 weeks. This finding brings into question the instructional utility of such measures when determining sensitivity of student growth.</p>
<p>One consideration is that the development of probes in the current study lacked a proven systematic method. For example, the probes were created from a list of terms and definitions from textbooks, notes, and exams provided by two practicing sixth-grade teachers. This list of terms and definitions was completely randomized from the entire year’s curriculum and therefore some terms appeared on probes even if students had not been introduced to them in class. In addition, while the researcher attempted not to have similar probes from week to week, these terms were repeated up to 3 times throughout the semester. It also appears that there were weeks where probes were not as challenging, as evidenced by the ceiling effects; and there may have been weeks when probes were too challenging, as evidenced by the floor effects.</p>
<p>While beyond the scope of this study, an alternative method to developing probes would have been to use the procedures identified by <xref ref-type="bibr" rid="bibr28-1534508413489162">Mooney, Schraven, et al. (2010)</xref>. This would include entering all vocabulary terms from all the sixth-grade social studies textbooks used in the public school system in the state and then asking the sixth-grade teachers and a social studies curriculum expert to identify which of the terms were the most important to student learning on a scale of 1 to 3, with 1 being the most important to learning. Terms falling below a 1.5 rating would be eliminated. This procedure could have provided a much more systematic method of determining which terms to utilize.</p>
</sec>
<sec id="section28-1534508413489162">
<title>Effectiveness of CSR</title>
<p>When examining the intervention sample specifically, only the paired sample <italic>t</italic>-test analysis revealed a statistically significant difference in change in vocabulary CBM pre- to post median scores for the intervention group only. However, no significant effects were found between the two groups when accounting for differences at pre and post and across time. The <italic>t</italic> test and DID analysis indicated no significant differences between groups on the mean change from pre to post on the NYSTP. Therefore, it is difficult to determine whether CSR truly made a significant impact on those in the intervention group.</p>
<p>CSR studies have targeted heterogeneous groups of students to include students with learning difficulties, learning disabilities, and those identified as English language learners (<xref ref-type="bibr" rid="bibr16-1534508413489162">Hitchcock et al., 2010</xref>; <xref ref-type="bibr" rid="bibr25-1534508413489162">Klingner et al., 1998</xref>; <xref ref-type="bibr" rid="bibr22-1534508413489162">Klingner et al., 2004</xref>; <xref ref-type="bibr" rid="bibr20-1534508413489162">Klingner &amp; Vaughn, 1996</xref>). <xref ref-type="bibr" rid="bibr22-1534508413489162">Klingner et al. (2004)</xref> indicated that low-achieving students in the CSR groups made larger gains compared with high-achieving and students with learning disabilities. Klingner and colleagues, found a low effect size of .19 for the overall sample, but higher effects for students with learning disabilities (.38) and low-achieving students (.51). In addition, students in the CSR classrooms demonstrated significant gains compared with the control group on the Gates-MacGinitie. More recently, in language arts classrooms, <xref ref-type="bibr" rid="bibr36-1534508413489162">Vaughn et al. (2011)</xref> found an effect size of .36 between the CSR and control classrooms with low-achieving students, but it was not statistically significant. The present study found a meaningful effect size of .60 between the CSR and control group, despite nonsignificance.</p>
</sec>
</sec>
<sec id="section29-1534508413489162">
<title>Limitations</title>
<p>There are some limitations to the present study that may have affected the findings. First, sample size of the intervention was particularly limited based on the exclusion criteria, returned consent forms, and limited capabilities (interventionists, schedules, and space) to implement small groups. The CSR intervention was only implemented twice per week for 30 min. <xref ref-type="bibr" rid="bibr24-1534508413489162">Klingner et al. (2001)</xref> suggest that CSR should be implemented up to 3 times per week for 45 min. While teaching a full curriculum, teachers would most certainly need more practice per week and longer than 4 weeks to fully teach and practice the four CSR strategies. Moreover, teachers and students were not allowed to discuss the CSR intervention. However, there was no way to control if diffusion occurred between the intervention and control group students. Finally, not sharing weekly data with the students could have contributed to a waning of student attention to task as the weeks progressed. Two holiday breaks totaling 4 weeks could have also affected results of student performance; however, this is the normal routine of schools that do not always lend themselves to ideal research conditions.</p>
<sec id="section30-1534508413489162">
<title>Implications for Practice</title>
<p>One unique feature of this study included the use of DID regression models. By controlling for selection bias between control and treatment groups, DID gives more of a conservative estimation of the treatment impact from pre to post, while simultaneously examining both groups. In addition, being able to examine the simultaneous differences between groups on slope is an added benefit, since <italic>t</italic>-test analysis often only examines static scores pre to post or between two separate groups. Finally, the DID model’s ability to examine random or fixed effects gives the researcher more information on how unique student variables affect the variance in performance. While this statistical analysis has been used primarily in economics and to investigate changes in policy, it is apparent that this analysis could be useful in experimental research in education.</p>
<p>The results of this study provide continued support that vocabulary-matching CBM can serve as an indication of content-area performance. As students move into the secondary level and into more content-area texts, difficulties arise for students who are struggling, especially with reading comprehension. Practitioners could use vocabulary CBM to screen students to predict future performance in content-area classes. Being able to use the mean of two forms instead of the median of three would allow for less administration time and provide similar information of future student performance to teachers. Alternate-form reliability suggested that perhaps more than one probe is necessary to gain a more reliable estimate of student performance. However, the low growth rates found in the present study require more investigation with respect to the instructional utility of vocabulary CBM and its sensitivity to student growth within a progress-monitoring model.</p>
</sec>
<sec id="section31-1534508413489162">
<title>Future Research</title>
<p>While the predictive validity of the vocabulary-matching CBM appears promising for content-area assessments, this needs to be further examined. For instance, to conceptualize vocabulary-matching CBM as a general outcome measure, it may be beneficial to examine its predictive validity of criterion-referenced statewide reading assessments. Although vocabulary-matching CBM could assist practitioners in identifying students for intervention, at this time it is difficult to determine whether these measures are the most valid and reliable for progress monitoring. As previously mentioned, after sixth grade, ORF does not adequately indicate reading performance for students (<xref ref-type="bibr" rid="bibr10-1534508413489162">Espin &amp; Deno, 1993</xref>; <xref ref-type="bibr" rid="bibr17-1534508413489162">Hosp &amp; Fuchs, 2015</xref>; <xref ref-type="bibr" rid="bibr18-1534508413489162">Jenkins &amp; Jewell, 1993</xref>). A standardized method to produce the most reliable and valid measures that are sensitive to student growth would allow for more consistent replication of research studies. Future research should focus on finding the most efficient, effective, and comprehensive methods of probe development to represent curriculum domains and grade-level standards.</p>
<p>Moreover, sequential studies are needed to examine vocabulary-matching CBM as a progress-monitoring tool, with students of all abilities to monitor interventions and regular classroom instruction. Future researchers are encouraged to determine whether vocabulary-matching CBM could be used in other content areas beyond social studies and science. Other subject areas such as mathematics, literature, foreign language, and art should be explored. It would also be beneficial to further compare vocabulary-matching CBM to ORF and Maze measures to replicate and extend the work of previous studies (<xref ref-type="bibr" rid="bibr11-1534508413489162">Espin &amp; Deno, 1995</xref>; <xref ref-type="bibr" rid="bibr12-1534508413489162">Espin &amp; Foegen, 1996</xref>) as these other CBM measures have become more technically adequate over time.</p>
<p>Although not statistically significant, the results of the study demonstrated practical implications that CSR could potentially be used with students needing additional support in comprehension skills but do not qualify for special education. Future research should continue to look at the effectiveness of CSR with a much larger and diverse sample of students not identified with learning disabilities.</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Allington</surname><given-names>R. L.</given-names></name>
</person-group> (<year>2002</year>). <article-title>You can’t learn much from books you can’t read</article-title>. <source>Educational Leadership</source>, <volume>60</volume>(<issue>3</issue>), <fpage>16</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr2-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Biancarosa</surname><given-names>G.</given-names></name>
<name><surname>Snow</surname><given-names>C. E.</given-names></name>
</person-group> (<year>2004</year>). <source>Reading next–A vision for action and research in middle and high school literacy: A report to the Carnegie Corporation of New York</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Alliance for Excellent Education</publisher-name>.</citation>
</ref>
<ref id="bibr3-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Borsuk</surname><given-names>E. R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Examination of an administrator-read vocabulary-matching measure as an indicator of science achievement</article-title>. <source>Assessment for Effective Intervention</source>, <volume>35</volume>, <fpage>168</fpage>–<lpage>177</lpage>.</citation>
</ref>
<ref id="bibr4-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bryant</surname><given-names>D. P.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Linan-Thompson</surname><given-names>S.</given-names></name>
<name><surname>Ugel</surname><given-names>N.</given-names></name>
<name><surname>Hamff</surname><given-names>A.</given-names></name>
<name><surname>Hougen</surname><given-names>M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Reading outcomes for students with and without reading disabilities in general education middle school content area classes</article-title>. <source>Learning Disability Quarterly</source>, <volume>23</volume>, <fpage>238</fpage>–<lpage>252</lpage>.</citation>
</ref>
<ref id="bibr5-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Burns</surname><given-names>M. K.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Response to intervention at the secondary level</article-title>. <source>Principal Leadership</source>, <volume>8</volume>(<issue>7</issue>), <fpage>12</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr6-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Busch</surname><given-names>T.</given-names></name>
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Using curriculum-based measurement to prevent failure and assess learning in content areas</article-title>. <source>Assessment for Effective Intervention</source>, <volume>28</volume>, <fpage>49</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr7-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Deno</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Curriculum-based measurement: The emerging alternative</article-title>. <source>Exceptional Children</source> <volume>52</volume>, <fpage>219</fpage>–<lpage>232</lpage>.</citation>
</ref>
<ref id="bibr8-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Edmonds</surname><given-names>M. S.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Wexler</surname><given-names>J.</given-names></name>
<name><surname>Reutebuch</surname><given-names>C.</given-names></name>
<name><surname>Cable</surname><given-names>A.</given-names></name>
<name><surname>Tackett</surname><given-names>K. K.</given-names></name>
<name><surname>Schnakenberg</surname><given-names>J. W.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A synthesis of reading interventions and effects on reading comprehension outcomes for older struggling readers</article-title>. <source>Review of Educational Research, 79</source>, <fpage>262</fpage>–<lpage>300</lpage>. doi:<pub-id pub-id-type="doi">10.3102/0034654308325998</pub-id></citation>
</ref>
<ref id="bibr9-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Busch</surname><given-names>T.</given-names></name>
<name><surname>Shin</surname><given-names>J.</given-names></name>
<name><surname>Kruschwitz</surname><given-names>R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Curriculum-based measures in the content areas: Validity of vocabulary-matching measures as indicators of performance in social studies</article-title>. <source>Learning Disabilities Research and Practice</source>, <volume>16</volume>, <fpage>142</fpage>–<lpage>151</lpage>.</citation>
</ref>
<ref id="bibr10-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Deno</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Performance in reading from content-area text as an indicator of achievement</article-title>. <source>Remedial and Special Education</source>, <volume>14</volume>, <fpage>47</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr11-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Deno</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Curriculum-based measures for secondary students: Utility and task specificity of text-based reading and vocabulary measures for predicting performance on content-area tasks</article-title>. <source>Diagnostique</source>, <volume>20</volume>, <fpage>121</fpage>–<lpage>142</lpage>.</citation>
</ref>
<ref id="bibr12-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Foegen</surname><given-names>A.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Validity of three general outcome measures for predicting secondary students’ performance on content-area tasks</article-title>. <source>Exceptional Children</source>, <volume>62</volume>, <fpage>497</fpage>–<lpage>514</lpage>.</citation>
</ref>
<ref id="bibr13-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Espin</surname><given-names>C. A.</given-names></name>
<name><surname>Shin</surname><given-names>J.</given-names></name>
<name><surname>Busch</surname><given-names>T. W.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Curriculum-based measurement in the content areas: Vocabulary-matching as an indicator of social studies learning</article-title>. <source>Journal of Learning Disabilities</source>, <volume>38</volume>, <fpage>353</fpage>–<lpage>363</lpage>.</citation>
</ref>
<ref id="bibr14-1534508413489162">
<citation citation-type="web">
<collab>European Commission</collab>. (<year>2009</year>). <source>Difference-in-differences</source>. Retrieved from: <ext-link ext-link-type="uri" xlink:href="http://ec.europa.eu/regional_policy/sources/docgener/evaluation/evalsed/sourcebooks/method_techniques/counterfactual_impact_evaluation/difference-in-differences/index_en.htm">http://ec.europa.eu/regional_policy/sources/docgener/evaluation/evalsed/sourcebooks/method_techniques/counterfactual_impact_evaluation/difference-in-differences/index_en.htm</ext-link></citation>
</ref>
<ref id="bibr15-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Harmon</surname><given-names>J. M.</given-names></name>
<name><surname>Hedrick</surname><given-names>W. B.</given-names></name>
<name><surname>Wood</surname><given-names>K. D.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Research on vocabulary instruction in the content areas: Implications for struggling readers</article-title>. <source>Reading &amp; Writing Quarterly</source>, <volume>21</volume>, <fpage>261</fpage>–<lpage>280</lpage>.</citation>
</ref>
<ref id="bibr16-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hitchcock</surname><given-names>J.</given-names></name>
<name><surname>Dimino</surname><given-names>J.</given-names></name>
<name><surname>Kurki</surname><given-names>A.</given-names></name>
<name><surname>Wilkins</surname><given-names>C.</given-names></name>
<name><surname>Gersten</surname><given-names>R.</given-names></name>
</person-group> (<year>2010</year>). <source>The impact of Collaborative Strategic Reading on the reading comprehension of grade 5 students in linguistically diverse schools. (NCEE 2011-4001)</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Center for Education Evaluation and Regional Assistance, Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr17-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hosp</surname><given-names>M. K.</given-names></name>
<name><surname>Fuchs</surname><given-names>L. S.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Using CBM as an indicator of decoding, word reading, and comprehension: Do the relations change with grade?</article-title> <source>School Psychology Review</source>, <volume>34</volume>, <fpage>9</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr18-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jenkins</surname><given-names>J.</given-names></name>
<name><surname>Jewell</surname><given-names>M.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Examining the validity of two measures for formative teaching: Reading aloud and maze</article-title>. <source>Exceptional Children</source>, <volume>59</volume>, <fpage>421</fpage>–<lpage>432</lpage>.</citation>
</ref>
<ref id="bibr19-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Katims</surname><given-names>D. S.</given-names></name>
<name><surname>Harmon</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Strategic instruction in middle school social studies: Enhancing academic and literacy outcomes for at-risk students</article-title>. <source>Intervention in School and Clinic</source>, <volume>35</volume>, <fpage>280</fpage>–<lpage>289</lpage>.</citation>
</ref>
<ref id="bibr20-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Reciprocal teaching of reading comprehension strategies for students with learning disabilities who use English as a second language</article-title>. <source>Elementary School Journal</source>, <volume>96</volume>, <fpage>275</fpage>–<lpage>293</lpage>.</citation>
</ref>
<ref id="bibr21-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The helping behaviors of fifth graders while using collaborative strategic reading during ESL content classes</article-title>. <source>TESOL Quarterly</source>, <volume>34</volume>(<issue>1</issue>), <fpage>69</fpage>–<lpage>98</lpage>.</citation>
</ref>
<ref id="bibr22-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Argüelles</surname><given-names>M. E.</given-names></name>
<name><surname>Hughes</surname><given-names>M. T.</given-names></name>
<name><surname>Ahwee</surname><given-names>S.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Collaborative strategic reading: “Real world” lessons from classroom teachers</article-title>. <source>Remedial and Special Education</source>, <volume>25</volume>, <fpage>291</fpage>–<lpage>302</lpage>.</citation>
</ref>
<ref id="bibr23-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Boardman</surname><given-names>A.</given-names></name>
<name><surname>Swanson</surname><given-names>E.</given-names></name>
</person-group> (<year>2012</year>). <source>Now We Get It!: Boosting Comprehension Strategies with Collaborative Strategic Reading</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr24-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Dimino</surname><given-names>J.</given-names></name>
<name><surname>Schumm</surname><given-names>J. S.</given-names></name>
<name><surname>Bryant</surname><given-names>D. P.</given-names></name>
</person-group> (<year>2001</year>). <source>Collaborative Strategic Reading: Strategies for Improving Comprehension</source>. <publisher-loc>Longmont, CO</publisher-loc>: <publisher-name>Sopris West Educational Services</publisher-name>.</citation>
</ref>
<ref id="bibr25-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Schumm</surname><given-names>J. S.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Collaborative strategic reading during social studies in heterogeneous fourth-grade classrooms</article-title>. <source>The Elementary School Journal</source>, <volume>99</volume>, <fpage>3</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr26-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lembke</surname><given-names>E.</given-names></name>
<name><surname>Stecker</surname><given-names>P.</given-names></name>
</person-group> (<year>2007</year>). <source>Curriculum-based measurement in mathematics: An evidence-based formative assessment procedure</source>. <publisher-loc>Portsmouth, NH</publisher-loc>: <publisher-name>RMC Research Corporation, Center on Instruction</publisher-name>.</citation>
</ref>
<ref id="bibr27-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mooney</surname><given-names>P.</given-names></name>
<name><surname>McCarter</surname><given-names>K. S.</given-names></name>
<name><surname>Schraven</surname><given-names>J.</given-names></name>
<name><surname>Haydel</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The relationship between content area general outcome measurement and statewide testing in sixth grade world history</article-title>. <source>Assessment for Effective Intervention</source>, <volume>35</volume>, <fpage>148</fpage>–<lpage>158</lpage>.</citation>
</ref>
<ref id="bibr28-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mooney</surname><given-names>P.</given-names></name>
<name><surname>Schraven</surname><given-names>J.</given-names></name>
<name><surname>Cox</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Test-retest reliability of vocabulary matching in sixth-grade world history</article-title>. <source>International Journal of Psychology: A Biopsychosocial Approach</source>, <volume>6</volume>, <fpage>29</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr29-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Murnane</surname><given-names>R. J.</given-names></name>
<name><surname>Willett</surname><given-names>J. B.</given-names></name>
</person-group> (<year>2011</year>). <source>Methods matter: Improving causal inference in educational and social science research</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr30-1534508413489162">
<citation citation-type="book">
<collab>National Center for Education Statistics</collab>. (<year>2011</year>). <source>The nation’s report card in reading</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>U.S. Department of Education, Institute of Education Sciences</publisher-name>.</citation>
</ref>
<ref id="bibr31-1534508413489162">
<citation citation-type="book">
<collab>National Center for Education Statistics</collab>. (<year>2012</year>). <source>The nation’s report card: Vocabulary results from the 2009 and 2011 NAEP reading assessments</source> (NCES 2013 452). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Institute of Education Sciences, U.S. Department of Education</publisher-name>.</citation>
</ref>
<ref id="bibr32-1534508413489162">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Raudenbush</surname><given-names>S. W.</given-names></name>
<name><surname>Bryk</surname><given-names>A. S.</given-names></name>
</person-group> (<year>2002</year>). <source>Hierarchical linear models: Applications and data analysis methods</source> (<edition>2nd ed.</edition>). <publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr33-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shin</surname><given-names>J.</given-names></name>
<name><surname>Deno</surname><given-names>S. L.</given-names></name>
<name><surname>Espin</surname><given-names>C.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Technical adequacy of the maze task curriculum-based measurement of reading growth</article-title>. <source>Journal of Special Education</source>, <volume>34</volume>, <fpage>164</fpage>–<lpage>172</lpage>.</citation>
</ref>
<ref id="bibr34-1534508413489162">
<citation citation-type="web">
<collab>The University of the State of New York</collab>. (<year>2009</year>).<source>Grade 5 elementary-level social studies test</source> [Booklet 1 multiple choice and constructed-response questions]. <publisher-loc>Albany, NY</publisher-loc>: <publisher-name>The State Education Department</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.nysedregents.org/Grade5/SocialStudies/home.html">http://www.nysedregents.org/Grade5/SocialStudies/home.html</ext-link></citation>
</ref>
<ref id="bibr35-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vannest</surname><given-names>K. J.</given-names></name>
<name><surname>Parker</surname><given-names>R.</given-names></name>
<name><surname>Dyer</surname><given-names>N.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Progress monitoring in grade 5 for low achievers</article-title>. <source>Journal of Special Education</source>, <volume>44</volume>, <fpage>221</fpage>–<lpage>233</lpage>.</citation>
</ref>
<ref id="bibr36-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Klingner</surname><given-names>J. K.</given-names></name>
<name><surname>Swanson</surname><given-names>E. A.</given-names></name>
<name><surname>Boardman</surname><given-names>A. G.</given-names></name>
<name><surname>Roberts</surname><given-names>G.</given-names></name>
<name><surname>Mohammed</surname><given-names>S. S.</given-names></name>
<name><surname>Stillman-Spisak</surname><given-names>S. J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Efficacy of Collaborative Strategic Reading with middle school students</article-title>. <source>American Educational Research Journal</source>, <volume>48</volume>, <fpage>938</fpage>–<lpage>964</lpage>.</citation>
</ref>
<ref id="bibr37-1534508413489162">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vaughn</surname><given-names>S.</given-names></name>
<name><surname>Swanson</surname><given-names>E. A.</given-names></name>
<name><surname>Roberts</surname><given-names>G.</given-names></name>
<name><surname>Wanzek</surname><given-names>J.</given-names></name>
<name><surname>Stillman-Spisak</surname><given-names>S. J.</given-names></name>
<name><surname>Solis</surname><given-names>M.</given-names></name>
<name><surname>Simmons</surname><given-names>D.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Improving reading comprehension and social studies knowledge in middle school</article-title>. <source>Reading Research Quarterly</source>, <volume>48</volume>, <fpage>77</fpage>–<lpage>93</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>