<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TIA</journal-id>
<journal-id journal-id-type="hwp">sptia</journal-id>
<journal-id journal-id-type="nlm-ta">Trends Amplif</journal-id>
<journal-title>Trends in Amplification</journal-title>
<issn pub-type="ppub">1084-7138</issn>
<issn pub-type="epub">1940-5588</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1084713813482759</article-id>
<article-id pub-id-type="publisher-id">10.1177_1084713813482759</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Perception of Pure Tones and Iterated Rippled Noise for Normal Hearing and Cochlear Implant Users</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Penninger</surname><given-names>Richard T.</given-names></name>
<xref ref-type="aff" rid="aff1-1084713813482759">1</xref>
<xref ref-type="aff" rid="aff2-1084713813482759">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Chien</surname><given-names>Wade W.</given-names></name>
<xref ref-type="aff" rid="aff3-1084713813482759">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Jiradejvong</surname><given-names>Patpong</given-names></name>
<xref ref-type="aff" rid="aff3-1084713813482759">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Boeke</surname><given-names>Emily</given-names></name>
<xref ref-type="aff" rid="aff4-1084713813482759">4</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Carver</surname><given-names>Courtney L.</given-names></name>
<xref ref-type="aff" rid="aff3-1084713813482759">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Limb</surname><given-names>Charles J.</given-names></name>
<xref ref-type="aff" rid="aff3-1084713813482759">3</xref>
<xref ref-type="aff" rid="aff5-1084713813482759">5</xref>
</contrib>
</contrib-group>
<aff id="aff1-1084713813482759"><label>1</label>Ghent University, Ghent, Belgium</aff>
<aff id="aff2-1084713813482759"><label>2</label>Medical University (MHH), Hannover, Germany</aff>
<aff id="aff3-1084713813482759"><label>3</label>Department of Otolaryngology, Johns Hopkins School of Medicine, Baltimore, MD, USA</aff>
<aff id="aff4-1084713813482759"><label>4</label>Tufts University, Medford, MA, USA</aff>
<aff id="aff5-1084713813482759"><label>5</label>Peabody Conservatory of Music, Baltimore, MD USA</aff>
<author-notes>
<corresp id="corresp1-1084713813482759">Richard T. Penninger, Ghent University, Blandijnberg 2, 9000 Ghent,
Belgium. Email: <email>Richard.penninger@ugent.be</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>17</volume>
<issue>1</issue>
<fpage>45</fpage>
<lpage>53</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Cochlear Implant (CI) users typically perform poorly on musical tasks, especially those based on pitch ranking and melody recognition. It was hypothesized that CI users would demonstrate deterioration in performance for a pitch ranking and a melody recognition task presented with iterated rippled noise (IRN) in comparison to pure tones (PT). In Addition, it was hypothesized that normal hearing (NH) listeners would show fewer differences in performance between IRN and PT for these two tasks.</p>
<p>In this study, the ability of CI users and NH subjects to rank pitches and to identify melodies created with IRN and PT was assessed in free field in a sound-isolated room. CI subjects scored significantly above chance level with PT stimuli in both tasks. With IRN stimuli their performance was around chance level. NH subjects scored significantly above chance level in both tasks and with all stimuli. NH subjects performed significantly better than CI subjects in both tasks. These results illustrate the difficulties of CI subjects to rank pitches and to identify melodies.</p>
</abstract>
<kwd-group>
<kwd>cochlear implants</kwd>
<kwd>pitch perception</kwd>
<kwd>melody recognition</kwd>
<kwd>iterated rippled noise</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1084713813482759" sec-type="intro">
<title>Introduction</title>
<p>Cochlear implant (CI) users often have difficulties with music perception (<xref ref-type="bibr" rid="bibr19-1084713813482759">Nimmons et al., 2008</xref>), despite relative overall success with speech perception. These difficulties in music perception are largely attributable to poor perception of pitch, the psychoacoustic correlate of stimulus frequency. In the human auditory system, pitch can be processed in two ways. In the cochlea, the basilar membrane acts as a frequency analyzer and activates the hair cells and auditory nerve fibers that are specifically tuned to the frequency of the incoming pitch and located spatially along the tonotopic gradient of the cochlea. This type of processing is referred to as “place pitch” (<xref ref-type="bibr" rid="bibr7-1084713813482759">Goldstein, 1973</xref>; <xref ref-type="bibr" rid="bibr24-1084713813482759">Terhardt, 1974</xref>; <xref ref-type="bibr" rid="bibr25-1084713813482759">Wightman, 1973</xref>), and is presumably critical for processing of a pure tone (PT). It has also been shown that the firing of auditory nerve fibers can “phase lock” to the frequency of the incoming pitch signal up to around 5,000 Hz (<xref ref-type="bibr" rid="bibr21-1084713813482759">Rose, Brugge, Anderson, &amp; Hind, 1967</xref>), and pitch information can be encoded by the rate of auditory nerve firing. This is referred to as “rate pitch” (<xref ref-type="bibr" rid="bibr16-1084713813482759">McKay, McDermott, &amp; Clark, 1994</xref>; <xref ref-type="bibr" rid="bibr20-1084713813482759">Pijl &amp; Schwarz, 1995</xref>). It is controversial whether pitch is processed primarily using place or rate pitch because the place and temporal codes usually covary with stimulus frequency in acoustic hearing (<xref ref-type="bibr" rid="bibr2-1084713813482759">Chatterjee &amp; Zwislocki, 1997</xref>; <xref ref-type="bibr" rid="bibr17-1084713813482759">Moller, 1999</xref>; <xref ref-type="bibr" rid="bibr35-1084713813482759">Zeng, 2002</xref>).</p>
<p>Iterated rippled noise (IRN) is created by a cascade of add and delay cycles (<xref ref-type="bibr" rid="bibr32-1084713813482759">Yost, 1996</xref>). The pitch of the IRN is shown by performing an autocorrelation with the signal (<xref ref-type="fig" rid="fig1-1084713813482759">Figure 1A</xref>). The delay of the first peak of the autocorrelation that is not at delay zero (highlighted) is the reciprocal of the pitch frequency. The strength of the pitch is determined by the relative height of this highlighted peak (<xref ref-type="bibr" rid="bibr33-1084713813482759">Yost, Patterson, &amp; Sheft, 1996</xref>) and it increases with stimulus duration (<xref ref-type="bibr" rid="bibr31-1084713813482759">Yost, 2009</xref>).</p>
<fig id="fig1-1084713813482759" position="float">
<label>Figure 1.</label>
<caption>
<p><xref ref-type="fig" rid="fig1-1084713813482759">Figure 1A</xref> shows the autocorrelation and the spectrogram of a 523.25 Hz iterated rippled noise (IRN) stimulus. The pitch of the IRN is indicated by the location of the first peak of the autocorrelation next to lag zero. It occurs at lag 1.91 ms. The reciprocal of the lag is the pitch frequency. <xref ref-type="fig" rid="fig1-1084713813482759">Figure 1B</xref> shows the spectrogram of the same stimulus. The IRN has linear spacing of the spectral peaks in the frequency domain.</p>
</caption>
<graphic xlink:href="10.1177_1084713813482759-fig1.tif"/></fig>
<p>The spectrogram of IRN has equal amplitude peaks at integer multiples of the fundamental frequency of the pitch (<xref ref-type="fig" rid="fig1-1084713813482759">Figure 1B</xref>). The spectrogram of PT sinusoids has peaks at the fundamental frequency of the pitch only. NH listeners can discriminate between two IRN stimuli up to around 5 kHz (<xref ref-type="bibr" rid="bibr34-1084713813482759">Yost, Patterson, &amp; Sheft, 1998</xref>). Most current CI speech processing strategies only process the envelope of the input signal, whereas temporal fine structure is the basis for IRN pitch processing (<xref ref-type="bibr" rid="bibr34-1084713813482759">Yost et al., 1998</xref>). Although there has been considerable data published on spectral ripple discrimination with CI users, there has been no publication using IRN. This differs from spectral ripple discrimination in that IRN has a distinctive temporal property that is absent in the spectral ripple stimuli used in previous studies (<xref ref-type="bibr" rid="bibr8-1084713813482759">Henry, Turner, &amp; Behrens, 2005</xref>; <xref ref-type="bibr" rid="bibr13-1084713813482759">Litvak, Spahr, Saoji, &amp; Fridman, 2007</xref>; <xref ref-type="bibr" rid="bibr30-1084713813482759">Won, Jones, Drennan, Jameyson, &amp; Rubinstein, 2011</xref>).</p>
<p>In this study, IRN and PT were used to investigate the differences in place and rate pitch perception for CI and NH users in a pitch ranking and a melody recognition task. It was hypothesized that CI subjects would demonstrate deterioration in performance for pitch ranking and melody recognition with IRN compared to PT. It was further hypothesized that normal hearing (NH) users would perform better than CI users and would show fewer differences in performance between IRN and PT in the two tasks.</p>
</sec>
<sec id="section2-1084713813482759" sec-type="methods">
<title>Method</title>
<p>Ten NH subjects and 10 CI subjects participated in the study. The age range was 36 to 75 years (mean = 53, <italic>SD</italic> = 11). The biographical information of all CI subjects in this study is shown in <xref ref-type="table" rid="table1-1084713813482759">Table 1</xref>. All persons enrolled were native English speakers. This research was approved by the Institutional Review Board of the Johns Hopkins University School of Medicine. Written consent was obtained from each participant. Each participant underwent pitch ranking and melody recognition tasks as described below.</p>
<table-wrap id="table1-1084713813482759" position="float">
<label>Table 1.</label>
<caption>
<p>Subject Demographics.</p>
</caption>
<graphic alternate-form-of="table1-1084713813482759" xlink:href="10.1177_1084713813482759-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="left"/>
<col align="left"/>
<col align="center"/>
<col align="center"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">ID</th>
<th align="center">Age</th>
<th align="center">Sex</th>
<th align="center">Cause of hearing loss</th>
<th align="center">Duration hearing loss (years)</th>
<th align="center">CI exposure (months)</th>
<th align="center">Device</th>
</tr>
</thead>
<tbody>
<tr>
<td> 1</td>
<td>60</td>
<td>M</td>
<td>Unknown</td>
<td>25</td>
<td>36</td>
<td>Nucleus freedom</td>
</tr>
<tr>
<td>2</td>
<td>48</td>
<td>F</td>
<td>Unknown</td>
<td>25</td>
<td>96</td>
<td>Clarion 1</td>
</tr>
<tr>
<td>3</td>
<td>36</td>
<td>F</td>
<td>Unknown</td>
<td>3</td>
<td>19</td>
<td>Nucleus freedom</td>
</tr>
<tr>
<td>4</td>
<td>57</td>
<td>F</td>
<td>Otosclerosis</td>
<td>39</td>
<td>48</td>
<td>Nucleus freedom</td>
</tr>
<tr>
<td>5</td>
<td>75</td>
<td>F</td>
<td>Autoimmune</td>
<td>28</td>
<td>140</td>
<td>Nucleus 22</td>
</tr>
<tr>
<td>6</td>
<td>54</td>
<td>M</td>
<td>Sudden hearing loss</td>
<td>3</td>
<td>24</td>
<td>Sonata</td>
</tr>
<tr>
<td>7</td>
<td>39</td>
<td>M</td>
<td>Unknown</td>
<td>2</td>
<td>12</td>
<td>Hi-Res 90K</td>
</tr>
<tr>
<td>8</td>
<td>52</td>
<td>F</td>
<td>Unknown</td>
<td>6</td>
<td>72</td>
<td>Hi-Res 90K</td>
</tr>
<tr>
<td>9</td>
<td>50</td>
<td>F</td>
<td>Unknown</td>
<td>2</td>
<td>15</td>
<td>Hi-Res 90K</td>
</tr>
<tr>
<td>10</td>
<td>59</td>
<td>M</td>
<td>Meniere</td>
<td>24</td>
<td>24</td>
<td>Hi-Res 90K</td>
</tr>
</tbody>
</table>
</table-wrap>
<sec id="section3-1084713813482759">
<title>Stimulus Generation</title>
<p>IRN was generated by delaying and adding white noise to itself. The IRN tones were created with eight iterations and with gain of one (see <xref ref-type="fig" rid="fig2-1084713813482759">Figure 2</xref>). The output waveform of one delay and add stage served as the input to the next stage (“add original” configuration) and for noise-delays (d) between 2 and 30 ms, IRN stimuli have a pitch corresponding to 1/d kHz (<xref ref-type="bibr" rid="bibr32-1084713813482759">Yost, 1996</xref>).</p>
<fig id="fig2-1084713813482759" position="float">
<label>Figure 2.</label>
<caption>
<p>The process of making iterated rippled noise (IRN). IRN was generated by delaying white noise by a certain amount of ms and adding it to itself. The perceived pitch was 1/delay. This process was repeated eight times (eight iterations).</p>
</caption>
<graphic xlink:href="10.1177_1084713813482759-fig2.tif"/></fig>
<p>All pitches (IRN and PT) were generated using Audacity 1.2.5 (Dominic Mazzoni, open source) at a sampling rate of 44.1 kHz. The IRNs were then filtered using fourth-order Butterworth filters between 150 Hz and 4.5 kHz to minimize any spectral cues. Stimuli were randomly presented in a soundproof booth through a single calibrated loudspeaker (Sony SS-MB150H) at a presentation level of 75 dB sound pressure level through an OB822 clinical audiometer (Madsen Electronics). The speaker was positioned directly in front of the listener. For CI subjects, the contralateral ear (which was profoundly impaired in all individuals) was occluded with an earplug to diminish the effects of any minimal residual hearing, and no hearing aids were used. Each pitch was constructed such that an eighth note was exactly 250 ms in duration. They were presented at a tempo of 120 beats per minute. Each note was given linear rise/decay ramps of 50 ms to reduce onset clicks and to minimize transients in the filter bank outputs.</p>
</sec>
<sec id="section4-1084713813482759">
<title>Pitch Ranking</title>
<p>The pitch ranking task was implemented using a two-interval, two-alternative, forced-choice (2I2AFC) test. On each presentation, two pitches were played sequentially. The listener was asked to identify which of the two pitches was higher in frequency. The minimum tested interval was one semitone, and the maximum was 12 semitones. The pitch pairs used consisted of semitone steps within an octave ranging from 261.63Hz to 523.25 Hz. Each interval was tested six times per subject using either PT or IRN in a randomized fashion. PT and IRN stimuli were run in intermixed blocks with randomized intervals.</p>
</sec>
<sec id="section5-1084713813482759">
<title>Melody Recognition</title>
<p>In this test, the listeners were asked to identify the recordings of 12 common melodies from a closed set. Individual pitches were combined to create isochronous, eighth notes melodies in order to reduce potential rhythm cues that might be used for melody identification. The accumulated semitone range (ASR) of all notes of each melody was calculated. ASR ranged from 26 to 73 semitones. The following melodies were selected for their general familiarity. In parenthesis is the corresponding ASR. “Auld Lang Syne” (47), “Deck the Halls” (53), “Frère Jaques” (58), “Frosty the Snow Man” (54), “London Bridges” (32), “Mary Had a Little Lamb” (26), “Ode of Joy” (26), “Somewhere Over the Rainbow” (73), the opening theme of “The Sound of Music” (29), “Swing Low Sweet Chariot” (51), “Twinkle, Twinkle Little Star” (30), and “Yankee Doodle” (46). All melodies were presented for 12 s to prevent the use of melody length as a cue. Prior to testing, all listeners were given a list of the 12 melodies and were asked to indicate their familiarity with each melody. Unfamiliar melodies were included in the test but were removed from the final analysis. Each melody was presented three times using PTs and IRNs in a randomized fashion. PT and IRN stimuli were run in intermixed blocks with randomized intervals.</p>
</sec>
</sec>
<sec id="section6-1084713813482759" sec-type="results">
<title>Results</title>
<p>Results from both experiments were found to be not normally distributed. The Kolmogorov–Smirnov test was used to check the data distribution. Both of the experiments in this study used forced-choice procedures, therefore the results can be analyzed with the binomial probability distribution. A binomial experiment consists of repeated trials where the outcome of each trial is labeled either success or failure. The probability of success remains constant from trial to trial. In evaluating the result of a forced-choice experiment, the first question is whether the subjects were merely guessing. For the pitch ranking procedure it was considered that the null hypothesis of the probability of success on each trial was 50%. For the melody recognition task there were 12 melodies to select meaning that the probability of success in each trial was 8.33% (1/12). If the resulting probability (<italic>p</italic>) is less than the criterion value α = 0.05 that is generally accepted for statistical significance. It was then concluded that it was unlikely that the null hypothesis is true, that is the subjects were most likely using some cue in the stimuli to obtain a good score. The second question is whether the subjects performed better with IRN or PT stimuli. <xref ref-type="bibr" rid="bibr22-1084713813482759">Simon (1997)</xref> advocated the unorthodox approach of simulating the experiment on a computer, sometimes known as the Monte Carlo method (<xref ref-type="bibr" rid="bibr22-1084713813482759">Simon, 1997</xref>). It is based on pseudorandom numbers with a binomial distribution. In the present study 100,000 runs were stimulated in the Monte Carlo simulation to check if the subjects performed better in one of the two condition (IRN or PT).</p>
<sec id="section7-1084713813482759">
<title>Pitch Ranking</title>
<p>Averaged across all pitches, NH users scored 89.58% ± 6.28% correct (mean ± <italic>SD</italic>) for the IRN stimuli. For the PT stimuli they scored 93.19% ± 5.55% correct. Performance with both listening conditions was significantly above chance level (both <italic>p</italic> = 0.00 (<italic>p</italic>_PT = 6.16e-141 and <italic>p</italic>_IRN = 3.03e-114)). <xref ref-type="fig" rid="fig3-1084713813482759">Figure 3A</xref> shows details about the performance of NH subjects.</p>
<fig id="fig3-1084713813482759" position="float">
<label>Figure 3.</label>
<caption>
<p>Performance of both listeners in the pitch ranking task. The error bars represent the 95% confidence interval of the mean. The dotted lines that are at 50% in both graphs show chance performance level. Linear regression was used on both graphs to fit a line to show the increase in performance with increasing semitone distance.</p>
</caption>
<graphic xlink:href="10.1177_1084713813482759-fig3.tif"/></fig>
<p>CI subjects scored on average 57.08% ± 7.76% for the IRN stimuli and 80.00% ± 11.90% for the PT stimuli. Performance was not significantly above chance level for IRN stimuli (<italic>p</italic> = .31) but significantly above chance level for PT stimuli (<italic>p</italic> &lt; .01). <xref ref-type="fig" rid="fig3-1084713813482759">Figure 3B</xref> shows details about the performance of the CI subjects.</p>
<p>For NH subjects no significant difference in performance was observed between both listening conditions (<italic>p</italic> = .31). CI subjects performed significantly better with PTs compared to IRN stimuli (<italic>p</italic> &lt; .01). The performance of the NH subjects was significantly better than the performance of the CI subjects in both listening conditions (<italic>p</italic> &lt; .01).</p>
<p>Linear regression was used to fit a line to the results using the equation <italic>y</italic>(<italic>t</italic>) = <italic>k</italic> × <italic>t</italic> + <italic>d</italic>. The factor “<italic>k</italic>” is the inclination and the summand “<italic>d</italic>” is the offset of the fitted line. The inclination “<italic>k</italic>” helps to determine if there is a performance increase with increasing semitone distance. Inclination and offset lie with a probability of 95% within their corresponding interval range. For NH subjects inclination and offset (each ± intervals) are [<italic>k</italic><sub>NH PT</sub> = 1.3% ± 0.6% and <italic>d</italic><sub>NH PT</sub> = 84.8% ± 4.9%] for the PT stimuli and [<italic>k</italic><sub>NH IRN</sub> = 1.7% ± 0.5% and <italic>d</italic><sub>NH IRN</sub> = 78.9% ± 3.9%] for the IRN stimuli. Both inclinations are positive meaning that the performance increased on average 1.3% per semitone for the PT and with 1.7% per semitone for the IRN stimuli (<xref ref-type="fig" rid="fig3-1084713813482759">Figure 3A</xref>). For CI subjects, performance of pitch ranking also increased as semitone distance increased. Inclination and offset were [<italic>k</italic><sub>CI IRN</sub> = 2.0% ± 0.7% and <italic>d</italic><sub>CI IRN</sub> = 44.0% ± 5.3] for IRN stimuli and [<italic>k</italic><sub>CI PT</sub> = 3.0% ± 1.1% and <italic>d</italic><sub>CI PT</sub> = 60.2% ± 8.4%] for the PT stimuli. Both inclinations are positive, meaning that performance increased on average with 2.0% per semitone for the IRN and with 3.0% per semitone for the PT stimuli (<xref ref-type="fig" rid="fig3-1084713813482759">Figure 3B</xref>).</p>
<p>NH listeners perform equally well regardless of listening condition. This is due to a ceiling effect in the results. CI users perform significantly better with PT stimuli.</p>
</sec>
<sec id="section8-1084713813482759">
<title>Melody Recognition</title>
<p>Averaged across all melodies, NH users scored 87.78% ± 11.00% correct for the IRN stimuli. For the PT stimuli NH subject scored 92.50% ± 8.29% correct. Performance for both listening conditions was significantly above chance level (<italic>p</italic> &lt; .01).</p>
<p>CI subjects scored on average 15.56% ± 4.78% for the IRN stimuli and 19.17% ± 7.47% for the PT stimuli. Performance was not significantly above chance level for the IRN (<italic>p</italic> = .09) but only just significantly above chance level for the PT stimuli (<italic>p</italic> = .03).</p>
<p>No significant difference in performance between both listening conditions was observed for NH subjects (<italic>p</italic> = .26). The performance of the NH subjects was significantly better than the performance of the CI subjects in both listening conditions (<italic>p</italic> &lt; .01). <xref ref-type="fig" rid="fig4-1084713813482759">Figure 4</xref> shows the performance in the melody recognition task for both groups of listeners. Linear regression was used again to test if increasing accumulated semitone range (ASR) improves performance. For NH subjects, inclinations of the performance graph for IRN and PT were <italic>k</italic><sub>NH IRN</sub> = 0.19% ± 0.36% and <italic>k</italic><sub>NH PT</sub> = 0.08% ± 0.30%. The corresponding offsets were <italic>d</italic><sub>NH IRN</sub> = 80.3% ± 15.3% and <italic>d</italic><sub>NH PT</sub> = 89.4% ± 12.21%. For CI subjects, IRN stimuli inclination and offset were <italic>k</italic><sub>CI IRN</sub> = 0% ± 0.16% and <italic>d</italic><sub>CI IRN</sub> = 16.6% ± 7.1%. For the PT stimuli, inclination was <italic>k</italic><sub>CI PT</sub> = 0% ± 0.26% and offset was <italic>d</italic><sub>CI PT</sub> = 18.9% ± 11.2%. For NH subjects, performance increased with 0.19% per ASRs for the IRN and with 0.08% per ASRs for the PT. For CI subjects inclinations averaged around 0% per ASR for both conditions.</p>
<fig id="fig4-1084713813482759" position="float">
<label>Figure 4.</label>
<caption>
<p>Performance both listeners in the melody recognition task. The error bars represent the 95% of confidence intervals. The dotted lines that are at 8.3% in both graphs show chance performance level.</p>
</caption>
<graphic xlink:href="10.1177_1084713813482759-fig4.tif"/></fig>
</sec>
</sec>
<sec id="section9-1084713813482759" sec-type="discussion">
<title>Discussion</title>
<p>NH subjects showed no difference in performance between IRN and PT stimuli in the pitch ranking and in the melody recognition task. The reason could be a ceiling effect in both tasks that might have washed out the differences in performance. It could however be that pitch ranking and melody discrimination performance for IRN and PT is the same for NH subjects. Further studies would be needed to investigate this.</p>
<p>CI subjects performed significantly above chance level with the PT stimuli in the pitch ranking and the melody recognition task. With IRN stimuli performance was around chance level in both tasks. For both listening conditions and tasks, the NH subjects performed significantly better than the CI users. Pitch perception for PT and IRN differs from one another in several ways that are particularly relevant for CI mediated listening.</p>
<sec id="section10-1084713813482759">
<title>TFS and Envelope</title>
<p>Speech is a temporally complex signal, containing both slow amplitude modulations of the temporal envelope and fast frequency oscillations of the temporal fine structure (TFS) within each frequency band (<xref ref-type="bibr" rid="bibr4-1084713813482759">Fogerty &amp; Humes, 2012</xref>). The envelope information that is transmitted primarily by most current CI processing strategies is sufficient for understanding speech in quiet conditions (<xref ref-type="bibr" rid="bibr26-1084713813482759">Wilson et al., 1991</xref>; <xref ref-type="bibr" rid="bibr27-1084713813482759">Wilson, Lawson, Zerbi, Finley, &amp; Wolford, 1995</xref>). TFS also plays an important role in pitch and speech perception and it enhances pitch and sound quality. Behavioral studies in humans show that sensorineural hearing loss (SNHL) decreases sensitivity to TFS of sound (<xref ref-type="bibr" rid="bibr14-1084713813482759">Lorenzi, Debruille, Garnier, Fleuriot, &amp; Moore, 2009</xref>; <xref ref-type="bibr" rid="bibr15-1084713813482759">Lorenzi, Gilbert, Carn, Garnier, &amp; Moore, 2006</xref>; <xref ref-type="bibr" rid="bibr18-1084713813482759">Moore, Glasberg, &amp; Hopkins, 2006</xref>). Henry and Heinz found that SNHL reduces the strength of temporal coding in noise at the most peripheral level of auditory processing (<xref ref-type="bibr" rid="bibr9-1084713813482759">Henry &amp; Heinz, 2012</xref>). TSF is not transmitted well by any CI system. Attempts to deliver TFS information have been made in some current sound processing strategies (<xref ref-type="bibr" rid="bibr10-1084713813482759">Hochmair et al., 2006</xref>; <xref ref-type="bibr" rid="bibr12-1084713813482759">Laneau, Wouters, &amp; Moonen, 2006</xref>).</p>
</sec>
<sec id="section11-1084713813482759">
<title>Amplitude Modulation Detection Problem Due to Signal Processing</title>
<p>In the process of vocoding, the stimuli is filtered and TFS is effectively tossed out and replaced with a constant rate pulse train in each channel. TFS can be expressed by frequency modulation and as the frequency modulations move in and out of the CI filters the process created amplitude modulations. TFS cues may also be perceived as a within-channel pitch cue if a broadband, flat envelope stimulus is supplied as input for the speech processor (<xref ref-type="bibr" rid="bibr6-1084713813482759">Gilbert &amp; Lorenzi, 2006</xref>; <xref ref-type="bibr" rid="bibr11-1084713813482759">Imennov, Won, Drennan, Jameyson, &amp; Rubinstein, 2013</xref>). Modulations can also occur as a response to a complex tone: If more than one harmonic falls within the bandwidth of a filter, the envelope modulation frequency will be the fundamental frequency of the input sound (<xref ref-type="bibr" rid="bibr23-1084713813482759">Swanson, 2008</xref>). No matter how the TFS cues are created, the CI subjects seem to have a temporal pitch limit around 300 Hz (<xref ref-type="bibr" rid="bibr35-1084713813482759">Zeng, 2002</xref>). The maximum rate per channel is, for example, 900 Hz for implants from Cochlear Ltd. and it could serve as a carrier of the amplitude modulation frequency. There is a factor of around 3 to 4 between the highest modulation frequency and the carrier rate (<xref ref-type="bibr" rid="bibr16-1084713813482759">McKay et al., 1994</xref>). Due to this low-carrier rate the maximum modulation frequency is around 300 Hz, which is lower than most pitches that were used in the present study.</p>
</sec>
<sec id="section12-1084713813482759">
<title>Amplitude Modulation Detection Problem Due to Background Noise</title>
<p>The periodic peaks in the time domain of an IRN signal are accompanied by the presence of a high background noise. This background noise overlaps with the signal and decreases the modulation depth of the periodic peaks. It severely impedes CI users because they generally have a small dynamic range (DR). Normal acoustic hearing can process sounds over a range of 120 dB, and instantaneous amplitudes in normal speech cover a 30 to 60 dB range (<xref ref-type="bibr" rid="bibr1-1084713813482759">Boothroyd, Erickson, &amp; Medwetsky, 1994</xref>). Implant listeners typically have DRs of only 6 to 15 dB in electric current, requiring the larger acoustic range to be compressed into the smaller electrical range (<xref ref-type="bibr" rid="bibr5-1084713813482759">Fu &amp; Shannon, 1999</xref>). This DR compression might be another explanation for the poor performance of CI subjects in ranking IRN stimuli. While certain stimulus manipulations such as increasing the duration of the stimulus may strengthen the pitch percept induced by IRN (<xref ref-type="bibr" rid="bibr31-1084713813482759">Yost, 2009</xref>), the present study found that NH controls could rank IRN pitches with only 250 ms duration well. CI users demonstrated great difficulty in these tasks. DR, along with other factors, was also found to significantly affect spectral-ripple discrimination for CI users (<xref ref-type="bibr" rid="bibr30-1084713813482759">Won, Jones, Drennan, Jameyson, &amp; Rubinstein, 2011</xref>Reducing DR also lowers phoneme recognition significantly, particularly in noise and for vowels (<xref ref-type="bibr" rid="bibr36-1084713813482759">Zeng &amp; Galvin, 1999</xref>).</p>
</sec>
<sec id="section13-1084713813482759">
<title>Comparison Spectral Ripples and IRN</title>
<p><xref ref-type="bibr" rid="bibr29-1084713813482759">Won, Drennan, &amp; Rubinstein (2007)</xref> performed a study with spectral-ripple discrimination for CI users. Their spectral ripples were logarithmically spaced in the frequency domain with an amplitude envelope determined by a sinusoid in a decibel scale. They found that spectral-ripple resolution correlates with speech reception in noise for CI users and could serve as a tool to evaluate CI performance with different speech processing strategies. In another study <xref ref-type="bibr" rid="bibr28-1084713813482759">Won, Drennan, Nie, Jameyson, &amp; Rubinstein (2011)</xref> found that temporal modulation detection measured with the sound processor can serve as a useful measure of the ability of clinical sound processing strategies to deliver clinically pertinent temporal information). Without TFS present, IRN and spectral ripples might look much more alike in their spectral properties. CI subjects have great difficulty with TFS perception therefore results should be similar for both stimulations. As noted in the introduction (<xref ref-type="fig" rid="fig1-1084713813482759">Figure 1</xref>), IRN have linear spacing of the peaks in the frequency spectrum whereas summed sinusoid spectral ripples are usually done with logarithmical spacing of the peaks in the frequency spectrum(<xref ref-type="bibr" rid="bibr29-1084713813482759">Won et al., 2007</xref>). The reason for using logarithmic ripples is that logarithmic amplitude is closer to the perceptual scale of loudness. Others, however do use ripples with a sinusoidal shape on a linear amplitude axis (<xref ref-type="bibr" rid="bibr8-1084713813482759">Henry et al., 2005</xref>).</p>
</sec>
<sec id="section14-1084713813482759">
<title>TFS Discrimination of the Hearing Impaired</title>
<p>Several studies have been conducted to analyze TFS discrimination for hearing impaired subject groups. <xref ref-type="bibr" rid="bibr3-1084713813482759">Drennan, Won, Dasika, &amp; Rubinstein (2007)</xref> investigated the effect of randomized TFS presented with vocoded speech on NH subjects. They found that improved delivery of TFS improves speech understanding in noise for implant recipients and that bilateral implant recipients might benefit from temporal envelope interaural time differences. <xref ref-type="bibr" rid="bibr8-1084713813482759">Henry et al. (2005)</xref> found a relationship between the spectral-ripple threshold and vowel and consonant recognition in quiet in NH, hearing impaired and CI subjects. More recently, <xref ref-type="bibr" rid="bibr11-1084713813482759">Imennov et al. (2013)</xref> investigated the perception of acoustic TFS with single channel and multiple channel strategies. Although both strategies were capable of delivering acoustic TFS cues, a single channel analog signal performed better under challenging discrimination condition. Without TFS cues the spectral properties of IRN and spectral ripples look very similar. Therefore improving transmission of IRN stimuli could as well be beneficial for speech understanding in noise.</p>
</sec>
<sec id="section15-1084713813482759">
<title>Place Pitch</title>
<p>An illustration of the difference in processing between IRN and PT-pitch is provided by plotting the output current on each electrode of a CI speech processor over time. The tones in this example were processed by the ACE strategy and at pulse rate of 500 pps per channel, implemented in Nucleus MATLAB Toolbox (NMT) from Cochlear Ltd. Both electrodograms in <xref ref-type="fig" rid="fig5-1084713813482759">Figure 5</xref> show the output current of two proceeding tones with 250 ms in duration (separated by a 250 ms pause). For PT frequency 261.63 Hz, the majority of the current is on electrode 21 and 22, the most apical electrodes. A little bit of current is also applied to electrode 20. For PT frequency 523.25 Hz the peak of the stimulation current is shifted toward electrodes 19-21 with a bit of current on electrodes 18 and 22 (<xref ref-type="fig" rid="fig5-1084713813482759">Figure 5A</xref>). The higher the pitch, the more the stimulation current shifts toward the middle of the cochlea. The lower the fundamental frequency, the more apical are the groups of electrodes that get stimulated. In this example the semitone distance between the two tones is 12 (one octave). These two tones had the maximum semitone distance played in the pitch ranking experiment. It best illustrates the difference in processing in the electrodogram for two tones. A certain distance in fundamental frequencies is required to activate different channels. Therefore, greater semitone distance leads to better performance in CI users. The good pitch ranking and melody recognition results with PT seem to be based mainly on a place pitch cue.</p>
<fig id="fig5-1084713813482759" position="float">
<label>Figure 5.</label>
<caption>
<p><xref ref-type="fig" rid="fig5-1084713813482759">Figure 5</xref> shows the change of current level over time on each electrode processed with Advanced Combination Encoders, or ACE, in a speech processor by Cochlear Ltd. (Cochlear Corp., Sydney, Australia). The output of two sequential tones with 261.63 and 523.25 Hz. PT (left), IRN (right) for the ACE processing scheme in a Nucleus implant is plotted. Each tone in the pair has a length of 250ms with linear rise/decay ramps of 50ms and they are interrupted by a silence pause with 250ms length.</p>
</caption>
<graphic xlink:href="10.1177_1084713813482759-fig5.tif"/></fig>
<p>IRN stimuli lead to stimulation of all active electrodes of the CI. Just by looking at the electrodogram in <xref ref-type="fig" rid="fig5-1084713813482759">Figure 5B</xref> it is hard to tell which of the two tones is higher in pitch. Any place pitch cue is eliminated completely. The sound files that served as input for these two stimuli were directly forwarded to NMT with 100% input–output dynamic range. This eliminates any potential background noise that could appear in the free field sound-isolated room and gives the best possible output of the sound processor.</p>
<p>These findings suggest that several factors account for the bad performance of CI subjects with IRN stimuli: (a) The lack of accurate TFS, (b) the background noise which obscures the dips in the amplitude modulations, and (c) the lack of a place pitch cue in the IRN stimuli. The lack of place pitch is probably the most important difference between the processing of IRN and PT stimuli for CI subjects. Although pitch ranking performance increases with increasing semitone distance, there was no effect of increasing ASD on performance for CI subjects. CI subjects are able to rank IRN pitch significantly above chance level, but melody recognition makes the task too complex for them. For NH users, there is still a small increase in performance with increasing ASR for the PT and almost no effect for the IRN stimuli. Improving the processing for IRN stimuli could not only help to improve music perception, it could also help to improve speech perception in noise.</p>
</sec>
</sec>
<sec id="section16-1084713813482759" sec-type="conclusions">
<title>Conclusion</title>
<p>CI subjects are able to rank pitch and to identify melodies only with PT. IRN pitches and IRN melodies are impossible to be ranked or identified by CI subjects mainly due to the lack of a place pitch cue. Furthermore, the input is smeared with a high background noise. The limited DR and the lack of accurate TFS seems to impede CI users further in filtering out the high background noise of the IRN stimuli. CI users are severely impaired compared to NH subjects in perceiving IRN pitches and melodies. Improving the processing of IRN stimuli could not only help to improve music perception—which was the primary goal of the present study—it could also to improve language perception in noisy environments.</p>
</sec>
</body>
<back>
<ack><p>The authors would like to thank all participants of the study.</p></ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The research leading to these results has received funding from the European Community’s Seventh Framework Program under the EBRAMUS project-grant agreement number 238157.</p></fn>
</fn-group>
<ref-list>
<title>Reference</title>
<ref id="bibr1-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boothroyd</surname><given-names>A.</given-names></name>
<name><surname>Erickson</surname><given-names>F. N.</given-names></name>
<name><surname>Medwetsky</surname><given-names>L.</given-names></name>
</person-group> (<year>1994</year>). <article-title>The hearing aid input: A phonemic approach to assessing the spectral distribution of speech</article-title>. <source>Ear and Hearing</source>, <volume>15</volume>, <fpage>432</fpage>-<lpage>442</lpage>.</citation>
</ref>
<ref id="bibr2-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chatterjee</surname><given-names>M.</given-names></name>
<name><surname>Zwislocki</surname><given-names>J. J.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Cochlear mechanisms of frequency and intensity coding. I. The place code for pitch</article-title>. <source>Hearing Research</source>, <volume>111</volume>, <fpage>65</fpage>-<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr3-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Drennan</surname><given-names>W. R.</given-names></name>
<name><surname>Won</surname><given-names>J. H.</given-names></name>
<name><surname>Dasika</surname><given-names>V. K.</given-names></name>
<name><surname>Rubinstein</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Effects of temporal fine structure on the lateralization of speech and on speech understanding in noise</article-title>. <source>Journal of the Association for Research in Otolaryngology</source>, <volume>8</volume>, <fpage>373</fpage>-<lpage>383</lpage>.</citation>
</ref>
<ref id="bibr4-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fogerty</surname><given-names>D.</given-names></name>
<name><surname>Humes</surname><given-names>L. E.</given-names></name>
</person-group> (<year>2012</year>). <article-title>A correlational method to concurrently measure envelope and temporal fine structure weights: Effects of age, cochlear pathology, and spectral shaping</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>132</volume>, <fpage>1679</fpage>-<lpage>1689</lpage>.</citation>
</ref>
<ref id="bibr5-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fu</surname><given-names>Q. J.</given-names></name>
<name><surname>Shannon</surname><given-names>R. V.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Effect of acoustic dynamic range on phoneme recognition in quiet and noise by cochlear implant users</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>106</volume>, <fpage>L65</fpage>-<lpage>L70</lpage>.</citation>
</ref>
<ref id="bibr6-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilbert</surname><given-names>G.</given-names></name>
<name><surname>Lorenzi</surname><given-names>C.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The ability of listeners to use recovered envelope cues from speech fine structure</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>119</volume>, <fpage>2438</fpage>-<lpage>2444</lpage>.</citation>
</ref>
<ref id="bibr7-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goldstein</surname><given-names>J. L.</given-names></name>
</person-group> (<year>1973</year>). <article-title>An optimum processor theory for the central formation of the pitch of complex tones</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>54</volume>, <fpage>1496</fpage>-<lpage>1516</lpage>.</citation>
</ref>
<ref id="bibr8-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henry</surname><given-names>B. A.</given-names></name>
<name><surname>Turner</surname><given-names>C. W.</given-names></name>
<name><surname>Behrens</surname><given-names>A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Spectral peak resolution and speech recognition in quiet: Normal hearing, hearing impaired, and cochlear implant listeners</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>118</volume>, <fpage>1111</fpage>-<lpage>1121</lpage>.</citation>
</ref>
<ref id="bibr9-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henry</surname><given-names>K. S.</given-names></name>
<name><surname>Heinz</surname><given-names>M. G.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Diminished temporal coding with sensorineural hearing loss emerges in background noise</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume>, <fpage>1362</fpage>-<lpage>1364</lpage>.</citation>
</ref>
<ref id="bibr10-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hochmair</surname><given-names>I.</given-names></name>
<name><surname>Nopp</surname><given-names>P.</given-names></name>
<name><surname>Jolly</surname><given-names>C.</given-names></name>
<name><surname>Schmidt</surname><given-names>M.</given-names></name>
<name><surname>Schosser</surname><given-names>H.</given-names></name>
<name><surname>Garnham</surname><given-names>C.</given-names></name>
<name><surname>Anderson</surname><given-names>I.</given-names></name>
</person-group> (<year>2006</year>). <article-title>MED-EL Cochlear implants: State of the art and a glimpse into the future</article-title>. <source>Trends in Amplification</source>, <volume>10</volume>, <fpage>201</fpage>-<lpage>219</lpage>.</citation>
</ref>
<ref id="bibr11-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Imennov</surname><given-names>N. S.</given-names></name>
<name><surname>Won</surname><given-names>J. H.</given-names></name>
<name><surname>Drennan</surname><given-names>W. R.</given-names></name>
<name><surname>Jameyson</surname><given-names>E.</given-names></name>
<name><surname>Rubinstein</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Detection of acoustic temporal fine structure by cochlear implant listeners: Behavioral results and computational modeling</article-title>. <source>Hearing Research</source>, <volume>298</volume>, <fpage>60</fpage>-<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr12-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Laneau</surname><given-names>J.</given-names></name>
<name><surname>Wouters</surname><given-names>J.</given-names></name>
<name><surname>Moonen</surname><given-names>M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Improved music perception with explicit pitch coding in cochlear implants</article-title>. <source>Audiology and Neurotology</source>, <volume>11</volume>, <fpage>38</fpage>-<lpage>52</lpage>.</citation>
</ref>
<ref id="bibr13-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Litvak</surname><given-names>L. M.</given-names></name>
<name><surname>Spahr</surname><given-names>A. J.</given-names></name>
<name><surname>Saoji</surname><given-names>A. A.</given-names></name>
<name><surname>Fridman</surname><given-names>G. Y.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Relationship between perception of spectral ripple and speech recognition in cochlear implant and vocoder listeners</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>122</volume>, <fpage>982</fpage>-<lpage>991</lpage>.</citation>
</ref>
<ref id="bibr14-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lorenzi</surname><given-names>C.</given-names></name>
<name><surname>Debruille</surname><given-names>L.</given-names></name>
<name><surname>Garnier</surname><given-names>S.</given-names></name>
<name><surname>Fleuriot</surname><given-names>P.</given-names></name>
<name><surname>Moore</surname><given-names>B. C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Abnormal processing of temporal fine structure in speech for frequencies where absolute thresholds are normal</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>125</volume>, <fpage>27</fpage>-<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr15-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lorenzi</surname><given-names>C.</given-names></name>
<name><surname>Gilbert</surname><given-names>G.</given-names></name>
<name><surname>Carn</surname><given-names>H.</given-names></name>
<name><surname>Garnier</surname><given-names>S.</given-names></name>
<name><surname>Moore</surname><given-names>B. C.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Speech perception problems of the hearing impaired reflect inability to use temporal fine structure</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>103</volume>, <fpage>18866</fpage>-<lpage>18869</lpage>.</citation>
</ref>
<ref id="bibr16-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McKay</surname><given-names>C. M.</given-names></name>
<name><surname>McDermott</surname><given-names>H. J.</given-names></name>
<name><surname>Clark</surname><given-names>G. M.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Pitch percepts associated with amplitude-modulated current pulse trains in cochlear implantees</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>96</volume>, <fpage>2664</fpage>-<lpage>2673</lpage>.</citation>
</ref>
<ref id="bibr17-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moller</surname><given-names>A. R.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Review of the roles of temporal and place coding of frequency in speech discrimination</article-title>. <source>Acta Oto-Laryngologica</source>, <volume>119</volume>, <fpage>424</fpage>-<lpage>430</lpage>.</citation>
</ref>
<ref id="bibr18-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moore</surname><given-names>B. C.</given-names></name>
<name><surname>Glasberg</surname><given-names>B. R.</given-names></name>
<name><surname>Hopkins</surname><given-names>K.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Frequency discrimination of complex tones by hearing-impaired subjects: Evidence for loss of ability to use temporal fine structure</article-title>. <source>Hearing Research</source>, <volume>222</volume>, <fpage>16</fpage>-<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr19-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nimmons</surname><given-names>G. L.</given-names></name>
<name><surname>Kang</surname><given-names>R. S.</given-names></name>
<name><surname>Drennan</surname><given-names>W. R.</given-names></name>
<name><surname>Longnion</surname><given-names>J.</given-names></name>
<name><surname>Ruffin</surname><given-names>C.</given-names></name>
<name><surname>Worman</surname><given-names>T.</given-names></name>
<name><surname>Rubeinstein</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Clinical assessment of music perception in cochlear implant listeners</article-title>. <source>Otology &amp; Neurotology</source>, <volume>29</volume>, <fpage>149</fpage>-<lpage>155</lpage>.</citation>
</ref>
<ref id="bibr20-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pijl</surname><given-names>S.</given-names></name>
<name><surname>Schwarz</surname><given-names>D. W.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Melody recognition and musical interval perception by deaf subjects stimulated with electrical pulse trains through single cochlear implant electrodes</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>98</volume>, <fpage>886</fpage>-<lpage>895</lpage>.</citation>
</ref>
<ref id="bibr21-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rose</surname><given-names>J. E.</given-names></name>
<name><surname>Brugge</surname><given-names>J. F.</given-names></name>
<name><surname>Anderson</surname><given-names>D. J.</given-names></name>
<name><surname>Hind</surname><given-names>J. E.</given-names></name>
</person-group> (<year>1967</year>). <article-title>Phase-locked response to low-frequency tones in single auditory nerve fibers of the squirrel monkey</article-title>. <source>Journal of Neurophysiology</source>, <volume>30</volume>, <fpage>769</fpage>-<lpage>793</lpage>.</citation>
</ref>
<ref id="bibr22-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simon</surname><given-names>T.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Two-dimensional Monte Carlo simulation and beyond: A comparison of several probabilistic risk assessment methods applied to a superfund site</article-title>. <source>Human and Ecological Risk Assessment: An International Journal</source>.</citation>
</ref>
<ref id="bibr23-1084713813482759">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Swanson</surname><given-names>B.</given-names></name>
</person-group> (<year>2008</year>). <source>Pitch perception with cochlear implants</source> (Unpublished doctoral thesis). <publisher-name>The University of Melbourne</publisher-name>, <publisher-loc>Australia</publisher-loc>.</citation>
</ref>
<ref id="bibr24-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Terhardt</surname><given-names>E.</given-names></name>
</person-group> (<year>1974</year>). <article-title>Pitch, consonance, and harmony</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>55</volume>, <fpage>1061</fpage>-<lpage>1069</lpage>.</citation>
</ref>
<ref id="bibr25-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wightman</surname><given-names>F. L.</given-names></name>
</person-group> (<year>1973</year>). <article-title>The pattern-transformation model of pitch</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>54</volume>, <fpage>407</fpage>-<lpage>416</lpage>.</citation>
</ref>
<ref id="bibr26-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>B. S.</given-names></name>
<name><surname>Finley</surname><given-names>C. C.</given-names></name>
<name><surname>Lawson</surname><given-names>D. T.</given-names></name>
<name><surname>Wolford</surname><given-names>R. D.</given-names></name>
<name><surname>Eddington</surname><given-names>D. K.</given-names></name>
<name><surname>Rabinowitz</surname><given-names>W. M.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Better speech recognition with cochlear implants</article-title>. <source>Nature</source>, <volume>352</volume>, <fpage>236</fpage>-<lpage>238</lpage>.</citation>
</ref>
<ref id="bibr27-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>B. S.</given-names></name>
<name><surname>Lawson</surname><given-names>D. T.</given-names></name>
<name><surname>Zerbi</surname><given-names>M.</given-names></name>
<name><surname>Finley</surname><given-names>C. C.</given-names></name>
<name><surname>Wolford</surname><given-names>R. D.</given-names></name>
</person-group> (<year>1995</year>). <article-title>New processing strategies in cochlear implantation</article-title>. <source>American Journal of Otolaryngology</source>, <volume>16</volume>, <fpage>669</fpage>-<lpage>675</lpage>.</citation>
</ref>
<ref id="bibr28-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Won</surname><given-names>J. H.</given-names></name>
<name><surname>Drennan</surname><given-names>W. R.</given-names></name>
<name><surname>Nie</surname><given-names>K.</given-names></name>
<name><surname>Jameyson</surname><given-names>E. M.</given-names></name>
<name><surname>Rubinstein</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Acoustic temporal modulation detection and speech perception in cochlear implant listeners</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>130</volume>, <fpage>376</fpage>-<lpage>388</lpage>.</citation>
</ref>
<ref id="bibr29-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Won</surname><given-names>J. H.</given-names></name>
<name><surname>Drennan</surname><given-names>W. R.</given-names></name>
<name><surname>Rubinstein</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Spectral-ripple resolution correlates with speech reception in noise in cochlear implant users</article-title>. <source>Journal of the Association for Research in Otolaryngology</source>, <volume>8</volume>, <fpage>384</fpage>-<lpage>392</lpage>.</citation>
</ref>
<ref id="bibr30-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Won</surname><given-names>J. H.</given-names></name>
<name><surname>Jones</surname><given-names>G. L.</given-names></name>
<name><surname>Drennan</surname><given-names>W. R.</given-names></name>
<name><surname>Jameyson</surname><given-names>E. M.</given-names></name>
<name><surname>Rubinstein</surname><given-names>J. T.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Evidence of across-channel processing for spectral-ripple discrimination in cochlear implant listeners</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>130</volume>, <fpage>2088</fpage>-<lpage>2097</lpage>.</citation>
</ref>
<ref id="bibr31-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yost</surname><given-names>W. A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Iterated rippled noise discrimination at long durations</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>126</volume>, <fpage>1336</fpage>-<lpage>1341</lpage>.</citation>
</ref>
<ref id="bibr32-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yost</surname><given-names>W. A.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Pitch of iterated rippled noise</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>100</volume>, <fpage>511</fpage>-<lpage>518</lpage>.</citation>
</ref>
<ref id="bibr33-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yost</surname><given-names>W. A.</given-names></name>
<name><surname>Patterson</surname><given-names>R.</given-names></name>
<name><surname>Sheft</surname><given-names>S.</given-names></name>
</person-group> (<year>1996</year>). <article-title>A time domain description for the pitch strength of iterated rippled noise</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>99</volume>, <fpage>1066</fpage>-<lpage>1078</lpage>.</citation>
</ref>
<ref id="bibr34-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yost</surname><given-names>W. A.</given-names></name>
<name><surname>Patterson</surname><given-names>R.</given-names></name>
<name><surname>Sheft</surname><given-names>S.</given-names></name>
</person-group> (<year>1998</year>). <article-title>The role of the envelope in processing iterated rippled noise</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>104</volume>, <fpage>2349</fpage>-<lpage>2361</lpage>.</citation>
</ref>
<ref id="bibr35-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zeng</surname><given-names>F. G.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Temporal pitch in electric hearing</article-title>. <source>Hearing Research</source>, <volume>174</volume>, <fpage>101</fpage>-<lpage>106</lpage>.</citation>
</ref>
<ref id="bibr36-1084713813482759">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zeng</surname><given-names>F. G.</given-names></name>
<name><surname>Galvin</surname><given-names>J. J.</given-names></name>
</person-group>(<year>1999</year>). <article-title>Amplitude mapping and phoneme recognition in cochlear implant listeners</article-title>. <source>Ear and Hearing</source>, <volume>20</volume>, <fpage>60</fpage>-<lpage>74</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>