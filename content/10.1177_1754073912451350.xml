<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EMR</journal-id>
<journal-id journal-id-type="hwp">spemr</journal-id>
<journal-title>Emotion Review</journal-title>
<issn pub-type="ppub">1754-0739</issn>
<issn pub-type="epub">1754-0747</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1754073912451350</article-id>
<article-id pub-id-type="publisher-id">10.1177_1754073912451350</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Special Section: Facial Expressions</subject></subj-group></article-categories>
<title-group>
<article-title>Categorical Perception for Emotional Faces</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Fugate</surname><given-names>Jennifer M. B.</given-names></name>
<aff id="aff1-1754073912451350">Department of Psychology, Northeastern University, USA</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-1754073912451350">Jennifer M. B. Fugate, Northeastern University, Department of Psychology, 340 Huntington Avenue, Boston, MA 02115, USA. Email: <email>fugate.jennifer@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>5</volume>
<issue>1</issue>
<fpage>84</fpage>
<lpage>89</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">ISRE and SAGE</copyright-holder>
</permissions>
<abstract>
<p>Categorical perception (CP) refers to how similar things look different depending on whether they are classified as the same category. Many studies demonstrate that adult humans show CP for human emotional faces. It is widely debated whether the effect can be accounted for solely by perceptual differences (structural differences among emotional faces) or whether additional perceiver-based conceptual knowledge is required. In this review, I discuss the phenomenon of CP and key studies showing CP for emotional faces. I then discuss a new model of emotion which highlights how perceptual and conceptual knowledge interact to explain how people see discrete emotions in others’ faces. In doing so, I discuss how language (emotion words included in the paradigm) contribute to CP.</p>
</abstract>
<kwd-group>
<kwd>categorical perception</kwd>
<kwd>emotional faces</kwd>
<kwd>language</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Categorical perception (CP) occurs when an individual perceives a stimulus which varies continually along some dimension as one of two discrete categories. The most commonly cited and perhaps easily explained example is color. Adults do not perceive continuous changes along the visible light spectrum, but rather discrete colors (<xref ref-type="bibr" rid="bibr6-1754073912451350">Bornstein, Kessen, &amp; Weiskopf, 1976</xref>). This is not to say that adults cannot distinguish between different wavelengths, but rather that some changes are more meaningful (e.g., red, orange) than others (e.g., shades of red). As a result, continually varying stimuli are perceived as belonging to distinct categories marked by a sharp boundary (<xref ref-type="bibr" rid="bibr16-1754073912451350">Harnad, 1987</xref>). The point at which perception shifts from one category to the other is known as the categorical boundary. A defining feature of CP is enhanced performance (i.e., accuracy, reaction time, discriminability) between stimuli which span the categorical boundary compared to discrimination between stimuli which do not cross the boundary, when the stimuli are separated by the same physical distance. Such enhanced performance between stimuli belonging to different categories (e.g., “between-category” trials) compared to performance between stimuli from one category (e.g., “within-category” trials) is known as the <italic>between-category advantage</italic> (<xref ref-type="bibr" rid="bibr14-1754073912451350">Goldstone, 1994</xref>).</p>
<p>Categorical perception was first observed for speech sounds (e.g., <xref ref-type="bibr" rid="bibr20-1754073912451350">Liberman, Harris, Hoffman, &amp; Griffin, 1957</xref>), but since has been found for an array of stimuli from a variety of modalities, including for complex stimuli such as facial identity (e.g., <xref ref-type="bibr" rid="bibr1-1754073912451350">Angeli, Davidoff, &amp; Valentine, 2008</xref>; <xref ref-type="bibr" rid="bibr5-1754073912451350">Beale &amp; Keil, 1995</xref>; <xref ref-type="bibr" rid="bibr19-1754073912451350">Kikutani, Roberson, &amp; Hanley, 2008</xref>; <xref ref-type="bibr" rid="bibr33-1754073912451350">Stevenage, 1998</xref>; <xref ref-type="bibr" rid="bibr35-1754073912451350">Viviani, Binda, &amp; Borsato, 2007</xref>) and facial expression (e.g., <xref ref-type="bibr" rid="bibr7-1754073912451350">Calder, Young, Perrett, Etcoff, &amp; Rowland, 1996</xref>; <xref ref-type="bibr" rid="bibr11-1754073912451350">Etcoff &amp; Magee, 1992</xref>; <xref ref-type="bibr" rid="bibr30-1754073912451350">Roberson &amp; Davidoff, 2000</xref>; <xref ref-type="bibr" rid="bibr37-1754073912451350">Young et al., 1997</xref>). <xref ref-type="fig" rid="fig1-1754073912451350">Figure 1</xref> displays isometrically morphed (blended) emotional faces. Rather than seeing individual variations among the faces, normal participants perceive faces up to a certain point as one emotion, and thereafter as a second emotion.</p>
<fig id="fig1-1754073912451350" position="float">
<label>Figure 1.</label>
<caption>
<p>Morphs from anger to fear created at 10% intervals. Participants who perceive these faces in a categorical fashion identify morphs in two discrete groups with consistency. Participants typically identify morphs 1–5 as angry and morphs 6–10 as fearful (given the two emotion words). Given such identification, the categorical boundary would be between morphs 5 and 6</p>
</caption>
<graphic xlink:href="10.1177_1754073912451350-fig1.tif"/></fig>
<sec id="section1-1754073912451350">
<title>Categorical Perception—The Measurement</title>
<p>Categorical perception is traditionally tested with two experimental paradigms, the second of which is dependent upon the results of the first paradigm. The first paradigm, <italic>identification</italic> (sometimes also called <italic>classification</italic>), establishes the location of the categorical boundary, whereas the second, <italic>discrimination</italic>, tests for the <italic>between-category advantage.</italic> The identification task is performed after the discrimination task to prevent the explicit use of category anchors (e.g., words which label the two categories; e.g., angry and sad). In the traditional identification task, a perceiver is presented with an array of stimuli that either exist naturally (e.g., color) or can be created to vary by using computerized “morphing” software. The perceiver is asked to identify each stimulus as one of the two words. If participants show CP, then they should identify all stimuli containing some level of content (up to some measurable point) as belonging to one category and all other stimuli containing more than this level of content as belonging to the other category. That is, they should show discrete sorting of stimuli into groups. When participants’ identifications of stimuli as belonging to one category are plotted against the incrementally changing stimuli, they should assume a sigmoid shape in which the categorical boundary can be inferred from the slope of line tangent to the steepest portion of the curve (see <xref ref-type="bibr" rid="bibr24-1754073912451350">McKone, Martini, &amp; Nakayama, 2001</xref>).</p>
<p>Any time a stimulus is identified as belonging to one category or another, one may get discrete identification of stimuli into groups. Therefore the presence of nonlinear identifications by itself is not sufficient for CP. Rather, CP also requires using a discrimination test to assess the <italic>between-category advantage</italic>. There exist many types of discrimination tasks whose utility and limitations have been previously discussed in depth (see <xref ref-type="bibr" rid="bibr24-1754073912451350">McKone et al., 2001</xref>, for a good review). Most commonly, a two choice AB-X task is employed. Participants see two morphs sequentially (A and B), followed by a target stimulus (X). Participants respond whether X is A or B (see <xref ref-type="fig" rid="fig2-1754073912451350">Figure 2</xref>). Critically, the physical difference between A and B in any pair must remain consistent across trials. If participants show CP, then they should also show enhanced performance for the between-category trials compared to the within-category trials (in addition to the discrete sorting in the identification task). It is also possible to mathematically determine the point at which enhanced performance should occur by calculating the derivative of the sigmoid which fits a participant’s identification data. This method represents a more precise method of determining the <italic>between-category advantage</italic> (e.g., <xref ref-type="bibr" rid="bibr12-1754073912451350">Fugate, Gouzoules, &amp; Barrett, 2010</xref>; <xref ref-type="bibr" rid="bibr24-1754073912451350">McKone et al., 2001</xref>). In this case, participants show CP if their performance on the discrimination task is significantly correlated to the derivative of the sigmoid calculated from their identification data (in addition to discrete sorting in the identification task). In practice, however, CP is often claimed when the sigmoid derivative function predicts more of the variance in a participant’s discrimination data than does a straight line.</p>
<fig id="fig2-1754073912451350" position="float">
<label>Figure 2.</label>
<caption>
<p>Example of an AB-X discrimination trial. Participants see morph A, then morph B, then are asked to indicate whether morph X is either A or B. Here X is B</p>
</caption>
<graphic xlink:href="10.1177_1754073912451350-fig2.tif"/></fig>
<p>Whether or not CP reflects shifts in the structural configuration of the stimuli themselves (e.g., how the stimuli are actually perceived) or cognitive influences (e.g., how the stimuli are classified) is highly debated (see <xref ref-type="bibr" rid="bibr14-1754073912451350">Goldstone, 1994</xref>; <xref ref-type="bibr" rid="bibr22-1754073912451350">Livingston, Andrews, &amp; Harnad, 1998</xref>). Said another way, is CP really <italic>perceptual</italic> or <italic>conceptual</italic> (see <xref ref-type="bibr" rid="bibr26-1754073912451350">Pilling, Wiggett, Ozgen, &amp; Davies, 2003</xref>)? In the following sections, I discuss studies showing CP for emotional faces and how some models of emotion make perceptual claims for the effect. As part of that discussion, I raise challenges to claiming a purely perceptual effect given the paradigm. Finally, I end with a new model of emotion which emphasizes how cognitive influences augment underlying structural differences to explain why people see emotional faces in a categorical fashion.</p>
</sec>
<sec id="section2-1754073912451350">
<title>Categorical Perception of Emotional Faces— Two Models of Emotion</title>
<p>Human perceivers see emotional faces as discrete categories. Perceivers quickly and often effortlessly look at another person’s face and make a judgment about what he or she is feeling (e.g., “he is angry” or “she is sad”). According to a basic view of emotion (<xref ref-type="bibr" rid="bibr9-1754073912451350">Ekman, 1992</xref>; <xref ref-type="bibr" rid="bibr18-1754073912451350">Izard, 1971</xref>; <xref ref-type="bibr" rid="bibr34-1754073912451350">Tomkins, 1962</xref>), faces, voices, body postures (or some combination thereof) encode discrete emotional meaning and are evolutionarily conserved among species (homologous), innate (biologically-derived), and culturally similar (universal) among humans (see <xref ref-type="bibr" rid="bibr25-1754073912451350">Ortony &amp; Turner, 1990</xref>). According to the basic view of emotion, the structural information in the face is sufficient for discrete emotion perception to occur. For example, a perceiver should be able to look at a scowling face and know with a high level of certainty that the face is angry (and not disgusted, sad, etc.), without the use of any other information (i.e., context or conceptual influences). In general, studies report categorical perception of emotional faces as evidence for a basic view of emotion. The logic is that each emotion (at least those which have been defined as “basic”) is distinct from any other basic emotion. Therefore people should not perceive intermediates of morphed emotional faces that reflect the structural differences of the stimuli.</p>
<p>According to a dimensional model of emotion, however, emotions do not belong to discrete categories, but rather reflect dimensions of some continually varying properties (e.g., arousal and valence; see <xref ref-type="bibr" rid="bibr31-1754073912451350">Russell, 1980</xref>). If this is the case, then people should be sensitive to continuous changes along a dimension as one face morphs into another. Specifically, when intermediate morphs are created from emotion categories which differ only along one dimension, people should perceive them as neutral because they pass through a zero point on the dimension (<xref ref-type="bibr" rid="bibr36-1754073912451350">Woodworth &amp; Schlosberg, 1954</xref>; see <xref ref-type="bibr" rid="bibr7-1754073912451350">Calder et al., 1996</xref>, for a diagram). On the other hand, people should perceive intermediate morphs created from emotion categories which differ along both dimensions as a new (third) emotion.</p>
<p>Several studies have tested whether CP reflects the use of category (consistent with a basic model) or dimensional information of emotion (e.g., <xref ref-type="bibr" rid="bibr13-1754073912451350">Fujimura, Matsuda, Katahira, Okada, &amp; Okanoya, 2011</xref>; <xref ref-type="bibr" rid="bibr37-1754073912451350">Young et al., 1997</xref>). For example, Young and colleagues report two studies consistent with a category approach to CP, while in two additional studies they find range effects and decreased performance for nonprototypical members (more consistent with a dimensional model) (see details in next section). <xref ref-type="bibr" rid="bibr13-1754073912451350">Fujimura and colleagues (2011)</xref> show that participants use both category and dimensional information, and suggest that a hybrid view of CP might be necessary (see also <xref ref-type="bibr" rid="bibr8-1754073912451350">Christie &amp; Friedman, 2004</xref>; <xref ref-type="bibr" rid="bibr32-1754073912451350">Russell, 2003</xref>).</p>
</sec>
<sec id="section3-1754073912451350">
<title>Studies Showing CP for Emotional Faces</title>
<p><xref ref-type="bibr" rid="bibr11-1754073912451350">Etcoff and Magee (1992)</xref> were the first to show CP for emotional faces. The authors created pairwise morphs of several emotional faces (e.g., anger, sadness, fear, disgust, happiness, surprise, and neutral as a control) based on line drawings of photos depicting one individual in the Ekman and Friesen face set (<xref ref-type="bibr" rid="bibr10-1754073912451350">1976</xref>). Only eight of the possible 20 combinations of morphed faces were tested, however, and a participant only completed the experiment on one of the eight continua. Participants pressed one of two keys labeled with an emotion word to identify the face (e.g., anger or fear). Participants’ identification data on each continuum were tested against a linear and nonlinear function. Identifications on each continuum were significantly different from that predicted by a straight line and significantly correlated with a sigmoid-like function. Participants also completed a sequential AB-X task on the continuum they identified. Between-category trials were more accurately discriminated than within-category trials for six of the eight continua. Those continua containing the emotion surprise did not show a <italic>between-category advantage</italic> (e.g., surprise–happy and surprise–fear).</p>
<p>Calder and colleagues (1996) created pairwise morphs of three emotional faces (anger, fear, happiness) from photos of one individual in the <xref ref-type="bibr" rid="bibr10-1754073912451350">Ekman and Friesen (1976)</xref> face set. In a second experiment, additional identities were used to create facial morphs of the same content. No formal analyses were conducted on the participants’ identification data, but the general pattern of sorting suggested that participants were identifying morphs into two discrete categories for both experiments. Participants also completed a sequential AB-X task. Participants’ discrimination data were then correlated with their identification-derived data. For experiment 1, there was a significant correlation between the actual and predicted (identification-derived) data for the happy–sad and sad–anger continua, but not for the anger–fear continuum. For experiment 2, there was a significant correlation between participants’ actual and predicted data for the anger–fear and sad–anger continua, but not for the happy–sad continuum. The between-category advantage was also assessed based on accuracy to discriminate the between- and within-trial pairs. In both experiments, participants were more accurate overall at discriminating the between- versus within-category trials. In experiment 2, however, there was also a significant interaction with continuum, in which participants were more accurate for the between-category trials (compared to the within-category trials) for the anger–fear and the sad–anger continua than for the sad–happy continuum. In neither experiment, however, was the accuracy for the between- and within-category trials tested individually by continuum.</p>
<p>In two successive experiments (experiments 3 and 4), <xref ref-type="bibr" rid="bibr7-1754073912451350">Calder and colleagues (1996)</xref> used the same faces in experiment 1 to create continual morphs among fear, anger, and happiness. The effect was a single continuum of morphed faces from fear through happiness through anger and then back to fear. A continual array of morphs rules out anchor and range effects that can occur when participants view the endpoints of a continuum. Using a continual array of morphs also allowed the number of times each morph was seen in the discrimination experiment to be equal. Participants identified each morph as one of three emotion words (e.g., anger, sad, or fear). Participants sorted morphs into discrete categories. In experiment 3, participants also performed a sequential AB-X task. Participants’ actual data was significantly correlated with their identification-derived data across the continual morphing array. In addition, accuracy was higher in the between- versus within-trials, although the effect was less for the anger–fear continuum.</p>
<p>In experiment 4, participants also performed a same/different task (rather than an AB-X task). Same/different tasks rule out memory demands associated with AB-X tasks. Participants’ actual data were significantly correlated with their identification-derived data across the array. In addition, participants showed an overall increase in discrimination (rather than accuracy) for morphs spanning the categorical boundaries, but the effect was less for the happiness–anger “section”.</p>
<p><xref ref-type="bibr" rid="bibr37-1754073912451350">Young and colleagues (1997)</xref> created all pairwise morphs of six emotional faces (e.g., anger, fear, disgust, sadness, happiness, and surprise) from photos of one individual in the <xref ref-type="bibr" rid="bibr10-1754073912451350">Ekman and Friesen (1976)</xref> set. Experiments 1 and 2 were meant to specifically test the claims laid out by a dimensional versus a basic view of emotion (as described earlier) to see whether, given multiple emotion word choices in the identification task, participants would identify more ambiguous (intermediate) morphs as a third emotion (experiment 1) or as a neutral emotion (experiment 2). Participants showed discrete sorting patterns (no use of intermediate emotions or neutral) except in two cases. Participants identified intermediate fear–anger morphs as “surprise” and intermediate disgust–anger morphs as “neutral.” In experiment 3, a new group of participants completed a sequential AB-X discrimination task, in which A and B could be from different morphing continua. Participants were more accurate on the between- versus within-category trials, yet the results are difficult to interpret because the distance between morphs created from different endpoints inherently varies. Due to space limitations, I refer the reader to the original article in which this criticism is discussed more fully.</p>
<p>To summarize, there have been several studies using emotional faces to test for CP. The common conclusion drawn from these studies is that the structural information in the face is sufficient for the phenomenon to occur. Careful scrutiny of the data, however, suggests that the results are somewhat inconsistent, even when the same type of paradigm (AB-X) is used. In addition to the inconsistencies, there are a number of larger concerns in drawing such conclusions. First, all the stimuli were created from very caricatured, prototypical faces, for which many have noted the artificial nature (e.g., <xref ref-type="bibr" rid="bibr2-1754073912451350">Barrett, 2006a</xref>). Second, morphs created from anger, fear, surprise, and disgust faces show the least evidence for CP, consistent with the idea that emotions which share affective (i.e., arousal and valence) information do not contain sufficient structural information. Finally, and most importantly, all of these studies require that participants identify the morph as one of two (or three, in the case of a continual array) emotion words. As a result, none of these studies can rule out that participants are not using the emotion words to help anchor the categories and refine category membership. That is, emotion words included as part of the task might “fill in the gaps” of the structural information.</p>
</sec>
<sec id="section4-1754073912451350">
<title>Testing a Psychological Construction View of Emotion</title>
<p>According to a psychological constructionist view (described in more detail in this issue; see <xref ref-type="bibr" rid="bibr21-1754073912451350">Lindquist &amp; Gendron, 2013</xref>, pp. 66–71), adult humans show CP for human emotional faces because they have emotion words like “anger,” “sadness,” and “fear” which provide an internal context to constrain the continuous and highly variable array of facial movements made by people in everyday life (see <xref ref-type="bibr" rid="bibr2-1754073912451350">Barrett, 2006a</xref>, <xref ref-type="bibr" rid="bibr3-1754073912451350">2006b</xref>; <xref ref-type="bibr" rid="bibr4-1754073912451350">Barrett, Lindquist, &amp; Gendron, 2007</xref>; <xref ref-type="bibr" rid="bibr12-1754073912451350">Fugate et al., 2010</xref>). Whereas a basic view of emotion requires that CP arises solely from the structural information in the face, a psychological constructionist says that CP occurs when people use words which help <italic>impose</italic> structural specificity. In this view, people need not be aware of using such words; in fact, people often categorize using words implicitly (<xref ref-type="bibr" rid="bibr2-1754073912451350">Barrett, 2006a</xref>, <xref ref-type="bibr" rid="bibr3-1754073912451350">2006b</xref>). A psychological constructionist view thus highlights the addition of <italic>conceptual</italic> processing in the categorical perception of emotional faces.</p>
<p>It is possible, even within a psychological constructionist view, that perceivers might show CP for faces which differ in affective (e.g., arousal and valence). In these cases, emotion words would most likely still have an effect on category membership, but they might refine the category boundaries rather than create them <italic>de novo</italic>. In this view, it would be fair to say that language can exploit what is given by nature, but it can also (and perhaps most remarkably) create categories into nature: language not only carves nature at its joints, but also carves joints into nature (see <xref ref-type="bibr" rid="bibr23-1754073912451350">Lupyan, 2006</xref>). This would be consistent with the fact that evidence for CP tends to be stronger for faces which differ in affective information (e.g., happy–sad) compared to faces which share affective information (e.g., anger–fear, anger–disgust, surprise–fear). Theoretically, then, if one could remove (or at least limit) conceptual knowledge, including the activation of emotion words, perceivers should show CP for morphed emotional faces when the two faces differ in affective information (e.g., happy, sad). In the absence of emotion words, however, perceivers should not show CP for emotional faces which share affective information (e.g., disgust, anger, fear, surprise).</p>
<p>My colleagues and I have tried to address these claims directly (<xref ref-type="bibr" rid="bibr12-1754073912451350">Fugate et al., 2010</xref>). Because all human adults have familiarity with human emotional faces (especially the caricatured ones shown in most experiments), it is impossible to address whether CP is the product of the faces themselves (the structural information) or whether additionally activated conceptual knowledge, including emotion words, affects CP. We (<xref ref-type="bibr" rid="bibr12-1754073912451350">Fugate et al., 2010</xref>) used the facial actions of an evolutionary related species whose faces are structurally quite similar to humans’, but for which people neither have familiarity nor readily assign emotion words. In experiment 1, we tested human participants who had either extensive training with nonhuman facial expressions or no familiarity with nonhuman primate facial expressions, to see whether they showed CP for four categories of chimpanzee expressions. Neither the nonhuman primate “experts” or “novices” showed the <italic>between-category advantage</italic> when all continua were analyzed together, although experts and novices both showed a <italic>between-category advantage</italic> for one shared continuum. In experiment 2, we first trained naïve human perceivers to learn categories of chimpanzee facial expressions with either labeled or unlabeled pictures. Participants only showed CP for chimpanzee faces after learning categories of expressions with labels (even though the labels were not repeated in the task—participants identified the morphs into two categories by pictures). Those participants who learned the same categories without a label did not show CP, despite being equally good at identifying the morphs into discrete categories. Thus having previously learned a label (which acted like a word in this case) was enough to drive CP.</p>
<p>Other direct evidence for the role of language in CP of emotional faces comes from a study in which participants were first placed under verbal load. In that study, participants no longer showed CP for the faces when access to language was blocked (<xref ref-type="bibr" rid="bibr30-1754073912451350">Roberson &amp; Davidoff, 2000</xref>; see also <xref ref-type="bibr" rid="bibr29-1754073912451350">Roberson, Damjanovic, &amp; Pilling, 2007</xref>).</p>
<p>The idea that language—specifically emotion words—contribute to CP of emotional faces is additionally supported by many studies that do not directly test CP, but either require participants to make discrete categorizations or category judgments. For a good detailed summary of this work, I refer the reader to the article by <xref ref-type="bibr" rid="bibr21-1754073912451350">Lindquist and Gendron (2013</xref>; see also <xref ref-type="bibr" rid="bibr4-1754073912451350">Barrett et al., 2007</xref>).</p>
</sec>
<sec id="section5-1754073912451350">
<title>Does Language Create or Augment CP for Emotional Faces?</title>
<p>The extent to which language affects CP is still largely debated; some argue for the direct role of language (e.g., language- caused effects), whereas others argue that the role is more indirect (e.g., language-mediated effects). It is possible that language exploits perceptual (i.e., structural) differences in stimuli, perhaps making fine-grained adjustments in the category boundary, or it is possible that language creates new categories. Consistent with the former idea, “category adjustment” models suggest CP arises from language, but only indirectly (<xref ref-type="bibr" rid="bibr17-1754073912451350">Huttenlocher, Hedges, &amp; Vevea, 2000</xref>; <xref ref-type="bibr" rid="bibr29-1754073912451350">Roberson et al., 2007</xref>). The idea is that naming a target at encoding activates a representation of the category prototype. As memory of the target fades over time, participants’ estimations are biased by conceptual memory (e.g., words). The result is a consistent shift in recognition toward the category center (<xref ref-type="bibr" rid="bibr29-1754073912451350">Roberson et al., 2007</xref>). The idea is that CP will only occur when there are poor (noncentral) exemplars for a category to which between-category exemplars are compared. In this case, language has an effect because poor exemplars of within-category members are likely to be named inconsistently between encoding and time of testing. Targets and distracters can easily be distinguished when they cross the category boundary because they differ at both the conceptual and perceptual levels (<xref ref-type="bibr" rid="bibr15-1754073912451350">Hanley &amp; Roberson, 2011</xref>). Indeed, when only good within-category trials (i.e., central exemplars) from multiple studies were analyzed, accuracy was at the level of between-category trials (<xref ref-type="bibr" rid="bibr15-1754073912451350">Hanley &amp; Roberson, 2011</xref>). Such a model is also consistent with the dual code model originally proposed by Pisoni and colleagues for CP of speech (<xref ref-type="bibr" rid="bibr27-1754073912451350">Pisoni &amp; Lazarus, 1974</xref>; <xref ref-type="bibr" rid="bibr28-1754073912451350">Pisoni &amp; Tash, 1974</xref>), in which the conceptual code (e.g., words) contains less information but is easier to retain than the perceptual code (e.g., structural differences among the faces), unless verbal interference occurs during encoding.</p>
</sec>
<sec id="section6-1754073912451350">
<title>Conclusion</title>
<p>It is difficult for us, as adult humans, to imagine what categorization would be like without our years of experience and our constant assessment of faces, whether into categories of gender, race, age, or emotion. The fact is, words—even when we are not aware of using them or we don’t need them to solve the task—provide us with a means to make these categorizations rapidly and easily. To this end, emotion perception studies (including CP studies) speak to how people perceive emotional faces in the context of words.</p>
<p>In order to achieve a fuller and better understanding of emotion perception, we should stop asking categorical questions (e.g., is CP <italic>perceptual</italic> or <italic>conceptual</italic>?) and start asking questions about the extent to which conceptual influences (such as language) affect perception and how early in processing such effects occur.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other">
<label>Author note:</label>
<p>This manuscript was supported by a National Research Service Award (F32MH083455) from the NIMH to Jennifer Fugate. The content also does not necessarily represent the official views of the NIH. The author would like to thank Lisa Feldman Barrett for her inspiration and discussion about this work, as well as Kristen Lindquist, Maria Gendron, and two anonymous reviewers for comments on the original manuscript.</p></fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Angeli</surname><given-names>A.</given-names></name>
<name><surname>Davidoff</surname><given-names>J.</given-names></name>
<name><surname>Valentine</surname><given-names>T.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Face familiarity, distinctiveness, and categorical perception</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>61</volume>, <fpage>690</fpage>–<lpage>707</lpage>.</citation>
</ref>
<ref id="bibr2-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barrett</surname><given-names>L. F.</given-names></name>
</person-group> (<year>2006a</year>). <article-title>Emotions as natural kinds?</article-title> <source>Perspectives on Psychological Science</source>, <volume>1</volume>, <fpage>28</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr3-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barrett</surname><given-names>L. F.</given-names></name>
</person-group> (<year>2006b</year>). <article-title>Solving the emotion paradox: Categorization and the experience of emotion</article-title>. <source>Personality and Social Psychology Review</source>, <volume>10</volume>, <fpage>20</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr4-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barrett</surname><given-names>L. F.</given-names></name>
<name><surname>Lindquist</surname><given-names>K.</given-names></name>
<name><surname>Gendron</surname><given-names>M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Language as context for the perception of emotion</article-title>. <source>Trends in Cognitive Science</source>, <volume>11</volume>, <fpage>327</fpage>–<lpage>332</lpage>.</citation>
</ref>
<ref id="bibr5-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Beale</surname><given-names>J. M.</given-names></name>
<name><surname>Keil</surname><given-names>F. C.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Categorical effects in the perception of faces</article-title>. <source>Cognition</source>, <volume>57</volume>, <fpage>217</fpage>–<lpage>239</lpage>.</citation>
</ref>
<ref id="bibr6-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bornstein</surname><given-names>M. H.</given-names></name>
<name><surname>Kessen</surname><given-names>W.</given-names></name>
<name><surname>Weiskopf</surname><given-names>S.</given-names></name>
</person-group> (<year>1976</year>). <article-title>Color vision and hue categorization in young human infants</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>2</volume>, <fpage>115</fpage>–<lpage>129</lpage>.</citation>
</ref>
<ref id="bibr7-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Calder</surname><given-names>A. J.</given-names></name>
<name><surname>Young</surname><given-names>A. W.</given-names></name>
<name><surname>Perrett</surname><given-names>D. I.</given-names></name>
<name><surname>Etcoff</surname><given-names>N. L.</given-names></name>
<name><surname>Rowland</surname><given-names>D.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Categorical perception of morphed facial expressions</article-title>. <source>Visual Cognition</source>, <volume>3</volume>, <fpage>81</fpage>–<lpage>117</lpage>.</citation>
</ref>
<ref id="bibr8-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Christie</surname><given-names>I. C.</given-names></name>
<name><surname>Friedman</surname><given-names>B. H.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Autonomic specificity of discrete emotion and dimensions of affective space: A multivariate approach</article-title>. <source>International Journal of Psychophysiology</source>, <volume>51</volume>, <fpage>143</fpage>–<lpage>153</lpage>.</citation>
</ref>
<ref id="bibr9-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Are there basic emotions?</article-title> <source>Psychological Review</source>, <volume>99</volume>, <fpage>550</fpage>–<lpage>553</lpage>.</citation>
</ref>
<ref id="bibr10-1754073912451350">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
<name><surname>Friesen</surname><given-names>W. V.</given-names></name>
</person-group> (<year>1976</year>). <source>Pictures of facial affect</source>. <publisher-loc>Palo Alto, CA</publisher-loc>: <publisher-name>Consulting Psychologists Press</publisher-name>.</citation>
</ref>
<ref id="bibr11-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Etcoff</surname><given-names>N. L.</given-names></name>
<name><surname>Magee</surname><given-names>J. J.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Categorical perception of facial expressions</article-title>. <source>Cognition</source>, <volume>44</volume>, <fpage>227</fpage>–<lpage>240</lpage>.</citation>
</ref>
<ref id="bibr12-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fugate</surname><given-names>J. M. B.</given-names></name>
<name><surname>Gouzoules</surname><given-names>H.</given-names></name>
<name><surname>Barrett</surname><given-names>L. F.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Reading chimpanzee faces: A test of the structural and conceptual hypotheses</article-title>. <source>Emotion</source>, <volume>10</volume>, <fpage>544</fpage>–<lpage>554</lpage>.</citation>
</ref>
<ref id="bibr13-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fujimura</surname><given-names>T.</given-names></name>
<name><surname>Matsuda</surname><given-names>Y.-T.</given-names></name>
<name><surname>Katahira</surname><given-names>K.</given-names></name>
<name><surname>Okada</surname><given-names>M.</given-names></name>
<name><surname>Okanoya</surname><given-names>K.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Categorical and dimensional perceptions in decoding emotional facial expressions</article-title>. <source>Cognition &amp; Emotion</source>, <volume>26</volume>, <fpage>587</fpage>–<lpage>601</lpage>.</citation>
</ref>
<ref id="bibr14-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goldstone</surname><given-names>R.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Influences of categorization on perceptual discrimination</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>123</volume>, <fpage>178</fpage>–<lpage>200</lpage>.</citation>
</ref>
<ref id="bibr15-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hanley</surname><given-names>J. R.</given-names></name>
<name><surname>Roberson</surname><given-names>D.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Categorical perception effects reflect differences in typicality on within-category trials</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>18</volume>, <fpage>355</fpage>–<lpage>363</lpage>.</citation>
</ref>
<ref id="bibr16-1754073912451350">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Harnad</surname><given-names>S.</given-names></name>
</person-group> (<year>1987</year>). <source>Categorical perception</source>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr17-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Huttenlocher</surname><given-names>J.</given-names></name>
<name><surname>Hedges</surname><given-names>L. V.</given-names></name>
<name><surname>Vevea</surname><given-names>J. L.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Why do categories affect stimulus judgment?</article-title> <source>Journal of Experimental Psychology: General</source>, <volume>129</volume>, <fpage>220</fpage>–<lpage>241</lpage>.</citation>
</ref>
<ref id="bibr18-1754073912451350">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Izard</surname><given-names>C. E.</given-names></name>
</person-group> (<year>1971</year>). <source>The face of emotion</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Appleton-Century-Crofts</publisher-name>.</citation>
</ref>
<ref id="bibr19-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kikutani</surname><given-names>M.</given-names></name>
<name><surname>Roberson</surname><given-names>D.</given-names></name>
<name><surname>Hanley</surname><given-names>J. R.</given-names></name>
</person-group> (<year>2008</year>). <article-title>What’s in a name? Categorical perception for unfamiliar faces can occur through labeling</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>15</volume>, <fpage>787</fpage>–<lpage>794</lpage>.</citation>
</ref>
<ref id="bibr20-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liberman</surname><given-names>A. M.</given-names></name>
<name><surname>Harris</surname><given-names>K. S.</given-names></name>
<name><surname>Hoffman</surname><given-names>H. S.</given-names></name>
<name><surname>Griffin</surname><given-names>B. C.</given-names></name>
</person-group> (<year>1957</year>). <article-title>The discrimination of speech sounds within and across phoneme boundaries</article-title>. <source>Journal of Experimental Psychology</source>, <volume>54</volume>, <fpage>358</fpage>–<lpage>368</lpage>.</citation>
</ref>
<ref id="bibr21-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lindquist</surname><given-names>K. A.</given-names></name>
<name><surname>Gendron</surname><given-names>M.</given-names></name>
</person-group> (<year>2013</year>). <article-title>What’s in a word? Language constructs emotion perception</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>66</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr22-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Livingston</surname><given-names>K. R.</given-names></name>
<name><surname>Andrews</surname><given-names>J. K.</given-names></name>
<name><surname>Harnad</surname><given-names>S.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Categorical perception effects induced by category learning</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>24</volume>, <fpage>732</fpage>–<lpage>753</lpage>.</citation>
</ref>
<ref id="bibr23-1754073912451350">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lupyan</surname><given-names>G.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Labels facilitate learning of novel categories</article-title>. In <person-group person-group-type="editor">
<name><surname>Cangelosi</surname><given-names>A.</given-names></name>
<name><surname>Smith</surname><given-names>A. D. M.</given-names></name>
<name><surname>Smith</surname><given-names>K. R.</given-names></name>
</person-group> (Eds.), <source>The evolution of language: Proceedings of the 6th international conference</source> (pp. <fpage>190</fpage>–<lpage>197</lpage>). <publisher-loc>Singapore</publisher-loc>: <publisher-name>World Scientific</publisher-name>.</citation>
</ref>
<ref id="bibr24-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McKone</surname><given-names>E.</given-names></name>
<name><surname>Martini</surname><given-names>P.</given-names></name>
<name><surname>Nakayama</surname><given-names>K.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Categorical perception of face identity in noise isolates configural processing</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>27</volume>, <fpage>573</fpage>–<lpage>599</lpage>.</citation>
</ref>
<ref id="bibr25-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ortony</surname><given-names>A.</given-names></name>
<name><surname>Turner</surname><given-names>T. J.</given-names></name>
</person-group> (<year>1990</year>). <article-title>What’s basic about basic emotions?</article-title> <source>Psychological Review</source>, <volume>97</volume>, <fpage>315</fpage>–<lpage>331</lpage>.</citation>
</ref>
<ref id="bibr26-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pilling</surname><given-names>M.</given-names></name>
<name><surname>Wiggett</surname><given-names>A.</given-names></name>
<name><surname>Ozgen</surname><given-names>E.</given-names></name>
<name><surname>Davies</surname><given-names>I. R. L.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Is color “categorical perception” really perceptual?</article-title> <source>Memory &amp; Cognition</source>, <volume>31</volume>, <fpage>538</fpage>–<lpage>551</lpage>.</citation>
</ref>
<ref id="bibr27-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pisoni</surname><given-names>D. B.</given-names></name>
<name><surname>Lazarus</surname><given-names>J. H.</given-names></name>
</person-group> (<year>1974</year>). <article-title>Categorical and noncategorical modes of speech perception along the voicing continuum</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>55</volume>, <fpage>328</fpage>–<lpage>333</lpage>.</citation>
</ref>
<ref id="bibr28-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pisoni</surname><given-names>D. B.</given-names></name>
<name><surname>Tash</surname><given-names>J.</given-names></name>
</person-group> (<year>1974</year>). <article-title>Reaction times to comparisons within and across phonetic categories</article-title>. <source>Perception and Psychophysics</source>, <volume>15</volume>, <fpage>285</fpage>–<lpage>290</lpage>.</citation>
</ref>
<ref id="bibr29-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roberson</surname><given-names>D.</given-names></name>
<name><surname>Damjanovic</surname><given-names>L.</given-names></name>
<name><surname>Pilling</surname><given-names>M.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Categorical perception of facial expressions: Evidence for a “category adjustment” model</article-title>. <source>Memory &amp; Cognition</source>, <volume>35</volume>, <fpage>1814</fpage>–<lpage>1829</lpage>.</citation>
</ref>
<ref id="bibr30-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roberson</surname><given-names>D.</given-names></name>
<name><surname>Davidoff</surname><given-names>J.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The categorical perception of color and facial expressions: The effect of verbal interference</article-title>. <source>Memory &amp; Cognition</source>, <volume>28</volume>, <fpage>977</fpage>–<lpage>986</lpage>.</citation>
</ref>
<ref id="bibr31-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1980</year>). <article-title>A circumplex model of affect</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>39</volume>, <fpage>1161</fpage>–<lpage>1178</lpage>.</citation>
</ref>
<ref id="bibr32-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Core affect and the psychological construction of emotion</article-title>. <source>Psychological Review</source>, <volume>110</volume>, <fpage>145</fpage>–<lpage>172</lpage>.</citation>
</ref>
<ref id="bibr33-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stevenage</surname><given-names>S. V.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Which twin are you? A demonstration of induced categorical perception of identical twin faces</article-title>. <source>British Journal of Psychology</source>, <volume>89</volume>, <fpage>39</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr34-1754073912451350">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tomkins</surname><given-names>S. S.</given-names></name>
</person-group> (<year>1962</year>). <source>Affect, imagery, consciousness. Vol. 1: The positive affects</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr35-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Viviani</surname><given-names>P.</given-names></name>
<name><surname>Binda</surname><given-names>P.</given-names></name>
<name><surname>Borsato</surname><given-names>T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Categorical perception of newly learned faces</article-title>. <source>Visual Cognition</source>, <volume>15</volume>, <fpage>420</fpage>–<lpage>467</lpage>.</citation>
</ref>
<ref id="bibr36-1754073912451350">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Woodworth</surname><given-names>R. S.</given-names></name>
<name><surname>Schlosberg</surname><given-names>H.</given-names></name>
</person-group> (<year>1954</year>). <source>Experimental psychology</source> (<edition>Revised ed</edition>.). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Henry Holt</publisher-name>.</citation>
</ref>
<ref id="bibr37-1754073912451350">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Young</surname><given-names>A. W.</given-names></name>
<name><surname>Rowland</surname><given-names>D.</given-names></name>
<name><surname>Calder</surname><given-names>A. J.</given-names></name>
<name><surname>Etcoff</surname><given-names>N. L.</given-names></name>
<name><surname>Seth</surname><given-names>A.</given-names></name>
<name><surname>Perrett</surname><given-names>D. I.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Facial expression megamix: Tests of dimensional and category accounts of emotion recognition</article-title>. <source>Cognition</source>, <volume>63</volume>, <fpage>271</fpage>–<lpage>313</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>