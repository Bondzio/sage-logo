<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MSX</journal-id>
<journal-id journal-id-type="hwp">spmsx</journal-id>
<journal-title>Musicae Scientiae</journal-title>
<issn pub-type="ppub">1029-8649</issn>
<issn pub-type="epub">XXXX-XXXX</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1029864912440778</article-id>
<article-id pub-id-type="publisher-id">10.1177_1029864912440778</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The roots of music: Emotional expression, dialogue and affect attunement in the psychogenesis of music</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Volgsten</surname><given-names>Ulrik</given-names></name>
</contrib>
<aff id="aff1-1029864912440778">Örebro University, Sweden</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1029864912440778">Ulrik Volgsten, School of Music, Theatre and Art, Örebro University, SE-701 82, Sweden. Email: <email>ulrik.volgsten@oru.se</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2012</year>
</pub-date>
<volume>16</volume>
<issue>2</issue>
<fpage>200</fpage>
<lpage>216</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">European Society for the Cognitive Sciences of Music</copyright-holder>
</permissions>
<abstract>
<p>In this paper I sketch the outlines for a comprehensive theory of the psychogenesis of music. That is, a theory of how human beings may come to hear certain sounds and combinations of sounds as music. It is a theory that takes its empirical starting point in previous and well-known research findings on fundamental human interaction and communication. As such it incorporates at its core a developmental-psychological theory about the human being’s development of a sense of self in relation to others, from infancy on, and is further supported by findings from research on infants’ behavior and reactions to music. It is argued that human interaction and communication is at the outset musical – or <italic>protomusical</italic> – and that which makes interaction and communication work is the emotive, or affective power of sound (“communicative musicality” is another term that has been used for mainly the same phenomenon). Although the empirical foundations are familiar, the comprehensive picture offered by the theory is new. The theory is structured according to a main thesis that states that music is a way of “making special” human self-development, our “sense of self”. However, for this affective-communicative theory to explain not only our reactions to protomusical sound, but also music at large (music understood in a broad universal sense), it must be extended to answer certain questions about human cognition. Therefore I start by referring to research in cognitive-psychology that explains cognition in part as a capacity to categorize phenomena according their level of detail or generality.</p>
</abstract>
<kwd-group>
<kwd>affect attunement</kwd>
<kwd>communicative musicality</kwd>
<kwd>developmental psychology of music</kwd>
<kwd>dialogism</kwd>
<kwd>making special</kwd>
<kwd>self development</kwd>
<kwd>non-verbal communication</kwd>
<kwd>sound categorization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1029864912440778">
<title>In the beginning was the voice – the mother’s voice</title>
<p>Already at four and a half to six months of age, babies seem to prefer certain phrasing in music. In one study, Mozart minuets were played with pauses inserted that either did or did not correspond to the phrase indications of the score. The infants in the test spent significantly longer time facing the loudspeaker out of which came the versions with pauses between phrases, than they did facing the loudspeaker out of which came versions that had pauses inserted in the middle of the phrases (<xref ref-type="bibr" rid="bibr35-1029864912440778">Krumhansl &amp; Jusczyk, 1990</xref>). When did the children acquire this preference for stylistically correct phrasing of music? Are we innately hard wired to prefer correct phrasing to stylistically-deviant versions? Some would not hesitate to say yes. Mozartean phrasing resembles human prosody and research shows that babies react to sound already in utero (cf. <xref ref-type="bibr" rid="bibr22-1029864912440778">Grimwade et al., 1971</xref>; <xref ref-type="bibr" rid="bibr51-1029864912440778">Olds, 1985</xref>; <xref ref-type="bibr" rid="bibr78-1029864912440778">Woodward &amp; Guidozzi, 1992</xref>; <xref ref-type="bibr" rid="bibr79-1029864912440778">Zimmer et al., 1982</xref>). Others would equally emphatically reject the claim. In either case, an explanation is needed to tell us why the infants react as they do.</p>
<p>Studying the human being after birth reveals that already within the first three days of life, a newborn baby can distinguish its mother’s voice from other female voices. Not only does it recognize its mother’s voice; it shows a clear preference for it (<xref ref-type="bibr" rid="bibr12-1029864912440778">DeCasper &amp; Fifer, 1980</xref>; <xref ref-type="bibr" rid="bibr32-1029864912440778">Karmiloff &amp; Karmiloff-Smith, 2001</xref>). At two months after birth babies react differently to different kinds of prosodic speech patterns: falling speech melodies soothe, rising melodies attract attention, bell-shaped and falling melodies maintain attention, while bell-shaped and unilevel voice melodies discourage ongoing behavior. The effects are similar both in American English and Mandarin Chinese (<xref ref-type="bibr" rid="bibr53-1029864912440778">Papousek et al., 1991</xref>). It has been suggested that the capacity to recognize the mother’s voice among other female voices serves “to prime the newborn to respond preferentially to its mother and . . . provide important feedback to the mother who is looking for signs of recognition” (<xref ref-type="bibr" rid="bibr24-1029864912440778">Hepper et al., 1993</xref>) and the recognition of one’s mother’s speech melodies has survival value (for a wider social significance, see <xref ref-type="bibr" rid="bibr10-1029864912440778">Cordes, 2003</xref>, who found similarities between prosody in motherese and different types of socially functional songs). Without a mother (or other caretaker) to feed it, the child would starve.</p>
<p>This answers the <italic>why</italic> part of the question. An answer as to <italic>how</italic> the infant comes to prefer its mother’s voice and certain phrasing of music has been offered by Sandra Trehub and her colleagues.</p>
<p>Trehub has studied both the attention-invoking dispositions of different types of speech contours (the exaggerated way of speaking that is sometimes referred to as baby talk, or motherese) and the soothing capacity of lullabies. She suggests as an explanation that these patterns correspond to prototypical categories that our cognitive apparatus is particularly apt at recognizing. The prosodic and the melodic contours are basic categories, with similarly perceived overall shapes that make them easily encoded and remembered. Trehub further suggests that the prototypicality of categories is accounted for by Gestalt principles (such as similarity, proximity and common direction). In particular she refers to the law of good continuation. The rising and falling contours, as well as the bell-shaped contour, are said to display “good forms”, which make them particularly easy to perceive by the infant. In addition, the child will also notice deviations from such good patterns more easily than it will notice deviations from less good patterns.</p>
<p>According to Trehub, this might explain how the mother’s voice comes to be recognized by the newborn (see <xref ref-type="bibr" rid="bibr32-1029864912440778">Karmiloff &amp; Karmiloff-Smith, 2001</xref>, for detailed explanation). The idiosyncratic deviations from the prototypicality of good patterning that the mother’s speech and melodic phrasing displays captures the child’s attention, and makes it possible for the child not only to recognize the general contour properties, but also to categorize the more fine-grained details of the mother’s voice: Trehub says that
<disp-quote>
<p>It is possible that infants go beyond a contour processing strategy, encoding the precise extent of the mother’s pitch excursions or intervals. This would provide them with a basis for recognizing the mother by her unique yet familiar tunes, which may also be presented in a personalized set of rhythms. (<xref ref-type="bibr" rid="bibr65-1029864912440778">Trehub &amp; Trainor, 1990</xref>; <xref ref-type="bibr" rid="bibr66-1029864912440778">Trehub &amp; Unyk, 1991</xref>)</p>
</disp-quote></p>
<p>Trehub’s explanatory framework shows how infants’ reactions to prosodic and melodic contours to some extent are both systematic and predictable. But we may go further and ask by what biological or physiological mechanisms these systematic reaction patterns are carried out. The research I will refer to in providing an answer is particularly interesting for our discussion, since it will show that our cognitive capacity for the categorization of sound is fundamentally affective, a matter of feeling.<sup><xref ref-type="fn" rid="fn1-1029864912440778">1</xref></sup></p>
</sec>
<sec id="section2-1029864912440778">
<title>Neurophysiology of contours</title>
<p>According to René Spitz (<xref ref-type="bibr" rid="bibr57-1029864912440778">1965</xref>, p. 44), the newborn’s perception of the world is limited to the experience of “pure differences”. A newborn cannot perceive any “thing” in the world, it has not yet formed any concepts for any particular objects. Instead it experiences abstract quality-changes such as rhythm, tempo, duration (<xref ref-type="bibr" rid="bibr57-1029864912440778">Spitz, 1965</xref>), intensity, and shape (<xref ref-type="bibr" rid="bibr37-1029864912440778">Lewkowicz &amp; Turkewitz, 1980</xref>; <xref ref-type="bibr" rid="bibr43-1029864912440778">Meltzoff, 1981</xref>). These experiences of various abstract quality changes are “amodal”: instead of distinguishing between different sensory modalities they function as a “common sense”, enabling the comparison between different modalities of sensory stimulation (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>). What do these abstract quality changes consist of?</p>
<p>Neurophysiological research findings (that are too technical to summarize here; see <xref ref-type="bibr" rid="bibr19-1029864912440778">Frijda et al., 1991</xref>; <xref ref-type="bibr" rid="bibr75-1029864912440778">Wallin, 1991</xref>; <xref ref-type="bibr" rid="bibr52-1029864912440778">Panksepp &amp; Trevarthen, 2009</xref>, for emotional phenomena and their neural correlates; <xref ref-type="bibr" rid="bibr77-1029864912440778">Wittmann &amp; Pöppel, 1999/2000</xref>, for the neural basis of time perception; <xref ref-type="bibr" rid="bibr48-1029864912440778">Nagy et al., 2010</xref>; <xref ref-type="bibr" rid="bibr68-1029864912440778">Vickhoff, 2008</xref>, on mirror neurons and imitative behavior) indicate that experiences of abstract quality changes may consist of what Daniel Stern has described as “temporal pattern[s] of changes in density of neural firing”: “[n]o matter if the object [is] encountered with the eye or the touch, and perhaps even with the ear, it produce[s] the same overall pattern of activation contour” (<xref ref-type="bibr" rid="bibr61-1029864912440778">Stern, 1995</xref>, p. 84). As a result of these patterns of firing being hedonically appraised by the organism (<xref ref-type="bibr" rid="bibr5-1029864912440778">Berlyne, 1971</xref>), the phenomenological experience is <italic>affective</italic>, it is a certain kind of feeling-experience. As Stern explains,
<disp-quote>
<p>whenever a motive is enacted (whether initiated internally or externally, as in drinking water when thirsty or receiving and adjusting to bad news), there is necessarily a shift in pleasure, arousal, level of motivation or goal achievement, and so on, that accompanies the enactment. These shifts unfold in time and each describe a temporal contour. The temporal contours, although neurophysiologically separate, act in concert and seem to be subjectively experienced as one complex feeling. (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, p. 84).</p>
</disp-quote></p>
<p>Transferred to music, I suggest that the prosodic and melodic contours emitted in lullabies and motherese cause corresponding neural activation contours in the recipient listener, experienced as shifts between tension and relaxation. In other words, to hear a melodic contour is fundamentally to feel it (cf. <xref ref-type="bibr" rid="bibr56-1029864912440778">Sammler et al., 2007</xref>). The activation contours also trigger attention to their external causes due to the shift in hedonic tone that they entail, which enable subordinate categorization and identification of the individual contours.</p>
<p>I have discussed elsewhere how the affective component of cognition may explain the motivation of further categorization and conceptualization (<xref ref-type="bibr" rid="bibr69-1029864912440778">Volgsten, 1999</xref>). The question of motivation is important, since in contrast to the protomusicality of prosodic contours and the short melodic phrases of lullabies, music seems to have no natural function; music is very much a socio-cultural phenomenon (<xref ref-type="bibr" rid="bibr9-1029864912440778">Brown et al., 2001</xref>; <xref ref-type="bibr" rid="bibr73-1029864912440778">Volgsten &amp; Brown, 2006</xref>). What I want to do now, therefore, is to show by which principles these short melodic and prosodic contours may be expanded and extended to account for the complex cultural phenomenon that we call music (I intentionally speak about music in the singular here, using the term in a culturally wide and inclusive sense, cf. <xref ref-type="bibr" rid="bibr49-1029864912440778">Nettl, 1983</xref>). Thereafter I will discuss in more detail the socio-cultural functioning of music.</p>
</sec>
<sec id="section3-1029864912440778">
<title>Levels of categorization</title>
<p>Although Trehub does not use the terminology, it is possible to describe the child’s recognition of the mother’s voice in terms of “basic” and “subordinate” levels of categorization. What is the difference between these levels of categorization? And what is “categorization” in the first place? Categorization, to categorize, means simply to group distinct phenomena together as being the same (i.e., belonging to the same category). In Western music, an “authentic cadence” and a “deceptive cadence” both belong to the category of “cadence”, whereas “Search and Destroy” and “Innsbruck, ich muss dich lassen” both belong to the category of “song”. Cadence and song are different categories. Level of categorization, on the other hand, refers to the amount of detail that distinguishes one category from another. Songs are categorized at a higher and more general level (in some cases encompassing the category of cadences as a distinguishing feature). At a lower, less general and more particular level of categorization we find subordinate categories such as “psalm”, “lullaby”, “jazz standard”, and “schlager”. Further down the categorical continuum we find particular psalms, lullabies and jazz standards, as well as cadences and pitch intervals. At lower levels we have to perceive more detailed attributes to distinguish the categories, while at higher levels the categories become increasingly abstract and general (cf. <xref ref-type="bibr" rid="bibr46-1029864912440778">Mervis &amp; Crisafi, 1982</xref>; <xref ref-type="bibr" rid="bibr54-1029864912440778">Rosch &amp; Mervis,1981</xref>; <xref ref-type="bibr" rid="bibr59-1029864912440778">Starkey, 1981</xref>).</p>
<p>A somewhat similar hierarchy of categorical levels can be found in the Liberian Kpelle terminology for musical performance. For instance, the term <italic>pêle</italic> refers to certain styles or types of singing, dancing and playing, whereas <italic>wule</italic> means song (or singing), and <italic>Te-te-púu</italic> is the name of a certain song, each song being made up of man-made sounds, or voices <italic>wóo</italic>, and so on (<xref ref-type="bibr" rid="bibr63-1029864912440778">Stone, 1981</xref>).</p>
<p>The basic level is thus not at the bottom of this continuum, but rather somewhere in the middle, between the extremes of particularity and generality. The distinguishing feature of basic-level categories is that they are easily encoded and remembered, they have similar affective shapes and show high intracategorical similarity and intercategorical dissimilarity. Tellingly, they are the most easily acquired by children, some of them perhaps even innate. Subordinate categories, on the other hand, encode more detail for their differentiation, such as the mother’s “unique . . . pitch excursions” and “personalized set of rhythms”.</p>
<p>Considering Trehub’s examples, we may assume there is a more or less innate preference for the good forms of the melodic contours at the basic level. Hedonic variation triggers attention to the specific details of the mother’s voice and leads to subordinate levels of categorization, levels that can be biologically explained with reference to survival value. The capacity for subordinate discrimination and categorization of a brief melodic contour can be described as a <italic>holistic pattern-recognition</italic>. Holistic pattern-recognition means that the listener recognizes the global quality of a melodic or prosodic contour (pattern) without thereby necessarily being able to decompose and identify its constituent notes. A melodic line with a certain arrangement of notes has a particular perceptual quality, or affective tone, that does not equal the sum of its parts, whereas a different arrangement of the same constituent notes will display a different affective characteristic (cf. <xref ref-type="bibr" rid="bibr76-1029864912440778">Warren, 1993</xref>). And while the lay listener may not be capable of repeating or analyzing the melodic compound into its constituent notes, the trained listener can (<xref ref-type="bibr" rid="bibr11-1029864912440778">DeBellis, 1995</xref>; however, neither DeBellis nor Warren explains perceptual quality in terms of affective tone). Another example highlighting the difference between basic and subordinate levels of categorization is the case of an untrained music listener spontaneously tapping his or her foot to an intermediate metric level of music (the strong basic-level beats), whereas the skilled musician has no problem attending and coordinating to both higher and lower levels of pulse and rhythm (<xref ref-type="bibr" rid="bibr17-1029864912440778">Drake et al., 1997</xref>).</p>
<p>If we regard the brief melodic and prosodic contours of lullabies and motherese as basic level, many songs, melodies and compositions supersede the former’s “basicality”. Simply put, most music in most cultures is more extensive and complex than mere basic level contours. Various functional explanations may be given for this universally occurring phenomenon (i.e., music being more complex than mere basic-level contours). Such explanations may claim that music originally is a courtship device, or that music is primarily an enhancer of group cohesion (<xref ref-type="bibr" rid="bibr9-1029864912440778">Brown et al., 2001</xref>), that it serves to display socially valued resources, or the control and channelling of aggression, or that music facilitates the establishment and maintenance of social identity through rites of passage (<xref ref-type="bibr" rid="bibr15-1029864912440778">Dissanayake, 2006</xref>). The logic seems to be that, from an evolutionary perspective, “more music” makes a stronger impression and thus fulfils its function more efficiently (and that “more music” entails more elaboration and the quality of being “special”, as I will argue).</p>
</sec>
<sec id="section4-1029864912440778">
<title>Expanding the basic level repertoire of contours</title>
<p>How then, is “more music” made from the basic level building blocks of prosodic contour? An important and efficient means of extending the affectively efficient principles of the basic level is metaphorical mapping. For instance, as Michael Spitzer points out, “When we hear the figured textures of Bach’s passion as counterpoint, we are mapping from basic level categories of musical experience – the familiar realm of conventional contrapuntal technique – onto a level that is more distant from firsthand experience” (<xref ref-type="bibr" rid="bibr58-1029864912440778">Spitzer, 2004</xref>, p. 21). A particular way of making sense of performance, composition or listening is “scaled up” (or “down”) to make sense a new dimension of music. Of course, regarding counterpoint as a basic level category, as Spitzer does, already assumes a substantive metaphorical mapping from what I have defined as biologically basic categories, that is, the prosodic contours perceived already at infancy. The point, however, is that we seem to have a more or less innate capacity to metaphorically project and extend the qualities of basic level contours onto wider time spans (or spatial regions, as in the three-dimensional conceptualization of Kpelle music).</p>
<p>As Spitzer’s example shows, basic level categories are not absolute and static, but flexible and modifiable (within limits and with respect to interest). For instance it has been observed that basic level categories may differ not only between cultures (<xref ref-type="bibr" rid="bibr16-1029864912440778">Dougherty, 1981</xref>), but also between adults and their children (<xref ref-type="bibr" rid="bibr45-1029864912440778">Mervis, 1984</xref>). Although this latter research has not considered music, I think musical examples would provide us with very similar conclusions.</p>
<p>So far I may have unduly emphasized research dealing with the perception and cognition of music heard. It is therefore important to point out the interactive aspects of music (i.e., playing, singing and dancing). Music is something we do, and passive listening (apart from lullabies) is largely a derivative form of musicking, which has developed in socially stratified cultures. As mentioned already, the newborn responds to its mother, it provides feedback. Infants respond by imitating and they also have “the capacity to provoke an imitative response, thus sustaining an interaction” (<xref ref-type="bibr" rid="bibr47-1029864912440778">Nagy &amp; Molnar, 2004</xref>). In addition, most (if not all) cultures engage their children from an early age in ritual or ritualistic dance, song and play, expecting participation and response (<xref ref-type="bibr" rid="bibr67-1029864912440778">Turner, 1982</xref>). Children are equipped with a “communicative musicality”, which not only accounts for their ability to engage in musical play, but also for their ongoing interpersonal relations and social development (<xref ref-type="bibr" rid="bibr38-1029864912440778">Malloch, 1999/2000</xref>; <xref ref-type="bibr" rid="bibr39-1029864912440778">Malloch &amp; Trevarthen, 2009</xref>). Thus metaphorical mapping should be seen not only as a way of cognitively extending one’s ability to hear, but also as a way of making sense of what one is doing and of developing one’s social interactions. Likewise, basic and superordinate levels of categorization are assumed to underlie performance as much as perception (according to David <xref ref-type="bibr" rid="bibr23-1029864912440778">Hargreaves, 2011</xref>, listening to music is a creative practice; see also Harris <xref ref-type="bibr" rid="bibr4-1029864912440778">Berger, 1997</xref>, on the heavy metal drummer’s “practice of perception”).</p>
<p>However, the basic and subordinate levels do not tell the whole story about categorical levels. Equally important is the <italic>superordinate</italic> level of categorization. In a way this superordinate level of categorization is even more important than the subordinate and basic levels, since it seems to be a uniquely human capacity. The main difference between lower and higher levels of categorization, as we have already seen, concerns the degree of particularity and concreteness versus the degree of generality and abstractness. High levels are more general and abstract, whereas low levels are more particular and concrete. In consequence this means that as we ascend from the basic level to higher and more general levels of categorization, it will become increasingly difficult to group phenomena on the basis of similarly perceived affective tone (the differences become too numerous), and it will become increasingly difficult to invoke single mental images that do justice to all instantiations of the category, whereas the action patterns required for performance of the category members become increasingly varied. At the topmost end of the continuum we reach the level where affective similarity is a minimal requirement and where <italic>verbal stipulation</italic> becomes the guarantee for categorical membership. In other words, what enables the acquisition of a superordinate category is verbal language (<xref ref-type="bibr" rid="bibr3-1029864912440778">Benelli, 1988</xref>; <xref ref-type="bibr" rid="bibr25-1029864912440778">Horton &amp; Markman, 1980</xref>; <xref ref-type="bibr" rid="bibr40-1029864912440778">Markman, 1989</xref>).</p>
<p>A good example is the general term <italic>music</italic> and its many cognates in the cultures of the world (whether they function as nouns or verbs). Music is a language-dependent superordinate category, and to experience sounding phenomena as examples of such general and abstract categories as (for instance) power ballads, ragas, taqsim or ngoma requires language. It is not the case that language gives us a term for a complex perceptual category that we already have. Instead, language is the very capacity that enables us to categorize such different-sounding instances as are covered by any of the above terms (power ballad, raga, taqsim, ngoma) under a single superordinate category. The same goes for the grouping of all categories together as an instance of, say, World Music. This might seem odd, even unlikely, though less so when we get the explanation.</p>
</sec>
<sec id="section5-1029864912440778">
<title>Superordinate categorization in action</title>
<p>Consider a situation when what counts as music for some is just strange noise for others.</p>
<p>What the superordinate category can do, or rather what the verbal label referring to the superordinate category can do – “music”, say (or ngoma, or raga, or taqsim) – is that it can be used to tell the listener how to hear the encountered sounds, namely to hear them “as” music (or ngoma, or raga, or taqsim). The superordinate category can be used to tell the listener that this seemingly unmusical sound is “the same” in some aesthetically relevant aspect as that other sound which we already categorize as music (or ngoma, or raga, or taqsim). The superordinate category can thus function as a metaphor inviting us to assimilate the unfamiliar.</p>
<p>This may explain the phenomenon that John Blacking called “radical change”. Radical change in a musical culture is a phenomenon that cannot be explained in the same way as mere variation, Blacking says, since it “is the result of conscious human decisions”, involving “essentially <italic>verbal</italic> ideas” about music. Exactly how verbal ideas about music come to be necessary for change in “musical ideas” (the latter are said to “presuppose” the former), which are “nonverbal and . . . performative”, is not clear on Blacking’s account, but the notion of superordinate categorization provides an answer.</p>
<p>Any novelty must make sense to its audience to be accepted as music. As Blacking puts it, “individual Einsteins are of no significance unless their thoughts and actions can be shared by other members of society” (<xref ref-type="bibr" rid="bibr7-1029864912440778">Blacking, 1986</xref>). If a new musical idea won’t make sense it will (at best) be dismissed as “original nonsense” (<xref ref-type="bibr" rid="bibr30-1029864912440778">Kant, 1974</xref>, §46). In contrast, superordinate categorization, as I have explained above, makes it possible to subsume the radically new into one’s own preestablished cultural framework on the basis of metaphorical imagination (turning Blacking’s individual Einstein into a musical genius, as it were).</p>
<p>In addition to innovation, radical musical change may also consist in the assimilation of a foreign music (or function) into a previously established repertoire. Once superordinate categorization is applied to one’s own music it enables a decontextualization and recontextualization of the experienced sounds and their requisite activities. This amounts to a cultural self-reflexivity that enables, on the one hand, the recognition that a foreign music which sounds totally unfamiliar compared to one’s own can fulfil the same socio-cultural function, or on the other, that a foreign music regarded as similar to one’s own may nevertheless be understood as fulfilling a completely different function in its original (unfamiliar) context.</p>
<p>Superordinate category-labels do their metaphorical work by temporarily bracketing off musical sounds and the activities necessary for their production from worldly circumstances, such as social function and context. They enable the separation of the two parameters. Superordinate categorization enables us to say that two otherwise different instances of music (or musical performance) are the same. Superordinate categorization thus enables the public acceptance of radical change, either conceived of as the creative novelties and innovations that extend mere variation, or as stylistic pluralism within a culture, where style is understood as referring to functionally similar but perceptually different musics (<xref ref-type="bibr" rid="bibr70-1029864912440778">Volgsten, 2006</xref>). In short, it enables the culturally self-aware development of art.</p>
</sec>
<sec id="section6-1029864912440778">
<title>Music as “making special”</title>
<p>According to Ellen Dissanayake, art is a way of “making special” the important aspects of our everyday lives (<xref ref-type="bibr" rid="bibr14-1029864912440778">Dissanayake, 1980</xref>). I have mentioned some evolutionary important functions that music – or rather, musical sounds, protomusic – may have fulfilled, such as courtship, group cohesion or the establishment and maintenance of social identity. Music could, in line with Dissanayake’s thesis, be understood as a way of “making special” functionally efficient sound behaviour, where the “making special” means culture-specific subarticulations and superordinate extensions of a universally available basic-level repertoire of sounds. But music as a human cultural artefact involves more than this. What I suggest is that music “makes special” nothing less than the development of human identity, the dialectical articulation of an “I”, “you”, “we” and “them”. This very particular way of making the everyday special can be said to supervene on more “obvious” functions such as those already mentioned. What makes the enhancement of self-development a less “obvious” function than, say, the establishment and maintenance of social identity (through rites of passage), is that the former goes unnoticed and that it is hardly ever intentional. This does not mean that it would be less important in any sense; rather the contrary.</p>
<p>However, the idea of an unintentional way of “making special”, the result of which goes unnoticed, may strike anyone as odd unless it be clear that “making special” is regarded here primarily as a function, not as a purposive action or “use” (cf. <xref ref-type="bibr" rid="bibr44-1029864912440778">Merriam, 1964</xref>). Music, as a human cultural artefact, is a result of “making special” the development of human identity, our sense of being a self in an interpersonal world. The means to this end is music’s emotional power, or rather (as we have already seen) the emotional power of sound, its affective component.</p>
<p>To support my claim I will refer to the developmental-psychological theory of Daniel Stern (to whom I have already referred), which articulates the human development of a “sense of self” in a number of interrelated and overlapping stages, or phases. I will first give a brief outline of Stern’s theory. Thereafter I will show how we, in analogy with the model proposed by Stern, develop our human capacity to perceive sounds as music. It should be kept in mind that in these trajectories (Stern’s and mine) each succeeding stage presupposes the preceding one, but it does not replace it (see also <xref ref-type="bibr" rid="bibr62-1029864912440778">Stern, 2000</xref>, xiff.). A fully developed sense of self, as well as of music, requires that all the developmental stages, or phases, act in concert.</p>
</sec>
<sec id="section7-1029864912440778">
<title>The developmental psychology of self</title>
<p>According to Stern, the qualities of sensation to which the newborn child attends, such as its mother’s voice, constitute the earliest temporally organized islands of coherence and coordination in an otherwise non-differentiated chaos (what Spitz called an experience of “pure differences”). These experiences serve as the earliest points of reference between which relationships of significance can be inferred. Most notably, the child will increasingly experience the difference between events that it may enact itself and events that are beyond the limits of its own immediate volition. The experience of being the agent of certain coherent events but not of others gives the child a first sense of what Stern calls <italic>self versus other</italic>, while the regulation of the infant’s affective state by another’s ministrations lead the child on to a second level, to a sense of <italic>self with other</italic> (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, 69ff; 100f).</p>
<p>These togetherness feelings – which are radically different from the earliest non-differentiation and symbiosis with the mother – constitute the earliest developmental phases of our personal selves and point further to the level of a <italic>subjective self</italic> (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, p. 138). At the level of a subjective self, perceived behavior begins to acquire social significance. At this level, affective contours become related to the context of purposeful interaction, whereas earlier amodal perception was merely affective. It is at this level that a sense of intentionality begins to emerge – the self having already been articulated against and with an <italic>other</italic>: now this relationship takes on a rudimentary dimension of subjective purposiveness.</p>
<p>The crucial means to this development Stern calls “affect attunement” (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, p. 138). Affect attunement is a more or less unconscious communicative behavior building on the amodal similarities between the infant’s and the parent’s respective behavior. Without necessarily being aware of the fact the parent attunes to the child’s activities by performing an analogous action that retains the amodal properties of the original action. The attuning activity performed by the parent shares with the child’s activity the underlying affective contour. Both activities are similar to the respective agents with regard to the amodal qualities of shape, rhythm and intensity (as experiments show, whenever the parent misattunes, for instance by exaggerating the intensity or showing no sense of rhythmic timing, the child reacts by becoming upset).</p>
<p>Basically this is a communication of feelings, through feelings, which becomes successively more “dialogical”. The prosodic contours of the parent’s talk to the baby has an affective impact, the contours are <italic>felt</italic> as they are heard. Likewise the baby responds with non-verbal vocalizations that are felt by the parent (and only subsequently interpreted as conveying information). This non-verbal, affective communication follows an intersubjective dialogical pattern rhythmically regulating the “calls” and “responses” (as it were) from parent and child. The dialogical pattern requires an affective attunement on the part of both. One senses the unfolding of the other’s prosodic contour and anticipates its phrasing off, at which point one’s own response may catch on (<xref ref-type="bibr" rid="bibr27-1029864912440778">Jaffe et al., 2001</xref>; <xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>).</p>
<p>Stern emphatically stresses that attunement is not a case of strict imitation (or “mirroring”), since that would direct attention to the external qualities of behavior. Rather, affect attunement “is the performance of behaviors that express the quality of feeling of a shared affect state without imitating the exact behavioral expression of the inner state” (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, p. 142). Affect attunement is more like a reciprocal variation of a mutually shared theme. It allows the growing awareness that the other is feeling something quite similar to what I feel, and that the activity is continued or interrupted for the same affective reason on both parts.</p>
<p>It is through affect attunement that we start to get a feeling for subjective selves and others. As this sense of a subjective self and a subjective other develops we become motivated to expand our grasp of affective contours in a temporally extensive and inclusive way. We sense that the ongoing activity (with its particular affective tone) is the outcome of what has happened earlier (with its particular tone), and we anticipate a continuation and perhaps even an end, a “closure” (all with their particular affective characteristics).</p>
<p>Stern speaks about “protonarrative envelopes” that add a temporally extended, narrative-like feeling shape to the perceived world, and where basic level affective contours come to function as elements in a subjectively articulated plot:
<disp-quote>
<p>The elements of plot get temporally distributed on a line of dramatic tension. And the dramatic line of tension is invariably synchronous with the temporal feeling shape. This is natural, since the motive-goal-tension is played out in terms of temporal shifts in arousal, pleasure, motivational strength, and goal attainment. In a sense, the perceived plot is superimposed or rather dispersed along the temporal feeling shape, which then acts as the line of tension to carry the narrative. (<xref ref-type="bibr" rid="bibr61-1029864912440778">Stern, 1995</xref>, p. 91)</p>
</disp-quote></p>
<p>When affective contours are experienced as linked together, they function as protonarrative envelopes, as a supportive scaffold for the distribution of perceived and successively denominated and narrated subjects, objects, actions and events. Subsequently language and narration themselves provide unifying themes that further extend the affective contour. Along with the acquisition of language, the sense of a subjective self will help to shape the child’s beliefs about its personal history and character, eventually enabling the final stage of development, at which we acquire a sense of a <italic>verbal self</italic> (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, p. 162). As Stern says, the role of language for the verbal self “is not primarily another means for individuation, nor is it primarily another means for creating togetherness”. The uniqueness of language is that it
<disp-quote>
<p>ultimately brings about the ability to narrate one’s own life story with all the potential that holds for changing how one views oneself. The making of a narrative . . . involves thinking in terms of persons who act as agents with intentions and goals that unfold in some causal sequence with a beginning, middle and an end. (<xref ref-type="bibr" rid="bibr60-1029864912440778">Stern, 1985</xref>, p. 173f)</p>
</disp-quote></p>
<p>As the verbal self develops, so does our linguistic ability to verbally specify personal characteristics (an ability sometimes referred to as “folk psychology”), the function of which is to predict and explain other people’s behavior (whereas emotion- and mood-terms are used for less predictable behavior, see <xref ref-type="bibr" rid="bibr21-1029864912440778">Griffiths, 1989</xref>). All in all, subjectivity and personality, that of others as well as our own, is not given in advance of social relations, and it is very much a question of verbal ascription of characteristics that emerge in, and as a result of, particular interactions with others. It is as much a result of one’s developing sense of self as it is a requisite for it. We do not become fully developed personal subjects until we are able to ascribe subjectivity to others. Part of this ability is language-bound. Language, to quote Daniel Dennett, establishes a self as its source:
<disp-quote>
<p>The strings or streams of narrative issue forth <italic>as if</italic> from a single source – not just in the obvious physical sense of flowing from just one mouth, or one pencil or pen, but in a more subtle sense: their effect on any audience is to encourage them to (try to) posit a unified agent whose words they are, about whom they are: in short, to posit a <italic>center of narrative gravity.</italic> (<xref ref-type="bibr" rid="bibr13-1029864912440778">Dennett, 1991</xref>, p. 418)</p>
</disp-quote></p>
</sec>
<sec id="section8-1029864912440778">
<title>A developmental psychology of music?</title>
<p>As I have claimed, music is the result of “making special” the development of our sense of self in an interpersonal world. This does not mean that music depicts or denotes the process of self-development and identity-making in some imitative or symbolic way. Rather, it is the means of sound already employed in this process that are made special, elaborated into music. Music is a way of making self-development special by means of exploiting affective qualities at the core of human self-development. We have seen the various levels of categorization at work in this process, as well as the developmental stages, or phases, of self. Let me now add the finishing notes to the score by giving some examples that show how musical phenomena relate to this self-development model. At the end, we shall also be able to see to what extent the self-developmental trajectory is <italic>necessary</italic> for our perception of music.</p>
<p>That we experience short musical phrases as cohesive gestalts depends on the same principles of basic level categorization as does the child’s preference for its mother’s voice. We can hypothesize that it is at the earliest stages of self-development – the development of our senses of <italic>self versus other</italic>, and <italic>self with other</italic> – that perception of musical phrasing begins. We saw at the outset that infants are fully capable of perceiving the melodic phrases of a Mozart minuet. But not all music in the world is as simple in phrase structure as a Mozart minuet (an experiment with Japanese music played to American infants gave negative results, see <xref ref-type="bibr" rid="bibr29-1029864912440778">Jusczyk, 2003</xref>). The point is of course that development starts with the simple and proceeds to the more complex. At the levels of <italic>self versus other</italic> and <italic>self with other</italic> the simplest musical phrases are distinguished from their affective impact, from the way they feel “in me”, as <italic>other than myself</italic>. Musical phrases are, for the first time, heard as being “out there”, as sound.</p>
<p>In contrast to simple phrasing, to perceive even the simplest melodic structure (an ABA form, for instance) as a continuous whole, rather than as phrases stringed contingently one after the other, would require the capacity for metaphorical projection mentioned earlier. The counterpart in human self-development is the protonarrative envelope, as envisioned by Stern. The “elements of plot” in the case of music would be the short melodic phrases and motives of the melody, with their own affective contours, while the protonarrative envelope is the affective contour of the melody in its entirety, whether this melody is a simple children’s song, a symphonic theme, or even a complete symphonic movement. The subordinate categorization of such envelopes enable us to differentiate and generalize different “schemas” at the basic level, sound schemas prescribing beginnings, middles and ends, which we come to expect and anticipate in our future encounters with music (<xref ref-type="bibr" rid="bibr20-1029864912440778">Gjerdingen, 1988</xref>; <xref ref-type="bibr" rid="bibr55-1029864912440778">Rosner &amp; Meyer, 1986</xref>; <xref ref-type="bibr" rid="bibr58-1029864912440778">Spitzer, 2004</xref>). Something similar to protonarrative envelopes is also, I believe, what Michel Imberty has in mind when speaking about the “macrostructure” of a musical work (<xref ref-type="bibr" rid="bibr26-1029864912440778">Imberty, 1997</xref>), and it seems to share affinities with <xref ref-type="bibr" rid="bibr36-1029864912440778">Fred Lerdahl and Ray Jackendoff’s (1983)</xref> “prolongational reduction”, according to which tension and relaxation in a well-formed tonal piece is said to occur in a hierarchy of structural levels, the topmost of which embraces the entire piece – though Lerdahl and Jackendoff’s generative theory lacks an account of the affective nature of short phrases at the “surface level” (and neither do they draw any connection to the development of our sense of self).</p>
<p>Our ability to project protonarrative envelopes develops reciprocally with our sense of a subjective self in relation to others. As affect attunement gives me a sense that my dialogical counterpart feels similarly about our common interactivity, I can project my own growing sense of intentionality and expectancy, whereas any unexpected behavior by the other (which inevitably will occur) enables me to infer other intentions and expectations than my own. This has implications also for our growing sense of music as something other than our own affective experiences (as something objectively “out there”). The developmental level enabling a sense of a subjective self is also, I further hypothesize, the level at which we come to experience music emotively, as in some sense <italic>expressing</italic> feelings (it’s still too early to speak about specific emotions). This common phenomenon – to hear music as expressions of feelings – has been variously explained with reference to our propensity to animate the world around us – as R. T. Allen says, “we first take the world to be animate and expressive and then learn to de-personify and de-animate parts of it” (<xref ref-type="bibr" rid="bibr2-1029864912440778">Allen, 1990</xref>) – or with reference to the rhetorical figure of <italic>prosopopoeia</italic>, the metaphorical figure attributing a voice or face to an inanimate phenomenon. Hearing music, Fred Everett Maus claims, is “a matter of continuous temptation” to engage in “the interpretative move from musical gesture to the unity of a persona” (<xref ref-type="bibr" rid="bibr41-1029864912440778">Maus, 1989</xref>), a move less mysterious when we consider that for most of the time, music has been experienced in a direct fashion, either performed by ourselves or in performance by another person face-to-face with us, rather than in the mass-mediated way so overly common today.</p>
<p>The final level of Stern’s developmental trajectory involves the sense of a verbal self. As we have seen, language is a means of specifying one’s self and its history and character, and so on. Likewise, verbal accounts specifying the identity, history and character of music abound in most music cultures of the world, although focus may lie at different levels (as Alan Merriam said, there is no culture that has nothing to say about its music, <xref ref-type="bibr" rid="bibr44-1029864912440778">Merriam, 1964</xref>, p. 117). For instance, as Steven Feld reports, the Kaluli speak of their music as a characteristic “lifting up over sound”, which is only possible for a song that has become “hard”. This view is directly related to their everyday environment in the forest, where sounds constantly shift figure and ground – an environment where only people that have overcome the softness of childhood and become hardened can survive (<xref ref-type="bibr" rid="bibr18-1029864912440778">Feld, 1981</xref>). Another example is the Tiv, who conceive of composition as “a quick subtraction after slow addition”. The phrase (which is a translation of a single Tiv term) reflects a zero-sum view of life and may also characterize the catching of fish, figurative speech, withdrawings from the bank, the digging of a well, and miscarriage (<xref ref-type="bibr" rid="bibr33-1029864912440778">Keil, 1979</xref>). Similarly, in the Western classical tradition, Anthony Newcomb has identified “plot archetypes” in some of the symphonies by Beethoven, Schumann and Mahler, expressing “renewed harmony to heal the wounds inflicted by mankind’s alienation from nature”, a progress from “Arcadia forward to Elysium” (<xref ref-type="bibr" rid="bibr50-1029864912440778">Newcomb, 1992</xref>).</p>
<p>Whereas these examples concern performances or works, Susan <xref ref-type="bibr" rid="bibr42-1029864912440778">McClary (1993)</xref> and Philip <xref ref-type="bibr" rid="bibr64-1029864912440778">Tagg (1979)</xref> have both analysed how extensive “plots” are built up by smaller musical phrases and units (what Tagg calls “musemes”) in both classical and popular music of Western culture. The examples also exemplify the transition in music from protonarrative to narrative “proper”, that is, when the affectively felt protonarrative envelope becomes consciously attended to as such, and analytically (i.e., verbally) specified at a component level.</p>
<p>However, it is not the narrative character of these accounts that make them language-dependent (to the extent that protonarrative envelopes develop prior to language); rather it is the abstract and general character of the concepts employed in the respective narrative accounts that require language. That two differently sounding phenomena may be categorized together as either a “lifting up over sound”, a “quick subtraction after slow addition”, or a “renewed harmony to heal the wounds” – this is what calls for a superordinate category.<sup><xref ref-type="fn" rid="fn2-1029864912440778">2</xref></sup></p>
<p>These examples also exemplify the introduction of the distinction between subject and object in our musical experiences. The verbal level is that at which we definitely separate the animate from the inanimate, when we say that music does not express emotions, at most it is “expressive of” them (<xref ref-type="bibr" rid="bibr34-1029864912440778">Kivy, 1989</xref>). The verbal level is that at which we distinguish subject from object. The sound that I sense as something other than my own subjective experience may be conceived of either as a type of action – music is something we do, a “performance” – or it may be conceived of as “that which” we perform (or hear performed). These distinctions require a sense of a verbal self, with the mastering of language that the verbal self implies, and also what we may call <italic>a verbal sense of music</italic>, enabling verbal specifications and theoretical distinctions of what we hear. Paraphrasing Dennett, whom I quoted earlier, we may say that the Western cultural custom to posit a “work” as the objective source for various similar performances of music is a result of a verbal urge to posit a center of narrative gravity – in this case the narrative can be historically traced to the renaissance composition of <italic>res facta</italic> and the “equiparation” of artists with the holy Pope, assumedly enabling artistic creation <italic>ex nihilo</italic> (see <xref ref-type="bibr" rid="bibr6-1029864912440778">Blackburn, 1987</xref>; <xref ref-type="bibr" rid="bibr31-1029864912440778">Kantorowicz, 1961</xref>; <xref ref-type="bibr" rid="bibr71-1029864912440778">Volgsten, 2012</xref>).</p>
<p>However, as Newcomb says with reference to the musical narrativity he verbally specifies in his analyses, narrativity need not be an “extramusical” matter, need not be “something external to the musical happenings themselves”; musical narrativity may rather be something that appears from the “interaction of formal paradigm, thematic character and recurrence, and plot archetype” (<xref ref-type="bibr" rid="bibr50-1029864912440778">Newcomb, 1992</xref>). As I stated earlier, the developmental levels act in concert. We presumably never hear a piece of music exclusively from the vantage point of a verbal self (with an exclusive verbal sense of music); it seems much more likely that we fluctuate between the levels, giving rise to more analytically determined experiences at times, and more affective experiences of music at other times – thus irritatingly confusing the listener types listed by a sociologist such as Theodor Adorno. Nevertheless, Adorno’s opposite point is equally true, that critical analysis “is not an external factor added to aesthetic experience”; it “is inherent in that experience” (<xref ref-type="bibr" rid="bibr1-1029864912440778">Adorno, 1989</xref>). Put differently, our musical experiences are always categorized to some extent by the discursive logosphere in which they appear. This holds, as we have seen, not only for the individual listener but for musical cultures at large (as well as for types of analysis that would not count as “critical” to Adorno).</p>
<p>In analogue to a fully developed sense of self (a state which one can perhaps at best continue to aspire to), a <italic>full</italic> sense of music – what I have called music as a human cultural artefact – would thus involve all the developmental stages pointed out. We can even say that “music as a cultural artefact” and “a full sense of music” is more than a mere analogue to a full sense of a self (with all its component stages); it is a real homologue. Music builds on many of the same affective components as our sense of self (such as prosodic countours), and our capacity to perceive sounds as music also builds on – and “makes special” – many of the same developmental principles as our sense of self. In particular I want to emphasize the role of affect attunement, of which I have so far said relatively little.</p>
</sec>
<sec id="section9-1029864912440778">
<title>Final remarks: Affect attunement and its consequences for our understanding of music</title>
<p>First, attunement is at work in any successful attending to a temporal sequence, music or other. According to Mari Riess Jones, attention to temporal sequences is primarily governed by certain biological “attending rhythms”. In order to attend to the temporal unfolding levels of a sound event, the listener has to synchronize his or her attending rhythms with those of the event. As she puts it, the listener’s “attending rhythms become phase-locked to corresponding time spans marked within the event”. This phase-locking between the listener’s internal rhythms and the various rhythmical layers of a piece of music “involves a synchronous interplay between an attender and an event in which the former comes to partially share the event’s rhythmic pattern”. In other words,
<disp-quote>
<p>the biological basis for responses to event time takes the form of attunement rhythms that selectively entrain, that shift over nested levels, and eventually are shaped by the event itself . . . In effect, the structure of a temporally coherent event can function as a natural time keeper for the attender. Instead of a clock-timed world, the attender responds to a dynamic event-timed world in which time judgments depend on an event’s characteristic timing and on how its structure confirms or disconfirms some expected course. (<xref ref-type="bibr" rid="bibr28-1029864912440778">Jones &amp; Boltz, 1989</xref>)</p>
</disp-quote></p>
<p>Affect attunement, as described by Daniel Stern, goes beyond this ability to attune to temporal events. It involves feeling that which one attunes to (the prosodic contour, for instance), as well as maintaining a dialogical relationship to it. The dialogicity, the give and take, which Stern exemplifies with reference to childrens’ games, is what allows the participants to sense the other’s sensations through the enactment of similarly felt behavior. Attunement hereby becomes a means for articulating one’s own subjectivity in relation to another equally subjective agent. Attunement turns into affect attunement. It is important to see that subjectivity is not “objectively” there and “discovered” through the developmental process; subjectivity is intersubjectively created by the dialogically-related agents as they develop a sense of self in relation to another self. What is new in Stern’s account of this development is his articulation and stress on the role of affect attunement as the means for this self-development.</p>
<p>My aim, on the other hand, has been to highlight the role of affect and affect attunement in our experiences of music. Music, as I have suggested, ultimately builds on the same proto- musical substrate as early communication between parent and infant (of course there are also other emotion-invoking aspects in music, of the biological, personal and cultural kind). The sounds are felt, and the participants engage in a dialogue of feeling. In the infant-parent context this enables the ascription of subjective intentions to the other – as well as to oneself. When hearing music the listener likewise attunes, engages emotionally, with the sounds. And likewise intentionality is ascribed. The music is heard as meaningful, purposeful. Even the simplest music “talks” to the listener (which is why even bird song, simple or not, can be heard as music). And in the same way as language enables us verbally to narrate our identities, language enables us to determine our musical experiences, both individually and culturally. Our vehicle on this trip is our capacity for affect attunement.</p>
<p>Sounds become music only in so far as sensitive human listeners relate to the sounds, attune to them, and ascribe (more or less culturally specified) musical qualities to them. As a definition of music, this is more than a little circular; it is not until we view the issue from a developmental and psychobiological perspective that this circularity gains supportive strength, and we can start to disentangle the “spiralling” forms of music as a human cultural artefact.</p>
<p>Thus my final point. In sound there is no music until a listener <italic>adds</italic> it, appreciates it, passes it on to others, through affect attunement (the first listener may be the composer or musician, playing or imagining). The music is <italic>added</italic> to the work as the musicians follow the composer’s instructions (more or less). The music is <italic>added</italic> to the sounding work as the audiences hear what the composer and musicians intended (more or less). And, as Kant would say, we expect others to join in with our judgement.</p>
<p>Music, in other words, is social. Take away the affective attunement, the emotional investment, to music and there is no more left in sound than a Mozart effect to trigger some mice in a maze (<xref ref-type="bibr" rid="bibr8-1029864912440778">Brown &amp; Theorell, 2006</xref>). Music certainly is more amazing than that. Music is a human cultural artefact, and its communication – its potential for human communion – should not be restricted by any tendency to reify its identity conditions (<xref ref-type="bibr" rid="bibr74-1029864912440778">Volgsten &amp; Åkerberg, 2006</xref>; <xref ref-type="bibr" rid="bibr72-1029864912440778">Volgsten, forthcoming</xref>). Like <italic>I</italic> and <italic>You</italic>, music is a result of You <italic>and</italic> I. Here lie the roots of music, and all that makes music so special.</p>
</sec>
</body>
<back>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1029864912440778">
<label>1.</label>
<p>I will not make any strict theoretical distinction between my uses of the terms “affect”, “emotion” and “feeling”, but rely on the reader’s ability to infer from context what meaning is intended.</p></fn>
<fn fn-type="other" id="fn2-1029864912440778">
<label>2.</label>
<p>Likewise, the point is not that the verbal self involves the verbal narration of our selves (that is Stern’s point, with all its important implications), but rather that the verbal self admits narration with the abstract and general terms that enable superordinate categorization, such as my “self”.</p></fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Adorno</surname><given-names>T. W.</given-names></name>
</person-group> (<year>1989</year>). <source>Introduction to the Sociology of Music</source>. Trans. <person-group person-group-type="translator">
<name><surname>Ashton</surname><given-names>E. B.</given-names></name>
</person-group> <publisher-loc>New York</publisher-loc>: <publisher-name>Continuum</publisher-name>.</citation>
</ref>
<ref id="bibr2-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Allen</surname><given-names>R. T.</given-names></name>
</person-group> (<year>1990</year>). <article-title>The arousal and expression of emotion by music</article-title>. <source>British Journal of Aesthetics</source>, <volume>30</volume>(<issue>1</issue>), <fpage>57</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr3-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Benelli</surname><given-names>B.</given-names></name>
</person-group> (<year>1988</year>). <article-title>On the linguistic origin of superordinate categorization</article-title>. <source>Human Development</source>, <volume>31</volume>, <fpage>20</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr4-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Berger</surname><given-names>H. M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>The practice of perception: Multi-functionality and time in the musical experiences of a heavy metal drummer</article-title>. <source>Ethnomusicology</source>, <volume>41</volume>(<issue>3</issue>), <fpage>464</fpage>–<lpage>488</lpage>.</citation>
</ref>
<ref id="bibr5-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Berlyne</surname><given-names>D. E.</given-names></name>
</person-group> (<year>1971</year>). <source>Aesthetics and psychobiology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Appleton-Century-Crofts</publisher-name>.</citation>
</ref>
<ref id="bibr6-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Blackburn</surname><given-names>B.</given-names></name>
</person-group> (<year>1987</year>). <article-title>On compositional process in the fifteenth century</article-title>. <source>Journal of the American Musicological Society</source>, <volume>40</volume>(<issue>2</issue>), <fpage>210</fpage>–<lpage>284</lpage>.</citation>
</ref>
<ref id="bibr7-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Blacking</surname><given-names>J.</given-names></name>
</person-group> (<year>1986</year>). <article-title>Identifying processes of musical change</article-title>. <source>The World of Music</source>, <volume>28</volume>(<issue>1</issue>), <fpage>3</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr8-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Theorell</surname><given-names>T.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The social uses of background music for personal enhancement</article-title>. In <person-group person-group-type="editor">
<name><surname>Brown</surname><given-names>Steven</given-names></name>
<name><surname>Volgsten</surname><given-names>Ulrik</given-names></name>
</person-group> (Eds.), <source>Music and manipulation: On the social uses and social control of music</source>. <publisher-loc>New York &amp; Oxford</publisher-loc>: <publisher-name>Berghahn Books</publisher-name>.</citation>
</ref>
<ref id="bibr9-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Merker</surname><given-names>B.</given-names></name>
<name><surname>Wallin</surname><given-names>N. L.</given-names></name>
</person-group> (<year>2001</year>). <article-title>An introduction to evolutionary musicology</article-title>. In <person-group person-group-type="editor">
<name><surname>Wallin</surname><given-names>N. L.</given-names></name>
<name><surname>Merker</surname><given-names>B.</given-names></name>
<name><surname>Brown</surname><given-names>S.</given-names></name>
</person-group> (Eds.), <source>The origins of music</source> (pp. <fpage>3</fpage>–<lpage>24</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>The MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-1029864912440778">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Cordes</surname><given-names>Inge</given-names></name>
</person-group> (<year>2003</year>). <article-title>Melodic contours as a connecting link between primate communication and human singing</article-title>. <source>Proceedings of the 5th Triennial ESCOM Conference</source>. <comment><ext-link ext-link-type="uri" xlink:href="http://www.epos.uni-osnabrueck.de/music/books/k/klww003/pdfs/143_Cordes_Proc.pdf">http://www.epos.uni-osnabrueck.de/music/books/k/klww003/pdfs/143_Cordes_Proc.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr11-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>DeBellis</surname><given-names>M.</given-names></name>
</person-group> (<year>1995</year>). <source>Music and conceptualization</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr12-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>DeCasper</surname><given-names>A. J.</given-names></name>
<name><surname>Fifer</surname><given-names>W. P.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Of human bonding: Newborns prefer their mother’s voices</article-title>. <source>Science</source>, <volume>208</volume>, <fpage>1174</fpage>–<lpage>1176</lpage>.</citation>
</ref>
<ref id="bibr13-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dennett</surname><given-names>D. C.</given-names></name>
</person-group> (<year>1991</year>). <source>Consciousness explained</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Penguin Books</publisher-name>.</citation>
</ref>
<ref id="bibr14-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dissanayake</surname><given-names>E.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Art as a human behavior: Toward an ethological view of art</article-title>. <source>Journal of Aesthetics and Art Criticism</source>, <volume>38</volume>(<issue>4</issue>), <fpage>397</fpage>–<lpage>406</lpage>.</citation>
</ref>
<ref id="bibr15-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dissanayake</surname><given-names>E.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Ritual and ritualization: Musical means of conveying and shaping emotion in humans and other animals</article-title>. In <person-group person-group-type="editor">
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (Eds.), <source>Music and manipulation: On the social uses and social control of music</source>. <publisher-loc>New York &amp; Oxford</publisher-loc>: <publisher-name>Berghahn Books</publisher-name>.</citation>
</ref>
<ref id="bibr16-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dougherty</surname><given-names>J. W. D.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Salience and relativity in classification</article-title>. <source>Language, culture and cognition: Anthropological perspectives</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Macmillan</publisher-name>.</citation>
</ref>
<ref id="bibr17-1029864912440778">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Drake</surname><given-names>C.</given-names></name>
<name><surname>Penel</surname><given-names>A.</given-names></name>
<name><surname>Bigand</surname><given-names>E.</given-names></name>
<name><surname>Stefan</surname><given-names>L.</given-names></name>
</person-group> (<year>1997</year>). <source>Tapping in time with musical and mechanical sequences</source>. <conf-name>Proceedings from the Third Triennial ESCOM Conference</conf-name> (pp. <fpage>286</fpage>–<lpage>291</lpage>). <conf-loc>Uppsala: Department of Psychology</conf-loc>.</citation>
</ref>
<ref id="bibr18-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Feld</surname><given-names>S.</given-names></name>
</person-group> (<year>1981</year>). <article-title>‘Flow Like a Waterfall’: The metaphors of Kaluli musical theory</article-title>. <source>Yearbook for Traditional Music</source>, <volume>13</volume>, <fpage>22</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr19-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Frijda</surname><given-names>N. H.</given-names></name>
<name><surname>Mesquita</surname><given-names>B.</given-names></name>
<name><surname>Sonnemans</surname><given-names>J.</given-names></name>
<name><surname>van Goozen</surname><given-names>S.</given-names></name>
</person-group> (<year>1991</year>). <article-title>The duration of affective phenomena or emotions, sentiments and passions</article-title>. <source>International Review of Studies on Emotions</source>, <volume>1</volume>, <fpage>247</fpage>–<lpage>259</lpage>.</citation>
</ref>
<ref id="bibr20-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gjerdingen</surname><given-names>R. O.</given-names></name>
</person-group> (<year>1988</year>). <source>A classic turn of phrase: music and the psychology of convention</source>. <publisher-loc>Philadelphia</publisher-loc>: <publisher-name>University of Pennsylvania Press</publisher-name>.</citation>
</ref>
<ref id="bibr21-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Griffiths</surname><given-names>P. E.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Folk, functional and neurochemical aspects of mood</article-title>. <source>Philosophical Psychology</source>, <volume>2</volume>(<issue>1</issue>), <fpage>17</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr22-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Grimwade</surname><given-names>J. C.</given-names></name>
<name><surname>Walker</surname><given-names>D. W.</given-names></name>
<name><surname>Bartlett</surname><given-names>M.</given-names></name>
<name><surname>Gordon</surname><given-names>S.</given-names></name>
<name><surname>Wood</surname><given-names>C.</given-names></name>
</person-group> (<year>1971</year>). <article-title>Human fetal heart rate change and movement in response to sound and vibration</article-title>. <source>American Journal of Obstetrics and Gynecology</source>, <volume>109</volume>(<issue>1</issue>), <fpage>86</fpage>–<lpage>90</lpage>.</citation>
</ref>
<ref id="bibr23-1029864912440778">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Hargreaves</surname><given-names>D.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Musical beauty and imagination</article-title>. <conf-name>Paper presented at the conference “Music(s) and Human Beings II”</conf-name>. <conf-loc>Örebro University</conf-loc>, <month>September</month> <year>2010</year>.</citation>
</ref>
<ref id="bibr24-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hepper</surname><given-names>P. G.</given-names></name>
<name><surname>Shahidullah</surname><given-names>S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Newborn and fetal response to maternal voice</article-title>. <source>Journal of Reproductive and Infant Psychology</source>, <volume>11</volume>(<issue>3</issue>), <fpage>147</fpage>–<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr25-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Horton</surname><given-names>M. S.</given-names></name>
<name><surname>Markman</surname><given-names>E. M.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Developmental differences in the acquisition of basic and superordinate categories</article-title>. <source>Child Development</source>, <volume>51</volume>, <fpage>708</fpage>–<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr26-1029864912440778">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Imberty</surname><given-names>M</given-names></name>
</person-group> (<year>1997</year>). <article-title>Can one seriously speak about narrativity in music?</article-title> In <person-group person-group-type="editor">
<name><surname>Gabrielsson</surname><given-names>A.</given-names></name>
</person-group> (Ed.). <conf-name>Proceedings from the Third Triennial ESCOM Conference</conf-name> (pp. <fpage>13</fpage>–<lpage>22</lpage>). <conf-loc>Uppsala: Department of Psychology</conf-loc>.</citation>
</ref>
<ref id="bibr27-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Jaffe</surname><given-names>J.</given-names></name>
<name><surname>Beebe</surname><given-names>B.</given-names></name>
<name><surname>Feldstein</surname><given-names>S.</given-names></name>
<name><surname>Crown</surname><given-names>C.</given-names></name>
<name><surname>Jasnow</surname><given-names>M.</given-names></name>
</person-group> (<year>2001</year>). <source>Rhythms of dialogue in infancy</source>. <publisher-loc>Boston, MA, &amp; Oxford</publisher-loc>: <publisher-name>Blackwell</publisher-name>.</citation>
</ref>
<ref id="bibr28-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jones</surname><given-names>M. R.</given-names></name>
<name><surname>Boltz</surname><given-names>M.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Dynamic attending and responses to time</article-title>. <source>Psychological Review</source>, <volume>96</volume>(<issue>3</issue>), <fpage>459</fpage>–<lpage>491</lpage>.</citation>
</ref>
<ref id="bibr29-1029864912440778">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Jusczyk</surname><given-names>P. W.</given-names></name>
</person-group> (<year>2003</year>). <source>American infants’ perception of cues to grammatical units in non-native languages and music: Evidence from Polish and Japanese</source>. <comment><ext-link ext-link-type="uri" xlink:href="http://hincapie.psych.purdue.edu/Jusczyk/pdf/Polish.pdf">http://hincapie.psych.purdue.edu/Jusczyk/pdf/Polish.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr30-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kant</surname><given-names>I.</given-names></name>
</person-group> (<year>1974</year>). <source>The critique of judgement</source>. Trans. <person-group person-group-type="translator">
<name><surname>Bernard</surname><given-names>J. H.</given-names></name>
</person-group> <publisher-loc>New York</publisher-loc>: <publisher-name>Hafner Press</publisher-name>.</citation>
</ref>
<ref id="bibr31-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kantorowicz</surname><given-names>E.</given-names></name>
</person-group> (<year>1961</year>). <article-title>The sovereignty of the artist: A note on legal maxims and Renaissance theories of art</article-title>. In <person-group person-group-type="editor">
<name><surname>Meiss</surname><given-names>M.</given-names></name>
</person-group> (Ed.), <source>De artibus opuscula XL: Essays in honour of Erwin Panofsky</source> (pp. <fpage>267</fpage>–<lpage>279</lpage>). <publisher-loc>New York</publisher-loc>: <publisher-name>New York University Press</publisher-name>.</citation>
</ref>
<ref id="bibr32-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Karmiloff</surname><given-names>Kyra</given-names></name>
<name><surname>Karmiloff-Smith</surname><given-names>Annette</given-names></name>
</person-group> (<year>2001</year>). <source>Pathways to language: From fetus to adolescent</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr33-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Keil</surname><given-names>C.</given-names></name>
</person-group> (<year>1979</year>). <source>Tiv song</source>. <publisher-loc>Chicago</publisher-loc>: <publisher-name>The University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr34-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kivy</surname><given-names>P.</given-names></name>
</person-group> (<year>1989</year>). <source>Sound sentiment: An essay on the musical emotions</source>. <publisher-loc>Philadelphia</publisher-loc>: <publisher-name>Temple University Press</publisher-name>.</citation>
</ref>
<ref id="bibr35-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Krumhansl</surname><given-names>C. K.</given-names></name>
<name><surname>Jusczyk</surname><given-names>P. W.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Infants’ perception of phrase structure in music</article-title>. <source>Psychological Science</source>, <volume>1</volume>(<issue>1</issue>), <fpage>70</fpage>–<lpage>3</lpage>.</citation>
</ref>
<ref id="bibr36-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lerdahl</surname><given-names>F.</given-names></name>
<name><surname>Jackendoff</surname><given-names>R.</given-names></name>
</person-group> (<year>1983</year>). <source>A generative theory of tonal music</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>The MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr37-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lewkowicz</surname><given-names>D. J.</given-names></name>
<name><surname>Turkewitz</surname><given-names>G</given-names></name>
</person-group> (<year>1980</year>). <article-title>Cross-modal equivalence in early infancy: Audio-visual intensity matching</article-title>. <source>Developmental Psychology</source>, <volume>16</volume>, <fpage>597</fpage>–<lpage>607</lpage>.</citation>
</ref>
<ref id="bibr38-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Malloch</surname><given-names>S. N.</given-names></name>
</person-group> (<year>1999/2000</year>). <article-title>Mothers and infants and communicative musicality</article-title>. <source>Musicae Scientiae</source>, <volume>3–4</volume> [<comment>special issue</comment>], <fpage>29</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr39-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Malloch</surname><given-names>S. N.</given-names></name>
<name><surname>Trevarthen</surname><given-names>C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Musicality: Communicating the vitality and interests of life</article-title>. In <person-group person-group-type="editor">
<name><surname>Malloch</surname><given-names>S. N.</given-names></name>
<name><surname>Trevarthen</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Communicative musicality: Exploring the basis of human companionship</source> (pp. <fpage>1</fpage>–<lpage>10</lpage>). <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr40-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Markman</surname><given-names>E. D.</given-names></name>
</person-group> (<year>1989</year>). <article-title>How children constrain the possible meanings of words</article-title>. In <person-group person-group-type="editor">
<name><surname>Neisser</surname><given-names>U</given-names></name>
</person-group> (Ed.), <source>Concepts and conceptual development: Ecological and intellectual factors in categorization</source> (pp. <fpage>255</fpage>–<lpage>287</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr41-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Maus</surname><given-names>F. E.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Agency in instrumental music and song</article-title>. <source>College Music Symposium</source>, <volume>29</volume>, <fpage>31</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr42-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McClary</surname><given-names>S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Narrative agendas in ‘Absolute music’</article-title>. In <person-group person-group-type="editor">
<name><surname>Solie</surname><given-names>R. A.</given-names></name>
</person-group> (Ed.), <source>Musicology and difference: Gender and sexuality in musical scholarship</source> (pp. <fpage>326</fpage>–<lpage>344</lpage>). <publisher-loc>Berkeley</publisher-loc>: <publisher-name>University of California Press</publisher-name>.</citation>
</ref>
<ref id="bibr43-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Meltzoff</surname><given-names>A. N.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Imitation, intermodal co-ordination and representation in early infancy</article-title>. In <person-group person-group-type="editor">
<name><surname>Butterworth</surname><given-names>G</given-names></name>
</person-group> (Ed.), <source>Infancy and epistemology: An evaluation of Piaget’s theory</source> (pp. <fpage>85</fpage>–<lpage>114</lpage>). <publisher-loc>Brighton</publisher-loc>: <publisher-name>Harvester Press</publisher-name>.</citation>
</ref>
<ref id="bibr44-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Merriam</surname><given-names>A. P.</given-names></name>
</person-group> (<year>1964</year>). <source>The anthropology of music</source>. <publisher-loc>Evanston</publisher-loc>: <publisher-name>Northwestern University Press</publisher-name>.</citation>
</ref>
<ref id="bibr45-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mervis</surname><given-names>C.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Early lexical development</article-title>. In <person-group person-group-type="editor">
<name><surname>Sophian</surname><given-names>C.</given-names></name>
</person-group> (Ed.), <source>Origins of cognitive skills</source> (pp. <fpage>339</fpage>–<lpage>370</lpage>). <publisher-loc>Hillsdale</publisher-loc>: <publisher-name>Lawrence Earlbaum Associates</publisher-name>.</citation>
</ref>
<ref id="bibr46-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mervis</surname><given-names>C. B.</given-names></name>
<name><surname>Crisafi</surname><given-names>M. A.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Order of acquisition of subordinate-, basic-, and superordinate-level categories</article-title>. <source>Child Development</source>, <volume>53</volume>, <fpage>258</fpage>–<lpage>66</lpage>.</citation>
</ref>
<ref id="bibr47-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nagy</surname><given-names>E.</given-names></name>
<name><surname>Molnar</surname><given-names>P.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Homo imitans or homo provocans? Human imprinting model of neonatal imitation</article-title>. <source>Infant Behavior &amp; Development</source>, <volume>27</volume>, <fpage>54</fpage>–<lpage>63</lpage>.</citation>
</ref>
<ref id="bibr48-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nagy</surname><given-names>E.</given-names></name>
<name><surname>Liotti</surname><given-names>M.</given-names></name>
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Waiter</surname><given-names>G.</given-names></name>
<name><surname>Bromiley</surname><given-names>A.</given-names></name>
<name><surname>Trevarthen</surname><given-names>C.</given-names></name>
<name><surname>Bardos</surname><given-names>G.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The neural mechanisms of reciprocal communication</article-title>. <source>Brain Research</source>, <volume>1353</volume>, <fpage>159</fpage>–<lpage>167</lpage>.</citation>
</ref>
<ref id="bibr49-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nettl</surname><given-names>B.</given-names></name>
</person-group> (<year>1983</year>). <source>The study of ethnomusicology: Twenty-nine issues and concepts</source>. <publisher-loc>Urbana, Chicago and London</publisher-loc>: <publisher-name>University of Illinois Press</publisher-name>.</citation>
</ref>
<ref id="bibr50-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Newcomb</surname><given-names>A.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Narrative archetypes and Mahler’s Ninth Symphony</article-title>. In <person-group person-group-type="editor">
<name><surname>Scher</surname><given-names>S. P.</given-names></name>
</person-group> (Ed.), <source>Music and text: Critical inquiries</source> (pp. <fpage>118</fpage>–<lpage>136</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr51-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Olds</surname><given-names>C.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Fetal response to music</article-title>. <source>Midwives Chronicle and Nursing Notes</source>, <volume>98</volume>, <fpage>202</fpage>–<lpage>203</lpage>.</citation>
</ref>
<ref id="bibr52-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Panksepp</surname><given-names>J.</given-names></name>
<name><surname>Trevarthen</surname><given-names>C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The neuroscience of emotion in music</article-title>. In <person-group person-group-type="editor">
<name><surname>Malloch</surname><given-names>S. N.</given-names></name>
<name><surname>Trevarthen</surname><given-names>C.</given-names></name>
</person-group> (Eds.), <source>Communicative musicality: Exploring the basis of human companionship</source> (pp. <fpage>105</fpage>–<lpage>146</lpage>). <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr53-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Papousek</surname><given-names>M.</given-names></name>
<name><surname>Papousek</surname><given-names>H.</given-names></name>
<name><surname>Symmes</surname><given-names>D.</given-names></name>
</person-group> (<year>1991</year>). <article-title>The meanings of melodies in motherese in tone and stress languages</article-title>. <source>Infant Behavior and Development</source>, <volume>14</volume>, <fpage>415</fpage>–<lpage>440</lpage>.</citation>
</ref>
<ref id="bibr54-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosch</surname><given-names>E.</given-names></name>
<name><surname>Mervis</surname><given-names>C. B.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Categorization of natural objects</article-title>. <source>Annual Review of Psychology</source>, <volume>32</volume>, <fpage>89</fpage>–<lpage>115</lpage>.</citation>
</ref>
<ref id="bibr55-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rosner</surname><given-names>B. S.</given-names></name>
<name><surname>Meyer</surname><given-names>L. B.</given-names></name>
</person-group> (<year>1986</year>). <article-title>The perceptual roles of melodic process, contour and form</article-title>. <source>Music Perception</source>, <volume>4</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr56-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sammler</surname><given-names>D.</given-names></name>
<name><surname>Grigutsch</surname><given-names>M.</given-names></name>
<name><surname>Fritz</surname><given-names>T.</given-names></name>
<name><surname>Koelsch</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Music and emotion: Electrophysiological correlates of the processing of pleasant and unpleasant music</article-title>. <source>Psychophysiology</source>, <volume>44</volume>, <fpage>293</fpage>–<lpage>304</lpage>.</citation>
</ref>
<ref id="bibr57-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Spitz</surname><given-names>R.</given-names></name>
</person-group> (<year>1965</year>). <source>The first year of life</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>International Universities Press</publisher-name>.</citation>
</ref>
<ref id="bibr58-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Spitzer</surname><given-names>M.</given-names></name>
</person-group> (<year>2004</year>). <source>Metaphor and musical thought</source>. <publisher-loc>Chicago &amp; London</publisher-loc>: <publisher-name>The University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr59-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Starkey</surname><given-names>D.</given-names></name>
</person-group> (<year>1981</year>). <article-title>The origins of concept formation: Object sorting and object preference in early infancy</article-title>. <source>Child Development</source>, <volume>52</volume>, <fpage>489</fpage>–<lpage>497</lpage>.</citation>
</ref>
<ref id="bibr60-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stern</surname><given-names>D.</given-names></name>
</person-group> (<year>1985</year>). <source>The interpersonal world of the infant: A view from psychoanalysis and developmental psychology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</citation>
</ref>
<ref id="bibr61-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stern</surname><given-names>D.</given-names></name>
</person-group> (<year>1995</year>). <source>The motherhood constellation: A unified view of parent-infant psychotherapy</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</citation>
</ref>
<ref id="bibr62-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stern</surname><given-names>D.</given-names></name>
</person-group> (<year>2000</year>). <source>The interpersonal world of the infant: A view from psychoanalysis and developmental psychology</source>. <publisher-loc>First paperback edition with a new introduction by the author. New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</citation>
</ref>
<ref id="bibr63-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>R. M.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Toward a Kpelle conceptualization of musical performance</article-title>. <source>The Journal of American Folklore</source>, <volume>94</volume>(<issue>372</issue>), <fpage>188</fpage>–<lpage>206</lpage>.</citation>
</ref>
<ref id="bibr64-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tagg</surname><given-names>P.</given-names></name>
</person-group> (<year>1979</year>). <source>Kojak: 50 seconds of television music</source>. <publisher-loc>Göteborg</publisher-loc>: <publisher-name>Skrifter från musikvetenskapliga institutionen</publisher-name>.</citation>
</ref>
<ref id="bibr65-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Trehub</surname><given-names>S. E.</given-names></name>
<name><surname>Trainor</surname><given-names>L. J.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Rules for listening in infancy</article-title>. In <person-group person-group-type="editor">
<name><surname>Enns</surname><given-names>J. T.</given-names></name>
</person-group> (Ed.), <source>The development of attention: Research and theory</source> (pp. <fpage>87</fpage>–<lpage>119</lpage>). <publisher-loc>North Holland</publisher-loc>: <publisher-name>Elsevier Publishers</publisher-name>.</citation>
</ref>
<ref id="bibr66-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Trehub</surname><given-names>S. E.</given-names></name>
<name><surname>Unyk</surname><given-names>A. M.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Music prototypes in developmental perspective</article-title>. <source>Psychomusicology</source>, <volume>10</volume>, <fpage>73</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr67-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Turner</surname><given-names>Victor</given-names></name>
</person-group> (<year>1982</year>). <source>From ritual to theatre: The human seriousness of play</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Performing Arts Journal Publ. cop</publisher-name>.</citation>
</ref>
<ref id="bibr68-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vickhoff</surname><given-names>B</given-names></name>
</person-group> (<year>2008</year>). <source>A perspective theory of music perception and emotion</source>. <publisher-loc>Göteborg</publisher-loc>: <publisher-name>Skrifter från musikvetenskapliga institutionen</publisher-name>.</citation>
</ref>
<ref id="bibr69-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (<year>1999</year>). <source>Music, mind and the serious zappa: The passions of a virtual listener</source>. <publisher-loc>Stockholm</publisher-loc>: <publisher-name>Skrifter från Musikvetenskapliga institutionen</publisher-name>.</citation>
</ref>
<ref id="bibr70-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Between ideology and identity: Media, discourse and affect in the musical experience</article-title>. In <person-group person-group-type="editor">
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (Eds.), <source>Music and manipulation: On the social uses and social control of music</source> (pp. <fpage>74</fpage>–<lpage>100</lpage>). <publisher-loc>New York &amp; Oxford</publisher-loc>: <publisher-name>Berghahn Books</publisher-name>.</citation>
</ref>
<ref id="bibr71-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (<year>2012</year>). <source>Musiken, medierna och lagarna: musikverkets idéhistoria och dess betydelse för etablerandet av en idealistisk upphovsrätt</source> [<trans-source xml:lang="en">Music, media and the law: The history of the musical work and its relevance for the establishment of an idealistic copyright</trans-source>]. <publisher-loc>Stockholm</publisher-loc>: <publisher-name>Gidlunds</publisher-name>.</citation>
</ref>
<ref id="bibr72-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (<year>forthcoming</year>). <article-title>Emotions, identity and copyright control – The constitutive role of affect attunement and its implications for the ontology of music</article-title>. In <person-group person-group-type="editor">
<name><surname>Cochrane</surname><given-names>T.</given-names></name>
<name><surname>Fantini</surname><given-names>B.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (Eds.), <source>The Emotional Power of Music</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr73-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volgsten</surname><given-names>U</given-names></name>
<name><surname>Brown</surname><given-names>S.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Preface</article-title>. In <person-group person-group-type="editor">
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (Eds.), <source>Music and manipulation: On the social uses and social control of music</source> (pp. <fpage>xxii</fpage>-<lpage>xvii</lpage>). <publisher-loc>New York &amp; Oxford</publisher-loc>: <publisher-name>Berghahn Books</publisher-name>.</citation>
</ref>
<ref id="bibr74-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
<name><surname>Åkerberg</surname><given-names>Y.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Copyright, music and morals: Artistic expression and the public sphere</article-title>. In <person-group person-group-type="editor">
<name><surname>Brown</surname><given-names>S.</given-names></name>
<name><surname>Volgsten</surname><given-names>U.</given-names></name>
</person-group> (Eds.), <source>Music and manipulation: On the social uses and social control of music</source> (pp.<fpage>336</fpage>–<lpage>364</lpage>). <publisher-loc>New York &amp; Oxford</publisher-loc>: <publisher-name>Berghahn Books</publisher-name>.</citation>
</ref>
<ref id="bibr75-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wallin</surname><given-names>N. L.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Biomusicology</article-title>. <publisher-loc>Stuyvesant</publisher-loc>: <publisher-name>Pendragon Press</publisher-name>.</citation>
</ref>
<ref id="bibr76-1029864912440778">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Warren</surname><given-names>R. M.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Perception of acoustic sequences: Global integration versus temporal resolution</article-title>. In <person-group person-group-type="editor">
<name><surname>McAdams</surname><given-names>S.</given-names></name>
<name><surname>Bigand</surname><given-names>E.</given-names></name>
</person-group> (Eds.), <source>Thinking in sound: The cognitive psychology of human audition</source> (pp. <fpage>37</fpage>–<lpage>68</lpage>). <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</citation>
</ref>
<ref id="bibr77-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wittmann</surname><given-names>M.</given-names></name>
<name><surname>Pöppel</surname><given-names>E.</given-names></name>
</person-group> (<year>1999/2000</year>). <article-title>Temporal mechanisms of the brain as fundamentals of communication – with special reference to music perception and performance</article-title>. <source>Musicae Scientiae</source> [<comment>special issue</comment>], <fpage>13</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr78-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Woodward</surname><given-names>S. C.</given-names></name>
<name><surname>Guidozzi</surname><given-names>F.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Intrauterine rhythm and blues?</article-title> <source>British Journal of Obstetrics and Gynaecology</source>, <volume>99</volume>, <fpage>787</fpage>–<lpage>790</lpage>.</citation>
</ref>
<ref id="bibr79-1029864912440778">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zimmer</surname><given-names>E. Z.</given-names></name>
<name><surname>Divon</surname><given-names>M. Y.</given-names></name>
<name><surname>Vilensky</surname><given-names>A.</given-names></name>
<name><surname>Sarna</surname><given-names>Z.</given-names></name>
<name><surname>Peretz</surname><given-names>B. A.</given-names></name>
<name><surname>Paldi</surname><given-names>E.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Maternal exposure to music and fetal activity</article-title>. <source>European Journal of Obstetrics and Gynaecology and Reproductive Biology</source>, <volume>13</volume>(<issue>4</issue>), <fpage>209</fpage>–<lpage>213</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>