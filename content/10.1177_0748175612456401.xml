<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEC</journal-id>
<journal-id journal-id-type="hwp">spmec</journal-id>
<journal-title>Measurement and Evaluation in Counseling and Development</journal-title>
<issn pub-type="ppub">0748-1756</issn>
<issn pub-type="epub">1947-6302</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0748175612456401</article-id>
<article-id pub-id-type="publisher-id">10.1177_0748175612456401</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Methods Plainly Speaking</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Calculating Effect Size in Single-Case Research</article-title>
<subtitle>A Comparison of Nonoverlap Methods</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Lenz</surname><given-names>A. Stephen</given-names></name>
<xref ref-type="aff" rid="aff1-0748175612456401">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0748175612456401"><label>1</label>The University of Memphis, Memphis, TN, USA</aff>
<author-notes>
<corresp id="corresp1-0748175612456401">Alan Stephen Lenz Jr., PhD, The University of Memphis, 303 Ball Hall, Memphis, TN 38152, USA Email: <email>aslenz@memphis.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>46</volume>
<issue>1</issue>
<fpage>64</fpage>
<lpage>73</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">Association for Assessment in Counseling and Education, a division of the American Counseling Association</copyright-holder>
</permissions>
<abstract>
<p>A guide for researchers to calculate effect sizes for single-case research using three nonoverlap methods is provided. These methods are evaluated for their strengths and limitations, applied to a data set, and contrasted with one another. Criteria are presented to determine goodness of fit between nonoverlap procedures and data sets.</p>
</abstract>
<kwd-group>
<kwd>effect size</kwd>
<kwd>single-case research</kwd>
<kwd>PND</kwd>
<kwd>PEM</kwd>
<kwd>PAND</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>In a culture of accountability, demonstrating credible practices through measurable outcomes is a commonplace requirement for helping professionals. Consequently, counselors and counselor educators were charged with implementing rigorous, yet flexible approaches to assess the influence of interventions on a variety of dependent variables. Concurrently, professional groups such as the Association for Assessment in Counseling and Education began to require reporting treatment effect sizes in addition to statistical significance during the 1980s. <xref ref-type="bibr" rid="bibr22-0748175612456401">Sanderson (2003)</xref> noted that the propagation of treatments that are supported by empirical evidence has positive implications related to both the health and economic status of individual consumers. Furthermore, managed care companies are increasingly interested in doing business with helping professionals that are trained in outcome-based interventions as a strategy to contain costs while continuing to provide adequate patient care (<xref ref-type="bibr" rid="bibr22-0748175612456401">Sanderson, 2003</xref>). Therefore, counselors should become versed in varied methods, including single-case research, to evaluate their practices with clientele.</p>
<p>Recognizing the need to meet this challenge, a task force headed by Chambless and colleagues (<xref ref-type="bibr" rid="bibr2-0748175612456401">Chambless et al., 1996</xref>; <xref ref-type="bibr" rid="bibr1-0748175612456401">Chambless et al., 1998</xref>) provided scientist-practitioners a valuable guidepost by identifying and defining guidelines for evaluating the efficacy of treatment interventions and corroborating their evidentiary support. As a result, Division 12 of the American Psychological Association has endorsed between-group and single-case research designs (SCRDs) as essential for evaluating the fidelity of interventions. Although between-groups studies have been a cornerstone of empirical evaluation, the certification of SCRDs as a robust method for supporting practices with evidence provided an avenue for counselors to demonstrate their effectiveness within individual participants. After all, counselors working in community settings are unlikely to have access to control groups and large amount of individuals with identical symptom constellations to evaluate over time. The endorsement of the SCRD by Chambliss and colleagues was a foundational step toward building a knowledge base that contributes to the credibility of counseling interventions within the scientific community at large. Since the endorsement of SCRDs by Chambliss and colleagues, several scholars implored counseling professionals to implement SCRDs to promote the innovation and diversity of practices that will benefit clients and students (<xref ref-type="bibr" rid="bibr3-0748175612456401">Foster, 2010</xref>; <xref ref-type="bibr" rid="bibr9-0748175612456401">Lundervold &amp; Belwood, 2000</xref>; <xref ref-type="bibr" rid="bibr21-0748175612456401">Ray, Minton, Schottelkorb, &amp; Brown, 2010</xref>; <xref ref-type="bibr" rid="bibr27-0748175612456401">Sharpley, 2007</xref>); to date, their call to action has been only modestly answered.</p>
<p>One possible explanation may be that some counselor education programs tend to emphasize the use of large between-groups methods and correlational methods for quantitatively evaluating treatments with a lesser consideration for single-case research methodology and data analysis. Additionally, counselors often assist clientele with resolving issues associated with abstract concepts (e.g., self-esteem, depression, and anxiety) rather than concrete observable behaviors (e.g., number of times a child interrupts their teacher). Another reason for the dearth of single-case research within our profession may be the lack of quality examples for computing treatment effect available for reference within our professional journals. Regardless of the cause, many counselors have been limited in demonstrating clinical relevance and efficacy when compared with other professionals such as those practicing applied behavioral analysis and behavior modification. This article is intended to provide counselors and counselor educators with a concise and practical reference for computing and interpreting treatment <italic>effect size</italic> or the amount of practical improvement associated with treatment interventions when implementing SCRDs. First, I will introduce and explain the basic logic for three methods to quantitatively synthesize SCRD; next, each method will be illustrated and interpreted using a fabricated data set; last, guidance regarding the method selection and use will be provided. The methods included herein represent useful contemporary approaches to SCRD data analysis that compliment visual inspection and inference that scientist-practitioners can implement rather than methodological innovations. Readers requiring a review of SCRD rationale and methodology are referred to the several journal and text resources available that are relevant to counseling professionals (Foster, 2011; <xref ref-type="bibr" rid="bibr13-0748175612456401">Morgan &amp; Morgan, 2009</xref>; <xref ref-type="bibr" rid="bibr14-0748175612456401">O’Neill, McDonnell, Billingsley, &amp; Jenson, 2011</xref>; <xref ref-type="bibr" rid="bibr27-0748175612456401">Sharpley, 2007</xref>).</p>
<sec id="section1-0748175612456401">
<title>Nonoverlap Methods for Calculating Treatment Effect Size</title>
<p>Within the past decade there has been a marked expansion in strategies for systematically evaluating quantitative data in single-case research. Prior to these developments, researchers relied heavily on visual inspection of the data trends illustrated on graphical representations to determine whether meaningful change had been noted between the baseline and treatment phases. Given the mixed methods nature of SCRDs, the utilization of effect size metrics should be an adjunctive support to the visual inspection of graphical illustration of data that include analysis of changes in slope and variability of data. In many cases, peaks and valleys illustrated in graphical representations of data provide researchers an opportunity to breathe life into the results of their studies and provide a platform to analyze the strengths and weaknesses of an intervention over time. Furthermore, visual analysis provides researchers with an opportunity to consider whether the effect size yielded agrees with the overall trends of data observed during an intervention.</p>
<p>In recognition of the need for more formal approaches for synthesizing data, several researchers (<xref ref-type="bibr" rid="bibr10-0748175612456401">Ma, 2006</xref>; <xref ref-type="bibr" rid="bibr16-0748175612456401">Parker, Hagan-Burke, &amp; Vannest, 2007</xref>; <xref ref-type="bibr" rid="bibr25-0748175612456401">Scruggs &amp; Mastropieri, 2001</xref>; <xref ref-type="bibr" rid="bibr26-0748175612456401">Scruggs, Mastropieri, &amp; Casto, 1987</xref>) developed more scientific means for examining and reporting research findings that promote reliability through replication. <xref ref-type="bibr" rid="bibr15-0748175612456401">Parker and Hagan-Burke (2007)</xref> suggested that measures of effect size provide a number of advantages over visual analysis alone, including (a) an objective measure of treatment effect, (b) increased precision of measurement, (c) allowance for cross-case comparisons and meta-analyses, (d) improved interrater reliability for calculating SCRD results, and (e) enhanced efficiency for documentation purposes. Perhaps most relevant, the ability for researchers to calculate quantitative values that depict treatment efficacy also lends itself to reporting outcomes in counseling and educational settings that may assist in reporting to funding agencies and other program stakeholders. Unlike traditional tests of statistical significance, the effect size metrics implemented in SCRDs provide an estimation of practical changes between baseline and treatment phases that is content and situation specific.</p>
<p>Among the most convenient and readily computed of the SCRD effect size measures are those that take into consideration the amount of nonoverlap between data points recorded in the baseline phase and those within the treatment phase of an intervention. In addition to the aforementioned advantages of effect size measures, I submit that almost all nonoverlap methods for computing treatment effectiveness require minimal to moderate levels of investigator training, can be hand calculated, and procedures are easily completed without the use of statistical software packages. In fact, the instructional templates and examples included herein are intended to provide the support for many intermediate-level researchers to begin implementing their own SCRDs. Each of the nonoverlap methods presented here bear strengths and limitations, and it is the responsibility of researchers to select the most prudent measure for inclusion in their data analysis. Finally, each of the methods presented are distribution-free, nonparametric strategies designed to synthesize graphical representations of data obtained during within-subject SCRDs.</p>
<sec id="section2-0748175612456401">
<title>Percentage of Nonoverlapping Data</title>
<p><xref ref-type="bibr" rid="bibr26-0748175612456401">Scruggs et al. (1987)</xref> presented the Percentage of Nonoverlapping Data (PND) procedure as one of the first major alternatives to visual trend analysis alone. This metric is conceptualized as the percentage of treatment phase data that exceeds a single noteworthy point within the baseline phase. One of the prominent strengths of PND is that it can be readily calculated with a ruler and pencil or straight line if using Excel graphs. Additionally, this procedure can be implemented with smaller data sets (i.e., <italic>n</italic> &lt; 20) and has routinely correlated very well with visual analysis judgments during meta-analysis (<xref ref-type="bibr" rid="bibr18-0748175612456401">Parker, Vannest, &amp; Davis, 2011</xref>). One limitation of the PND is that the yielded effect size measure is based on only one data point in the baseline phase and is therefore vulnerable to an outlier that may promote Type 2 error. Specifically, if one of the data points in the baseline phase approaches the ceiling or floor of the score range, it may be possible for no treatment effect to be yielded despite obvious improvements depicted in treatment phase data. Additionally, because PND is designed to be used for hand calculations with graphical representations of data, analysis can become difficult with very large data sets or crowded graphs. Several applications of the PND statistic are available for review in the counseling and counselor education literature (<xref ref-type="bibr" rid="bibr6-0748175612456401">Lenz, Oliver, &amp; Nelson, 2011</xref>; <xref ref-type="bibr" rid="bibr7-0748175612456401">Lenz, Perepiczka, &amp; Balkin, 2012</xref>; <xref ref-type="bibr" rid="bibr23-0748175612456401">Schottelkorb &amp; Ray, 2009</xref>).</p>
</sec>
<sec id="section3-0748175612456401">
<title>Percentage of Data Exceeding the Median</title>
<p><xref ref-type="bibr" rid="bibr10-0748175612456401">Ma (2006)</xref> introduced the Percentage of Data Exceeding the Median (PEM) procedure to accommodate data sets in which outliers in the baseline condition may negatively affect the evaluation of an intervention. This procedure is conceptualized as the analysis of treatment phase data that is contingent on the overlap with the median data point within the baseline phase. <xref ref-type="bibr" rid="bibr10-0748175612456401">Ma (2006</xref>, <xref ref-type="bibr" rid="bibr11-0748175612456401">2009</xref>) suggested that PEM is based on the assumption that if the intervention is effective, data will be predominately on the therapeutic side of the median; if an intervention is ineffective, data points in the treatment phase will vacillate above and below the baseline median. Like PND, PEM can be calculated by hand or using Excel files with relative ease and can be reliability implemented with smaller data sets with success. Like PND, PEM has also been demonstrated as a useful tool for completing meta-analyses of SCRDs (<xref ref-type="bibr" rid="bibr11-0748175612456401">Ma, 2009</xref>; <xref ref-type="bibr" rid="bibr20-0748175612456401">Preston &amp; Carter, 2009</xref>). Some criticisms were noted that if PEM is not prudently selected for use, inflated effect sizes may promote Type 1 error. For this reason, PEM is recommended for use in instances when there is some variability over time or a significant outlier is present within the baseline data. Because this metric is relatively new, the availability of published articles for reference is not as great as that with PND; however, some examples relevant to counselors and counselor educators are available (<xref ref-type="bibr" rid="bibr5-0748175612456401">Lenz &amp; Aguilar, 2012</xref>; <xref ref-type="bibr" rid="bibr8-0748175612456401">Lenz, Speciale, &amp; Aguilar, 2012</xref>).</p>
</sec>
<sec id="section4-0748175612456401">
<title>Percentage of All Nonoverlapping Data</title>
<p><xref ref-type="bibr" rid="bibr16-0748175612456401">Parker et al. (2007)</xref> presented the Percentage of All Nonoverlapping Data (PAND) procedure to provide an alternative to techniques such as PND and PEM that have received criticism for overemphasizing the importance of a single data point within the baseline phase. Similar to PND and PEM, PAND uses a ratio based on the nonoverlap of data between phases; however, the unique feature introduced by <xref ref-type="bibr" rid="bibr16-0748175612456401">Parker et al. (2007)</xref> is the use of all the data from both phases to reach a determination of treatment efficacy. This practice is purported to yield a more robust measure of effect size in data sets including a minimum of 20 observations when compared with PND (<xref ref-type="bibr" rid="bibr16-0748175612456401">Parker et al., 2007</xref>). Additionally, by dividing the graphical data into a 2 × 2 table using the nonoverlap line, the PAND method is able to create equal marginal proportions not achieved using PND and PEM. <xref ref-type="bibr" rid="bibr16-0748175612456401">Parker et al. (2007)</xref> noted that limitations associated with PAND are the sensitivity to outliers similar to that noted with PND and inability to control for positive trends in the baseline phase as PEM does. To date, I have not seen the PAND procedure implemented in the counseling literature; however, readers are referred to <xref ref-type="bibr" rid="bibr16-0748175612456401">Parker et al. (2007</xref>, <xref ref-type="bibr" rid="bibr18-0748175612456401">2011</xref>) for examples of this data analysis application.</p>
</sec>
</sec>
<sec id="section5-0748175612456401">
<title>Interpreting Treatment Effect Size</title>
<p><xref ref-type="bibr" rid="bibr24-0748175612456401">Scruggs and Mastropieri (1998)</xref> provided a rubric for interpreting effect sizes yielded from nonoverlap data analysis procedures such as PND, PEM, and PAND. Each of the nonoverlap methods described here yields a proportion of data overlap between a baseline and treatment condition expressed in a decimal format that ranges between zero and one. When applying the rubric, higher scores represent greater treatment effects and lower scores represent less effective treatments. <xref ref-type="bibr" rid="bibr24-0748175612456401">Scruggs and Mastropieri (1998)</xref> suggested that effect sizes of .90 and greater are indicative of very effective treatments, those ranging from .70 to .89 represent moderate effectiveness, those between .50 to .69 are debatably effective, and scores less than .50 are regarded as not effective.</p>
</sec>
<sec id="section6-0748175612456401" sec-type="methods">
<title>Method</title>
<p>To facilitate the objective of this article, a brief AB data set and graph were fabricated to provide a reference for calculating each of the three overlap methods. The raw data for the baseline phase (A) are as follows: 22, 25, 23, 26, 20, 22, and 25; scores for the treatment phase (B) are as follows: 26, 25, 22, 22, 18, 21, 18, 20, 21, 18, 16, 16, 14, 14, and 12. These scores were presented on a standard AB-style graph in preparation for data analysis (see <xref ref-type="fig" rid="fig1-0748175612456401">Figure 1</xref>). For the sake of conceptualization, it will be assumed that the graphical illustrations of data in <xref ref-type="fig" rid="fig1-0748175612456401">Figure 1</xref> represent a client’s scores on an anxiety inventory in which higher scores indicate greater levels of subjective anxiety.</p>
<fig id="fig1-0748175612456401" position="float">
<label>Figure 1.</label>
<caption>
<p>Illustration of three overlap methods for calculating effect size for single-case research designs</p>
<p>Note: PND = percentage of nonoverlapping data; PEM = percentage of data exceeding the median; PAND = percentage of all nonoverlapping data.</p>
</caption>
<graphic xlink:href="10.1177_0748175612456401-fig1.tif"/></fig>
<sec id="section7-0748175612456401">
<title>Calculations of Overlap Methods</title>
<p>The fabricated data set was entered into an Excel file and a simple AB graph was generated displaying the client’s ratings of anxiety prior to and during a 15-week counseling intervention. Ratings of anxiety are depicted along the ordinate axis with baseline (B1-B7) and treatment (T1-T15) measurement intervals displayed along the abscissa. The baseline and treatment phases were distinguished using a vertical dashed line draw using the Excel shapes function. Three copies of this graph were made and placed in separate tabs labeled as PND, PEM, and PAND. Each of the three nonoverlap methods were calculated independently and by a graduate assistant who has received training and supervision with each of these methods to assure reliability of the effect sizes. <xref ref-type="table" rid="table1-0748175612456401">Table 1</xref> illustrates the procedure and outcome yielded by the application of PND, PEM, and PAND using the sample data set. <xref ref-type="fig" rid="fig1-0748175612456401">Figure 1</xref> provides a visual representation of our preparation prior to computing effect sizes. Finally, each application of the nonoverlap methods was subjected to interpretation based on the aforementioned guidelines presented by <xref ref-type="bibr" rid="bibr24-0748175612456401">Scruggs and Mastropieri (1998)</xref>.</p>
<table-wrap id="table1-0748175612456401" position="float">
<label>Table 1.</label>
<caption>
<p>Calculation Procedures for Three Overlap Methods for Calculating Effect Size for Single-Case Research Designs</p>
</caption>
<graphic alternate-form-of="table1-0748175612456401" xlink:href="10.1177_0748175612456401-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Method</th>
<th align="center">Procedure</th>
<th align="center">Application to Data Set</th>
</tr>
</thead>
<tbody>
<tr>
<td>PND</td>
<td>1. Identify intended change (increase or decrease in scores) in the data from baseline phase to treatment phase.</td>
<td>Decrease client ratings of anxiety</td>
</tr>
<tr>
<td/>
<td>2. Identify the greatest or least datum point in the baseline phase (on the therapeutic side). Select the greatest point of goal of treatment is to decrease scores and the least if goal is to increase scores.</td>
<td>20</td>
</tr>
<tr>
<td/>
<td>3. Draw data line from the datum point identified in Step 2 that extends through the treatment phase.</td>
<td/>
</tr>
<tr>
<td/>
<td>4. Count the number of data points above or below the line (on the therapeutic side) drawn in Step 3.</td>
<td>8</td>
</tr>
<tr>
<td/>
<td>5. Divide the count from Step 4 by the total number of data points in the treatment phase</td>
<td>8/15 = 0.53</td>
</tr>
<tr>
<td/>
<td>Effect size interpretation:</td>
<td>Not effective to debatable</td>
</tr>
<tr>
<td>PEM</td>
<td>1. Identify intended change.</td>
<td>Decrease ratings</td>
</tr>
<tr>
<td/>
<td>2. Identify the median datum point in the baseline phase.</td>
<td>23</td>
</tr>
<tr>
<td/>
<td>3. Draw a line through all the data in the both the baseline and treatment phases at the level identified in Step 2.</td>
<td/>
</tr>
<tr>
<td/>
<td>4. Count the number of data points above or below the line (on the therapeutic side) drawn in Step 3.</td>
<td>13</td>
</tr>
<tr>
<td/>
<td>5. Divide the count from Step 4 by the total number of data points in the treatment phase.</td>
<td>13/15 = 0.86</td>
</tr>
<tr>
<td/>
<td>Effect size interpretation:</td>
<td>Moderate to large</td>
</tr>
<tr>
<td>PAND</td>
<td>1. Identify intended change.</td>
<td>Decrease ratings</td>
</tr>
<tr>
<td/>
<td>2. Sum the total number of data points in baseline and treatment phases.</td>
<td>22</td>
</tr>
<tr>
<td/>
<td>3. Draw a line to identify the minimum number of data points needed to eliminate the overlap between the baseline and treatment conditions.</td>
<td/>
</tr>
<tr>
<td/>
<td>4. Count the number of data points removed from the treatment condition to eliminate all overlap.</td>
<td>7</td>
</tr>
<tr>
<td/>
<td>5. Subtract the total number of data points removed to eliminate overlap from the total number of data points.</td>
<td>22 − 7 = 15</td>
</tr>
<tr>
<td/>
<td>6. Divide the value from Step 5 by the total number of data points identified in Step 2.</td>
<td>15/22 = 0.68</td>
</tr>
<tr>
<td/>
<td>Effect size interpretation:</td>
<td>Debatable to moderate</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0748175612456401"><p>Note: PND = percentage of nonoverlapping data; PEM = percentage of data exceeding the median; PAND = percentage of all nonoverlapping data.</p></fn>
</table-wrap-foot></table-wrap>
</sec>
</sec>
<sec id="section8-0748175612456401" sec-type="results">
<title>Results</title>
<p>The results of the PND, PEM, and PAND analyses yielded varied determinations of treatment effectiveness when applied to the data set (see <xref ref-type="fig" rid="fig1-0748175612456401">Figure 1</xref> and <xref ref-type="table" rid="table1-0748175612456401">Table 1</xref>). The PND statistic for the Ratings of Anxiety (.53) resulted from eight points in the treatment phase recorded below the PND line in the baseline phase (20) indicating the effectiveness of the hypothetical intervention within the low end of the debatably effective range. This is curious given the overtly downward trend of the data throughout the treatment phase with a range of 14 points from the first session to the last.</p>
<p>The PEM statistic for the Ratings of Anxiety (.86) resulted from 13 points in the treatment phase exceeding the baseline median (23) indicating the effectiveness of the hypothetical intervention within the high end of the moderately effective range. The trend analysis for this graphical depiction appears to corroborate this finding given the progressive decrease in scale scores below the baseline median.</p>
<p>The PAND statistic for the Ratings of Anxiety (.68) resulted from the proportion associated with 7 points in the treatment phase being removed to eliminate all overlap between phases indicating the effectiveness of the hypothetical intervention within the high end of the debatably effective range. This metric appears to be a conservative estimate when compared with the visual trend analysis for this graphical depiction of hypothetical client’s scores.</p>
</sec>
<sec id="section9-0748175612456401" sec-type="discussion">
<title>Discussion</title>
<p>The purpose of this article is to provide a practical resource for counselors and counselor educators to reference when analyzing the findings of SCRDs. In the case of this data set, the results of the effect size calculations yielded disparate measures of treatment efficacy and demonstrate the importance of making several considerations for selecting the best procedure to use. Specifically, researchers are encouraged to deliberate about the characteristics of the distributions within the baseline phase, size of data, and the purpose of their research prior to selecting PND, PEM, or PAND to support visual analysis of graphical data.</p>
<p>In the case of the hypothetical data set, the baseline phase data included a significant outlier (20) that influenced the sensitivity making a determination of treatment efficacy. As a consequence, each of the nonoverlap methods provided different effect sizes regarding the effectiveness of the intervention. In this instance, the outlier data point decreased the sensitivity of PND and PAND to accurately yield effect sizes that were logically associated with the visual analysis of graphical data. Although there are no specific cutoff points for deciding against using PEM instead in the presence of an outlier, researchers are encouraged to evaluate the characteristics of the baseline data if the outlier were removed. <xref ref-type="fig" rid="fig1-0748175612456401">Figure 1</xref> illustrates that the gross majority (71%) of data points were clustered between 22 and 25; therefore, it may be prudent to implement PEM, which controls for this variable and reflects more accurately the baseline data median trend.</p>
<p>In addition to the characteristics of baseline data, researchers are also encouraged to evaluate the size of their data set when selecting a measure of effect size. Foremost, because nonoverlap methods are based on calculating proportions of data across phases, smaller data sets can inflate and deflate results by decreasing the size of the denominator. Additionally, researchers are encouraged to assure that the amount of observations in the baseline phase of their study adequately establishes a representative picture of the degree to which the phenomenon being studied is present. One guidepost may be to include a minimum of three to five observations in the baseline condition; however, collecting data until a relatively stable trend line is observed may be more prudent. When evaluating larger data sets (<italic>n</italic> &gt; 20) with an absence of significant outliers, PAND is regarded as a robust measure for evaluating the practical effectiveness of an intervention that is based on data in both the baseline and treatment phases.</p>
<p>Finally, when selecting a measure of effect size to evaluate the outcome of their SCRD, researchers should consider the purpose of their evaluation. Several studies (<xref ref-type="bibr" rid="bibr18-0748175612456401">Parker et al., 2011</xref>; <xref ref-type="bibr" rid="bibr17-0748175612456401">Parker &amp; Vannest, 2009</xref>; <xref ref-type="bibr" rid="bibr28-0748175612456401">Wolery, Busick, Reichow, &amp; Barton, 2010</xref>) demonstrated that some methods of calculating effect size for SCRDs are more conservative when compared with others. When the purpose of research is to make high-stakes determinations in mental health and educational settings, researchers will want to implement a measure that will assist in making responsible inferences. For instance, <xref ref-type="bibr" rid="bibr28-0748175612456401">Wolery et al. (2010)</xref> found that PND was more conservative than PEM for making determinations of treatment efficacy. However, in the meta-analytic comparison provided by Wolery et al., the authors did not screen data for appropriateness of fit between procedures. This highlights the fact that there is no simple rule choosing an effect size measure based on simple rules of rigor or conservativeness and highlights the importance for researchers to consider their data on an individual basis to avoid making Type 1 and Type 2 errors when interpreting their findings.</p>
</sec>
<sec id="section10-0748175612456401" sec-type="conclusions">
<title>Conclusion</title>
<p>Since the momentum for implementing and reporting the findings of SCRDs has accelerated, only a modest amount of studies reported in the counseling and counselor education literature implement rigorous data analysis practices. Although SCRDs may not be preferred for every research question, nonoverlap methods for computing treatment effect sizes provide a valuable tool for supporting accountability between practitioners, clients, funding sources, and community stakeholders. Furthermore, the use of nonoverlap methods to calculate treatment effect size as an adjunct to visual analysis may help further repudiate the use of SCRDs in community and educational settings in instances when between-groups designs may not be sensible. As with any other statistical procedure, PND, PEM, and PAND should be implemented prudently after considering baseline data characteristics, the size of data sets, and the purpose for evaluating a phenomenon. In addition to the aforementioned publications that include PND, PEM, and PAND analyses (<xref ref-type="bibr" rid="bibr5-0748175612456401">Lenz &amp; Aguilar, 2012</xref>; <xref ref-type="bibr" rid="bibr6-0748175612456401">Lenz et al., 2011</xref>; <xref ref-type="bibr" rid="bibr7-0748175612456401">Lenz, Perepiczka, et al., 2012</xref>; <xref ref-type="bibr" rid="bibr8-0748175612456401">Lenz, Speciale, et al., 2012</xref>; <xref ref-type="bibr" rid="bibr23-0748175612456401">Schottelkorb &amp; Ray, 2009</xref>), researchers interested in practicing the application of these methods are encouraged to conduct analyses using examples of counseling research in which the methods can be readily applied (see <xref ref-type="bibr" rid="bibr4-0748175612456401">Heppner &amp; Hendricks, 1995</xref>; <xref ref-type="bibr" rid="bibr12-0748175612456401">Martin-Causey &amp; Hinkle, 1995</xref>; <xref ref-type="bibr" rid="bibr19-0748175612456401">Powell &amp; Newgent, 2010</xref>). Although this article is practical in nature, researchers are encouraged to increase their familiarity with SCRDs and explore the many applications of this methodology that can support and advance the counseling profession.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<bio>
<title>Bio</title>
<p><bold>A. Stephen Lenz</bold>, PhD, LPC, is an assistant professor in the Department of Counseling, Educational Psychology, and Research at The University of Memphis. He has worked with children, adolescents, adults, and families in community-based and University counseling settings. His research interests include career development with adolescents, holistic approaches to counseling, counselor education, and supervision, community-based program evaluation, counseling outcome research, single-case research, and instrument development.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chambless</surname><given-names>D. L.</given-names></name>
<name><surname>Baker</surname><given-names>M.</given-names></name>
<name><surname>Baucom</surname><given-names>D. H.</given-names></name>
<name><surname>Beutler</surname><given-names>L. E.</given-names></name>
<name><surname>Calhoun</surname><given-names>K. S.</given-names></name>
<name><surname>. . . Woody</surname><given-names>S. R.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Update on empirically validated therapies, II</article-title>. <source>Clinical Psychologist</source>. <volume>51</volume>, <fpage>3</fpage>–<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr2-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chambless</surname><given-names>D. L.</given-names></name>
<name><surname>Sanderson</surname><given-names>W. C.</given-names></name>
<name><surname>Shoham</surname><given-names>V.</given-names></name>
<name><surname>Johnson</surname><given-names>S. B.</given-names></name>
<name><surname>Pope</surname><given-names>K. S.</given-names></name>
<name><surname>Crits-Christoph</surname><given-names>P.</given-names></name>
<name><surname>. . . McCurry</surname><given-names>S.</given-names></name>
</person-group> (<year>1996</year>). <article-title>An update on empirically validated therapies</article-title>. <source>Clinical Psychologist</source>, <volume>49</volume>, <fpage>5</fpage>–<lpage>18</lpage>.</citation>
</ref>
<ref id="bibr3-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Foster</surname><given-names>L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A best kept secret: Single- subject research design in counseling</article-title>. <source>Counseling Outcome Research and Evaluation</source>, <volume>1</volume>, <fpage>30</fpage>–<lpage>39</lpage>. doi:<pub-id pub-id-type="doi">10.1177/2150137810387130</pub-id></citation>
</ref>
<ref id="bibr4-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heppner</surname><given-names>M. J.</given-names></name>
<name><surname>Hendricks</surname><given-names>F.</given-names></name>
</person-group> (<year>1995</year>). <article-title>A process and outcome study evaluating career indecision and indecisiveness</article-title>. <source>Journal of Counseling and Development</source>, <volume>73</volume>, <fpage>426</fpage>–<lpage>437</lpage>.</citation>
</ref>
<ref id="bibr5-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lenz</surname><given-names>A. S.</given-names></name>
<name><surname>Aguilar</surname><given-names>J. V.</given-names></name>
</person-group> (<year>2012</year>). <source>Integrating relational cultural therapy concepts into supervision: Mediating effects on relational health and working alliance</source>. Manuscript submitted for publication.</citation>
</ref>
<ref id="bibr6-0748175612456401">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Lenz</surname><given-names>A. S.</given-names></name>
<name><surname>Oliver</surname><given-names>M.</given-names></name>
<name><surname>Nelson</surname><given-names>K. W.</given-names></name>
</person-group> (<year>2011</year>). <source>In-person and computer-mediated distance group supervision: A case study</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://counselingoutfitters.com/vistas/vistas11/Article_67.pdf">http://counselingoutfitters.com/vistas/vistas11/Article_67.pdf</ext-link></citation>
</ref>
<ref id="bibr7-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lenz</surname><given-names>A. S.</given-names></name>
<name><surname>Perepiczka</surname><given-names>M.</given-names></name>
<name><surname>Balkin</surname><given-names>R.</given-names></name>
</person-group> (<year>2012</year>). <source>Evidence for the mediating effects of a support group for attitudes toward statistics</source>. Manuscript submitted for publication.</citation>
</ref>
<ref id="bibr8-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lenz</surname><given-names>A. S.</given-names></name>
<name><surname>Speciale</surname><given-names>M.</given-names></name>
<name><surname>Aguilar</surname><given-names>J. V.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Relational-cultural therapy intervention with incarcerated adolescents: A single-case effectiveness design</article-title>. <source>Counseling Outcome Research and Evaluation</source>, <volume>3</volume>, <fpage>17</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr9-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lundervold</surname><given-names>D. A.</given-names></name>
<name><surname>Belwood</surname><given-names>M. F.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The best kept secret in counseling: Single-case (<italic>N</italic> = 1) experimental designs</article-title>. <source>Journal of Counseling &amp; Development</source>, <volume>78</volume>, <fpage>92</fpage>–<lpage>102</lpage>.</citation>
</ref>
<ref id="bibr10-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ma</surname><given-names>H. H.</given-names></name>
</person-group> (<year>2006</year>). <article-title>An alternative method for quantitative synthesis of single-subject researches: Percentage of data points exceeding the median</article-title>. <source>Behavior Modification</source>, <volume>30</volume>, <fpage>598</fpage>–<lpage>617</lpage>.</citation>
</ref>
<ref id="bibr11-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ma</surname><given-names>H. H.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The effectiveness of intervention on the behavior of individuals with autism: A meta-analysis using percentage of data points exceeding the median of baseline phase (PEM)</article-title>. <source>Behavior Modification</source>, <volume>33</volume>, <fpage>339</fpage>–<lpage>359</lpage>. doi:<pub-id pub-id-type="doi">10.1177/0145445509333173</pub-id></citation>
</ref>
<ref id="bibr12-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Martin-Causey</surname><given-names>T.</given-names></name>
<name><surname>Hinkle</surname><given-names>J. S.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Multimodal therapy with an aggressive preadolescent: A demonstration of effectiveness and accountability</article-title>. <source>Journal of Counseling and Development</source>, <volume>73</volume>, <fpage>305</fpage>–<lpage>310</lpage>.</citation>
</ref>
<ref id="bibr13-0748175612456401">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Morgan</surname><given-names>D. L.</given-names></name>
<name><surname>Morgan</surname><given-names>R. K.</given-names></name>
</person-group> (<year>2009</year>). <source>Single-case research methods for the behavioral and health sciences</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr14-0748175612456401">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>O’Neill</surname><given-names>R. E.</given-names></name>
<name><surname>McDonnell</surname><given-names>J. J.</given-names></name>
<name><surname>Billingsley</surname><given-names>F. F.</given-names></name>
<name><surname>Jenson</surname><given-names>W. R.</given-names></name>
</person-group> (<year>2011</year>). <source>Single case research designs in educational and community settings</source>. <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Pearson</publisher-name>.</citation>
</ref>
<ref id="bibr15-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parker</surname><given-names>R. I.</given-names></name>
<name><surname>Hagan-Burke</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Useful effect size interpretations for single case research</article-title>. <source>Behavior Therapy</source>, <volume>38</volume>, <fpage>95</fpage>–<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr16-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parker</surname><given-names>R. I.</given-names></name>
<name><surname>Hagan-Burke</surname><given-names>S.</given-names></name>
<name><surname>Vannest</surname><given-names>K.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Percentage of all non-overlapping data (PAND): An alternative to PND</article-title>. <source>Journal of Special Education</source>, <volume>40</volume>, <fpage>194</fpage>–<lpage>204</lpage>.</citation>
</ref>
<ref id="bibr17-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parker</surname><given-names>R. I.</given-names></name>
<name><surname>Vannest</surname><given-names>K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>An improved effect size for single-case research: Nonoverlap of all pairs</article-title>. <source>Behavior Therapy</source>, <volume>40</volume>, <fpage>357</fpage>–<lpage>367</lpage>.</citation>
</ref>
<ref id="bibr18-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parker</surname><given-names>R. I.</given-names></name>
<name><surname>Vannest</surname><given-names>K.</given-names></name>
<name><surname>Davis</surname><given-names>J. L.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Effect size in single-case research: A review of nine overlap techniques</article-title>. <source>Behavior Modification</source>, <volume>35</volume>, <fpage>303</fpage>–<lpage>322</lpage>. doi:<pub-id pub-id-type="doi">10.1177/0145445511399147</pub-id></citation>
</ref>
<ref id="bibr19-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Powell</surname><given-names>M. L.</given-names></name>
<name><surname>Newgent</surname><given-names>R. A.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Improving the empirical credibility of cinematherapy: A single-subject interrupted time series design</article-title>. <source>Counseling Outcome Research and Evaluation</source>, <volume>1</volume>, <fpage>40</fpage>–<lpage>49</lpage>. doi:<pub-id pub-id-type="doi">10.1177/2150137810373920</pub-id></citation>
</ref>
<ref id="bibr20-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Preston</surname><given-names>D.</given-names></name>
<name><surname>Carter</surname><given-names>M.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A review of the efficacy of the picture exchange communication system intervention</article-title>. <source>Journal of Autism and Developmental Disorders</source>, <volume>39</volume>, <fpage>1147</fpage>–<lpage>1486</lpage>.</citation>
</ref>
<ref id="bibr21-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ray</surname><given-names>D. C.</given-names></name>
<name><surname>Minton</surname><given-names>C. A.</given-names></name>
<name><surname>Schottelkorb</surname><given-names>A. A.</given-names></name>
<name><surname>Brown</surname><given-names>A. G.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Single-case design in child counseling research: Implications for counselor education</article-title>. <source>Counselor Education &amp; Supervision</source>, <volume>49</volume>, <fpage>193</fpage>–<lpage>208</lpage>.</citation>
</ref>
<ref id="bibr22-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sanderson</surname><given-names>W. C.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Why empirically supported treatments are important</article-title>. <source>Behavioral Modification</source>, <volume>27</volume>, <fpage>290</fpage>–<lpage>299</lpage>. doi:<pub-id pub-id-type="doi">10.1177/0145445503253828</pub-id></citation>
</ref>
<ref id="bibr23-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schottelkorb</surname><given-names>A. A.</given-names></name>
<name><surname>Ray</surname><given-names>D. C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>ADHD symptom reduction in elementary students: A single subject case effectiveness design</article-title>. <source>Professional School Counseling</source>, <volume>13</volume>, <fpage>11</fpage>–<lpage>22</lpage>. doi:<pub-id pub-id-type="doi">10.5330/PSC.n.2010-13.11</pub-id></citation>
</ref>
<ref id="bibr24-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scruggs</surname><given-names>T. E.</given-names></name>
<name><surname>Mastropieri</surname><given-names>M. A.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Summarizing single-subject research: Issues and applications</article-title>. <source>Behavior Modification</source>, <volume>22</volume>, <fpage>221</fpage>–<lpage>242</lpage>.</citation>
</ref>
<ref id="bibr25-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scruggs</surname><given-names>T. E.</given-names></name>
<name><surname>Mastropieri</surname><given-names>M. A.</given-names></name>
</person-group> (<year>2001</year>). <article-title>How to summarize single-participant research: Ideas and applications</article-title>. <source>Exceptionality</source>, <volume>9</volume>, <fpage>227</fpage>–<lpage>244</lpage>. doi:<pub-id pub-id-type="doi">10.1207/S15327035EX0904_5</pub-id></citation>
</ref>
<ref id="bibr26-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scruggs</surname><given-names>T. E.</given-names></name>
<name><surname>Mastropieri</surname><given-names>M. A.</given-names></name>
<name><surname>Casto</surname><given-names>G.</given-names></name>
</person-group> (<year>1987</year>). <article-title>The quantitative synthesis of single-subject research: Methodology and validation</article-title>. <source>Remedial and Special Education</source>, <volume>8</volume>, <fpage>24</fpage>–<lpage>33</lpage>.</citation>
</ref>
<ref id="bibr27-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sharpley</surname><given-names>C. F.</given-names></name>
</person-group> (<year>2007</year>). <article-title>So why aren’t counselors reporting n = 1 research designs?</article-title> <source>Journal of Counseling and Development</source>, <volume>85</volume>, <fpage>349</fpage>–<lpage>356</lpage>.</citation>
</ref>
<ref id="bibr28-0748175612456401">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolery</surname><given-names>M.</given-names></name>
<name><surname>Busick</surname><given-names>M.</given-names></name>
<name><surname>Reichow</surname><given-names>B.</given-names></name>
<name><surname>Barton</surname><given-names>E. E.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Comparison of overlap methods for quantitatively synthesizing single-subject data</article-title>. <source>Journal of Special Education</source>, <volume>44</volume>, <fpage>18</fpage>–<lpage>28</lpage>. doi:<pub-id pub-id-type="doi">10.1177/0022466908328009</pub-id></citation>
</ref>
</ref-list>
</back>
</article>