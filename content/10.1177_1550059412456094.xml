<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EEG</journal-id>
<journal-id journal-id-type="hwp">speeg</journal-id>
<journal-title>Clinical EEG and Neuroscience</journal-title>
<issn pub-type="ppub">1550-0594</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1550059412456094</article-id>
<article-id pub-id-type="publisher-id">10.1177_1550059412456094</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Embedded Prediction in Feature Extraction</article-title>
<subtitle>Application to Single-Trial EEG Discrimination</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Hsu</surname>
<given-names>Wei-Yen</given-names>
</name>
<xref ref-type="aff" rid="aff1-1550059412456094">1</xref>
<xref ref-type="aff" rid="aff2-1550059412456094">2</xref>
<xref ref-type="corresp" rid="corresp1-1550059412456094"/>
</contrib>
</contrib-group>
<aff id="aff1-1550059412456094"><label>1</label>Department of Information Management, National Chung Cheng University, Taiwan</aff>
<aff id="aff2-1550059412456094">
<label>2</label>Advanced Institute of Manufacturing with High-tech Innovations, National Chung Cheng University, Taiwan </aff>
<author-notes>
<corresp id="corresp1-1550059412456094">Wei-Yen Hsu, Department of Information Management, National Chung Cheng University, 168 University Road, Minhsiung Township, Chiayi County 62102, Taiwan. Email: <email>shenswy@gmail.com</email>; <email>shen@csie.ncku.edu.tw</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>44</volume>
<issue>1</issue>
<fpage>31</fpage>
<lpage>38</lpage>
<history>
<date date-type="received">
<day>9</day>
<month>9</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>5</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© EEG and Clinical Neuroscience Society (ECNS) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="society">EEG and Clinical Neuroscience Society</copyright-holder>
</permissions>
<abstract>
<p>In this study, an analysis system embedding neuron-fuzzy prediction in feature extraction is proposed for brain–computer interface (BCI) applications. Wavelet-fractal features combined with neuro-fuzzy predictions are applied for feature extraction in motor imagery (MI) discrimination. The features are extracted from the electroencephalography (EEG) signals recorded from participants performing left and right MI. Time-series predictions are performed by training 2 adaptive neuro-fuzzy inference systems (ANFIS) for respective left and right MI data. Features are then calculated from the difference in multi-resolution fractal feature vector (MFFV) between the predicted and actual signals through a window of EEG signals. Finally, the support vector machine is used for classification. The proposed method estimates its performance in comparison with the linear adaptive autoregressive (AAR) model and the AAR time-series prediction of 6 participants from 2 data sets. The results indicate that the proposed method is promising in MI classification.</p>
</abstract>
<kwd-group>
<kwd>brain–computer interface (BCI)</kwd>
<kwd>motor imagery (MI)</kwd>
<kwd>neuro-fuzzy prediction</kwd>
<kwd>modified fractal dimension</kwd>
<kwd>support vector machine (SVM)</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1550059412456094">
<title>Introduction</title>
<p>The work of BCI is to provide humans an alternative channel that allows direct transmission of messages from the brain by analyzing the brain’s mental activities.<sup><xref ref-type="bibr" rid="bibr1-1550059412456094">1</xref><xref ref-type="bibr" rid="bibr2-1550059412456094"/><xref ref-type="bibr" rid="bibr3-1550059412456094"/><xref ref-type="bibr" rid="bibr4-1550059412456094"/><xref ref-type="bibr" rid="bibr5-1550059412456094"/><xref ref-type="bibr" rid="bibr6-1550059412456094"/><xref ref-type="bibr" rid="bibr7-1550059412456094"/>–<xref ref-type="bibr" rid="bibr8-1550059412456094">8</xref></sup> BCI systems have become popular in motor imagery electroencephalography (MI EEG) signals in the last decade.<sup><xref ref-type="bibr" rid="bibr9-1550059412456094">9</xref></sup> BCI reveals that there are special characteristics of event-related desynchronization and synchronization in mu and beta rhythms over the sensorimotor cortex during MI tasks by discriminating EEG signals between left and right MIs.<sup><xref ref-type="bibr" rid="bibr10-1550059412456094">10</xref>,<xref ref-type="bibr" rid="bibr11-1550059412456094">11</xref></sup> The principal objective of this study is to propose a BCI system that combines neuro-fuzzy prediction and MFFV features with a support vector machine (SVM) for MI classification.</p>
<p>A model is used for time-series prediction to forecast future events based on known past events.<sup><xref ref-type="bibr" rid="bibr12-1550059412456094">12</xref></sup> A variety of methods have been presented in time-series prediction, such as linear regression, Kalman filtering,<sup><xref ref-type="bibr" rid="bibr13-1550059412456094">13</xref></sup> neural network (NN),<sup><xref ref-type="bibr" rid="bibr14-1550059412456094">14</xref></sup> and the use of a fuzzy inference system (FIS).<sup><xref ref-type="bibr" rid="bibr15-1550059412456094">15</xref></sup> Linear regression is simple and common, but it has less adaptation. Kalman filtering is an adaptive method but intrinsically linear. Neural network can approximate any nonlinear functions, but it demands a great deal of training data and is hard to interpret. In contrast, FIS has good capability of interpretation, but its adaptability is relatively low. The FISs are fuzzy predictions that can learn fuzzy “if-then” rules to predict data. They are readable, extensible, and universally approximate.<sup><xref ref-type="bibr" rid="bibr15-1550059412456094">15</xref></sup> An adaptive neuro-fuzzy inference system (ANFIS)<sup><xref ref-type="bibr" rid="bibr16-1550059412456094">16</xref></sup> integrates the advantage of both NN and fuzzy system. That is, ANFIS not only has good learning capability but can also be easily interpreted. In addition, the training of ANFIS is fast and can usually converge with just a small data set. These good properties are suitable for the prediction of nonstationary EEG signals. Therefore, ANFIS is used for time-series prediction in this study.</p>
<p>An effective feature extraction method can enhance the classification accuracy. An important component for most BCIs is to extract significant features from the event-related area during different MI tasks. A large number of feature extraction methods have been proposed. Among these, the band power and adaptive autoregressive (AAR) parameters are commonly used.<sup><xref ref-type="bibr" rid="bibr17-1550059412456094">17</xref>–<xref ref-type="bibr" rid="bibr20-1550059412456094">20</xref></sup> Feature extraction based on band power is usually obtained by computing the powers at the alpha and beta bands. The features are then extracted from band powers by calculating their logarithm values<sup><xref ref-type="bibr" rid="bibr17-1550059412456094">17</xref></sup> or by averaging over them.<sup><xref ref-type="bibr" rid="bibr18-1550059412456094">18</xref></sup> Adaptive autoregressive parameters are another popular feature in mental tasks.<sup><xref ref-type="bibr" rid="bibr19-1550059412456094">19</xref>,<xref ref-type="bibr" rid="bibr20-1550059412456094">20</xref></sup> The all-pole AAR model lends itself well to modeling EEG signals as filtered white noise with certain preferred energy bands. The EEG time series is fitted with an AAR model.</p>
<p>Furthermore, fractal geometry<sup><xref ref-type="bibr" rid="bibr21-1550059412456094">21</xref></sup> provides a proper mathematical model to describe the complex and irregular shapes that exist in nature. Fractal dimension is a statistical quantity that effectively extracts fractal features. In the last decade, feature extraction characterized by fractal dimension has been widely applied in various kinds of biomedical image and signal analyses, such as texture extraction<sup><xref ref-type="bibr" rid="bibr22-1550059412456094">22</xref>,<xref ref-type="bibr" rid="bibr23-1550059412456094">23</xref></sup> and EEG analyses of sleeping newborns.<sup><xref ref-type="bibr" rid="bibr24-1550059412456094">24</xref>,<xref ref-type="bibr" rid="bibr25-1550059412456094">25</xref></sup> In this study, discrete wavelet transform (DWT), together with modified fractal dimension, is utilized for feature extraction. That is, MFFVs are extracted from wavelet data by modified fractal dimension. The MFFVs contain not only multiple scale attributes but also important fractal information.</p>
<p>SVM,<sup><xref ref-type="bibr" rid="bibr26-1550059412456094">26</xref>–<xref ref-type="bibr" rid="bibr28-1550059412456094">28</xref></sup> recognizing and classifying the patterns into 2 categories from a set of data, is usually used for the analyses of classification and regression. For example, SVM is used for large clinical studies on the abilities of patients with stroke,<sup><xref ref-type="bibr" rid="bibr29-1550059412456094">29</xref></sup> as well as to improve Alzheimer disease diagnosis.<sup><xref ref-type="bibr" rid="bibr30-1550059412456094">30</xref></sup> Since SVM can balance accuracy and generalization simultaneously,<sup><xref ref-type="bibr" rid="bibr26-1550059412456094">26</xref></sup> it is used for classification in this study.</p>
<p>To evaluate the performance, several popular methods, including the AAR-parameter approach and AAR time-series prediction, are implemented for comparison.</p>
</sec>
<sec id="section2-1550059412456094" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>An analysis system is proposed for MI EEG classification, as illustrated in <xref ref-type="fig" rid="fig1-1550059412456094">Figure 1</xref>. The procedure is performed in several steps; data configuration, neuron-fuzzy prediction, feature extraction, and classification. First, raw EEG data are filtered into wide-band data that contain mu and beta rhythm components. The ANFIS time-series predictions are extracted off-line from training data. Information from ANFIS time-series predictions is directly applied to predict the test data. Modified fractal dimension, combined with DWT, is utilized for feature extraction. Extracted fractal features are used to train the parameters of the SVM classifier off-line. Finally, the SVM, together with trained parameters, is utilized to discriminate the features.</p>
<fig id="fig1-1550059412456094" position="float">
<label>Figure 1.</label>
<caption>
<p>Flowchart of the proposed system. It consists of several steps, including data configuration, neuron-fuzzy prediction, feature extraction, and classification.</p>
</caption>
<graphic xlink:href="10.1177_1550059412456094-fig1.tif"/>
</fig>
<sec id="section3-1550059412456094">
<title>Data Description</title>
<p>The EEG data were recorded by the Graz BCI group.<sup><xref ref-type="bibr" rid="bibr20-1550059412456094">20</xref>,<xref ref-type="bibr" rid="bibr31-1550059412456094">31</xref><xref ref-type="bibr" rid="bibr32-1550059412456094"/><xref ref-type="bibr" rid="bibr33-1550059412456094"/><xref ref-type="bibr" rid="bibr34-1550059412456094"/>–<xref ref-type="bibr" rid="bibr35-1550059412456094">35</xref></sup> Two data sets were used to evaluate the performance of all methods in the experiments. The first data sets were recorded from 3 participants during a feedback experimental recording procedure. The task was to control a bar by means of imagery left- or right-hand movements.<sup><xref ref-type="bibr" rid="bibr20-1550059412456094">20</xref>,<xref ref-type="bibr" rid="bibr31-1550059412456094">31</xref>,<xref ref-type="bibr" rid="bibr33-1550059412456094">33</xref>,<xref ref-type="bibr" rid="bibr34-1550059412456094">34</xref></sup> The order of left and right cues was random. The first participant S1 performed 280 trials, while the last 2 participants, S2 and S3, performed 320 trials. The length of each trial was 8 to 9 seconds. The first 2 seconds were quiet, an acoustic stimulus indicated the beginning of a trial at <italic>t</italic> = 2 seconds, and a fixation cross (+) was displayed for 1 second. Then at <italic>t</italic> = 3 seconds, an arrow (left or right) was displayed as a cue (the data recorded between 3 and 8 seconds are considered as event related). At the same time, each participant was asked to move the bar by imagining left- or right-hand movements according to the direction of the cue. The recordings were made using a g.tec amplifier and Ag/AgCl electrodes. All signals were sampled at 128 Hz and filtered between 0.5 and 30 Hz.</p>
<p>The second data sets were recorded from 3 other participants using a 64-channel neuroscan EEG amplifier.<sup><xref ref-type="bibr" rid="bibr32-1550059412456094">32</xref>,<xref ref-type="bibr" rid="bibr35-1550059412456094">35</xref></sup> The left and right mastoids served as reference and ground, respectively. The EEG data were sampled at 250 Hz and filtered between 1 and 50 Hz. The participants were asked to perform imagery movements prompted by a visual cue. Each trial started with an empty black screen; at <italic>t</italic> = 2 seconds a short beep tone was presented and a cross “+” appeared on the screen to notify the participants. Then at <italic>t</italic> = 3 seconds an arrow lasting for 1.25 seconds pointed to either the left or right direction. Each direction indicated the participants to imagine either a left- or right-hand movement. The imagery movements were performed until the cross disappeared at <italic>t</italic> = 7 seconds. No feedback was obtained in the experiments. The data set recorded from participant S4 was 180 trials, while the data sets for participants S5 and S6 were 120 trials. For each participant, the first half of the trials was used as training data and the second half as test data.</p>
</sec>
<sec id="section4-1550059412456094">
<title>Data Configuration</title>
<p>Mu and beta rhythms are distributed between 8 and 30 Hz and are located over the sensorimotor cortex. Using a wider frequency range can generally achieve higher classification accuracy in comparison with a narrower one.<sup><xref ref-type="bibr" rid="bibr36-1550059412456094">36</xref></sup> A wide frequency range containing all mu and beta rhythm components was adopted to include all of the important signal spectra for MI classification. In this study, the raw EEG data were filtered to the frequency range between 8 and 30 Hz, with a fifth order Butterworth band-pass filter.</p>
<p>To make a prediction at sample <italic>t</italic>, the measured signals extracted from the recorded EEG time-series data are used from samples <italic>t − Ld</italic> to <italic>t − d</italic>. The parameters <italic>L</italic> and <italic>d</italic> are the embedding dimension and time delay, respectively. In general, the best values for <italic>L</italic> and <italic>d</italic> are described in the information theoretic approach. In this study, features are extracted through a prediction method. The classification accuracy is then a good measure to choose the best <italic>L</italic> and <italic>d</italic> − 6 and <italic>d</italic> − 1, respectively. Each training input data for ANFIS prediction consists of respective measured signals of length <italic>L</italic> on both the <italic>C</italic>3 and <italic>C</italic>4 channels.<sup><xref ref-type="bibr" rid="bibr37-1550059412456094">37</xref></sup> The training input data are represented as follows:<disp-formula id="disp-formula1-1550059412456094">
<label>1</label>
<mml:math id="mml-disp1-1550059412456094">
<mml:mfenced close="⌋" open="⌊"><mml:mrow><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mn>3</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>L</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:mo stretchy="false">…</mml:mo><mml:mo stretchy="false">,</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mn>3</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mn>4</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>L</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:mo stretchy="false">…</mml:mo><mml:mo stretchy="false">,</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mn>4</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>t</mml:mi></mml:msup><mml:msup><mml:mfenced close="" open="|"><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mn>3</mml:mn><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mn>4</mml:mn><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mfenced>
</mml:math>
<graphic alternate-form-of="disp-formula1-1550059412456094" xlink:href="10.1177_1550059412456094-eq1.tif"/>
</disp-formula>
There are event-related data of approximately 5 seconds in each trial. All parameter selections are performed from the training data. All training data are used to train the parameters of prediction models, which will be further used for feature extraction. The test data are finally tested to evaluate the performance of the system by using the trained parameters.</p>
</sec>
<sec id="section5-1550059412456094">
<title>Prediction Models</title>
<sec id="section6-1550059412456094">
<title>Neuro-Fuzzy Prediction</title>
<p>Time-series prediction is the use of a model to forecast future events based on known past events. Although all kinds of methods in time-series prediction have been presented, ANFIS time-series prediction is slightly modified and adopted in this study since it integrates the advantages of NN and fuzzy system.</p>
<p>The ANFIS network architecture applied to the time-series prediction of EEG data is introduced. A detailed description of ANFIS can be found in ref.<sup><xref ref-type="bibr" rid="bibr16-1550059412456094">16</xref></sup> The ANFIS enhances fuzzy parameter tuning with self-learning capabilities for achieving optimal prediction objectives. An ANFIS network is a multilayer feed-forward network, where each node performs a particular node function on incoming signals. It is characterized with a set of parameters pertaining to that node. To reflect different adaptive capabilities, both square and circle node symbols are used. A square node (adaptive node) has parameters needed to be trained, while a circle node (fixed node) has none. The parameters of the ANFIS network consist of the union of the parameter sets associated with each adaptive node. To achieve a desired input–output mapping, these parameters are updated according to the given training data and a recursive least square (RLS) estimate.</p>
<p>In this study, the ANFIS network applied for time-series prediction contains <italic>L</italic> inputs and 1 output. There are <italic>2<sup>L</sup></italic> fuzzy if-then rules of Takagi and Sugeno<sup><xref ref-type="bibr" rid="bibr38-1550059412456094">38</xref></sup> in the representation of a rule base. The output is a current sample, and the inputs are the past <italic>L</italic> samples in the time delay <italic>t</italic>. The output of the <italic>i</italic>th node in the <italic>l</italic>th layer is denoted by <inline-formula id="inline-formula1-1550059412456094">
<mml:math id="mml-inline1-1550059412456094">
<mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:msubsup>
</mml:math>
</inline-formula>. The node function for each layer is then described as follows.</p>
<p><italic>Layer 1</italic>: Each node in this layer is a square node, where the degree of membership functions of input data is calculated. The output of each node in this layer is represented as<disp-formula id="disp-formula2-1550059412456094">
<label>2</label>
<mml:math id="mml-disp2-1550059412456094">
<mml:mrow><mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mtext>μ</mml:mtext><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>;</mml:mo><mml:malignmark/><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:malignmark/><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>L</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math>
<graphic alternate-form-of="disp-formula2-1550059412456094" xlink:href="10.1177_1550059412456094-eq2.tif"/>
</disp-formula>
where <italic>i</italic> = 2(<italic>j</italic> − 1) + <italic>k</italic>, <italic>C</italic> represents <italic>C</italic>3 or <italic>C</italic>4 as the input to node <italic>i</italic> and <italic>M<sub>jk</sub>
</italic> is the linguistic label associated with this node function. The bell-shape Gaussian membership function <inline-formula id="inline-formula2-1550059412456094">
<mml:math id="mml-inline2-1550059412456094">
<mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">μ</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> is used in<disp-formula id="disp-formula3-1550059412456094">
<label>3</label>
<mml:math id="mml-disp3-1550059412456094">
<mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">μ</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mo stretchy="false">−</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">σ</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula3-1550059412456094" xlink:href="10.1177_1550059412456094-eq3.tif"/>
</disp-formula>
where the parameter set {<italic>a<sub>jk</sub></italic>, σ<italic><sub>jk</sub></italic>} adjusts the shape of the Gaussian membership function. Parameter <italic>M<sub>jk</sub></italic> in this layer is referred to as the premise parameter.</p>
<p><italic>Layer 2</italic>: Each node in this layer is a circle node labeled Π, multiplying the incoming signals together and sending out their product.<disp-formula id="disp-formula4-1550059412456094">
<label>4</label>
<mml:math id="mml-disp4-1550059412456094">
<mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false" stretchy="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">μ</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">−</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo stretchy="false">,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">,</mml:mo><mml:mn>2</mml:mn>
</mml:math>
<graphic alternate-form-of="disp-formula4-1550059412456094" xlink:href="10.1177_1550059412456094-eq4.tif"/>
</disp-formula>
Each node output represents the firing strength of a rule.</p>
<p><italic>Layer 3</italic>: Each node in this layer is a circle node labeled <italic>N</italic>. The firing strength of a rule for each node in this layer is normalized.</p>
<p><disp-formula id="disp-formula5-1550059412456094">
<label>5</label>
<mml:math id="mml-disp5-1550059412456094">
<mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:msubsup><mml:mo stretchy="false">=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">,</mml:mo><mml:mn>2</mml:mn>
</mml:math>
<graphic alternate-form-of="disp-formula5-1550059412456094" xlink:href="10.1177_1550059412456094-eq5.tif"/>
</disp-formula>
</p>
<p><italic>Layer 4</italic>: Each node in this layer is a square node with its node function represented as<disp-formula id="disp-formula6-1550059412456094">
<label>6</label>
<mml:math id="mml-disp6-1550059412456094">
<mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mn>4</mml:mn></mml:msubsup><mml:mo stretchy="false">=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:munderover><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfenced><mml:mo stretchy="false">,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">,</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula6-1550059412456094" xlink:href="10.1177_1550059412456094-eq6.tif"/>
</disp-formula>
where the output <italic>f<sub>i</sub></italic> is a linear combination of the parameter set {<italic>p<sub>ij</sub></italic>, <italic>r<sub>i</sub></italic>}. Parameter <italic>f<sub>i</sub></italic> in this layer is referred to as a consequent parameter.</p>
<p><italic>Layer 5</italic>: The single node in this layer is a circle node labeled Σ, computing the overall output <italic>y</italic> as the sum of all incoming signals.<disp-formula id="disp-formula7-1550059412456094">
<label>7</label>
<mml:math id="mml-disp7-1550059412456094">
<mml:msubsup><mml:mi>O</mml:mi><mml:mn>1</mml:mn><mml:mn>5</mml:mn></mml:msubsup><mml:mo stretchy="false">=</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:munder><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mi>i</mml:mi></mml:munder></mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-1550059412456094" xlink:href="10.1177_1550059412456094-eq7.tif"/>
</disp-formula>
The consequent parameters are updated by the RLS learning procedure in the forward pass for ANFIS network learning, while the antecedent parameters are adjusted by using the error between the predicted and actual signals. A combination of least squares and back propagation methods is adopted for the optimization of ANFIS parameters. Two ANFISs are used to perform prediction. That is, the labels lANFIS and rANFIS are used to predict left and right training MI EEG data, respectively.</p>
</sec>
<sec id="section7-1550059412456094">
<title>Other prediction methods</title>
<p>Several prediction methods are also introduced for performance comparison. They are the AAR-parameter approach and the AAR time-series prediction. The AAR-parameter method is an AAR signal modeling approach. The all-pole AAR model lends itself well to modeling the EEG as filtered white noise with certain preferred energy bands. The EEG time series is fitted with an AAR model. In the experiments, the order of the AAR model is chosen as 6 and the AAR parameters are estimated with the RLS algorithm. The AAR parameters are used as features at each sample point for each trial. The AAR time-series prediction method is a time-series prediction approach, where lANFIS and rANFIS in the ANFIS time-series prediction method are replaced by left and right AAR models. The lengths of windows for the AAR parameter approach and AAR time-series prediction are all 1-second windows, which are the same as that for the ANFIS time-series prediction.</p>
</sec>
</sec>
<sec id="section8-1550059412456094">
<title>Feature Extraction</title>
<p>After lANFIS and rANFIS are trained trial by trial using the left and right MI training data, respectively, they are used to perform one-step ahead prediction. The test data are then input to these 2 ANFISs, sample by sample, and features are extracted by continually calculating the difference in MFFVs between the predicted and actual signals as the length of predicted signals achieves a 1-second window. The MFFV will be outlined in the next paragraph. In this study, feature extraction is performed on the 1-second window of predicted signals instead of directly classifying the native predicted signals.</p>
<p>A signal is decomposed into numerous details in multi-resolution analysis, where each scale represents a class of distinct physical characteristics within the signal. The Daubechies wavelet transform is used to achieve multi-resolutional representation in this study.<sup><xref ref-type="bibr" rid="bibr23-1550059412456094">23</xref>,<xref ref-type="bibr" rid="bibr36-1550059412456094">36</xref>,<xref ref-type="bibr" rid="bibr39-1550059412456094">39</xref><xref ref-type="bibr" rid="bibr40-1550059412456094"/><xref ref-type="bibr" rid="bibr41-1550059412456094"/><xref ref-type="bibr" rid="bibr42-1550059412456094"/><xref ref-type="bibr" rid="bibr43-1550059412456094"/><xref ref-type="bibr" rid="bibr44-1550059412456094"/>–<xref ref-type="bibr" rid="bibr45-1550059412456094">45</xref></sup> The 1-second segment is decomposed into numerous nonoverlapping subbands by the Daubechies wavelet transform.</p>
<p>Fractal geometry provides a proper mathematical model to describe a complex shape that exists in nature with fractal features. Since fractal dimension is relatively insensitive to signal scaling and shows a strong correlation with human judgment of surface roughness,<sup><xref ref-type="bibr" rid="bibr21-1550059412456094">21</xref></sup> it is chosen as the feature extraction method. A variety of approaches were proposed to estimate fractal dimension from signals or images.<sup><xref ref-type="bibr" rid="bibr22-1550059412456094">22</xref><xref ref-type="bibr" rid="bibr23-1550059412456094"/><xref ref-type="bibr" rid="bibr24-1550059412456094"/><xref ref-type="bibr" rid="bibr25-1550059412456094"/><xref ref-type="bibr" rid="bibr26-1550059412456094"/>–<xref ref-type="bibr" rid="bibr27-1550059412456094">27</xref></sup> A differential box counting (DBC) method, covering a wide dynamic range with a low computational complexity, is modified and used in this study.<sup><xref ref-type="bibr" rid="bibr36-1550059412456094">36</xref></sup> A MFFV is extracted by modified fractal dimension from all the nonoverlapping subbands of a 1-second segment.</p>
<p>The MFFV reflects the roughness and complexity of nonoverlapping subbands of a signal. These MFFV calculations reduce the prediction cost from a 1-second window to a feature vector for each signal. Features are extracted by continually calculating the difference of MFFVs between the predicted and actual signals as the length of predicted signals achieves a 1-second window. In other words, 2 sets of MFFV features are first extracted from the predicted and actual signals, respectively, as the length of predicted signals achieves a 1-second window. They are then subtracted for each respective subband. Finally, features are obtained by continually calculating their difference. The left and right test data are input to both the lANFIS and rANFIS, and each ANFIS provides 2 predictions from the <italic>C</italic>3 and <italic>C</italic>4 channels. Accordingly, 4 sets of MFFVs can be extracted after each new set of predictions is obtained. Each time a new set of predictions is produced, the oldest one is removed from the 1-second segment and a new MFFV is then extracted from the signals within the window. Since a large window is too redundant for real-time application, a 1-second window is short and selected for feature extraction. The length of a 1-second segment is a compromise between the computation cost and event-related potential (ERP) component applications. If the window length is selected properly, the extracted MFFVs will produce the maximum feature separability and obtain the highest classification accuracy.</p>
</sec>
<sec id="section9-1550059412456094">
<title>Classification</title>
<p>The SVM proposed by Vapnik<sup><xref ref-type="bibr" rid="bibr26-1550059412456094">26</xref></sup> has a very steady theory in statistical learning and guarantees to obtain the optimal decision function from a set of training data. The main idea of SVM is to construct a hyperplane as the decision surface in such a way that the margin of separation between positive and negative examples is maximized. The SVM optimization problem is</p>
<p><disp-formula id="disp-formula8-1550059412456094">
<mml:math id="mml-disp8-1550059412456094">
<mml:mrow><mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mi>w</mml:mi></mml:munder><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>w</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:munderover><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">ξ</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-1550059412456094" xlink:href="10.1177_1550059412456094-eq8.tif"/>
</disp-formula>
subject to <inline-formula id="inline-formula3-1550059412456094">
<mml:math id="mml-inline3-1550059412456094">
<mml:mrow><mml:msub><mml:mtext>ξ</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:malignmark/><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow>
</mml:math>
</inline-formula>, and
<disp-formula id="disp-formula9-1550059412456094">
<label>8</label>
<mml:math id="mml-disp9-1550059412456094">
<mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mfenced><mml:mo stretchy="false">≥</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">ξ</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:mspace width="1em"/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">,</mml:mo><mml:mo stretchy="false">…</mml:mo><mml:mi>N</mml:mi>
</mml:math>
<graphic alternate-form-of="disp-formula9-1550059412456094" xlink:href="10.1177_1550059412456094-eq9.tif"/>
</disp-formula>
where <italic>g</italic>(<italic>x</italic>) = <italic>w<sup>T</sup>x</italic> + <italic>b</italic> represents the hyperplane, <italic>w</italic> is the weighting vector, <italic>b</italic> is the bias term, <italic>x</italic> is the training vector with label <italic>d</italic>, <italic>C</italic> is the weighting constant, and ξ is the slack variable. It is then transformed into a convex quadratic dual problem. The discriminant function with optimal <italic>w</italic> and <italic>b</italic>, <inline-formula id="inline-formula5-1550059412456094">
<mml:math id="mml-inline4-1550059412456094">
<mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>o</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>x</mml:mi><mml:mo stretchy="false">+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub>
</mml:math>
</inline-formula>, posterior to the optimization form becomes<disp-formula id="disp-formula10-1550059412456094">
<label>9</label>
<mml:math id="mml-disp10-1550059412456094">
<mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false" stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="italic">α</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-1550059412456094" xlink:href="10.1177_1550059412456094-eq10.tif"/>
</disp-formula>
where α is a Lagrange multiplier and <italic>K</italic>(<italic>x</italic>, <italic>x<sub>i</sub>
</italic>) is a kernel function. Generally, appropriate kernel functions are the polynomial kernel function <inline-formula id="inline-formula6-1550059412456094">
<mml:math id="mml-inline5-1550059412456094">
<mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mi>p</mml:mi></mml:msup>
</mml:math>
</inline-formula> and the radial basis function kernel function <inline-formula id="inline-formula7-1550059412456094">
<mml:math id="mml-inline6-1550059412456094">
<mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi mathvariant="italic">σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mfenced close="∥" open="∥"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced>
</mml:math>
</inline-formula>. In this study, the latter is chosen for the SVM.</p>
<p>In the proposed system, classification is performed on MFFVs for recognizing the corresponding state at the sample rate. A different SVM classifier at each sample point is produced to classify each set of MFFVs for the training data. The classification sample point possessing maximal classification rate for training data is used as the standard classifier, which will be used for all classifications performed on the test data. The best parameters selected from the training data are then applied to the test data to estimate the classification accuracy of test data.</p>
</sec>
<sec id="section10-1550059412456094">
<title>Statistical Analysis</title>
<p>Two-way analysis of variance (ANOVA) and multiple comparison tests were performed in the experiments. Statistical analyses with 2-way ANOVA were used to evaluate whether the difference in performance was significant or not for the 2 factors, methods, and participants. After analyzing with the 2-way ANOVA, multiple comparison tests were used to estimate the <italic>P </italic>values and the significance of each pair of methods. The confidence interval of the test was 0.99.</p>
</sec>
</sec>
<sec id="section11-1550059412456094">
<title>Results</title>
<sec id="section12-1550059412456094">
<title>Performance of Prediction Methods</title>
<p>To assess the performance of the proposed time-series prediction method, several prediction methods, including the AAR-parameter approach and the AAR time-series prediction, combined with power spectra features, are implemented for comparison. The power spectra features are obtained by calculating the powers at the alpha and beta bands. The comparison results of classification accuracy among different time-series prediction using power spectra features are listed in <xref ref-type="table" rid="table1-1550059412456094">Table 1</xref>. The average classification accuracy of the AAR-parameter approach is 67.0%, while AAR time-series prediction is 77.7% in average classification accuracy. The ANFIS time-series prediction obtains the best average classification accuracy (82.8%).</p>
<table-wrap id="table1-1550059412456094" position="float">
<label>Table 1.</label>
<caption>
<p>Comparison of Performance Among Different Time-Series Prediction Frameworks Using Power Spectra Features.</p>
</caption>
<graphic alternate-form-of="table1-1550059412456094" xlink:href="10.1177_1550059412456094-table1.tif"/>
<table>
<thead>
<tr>
<th>Classification accuracy (%)</th>
<th>AAR parameters</th>
<th>AAR prediction</th>
<th>Neuro-fuzzy prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td>S1</td>
<td>71.5</td>
<td>81.4</td>
<td>86.9</td>
</tr>
<tr>
<td>S2</td>
<td>66.3</td>
<td>76.6</td>
<td>84.2</td>
</tr>
<tr>
<td>S3</td>
<td>64.9</td>
<td>78.3</td>
<td>77.2</td>
</tr>
<tr>
<td>S4</td>
<td>72.6</td>
<td>79.6</td>
<td>88.6</td>
</tr>
<tr>
<td>S5</td>
<td>65.7</td>
<td>73.1</td>
<td>80.1</td>
</tr>
<tr>
<td>S6</td>
<td>61.0</td>
<td>77.0</td>
<td>79.8</td>
</tr>
<tr>
<td>Average</td>
<td>67.0</td>
<td>77.7</td>
<td>82.8</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1550059412456094">
<p>Abbreviation: AAR, adaptive autoregressive.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section13-1550059412456094">
<title>Performance of Features</title>
<p>To further estimate the performance of the proposed ANFIS time-series prediction method and MFFV features, the ANFIS time-series prediction method, combined with power spectra features, is used for comparison in <xref ref-type="table" rid="table2-1550059412456094">Table 2</xref>. The average classification accuracy for the ANFIS time-series prediction method, combined with power spectra features, is 82.8%, while the MFFV features under the ANFIS time-series prediction method obtain 91.0% in average classification accuracy.</p>
<table-wrap id="table2-1550059412456094" position="float">
<label>Table 2.</label>
<caption>
<p>Comparison of Performance Between Power Spectra and MFFV Features Under the Use of ANFIS Time-Series Prediction.</p>
</caption>
<graphic alternate-form-of="table2-1550059412456094" xlink:href="10.1177_1550059412456094-table2.tif"/>
<table>
<thead>
<tr>
<th>Classification accuracy (%)</th>
<th>Power spectra</th>
<th>MFFV</th>
</tr>
</thead>
<tbody>
<tr>
<td>S1</td>
<td>86.9</td>
<td>92.8</td>
</tr>
<tr>
<td>S2</td>
<td>84.2</td>
<td>88.5</td>
</tr>
<tr>
<td>S3</td>
<td>77.2</td>
<td>90.3</td>
</tr>
<tr>
<td>S4</td>
<td>88.6</td>
<td>93.9</td>
</tr>
<tr>
<td>S5</td>
<td>80.1</td>
<td>88.2</td>
</tr>
<tr>
<td>S6</td>
<td>79.8</td>
<td>92.0</td>
</tr>
<tr>
<td>Average</td>
<td>82.8 </td>
<td>91.0 </td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1550059412456094">
<p>Abbreviations: ANFIS, neuro-fuzzy inference systems; MFFV, multi-resolution fractal feature vector.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section14-1550059412456094">
<title>Results of Tests</title>
<p>The ANOVA tables regarding the comparison of prediction methods under power spectra features and the comparison of features are listed in <xref ref-type="table" rid="table3-1550059412456094">Tables 3</xref> and <xref ref-type="table" rid="table4-1550059412456094">4</xref>, respectively. The results of tests are discussed in detail in the next section.</p>
<table-wrap id="table3-1550059412456094" position="float">
<label>Table 3.</label>
<caption>
<p>The ANOVA Table: Comparison of Prediction Methods Under Power Spectra Features.</p>
</caption>
<graphic alternate-form-of="table3-1550059412456094" xlink:href="10.1177_1550059412456094-table3.tif"/>
<table>
<thead>
<tr>
<th>μ<italic>
<sub>i</sub>
</italic> − μ<italic>
<sub>j</sub>
</italic>, <italic>p</italic> (prediction methods)</th>
<th>μ<sub>1</sub> (AAR parameters)</th>
<th>μ<sub>2</sub> (AAR prediction)</th>
</tr>
</thead>
<tbody>
<tr>
<td>μ<sub>2</sub> (AAR prediction)</td>
<td>0.0007</td>
<td>
</td>
</tr>
<tr>
<td>μ<sub>3</sub> (neuro-fuzzy prediction)</td>
<td>&lt;0.0001</td>
<td>0.0195</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1550059412456094">
<p>Abbreviation: AAR, adaptive autoregressive; ANOVA, analysis of variance.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table4-1550059412456094" position="float">
<label>Table 4.</label>
<caption>
<p>The ANOVA Table: Comparison of Features.</p>
</caption>
<graphic alternate-form-of="table4-1550059412456094" xlink:href="10.1177_1550059412456094-table4.tif"/>
<table>
<thead>
<tr>
<th>μ<italic>
<sub>i</sub>
</italic> − μ<italic>
<sub>j</sub>
</italic>, <italic>p</italic> (features)</th>
<th>μ<sub>1</sub> (power spectra)</th>
</tr>
</thead>
<tbody>
<tr>
<td>μ<sub>2</sub> (MFFV)</td>
<td>0.0030</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-1550059412456094">
<p>Abbreviations: ANOVA, analysis of variance; MFFV, multi-resolution fractal feature vector.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section15-1550059412456094">
<title>Discussion</title>
<sec id="section16-1550059412456094">
<title>Statistical Evaluation of Prediction Methods</title>
<p>The ANFIS combines the advantage of NN with that of FIS. Moreover, the training of ANFIS is fast and can generally converge from small data sets. These attractive properties are suitable for the prediction of nonstationary EEG signals. <xref ref-type="table" rid="table1-1550059412456094">Table 1</xref> lists the comparisons of performance among different prediction frameworks using power spectra features. In addition, 2-way ANOVA and multiple comparison tests are performed to verify whether the prediction methods are significantly different. The results indicate that the AAR time-series prediction method is much better than the AAR parameter approach in classification accuracy (<italic>P </italic>value .0007), which is improved by 10.7% on average. The ANFIS time-series prediction method, however, is slightly better than the AAR prediction method (<italic>P </italic>value .0195), where the classification accuracy increases by 5.1%. Accordingly, ANFIS time-series prediction has the best performance in classification accuracy among these 3 methods. The results denote that ANFIS time-series prediction is the best prediction framework in MI classification.</p>
</sec>
<sec id="section17-1550059412456094">
<title>Statistical Evaluation of Features</title>
<p>Wavelet-fractal features are extracted from wavelet data by modified fractal dimension. The MFFVs are utilized to describe the characteristics of fractal features in different wavelet scales, which are greatly beneficial for the analysis of EEG data. The comparison of performance between power spectra and MFFV features under the use of ANFIS time-series prediction is listed in <xref ref-type="table" rid="table2-1550059412456094">Table 2</xref>. In addition, 2-way ANOVA and multiple comparison tests are performed again to validate whether the 2 features are significantly different. The results indicate that MFFV features are significantly better than power spectra features in classification accuracy (<italic>P </italic>value .0030), which is improved by 8.2% on average. The results indicate that MFFV features are better. These 2 results also suggest that the ANFIS prediction framework, together with MFFV features, is a good combination in BCI applications.</p>
</sec>
<sec id="section18-1550059412456094">
<title>Advantage of Proposed Method</title>
<p>The proposed ANFIS prediction framework, combined with MFFV features, provides a good potential for EEG-based MI classification. Furthermore, the proposed method also has the following 2 potential advantages: first, the MFFV features really improve the separability of MI data, because the power spectra feature extracted from the predicted signals results in a poorer performance. Second, the MFFV features can effectively reduce the degradation of noise; in other words, the MFFV features are extracted by DWT and modified fractal dimension. The former obtains multiscale information of EEG signals while the latter decreases the effect of noise. This is because the calculation of an improved DBC method is proposed and applied to the modified fractal dimension.</p>
</sec>
</sec>
<sec id="section19-1550059412456094">
<title>Conclusion</title>
<p>We have proposed a BCI system embedding neuro-fuzzy prediction in feature extraction. The results demonstrate the potential for the use of neuro-fuzzy prediction together with the SVM in MI classification. The results also show that the proposed system is robust for intersubject use under careful parameter training, which is important for BCI applications. Compared with other well-known approaches, neuro-fuzzy prediction, together with SVM, achieves better results in BCI applications. In future studies, more effective predictions/features and powerful classifiers will be used to further improve the classification results.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The author expresses his sincere appreciation for grants from NSC101-2320-B-038-001 and NSC101-2221-E-038-004, National Science Council, Taiwan.</p>
</ack>
<fn-group>
<fn fn-type="conflict" id="fn1-1550059412456094"><label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn2-1550059412456094"><label>Funding</label>
<p>The author received financial support from NSC101-2320-B-038-001 and NSC101-2221-E-038-004, National Science Council, Taiwan, for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1550059412456094">
<label>1</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nicolaou</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Georgiou</surname>
<given-names>J</given-names>
</name>
</person-group>. <article-title>The use of permutation entropy to characterize sleep electroencephalograms</article-title>. <source>Clin EEG Neurosci</source>. <year>2011</year>;<volume>42</volume>(<issue>1</issue>):<fpage>24</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr2-1550059412456094">
<label>2</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wolpaw</surname>
<given-names>JR</given-names>
</name>
<name>
<surname>Birbaumer</surname>
<given-names>N</given-names>
</name>
<name>
<surname>McFarland</surname>
<given-names>DJ</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Vaughan</surname>
<given-names>TM</given-names>
</name>
</person-group>. <article-title>Brain–computer interfaces for communication and control</article-title>. <source>Clin Neurophysiol</source>. <year>2002</year>;<volume>113</volume>(<issue>6</issue>):<fpage>767</fpage>–<lpage>791</lpage>.</citation>
</ref>
<ref id="bibr3-1550059412456094">
<label>3</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Xu</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Zhao</surname>
<given-names>SZ</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>HS</given-names>
</name>
<name>
<surname>Zheng</surname>
<given-names>CX</given-names>
</name>
</person-group>. <article-title>Decreased delta event-related synchronization in patients with early vascular dementia</article-title>. <source>Clin EEG Neurosci</source>. <year>2011</year>;<volume>42</volume>(<issue>1</issue>):<fpage>53</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr4-1550059412456094">
<label>4</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ahmadlou</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Adeli</surname>
<given-names>H</given-names>
</name>
</person-group>. <article-title>Fuzzy synchronization likelihood with application to attention-deficit/hyperactivity disorder</article-title>. <source>Clin EEG Neurosci</source>. <year>2011</year>;<volume>42</volume>(<issue>1</issue>):<fpage>6</fpage>–<lpage>13</lpage>.</citation>
</ref>
<ref id="bibr5-1550059412456094">
<label>5</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>Continuous EEG signal analysis for asynchronous BCI application</article-title>. <source>Int J Neural Syst</source>. <year>2011</year>;<volume>21</volume>(<issue>4</issue>):<fpage>335</fpage>–<lpage>350</lpage>.</citation>
</ref>
<ref id="bibr6-1550059412456094">
<label>6</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lin</surname>
<given-names>CT</given-names>
</name>
<name>
<surname>Lin</surname>
<given-names>FC</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>SA</given-names>
</name>
<name>
<surname>Lu</surname>
<given-names>SW</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>TC</given-names>
</name>
<name>
<surname>Ko</surname>
<given-names>LW.</given-names>
</name>
</person-group> <article-title>EEG-based brain–computer interface for smart living environment auto-adjustment</article-title>. <source>J Med Biol Eng</source>. <year>2010</year>;<volume>30</volume>(<issue>4</issue>):<fpage>237</fpage>–<lpage>245</lpage>.</citation>
</ref>
<ref id="bibr7-1550059412456094">
<label>7</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>EEG-based motor imagery classification using neuro-fuzzy prediction and wavelet fractal features</article-title>. <source>J Neurosci Methods</source>. <year>2010</year>;<volume>189</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>302</lpage>.</citation>
</ref>
<ref id="bibr8-1550059412456094">
<label>8</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>Application of competitive Hopfield neural network to brain–computer interface systems</article-title>. <source>Int J Neural Syst</source>. <year>2012</year>;<volume>22</volume>(<issue>1</issue>):<fpage>51</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr9-1550059412456094">
<label>9</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Torres</surname>
<given-names>MSM</given-names>
</name>
<name>
<surname>Celeste</surname>
<given-names>WC</given-names>
</name>
<name>
<surname>Bastos-Filho</surname>
<given-names>TF</given-names>
</name>
<etal/>
</person-group>. <article-title>Brain–computer interface based on visual evoked potentials to command autonomous robotic wheelchair</article-title>. <source>J Med Biol Eng</source>. <year>2010</year>;<volume>30</volume>(<issue>6</issue>):<fpage>407</fpage>–<lpage>415</lpage>.</citation>
</ref>
<ref id="bibr10-1550059412456094">
<label>10</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>Enhanced active segment selection for single-trial EEG classification</article-title>. <source>Clin EEG Neurosci</source>. <year>2012</year>;<volume>43</volume>(<issue>2</issue>):<fpage>87</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr11-1550059412456094">
<label>11</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Lopes da Silva</surname>
<given-names>FH</given-names>
</name>
</person-group>. <article-title>Event-related EEG/MEG synchronization and desynchronization: basic principles</article-title>. <source>Clin Neurophysiol</source>. <year>1999</year>;<volume>110</volume>(<issue>11</issue>):<fpage>1842</fpage>–<lpage>1857</lpage>.</citation>
</ref>
<ref id="bibr12-1550059412456094">
<label>12</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Shumway</surname>
<given-names>RH</given-names>
</name>
<name>
<surname>Stoffer</surname>
<given-names>DS.</given-names>
</name>
</person-group> <source>Times Series Analysis and Its Application</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>; <year>2000</year>.</citation>
</ref>
<ref id="bibr13-1550059412456094">
<label>13</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hu</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Prokhorov</surname>
<given-names>DV</given-names>
</name>
<name>
<surname>Wunsch</surname>
<given-names>II</given-names>
</name>
<name>
<surname>Donald</surname>
<given-names>C</given-names>
</name>
</person-group>. <article-title>Time series prediction with a weighted bidirectional multi-stream extended Kalman filter</article-title>. <source>Neurocomputing</source>. <year>2007</year>;<volume>70</volume>(<issue>13-15</issue>):<fpage>2392</fpage>–<lpage>2399</lpage>.</citation>
</ref>
<ref id="bibr14-1550059412456094">
<label>14</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stamatis</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Parthimos</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Griffith</surname>
<given-names>TM</given-names>
</name>
</person-group>. <article-title>Forecasting chaotic cardiovascular time series with an adaptive slope multilayer perceptron neural network</article-title>. <source>IEEE Tran Biomed Eng</source>. <year>1999</year>;<volume>46</volume>(<issue>12</issue>):<fpage>1441</fpage>–<lpage>1453</lpage>.</citation>
</ref>
<ref id="bibr15-1550059412456094">
<label>15</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rong</surname>
<given-names>HJ</given-names>
</name>
<name>
<surname>Sundararajan</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Huang</surname>
<given-names>GB</given-names>
</name>
<name>
<surname>Saratchandran</surname>
<given-names>P</given-names>
</name>
</person-group>. <article-title>Sequential Adaptive Fuzzy Inference System (SAFIS) for nonlinear system identification and prediction</article-title>. <source>Fuzzy Sets Systems</source>. <year>2006</year>;<volume>157</volume>(<issue>9</issue>):<fpage>1260</fpage>–<lpage>1275</lpage>.</citation>
</ref>
<ref id="bibr16-1550059412456094">
<label>16</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jang Roger</surname>
<given-names>JS</given-names>
</name>
</person-group>. <article-title>ANFIS: adaptive-network-based fuzzy inference system</article-title>. <source>IEEE Trans SMC</source>. <year>1993</year>;<volume>23</volume>(<issue>3</issue>):<fpage>665</fpage>–<lpage>685</lpage>.</citation>
</ref>
<ref id="bibr17-1550059412456094">
<label>17</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Obermaier</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Neuper</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Guger</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
</person-group>. <article-title>Information transfer rate in a five-classes brain–computer interface</article-title>. <source>IEEE Trans Neural Syst Rehabil Eng</source>. <year>2001</year>;<volume>9</volume>(<issue>3</issue>):<fpage>283</fpage>–<lpage>288</lpage>.</citation>
</ref>
<ref id="bibr18-1550059412456094">
<label>18</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Guger</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Edlinger</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Harkam</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Niedermayer</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
</person-group>. <article-title>How many people are able to operate an EEG-based brain–computer interface (BCI)?</article-title> <source>IEEE Trans Neural Syst Rehabil Eng</source>. <year>2003</year>;<volume>11</volume>(<issue>2</issue>):<fpage>145</fpage>–<lpage>147</lpage>.</citation>
</ref>
<ref id="bibr19-1550059412456094">
<label>19</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Burke</surname>
<given-names>DP</given-names>
</name>
<name>
<surname>Kelly</surname>
<given-names>SP</given-names>
</name>
<name>
<surname>Chazal de</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Reilly</surname>
<given-names>RB</given-names>
</name>
<name>
<surname>Finucane</surname>
<given-names>C</given-names>
</name>
</person-group>. <article-title>A parametric feature extraction and classification strategy for brain–computer interfacing</article-title>. <source>IEEE Trans Neural Syst Rehabil Eng</source>. <year>2005</year>;<volume>13</volume>(<issue>1</issue>):<fpage>12</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr20-1550059412456094">
<label>20</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Guger</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Schlögl</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Neuper</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Walterspacher</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Strein</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G.</given-names>
</name>
</person-group> <article-title>Rapid prototyping of an EEG-based brain–computer interface (BCI)</article-title>. <source>IEEE Trans Neural Syst Rehabil Eng</source>. <year>2001</year>;<volume>9</volume>(<issue>1</issue>):<fpage>49</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr21-1550059412456094">
<label>21</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Mandelbrot</surname>
<given-names>BB</given-names>
</name>
</person-group>. <source>Fractal Geometry of Nature</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Freeman Press</publisher-name>; <year>1982</year>.</citation>
</ref>
<ref id="bibr22-1550059412456094">
<label>22</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>Improved watershed transform for tumor segmentation: application to mammogram image compression</article-title>. <source>Expert Syst Appl</source>. <year>2012</year>;<volume>39</volume>(<issue>4</issue>):<fpage>3950</fpage>–<lpage>3955</lpage>.</citation>
</ref>
<ref id="bibr23-1550059412456094">
<label>23</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lee</surname>
<given-names>WL</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>YC</given-names>
</name>
<name>
<surname>Hsieh</surname>
<given-names>KS</given-names>
</name>
</person-group>. <article-title>Ultrasonic liver tissues classification by fractal feature vector based on M-band wavelet transform</article-title>. <source>IEEE Trans Med Imaging</source>. <year>2003</year>;<volume>22</volume>(<issue>3</issue>):<fpage>382</fpage>–<lpage>392</lpage>.</citation>
</ref>
<ref id="bibr24-1550059412456094">
<label>24</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>EEG-based motor imagery classification using enhanced active segment selection and adaptive classifier</article-title>. <source>Comput Biol Med</source>. <year>2011</year>;<volume>41</volume>(<issue>8</issue>):<fpage>633</fpage>–<lpage>639</lpage>.</citation>
</ref>
<ref id="bibr25-1550059412456094">
<label>25</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Lin</surname>
<given-names>CH</given-names>
</name>
<name>
<surname>Hsu</surname>
<given-names>HJ</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>PH</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>IR</given-names>
</name>
</person-group>. <article-title>Wavelet-based envelope features with automatic eog artifact removal: application to single-trial eeg data</article-title>. <source>Expert Syst Appl</source>. <year>2012</year>;<volume>39</volume>(<issue>3</issue>):<fpage>2743</fpage>–<lpage>2749</lpage>.</citation>
</ref>
<ref id="bibr26-1550059412456094">
<label>26</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Boser</surname>
<given-names>BE</given-names>
</name>
<name>
<surname>Guyon</surname>
<given-names>IM</given-names>
</name>
<name>
<surname>Vapnik</surname>
<given-names>V.</given-names>
</name>
</person-group> <article-title>A training algorithm for optimal margin classifiers</article-title>. <source>Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory</source>. <year>1992</year>;<fpage>144</fpage>–<lpage>152</lpage>.</citation>
</ref>
<ref id="bibr27-1550059412456094">
<label>27</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Kuo</surname>
<given-names>WF</given-names>
</name>
</person-group>. <article-title>Unsupervised Fuzzy C-Means clustering for motor imagery EEG recognition</article-title>. <source>IJICIC</source>. <year>2011</year>;<volume>7</volume>(<issue>8</issue>):<fpage>4965</fpage>–<lpage>4976</lpage>.</citation>
</ref>
<ref id="bibr28-1550059412456094">
<label>28</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>Fuzzy Hopfield neural network clustering for single-trial motor imagery EEG classification</article-title>. <source>Expert Syst Appl</source>. <year>2012</year>;<volume>39</volume>(<issue>1</issue>):<fpage>1055</fpage>–<lpage>1061</lpage>.</citation>
</ref>
<ref id="bibr29-1550059412456094">
<label>29</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ang</surname>
<given-names>KK</given-names>
</name>
<name>
<surname>Guan</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Chua</surname>
<given-names>KS</given-names>
</name>
<etal/>
</person-group>. <article-title>A large clinical study on the ability of stroke patients to use EEG-based motor imagery brain–computer interface</article-title>. <source>Clin EEG Neurosci</source>. <year>2011</year>;<volume>42</volume>(<issue>4</issue>):<fpage>253</fpage>–<lpage>258</lpage>.</citation>
</ref>
<ref id="bibr30-1550059412456094">
<label>30</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Trambaiolli</surname>
<given-names>LR</given-names>
</name>
<name>
<surname>Lorena</surname>
<given-names>AC</given-names>
</name>
<name>
<surname>Fraga</surname>
<given-names>FJ</given-names>
</name>
<name>
<surname>Kanda</surname>
<given-names>PA</given-names>
</name>
<name>
<surname>Anghinah</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Nitrini</surname>
<given-names>R</given-names>
</name>
</person-group>. <article-title>Improving Alzheimer’s disease diagnosis with machine learning techniques</article-title>. <source>Clin EEG Neurosci</source>. <year>2011</year>;<volume>42</volume>(<issue>3</issue>):<fpage>160</fpage>–<lpage>165</lpage>.</citation>
</ref>
<ref id="bibr31-1550059412456094">
<label>31</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schlogl</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Keinrath</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Scherer</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
</person-group>. <article-title>Estimating the mutual information of an EEG-based brain computer interface</article-title>. <source>Biomed Tech (Berl)</source>. <year>2002</year>;<volume>47</volume>(<issue>1-2</issue>):<fpage>3</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr32-1550059412456094">
<label>32</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schlogl</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Bischof</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
</person-group>. <article-title>Characterization of four-class motor imagery EEG data for the BCI-competition 2005</article-title>. <source>J Neural Eng</source>. <year>2005</year>;<volume>2</volume>(<issue>4</issue>):<fpage>L14</fpage>–<lpage>L22</lpage>.</citation>
</ref>
<ref id="bibr33-1550059412456094">
<label>33</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haselsteiner</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Pfurtscheller</surname>
<given-names>G</given-names>
</name>
</person-group>. <article-title>Using time-dependent neural networks for EEG classification</article-title>. <source>IEEE Trans Rehabil Eng</source>. <year>2000</year>;<volume>8</volume>(<issue>4</issue>):<fpage>457</fpage>–<lpage>463</lpage>.</citation>
</ref>
<ref id="bibr34-1550059412456094">
<label>34</label>
<citation citation-type="web">
<collab collab-type="author">Graz Data Sets and description for the BCI 2003 competition [Online]</collab>. <ext-link ext-link-type="uri" xlink:href="http://ida.first.fraunhofer.de/projects/bci/competition/">http://ida.first.fraunhofer.de/projects/bci/competition/</ext-link> <comment>(accessed date May 1, 2011)</comment>.</citation>
</ref>
<ref id="bibr35-1550059412456094">
<label>35</label>
<citation citation-type="web">
<collab collab-type="author">Graz Data Sets and description for the BCI 2005 competition [Online]</collab>. <ext-link ext-link-type="uri" xlink:href="http://ida.first.fraunhofer.de/projects/bci/competition_iii/">http://ida.first.fraunhofer.de/projects/bci/competition_iii/</ext-link> <comment>(accessed date May 1, 2011)</comment>.</citation>
</ref>
<ref id="bibr36-1550059412456094">
<label>36</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Lin</surname>
<given-names>CC</given-names>
</name>
<name>
<surname>Ju</surname>
<given-names>MS</given-names>
</name>
<name>
<surname>Sun</surname>
<given-names>YN</given-names>
</name>
</person-group>. <article-title>Wavelet-based fractal features with active segment selection: application to single-trial EEG data</article-title>. <source>J Neurosci Methods</source>. <year>2007</year>;<volume>163</volume>(<issue>1</issue>):<fpage>145</fpage>–<lpage>160</lpage>.</citation>
</ref>
<ref id="bibr37-1550059412456094">
<label>37</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jasper</surname>
<given-names>H</given-names>
</name>
</person-group>. <article-title>Report of committee on methods of clinical exam in EEG</article-title>. <source>Electroencephalogr Clin Neurophysiol</source>. <year>1958</year>;<volume>10</volume>:<fpage>370</fpage>–<lpage>375</lpage>.</citation>
</ref>
<ref id="bibr38-1550059412456094">
<label>38</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lian</surname>
<given-names>KY</given-names>
</name>
<name>
<surname>Su</surname>
<given-names>CH</given-names>
</name>
<name>
<surname>Huang</surname>
<given-names>CS</given-names>
</name>
</person-group>. <article-title>Performance enhancement for T–S fuzzy control using neural networks</article-title>. <source>IEEE Trans Fuzzy Systems</source>. <year>2006</year>;<volume>14</volume>(<issue>5</issue>):<fpage>619</fpage>–<lpage>627</lpage>.</citation>
</ref>
<ref id="bibr39-1550059412456094">
<label>39</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Daubechies</surname>
<given-names>I</given-names>
</name>
</person-group>. <article-title>Orthonormal bases of compactly supported wavelets</article-title>. <source>Comm Pure Appl Math</source>. <year>1988</year>;<volume>41</volume>:<fpage>909</fpage>–<lpage>996</lpage>.</citation>
</ref>
<ref id="bibr40-1550059412456094">
<label>40</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Poon</surname>
<given-names>PWF</given-names>
</name>
<name>
<surname>Sun</surname>
<given-names>YN</given-names>
</name>
</person-group>. <article-title>Automatic seamless mosaicing of microscopic images: enhancing appearance with colour degradation compensation and wavelet-based blending</article-title>. <source>J Microsc</source>. <year>2008</year>;<volume>231</volume>(<issue>3</issue>):<fpage>408</fpage>–<lpage>418</lpage>.</citation>
</ref>
<ref id="bibr41-1550059412456094">
<label>41</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
</person-group>. <article-title>Analytic differential approach for robust registration of rat brain histological images</article-title>. <source>Microsc Res Tech</source>. <year>2011</year>;<volume>74</volume>(<issue>6</issue>):<fpage>523</fpage>–<lpage>530</lpage>.</citation>
</ref>
<ref id="bibr42-1550059412456094">
<label>42</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>YC</given-names>
</name>
<name>
<surname>Hsu</surname>
<given-names>CY</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>CT</given-names>
</name>
<name>
<surname>Chiu</surname>
<given-names>HW</given-names>
</name>
</person-group>. <article-title>Application of multiscale amplitude modulation features and FCM clustering to brain–computer interface</article-title>. <source>Clin EEG Neurosci</source>. <year>2012</year>;<volume>43</volume>(<issue>1</issue>):<fpage>32</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr43-1550059412456094">
<label>43</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lin</surname>
<given-names>CH</given-names>
</name>
<name>
<surname>Chao</surname>
<given-names>MW</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>JY</given-names>
</name>
<name>
<surname>Yu</surname>
<given-names>CW</given-names>
</name>
<name>
<surname>Hsu</surname>
<given-names>WY.</given-names>
</name>
</person-group> <article-title>A high-capacity distortion-free information hiding algorithm for 3D polygon models</article-title>. <source>IJICIC</source>. <year>2013</year>;<volume>9</volume>(<issue>1</issue>): <comment>In press</comment>.</citation>
</ref>
<ref id="bibr44-1550059412456094">
<label>44</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Sun</surname>
<given-names>YN.</given-names>
</name>
</person-group> <article-title>EEG-based motor imagery analysis using weighted wavelet transform features</article-title>. <source>J Neurosci Methods</source>. <year>2009</year>;<volume>176</volume>(<issue>2</issue>):<fpage>310</fpage>–<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr45-1550059412456094">
<label>45</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hsu</surname>
<given-names>WY.</given-names>
</name>
</person-group> <article-title>Wavelet-coherence features for motor imagery EEG analysis posterior to EOG noise elimination</article-title>. <source>IJICIC</source>. <year>2013</year>;<volume>9</volume>(<issue>1</issue>): <comment>In press</comment>.</citation>
</ref>
</ref-list>
</back>
</article>