<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSS</journal-id>
<journal-id journal-id-type="hwp">sppss</journal-id>
<journal-id journal-id-type="nlm-ta">Psychol Sci</journal-id>
<journal-title>Psychological Science</journal-title>
<journal-subtitle>Research, Theory, &amp; Application in Psychology and Related Sciences</journal-subtitle>
<issn pub-type="ppub">0956-7976</issn>
<issn pub-type="epub">1467-9280</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0956797611430953</article-id>
<article-id pub-id-type="publisher-id">10.1177_0956797611430953</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Measuring the Prevalence of Questionable Research Practices With Incentives for Truth Telling</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>John</surname><given-names>Leslie K.</given-names></name>
<xref ref-type="aff" rid="aff1-0956797611430953">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Loewenstein</surname><given-names>George</given-names></name>
<xref ref-type="aff" rid="aff2-0956797611430953">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Prelec</surname><given-names>Drazen</given-names></name>
<xref ref-type="aff" rid="aff3-0956797611430953">3</xref>
</contrib>
</contrib-group>
<aff id="aff1-0956797611430953"><label>1</label>Marketing Unit, Harvard Business School</aff>
<aff id="aff2-0956797611430953"><label>2</label>Department of Social &amp; Decision Sciences, Carnegie Mellon University</aff>
<aff id="aff3-0956797611430953"><label>3</label>Sloan School of Management and Departments of Economics and Brain &amp; Cognitive Sciences, Massachusetts Institute of Technology</aff>
<author-notes>
<corresp id="corresp1-0956797611430953">Leslie K. John, Harvard Business School—Marketing, Morgan Hall 169, Soldiers Field, Boston, MA 02163 E-mail: <email>ljohn@hbs.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>5</month>
<year>2012</year>
</pub-date>
<volume>23</volume>
<issue>5</issue>
<fpage>524</fpage>
<lpage>532</lpage>
<history>
<date date-type="received">
<day>20</day>
<month>5</month>
<year>2011</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>10</month>
<year>2011</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.</p>
</abstract>
<kwd-group>
<kwd>professional standards</kwd>
<kwd>judgment</kwd>
<kwd>disclosure</kwd>
<kwd>methodology</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Although cases of overt scientific misconduct have received significant media attention recently (<xref ref-type="bibr" rid="bibr1-0956797611430953">Altman, 2006</xref>; <xref ref-type="bibr" rid="bibr6-0956797611430953">Deer, 2011</xref>; <xref ref-type="bibr" rid="bibr31-0956797611430953">Steneck, 2002</xref>, <xref ref-type="bibr" rid="bibr32-0956797611430953">2006</xref>), exploitation of the gray area of acceptable practice is certainly much more prevalent, and may be more damaging to the academic enterprise in the long run, than outright fraud. Questionable research practices (QRPs), such as excluding data points on the basis of post hoc criteria, can spuriously increase the likelihood of finding evidence in support of a hypothesis. Just how dramatic these effects can be was demonstrated by <xref ref-type="bibr" rid="bibr28-0956797611430953">Simmons, Nelson, and Simonsohn (2011)</xref> in a series of experiments and simulations that showed how greatly QRPs increase the likelihood of finding support for a false hypothesis. QRPs are the steroids of scientific competition, artificially enhancing performance and producing a kind of arms race in which researchers who strictly play by the rules are at a competitive disadvantage. QRPs, by nature of the very fact that they are often questionable as opposed to blatantly improper, also offer considerable latitude for rationalization and self-deception.</p>
<p>Concerns over QRPs have been mounting (<xref ref-type="bibr" rid="bibr5-0956797611430953">Crocker, 2011</xref>; <xref ref-type="bibr" rid="bibr19-0956797611430953">Lacetera &amp; Zirulia, 2011</xref>; <xref ref-type="bibr" rid="bibr23-0956797611430953">Marshall, 2000</xref>; <xref ref-type="bibr" rid="bibr29-0956797611430953">Sovacool, 2008</xref>; <xref ref-type="bibr" rid="bibr33-0956797611430953">Sterba, 2006</xref>; <xref ref-type="bibr" rid="bibr38-0956797611430953">Wicherts, 2011</xref>), and several studies—many of which have focused on medical research—have assessed their prevalence (<xref ref-type="bibr" rid="bibr12-0956797611430953">Gardner, Lidz, &amp; Hartwig, 2005</xref>; <xref ref-type="bibr" rid="bibr13-0956797611430953">Geggie, 2001</xref>; <xref ref-type="bibr" rid="bibr15-0956797611430953">Henry et al., 2005</xref>; <xref ref-type="bibr" rid="bibr22-0956797611430953">List, Bailey, Euzent, &amp; Martin, 2001</xref>; <xref ref-type="bibr" rid="bibr24-0956797611430953">Martinson, Anderson, &amp; de Vries, 2005</xref>; <xref ref-type="bibr" rid="bibr34-0956797611430953">Swazey, Anderson, &amp; Louis, 1993</xref>). In the study reported here, we measured the percentage of psychologists who have engaged in QRPs.</p>
<p>As with any unethical or socially stigmatized behavior, self-reported survey data are likely to underrepresent true prevalence. Respondents have little incentive, apart from good will, to provide honest answers (<xref ref-type="bibr" rid="bibr10-0956797611430953">Fanelli, 2009</xref>). The goal of the present study was to obtain realistic estimates of QRPs with a new survey methodology that incorporates explicit response-contingent incentives for truth telling and supplements self-reports with impersonal judgments about the prevalence of practices and about respondents’ honesty. These impersonal judgments made it possible to elicit alternative estimates, from which we inferred the upper and lower boundaries of the actual prevalence of QRPs. Across QRPs, even raw self-admission rates were surprisingly high, and for certain practices, the inferred actual estimates approached 100%, which suggests that these practices may constitute the de facto scientific norm.</p>
<sec id="section1-0956797611430953" sec-type="methods">
<title>Method</title>
<p>In a study with a two-condition, between-subjects design, we e-mailed an electronic survey to 5,964 academic psychologists at major U.S. universities (for details on the survey and the sample, see Procedure and Table S1, respectively, in the Supplemental Material available online). Participants anonymously indicated whether they had personally engaged in each of 10 QRPs (<italic>self-admission rate</italic>; <xref ref-type="table" rid="table1-0956797611430953">Table 1</xref>), and if they had, whether they thought their actions had been defensible. The order in which the QRPs were presented was randomized between subjects. There were 2,155 respondents to the survey, which was a response rate of 36%. Of respondents who began the survey, 719 (33.4%) did not complete it (see Supplementary Results and Fig. S1 in the Supplemental Material); however, because the QRPs were presented in random order, data from all respondents—even those who did not finish the survey—were included in the analysis.</p>
<table-wrap id="table1-0956797611430953" position="float">
<label>Table 1.</label>
<caption>
<p>Results of the Main Study: Mean Self-Admission Rates, Comparison of Self-Admission Rates Across Groups, and Mean Defensibility Ratings</p>
</caption>
<graphic alternate-form-of="table1-0956797611430953" xlink:href="10.1177_0956797611430953-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="left" colspan="2">Self-admission rate (%)</th>
<th align="left" rowspan="2">Odds ratio (BTS/control)</th>
<th align="left" rowspan="2">Two-tailed <italic>p</italic> (likelihood ratio test)</th>
<th align="left" rowspan="2">Defensibility rating (across groups)</th>
</tr>
<tr>
<th align="left">Item</th>
<th align="left">Control group</th>
<th align="left">BTS group</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. In a paper, failing to report all of a study’s dependent measures</td>
<td>63.4</td>
<td>66.5</td>
<td>1.14</td>
<td>.23</td>
<td>1.84 (0.39)</td>
</tr>
<tr>
<td>2. Deciding whether to collect more data after looking to see whether the results were significant</td>
<td>55.9</td>
<td>58.0</td>
<td>1.08</td>
<td>.46</td>
<td>1.79 (0.44)</td>
</tr>
<tr>
<td>3. In a paper, failing to report all of a study’s conditions</td>
<td>27.7</td>
<td>27.4</td>
<td>0.98</td>
<td>.90</td>
<td>1.77 (0.49)</td>
</tr>
<tr>
<td>4. Stopping collecting data earlier than planned because one found the result that one had been looking for</td>
<td>15.6</td>
<td>22.5</td>
<td>1.57</td>
<td>.00</td>
<td>1.76 (0.48)</td>
</tr>
<tr>
<td>5. In a paper, “rounding off” a <italic>p</italic> value (e.g., reporting that a <italic>p</italic> value of .054 is less than .05)</td>
<td>22.0</td>
<td>23.3</td>
<td>1.07</td>
<td>.58</td>
<td>1.68 (0.57)</td>
</tr>
<tr>
<td>6. In a paper, selectively reporting studies that “worked”</td>
<td>45.8</td>
<td>50.0</td>
<td>1.18</td>
<td>.13</td>
<td>1.66 (0.53)</td>
</tr>
<tr>
<td>7. Deciding whether to exclude data after looking at the impact of doing so on the results</td>
<td>38.2</td>
<td>43.4</td>
<td>1.23</td>
<td>.06</td>
<td>1.61 (0.59)</td>
</tr>
<tr>
<td>8. In a paper, reporting an unexpected finding as having been predicted from the start</td>
<td>27.0</td>
<td>35.0</td>
<td>1.45</td>
<td>.00</td>
<td>1.50 (0.60)</td>
</tr>
<tr>
<td>9. In a paper, claiming that results are unaffected by demographic variables (e.g., gender) when one is actually unsure (or knows that they do)</td>
<td>3.0</td>
<td>4.5</td>
<td>1.52</td>
<td>.16</td>
<td>1.32 (0.60)</td>
</tr>
<tr>
<td>10. Falsifying data</td>
<td>0.6</td>
<td>1.7</td>
<td>2.75</td>
<td>.07</td>
<td>0.16 (0.38)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0956797611430953">
<p>Note: Items are listed in decreasing order of rated defensibility. Respondents who admitted to having engaged in a given behavior were asked to rate whether they thought it was defensible to have done so (0 = <italic>no</italic>, 1 = <italic>possibly</italic>, and 2 = <italic>yes</italic>). Standard deviations are given in parentheses. BTS = Bayesian truth serum. Applying the Bonferroni correction for multiple comparisons, we adjusted the critical alpha level downward to .005 (i.e., .05/10 comparisons).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In addition to providing self-admission rates, respondents also provided two impersonal estimates related to each QRP: (a) the percentage of other psychologists who had engaged in each behavior (<italic>prevalence estimate</italic>), and (b) among those psychologists who had, the percentage that would admit to having done so (<italic>admission estimate</italic>). Therefore, each respondent was asked to provide three pieces of information for each QRP. Respondents who indicated that they had engaged in a QRP were also asked to rate whether they thought it was defensible to have done so (0 = <italic>no</italic>, 1 = <italic>possibly</italic>, and 2 = <italic>yes</italic>). If they wished, they could also elaborate on why they thought it was (or was not) defensible.</p>
<p>After providing this information for each QRP, respondents were also asked to rate their degree of doubt about the integrity of the research done by researchers at other institutions, other researchers at their own institution, graduate students, their collaborators, and themselves (1 = <italic>never</italic>, 2 = <italic>once or twice</italic>, 3 = <italic>occasionally</italic>, 4 = <italic>often</italic>).</p>
<p>The two versions of the survey differed in the incentives they offered to respondents. In the Bayesian-truth-serum (BTS) condition, a scoring algorithm developed by one of the authors (<xref ref-type="bibr" rid="bibr26-0956797611430953">Prelec, 2004</xref>) was used to provide incentives for truth telling. This algorithm uses respondents’ answers about their own behavior and their estimates of the sample distribution of answers as inputs in a truth-rewarding scoring formula. Because the survey was anonymous, compensation could not be directly linked to individual scores. Instead, respondents were told that we would make a donation to a charity of their choice, selected from five options, and that the size of this donation would depend on the truthfulness of their responses, as determined by the BTS scoring system. By inducing a (correct) belief that dishonesty would reduce donations, we hoped to amplify the moral stakes riding on each answer (for details on the donations, see Supplementary Results in the Supplemental Material). Respondents were not given the details of the scoring system but were told that it was based on an algorithm published in <italic>Science</italic> and were given a link to the article. There was no deception: Respondents’ BTS scores determined our contributions to the five charities. Respondents in the control condition were simply told that a charitable donation would be made on behalf of each respondent. (For details on the effect of the size of the incentive on response rates, see Participation Incentive Survey in the Supplemental Material.)</p>
<p>The three types of answers to the survey questions—self-admission, prevalence estimate, admission estimate—allowed us to estimate the actual prevalence of each QRP in different ways. The credibility of each estimate hinged on the credibility of one of the three answers in the survey: First, if respondents answered the personal question honestly, then self-admission rates would reveal the actual prevalence of the QRPs in this sample. Second, if average prevalence estimates were accurate, then they would also allow us to directly estimate the actual prevalence of the QRPs. Third, if average admission estimates were accurate, then actual prevalence could be estimated using the ratios of admission rates to admission estimates. This would correspond to a case in which respondents did not know the actual prevalence of a practice but did have a good sense of how likely it is that a colleague would admit to it in a survey. The three estimates should converge if the self-admission rate equaled the prevalence estimate multiplied by the admission estimate. To the extent that this equality is violated, there would be differences between prevalence rates measured by the different methods.</p>
</sec>
<sec id="section2-0956797611430953" sec-type="results">
<title>Results</title>
<p>Raw self-admission rates, prevalence estimates, prevalence estimates derived from the admission estimates (i.e., self-admission rate/admission estimate), and geometric means of these three percentages are shown in <xref ref-type="fig" rid="fig1-0956797611430953">Figure 1</xref>. For details on our approach to analyzing the data, see Data Analysis in the Supplemental Material.</p>
<fig id="fig1-0956797611430953" position="float">
<label>Fig. 1.</label>
<caption>
<p>Results of the Bayesian-truth-serum condition in the main study. For each of the 10 items, the graph shows the self-admission rate, prevalence estimate, prevalence estimate derived from the admission estimate (i.e., self-admission rate/admission estimate), and geometric mean of these three percentages (numbers above the bars). See <xref ref-type="table" rid="table1-0956797611430953">Table 1</xref> for the complete text of the items.</p>
</caption>
<graphic xlink:href="10.1177_0956797611430953-fig1.tif"/>
</fig>
<sec id="section3-0956797611430953">
<title>Truth-telling incentives</title>
<p>A priori, truth-telling incentives (as provided in the BTS condition) should affect responses in proportion to the baseline (i.e., control condition) level of false denials. These baseline levels are unknown, but one can hypothesize that they should be minimal for impersonal estimates of prevalence and admission, and greatest for personal admissions of unethical practices broadly judged as unacceptable, which represent “red-card” violations.</p>
<p>As hypothesized, prevalence estimates (see Table S2 in the Supplemental Material) and admission estimates (see Table S3 in the Supplemental Material) were comparable in the two conditions, but self-admission rates for some items (<xref ref-type="table" rid="table1-0956797611430953">Table 1</xref>), especially those that were “more questionable,” were higher in the BTS condition than in the control condition. (<xref ref-type="table" rid="table1-0956797611430953">Table 1</xref> also presents the <italic>p</italic> values of the likelihood ratio test of the difference in admission rates between conditions.)</p>
<p>We assessed the effect of the BTS manipulation by examining the odds ratio of self-admission rates in the BTS condition to self-admission rates in the control condition. The odds ratio was high for one practice (falsifying data), moderate for three practices (premature stopping of data collection, falsely reporting a finding as expected, and falsely claiming that results are unaffected by certain variables), and negligible for the remainder of the practices (<xref ref-type="table" rid="table1-0956797611430953">Table 1</xref>). The acceptability of a practice can be inferred from the self-admission rate in the control condition (baseline) or assessed directly by judgments of defensibility. The nonparametric correlation of BTS impact, as measured by odds ratio, with the baseline self-admission rate was –.62 (<italic>p</italic> &lt; .06; parametric correlation = −.65, <italic>p</italic> &lt; .05); the correlation of odds ratio with defensibility rating was –.68 (<italic>p</italic> &lt; .03; parametric correlation = −.94, <italic>p</italic> &lt; .001). These correlations were more modest when Item 10 (“Falsifying data”) was excluded (odds ratio with baseline self-admission rate: nonparametric correlation = −.48, <italic>p</italic> &lt; .20; parametric correlation = −.59, <italic>p</italic> &lt; .10; odds ratio with defensibility rating: nonparametric correlation = −.57, <italic>p</italic> &lt; .12; parametric correlation = −.59, <italic>p</italic> &lt; .10).</p>
</sec>
<sec id="section4-0956797611430953">
<title>Prevalence estimates</title>
<p><xref ref-type="fig" rid="fig1-0956797611430953">Figure 1</xref> displays mean prevalence estimates for the three types of responses in the BTS condition (the admission estimates were capped at 100%; they exceeded 100% by a small margin for a few items). The figure also shows the geometric means of all three responses; these means, in effect, give equal credence to the three types of answers. The raw admission rates are almost certainly too low given the likelihood that respondents did not admit to all QRPs that they actually engaged in. Therefore, the geometric means are probably conservative judgments of true prevalence.</p>
<p>One would infer from the geometric means of the three variables that nearly 1 in 10 research psychologists has introduced false data into the scientific record (Items 5 and 10) and that the majority of research psychologists have engaged in practices such as selective reporting of studies (Item 6), not reporting all dependent measures (Item 1), collecting more data after determining whether the results were significant (Item 2), reporting unexpected findings as having been predicted (Item 8), and excluding data post hoc (Item 7).</p>
<p>These estimates are somewhat higher than estimates reported in previous research. For example, a meta-analysis of surveys—none of which provided incentives for truthful responding—found that, among scientists from a variety of disciplines, 9.5% of respondents admitted to having engaged in QRPs other than data falsification; the upper-boundary estimate was 33.7% (<xref ref-type="bibr" rid="bibr10-0956797611430953">Fanelli, 2009</xref>). In the present study, the mean self-admission rate in the BTS condition (excluding the data-falsification item for comparability with <xref ref-type="bibr" rid="bibr10-0956797611430953">Fanelli, 2009</xref>) was 36.6%—higher than both of the meta-analysis estimates. Moreover, among participants in the BTS condition who completed the survey, 94.0% admitted to having engaged in at least one QRP (compared with 91.4% in the control condition). The self-admission rate in our control condition (33.0%) mirrored the upper-boundary estimate obtained in Fanelli’s meta-analysis (33.7%).</p>
<p>Response to a given item on our survey was predictive of responses to the other items: The survey items approximated a Guttman scale, meaning that an admission to a relatively rare behavior (e.g., falsifying data) usually implied that the respondent had also engaged in more common behaviors. Among completed response sets, the coefficient of reproducibility—the average proportion of a person’s responses that can be reproduced by knowing the number of items to which he or she responded affirmatively—was .80 (high values indicate close agreement; items are considered to form a Guttman scale if reproducibility is .90 or higher; <xref ref-type="bibr" rid="bibr14-0956797611430953">Guttman, 1974</xref>). This finding suggests that researchers’ engagement in or avoidance of specific QRPs is not completely idiosyncratic. It indicates that there is a rough consensus among researchers about the relative unethicality of the behaviors, but large variation in where researchers draw the line when it comes to their own behavior.</p>
</sec>
<sec id="section5-0956797611430953">
<title>Perceived defensibility</title>
<p>Respondents had an opportunity to state whether they thought their actions were defensible. Consistent with the notion that latitude for rationalization is positively associated with engagement in QRPs, our findings showed that respondents who admitted to a QRP tended to think that their actions were defensible. The overall mean defensibility rating of practices that respondents acknowledged having engaged in was 1.70 (<italic>SD</italic> = 0.53)—between possibly defensible and defensible. Mean judged defensibility for each item is shown in <xref ref-type="table" rid="table1-0956797611430953">Table 1</xref>. Defensibility ratings did not generally differ according to the respondents’ discipline or the type of research they conducted (see Table S4 in the Supplemental Material).</p>
</sec>
<sec id="section6-0956797611430953">
<title>Doubts about research integrity</title>
<p>A large percentage of respondents indicated that they had doubts about research integrity on at least one occasion (<xref ref-type="fig" rid="fig2-0956797611430953">Fig. 2</xref>). The degree of doubt differed by target; for example, respondents were more wary of research generated by researchers at other institutions than of research conducted by their collaborators. Although heterogeneous referent-group sizes make these differences difficult to interpret (the number of researchers at other institutions is presumably larger than one’s own set of collaborators), it is noteworthy that approximately 35% of respondents indicated that they had doubts about the integrity of their own research on at least one occasion.</p>
<fig id="fig2-0956797611430953" position="float">
<label>Fig. 2.</label>
<caption>
<p>Results of the main study: distribution of responses to a question asking about doubts concerning the integrity of the research conducted by various categories of researchers.</p>
</caption>
<graphic xlink:href="10.1177_0956797611430953-fig2.tif"/>
</fig>
</sec>
<sec id="section7-0956797611430953">
<title>Frequency of engagement</title>
<p>Although the prevalence estimates obtained in the BTS condition are somewhat higher than previous estimates, they do not enable us to distinguish between the researcher who routinely engages in a given behavior and the researcher who has only engaged in that behavior once. To the extent that self-admission rates are driven by the former type, our results are more worrisome. We conducted a smaller-scale survey, in which we tested for differences in admission rates as a function of the response scale.</p>
<p>We asked 133 attendees of an annual conference of behavioral researchers whether they had engaged in each of 25 different QRPs (many of which we also inquired about in the main study). Using a 2 × 2 between-subjects design, we manipulated the wording of the questions and the response scale. The questions were either phrased as a generic action (“Falsifying data”) or in the first person (“I have falsified data”), and participants indicated whether they had engaged in the behaviors using either a dichotomous response scale (yes/no, as in the main study) or a frequency response scale (<italic>never, once or twice, occasionally, frequently</italic>).</p>
<p>Because the overall self-admission rates to the individual items were generally similar to those obtained in the main study, we do not report them here. Respondents made fewer affirmative admissions on the dichotomous response scale (<italic>M</italic> = 3.77 out of 25, <italic>SD</italic> = 2.27) than on the frequency response scale (<italic>M</italic> = 6.02 out of 25, <italic>SD</italic> = 3.70), <italic>F</italic>(1, 129) = 17.0, <italic>p</italic> &lt; .0005). This result suggests that in the dichotomous-scale condition, some nontrivial fraction of respondents who engaged in a QRP only a small number of times reported that they had never engaged in it. This suggests that the prevalence rates obtained in the main study are conservative. There was no effect of the wording manipulation.</p>
<p>We explored the response-scale effect further by comparing the distribution of responses between the two response-scale conditions across all 25 items and collapsing across the wording manipulation (<xref ref-type="fig" rid="fig3-0956797611430953">Fig. 3</xref>). Among the affirmative responses in the frequency-response-scale condition (i.e., responses of <italic>once or twice, occasionally</italic>, or <italic>frequently</italic>), 64% (i.e., .153/(.151 + .062 + .023)) of the affirmative responses fell into the <italic>once or twice</italic> category, a nontrivial percentage fell into <italic>occasionally</italic> (26%), and 10% fell into <italic>frequently</italic>. This result suggests that the prevalence estimates from the BTS study represent a combination of single-instance and habitual engagement in the behaviors.</p>
<fig id="fig3-0956797611430953" position="float">
<label>Fig. 3.</label>
<caption>
<p>Results of the follow-up study: distribution of responses among participants who were asked whether they had engaged in 25 questionable research practices. Participants answered using either (a) a frequency response scale or (b) a dichotomous response scale.</p>
</caption>
<graphic xlink:href="10.1177_0956797611430953-fig3.tif"/>
</fig>
</sec>
<sec id="section8-0956797611430953">
<title>Subgroup differences</title>
<p><xref ref-type="table" rid="table2-0956797611430953">Table 2</xref> presents self-admission rates as a function of disciplines within psychology and the primary methodology used in research. Relatively high rates of QRPs were self-reported among the cognitive, neuroscience, and social disciplines, and among researchers using behavioral, experimental, and laboratory methodologies (for details, see Data Analysis in the Supplemental Material). Clinical psychologists reported relatively low rates of QRPs.</p>
<table-wrap id="table2-0956797611430953" position="float">
<label>Table 2.</label>
<caption>
<p>Mean Self-Admission Rate, Applicability Rating, and Defensibility Rating by Category of Research</p>
</caption>
<graphic alternate-form-of="table2-0956797611430953" xlink:href="10.1177_0956797611430953-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Category of research</th>
<th align="left">Self-admission rate (%)</th>
<th align="left">Applicability rating</th>
<th align="left">Defensibility rating</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="4">Discipline</td>
</tr>
<tr>
<td> Clinical</td>
<td>27<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref></td>
<td>2.59 (0.94)</td>
<td>0.56 (0.28)</td>
</tr>
<tr>
<td> Cognitive</td>
<td>37<xref ref-type="table-fn" rid="table-fn3-0956797611430953">***</xref></td>
<td>2.75<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref> (0.93)</td>
<td>0.64 (0.23)</td>
</tr>
<tr>
<td> Developmental</td>
<td>31</td>
<td>2.77<xref ref-type="table-fn" rid="table-fn3-0956797611430953">**</xref> (0.89)</td>
<td>0.66 (0.27)</td>
</tr>
<tr>
<td> Forensic</td>
<td>28</td>
<td>3.02<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref> (1.12)</td>
<td>0.52 (0.29)</td>
</tr>
<tr>
<td> Health</td>
<td>30</td>
<td>2.56 (0.94)</td>
<td>0.69 (0.31)</td>
</tr>
<tr>
<td> Industrial organizational</td>
<td>31</td>
<td>2.80 (0.63)</td>
<td>0.73 (0.30)</td>
</tr>
<tr>
<td> Neuroscience</td>
<td>35<xref ref-type="table-fn" rid="table-fn3-0956797611430953">**</xref></td>
<td>2.71 (0.92)</td>
<td>0.61 (0.21)</td>
</tr>
<tr>
<td> Personality</td>
<td>32</td>
<td>2.65<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref> (0.92)</td>
<td>0.66 (0.36)</td>
</tr>
<tr>
<td> Social</td>
<td>40<xref ref-type="table-fn" rid="table-fn3-0956797611430953">***</xref></td>
<td>2.89<xref ref-type="table-fn" rid="table-fn3-0956797611430953">***</xref> (0.85)</td>
<td>0.73<xref ref-type="table-fn" rid="table-fn3-0956797611430953">**</xref> (0.31)</td>
</tr>
<tr>
<td colspan="4">Research type</td>
</tr>
<tr>
<td> Clinical</td>
<td>30</td>
<td>2.61 (0.99)</td>
<td>0.56 (0.27)</td>
</tr>
<tr>
<td> Behavioral</td>
<td>34<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref></td>
<td>2.77<xref ref-type="table-fn" rid="table-fn3-0956797611430953">**</xref> (0.88)</td>
<td>0.63 (0.28)</td>
</tr>
<tr>
<td> Laboratory</td>
<td>36<xref ref-type="table-fn" rid="table-fn3-0956797611430953">***</xref></td>
<td>2.87<xref ref-type="table-fn" rid="table-fn3-0956797611430953">***</xref> (0.86)</td>
<td>0.66 (0.29)</td>
</tr>
<tr>
<td> Field</td>
<td>31</td>
<td>2.76<xref ref-type="table-fn" rid="table-fn3-0956797611430953">**</xref> (0.88)</td>
<td>0.63 (0.28)</td>
</tr>
<tr>
<td> Experimental</td>
<td>36<xref ref-type="table-fn" rid="table-fn3-0956797611430953">***</xref></td>
<td>2.83<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref> (0.87)</td>
<td>0.66<xref ref-type="table-fn" rid="table-fn3-0956797611430953">*</xref> (0.29)</td>
</tr>
<tr>
<td> Modeling</td>
<td>33</td>
<td>2.74 (0.89)</td>
<td>0.62 (0.26)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0956797611430953"><p>Note: Self-admission rates are from the main study and are collapsed across all 10 items; applicability and defensibility ratings are from the follow-up study. Applicability was rated on a 4-point scale (1 = <italic>never applicable</italic>, 2 = <italic>sometimes applicable</italic>, 3 = <italic>often applicable</italic>, 4 = <italic>always applicable</italic>). Defensibility was rated on a 3-point scale (0 = <italic>no</italic>, 1 = <italic>possibly</italic>, 2 = <italic>yes</italic>). For self-admission rates, random-effects logistic regression was used to identify significant effects; for applicability and defensibility ratings, random-effects ordered probit regressions were used to identify significant effects.</p></fn>
<fn id="table-fn3-0956797611430953">
<label>*</label>
<p><italic>p</italic> &lt; .05. **<italic>p</italic> &lt; .01. ***<italic>p</italic> &lt; .0005.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>These subgroup differences could reflect the particular relevance of our QRPs to these disciplines and methodologies, or they could reflect differences in perceived defensibility of the behaviors. To explore these possible explanations, we sent a brief follow-up survey to 1,440 of the participants in the main study, which asked them to rate two aspects of the same 10 QRPs. First, they were asked to rate the extent to which each practice applies to their research methodology (i.e., how frequently, if at all, they encountered the opportunity to engage in the practice). The possible responses were <italic>never applicable, sometimes applicable, often applicable</italic>, and <italic>always applicable</italic>. Second, they were asked whether it is generally defensible to engage in each practice. The possible responses were <italic>indefensible, possibly defensible</italic>, and <italic>defensible</italic>. Unlike in the main study, in which respondents were asked to provide a defensibility rating only if they had admitted to having engaged in a given practice, all respondents in the follow-up survey were asked to provide these ratings. We counterbalanced the order in which respondents rated the two dimensions. There were 504 respondents, for a response rate of 35%. Of respondents who began the survey, 65 (12.9%) did not complete it; as in the main study, data from all respondents—even those who did not finish the survey—were included in the analysis because the QRPs were presented in randomized order.</p>
<p><xref ref-type="table" rid="table2-0956797611430953">Table 2</xref> presents the results from the follow-up survey. The subgroup differences in applicability ratings and defensibility ratings were partially consistent with the differences in self-reported prevalence: Most notably, mean applicability and defensibility ratings were elevated among social psychologists—a subgroup with relatively high self-admission rates. Similarly, the items were particularly applicable to (but not judged to be more defensible by) researchers who conduct behavioral, experimental, and laboratory research.</p>
<p>To test for the relative importance of applicability and defensibility ratings in explaining subfield differences, we conducted an analysis of variance on mean self-admission rates across QRPs and disciplines. Both type of QRP (<italic>p</italic> &lt; .001, η<sub><italic>p</italic></sub><sup>2</sup> = .87) and subfield (<italic>p</italic> &lt; .05, η<sub><italic>p</italic></sub><sup>2</sup> = .21) were highly significant predictors of self-admission rates, and their significance and effect size were largely unchanged after controlling for applicability and defensibility ratings, even though both of the latter variables were highly significant independent predictors of mean self-admission rates. Similarly, methodology was also a highly significant predictor of self-admission rates (<italic>p</italic> &lt; .05, η<sub><italic>p</italic></sub><sup>2</sup> = .27), and its significance and effect size were largely unchanged after controlling for applicability and defensibility ratings (even though the latter were highly significant predictors of self-admission rates).</p>
<p>The defensibility ratings obtained in the main study stand in contrast with those obtained in the follow-up survey: Respondents considered these behaviors to be defensible when they engaged in them (as was shown in the main study) but considered them indefensible overall (as was shown in the follow-up study).</p>
</sec>
</sec>
<sec id="section9-0956797611430953" sec-type="discussion">
<title>Discussion</title>
<p>Concerns over scientific misconduct have led previous researchers to estimate the prevalence of QRPs that are broadly applicable to scientists (<xref ref-type="bibr" rid="bibr24-0956797611430953">Martinson et al., 2005</xref>). In light of recent concerns over scientific integrity within psychology, we designed this study to provide accurate estimates of the prevalence of QRPs that are specifically applicable to research psychologists. In addition to being one of the first studies to specifically target research psychologists, it is also the first to test the effectiveness of an incentive-compatible elicitation format that measures prevalence rates in three different ways.</p>
<p>All three prevalence measures point to the same conclusion: A surprisingly high percentage of psychologists admit to having engaged in QRPs. The effect of the BTS manipulation on self-admission rates was positive, and greater for practices that respondents judge to be less defensible. Beyond revealing the prevalence of QRPs, this study is also, to our knowledge, the first to illustrate that an incentive-compatible information-elicitation method can lead to higher, and likely more valid, prevalence estimates of sensitive behaviors. This method could easily be used to estimate the prevalence of other sensitive behaviors, such as illegal or sexual activities. For potentially even greater benefit, BTS-based truth-telling incentives could be combined with audio computer-assisted self-interviewing—a technology that has been found to increase self-reporting of sensitive behaviors (<xref ref-type="bibr" rid="bibr36-0956797611430953">Turner et al., 1998</xref>).</p>
<p>There are two primary components to the BTS procedure—both a request and an incentive to tell the truth—and we were unable to isolate their independent effects on disclosure. However, both components rewarded respondents for telling the truth, not for simply responding “yes” regardless of whether they had engaged in the behaviors. Therefore, both components were designed to increase the validity of responses. Future research could test the relative contribution of the various BTS components in eliciting truthful responses.</p>
<p>This research was based on the premise that higher prevalence estimates are more valid—an assumption that pervades a large body of research designed to assess the prevalence of sensitive behaviors (<xref ref-type="bibr" rid="bibr3-0956797611430953">Bradburn &amp; Sudman, 1979</xref>; <xref ref-type="bibr" rid="bibr7-0956797611430953">de Jong, Pieters, &amp; Fox, 2010</xref>; <xref ref-type="bibr" rid="bibr21-0956797611430953">Lensvelt-Mulders, Hox, van der Heijden, &amp; Maas, 2005</xref>; <xref ref-type="bibr" rid="bibr35-0956797611430953">Tourangeau &amp; Yan, 2007</xref>; <xref ref-type="bibr" rid="bibr37-0956797611430953">Warner, 1965</xref>). This assumption is generally accepted, provided that the behaviors in question are sensitive or socially undesirable. The rationale is that respondents are unlikely to be tempted to admit to shameful behaviors in which they have not engaged; instead, they are prone to denying involvement in behaviors in which they actually have engaged (<xref ref-type="bibr" rid="bibr10-0956797611430953">Fanelli, 2009</xref>). We think this assumption is also defensible in the present study given its subject matter.</p>
<p>As noted in the introduction, there is a large gray area of acceptable practices. Although falsifying data (Item 10 in our study) is never justified, the same cannot be said for all of the items on our survey; for example, failing to report all of a study’s dependent measures (Item 1) could be appropriate if two measures of the same construct show the same significant pattern of results but cannot be easily combined into one measure. Therefore, not all self-admissions represent scientific felonies, or even misdemeanors; some respondents provided perfectly defensible reasons for engaging in the behaviors. Yet other respondents provided justifications that, although self-categorized as defensible, were contentious (e.g., dropping dependent measures inconsistent with the hypothesis because doing so enabled a more coherent story to be told and thus increased the likelihood of publication). It is worth noting, however, that in the follow-up survey—in which participants rated the behaviors regardless of personal engagement—the defensibility ratings were low. This suggests that the general sentiment is that these behaviors are unjustifiable.</p>
<p>We assume that the vast majority of researchers are sincerely motivated to conduct sound scientific research. Furthermore, most of the respondents in our study believed in the integrity of their own research and judged practices they had engaged in to be acceptable. However, given publication pressures and professional ambitions, the inherent ambiguity of the defensibility of “questionable” research practices, and the well-documented ubiquity of motivated reasoning (<xref ref-type="bibr" rid="bibr18-0956797611430953">Kunda, 1990</xref>), researchers may not be in the best position to judge the defensibility of their own behavior. This could in part explain why the most egregious practices in our survey (e.g., falsifying data) appear to be less common than the relatively less questionable ones (e.g., failing to report all of a study’s conditions). It is easier to generate a post hoc explanation to justify removing nuisance data points than it is to justify outright data falsification, even though both practices produce similar consequences.</p>
<p>Given the findings of our study, it comes as no surprise that many researchers have expressed concerns over failures to replicate published results (<xref ref-type="bibr" rid="bibr2-0956797611430953">Bower &amp; Mayer, 1985</xref>; <xref ref-type="bibr" rid="bibr4-0956797611430953">Crabbe, Wahlsten, &amp; Dudek, 1999</xref>; <xref ref-type="bibr" rid="bibr8-0956797611430953">Doyen, Klein, Pichon, &amp; Cleeremans, 2012</xref>, <xref ref-type="bibr" rid="bibr9-0956797611430953">Enserink, 1999</xref>; <xref ref-type="bibr" rid="bibr11-0956797611430953">Galak, LeBoeuf, Nelson, &amp; Simmons, 2012</xref>; <xref ref-type="bibr" rid="bibr16-0956797611430953">Ioannidis, 2005a</xref>, <xref ref-type="bibr" rid="bibr17-0956797611430953">2005b</xref>; <xref ref-type="bibr" rid="bibr25-0956797611430953">Palmer, 2000</xref>; <xref ref-type="bibr" rid="bibr30-0956797611430953">Steele, Bass, &amp; Crook, 1999</xref>). In an article on the problem of nonreplicability, <xref ref-type="bibr" rid="bibr20-0956797611430953">Lehrer (2010)</xref> discussed possible explanations for the “decline effect”—the tendency for effect sizes to decrease with subsequent attempts at replication. He concluded that conventional accounts of this effect (regression to the mean, publication bias) may be incomplete. In a subsequent and insightful commentary, <xref ref-type="bibr" rid="bibr27-0956797611430953">Schooler (2011)</xref> suggested that unpublished data may help to account for the decline effect. By documenting the surprisingly large percentage of researchers who have engaged in QRPs—including selective omission of observations, experimental conditions, and studies from the scientific record—the present research provides empirical support for Schooler’s claim. <xref ref-type="bibr" rid="bibr28-0956797611430953">Simmons and his colleagues (2011)</xref> went further by showing how easily QRPs can yield invalid findings and by proposing reforms in the process of reporting research and accepting scientific manuscripts for publication.</p>
<p>QRPs can waste researchers’ time and stall scientific progress, as researchers fruitlessly pursue extensions of effects that are not real and hence cannot be replicated. More generally, the prevalence of QRPs raises questions about the credibility of research findings and threatens research integrity by producing unrealistically elegant results that may be difficult to match without engaging in such practices oneself. This can lead to a “race to the bottom,” with questionable research begetting even more questionable research. If reforms would effectively reduce the prevalence of QRPs, they not only would bolster scientific integrity but also could reduce the pressure on researchers to produce unrealistically elegant results.</p>
</sec>
</body>
<back>
<ack>
<p>We thank Evan Robinson for implementing the e-mail procedure that tracked participation while ensuring respondents’ anonymity. We also thank Anne-Sophie Charest and Bill Simpson for statistical consulting and members of the Center for Behavioral Decision Research for their input on initial drafts of the survey items.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p>
</fn>
<fn fn-type="supplementary-material">
<p>Additional supporting information may be found at <ext-link ext-link-type="uri" xlink:href="http://pss.sagepub.com/content/by/supplemental-data">http://pss.sagepub.com/content/by/supplemental-data</ext-link></p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0956797611430953">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Altman</surname><given-names>L. K.</given-names></name>
</person-group> (<year>2006</year>, <month>May</month> <day>2</day>). <article-title>For science gatekeepers, a credibility gap</article-title>. <source>The New York Times</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.nytimes.com/2006/05/02/health/02docs.html?pagewanted=all">http://www.nytimes.com/2006/05/02/health/02docs.html?pagewanted=all</ext-link></comment></citation>
</ref>
<ref id="bibr2-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bower</surname><given-names>G. H.</given-names></name>
<name><surname>Mayer</surname><given-names>J. D.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Failure to replicate mood-dependent retrieval</article-title>. <source>Bulletin of the Psychonomic Society</source>, <volume>23</volume>, <fpage>39</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr3-0956797611430953">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bradburn</surname><given-names>N.</given-names></name>
<name><surname>Sudman</surname><given-names>S.</given-names></name>
</person-group> (<year>1979</year>). <source>Improving interview method and questionnaire design: Response effects to threatening questions in survey research</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</citation>
</ref>
<ref id="bibr4-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Crabbe</surname><given-names>J. C.</given-names></name>
<name><surname>Wahlsten</surname><given-names>D.</given-names></name>
<name><surname>Dudek</surname><given-names>B. C.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Genetics of mouse behavior: Interactions with laboratory environment</article-title>. <source>Science</source>, <volume>284</volume>, <fpage>1670</fpage>–<lpage>1672</lpage>.</citation>
</ref>
<ref id="bibr5-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Crocker</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The road to fraud starts with a single step</article-title>. <source>Nature</source>, <volume>479</volume>, <fpage>151</fpage>.</citation>
</ref>
<ref id="bibr6-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Deer</surname><given-names>B.</given-names></name>
</person-group> (<year>2011</year>). <article-title>How the case against the MMR vaccine was fixed</article-title>. <source>British Medical Journal</source>, <volume>342</volume>, <fpage>77</fpage>–<lpage>82</lpage>.</citation>
</ref>
<ref id="bibr7-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>de Jong</surname><given-names>M. G.</given-names></name>
<name><surname>Pieters</surname><given-names>R.</given-names></name>
<name><surname>Fox</surname><given-names>J.-P</given-names></name>
</person-group>. (<year>2010</year>). <article-title>Reducing social desirability bias through item randomized response: An application to measure underreported desires</article-title>. <source>Journal of Marketing Research</source>, <volume>47</volume>, <fpage>14</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr8-0956797611430953">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Doyen</surname><given-names>S.</given-names></name>
<name><surname>Klein</surname><given-names>O.</given-names></name>
<name><surname>Pichon</surname><given-names>C.-L.</given-names></name>
<name><surname>Cleeremans</surname><given-names>A.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Behavioral priming: It’s all in the mind, but whose mind?</article-title> <source>PLoS ONE</source>, <volume>7</volume>(<issue>1</issue>), <fpage>e29081.</fpage> <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029081">http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029081</ext-link></comment></citation>
</ref>
<ref id="bibr9-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Enserink</surname><given-names>M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Fickle mice highlight test problems</article-title>. <source>Science</source>, <volume>284</volume>, <fpage>1599</fpage>–<lpage>1600</lpage>.</citation>
</ref>
<ref id="bibr10-0956797611430953">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Fanelli</surname><given-names>D.</given-names></name>
</person-group> (<year>2009</year>). <article-title>How many scientists fabricate and falsify research? A systematic review and meta-analysis of survey data</article-title>. <source>PLoS One</source>, <volume>4</volume>(<issue>5</issue>), <fpage>e5738</fpage>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0005738">http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0005738</ext-link></comment></citation>
</ref>
<ref id="bibr11-0956797611430953">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Galak</surname><given-names>J.</given-names></name>
<name><surname>LeBoeuf</surname><given-names>R. A.</given-names></name>
<name><surname>Nelson</surname><given-names>L. D.</given-names></name>
<name><surname>Simmons</surname><given-names>J. P.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Correcting the past: Failures to replicate psi</article-title>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2001721">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2001721</ext-link></comment></citation>
</ref>
<ref id="bibr12-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gardner</surname><given-names>W.</given-names></name>
<name><surname>Lidz</surname><given-names>C. W.</given-names></name>
<name><surname>Hartwig</surname><given-names>K. C.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Authors’ reports about research integrity problems in clinical trials</article-title>. <source>Contemporary Clinical Trials</source>, <volume>26</volume>, <fpage>244</fpage>–<lpage>251</lpage>.</citation>
</ref>
<ref id="bibr13-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Geggie</surname><given-names>D.</given-names></name>
</person-group> (<year>2001</year>). <article-title>A survey of newly appointed consultants’ attitudes towards research fraud</article-title>. <source>Journal of Medical Ethics</source>, <volume>27</volume>, <fpage>344</fpage>–<lpage>346</lpage>.</citation>
</ref>
<ref id="bibr14-0956797611430953">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Guttman</surname><given-names>L. L.</given-names></name>
</person-group> (<year>1974</year>). <article-title>The basis for scalogram analysis</article-title>. In <person-group person-group-type="editor">
<name><surname>Maranell</surname><given-names>G. M.</given-names></name>
</person-group> (Ed.), <source>Scaling: A sourcebook for behavioral scientists</source> (pp. <fpage>142</fpage>–<lpage>171</lpage>). <publisher-loc>New Brunswick, NJ</publisher-loc>: <publisher-name>Transaction</publisher-name>.</citation>
</ref>
<ref id="bibr15-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henry</surname><given-names>D. A.</given-names></name>
<name><surname>Kerridge</surname><given-names>I. H.</given-names></name>
<name><surname>Hill</surname><given-names>S. R.</given-names></name>
<name><surname>McNeill</surname><given-names>P. M.</given-names></name>
<name><surname>Doran</surname><given-names>E.</given-names></name>
<name><surname>Newby</surname><given-names>D. A.</given-names></name>
<name><surname>. . . Day</surname><given-names>R. O.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Medical specialists and pharmaceutical industry-sponsored research: A survey of the Australian experience</article-title>. <source>Medical Journal of Australia</source>, <volume>182</volume>, <fpage>557</fpage>–<lpage>560</lpage>.</citation>
</ref>
<ref id="bibr16-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name>
</person-group> (<year>2005a</year>). <article-title>Contradicted and initially stronger effects in highly cited clinical research</article-title>. <source>Journal of the American Medical Association</source>, <volume>294</volume>, <fpage>218</fpage>–<lpage>228</lpage>.</citation>
</ref>
<ref id="bibr17-0956797611430953">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name>
</person-group> (<year>2005b</year>). <article-title>Why most published research findings are false</article-title>. <source>PLoS Medicine</source>, <volume>2</volume>(<issue>8</issue>), <fpage>e124</fpage>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.0020124">http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.0020124</ext-link></comment></citation>
</ref>
<ref id="bibr18-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kunda</surname><given-names>Z.</given-names></name>
</person-group> (<year>1990</year>). <article-title>The case for motivated reasoning</article-title>. <source>Psychological Bulletin</source>, <volume>108</volume>, <fpage>480</fpage>–<lpage>498</lpage>.</citation>
</ref>
<ref id="bibr19-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lacetera</surname><given-names>N.</given-names></name>
<name><surname>Zirulia</surname><given-names>L.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The economics of scientific misconduct</article-title>. <source>The Journal of Law, Economics, &amp; Organization</source>, <volume>27</volume>, <fpage>568</fpage>–<lpage>603</lpage>.</citation>
</ref>
<ref id="bibr20-0956797611430953">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Lehrer</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>, <month>December</month> <day>13</day>). <article-title>The truth wears off</article-title>. <source>The New Yorker</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.newyorker.com/reporting/2010/12/13/101213fa_fact_lehrer">http://www.newyorker.com/reporting/2010/12/13/101213fa_fact_lehrer</ext-link></comment></citation>
</ref>
<ref id="bibr21-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lensvelt-Mulders</surname><given-names>G. J. L. M.</given-names></name>
<name><surname>Hox</surname><given-names>J. J.</given-names></name>
<name><surname>van der Heijden</surname><given-names>P. G. M.</given-names></name>
<name><surname>Maas</surname><given-names>C. J. M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Meta-analysis of randomized response research: Thirty-five years of validation</article-title>. <source>Sociological Methods &amp; Research</source>, <volume>33</volume>, <fpage>319</fpage>–<lpage>348</lpage>.</citation>
</ref>
<ref id="bibr22-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>List</surname><given-names>J.</given-names></name>
<name><surname>Bailey</surname><given-names>C.</given-names></name>
<name><surname>Euzent</surname><given-names>P.</given-names></name>
<name><surname>Martin</surname><given-names>T.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Academic economists behaving badly? A survey on three areas of unethical behavior</article-title>. <source>Economic Inquiry</source>, <volume>39</volume>, <fpage>162</fpage>–<lpage>170</lpage>.</citation>
</ref>
<ref id="bibr23-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marshall</surname><given-names>E.</given-names></name>
</person-group> (<year>2000</year>). <article-title>How prevalent is fraud? That’s a million-dollar question</article-title>. <source>Science</source>, <volume>290</volume>, <fpage>1662</fpage>–<lpage>1663</lpage>.</citation>
</ref>
<ref id="bibr24-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Martinson</surname><given-names>B. C.</given-names></name>
<name><surname>Anderson</surname><given-names>M. S.</given-names></name>
<name><surname>de Vries</surname><given-names>R.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Scientists behaving badly</article-title>. <source>Nature</source>, <volume>435</volume>, <fpage>737</fpage>–<lpage>738</lpage>.</citation>
</ref>
<ref id="bibr25-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Palmer</surname><given-names>A. R.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Quasireplication and the contract of error: Lessons from sex ratios, heritabilities, and fluctuating asymmetry</article-title>. <source>Annual Review of Ecology and Systematics</source>, <volume>31</volume>, <fpage>441</fpage>–<lpage>480</lpage>.</citation>
</ref>
<ref id="bibr26-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Prelec</surname><given-names>D.</given-names></name>
</person-group> (<year>2004</year>). <article-title>A Bayesian truth serum for subjective data</article-title>. <source>Science</source>, <volume>306</volume>, <fpage>462</fpage>–<lpage>466</lpage>.</citation>
</ref>
<ref id="bibr27-0956797611430953">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Schooler</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Unpublished results hide the decline effect</article-title>. <source>Nature</source>, <volume>470</volume>, <fpage>437</fpage>.</citation>
</ref>
<ref id="bibr28-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simmons</surname><given-names>J. P.</given-names></name>
<name><surname>Nelson</surname><given-names>L. D.</given-names></name>
<name><surname>Simonsohn</surname><given-names>U.</given-names></name>
</person-group> (<year>2011</year>). <article-title>False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title>. <source>Psychological Science</source>, <volume>22</volume>, <fpage>1359</fpage>–<lpage>1366</lpage>.</citation>
</ref>
<ref id="bibr29-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sovacool</surname><given-names>B.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Exploring scientific misconduct: Isolated individuals, impure institutions, or an inevitable idiom of modern science?</article-title> <source>Journal of Bioethical Inquiry</source>, <volume>5</volume>, <fpage>271</fpage>–<lpage>282</lpage>.</citation>
</ref>
<ref id="bibr30-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Steele</surname><given-names>K. M.</given-names></name>
<name><surname>Bass</surname><given-names>K. E.</given-names></name>
<name><surname>Crook</surname><given-names>M. D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>The mystery of the Mozart effect: Failure to replicate</article-title>. <source>Psychological Science</source>, <volume>10</volume>, <fpage>366</fpage>–<lpage>369</lpage>.</citation>
</ref>
<ref id="bibr31-0956797611430953">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Steneck</surname><given-names>N. H.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Assessing the integrity of publicly supported research</article-title>. In <person-group person-group-type="editor">
<name><surname>Steneck</surname><given-names>N. H.</given-names></name>
<name><surname>Scheetz</surname><given-names>M. D.</given-names></name>
</person-group> (Eds.), <source>Investigating Research Integrity: Proceedings of the First ORI Research Conference on Research Integrity</source> (pp. <fpage>1</fpage>–<lpage>16</lpage>). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Office of Research Integrity</publisher-name>.</citation>
</ref>
<ref id="bibr32-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Steneck</surname><given-names>N. H.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Fostering integrity in research: Definitions, current knowledge, and future directions</article-title>. <source>Science and Engineering Ethics</source>, <volume>12</volume>, <fpage>53</fpage>–<lpage>74</lpage>.</citation>
</ref>
<ref id="bibr33-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sterba</surname><given-names>S. K.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Misconduct in the analysis and reporting of data: Bridging methodological and ethical agendas for change</article-title>. <source>Ethics &amp; Behavior</source>, <volume>16</volume>, <fpage>305</fpage>–<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr34-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Swazey</surname><given-names>J. P.</given-names></name>
<name><surname>Anderson</surname><given-names>M. S.</given-names></name>
<name><surname>Louis</surname><given-names>K. S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Ethical problems in academic research</article-title>. <source>American Scientist</source>, <volume>81</volume>, <fpage>542</fpage>–<lpage>553</lpage>.</citation>
</ref>
<ref id="bibr35-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tourangeau</surname><given-names>R.</given-names></name>
<name><surname>Yan</surname><given-names>T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Sensitive questions in surveys</article-title>. <source>Psychological Bulletin</source>, <volume>133</volume>, <fpage>859</fpage>–<lpage>883</lpage>.</citation>
</ref>
<ref id="bibr36-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Turner</surname><given-names>C. F.</given-names></name>
<name><surname>Ku</surname><given-names>L.</given-names></name>
<name><surname>Rogers</surname><given-names>S. M.</given-names></name>
<name><surname>Lindberg</surname><given-names>L. D.</given-names></name>
<name><surname>Pleck</surname><given-names>J. H.</given-names></name>
<name><surname>Sonenstein</surname><given-names>F. L.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Adolescent sexual behavior, drug use, and violence: Increased reporting with computer survey technology</article-title>. <source>Science</source>, <volume>280</volume>, <fpage>867</fpage>–<lpage>873</lpage>.</citation>
</ref>
<ref id="bibr37-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Warner</surname><given-names>S. L.</given-names></name>
</person-group> (<year>1965</year>). <article-title>Randomized response: A survey technique for eliminating evasive answer bias</article-title>. <source>Journal of the American Statistical Association</source>, <volume>60</volume>, <fpage>63</fpage>–<lpage>69.</lpage></citation>
</ref>
<ref id="bibr38-0956797611430953">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wicherts</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Psychology must learn a lesson from fraud case</article-title>. <source>Nature</source>, <volume>480</volume>, <fpage>7</fpage>.</citation>
</ref>
</ref-list>
</back>
</article>