<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PIB</journal-id>
<journal-id journal-id-type="hwp">sppib</journal-id>
<journal-title>Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture</journal-title>
<issn pub-type="ppub">0954-4054</issn>
<issn pub-type="epub">2041-1975</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0954405412457121</article-id>
<article-id pub-id-type="publisher-id">10.1177_0954405412457121</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Prediction of workpiece dynamic motion using an optimized artificial neural network</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Vishnupriyan</surname><given-names>S</given-names></name>
<xref ref-type="aff" rid="aff1-0954405412457121">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Muruganandam</surname><given-names>A</given-names></name>
<xref ref-type="aff" rid="aff2-0954405412457121">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Govindarajan</surname><given-names>L</given-names></name>
<xref ref-type="aff" rid="aff3-0954405412457121">3</xref>
</contrib>
</contrib-group>
<aff id="aff1-0954405412457121"><label>1</label>Department of Mechanical and Industrial Engineering, Caledonian College of Engineering, Sultanate of Oman</aff>
<aff id="aff2-0954405412457121"><label>2</label>Department of Mechanical Engineering, PSNA College of Engineering and Technology, India</aff>
<aff id="aff3-0954405412457121"><label>3</label>Department of Process Operations Technology, International Maritime College, Sultanate of Oman</aff>
<author-notes>
<corresp id="corresp1-0954405412457121">S Vishnupriyan, Department of Mechanical and Industrial Engineering, Caledonian College of Engineering, Muscat, Sultanate of Oman. Email: <email>svishnupriyan@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>226</volume>
<issue>10</issue>
<issue-title>Special Issue on ‘Sustainable Manufacturing and the Key Enabling Technologies’</issue-title>
<fpage>1705</fpage>
<lpage>1716</lpage>
<history>
<date date-type="received">
<day>28</day>
<month>3</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>11</day>
<month>7</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© IMechE 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Institution of Mechanical Engineers</copyright-holder>
</permissions>
<abstract>
<p>A machining fixture is an element used to hold the workpiece in the desired position and orientation during machining. The overall machining error in a workpiece is a result of different sources of errors in a workpiece–fixture system. One among them is the motion of the workpiece under the action of cutting forces. Evaluation of this dynamic motion is essential for the determination of the overall machining error. Most commonly, the finite element method is employed to compute the workpiece dynamic motion. During optimization of fixture layout, a large number of layouts are generated and the workpiece dynamic motion must be computed for each of the layouts. In such cases, use of the finite element method is prohibitive because of the long computation time required. Also, the results of the finite element analysis are susceptible to different parameters used in the analysis. Hence, an alternate and efficient methodology is necessary to determine the workpiece displacement for a given fixture layout. This article proposes a method of using an artificial neural network for the prediction of workpiece dynamic motion. Different layouts are obtained using a modular fixture and actual machining is performed on the workpiece. For each layout, the workpiece dynamic motion is computed at select datum points and an artificial neural network is trained with these data. To achieve better prediction capability of the artificial neural network and minimize different forms of errors in training and generalization, critical parameters of the artificial neural network are optimized using a genetic algorithm. Then, this optimized network is employed to predict the workpiece dynamic motion for any arbitrary layout. Results show that the optimized artificial neural network is capable of predicting the workpiece dynamic motion with acceptable accuracy (maximum absolute relative error 9.71%). This method, hence, can serve as an economical means of computing the overall machining error during optimization of fixture layouts.</p>
</abstract>
<kwd-group>
<kwd>Fixture design</kwd>
<kwd>dynamic motion</kwd>
<kwd>artificial neural network</kwd>
<kwd>genetic algorithm</kwd>
<kwd>optimization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0954405412457121" sec-type="intro">
<title>Introduction</title>
<p>With more emphasis on the quality of parts, fixture design has evolved as an important area of research. As a workholding device, a machining fixture is responsible for ensuring that the workpiece is held in the required position and orientation during machining. Any error in the fixture design is directly translated as the machining error of the workpiece and hence the machining accuracy is lost. In a workpiece–fixture system (WFS), many sources of error contribute to the final machining error of the workpiece. These include, but are not limited to, the geometric error at locators, compliance at the workpiece–locator contact bulk elasticity of workpiece and workpiece dynamic motion (WDM). As cutting forces are time varying, the workpiece being machined experiences dynamic motion and this has a significant contribution to the final machining error. Because of this reason, many researchers have investigated the effect of the workpiece dynamics and the ways to minimize the same in order to improve workpiece accuracy.</p>
<p>Studies on the dynamics aspect of WFS focus on the modeling of the workpiece fixture contacts, analyzing the dynamic behavior of WFS and optimizing the fixture parameters for minimizing the dynamic motion. Daimon et al.<sup><xref ref-type="bibr" rid="bibr1-0954405412457121">1</xref></sup> presented a method for selecting supports to improve workpiece dynamic rigidity based on a finite element analysis. Mittal et al.<sup><xref ref-type="bibr" rid="bibr2-0954405412457121">2</xref></sup> used the dynamic analysis and design system (DADS) software for analyzing the workpiece dynamics. In their work, the workpiece–fixture contact was modeled using a lumped spring actuator element. Liao and Hu<sup><xref ref-type="bibr" rid="bibr3-0954405412457121">3</xref></sup> extended this work by considering the structural compliance of the workpiece and contact friction. For this purpose, the finite element method (FEM) was used in conjunction with the DADS software. Liao and Hu<sup><xref ref-type="bibr" rid="bibr4-0954405412457121">4</xref></sup> employed a translational spring damper actuator model to represent the workpiece–fixture contact in an attempt to determine the clamping force, clamping point and clamping sequence in the case of time varying machining loads. The FEM was employed to determine the modal coordinates considering the elasticity of the workpiece and locator. Fang et al.<sup><xref ref-type="bibr" rid="bibr5-0954405412457121">5</xref></sup> presented a model to study friction damping considering the dynamics of both workpiece and fixture elements. They attributed the phenomenon of interface locking for the dependency of friction damping on clamping forces.</p>
<p>Deiab and Elbestawi<sup><xref ref-type="bibr" rid="bibr6-0954405412457121">6</xref></sup> analyzed the effect of chip removal on the WFS dynamics using a finite element model. Liu and Strong<sup><xref ref-type="bibr" rid="bibr7-0954405412457121">7</xref></sup> presented a linear programming (LP)-based fixture verification method considering the dynamics of the fixture workpiece system. However, they considered both workpiece and fixture elements to be rigid. Motlagh et al.<sup><xref ref-type="bibr" rid="bibr8-0954405412457121">8</xref></sup> employed a modified version of the Armstrong friction model to study the WFS behavior under dynamic conditions.</p>
<p>The common limitation of the above works is that they did not address the methods of achieving the minimum dynamic motion of the workpiece under the given conditions.</p>
<p>Since the WDM can be minimized by optimizing either or both the fixture layout and clamping forces, attempts have been made on this front. Using a rigid body dynamic model, Li and Melkote<sup><xref ref-type="bibr" rid="bibr9-0954405412457121">9</xref></sup> optimized the fixture layout for minimum WDM. This work did not consider the elasticity of the workpiece and fixture elements. Deng and Melkote<sup><xref ref-type="bibr" rid="bibr10-0954405412457121">10</xref></sup> determined the minimum clamping forces required for fixturing stability using particle swarm optimization (PSO). In this work, the contact elasticity model was used to check the stability of the workpiece under dynamic conditions. Padmanaban and Prabhaharan<sup><xref ref-type="bibr" rid="bibr11-0954405412457121">11</xref></sup> used a genetic algorithm (GA) and ant colony algorithm (ACA), separately, to determine the optimal positions of fixture elements to achieve minimum dynamic displacement of the workpiece. However, in this work, the search space was limited to the node numbers of a finite element model. To overcome this drawback, Padmanaban et al.<sup><xref ref-type="bibr" rid="bibr12-0954405412457121">12</xref></sup> employed a continuous optimization scheme based on the ACA to optimize the fixture layout under dynamic conditions. In this work, the search space was defined as the physical coordinates, thereby enabling a more effective search. In both of these works, simple two-dimensional geometries were considered.</p>
<p>Though these works have provided a solid foundation on the analysis of WFS dynamics, some shortfalls can be noted. First, a systematic methodology to relate the WDM to the machining tolerance is not provided. This is required because, with the machining tolerance given, if the WDM is known <italic>a priori</italic>, following the principles of tolerance accumulation, one can determine how much error can be ‘shared’ by the other error sources mentioned earlier.</p>
<p>Second, limitation lies in the approach to layout optimization. Some of the above works sought to optimize the layout or clamping forces in an attempt to minimize the WDM. But most of these studies employed finite element models and are not based on experimental methods. Using the FEM has some limitations. To achieve a realistic model of workpiece–fixture contact, both of them must be modeled as elastic members. For such modeling, even a static analysis based on the FEM is computationally intensive.<sup><xref ref-type="bibr" rid="bibr13-0954405412457121">13</xref></sup> For dynamic analyses, this problem is more acute. It is not uncommon to see the software requiring hours of time for completing a single iteration. In an optimization process, the number of layouts is so large in number that analyzing each layout using the FEM is prohibitive. The other limitation is in the form of non-uniqueness of the results of the FEM-based analyses. It is known that the results of a finite element analysis depend largely on the parameters used in the study. This may include modeling of contacts, mesh size and element shape and type.<sup><xref ref-type="bibr" rid="bibr14-0954405412457121">14</xref></sup> In other words, different finite element analyses performed on the same WFS can produce different results, the degree of variation being case-based.</p>
<p>Owing to the above reasons, a computationally efficient method of determining the WDM is warranted. Such a method should be capable of simulating the actual machining conditions in a better way and it should also be economical in terms of computational time.</p>
<p>This article proposes the use of an optimized artificial neural network (ANN) for predicting the dynamic motion of a real, three dimensional workpiece. The dynamics of a workpiece–fixture system is complex and there is no direct mathematical relationship available to correlate the fixture layout to the workpiece motion owing to dynamics. It is because of this reason that the use of ANNs is promising for this application of predicting WDM. In the present work, the case of a prismatic workpiece being machined in a typical 3-2-1 fixture set-up is considered and the WDM for different layouts is captured experimentally. The prediction accuracy of an ANN is influenced by various parameters used in its architecture. Hence, a suitable model of ANN is identified and its critical parameters are optimized using a GA. Then the network is trained with the experimental data so that it can predict the WDM for an arbitrarily generated layout.</p>
</sec>
<sec id="section2-0954405412457121">
<title>Dynamic motion and machining error</title>
<p>The workpiece is subject to time-varying cutting forces during machining. This induces vibration in the workpiece and the vibration amplitude depends on many factors, like fixture design, machine tool rigidity and cutting conditions. <xref ref-type="fig" rid="fig1-0954405412457121">Figure 1</xref> depicts a representative workpiece surface that vibrates. The cutter path is pre-defined and does not change during cutting. But, since the workpiece has displaced owing to vibration, the cutter “meets” the workpiece at a point different than the intended one. This point is away by a distance shown exaggerated as δ and this deviation directly amounts to an error. It should be noted that the workpiece vibratory motion is possible in all six degrees of freedom (three translations and three rotations) and, hence, the error, called a dynamics related error, is a vector, written as δ<bold><italic>m</italic></bold><sub>d</sub> given by</p>
<fig id="fig1-0954405412457121" position="float">
<label>Figure 1.</label>
<caption><p>Error due to dynamic motion of the workpiece.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig1.tif"/>
</fig>
<p><disp-formula id="disp-formula1-0954405412457121">
<label>(1)</label>
<mml:math display="block" id="math1-0954405412457121">
<mml:mrow>
<mml:mi>δ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold-italic">m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>d</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>δ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>x</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>δ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>y</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>δ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>z</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>x</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>y</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>z</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0954405412457121" xlink:href="10.1177_0954405412457121-eq1.tif"/>
</disp-formula></p>
<p>But, depending on how the tolerance is specified in the critical machining feature of the workpiece, dynamic motion along one or more directions would be of interest. For example, if the tolerance is specified on the <italic>Y</italic> direction, only δ<sub>y</sub> requires to be considered.</p>
<p>As mentioned above, since the motion of the cutting tool is fixed for a given machining operation, evaluation of machining error can be equivalently transformed into the evaluation of the variation of the processing datum with respect to the global coordinate system (GCS).<sup><xref ref-type="bibr" rid="bibr15-0954405412457121">15</xref></sup> Variation of the processing datum is measured by computing the variation of certain representative points along the datum. These points are known as processing datum points. Maximum variation experienced among those points is the final machining error of the critical feature of the workpiece. Stated mathematically</p>
<p><disp-formula id="disp-formula2-0954405412457121">
<label>(2)</label>
<mml:math display="block" id="math2-0954405412457121">
<mml:mrow>
<mml:mi>δ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>i</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>max</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>abs</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>δ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mi>δ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo>…</mml:mo>
<mml:mi>δ</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>n</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0954405412457121" xlink:href="10.1177_0954405412457121-eq2.tif"/>
</disp-formula></p>
<p>where <italic>i</italic> refers to the <italic>X, Y, Z</italic> directions and <italic>n</italic> is the number of processing datum points.</p>
</sec>
<sec id="section3-0954405412457121">
<title>Proposed approach</title>
<p>The task at hand is to arrive at a new, computationally efficient methodology for determining the WDM for a given fixture layout. To achieve the stated aim, this article proposes an ANN-based method depicted in <xref ref-type="fig" rid="fig2-0954405412457121">Figure 2</xref>. The method involves the following steps.</p>
<fig id="fig2-0954405412457121" position="float">
<label>Figure 2.</label>
<caption><p>Methodology for the prediction of WDM using an ANN.</p>
<p>WDM: workpiece dynamic motion; ANN: artificial neural network; GA: genetic algorithm.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig2.tif"/>
</fig>
<list id="list1-0954405412457121" list-type="order">
<list-item><p>Set up a modular fixture so that different layouts can be achieved.</p></list-item>
<list-item><p>Perform machining on the workpiece with different layouts.</p></list-item>
<list-item><p>Measure the dynamic motion of the workpiece at the datum points.</p></list-item>
<list-item><p>Identify a suitable ANN and optimize its critical parameters.</p></list-item>
<list-item><p>Train the network with the data of WDM obtained experimentally.</p></list-item>
<list-item><p>Use the ANN for prediction of workpiece motion for a required layout.</p></list-item>
</list>
</sec>
<sec id="section4-0954405412457121">
<title>Numerical illustration</title>
<sec id="section5-0954405412457121">
<title>Problem definition</title>
<p>The study involves a WFS as shown in <xref ref-type="fig" rid="fig3-0954405412457121">Figure 3</xref>. A through slot of size 80 mm × 60 mm is to be milled on a cubical aluminum block of side 101.6 mm. Typical a 3-2-1 locating scheme is followed and hence the fixture consists of six locators denoted as <italic>L</italic><sub>1</sub>…<italic>L</italic><sub>6</sub>. Locators <italic>L</italic><sub>1</sub>, <italic>L</italic><sub>2</sub> and <italic>L</italic><sub>3</sub> are in the primary datum, <italic>L</italic><sub>4</sub> and <italic>L</italic><sub>5</sub> are in the secondary datum and <italic>L</italic><sub>6</sub> is in the tertiary datum. Two clamps <italic>C</italic><sub>1</sub> and <italic>C</italic><sub>2</sub> exert the required clamping forces. The material properties of workpiece and fixture elements are given in <xref ref-type="table" rid="table1-0954405412457121">Table 1</xref>.</p>
<fig id="fig3-0954405412457121" position="float">
<label>Figure 3.</label>
<caption><p>WFS under study.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig3.tif"/>
</fig>
<table-wrap id="table1-0954405412457121" position="float">
<label>Table 1.</label>
<caption><p>Material properties.</p></caption>
<graphic alternate-form-of="table1-0954405412457121" xlink:href="10.1177_0954405412457121-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Material</th>
<th align="left">Properties</th>
</tr>
</thead>
<tbody>
<tr>
<td>Aluminum (workpiece)</td>
<td>Density = 2300 kg/m<sup>3</sup></td>
</tr>
<tr>
<td/>
<td>Young’s modulus = 70 GPa</td>
</tr>
<tr>
<td/>
<td>Poisson’s ratio = 0.334</td>
</tr>
<tr>
<td/>
<td>Weight = 23.6 N</td>
</tr>
<tr>
<td>Steel ( locators – planar tipped, radius 6 mm, length 8 mm)</td>
<td>Young’s modulus = 207 GPaPoisson’s ratio = 0.292</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The critical feature in this workpiece is the distance of the slot from the right end, marked as 30 ± 0.05 mm. Since the machining tolerance is specified along the <italic>Y</italic> direction, the WDM along <italic>Y</italic> direction alone is of interest. Therefore, in the subsequent sections of the article, WDM represents WDM in the <italic>Y</italic> direction. The problem at hand is to predict the dynamic motion of the workpiece for a given layout with the least possible error.</p>
</sec>
<sec id="section6-0954405412457121">
<title>Experimental set-up</title>
<p>Since the WDM is to be captured for different layouts, a modular fixture is employed. This fixture, shown in <xref ref-type="fig" rid="fig4-0954405412457121">Figure 4</xref>, has provision for locators and clamps to be placed according to the requirement. The workpiece is held in this fixture and clamped by means of screw clamps. This fixture is held in an ARIX vertical machining center and end milling of the slot is carried out on the workpiece. This machining center has a capacity of 1000 mm × 500 mm × 500 mm along the longitudinal, cross and vertical axes, respectively, and a maximum feed rate of 4000 mm/min with a table size of 1270 mm × 330 mm. <xref ref-type="table" rid="table2-0954405412457121">Table 2</xref> shows the cutting conditions used in the study. The time-varying machining forces in <italic>X, Y</italic> and <italic>Z</italic> directions during milling are shown in <xref ref-type="fig" rid="fig5-0954405412457121">Figure 5</xref>. It can be seen that maximum forces are encountered during the initial instant of machining. After this point in time, machining forces are lesser in magnitude. The machining forces given in <xref ref-type="table" rid="table2-0954405412457121">Table 2</xref> are the maximum forces encountered during milling.</p>
<fig id="fig4-0954405412457121" position="float">
<label>Figure 4.</label>
<caption><p>Modular fixture set-up.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig4.tif"/>
</fig>
<table-wrap id="table2-0954405412457121" position="float">
<label>Table 2.</label>
<caption><p>Cutting conditions.</p></caption>
<graphic alternate-form-of="table2-0954405412457121" xlink:href="10.1177_0954405412457121-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<tbody>
<tr>
<td>Cutting forces</td>
<td><italic>F</italic><sub><italic>X</italic></sub> = 120 N, <italic>F</italic><sub><italic>Y</italic></sub> = 150 N, <italic>F</italic><sub><italic>Z</italic></sub> = 240 N</td>
</tr>
<tr>
<td>Depth of cut</td>
<td>2 mm</td>
</tr>
<tr>
<td>Feed</td>
<td>100 mm/min</td>
</tr>
<tr>
<td>Clamping force</td>
<td>650 N</td>
</tr>
<tr>
<td>Coefficient of friction</td>
<td>0.3</td>
</tr>
</tbody>
</table>
</table-wrap>
<fig id="fig5-0954405412457121" position="float">
<label>Figure 5.</label>
<caption><p>Cutting forces during machining.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig5.tif"/>
</fig>
<p>Before the actual start of machining, the position of each of the six locators and two clamps have to be decided. This has to be done without violating logic and established principles of locating. It is well known from the principles of locating that the machining forces should always be directed against a locator rather than a clamp. Also, two locators cannot be coincident. The third requirement is that the locators/clamp cannot be placed at the corner or edge of the workpiece to avoid instability. These requirements have been taken into consideration while fixing the bounds for the present case and these bounds are shown in <xref ref-type="table" rid="table3-0954405412457121">Table 3</xref>.</p>
<table-wrap id="table3-0954405412457121" position="float">
<label>Table 3.</label>
<caption><p>Bounds for locators and clamps.</p></caption>
<graphic alternate-form-of="table3-0954405412457121" xlink:href="10.1177_0954405412457121-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Fixture element</th>
<th align="left">Positional constraints used in optimization (mm)</th>
</tr>
</thead>
<tbody>
<tr>
<td>L<sub>1</sub></td>
<td>45 ≥ <italic>X</italic> ≥ 10, 10 ≥ <italic>Y</italic> ≥ 45, <italic>Z</italic> = 0</td>
</tr>
<tr>
<td>L<sub>2</sub></td>
<td>45 ≥ <italic>X</italic> ≥ 10, 91 ≥ <italic>Y</italic> ≥ 50, <italic>Z</italic> = 0</td>
</tr>
<tr>
<td>L<sub>3</sub></td>
<td>91 ≥ <italic>X</italic> ≥ 50, 91 ≥ <italic>Y</italic> ≥ 10, <italic>Z</italic> = 0</td>
</tr>
<tr>
<td>L<sub>4</sub></td>
<td>45 ≥ <italic>X</italic> ≥ 10, <italic>Y</italic> = 0, 70 ≥ <italic>Z</italic> ≥ 30</td>
</tr>
<tr>
<td>L<sub>5</sub></td>
<td>91 ≥ <italic>X</italic> ≥ 50, <italic>Y</italic> = 0, 70 ≥ <italic>Z</italic> ≥ 30</td>
</tr>
<tr>
<td>L<sub>6</sub></td>
<td>
<italic>X</italic> = 101.6, 91 ≥ <italic>Y</italic> ≥ 10, 65 ≥ <italic>Z</italic> ≥ 20</td>
</tr>
<tr>
<td>C<sub>1</sub></td>
<td>91 ≥ <italic>X</italic> ≥ 10, <italic>Y</italic>= 101.6, 80 ≥ <italic>Z</italic> ≥ 20</td>
</tr>
<tr>
<td>C<sub>2</sub></td>
<td>
<italic>X</italic> = 0, 91 ≥ <italic>Y</italic> ≥ 10, 70 ≥ <italic>Z</italic> ≥ 20</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The number of experiments to be conducted (number of different layouts to be used in the experiment for forming the data pool) was obtained based on the concepts of design of experiments (DoE). The problem with factorial design is that the combinations increase exponentially as the factors increase. In the present case, there are 16 factors (see ‘Modeling of the ANN’) and, hence, use of full factorial design would lead to a prohibitively large number of experiments and therefore cannot be adopted. Hence, the fractional factorial design (FFD) model is adopted in this work. Using the <italic>Design Expert</italic> software (version 7.0.0), for two levels with 16 factors, it was found that 128 experiments must be conducted.<sup><xref ref-type="bibr" rid="bibr16-0954405412457121">16</xref></sup> For each of these layouts, the WDM must be computed. In all the experiments, it must be ensured that the coordinates of each locator and clamp satisfy the bounds given in <xref ref-type="table" rid="table3-0954405412457121">Table 3</xref>.</p>
<p>During the experiment, the locators and clamps are fixed as per the layout generated. The workpiece is held in this layout within the machining fixture and machining is done using an end mill. For one complete stroke of the end mill, the workpiece displacement is computed at each of the processing datum points A, B and C. Since three datum points are considered, three accelerometers in conjunction with a multichannel data acquisition system (National Instruments) are used to acquire the workpiece acceleration. These acceleration signals are processed and converted to displacement data using the LabVIEW<sup>®</sup> software. The data acquisition set-up is shown schematically in <xref ref-type="fig" rid="fig6-0954405412457121">Figure 6</xref> and pictorially in <xref ref-type="fig" rid="fig7-0954405412457121">Figure 7</xref>.</p>
<fig id="fig6-0954405412457121" position="float">
<label>Figure 6.</label>
<caption><p>Schematic of measuring the WDM.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig6.tif"/>
</fig>
<fig id="fig7-0954405412457121" position="float">
<label>Figure 7.</label>
<caption><p>Data acquisition set-up.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig7.tif"/>
</fig>
<p>Since the experiment needs to be carried out for 128 different layouts, it would be uneconomical if the complete slot of 40 mm width were to be machined for taking one reading. Hence, considering economic aspects, one complete stroke of the end mill is executed and this is assumed to represent the machining of an entire width of the slot.</p>
</sec>
<sec id="section7-0954405412457121">
<title>Experimental results</title>
<p>The WDM during machining is depicted in <xref ref-type="fig" rid="fig8-0954405412457121">Figure 8</xref>. <xref ref-type="fig" rid="fig8-0954405412457121">Figure 8(a)</xref> shows the WDM at a given instant and <xref ref-type="fig" rid="fig8-0954405412457121">Figure 8(b)</xref> shows the variation of WDM at the three datum points for one complete stroke of the end mill. As can be seen, the magnitude of this motion is different at the datum points. For example, point A experiences a maximum value of 0.017 mm at the start of the cutting. As machining progresses and the cutter moves away from A, the magnitude gradually decreases. The pattern of change at the datum points seems to suggest that, as the cutter comes closer to a datum point, WDM at that datum point reaches its maximum and keeps decreasing after that. It should however, be noted that the trend and magnitudes may be different for a different layout. For example, consider <xref ref-type="table" rid="table4-0954405412457121">Table 4</xref> which shows the WDM for five randomly generated layouts. It can be seen that these values are significantly higher than the case depicted in <xref ref-type="fig" rid="fig8-0954405412457121">Figure 8(b)</xref>.</p>
<fig id="fig8-0954405412457121" position="float">
<label>Figure 8.</label>
<caption><p>WDM at datum points during machining: (a) instantaneous; (b) along machining length.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig8.tif"/>
</fig>
<table-wrap id="table4-0954405412457121" position="float">
<label>Table 4.</label>
<caption><p>WDM for random layouts.</p></caption>
<graphic alternate-form-of="table4-0954405412457121" xlink:href="10.1177_0954405412457121-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Layout</th>
<th align="left">Dynamic motion (µm)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>19.2</td>
</tr>
<tr>
<td>2</td>
<td>21.8</td>
</tr>
<tr>
<td>3</td>
<td>19.7</td>
</tr>
<tr>
<td>4</td>
<td>20.4</td>
</tr>
<tr>
<td>5</td>
<td>19.4</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
</sec>
<sec id="section8-0954405412457121">
<title>Prediction of WDM using an ANN</title>
<sec id="section9-0954405412457121">
<title>Modeling of the ANN</title>
<p>In this research work, a feed forward ANN with back propagation algorithm<sup><xref ref-type="bibr" rid="bibr17-0954405412457121">17</xref></sup> is used for the prediction of WDM. One of the built-in functions of MATLAB, namely the <italic>newff</italic>, is used for creating the network and the function <italic>traingdm</italic> is used for training the same. The ANN proposed in this work has a single hidden layer. Transfer functions <italic>tansig</italic> and <italic>purelin</italic> are used for the hidden layer and the output layer, respectively. These functions are briefly reviewed in the <xref ref-type="app" rid="app1-0954405412457121">Appendix</xref>.</p>
<p>In the present problem, the objective is to develop an ANN that is capable of predicting the WDM at three datum points for a given fixture layout. Referring to <xref ref-type="fig" rid="fig3-0954405412457121">Figure 3</xref>, the WFS consists of six locators and two clamps. Hence, the input to the ANN are the <italic>X, Y</italic> and <italic>Z</italic> coordinates of these eight elements, and the ANN output will be the WDM at datum points A, B and C. This means that the input vector should be of length 24, and output a vector of length 3. But some of the coordinates get fixed by virtue of their location. Referring to <xref ref-type="fig" rid="fig3-0954405412457121">Figure 3</xref> and <xref ref-type="table" rid="table3-0954405412457121">Table 3</xref>, it can be seen that the <italic>Z</italic> coordinate of <italic>L</italic><sub>1</sub>, <italic>L</italic><sub>2</sub>, <italic>L</italic><sub>3</sub>, <italic>Y</italic> coordinate of <italic>L</italic><sub>4</sub> and <italic>L</italic><sub>5</sub>, and <italic>X</italic> coordinate of <italic>C</italic><sub>2</sub> are all zero. Similarly, the <italic>X</italic> coordinate of <italic>L</italic><sub>6</sub> and <italic>Y</italic> coordinate of <italic>C</italic><sub>1</sub> are the same (101.6 mm). Since these eight components get fixed, the number of variable input coordinates is reduced from 24 to 16. <xref ref-type="fig" rid="fig9-0954405412457121">Figure 9</xref> shows the ANN architecture that accepts 16 inputs and gives the WDM as output.</p>
<fig id="fig9-0954405412457121" position="float">
<label>Figure 9.</label>
<caption><p>Architecture of the ANN.</p>
<p>WDM: workpiece dynamic motion.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig9.tif"/>
</fig>
</sec>
<sec id="section10-0954405412457121">
<title>Working of the ANN</title>
<p>In an ANN, each input parameter is indicated by a node in the input layer. Each of these inputs in the input vector <bold>p</bold> is multiplied by its corresponding weight and distributed to each neuron in the hidden layer. These are summed up to give a vector (<bold>n<sup>h</sup></bold>). This vector is subject to a transfer function (<italic>F</italic><sup>h</sup>), thereby giving an output at the hidden layer (<bold>a<sup>h</sup></bold>). Each of these outputs is distributed to each neuron in the output layer, weighted again and summed up to give a vector (<bold>n<sup>o</sup></bold>). This vector is subject to transfer function (<italic>F</italic><sup><italic>o</italic></sup>), so as to result an output at the output layer (output of the entire network), denoted as <bold>a<sup>o</sup></bold>. It can be noted that <bold>n</bold> is used to denote the vector at a given layer before applying the transfer function and <bold>a</bold> is used to denote the output of the layer after transfer function <italic>F</italic> is applied to <bold>n.</bold></p>
<p>The different weights between two layers can be written in the form of a weight matrix <bold>W</bold>. If <italic>R</italic> is the number of input elements and <italic>S</italic> is the number of neurons in the next (hidden) layer, then <bold>W</bold> is of size <italic>S</italic> × <italic>R</italic>. In general, the weight matrix between the <italic>k</italic>th and (<italic>k–</italic>1)th layers, denoted as <bold>W<sup>k</sup></bold>, is given by</p>
<p><disp-formula id="disp-formula3-0954405412457121">
<label>(3)</label>
<mml:math display="block" id="math3-0954405412457121">
<mml:mrow>
<mml:msup>
<mml:mi mathvariant="bold">W</mml:mi>
<mml:mi mathvariant="bold">k</mml:mi>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mi>S</mml:mi>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mi>S</mml:mi>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mn>…</mml:mn>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi>w</mml:mi>
<mml:mrow>
<mml:mi>S</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0954405412457121" xlink:href="10.1177_0954405412457121-eq3.tif"/>
</disp-formula></p>
<p>in which <italic>w</italic><sub><italic>j,i</italic></sub> is the weight whose destination is neuron <italic>j</italic> in the <italic>k</italic>th layer and the source of the same being neuron <italic>i</italic> in the (<italic>k–1</italic>)th layer. Thus, <italic>w</italic><sub>2,1</sub> represents the weight for neuron 2 in the <italic>k</italic>th layer that comes from neuron 1 in the previous layer (see <xref ref-type="fig" rid="fig9-0954405412457121">Figure 9</xref>).</p>
<p>With the parameters defined above, the input–output relation for a layer can be written as</p>
<p><disp-formula id="disp-formula4-0954405412457121">
<label>(4)</label>
<mml:math display="block" id="math4-0954405412457121">
<mml:mrow>
<mml:mi mathvariant="bold">a</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>F</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi mathvariant="bold">Wp</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi mathvariant="bold">b</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0954405412457121" xlink:href="10.1177_0954405412457121-eq4.tif"/>
</disp-formula></p>
<p>where <bold>b</bold> is the bias vector for the layer.</p>
<p><xref ref-type="disp-formula" rid="disp-formula4-0954405412457121">Equation (4)</xref>, as applied to the input and hidden layer, will be</p>
<p><disp-formula id="disp-formula5-0954405412457121">
<label>(5)</label>
<mml:math display="block" id="math5-0954405412457121">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>h</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>h</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mspace width="0.25em"/>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">W</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>h</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mi mathvariant="bold">p</mml:mi>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>h</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0954405412457121" xlink:href="10.1177_0954405412457121-eq5.tif"/>
</disp-formula></p>
<p>and between hidden and output layers will be</p>
<p><disp-formula id="disp-formula6-0954405412457121">
<label>(6)</label>
<mml:math display="block" id="math6-0954405412457121">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>o</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>F</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>o</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">W</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>o</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>h</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi mathvariant="bold">b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>o</mml:mtext>
</mml:mrow>
</mml:msup>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0954405412457121" xlink:href="10.1177_0954405412457121-eq6.tif"/>
</disp-formula></p>
<p>As mentioned in ‘Modeling of the ANN’, the input layer has 16 neurons and the output layer has three neurons. At this stage, the number of neurons in the hidden layer (<italic>n</italic><sub><italic>h</italic></sub>) is not known. This will be determined by optimization as explained in ‘Need for optimization of ANN parameters’. With these details, and remembering that the transfer functions <italic>tansig</italic> and <italic>purelin</italic> are used for hidden layer and output layer respectively, the ANN employed in the present work can be schematically represented as shown in <xref ref-type="fig" rid="fig10-0954405412457121">Figure 10</xref>.</p>
<fig id="fig10-0954405412457121" position="float">
<label>Figure 10.</label>
<caption><p>Working scheme of the ANN.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig10.tif"/>
</fig>
</sec>
<sec id="section11-0954405412457121">
<title>Need for optimization of ANN parameters</title>
<p>Performance of an ANN is affected by different factors and hence, it is imperative to identify and optimize these factors.</p>
<p>Mathworks<sup><bold><xref ref-type="bibr" rid="bibr18-0954405412457121">18</xref></bold></sup> reports that for the <italic>traingdm</italic> function, the performance of the network is very sensitive to the setting of <italic>learning rate</italic> (LR) and <italic>momentum constant</italic> (MC) (please refer to <xref ref-type="app" rid="app1-0954405412457121">Appendix</xref> for details). Hence, optimal values of these two parameters need to be determined.</p>
<p>The second factor that warrants attention is the <italic>network size. Network size</italic> determines the network efficiency and the time taken for learning and generalization. As explained in ‘Modeling of the ANN’, the number of neurons in the input and output layers depend on the number of inputs and output variables, respectively. With the number of neurons in the input and output layers fixed, the network size depends on the number of neurons in the hidden layer (<italic>n</italic><sub><italic>h</italic></sub>). The network complexity increases exponentially with respect to the number of neurons in the hidden layer.<sup><xref ref-type="bibr" rid="bibr19-0954405412457121">19</xref></sup></p>
<p>The third factor relates to the errors encountered in using an ANN. In the ANN parlance, two types of error are identified. These are the <italic>training error</italic> and the <italic>generalization error</italic>. The former refers to the difference between what the ANN must learn and what it has actually learnt. The latter denotes the difference between the ANN predicted value and the actual or target value. For the ANN to be efficient in prediction, it is essential that both these errors are minimized.</p>
<p>Hence, a computationally efficient ANN should possess the following characteristics.</p>
<list id="list2-0954405412457121" list-type="order">
<list-item><p>Optimal values of learning rate and momentum constant.</p></list-item>
<list-item><p>Optimal number of neurons in the hidden layer.</p></list-item>
<list-item><p>Minimum error in training and generalization.</p></list-item>
</list>
<p>This requires that the ANN should first be optimized to attain these characteristics. Before optimization is invoked, a suitable objective function must be identified that can collectively represent the above three parameters.</p>
<p>The objective function used by Benardos and Vosniakos<sup><xref ref-type="bibr" rid="bibr19-0954405412457121">19</xref></sup> is employed in this work, and the same is given by</p>
<p><disp-formula id="disp-formula7-0954405412457121">
<label>(7)</label>
<mml:math display="block" id="math7-0954405412457121">
<mml:mrow>
<mml:mi>Φ</mml:mi>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>001</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mspace width="0.25em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>train</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>gen</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0954405412457121" xlink:href="10.1177_0954405412457121-eq7.tif"/>
</disp-formula></p>
<p>where <italic>E</italic><sub><italic>train</italic></sub> and <italic>E</italic><sub><italic>gen</italic></sub> refer to the errors in training and generalization, respectively, and <italic>n</italic><sub><italic>h</italic></sub> refers to the number of neurons in the hidden layer. Various parameters are available to measure these errors. These include the mean square error (MSE), mean squared error with regularization (MSER) and mean absolute relative error (MARE). This work uses the MARE to measure these errors since it is easier to interpret and does not require scaling or normalization.</p>
<p>On this basis, <italic>E</italic><sub><italic>train</italic></sub> and <italic>E</italic><sub><italic>gen</italic></sub> are given by</p>
<p><disp-formula id="disp-formula8-0954405412457121">
<label>(8)</label>
<mml:math display="block" id="math8-0954405412457121">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>train</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>oi</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>oi</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0954405412457121" xlink:href="10.1177_0954405412457121-eq8.tif"/>
</disp-formula></p>
<p>where</p>
<p><italic>
S</italic>
<sub>
<italic>oi</italic>
</sub> = target value of the <italic>i</italic>th training data vector (what the ANN must learn);</p>
<p><italic>
S</italic>
<sub>
<italic>i</italic>
</sub> = ANN’s response to the training data vector (what the ANN has actually learnt);</p>
<p><italic>
N</italic> = the number of training datasets.</p>
<p>Similarly</p>
<p><disp-formula id="disp-formula9-0954405412457121">
<label>(9)</label>
<mml:math display="block" id="math9-0954405412457121">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>gen</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mo stretchy="false">|</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>oi</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">/</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>oi</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0954405412457121" xlink:href="10.1177_0954405412457121-eq9.tif"/>
</disp-formula></p>
<p>where</p>
<p><italic>T</italic><sub><italic>oi</italic></sub> = target value of the <italic>i</italic>th testing data vector (what the ANN must predict);</p>
<p><italic>T</italic><sub><italic>i</italic></sub> = ANN’s output (what the ANN has actually predicted);</p>
<p><italic>N</italic><sub><italic>t</italic></sub> = number of testing datasets.</p>
<p>In <xref ref-type="disp-formula" rid="disp-formula9-0954405412457121">equation (9)</xref>, the term inside the modulus symbol is simply the absolute error relative to the target value. This is termed as absolute relative error (ARE).</p>
</sec>
<sec id="section12-0954405412457121">
<title>GA-based optimization of ANN parameters</title>
<p>In this work, a GA coded in the MATLAB environment attempts to minimize the function Φ defined by <xref ref-type="disp-formula" rid="disp-formula3-0954405412457121">equation (3)</xref>. It can be noted that minimizing this function serves the twin purposes of a compact network and a minimum error in training and generalization. This problem of optimization can be stated as follows.</p>
<p>Minimize</p>
<p><disp-formula id="disp-formula10-0954405412457121">
<mml:math display="block" id="math10-0954405412457121">
<mml:mrow>
<mml:mi>Φ</mml:mi>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>001</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mspace width="0.25em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>train</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>gen</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0954405412457121" xlink:href="10.1177_0954405412457121-eq10.tif"/>
</disp-formula></p>
<p>subject to</p>
<p><disp-formula id="disp-formula11-0954405412457121">
<label>(10)</label>
<mml:math display="block" id="math11-0954405412457121">
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>≥</mml:mo>
<mml:mi>LR</mml:mi>
<mml:mo>≥</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>≥</mml:mo>
<mml:mi>MC</mml:mi>
<mml:mo>≥</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>50</mml:mn>
<mml:mo>≥</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>≥</mml:mo>
<mml:mn>5</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0954405412457121" xlink:href="10.1177_0954405412457121-eq11.tif"/>
</disp-formula></p>
<p>Further to ‘Experimental set-up’, the WDM data is available from 128 experiments. These 128 data must be apportioned for training and generalization. Based on Mathwords<sup><xref ref-type="bibr" rid="bibr18-0954405412457121">18</xref></sup> and Benardos and Vosniakos,<sup><xref ref-type="bibr" rid="bibr19-0954405412457121">19</xref></sup> 15% of the available data (20 sets of data) are used for generalization and the remaining 108 are used for training.</p>
<p>The training data input to the ANN consists of the details of the <italic>i</italic>th layout given by <bold>V</bold><sub><italic>i</italic></sub> and the WDM obtained at the three datum points for each layout, given by <bold>d</bold><sub><italic>i</italic></sub>. In essence, <bold>V</bold><sub><italic>i</italic></sub> represents the coordinates of each locator and clamp.</p>
<p>The input to the ANN is hence a matrix <bold>TD</bold>ℜ<sup><italic>108 × 19</italic></sup> with the following form</p>
<p><disp-formula id="disp-formula12-0954405412457121">
<label>(11)</label>
<mml:math display="block" id="math12-0954405412457121">
<mml:mrow>
<mml:mi mathvariant="bold">T</mml:mi>
<mml:mi mathvariant="bold">D</mml:mi>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">V</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">d</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">V</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">d</mml:mi>
<mml:mn>2</mml:mn>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mo>.</mml:mo>
</mml:mtd>
<mml:mtd>
<mml:mo>.</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">V</mml:mi>
<mml:mrow>
<mml:mn>108</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mi mathvariant="bold">d</mml:mi>
<mml:mrow>
<mml:mn>108</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0954405412457121" xlink:href="10.1177_0954405412457121-eq12.tif"/>
</disp-formula></p>
<p>where</p>
<p><inline-formula id="inline-formula1-0954405412457121">
<mml:math display="inline" id="math13-0954405412457121">
<mml:mrow>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">V</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>∈</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>×</mml:mo>
<mml:mn>19</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula> is the input vector for the <italic>i</italic>th layout, with the coordinate vector</p>
<p><disp-formula id="disp-formula13-0954405412457121">
<label>(12)</label>
<mml:math display="block" id="math14-0954405412457121">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">V</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>.</mml:mo>
<mml:mo>.</mml:mo>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>C</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>Z</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>C</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>∈</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>×</mml:mo>
<mml:mn>16</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula13-0954405412457121" xlink:href="10.1177_0954405412457121-eq13.tif"/>
</disp-formula></p>
<p>and</p>
<p><disp-formula id="disp-formula14-0954405412457121">
<label>(13)</label>
<mml:math display="block" id="math15-0954405412457121">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi mathvariant="bold">d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mi>WD</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>WD</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>WD</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>∈</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>×</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula14-0954405412457121" xlink:href="10.1177_0954405412457121-eq14.tif"/>
</disp-formula></p>
<p>To drive the ANN towards minimum error in learning, a small number in the vicinity of zero is set as the <italic>goal</italic>. The GA is coded so as to achieve this goal of near zero error. In this work, the goal is set as 1 × 10<sup>−7</sup> and the process of optimization is invoked.</p>
<p>It is obvious that the network cannot be run infinitely in an attempt to improve its learning performance. On the other hand, if the number of runs is below a certain level, the learning ability of the ANN may be hindered. Hence, a balance needs to be struck by means of some termination criterion. Training of the ANN is made to stop when any of these conditions occurs:</p>
<list id="list3-0954405412457121" list-type="alpha-lower">
<list-item><p>the maximum number of epochs (repetitions) is reached;</p></list-item>
<list-item><p>the maximum amount of time specified is exceeded;</p></list-item>
<list-item><p>performance is minimized to the goal.</p></list-item>
</list>
<p>Specification of these conditions depends on many factors, such as the accuracy needed and availability of computational time. In the present case, the maximum number of epochs is set as 5000.</p>
<p>In essence, number of epochs denotes how many iterations the ANN must take to finish the process of learning. The ANN reads the input data the number of epochs times repeatedly, with the hope of achieving the desired learning accuracy.</p>
</sec>
<sec id="section13-0954405412457121">
<title>GA parameters</title>
<p>In this work, real coding of variables is used for the coding of the GA. Since three parameters (LA, MC, <italic>n</italic><sub><italic>h</italic></sub>) are optimized, the chromosome has a string length of 3. Real coding of variables is followed. Intermediate operator for crossover and incremental operator for mutation<sup><xref ref-type="bibr" rid="bibr20-0954405412457121">20</xref></sup> are employed. <xref ref-type="table" rid="table5-0954405412457121">Table 5</xref> shows the other GA parameters used.</p>
<table-wrap id="table5-0954405412457121" position="float">
<label>Table 5.</label>
<caption><p>GA control parameters.</p></caption>
<graphic alternate-form-of="table5-0954405412457121" xlink:href="10.1177_0954405412457121-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Population size</td>
<td>20</td>
</tr>
<tr>
<td>Number of generations</td>
<td>100</td>
</tr>
<tr>
<td>Crossover probability</td>
<td>0.85</td>
</tr>
<tr>
<td>Mutation probability</td>
<td>0.05</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
</sec>
<sec id="section14-0954405412457121" sec-type="results">
<title>Analysis of results</title>
<sec id="section15-0954405412457121">
<title>Optimal network parameters</title>
<p><xref ref-type="fig" rid="fig11-0954405412457121">Figure 11</xref> shows the screenshot of the learning performance of the network as taken from MATLAB. Initially the difference between the goal and the actual values is very large. This gap indicates the degree of lack of accuracy between the inputs to the ANN and how the ANN has understood the same. It can be seen that as the epochs increase, the difference between the goal and the actual error present during learning gets narrow and the actual training error meets the goal at 3971 epochs.</p>
<fig id="fig11-0954405412457121" position="float">
<label>Figure 11.</label>
<caption><p>Learning performance of the ANN: (a) performance plot; (b) gradient plot.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig11.tif"/>
</fig>
<p>It is also evident from the plot that the difference between the goal and the actual training error was nearly 100 and it ultimately gets reduced to 10<sup>−7</sup>. This shows that, had the ANN parameters not been optimized, it would have resulted in a large learning error. Since the accuracy of learning has a bearing on the generalization capability of the ANN, error in learning leads to an error in generalization. As a result, the WDM predicted by the network will also be flawed. This underscores the importance of optimizing the ANN parameters.</p>
<p>By achieving the set goal, it is proved that the network has a good learning capability. The optimal parameters pertaining to this result, as determined by the GA, are given in <xref ref-type="table" rid="table6-0954405412457121">Table 6</xref>.</p>
<table-wrap id="table6-0954405412457121" position="float">
<label>Table 6.</label>
<caption><p>Optimal parameters of the ANN.</p></caption>
<graphic alternate-form-of="table6-0954405412457121" xlink:href="10.1177_0954405412457121-table6.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Learning rate</td>
<td>0.041</td>
</tr>
<tr>
<td>Momentum constant</td>
<td>0.523</td>
</tr>
<tr>
<td>Number of neurons in hidden layer</td>
<td>20</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section16-0954405412457121">
<title>Generalization performance of the ANN</title>
<p>To study its generalization capability, the ANN was fed with the coordinate data of 20 different layouts. It can be noted that the WDM for these 20 layouts are also obtained experimentally. Now the values of the WDM that would be predicted by the ANN for these layouts are compared with the experimentally obtained values. Any difference between these two values is termed the generalization error and the same is quantified using a measure MARE, as explained in ‘Modeling of the ANN’. The relevant values for the 20 datasets are given in <xref ref-type="table" rid="table7-0954405412457121">Table 7</xref> and depicted in <xref ref-type="fig" rid="fig12-0954405412457121">Figure 12</xref>. It can be seen that the difference between target and predicted values is very small. <xref ref-type="fig" rid="fig13-0954405412457121">Figure 13</xref> shows the ARE in percentage terms. It is seen that the maximum ARE is 9.71% and the MARE is found to be 0.03537.</p>
<table-wrap id="table7-0954405412457121" position="float">
<label>Table 7.</label>
<caption><p>Generalization performance of the ANN.</p></caption>
<graphic alternate-form-of="table7-0954405412457121" xlink:href="10.1177_0954405412457121-table7.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Dataset</th>
<th align="left" colspan="2">WDM (µm)</th>
<th align="left">ARE</th>
<th align="left">ARE (%)</th>
</tr>
<tr>
<th/>
<th align="left">Target</th>
<th align="left">Predicted</th>
<th/>
<th/>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>12.36</td>
<td>11.80</td>
<td>0.045</td>
<td>4.53</td>
</tr>
<tr>
<td>2</td>
<td>11.78</td>
<td>10.64</td>
<td>0.097</td>
<td>9.71</td>
</tr>
<tr>
<td>3</td>
<td>11.86</td>
<td>12.55</td>
<td>0.059</td>
<td>5.85</td>
</tr>
<tr>
<td>4</td>
<td>10.36</td>
<td>10.05</td>
<td>0.030</td>
<td>2.99</td>
</tr>
<tr>
<td>5</td>
<td>17.41</td>
<td>16.99</td>
<td>0.024</td>
<td>2.41</td>
</tr>
<tr>
<td>6</td>
<td>11.71</td>
<td>10.92</td>
<td>0.067</td>
<td>6.68</td>
</tr>
<tr>
<td>7</td>
<td>15.39</td>
<td>15.27</td>
<td>0.008</td>
<td>0.78</td>
</tr>
<tr>
<td>8</td>
<td>16.51</td>
<td>16.98</td>
<td>0.029</td>
<td>2.86</td>
</tr>
<tr>
<td>9</td>
<td>12.98</td>
<td>13.21</td>
<td>0.018</td>
<td>1.78</td>
</tr>
<tr>
<td>10</td>
<td>11.03</td>
<td>10.98</td>
<td>0.005</td>
<td>0.48</td>
</tr>
<tr>
<td>11</td>
<td>14.25</td>
<td>14.83</td>
<td>0.041</td>
<td>4.07</td>
</tr>
<tr>
<td>12</td>
<td>13.78</td>
<td>12.64</td>
<td>0.083</td>
<td>8.27</td>
</tr>
<tr>
<td>13</td>
<td>10.91</td>
<td>11.05</td>
<td>0.013</td>
<td>1.28</td>
</tr>
<tr>
<td>14</td>
<td>14.56</td>
<td>13.84</td>
<td>0.049</td>
<td>4.95</td>
</tr>
<tr>
<td>15</td>
<td>15.05</td>
<td>15.58</td>
<td>0.035</td>
<td>3.52</td>
</tr>
<tr>
<td>16</td>
<td>17.20</td>
<td>17.01</td>
<td>0.011</td>
<td>1.10</td>
</tr>
<tr>
<td>17</td>
<td>17.84</td>
<td>18.06</td>
<td>0.012</td>
<td>1.23</td>
</tr>
<tr>
<td>18</td>
<td>11.65</td>
<td>11.34</td>
<td>0.027</td>
<td>2.66</td>
</tr>
<tr>
<td>19</td>
<td>13.02</td>
<td>13.50</td>
<td>0.037</td>
<td>3.69</td>
</tr>
<tr>
<td>20</td>
<td>18.08</td>
<td>17.63</td>
<td>0.025</td>
<td>2.49</td>
</tr>
<tr>
<td colspan="3">MARE</td>
<td colspan="2">0.035667955</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0954405412457121">
<p>WDM: workpiece dynamic motion; ARE: absolute relative error; MARE: mean absolute relative error.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<fig id="fig12-0954405412457121" position="float">
<label>Figure 12.</label>
<caption><p>Target and predicted WDM in generalization.</p>
<p>WDM: workpiece dynamic motion.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig12.tif"/>
</fig>
<fig id="fig13-0954405412457121" position="float">
<label>Figure 13.</label>
<caption><p>Percentage of ARE in generalization.</p>
<p>ARE: absolute relative error.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig13.tif"/>
</fig>
<p>From <xref ref-type="table" rid="table7-0954405412457121">Table 7</xref> it can be noted that the difference between the target and predicted values for individual datasets differs. In some cases both data are almost the same, whereas in some other cases a difference exists. Going by individual pairs of data could lead to a prejudiced conclusion about the ANN performance. Because of the same reason, a parameter such as the MARE was necessary, which can collectively rate the accuracy of ANN prediction rather than on the basis of individual data.</p>
</sec>
<sec id="section17-0954405412457121">
<title>Effect on machining tolerance</title>
<p>Now that the magnitude of the WDM is known, it can be assessed against the machining tolerance of 0.05 mm provided on the workpiece (<xref ref-type="fig" rid="fig2-0954405412457121">Figure 2</xref>). For example, for layout 1 in <xref ref-type="table" rid="table7-0954405412457121">Table 7</xref>, the ANN predicted value of the WDM is 11.8 µm (0.0118 mm). This means that, this particular layout has a ‘window’ of 0.0382 mm that can be shared by the other sources of error in the WFS. These sources include, but are not restricted to, those mentioned in the introduction.</p>
<p>On the other hand, if the predicted WDM exceeds 0.05 mm, this layout can straightaway be rejected. This is because, with a single source alone resulting in 0.05 mm machining error, the effect of one or more components owing to the above-mentioned sources would only cause the overall machining error to exceed 0.05 mm. This leads to non-conformance to the tolerance requirements.</p>
</sec>
</sec>
<sec id="section18-0954405412457121" sec-type="conclusions">
<title>Conclusions</title>
<p>This article presented a novel approach of predicting WDM using an optimized ANN. Using a modular fixture set-up, different layouts were obtained and the WDM was computed at the datum points experimentally. An ANN was trained using this data. Learning rate, momentum constant and number of neurons in the hidden layer of the ANN were identified as critical parameters, and these were optimized so as to achieve a better prediction efficiency of the network. The performance measure of the ANN showed that the network has good learning and generalization capabilities. With the ANN proved to be efficient, it can now be used for the evaluation of WDM for any required layout. This, in turn, can serve as an economical and efficient method for fixture layout optimization.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0954405412457121">
<title>Appendix</title>
<p>This appendix reviews the MATLAB functions used in the present work.</p>
<sec id="section19-0954405412457121">
<title>newff</title>
<p>Creates a feed-forward back propagation network.</p>
</sec>
<sec id="section20-0954405412457121">
<title>traingdm</title>
<p>This refers to ‘training using gradient descent with momentum’. Training is a process of a step-wise modification of weights and bias in the direction of the maximal gradient of object function. In this algorithm, the weights and biases are updated in the direction of the negative gradient of the performance function. The change in weights (Δ<italic>w</italic>) and bias (Δ<italic>b</italic>) are modified as follows<sup><xref ref-type="bibr" rid="bibr21-0954405412457121">21</xref></sup></p>
<p><disp-formula id="disp-formula15-0954405412457121">
<label>(14)</label>
<mml:math display="block" id="math16-0954405412457121">
<mml:mrow>
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>Δ</mml:mi>
<mml:msubsup>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mi>α</mml:mi>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>.</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>Δ</mml:mi>
<mml:msubsup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mi>α</mml:mi>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>E</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:mfrac>
<mml:mspace width="0.25em"/>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula15-0954405412457121" xlink:href="10.1177_0954405412457121-eq15.tif"/>
</disp-formula></p>
<p>where, α is the learning rate, <italic>E</italic> is the performance index mean squared error (MSE), and index <italic>i,k</italic> denotes the neuron and layer, respectively.</p>
<p><italic>tansig. tansig</italic> is a hyperbolic tangent sigmoid transfer function used to calculate a layer’s output from its net input. The algorithm of <italic>tansig</italic>, as applied to a function (<italic>n</italic>) is</p>
<p><disp-formula id="disp-formula16-0954405412457121">
<label>(15)</label>
<mml:math display="block" id="math17-0954405412457121">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>tansig</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>*</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula16-0954405412457121" xlink:href="10.1177_0954405412457121-eq16.tif"/>
</disp-formula></p>
<p>This function is shown in <xref ref-type="fig" rid="fig14-0954405412457121">Figure 14</xref>.</p>
<fig id="fig14-0954405412457121" position="float">
<label>Figure 14.</label>
<caption><p>Representation of the <italic>tansig</italic> function.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig14.tif"/>
</fig>
</sec>
<sec id="section21-0954405412457121">
<title>purelin</title>
<p>This is a linear transfer function, whose algorithm is given by</p>
<p><disp-formula id="disp-formula17-0954405412457121">
<label>(16)</label>
<mml:math display="block" id="math18-0954405412457121">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>purelin</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula17-0954405412457121" xlink:href="10.1177_0954405412457121-eq17.tif"/>
</disp-formula></p>
<p><xref ref-type="fig" rid="fig15-0954405412457121">Figure 15</xref> shows this function.</p>
<fig id="fig15-0954405412457121" position="float">
<label>Figure 15.</label>
<caption><p>Representation of <italic>purelin</italic> function.</p></caption>
<graphic xlink:href="10.1177_0954405412457121-fig15.tif"/>
</fig>
</sec>
<sec id="section22-0954405412457121">
<title>Learning rate</title>
<p>The learning rate α, is a positive real number. The LR is multiplied times the negative of the gradient to determine the changes to the weights and biases. The larger the learning rate, the bigger the step. If the learning rate is set too high, the algorithm can oscillate and become unstable. If the learning rate is too small, the algorithm takes too long to converge.</p>
</sec>
<sec id="section23-0954405412457121">
<title>Momentum constant</title>
<p>Momentum allows a network to respond not only to the local gradient, but also to recent trends in the error surface. Without momentum a network can get stuck in a shallow local minimum. Momentum constant defines the amount of momentum and lies between 0 (no momentum) and values close to 1 (lots of momentum). A momentum constant of 1 results in a network that is completely insensitive to the local gradient and, therefore, does not learn properly.</p>
</sec>
</app>
</app-group>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0954405412457121">
<label>1.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Daimon</surname><given-names>M</given-names></name>
<name><surname>Yoshida</surname><given-names>N</given-names></name>
<name><surname>Kojima</surname><given-names>H</given-names></name><etal/>
</person-group>. <article-title>Study for designing fixture considering dynamics of thin walled plate and box-like workpieces</article-title>. <source>Ann CIRP</source> <year>1985</year>; <volume>34</volume>(<issue>3</issue>): <fpage>319</fpage>–<lpage>324</lpage>.</citation>
</ref>
<ref id="bibr2-0954405412457121">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mittal</surname><given-names>RO</given-names></name>
<name><surname>Cohen</surname><given-names>PH</given-names></name>
<name><surname>Gilmore</surname><given-names>BJ</given-names></name>
</person-group>. <article-title>Dynamic modeling of the fixture workpiece system</article-title>. <source>Robot Computer Integr Manuf</source> <year>1991</year>; <volume>8</volume>(<issue>4</issue>): <fpage>201</fpage>–<lpage>217</lpage>.</citation>
</ref>
<ref id="bibr3-0954405412457121">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liao</surname><given-names>YG</given-names></name>
<name><surname>Hu</surname><given-names>SJ</given-names></name>
</person-group>. <article-title>Flexible multi body dynamics based fixture workpiece analysis model for fixturing stability</article-title>. <source>Int J Mach Tools Manuf</source> <year>2000</year>; <volume>40</volume>(<issue>3</issue>): <fpage>343</fpage>–<lpage>362</lpage>.</citation>
</ref>
<ref id="bibr4-0954405412457121">
<label>4.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liao</surname><given-names>YG</given-names></name>
<name><surname>Hu</surname><given-names>SJ</given-names></name>
</person-group>. <article-title>An integrated model of a fixture workpiece system for surface quality prediction</article-title>. <source>Int J Advd Manuf Technol</source> <year>2001</year>; <volume>17</volume>(<issue>11</issue>): <fpage>810</fpage>–<lpage>818</lpage>.</citation>
</ref>
<ref id="bibr5-0954405412457121">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fang</surname><given-names>B</given-names></name>
<name><surname>DeVor</surname><given-names>RE</given-names></name>
<name><surname>Kapoor</surname><given-names>SG</given-names></name>
</person-group>. <article-title>Influence of friction damping on workpiece fixture system dynamics and machining stability</article-title>. <source>J Manuf Sci Eng</source> <year>2002</year>; <volume>124</volume>(<issue>2</issue>): <fpage>226</fpage>–<lpage>233</lpage>.</citation>
</ref>
<ref id="bibr6-0954405412457121">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Deiab</surname><given-names>IM</given-names></name>
<name><surname>Elbestawi</surname><given-names>MA</given-names></name>
</person-group>. <article-title>Effect of workpiece/fixture dynamics on the machining process output</article-title>. <source>J Eng Manuf</source> <year>2004</year>; <volume>218</volume>(<issue>11</issue>): <fpage>1541</fpage>–<lpage>1553</lpage>.</citation>
</ref>
<ref id="bibr7-0954405412457121">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liu</surname><given-names>JJ</given-names></name>
<name><surname>Strong</surname><given-names>DR</given-names></name>
</person-group>. <article-title>Machining fixture verification for linear fixture systems</article-title>. <source>Int J Prod Res</source> <year>2002</year>; <volume>40</volume>(<issue>14</issue>): <fpage>3441</fpage>–<lpage>3459</lpage>.</citation>
</ref>
<ref id="bibr8-0954405412457121">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Motlagh</surname><given-names>HE</given-names></name>
<name><surname>Hamedi</surname><given-names>M</given-names></name>
<name><surname>Bahramy</surname><given-names>MN</given-names></name>
</person-group> <article-title>Application of the Armstrong friction model to study the dynamic transient response in workpiece–fixture systems</article-title>. <source>J Manuf Sci Eng</source> <year>2004</year>; <volume>218</volume>(<issue>7</issue>): <fpage>737</fpage>–<lpage>747</lpage>.</citation>
</ref>
<ref id="bibr9-0954405412457121">
<label>9.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>B</given-names></name>
<name><surname>Melkote</surname><given-names>SN</given-names></name>
</person-group>. <article-title>Optimal fixture design accounting for the effect of workpiece dynamics</article-title>. <source>Int J Adv Manuf Technol</source> <year>2001</year>; <volume>18</volume>(<issue>10</issue>): <fpage>701</fpage>–<lpage>707</lpage>.</citation>
</ref>
<ref id="bibr10-0954405412457121">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Deng</surname><given-names>H</given-names></name>
<name><surname>Melkote</surname><given-names>SN</given-names></name>
</person-group>. <article-title>Determination of minimum clamping forces for dynamically stable fixturing</article-title>. <source>Int J Mach Tools Manuf</source> <year>2006</year>; <volume>46</volume>(<issue>7–8</issue>): <fpage>847</fpage>–<lpage>857</lpage>.</citation>
</ref>
<ref id="bibr11-0954405412457121">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Padmanaban</surname><given-names>KP</given-names></name>
<name><surname>Prabhaharan</surname><given-names>G</given-names></name>
</person-group>. <article-title>Dynamic analysis on optimal placement of fixturing elements using evolutionary techniques</article-title>. <source>Int J Prod Res</source> <year>2008</year>; <volume>46</volume>(<issue>15</issue>): <fpage>4177</fpage>–<lpage>4214</lpage>.</citation>
</ref>
<ref id="bibr12-0954405412457121">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Padmanaban</surname><given-names>KP</given-names></name>
<name><surname>Alurshri</surname><given-names>KP</given-names></name>
<name><surname>Prabhaharan</surname><given-names>G</given-names></name>
</person-group>. <article-title>Machining fixture layout design using ant colony algorithm based continuous optimization method</article-title>. <source>Int J Adv Manuf Technol</source> <year>2009</year>; <volume>45</volume>(<issue>9–10</issue>): <fpage>922</fpage>–<lpage>934</lpage>.</citation>
</ref>
<ref id="bibr13-0954405412457121">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Y</given-names></name>
<name><surname>Chen</surname><given-names>X</given-names></name>
<name><surname>Gindy</surname><given-names>J</given-names></name><etal/>
</person-group>. <article-title>Elastic deformation of a fixture and turbine blade system based on finite element analysis</article-title>. <source>Int J Adv Manuf Technol</source> <year>2008</year>; <volume>36</volume>(<issue>3–4</issue>): <fpage>296</fpage>–<lpage>304</lpage>.</citation>
</ref>
<ref id="bibr14-0954405412457121">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nicholas</surname><given-names>A</given-names></name>
<name><surname>Rencis</surname><given-names>Y</given-names></name>
<name><surname>Rong</surname><given-names>Y</given-names></name>
</person-group>. <article-title>Development of a finite element analysis tool for fixture design integrity verification and optimization</article-title>. <source>Int J Adv Manuf Technol</source> <year>2005</year>; <volume>25</volume>(<issue>5–6</issue>): <fpage>409</fpage>–<lpage>419</lpage>.</citation>
</ref>
<ref id="bibr15-0954405412457121">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Qin</surname><given-names>GH</given-names></name>
<name><surname>Zhang</surname><given-names>WH</given-names></name>
<name><surname>Wu</surname><given-names>Zi</given-names></name><etal/>
</person-group>. <article-title>Systematic modeling of workpiece-fixture geometric default and compliance for the prediction of workpiece machining error</article-title>. <source>J Manuf Sci Eng</source> <year>2007</year>; <volume>129</volume>(<issue>4</issue>): <fpage>789</fpage>–<lpage>801</lpage>.</citation>
</ref>
<ref id="bibr16-0954405412457121">
<label>16.</label>
<citation citation-type="other"><collab><italic>Design Expert user’s manual</italic>, ver.7.0.0</collab>.</citation>
</ref>
<ref id="bibr17-0954405412457121">
<label>17.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kartalopoulos</surname><given-names>SV</given-names></name>
</person-group>. <source>Understanding neural networks and fuzzy logic- Basic concepts and applications</source>. <publisher-loc>New Delhi, India</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>, <year>2000</year>.</citation>
</ref>
<ref id="bibr18-0954405412457121">
<label>18.</label>
<citation citation-type="journal">
<collab>Mathworks, Inc.</collab> <source>Neural network tool box user’s guide</source>. <year>2006</year>.</citation>
</ref>
<ref id="bibr19-0954405412457121">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Benardos</surname><given-names>PG</given-names></name>
<name><surname>Vosniakos</surname><given-names>GC</given-names></name>
</person-group>. <article-title>Optimizing feedforward artificial neural network architecture</article-title>. <source>Eng Appl Artif Intell</source> <year>2006</year>; <volume>20</volume>(<issue>3</issue>): <fpage>365</fpage>–<lpage>382</lpage>.</citation>
</ref>
<ref id="bibr20-0954405412457121">
<label>20.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Vishnupriyan</surname><given-names>S</given-names></name>
<name><surname>Majumder</surname><given-names>MC</given-names></name>
<name><surname>Ramachandran</surname><given-names>KP</given-names></name>
</person-group>. <article-title>Optimal fixture parameters considering locator errors</article-title>. <source>Int J Prod Res</source> <year>2011</year>; <volume>49</volume>(<issue>21</issue>): <fpage>6343</fpage>–<lpage>6361</lpage>.</citation>
</ref>
<ref id="bibr21-0954405412457121">
<label>21.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Özel</surname><given-names>T</given-names></name>
<name><surname>Karpat</surname><given-names>Y</given-names></name>
</person-group>. <article-title>Predictive modeling of surface roughness and tool wear in hard turning using regression and neural networks</article-title>. <source>Int J Mach Tools Manuf</source> <year>2005</year>; <volume>45</volume>(<issue>4–5</issue>): <fpage>467</fpage>–<lpage>479</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>