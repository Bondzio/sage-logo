<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">HPC</journal-id>
<journal-id journal-id-type="hwp">sphpc</journal-id>
<journal-title>The International Journal of High Performance Computing Applications</journal-title>
<issn pub-type="ppub">1094-3420</issn>
<issn pub-type="epub">1741-2846</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1094342011431591</article-id>
<article-id pub-id-type="publisher-id">10.1177_1094342011431591</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Accelerating analysis of void space in porous materials on multicore and GPU platforms</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Martin</surname>
<given-names>Richard L</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011431591">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Prabhat</surname>
</name>
<xref ref-type="aff" rid="aff1-1094342011431591">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Donofrio</surname>
<given-names>David D</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011431591">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sethian</surname>
<given-names>James A</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011431591">1</xref>
<xref ref-type="aff" rid="aff2-1094342011431591">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Haranczyk</surname>
<given-names>Maciej</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011431591">1</xref>
<xref ref-type="corresp" rid="corresp1-1094342011431591"/>
</contrib>
<bio>
<title>Author’s Biographies</title>
<p>
<italic>Richard Luis Martin</italic> is a Postdoctoral Research Fellow in the Scientific Computing Group at Lawrence Berkeley National Laboratory. He received his PhD in Cheminformatics and BSc in Computer Science and Mathematics from The University of Sheffield. His research interests include the development of algorithms and descriptors for classification and screening.</p>
<p>
<italic>Prabhat</italic> is a member of the Visualization group at Berkeley Lab. Prabhat received an MS in Computer Science from Brown University in 2001 and a B.Tech in Computer Science and Engineering from IIT-Delhi in 1999. His current research interests include scientific visualization, high-performance computing, parallel I/O, GPGPU, machine learning and applied statistics.</p>
<p>
<italic>David Donofrio</italic> is a member of the Advanced Technologies Group at Berkeley Lab. David received his degree in Computer Engineering from Virginia Tech in 2001 and was previously a member of Intel’s 3D Graphics Architecture team. His research interests include: energy efficient computing, computer architecture, high performance computing and performance modeling.</p>
<p>
<italic>James A. Sethian</italic> is Professor of Mathematics at the University of California, Berkeley, and Head of the Mathematics Department at the Lawrence Berkeley National Laboratory.</p>
<p>
<italic>Maciej Haranczyk</italic> is a Research Scientist in the Scientific Computing Group at Berkeley Lab. Dr. Haranczyk received a PhD and MS degrees in Chemistry from University of Gdansk, Poland. He spent his post-doctoral appointment as a 2008 Glenn T. Seaborg Fellow at Berkeley Lab. His research interests include development of methods, tools and approaches to enable efficient molecular and materials discovery.</p>
</bio>
</contrib-group>
<aff id="aff1-1094342011431591">
<label>1</label>Lawrence Berkeley National Laboratory, Berkeley, USA</aff>
<aff id="aff2-1094342011431591">
<label>2</label>Department of Mathematics, University of California, Berkeley, USA</aff>
<author-notes>
<corresp id="corresp1-1094342011431591">Maciej Haranczyk, Computational Research Division, Lawrence Berkeley National Laboratory, One Cyclotron Rd, MS 50F-1650 Berkeley, CA 94720, USA E-mail: <email>mharanczyk@lbl.gov</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>11</month>
<year>2012</year>
</pub-date>
<volume>26</volume>
<issue>4</issue>
<issue-title>Special Issue: Manycore and Accelerator-based High-performance Scientific Computing</issue-title>
<fpage>347</fpage>
<lpage>357</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Developing computational tools that enable discovery of new materials for energy-related applications is a challenge. Crystalline porous materials are a promising class of materials that can be used for oil refinement, hydrogen or methane storage as well as carbon dioxide capture. Selecting optimal materials for these important applications requires analysis and screening of millions of potential candidates. Recently, we proposed an automatic approach based on the Fast Marching Method (FMM) for performing analysis of void space inside materials, a critical step preceding expensive molecular dynamics simulations. This breakthrough enables unsupervised, high-throughput characterization of large material databases. The algorithm has three steps: (1) calculation of the cost-grid which represents the structure and encodes the occupiable positions within the void space; (2) using FMM to segment out patches of the void space in the grid of (1), and find how they are connected to form either periodic channels or inaccessible pockets; and (3) generating blocking spheres that encapsulate the discovered inaccessible pockets and are used in proceeding molecular simulations. In this work, we expand upon our original approach through (A) replacement of the FMM-based approach with a more computationally efficient flood fill algorithm; and (B) parallelization of all steps in the algorithm, including a GPU implementation of the most computationally expensive step, the cost-grid generation. We report the acceleration achievable in each step and in the complete application, and discuss the implications for high-throughput material screening.</p>
</abstract>
<kwd-group>
<kwd>code optimization</kwd>
<kwd>general purpose computation on GPUs</kwd>
<kwd>multicore programming</kwd>
<kwd>porous materials</kwd>
<kwd>screening</kwd>
<kwd>zeolites</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1094342011431591">
<title>1 Introduction</title>
<p>Crystalline porous materials have found wide use in industry since the late 1950s. They are commonly used as chemical catalysts, in particular as cracking catalysts in oil refinement, membranes for separations and as water softeners (<xref ref-type="bibr" rid="bibr1-1094342011431591">Auerbach et al., 2004</xref>; <xref ref-type="bibr" rid="bibr23-1094342011431591">Krishna and van Baten, 2007</xref>; <xref ref-type="bibr" rid="bibr34-1094342011431591">Smit and Maesen, 2008a</xref>,<xref ref-type="bibr" rid="bibr35-1094342011431591">b</xref>). There is an increasing interest in utilizing these materials as membranes or adsorbents for carbon dioxide capture applications as well as for hydrogen or natural gas storage (<xref ref-type="bibr" rid="bibr28-1094342011431591">Millward and Yaghi, 2005</xref>; <xref ref-type="bibr" rid="bibr2-1094342011431591">Bannerjee et al., 2008</xref>; <xref ref-type="bibr" rid="bibr6-1094342011431591">Choi et al., 2008</xref>; <xref ref-type="bibr" rid="bibr43-1094342011431591">Walton et al., 2008</xref>; <xref ref-type="bibr" rid="bibr37-1094342011431591">Sumida et al., 2009</xref>). The need for optimal materials, which would be inexpensive, safe and efficient, has stimulated researchers to develop databases containing millions of predicted material structures (<xref ref-type="bibr" rid="bibr11-1094342011431591">Earl and Deem, 2006</xref>; <xref ref-type="bibr" rid="bibr8-1094342011431591">Deem et al., 2009</xref>; <xref ref-type="bibr" rid="bibr14-1094342011431591">Foster and Treacy, 2010</xref>). Development of such databases holds great promise for the discovery of new materials for many applications. However, it is now being realized that in order to make such discoveries possible, new computational and cheminformatics techniques have to be developed to characterize, categorize, and screen such large databases. Approaches based on manually intensive visual analysis techniques are simply infeasible for screening large numbers of structures in a high-throughput manner.</p>
<p>An important aspect of the analysis of porous materials is determination of a guest molecule-related accessibility of their void space. In particular, this involves the detection of inaccessible pockets, which can be occupied by guest molecules in computer calculations, even though such pockets are inaccessible in adsorption experiments. It is important to account for (and often artificially block or exclude) these pockets in the calculation of guest-accessible volumes or surface areas, or in the prediction of guest-related properties using molecular simulation techniques. For example, in Monte Carlo (MC) simulations of adsorption (<xref ref-type="bibr" rid="bibr15-1094342011431591">Frenkel and Smit, 2002</xref>), the blocking procedure can be a simple distance check from the center of the small pockets and a rejection of all Monte Carlo trial moves that would place a molecule inside a certain radius (<xref ref-type="bibr" rid="bibr3-1094342011431591">Bates et al., 1996</xref>; <xref ref-type="bibr" rid="bibr10-1094342011431591">Dubbeldam and Smit, 2003</xref>). The latter sets of positions of pocket centers and the corresponding radii are referred to as the blocking spheres. The importance of pore blocking in Monte Carlo simulations has been recently re-emphasized by <xref ref-type="bibr" rid="bibr24-1094342011431591">Krishna and van Baten (2010)</xref>. Similar to MC simulations, molecular dynamics simulations have to account for such pockets in order to ensure that guest molecules are not placed in inaccessible areas.</p>
<p>Recently, we presented an automatic approach for determining accessibility of the void space of porous materials, thereby enabling execution of molecular simulation-based calculation of materials' properties in an unsupervised, high-throughput manner (<xref ref-type="bibr" rid="bibr19-1094342011431591">Haranczyk and Sethian, 2010</xref>). In our approach, we used a partial differential equation (PDE)-based front propagation technique to segment out channels and inaccessible pockets of a periodic unit cell of a material. Unlike other approaches that approximate guest molecules with a spherical probe, the general framework of our approach (<xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian, 2009</xref>) allows guest molecules to have more complex and flexible shapes. We model complex objects built from solid blocks connected by flexible links (molecular worms). The new capabilities offered by our approach (<xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian, 2009</xref>, <xref ref-type="bibr" rid="bibr19-1094342011431591">2010</xref>) come at the price of increased computational cost associated with the discretization and analysis of the configuration space of a guest molecule inside the material.</p>
<p>We make three key observations regarding our approach which enable us to effectively utilize modern high-performance computing platforms. First, our approach can be easily applied to different materials in the database in a distributed setting. Since analysis of one material is independent of other materials, each material can be processed on a single node with no inter-node communication requirements. Secondly, our approach is memory intensive; we typically require 4 to 64 GB of memory for processing a single material. This amount of memory is typically available on a single HPC node, but is usually shared across multiple CPU cores. Sometimes HPC nodes might also have a powerful coprocessor card (GPU or vector processor) available with much less memory and limited bandwidth. We need to be cognizant of this trend in modern HPC systems and utilize all available computational horsepower on a single node. Finally, the most computationally expensive step in our analysis (i.e. cost grid calculation) has ample parallelism in its formulation: the step can proceed independently at each discretization of the configuration space.</p>
<p>Following these observations, we have refactored our algorithms and implemented optimized versions on an AMD multicore CPU and an Nvidia GPU. We discuss specific details of our algorithm and demonstrate dramatic speedup over our serial baseline implementation in the following sections.</p>
</sec>
<sec id="section2-1094342011431591">
<title>2 Related work</title>
<p>Traditional approaches for analyzing accessibility of the void space in crystalline porous materials involve visual analysis. Such analyses are typically performed by inspection of the so-called pore landscapes (<xref ref-type="bibr" rid="bibr24-1094342011431591">Krishna and van Baten, 2010</xref>), which are isosurfaces corresponding to the maximum accessible free energy level (<xref ref-type="bibr" rid="bibr22-1094342011431591">Keffer et al., 1996</xref>). An alternative approach involves analysis of abstract structure representations such as chemical hieroglyphs (<xref ref-type="bibr" rid="bibr38-1094342011431591">Theisen et al., 2010</xref>). Automatic detection of internal cavities has been explored in the context of zeolites (<xref ref-type="bibr" rid="bibr12-1094342011431591">First et al., 2011</xref>)---using “largest void cylinders” and spherical “cages”---and proteins (<xref ref-type="bibr" rid="bibr39-1094342011431591">Till and Ullmann, 2010</xref>), and the more general question of finding possible pathways through chemical systems has been addressed in both proteins (<xref ref-type="bibr" rid="bibr31-1094342011431591">Petrek et al., 2006</xref>) and materials (<xref ref-type="bibr" rid="bibr5-1094342011431591">Blatov et al., 2006</xref>; <xref ref-type="bibr" rid="bibr13-1094342011431591">Foster et al., 2006</xref>; <xref ref-type="bibr" rid="bibr17-1094342011431591">Haldoupis et al., 2010</xref>; <xref ref-type="bibr" rid="bibr44-1094342011431591">Willems et al., 2011</xref>). All of the aforementioned references, with the exception of <xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian (2009)</xref>, attempt to study paths of a spherical probe representing the molecule inside a convex hull constructed from atoms of a protein or materials framework.</p>
<p>To the best of our knowledge, all of the approaches for automatic analysis of porous materials are designed for single-threaded execution. We are not aware of a study which implements these techniques on heterogeneous computing architectures and discusses performance characteristics. We do note, however, that the field of computational chemistry routinely uses HPC systems (including multicore CPUs and vector machines) for determining electronic structure and running molecular dynamics simulations. GPU platforms have been recently utilized in the latter applications (<xref ref-type="bibr" rid="bibr40-1094342011431591">Ufimtsev and Martinez, 2008</xref>, <xref ref-type="bibr" rid="bibr41-1094342011431591">2009a</xref>,<xref ref-type="bibr" rid="bibr42-1094342011431591">b</xref>; <xref ref-type="bibr" rid="bibr36-1094342011431591">Stone et al., 2010</xref>), and in an evolutionary algorithm for zeolite framework generation (<xref ref-type="bibr" rid="bibr26-1094342011431591">Maitre et al., 2009a</xref>,b; <xref ref-type="bibr" rid="bibr25-1094342011431591">Krüger et al., 2010</xref>; <xref ref-type="bibr" rid="bibr4-1094342011431591">Baumes et al., 2011</xref>; <xref ref-type="bibr" rid="bibr21-1094342011431591">Jiang et al., 2011</xref>).</p>
</sec>
<sec id="section3-1094342011431591">
<title>3 Science application</title>
<p>We have recently developed an approach to analyzing the accessibility of the void space in a porous material to a guest molecule. Our approach can accommodate simple approximations of a guest molecule as a spherical probe, as well as more complex models resembling the shape and flexibility of a “real” molecule (<xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian, 2009</xref>). In the latter model, complex objects are built from solid blocks connected by flexible links, and they are able to change orientation and/or shape during the traversal of a chemical structure, allowing them to reach areas not accessible to either a single large spherical probe or rigid real-shape probes.</p>
<p>In the above approach, we cast this problem as an Hamilton--Jacobi-type Eikonal equation in configuration space describing a guest molecule inside a material:<disp-formula id="disp-formula1-1094342011431591">
<mml:math id="mml-disp1-1094342011431591">
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi mathvariant="normal">∇</mml:mi>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
</mml:math>
<graphic alternate-form-of="disp-formula1-1094342011431591" xlink:href="10.1177_1094342011431591-eq1.tif"/>
</disp-formula>
</p>
<p>Here, <inline-formula id="inline-formula1-1094342011431591">
<mml:math id="mml-inline1-1094342011431591">
<mml:mi>U</mml:mi>
</mml:math>
</inline-formula> is the minimal total cost and <inline-formula id="inline-formula2-1094342011431591">
<mml:math id="mml-inline2-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> is a cost function defined at each point <inline-formula id="inline-formula3-1094342011431591">
<mml:math id="mml-inline3-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> in the domain, corresponding to its ability to be occupied. The equation is solved by using a variant of Fast Marching Methods (FMM) (<xref ref-type="bibr" rid="bibr32-1094342011431591">Sethian, 1996</xref>, <xref ref-type="bibr" rid="bibr33-1094342011431591">1999</xref>), which are Dijkstra-like (<xref ref-type="bibr" rid="bibr9-1094342011431591">Dijkstra, 1959</xref>) methods for solving boundary value problems of the form of the Eikonal equation. Here, abstractly, the cost function is defined at the beginning of the problem, and the solution <inline-formula id="inline-formula4-1094342011431591">
<mml:math id="mml-inline4-1094342011431591">
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> to the above problem represents the total cost, which is the smallest obtainable integral of <inline-formula id="inline-formula5-1094342011431591">
<mml:math id="mml-inline5-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, considered over all possible trajectories throughout the computational domain from a start point to a finish point. The latter feature can then be used to construct practical techniques enabling, for example, the determination of shortest paths (<xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian, 2009</xref>), and a prediction of the accessibility of sections of the void space, e.g. detection of inaccessible pockets (<xref ref-type="bibr" rid="bibr19-1094342011431591">Haranczyk and Sethian, 2010</xref>).</p>
<p>The latter application of our approach, being of special interest in this article, has three steps:<list list-type="order">
<list-item>
<p>Calculation of cost <inline-formula id="inline-formula6-1094342011431591">
<mml:math id="mml-inline6-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> at each grid point <inline-formula id="inline-formula7-1094342011431591">
<mml:math id="mml-inline7-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> of the discretized domain. Point <inline-formula id="inline-formula8-1094342011431591">
<mml:math id="mml-inline8-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> corresponds to a configuration of a probe inside a material, and in the simplest case of a spherical probe it corresponds to a position inside a material. The time requirement scales linearly with <inline-formula id="inline-formula9-1094342011431591">
<mml:math id="mml-inline9-1094342011431591">
<mml:mi>N</mml:mi>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula10-1094342011431591">
<mml:math id="mml-inline10-1094342011431591">
<mml:mi>N</mml:mi>
</mml:math>
</inline-formula> is the total number of mesh points in the computational domain.</p>
</list-item>
<list-item>
<p>Segmenting the grid into distinct, aperiodic regions of void space (patches). An illustration of this process is provided in <xref ref-type="fig" rid="fig1-1094342011431591">Figure 1</xref>. After segmentation, periodic boundary conditions are applied, and regions which connect across the periodic boundary are connected. Thus, those regions which constitute channels through the void space can be identified, with the remaining regions constituting inaccessible pockets.</p>
</list-item>
<list-item>
<p>Calculation of blocking spheres to be used as “exclusion zones” in the proceeding molecular simulations. Blocking spheres enclose all pockets of Step 2 completely, without intruding upon any channels of the system.</p>
</list-item>
</list>
</p>
<fig id="fig1-1094342011431591" position="float">
<label>Figure 1.</label>
<caption>
<p>These snapshots illustrate a propagating front (in green) that explores void channels in the periodic unit cell of DDR zeolite. Red arrows point to inaccessible pockets that cannot be accessed by the front.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig1.tif"/>
</fig>
<p>In this work we take the above application framework as a serial baseline prototype, and improve upon it in two major ways. First, we replace the FMM-based method in the segmentation step with a non-PDE-based flood fill (also known as seed fill or bucket fill) algorithm. Flood fill is a technique whereby connected regions of adjacent grid points are efficiently identified, and is in common usage, for instance in image processing applications. This change constitutes a speedup since the elements of the original algorithm associated with the total cost and causality of propagating fronts are removed at the cost of not being able to predict shortest paths. Secondly, we develop and implement parallel algorithms for each of the three steps.</p>
<p>The absolute runtime for Steps 1--3 of the approach depends on factors including the number of grid points used to describe the system. The grid resolution depends on the requested accuracy and specific characteristics of the investigated material (e.g. density, which correlates with volume of the void space to be investigated); see <xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian (2009</xref>, <xref ref-type="bibr" rid="bibr19-1094342011431591">2010</xref>) and <xref ref-type="bibr" rid="bibr44-1094342011431591">Willems et al. (2011)</xref> for detailed discussions. We profiled typical “production” runs of our serial baseline implementation and discovered Step 1 to be the most time consuming, typically requiring an order of magnitude more time than Steps 2 or 3. This trend only gets worse as the size of the problem under investigation increases. <xref ref-type="fig" rid="fig2-1094342011431591">Figure 2</xref> illustrates this point with the example of four zeolite materials in which we detected void space pockets inaccessible to methane. These examples involved the calculation of a three-dimensional grid with a step size of 0.1 Å; due to the different sizes of the systems (the size of the periodic box representing the crystalline material) for EDI, HEU, TSC and LTN zeolite materials, this translates to approximately 300K, 2.5M, 29M and 45M grid points in each structure respectively. It can be seen that as the volume of the structures increases, the proportion of time spent on Steps 1 and 3 increases, while the proportion for Step 2 decreases.</p>
<fig id="fig2-1094342011431591" position="float">
<label>Figure 2.</label>
<caption>
<p>Profile of execution time on various Zeolite structures.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig2.tif"/>
</fig>
<p>Within our aim of parallelizing the whole algorithm, our strategy in this work was to primarily focus on optimizing the most time-consuming task, i.e. calculating the cost function on the discretized configuration grid, which is also the most intrinsically parallel step. In the following, we will briefly discuss the calculations involved in each step. Further details can be found in <xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian (2009)</xref>.</p>
<p>The most straightforward cost function <inline-formula id="inline-formula11-1094342011431591">
<mml:math id="mml-inline11-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>, where <inline-formula id="inline-formula12-1094342011431591">
<mml:math id="mml-inline12-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> is a grid point, is defined as follows: <inline-formula id="inline-formula13-1094342011431591">
<mml:math id="mml-inline13-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>1</mml:mn>
</mml:math>
</inline-formula> for each point <inline-formula id="inline-formula14-1094342011431591">
<mml:math id="mml-inline14-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> which can be occupied, <inline-formula id="inline-formula15-1094342011431591">
<mml:math id="mml-inline15-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mi mathvariant="normal">∞</mml:mi>
</mml:math>
</inline-formula> otherwise. Here, an “occupiable” point means a position in which the probe is not colliding with any atom of the material’s framework; a collision occurs when the distance between the center of the probe and any of the structure atoms is smaller than the sum of their specified radii. The latter case is equivalent to a hard sphere approximation of atoms. More advanced definitions of the cost functions (including considerations of specific interactions) have also been proposed (<xref ref-type="bibr" rid="bibr18-1094342011431591">Haranczyk and Sethian, 2009</xref>, <xref ref-type="bibr" rid="bibr19-1094342011431591">2010</xref>).</p>
<p>Pseudocode for the cost-grid algorithm is given below. The algorithm uses two sets of coordinates: fractional and Cartesian. Fractional coordinates are used to define positions with respect to the periodic unit cell's vectors, with values in the range 0-1 indicating a position within the unit cell. These coordinates can easily handle periodic boundary conditions. Cartesian coordinates are used to determine distances between atoms.</p>
<p>
<monospace>Analyze unit cell vectors to determine all periodic unit cells which must be checked to find nearest coordinates</monospace>
<monospace>For each discrete grid point</monospace>
<monospace>If any fractional coordinates outside 0-1 range</monospace>
<monospace> Output distance of zero (position rejected)</monospace>
<monospace>Else</monospace>
<monospace> Initialize minimum distance</monospace>
<monospace> For each atom in probe molecule</monospace>
<monospace> For each atom in structure</monospace>
<monospace>For each periodic unit cell</monospace>
<monospace>Calculate Cartesian distance between probe and periodic image of structure atom</monospace>
<monospace>Subtract atom radii</monospace>
<monospace>Update minimum distance</monospace>
<monospace>If minimum distance less than or equal to zero</monospace>
<monospace> Output distance of zero (collision)</monospace>
<monospace>(end image loop)</monospace>
<monospace> (end structure loop)</monospace>
<monospace> (end probe loop)</monospace>
<monospace> Output minimum distance (no collision)</monospace>
<monospace>(end if/else)</monospace>
<monospace>(end)</monospace>
</p>
<p>The nested loops in the above pseudocode, and the independence of each grid point calculation, make this algorithm amenable to parallelization; furthermore, the requirement to be able to calculate <inline-formula id="inline-formula16-1094342011431591">
<mml:math id="mml-inline16-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> for millions of grid points also makes this algorithm an interesting candidate for a GPU implementation. We give details of these implementations in the following section. The two remaining steps in the application are also parallelizable, and we provide pseudocode for the segmentation step below. The sphere blocking algorithm for inaccessible pockets has previously been described in detail (<xref ref-type="bibr" rid="bibr19-1094342011431591">Haranczyk and Sethian, 2010</xref>). The parallel implementation of Steps 2--3 will be discussed in sections 4.7--4.8.</p>
<p>The segmentation step identifies a set of distinct segments (patches) of the void space and assigns them unique identifiers (SEGMENTNUMBERs). The flood fill step requires keeping track of a “set” value for each grid point, which during the fill denotes whether this point has been visited (KNOWN), considered (TRIAL) or otherwise (FAR). Initially, all points with <inline-formula id="inline-formula17-1094342011431591">
<mml:math id="mml-inline17-1094342011431591">
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">&gt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula> are FAR, as they are occupiable but the segment to which they belong is unknown. When a point is visited, it becomes KNOWN; TRIAL points are those that have been found to be adjacent to some KNOWN point, and are waiting in a stack to have their adjacent points considered in turn. After a segment has been filled, all points therein are assigned to KNOWN+SEGMENTNUMBER for future identification of which segment (i.e. set-KNOWN) they belong to.</p>
<p>
<monospace>Set FAR 0</monospace>
<monospace>Set TRIAL 1</monospace>
<monospace>Set KNOWN 2</monospace>
<monospace>Set SEGMENTNUMBER 1</monospace>
<monospace>For each discrete grid point, x</monospace>
<monospace> If x is FAR</monospace>
<monospace>  Assign x to be TRIAL</monospace>
<monospace>  Push x to stack</monospace>
<monospace>  While stack is non-empty</monospace>
<monospace>   Pop the stack, retrieving point y</monospace>
<monospace>   Assign y to be KNOWN</monospace>
<monospace>   For each point z adjacent to y</monospace>
<monospace>    If z is FAR</monospace>
<monospace>     Assign z to be TRIAL</monospace>
<monospace>     Push z to stack</monospace>
<monospace>    (end if)</monospace>
<monospace>   (end adjacent points to stack loop)</monospace>
<monospace>  (end stack pop loop)</monospace>
<monospace>  Now stack exhausted, assign all KNOWN points to KNOWN+SEGMENTNUMBER</monospace>
<monospace>  Increment SEGMENTNUMBER</monospace>
<monospace> (end if statement for this segment)</monospace>
<monospace>(end loop over entire grid)</monospace>
</p>
<p>Following the segmentation, segments which are adjacent through consideration of the periodic boundary are detected and merged. At this point, segments can be classified as either channels or pockets. If it is possible to travel within one segment from one unit cell to the same position in an adjacent cell, then this segment is a channel; this property is determined through consideration of the periodic boundary adjacency matrix which encodes the connections between segments and which boundaries are crossed. All non-channel segments must be pockets, and will be blocked; note that it is possible for a series of segments to be connected across the periodic boundary and yet not form a channel (i.e. they form a periodic pocket).</p>
</sec>
<sec id="section4-1094342011431591" sec-type="methods">
<title>4 Methods</title>
<p>We implemented optimized versions of the steps detailed in the previous section and tested performance on a high-end workstation with Opteron Magny-Cours processors. We also tested performance of the code on an Nvidia Fermi C2050 card. We chose these particular hardware platforms because they are representative of single nodes in our larger HPC facilities. Therefore, we can leverage the results from our present work for future large concurrency runs.</p>
<sec id="section5-1094342011431591">
<title>4.1 Dataset</title>
<p>For testing purposes, we chose the most challenging structure with the largest periodic unit cell in the IZA dataset of zeolites, LTN. Its unit cell is orthogonal and cubic, comprising 2304 atoms, of which 1536 (two thirds) are oxygen, and 768 (one third) are silicon. We sampled the periodic unit cell at a 0.1 Å resolution, resulting in a grid of 357 elements in each dimension (45,499,293 grid points total). The probe used to examine this structure is methane, represented as a single sphere of radius 1.825 Å (united atom approximation).</p>
<p>For each grid point, in addition to the minimum distance as described in the pseudocode, the algorithm must output a “set” (i.e. accessible, inaccessible or out of bounds). These two large arrays of values are encoded as character and unsigned short int variables respectively, resulting in a total of <inline-formula id="inline-formula18-1094342011431591">
<mml:math id="mml-inline18-1094342011431591">
<mml:mo stretchy="false">~</mml:mo>
</mml:math>
</inline-formula>136.5 million bytes (130.2MB) of data for this problem size. In the case of the multicore CPU code, this data is written directly into main memory and is analyzed by subsequent steps in our program (i.e. segmentation, etc.). However, for the GPU implementation, partial results for the grid are computed, and then read back and placed into main memory on the host.</p>
</sec>
<sec id="section6-1094342011431591">
<title>4.2 Software</title>
<p>We developed our code in C++ and used pthreads for the multi-threaded implementation. We used the gcc compiler with -O3 options for compiling optimized code. We also performed manual loop unrolling and used SSE intrinsics for using SIMD hardware on the CPU. We used CUDA for porting our code to the GPUs. Specific GPU optimizations are listed in a following section. Our code uses single-precision floating point on both CPU and GPU platforms. We verified the results of our optimized CPU and GPU implementations against a gold-standard unoptimized CPU code, and checked that our results were consistent.</p>
</sec>
<sec id="section7-1094342011431591">
<title>4.3 Hardware</title>
<p>We were primarily interested in optimizing the expensive cost calculation step, i.e. Step 1, on a multicore CPU and on GPUs. Details pertaining to the hardware architecture for the Magny-Cours, FX5800 and Fermi C2050 are presented in <xref ref-type="table" rid="table1-1094342011431591">Table 1</xref>. Extensive descriptions of GPU hardware and programming optimizations are available in <xref ref-type="bibr" rid="bibr29-1094342011431591">NVIDIA (2011a</xref>,<xref ref-type="bibr" rid="bibr30-1094342011431591">b</xref>) and <xref ref-type="bibr" rid="bibr16-1094342011431591">GPGPU.org (2011)</xref>.</p>
<table-wrap id="table1-1094342011431591" position="float">
<label>Table 1.</label>
<caption>
<p>Details of the evaluated architectures.</p>
</caption>
<graphic alternate-form-of="table1-1094342011431591" xlink:href="10.1177_1094342011431591-table1.tif"/>
<table>
<thead>
<tr>
<th>Core Architecture</th>
<th>AMD Opteron</th>
<th>NVIDIA GF100</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type</td>
<td>out-of-order</td>
<td>in-order</td>
</tr>
<tr>
<td>
</td>
<td>SMD</td>
<td>SIMT</td>
</tr>
<tr>
<td>Clock (GHz)</td>
<td>2.1</td>
<td>1.15</td>
</tr>
<tr>
<td>SP GFlop/s</td>
<td>8.4</td>
<td>73.6</td>
</tr>
<tr>
<td>L1 Data Cache</td>
<td>128K</td>
<td>16 KB</td>
</tr>
<tr>
<td>L2 Data Cache</td>
<td>512K</td>
<td>48 KB</td>
</tr>
<tr>
<td>SMP Architecture</td>
<td>Opteron 6172 Magny-Cours</td>
<td>Tesla C2050 (Fermi)</td>
</tr>
<tr>
<td>Threads per core</td>
<td>1</td>
<td>4096</td>
</tr>
<tr>
<td>Cores per socket</td>
<td>12</td>
<td>14<sup>a</sup>
</td>
</tr>
<tr>
<td>Sockets per SMP</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>Shared Last-level cache</td>
<td>12 MB</td>
<td>768 KB</td>
</tr>
<tr>
<td>Aggregate System DRAM</td>
<td>48 GB</td>
<td>3 GB</td>
</tr>
<tr>
<td>Aggregate DRAM GB/s</td>
<td>80</td>
<td>144 (no ecc)</td>
</tr>
<tr>
<td>Aggregate SP GFlop/s</td>
<td>100.8</td>
<td>1030.4</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1094342011431591">
<p>
<sup>a</sup>For simplicity, we call each shared multiprocessor (SM) on a GPU a “core”. All bandwidths and flop rates are peak theoretical.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section8-1094342011431591">
<title>4.4 Cost calculation step: algorithm characteristics</title>
<p>We profiled the cost calculation step in the program and determined that it was compute-bound. The innermost loop of the algorithm presented in Section 3 is the most expensive, involving calculation of distances over thousands of structure atoms. We are able to fit data corresponding to atom positions in the L1 cache on the CPU, and constant memory on the GPU. We are primarily limited by the performance of the floating point units.</p>
<p>The size of the computational grid can be large (<inline-formula id="inline-formula19-1094342011431591">
<mml:math id="mml-inline19-1094342011431591">
<mml:mo stretchy="false">~</mml:mo>
</mml:math>
</inline-formula>16GB), and this typically does not fit in GPU memory. We overcome this limitation by double buffering: we compute different parts of the grid while the results from the first part are read back asynchronously. The proportion of time spent in transferring data over the PCIe bus to the host memory is small compared to the cost of computing the grid; thereby we avoid both major limitations that plague typical GPGPU applications.</p>
</sec>
<sec id="section9-1094342011431591">
<title>4.5 Optimizations for multicore CPU implementation</title>
<p>For the multi-threaded CPU implementation, we create a pool of threads (with the number of threads being equal to the number of cores). We direct each thread to analyze slices of the sampling grid where <inline-formula id="inline-formula20-1094342011431591">
<mml:math id="mml-inline20-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> is constant (i.e. <inline-formula id="inline-formula21-1094342011431591">
<mml:math id="mml-inline21-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula>-slices). The first thread is initialized with <inline-formula id="inline-formula22-1094342011431591">
<mml:math id="mml-inline22-1094342011431591">
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">=</mml:mo>
<mml:mn>0</mml:mn>
</mml:math>
</inline-formula>, and each subsequent thread initialized with the next unclaimed value for <inline-formula id="inline-formula23-1094342011431591">
<mml:math id="mml-inline23-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula>. Each thread then loops over the other dimensions of the grid, beginning with the slowest (the <inline-formula id="inline-formula24-1094342011431591">
<mml:math id="mml-inline24-1094342011431591">
<mml:mi>y</mml:mi>
</mml:math>
</inline-formula> dimension) and ending with the probe orientation or conformation dimensions, if necessitated by the probe molecule. Early termination criteria are applied if a point is found to be out of bounds or to collide with the structure, and the thread moves on to the next grid point. Once a thread has examined all grid points within its <inline-formula id="inline-formula25-1094342011431591">
<mml:math id="mml-inline25-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula>-slice, it updates <inline-formula id="inline-formula26-1094342011431591">
<mml:math id="mml-inline26-1094342011431591">
<mml:mi>x</mml:mi>
</mml:math>
</inline-formula> to the next unclaimed value and begins processing that slice. This is repeated until all slices have been processed. This dynamic schedule is preferable because structures may have a non-uniform allocation of atoms, and it might be hard to come up with a good a priori static allocation of work across threads. In general, we tried to minimize synchronizations and data sharing across multiple threads.</p>
<p>In addition to multithreading, we optimized the per-thread performance with SIMD extensions, and further improved performance by minimizing coordinate conversion (e.g. Cartesian <inline-formula id="inline-formula27-1094342011431591">
<mml:math id="mml-inline27-1094342011431591">
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>z</mml:mi>
</mml:math>
</inline-formula> to fractional <inline-formula id="inline-formula28-1094342011431591">
<mml:math id="mml-inline28-1094342011431591">
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>b</mml:mi>
<mml:mo stretchy="false">,</mml:mo>
<mml:mi>c</mml:mi>
</mml:math>
</inline-formula>) operations with respect to the unoptimized function. We also manually inline functions and avoid unnecessary if--else statements. Finally, we employ loop unrolling to minimize instruction dependencies.</p>
</sec>
<sec id="section10-1094342011431591">
<title>4.6 Optimizations for GPU implementation</title>
<p>The GPU approach differs from the multicore implementation in that each thread on the GPU analyzes a single grid point; however, the procedure for calculating the distance and set values for each grid point is the same, including the early termination criteria. We take special care to pack constant quantities (atom coordinates, etc.) into the GPU constant memory. This has the advantage of fast access from the GPU cores as well as reduced register pressure, enabling more threads to be executed.</p>
<p>Our optimized GPU kernel includes the optimizations applied to the CPU function (excluding SIMD). It consumes 36 bytes of shared memory and 18 registers. We maximize occupancy by tailoring the arrangement of threads specifically to each GPU. Finally, we also use optimal functions for single-precision operations such as fmin() and rintf().</p>
</sec>
<sec id="section11-1094342011431591">
<title>4.7 Parallelization of the segmentation step</title>
<p>In the pseudocode provided in Section 3, the flood fill algorithm segments accessible regions within some volume and finds the segments which constitute channels through analyzing their periodic boundary crossings; when a segment touches the boundary of the grid, it must be connected to the segment which is represented by the periodically adjacent grid point. Our strategy for parallelization of this routine is to first split the grid into <inline-formula id="inline-formula29-1094342011431591">
<mml:math id="mml-inline29-1094342011431591">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula> distinct domains, segmenting each independently on a separate thread, and then to “stitch” the resulting segments together by considering inter-domain boundaries in the same manner as the periodic boundary. The grid is split into <inline-formula id="inline-formula30-1094342011431591">
<mml:math id="mml-inline30-1094342011431591">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula> domains simply by considering all <inline-formula id="inline-formula31-1094342011431591">
<mml:math id="mml-inline31-1094342011431591">
<mml:mi>N</mml:mi>
</mml:math>
</inline-formula> grid points in order and assigning the first <inline-formula id="inline-formula32-1094342011431591">
<mml:math id="mml-inline32-1094342011431591">
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>/</mml:mo>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula> to the first domain, and so on. As such, for comparatively large <inline-formula id="inline-formula33-1094342011431591">
<mml:math id="mml-inline33-1094342011431591">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula> it is possible for a domain to be a disconnected region of space, however this condition is robust under our pseudocode.</p>
</sec>
<sec id="section12-1094342011431591">
<title>4.8 Parallelization of the pocket blocking step</title>
<p>A pocket is a connected region of grid points which does not form a channel; it may, however, cross the periodic boundary, and if so is considered as more than one segment. Each segment can be blocked independently of any other, and hence our parallel implementation consists of the existing pocket blocking algorithm, with <inline-formula id="inline-formula34-1094342011431591">
<mml:math id="mml-inline34-1094342011431591">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula> pthreads deployed, each of which considers and blocks the first unblocked pocket in the list.</p>
</sec>
</sec>
<sec id="section13-1094342011431591">
<title>5 Results</title>
<p>We implemented all of the optimizations presented in the earlier section, and now present results from our experiments. <xref ref-type="table" rid="table2-1094342011431591">Table 2</xref> presents the absolute timings for all three steps in the algorithm for 1 to 24 Opteron cores. Timings for the cost-grid step are presented for the Fermi hardware. The number of pockets found is also presented. These results are further illustrated in <xref ref-type="fig" rid="fig3-1094342011431591">Figures 3</xref>
<xref ref-type="fig" rid="fig4-1094342011431591"/>
<xref ref-type="fig" rid="fig5-1094342011431591"/>
<xref ref-type="fig" rid="fig6-1094342011431591"/>
<xref ref-type="fig" rid="fig7-1094342011431591"/> to <xref ref-type="fig" rid="fig8-1094342011431591">8</xref>.</p>
<table-wrap id="table2-1094342011431591" position="float">
<label>Table 2.</label>
<caption>
<p>Detailed timing results for various materials and hardware platforms.</p>
</caption>
<graphic alternate-form-of="table2-1094342011431591" xlink:href="10.1177_1094342011431591-table2.tif"/>
<table>
<thead>
<tr>
<th colspan="2">
</th>
<th colspan="4">
<italic>ABSOLUTE TIME (seconds, including copying time for GPU</italic>
</th>
<th colspan="4">
<italic>SPEED-UP OVER 1 CORE</italic>
</th>
</tr>
<tr>
<th>Structure</th>
<th>Implementation</th>
<th>Cost-grid</th>
<th>Flood Fill</th>
<th>Pocket Blocking</th>
<th>
<italic>Total application</italic>
</th>
<th>Cost-grid</th>
<th>Flood Fill</th>
<th>Pocket Blocking</th>
<th>
<italic>Total application</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="7">
<italic>LTN (152 pockets)</italic>
</td>
<td>1 core</td>
<td>2122.761</td>
<td>1.063</td>
<td>78.404</td>
<td>
<italic>2202.355</italic>
</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>
<italic>1.000</italic>
</td>
</tr>
<tr>
<td>2 cores</td>
<td>1056.060</td>
<td>0.591</td>
<td>37.609</td>
<td>
<italic>1094.387</italic>
</td>
<td>2.010</td>
<td>1.799</td>
<td>2.085</td>
<td>
<italic>2.012</italic>
</td>
</tr>
<tr>
<td>4 cores</td>
<td>530.136</td>
<td>0.338</td>
<td>18.557</td>
<td>
<italic>549.159</italic>
</td>
<td>4.004</td>
<td>3.145</td>
<td>4.225</td>
<td>
<italic>4.010</italic>
</td>
</tr>
<tr>
<td>8 cores</td>
<td>265.455</td>
<td>0.253</td>
<td>9.635</td>
<td>
<italic>275.471</italic>
</td>
<td>7.997</td>
<td>4.202</td>
<td>8.137</td>
<td>
<italic>7.995</italic>
</td>
</tr>
<tr>
<td>16 cores</td>
<td>135.404</td>
<td>0.288</td>
<td>5.469</td>
<td>
<italic>141.290</italic>
</td>
<td>15.677</td>
<td>3.691</td>
<td>14.336</td>
<td>
<italic>15.587</italic>
</td>
</tr>
<tr>
<td>24 cores</td>
<td>89.137</td>
<td>0.340</td>
<td>4.843</td>
<td>
<italic>94.446</italic>
</td>
<td>23.815</td>
<td>3.126</td>
<td>16.189</td>
<td>
<italic>23.319</italic>
</td>
</tr>
<tr>
<td>Fermi GPU</td>
<td>7.915</td>
<td>(0.340)</td>
<td>(4.843)</td>
<td>
<italic>13.224</italic>
</td>
<td>268.193</td>
<td>(3.126)</td>
<td>(16.189)</td>
<td>
<italic>166.542</italic>
</td>
</tr>
<tr>
<td rowspan="7">
<italic>TSC (116 pockets)</italic>
</td>
<td>1 core</td>
<td>853.992</td>
<td>23.541</td>
<td>125.924</td>
<td>
<italic>1003.547</italic>
</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>
<italic>1.000</italic>
</td>
</tr>
<tr>
<td>2 cores</td>
<td>426.948</td>
<td>7.887</td>
<td>62.107</td>
<td>
<italic>497.030</italic>
</td>
<td>2.000</td>
<td>2.985</td>
<td>2.028</td>
<td>
<italic>2.019</italic>
</td>
</tr>
<tr>
<td>4 cores</td>
<td>214.443</td>
<td>5.071</td>
<td>30.866</td>
<td>
<italic>250.470</italic>
</td>
<td>3.982</td>
<td>4.642</td>
<td>4.080</td>
<td>
<italic>4.007</italic>
</td>
</tr>
<tr>
<td>8 cores</td>
<td>108.776</td>
<td>4.553</td>
<td>16.558</td>
<td>
<italic>129.977</italic>
</td>
<td>7.851</td>
<td>5.170</td>
<td>7.605</td>
<td>
<italic>7.721</italic>
</td>
</tr>
<tr>
<td>16 cores</td>
<td>55.834</td>
<td>4.370</td>
<td>8.971</td>
<td>
<italic>69.262</italic>
</td>
<td>15.295</td>
<td>5.387</td>
<td>14.037</td>
<td>
<italic>14.489</italic>
</td>
</tr>
<tr>
<td>24 cores</td>
<td>37.893</td>
<td>4.186</td>
<td>7.346</td>
<td>
<italic>49.513</italic>
</td>
<td>22.537</td>
<td>5.624</td>
<td>17.142</td>
<td>
<italic>20.268</italic>
</td>
</tr>
<tr>
<td>Fermi GPU</td>
<td>3.336</td>
<td>(4.186)</td>
<td>(7.346)</td>
<td>
<italic>14.956</italic>
</td>
<td>255.971</td>
<td>(5.624)</td>
<td>(17.142)</td>
<td>
<italic>67.099</italic>
</td>
</tr>
<tr>
<td rowspan="7">
<italic>HEU</italic>
<break/>(26 pockets)</td>
<td>1 core</td>
<td>5.490</td>
<td>0.075</td>
<td>0.994</td>
<td>
<italic>6 .586</italic>
</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>
<italic>1.000</italic>
</td>
</tr>
<tr>
<td>2 cores</td>
<td>2.707</td>
<td>0.055</td>
<td>0.503</td>
<td>
<italic>3 .279</italic>
</td>
<td>2.028</td>
<td>1.364</td>
<td>1.976</td>
<td>
<italic>2.009</italic>
</td>
</tr>
<tr>
<td>4 cores</td>
<td>1.332</td>
<td>0.055</td>
<td>0.254</td>
<td>
<italic>1 .654</italic>
</td>
<td>4.122</td>
<td>1.364</td>
<td>3.913</td>
<td>
<italic>3.983</italic>
</td>
</tr>
<tr>
<td>8 cores</td>
<td>0.673</td>
<td>0.056</td>
<td>0.186</td>
<td>
<italic>0 .927</italic>
</td>
<td>8.158</td>
<td>1.339</td>
<td>5.344</td>
<td>
<italic>7.105</italic>
</td>
</tr>
<tr>
<td>16 cores</td>
<td>0.344</td>
<td>0.058</td>
<td>0.186</td>
<td>
<italic>0 .601</italic>
</td>
<td>15.968</td>
<td>1.293</td>
<td>5.344</td>
<td>
<italic>10.962</italic>
</td>
</tr>
<tr>
<td>24 cores</td>
<td>0.235</td>
<td>0.071</td>
<td>0.189</td>
<td>
<italic>0 .507</italic>
</td>
<td>23.374</td>
<td>1.056</td>
<td>5.259</td>
<td>
<italic>12.993</italic>
</td>
</tr>
<tr>
<td>Fermi GPU</td>
<td>0.114</td>
<td>(0.071)</td>
<td>(0.189)</td>
<td>
<italic>0 .386</italic>
</td>
<td>47.955</td>
<td>(1.056)</td>
<td>(5.259)</td>
<td>
<italic>17.041</italic>
</td>
</tr>
<tr>
<td rowspan="7">
<italic>EDI</italic> (1 pocket)</td>
<td>1 core</td>
<td>0.114</td>
<td>0.010</td>
<td>0.038</td>
<td>
<italic>0 .170</italic>
</td>
<td>1.000</td>
<td>1.000</td>
<td>1.000</td>
<td>
<italic>1.000</italic>
</td>
</tr>
<tr>
<td>2 cores</td>
<td>0.058</td>
<td>0.005</td>
<td>0.034</td>
<td>
<italic>0 .105</italic>
</td>
<td>1.948</td>
<td>2.000</td>
<td>1.118</td>
<td>
<italic>1.611</italic>
</td>
</tr>
<tr>
<td>4 cores</td>
<td>0.035</td>
<td>0.005</td>
<td>0.036</td>
<td>
<italic>0 .083</italic>
</td>
<td>3.279</td>
<td>2.000</td>
<td>1.056</td>
<td>
<italic>2.053</italic>
</td>
</tr>
<tr>
<td>8 cores</td>
<td>0.025</td>
<td>0.005</td>
<td>0.048</td>
<td>
<italic>0 .085</italic>
</td>
<td>4.644</td>
<td>2.000</td>
<td>0.792</td>
<td>
<italic>2.010</italic>
</td>
</tr>
<tr>
<td>16 cores</td>
<td>0.016</td>
<td>0.007</td>
<td>0.042</td>
<td>
<italic>0 .070</italic>
</td>
<td>7.099</td>
<td>1.429</td>
<td>0.905</td>
<td>
<italic>2.425</italic>
</td>
</tr>
<tr>
<td>24 cores</td>
<td>0.013</td>
<td>0.012</td>
<td>0.047</td>
<td>
<italic>0 .078</italic>
</td>
<td>9.077</td>
<td>0.833</td>
<td>0.809</td>
<td>
<italic>2.191</italic>
</td>
</tr>
<tr>
<td>Fermi GPU</td>
<td>0.009</td>
<td>(0.012)</td>
<td>(0.047)</td>
<td>
<italic>0 .074</italic>
</td>
<td>13.196</td>
<td>(0.833)</td>
<td>(0.809)</td>
<td>
<italic>2.307</italic>
</td>
</tr>
</tbody>
</table>
</table-wrap>
<fig id="fig3-1094342011431591" position="float">
<label>Figure 3.</label>
<caption>
<p>Speedup results for cost-grid calculation on multicore CPU.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig3.tif"/>
</fig>
<fig id="fig4-1094342011431591" position="float">
<label>Figure 4.</label>
<caption>
<p>Speedup results for flood fill calculation on multicore CPU.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig4.tif"/>
</fig>
<fig id="fig5-1094342011431591" position="float">
<label>Figure 5.</label>
<caption>
<p>Speedup results for pocket blocking calculation on multicore CPU.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig5.tif"/>
</fig>
<fig id="fig6-1094342011431591" position="float">
<label>Figure 6.</label>
<caption>
<p>Speedup results for entire application executed on multicore CPU.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig6.tif"/>
</fig>
<fig id="fig7-1094342011431591" position="float">
<label>Figure 7.</label>
<caption>
<p>Absolute times for computation of LTN zeolite on multiple platforms.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig7.tif"/>
</fig>
<fig id="fig8-1094342011431591" position="float">
<label>Figure 8.</label>
<caption>
<p>Speedup results for computation of LTN zeolite on multiple platforms.</p>
</caption>
<graphic xlink:href="10.1177_1094342011431591-fig8.tif"/>
</fig>
<p>These results illustrate the fundamental differences between the three steps in our algorithm. The cost-grid calculation is shown (<xref ref-type="fig" rid="fig3-1094342011431591">Figure 3</xref>) to continually benefit from increasing the number of threads up to 24; indeed, for all but the smallest of the examined structures, a near linear speedup is observed with respect to the number of pthreads deployed. It is clear that this step benefits further still from the GPU implementation (<xref ref-type="table" rid="table2-1094342011431591">Table 2</xref>); in the two larger structures, speedups of over 250<inline-formula id="inline-formula35-1094342011431591">
<mml:math id="mml-inline35-1094342011431591">
<mml:mo stretchy="false">×</mml:mo>
</mml:math>
</inline-formula> compared to a single CPU thread are observed, which in turn correspond to an 11<inline-formula id="inline-formula36-1094342011431591">
<mml:math id="mml-inline36-1094342011431591">
<mml:mo stretchy="false">×</mml:mo>
</mml:math>
</inline-formula> speedup over the 24 thread implementation. These speedup factors are lower for the smaller structures, for which it can be seen that the computation time is much smaller even on a single CPU thread.</p>
<p>By contrast, the time spent in the segmentation step (<xref ref-type="table" rid="table2-1094342011431591">Table 2</xref>) exhibits behavior wherein increasing the number of threads up to eight is beneficial, however beyond this point three of the four structures begin to demonstrate a reduction in performance, particularly pronounced for the smallest structure, EDI. With a large number of threads, the grid is divided into a large number of independent domains, decreasing the time spent per domain but increasing the number of boundary crossings that must be examined. Hence, we observe (<xref ref-type="fig" rid="fig4-1094342011431591">Figure 4</xref>) that a saddle exists in the region of eight threads, and increasing beyond this point, either with more pthreads or with a GPU approach, is unlikely to be beneficial in the general case. The results for pocket blocking (<xref ref-type="fig" rid="fig5-1094342011431591">Figure 5</xref>) show near linear speedup up to four threads, excluding EDI; EDI has only one pocket, and so it is clear that the multicore implementation does not yield any benefit. Since the two larger structures contain over 100 pockets, they show continued speedup up to 24 threads. However, the speedup factor with respect to the increasing number of threads can be seen to be decreasing, and hence it is expected that a GPU implementation is unlikely to be advantageous. An additional issue with respect to a GPU pocket blocking routine is that the whole cost grid must be queried while spheres are being created to ensure that the spheres do not overlap with other segments, and this would place considerable constraints on GPU memory.</p>
<p>We also consider overall application speedup (<xref ref-type="fig" rid="fig6-1094342011431591">Figure 6</xref>), assuming <inline-formula id="inline-formula37-1094342011431591">
<mml:math id="mml-inline37-1094342011431591">
<mml:mi>n</mml:mi>
</mml:math>
</inline-formula> threads applied to each step or, in the case of the GPU implementation, the maximum number of threads (24) for the segmentation and blocking steps. Since the cost-grid has already been observed to be the most computationally expensive step, the speedups in this portion of the algorithm dominate the overall speedups observed. As such, near linear speedup is observed in the overall application for the larger structures. Further total speedup can be achieved with the GPU implementation of the cost-calculation step; the results for Fermi indicate that on the largest structure, LTN, we achieve over a 165<inline-formula id="inline-formula38-1094342011431591">
<mml:math id="mml-inline38-1094342011431591">
<mml:mo stretchy="false">×</mml:mo>
</mml:math>
</inline-formula> speedup over single CPU thread, and over 7<inline-formula id="inline-formula39-1094342011431591">
<mml:math id="mml-inline39-1094342011431591">
<mml:mo stretchy="false">×</mml:mo>
</mml:math>
</inline-formula> speedup over 24 CPU threads. <xref ref-type="fig" rid="fig7-1094342011431591">Figures 7</xref> and <xref ref-type="fig" rid="fig8-1094342011431591">8</xref> present, respectively, the total calculation time and speedup for the LTN zeolite.</p>
</sec>
<sec id="section14-1094342011431591">
<title>6 Discussion</title>
<p>While significant effort was made in optimizing the CPU performance in order to achieve a more balanced comparison with GPUs, there are still additional optimizations that could be exploited. Specifically, the data for the CPU implementation is currently arranged in an Array of Structures (AoS) format rather than the more SIMD-friendly Structure of Arrays (SoA) format. The current AoS layout leaves one of the four SIMD slots unused, as well as being a less efficient data layout, occasionally requiring more data swizzling. In addition, an SoA format would more readily exploit a wider, eight-slot SIMD unit such as those available on the latest Intel CPUs. However, the relatively short length of the innermost loop leads us to believe that the amount of efficiency gained for our current optimizations represents the majority of speedup attainable on a CPU. We also did not pay attention to NUMA issues on the multicore implementation by utilizing the first-touch policy on memory pages. We also did not use blocking optimizations (cache, thread, etc.) on the CPU. While our code is not bandwidth-bound, it is possible that both of these implementations will improve the performance of the CPU implementation.</p>
<p>A natural algorithmic optimization to consider is to use an acceleration structure such as an octree to improve the collision detection process. Currently, we do an <inline-formula id="inline-formula40-1094342011431591">
<mml:math id="mml-inline40-1094342011431591">
<mml:mi>O</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula> scan through the array of structure atoms. A tree-based structure can potentially improve the performance to <inline-formula id="inline-formula41-1094342011431591">
<mml:math id="mml-inline41-1094342011431591">
<mml:mi>O</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo form="prefix" movablelimits="false">log</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:math>
</inline-formula>. Such methods are very well suited to CPUs, but not as well to GPUs due to non-uniform memory access and thread divergence. We would like to utilize functionality from the CUDA Data Parallel Primitives Library (<xref ref-type="bibr" rid="bibr7-1094342011431591">CUDPP, 2011</xref>) towards this end. We would like to consider other algorithmic and optimization methods in future work.</p>
</sec>
<sec id="section15-1094342011431591">
<title>7 Conclusion</title>
<p>Our three-step algorithm for the analysis of the void space of porous materials has demonstrated the suitability of this algorithm for acceleration through the exploitation of its parallel nature. The first step, the cost-grid calculation, has an inherently parallel nature and therefore it was implemented on multicore and GPU architectures. We have also investigated the benefits of parallelization of the other two steps in our algorithm, but we found that they do not exhibit the same inherently parallel nature as the cost-grid, and exhibit characteristics which limit the benefit of parallelization. They were implemented on the multicore CPU. Nevertheless, since the cost-grid is by far the most expensive single step in the algorithm, total application time speedup using 24 Opteron threads for the largest structure in our dataset is over 23<inline-formula id="inline-formula42-1094342011431591">
<mml:math id="mml-inline42-1094342011431591">
<mml:mo stretchy="false">×</mml:mo>
</mml:math>
</inline-formula> (i.e. near linear), and an over 7<inline-formula id="inline-formula43-1094342011431591">
<mml:math id="mml-inline43-1094342011431591">
<mml:mo stretchy="false">×</mml:mo>
</mml:math>
</inline-formula> further speedup in the total application is observed by utilizing the GPU for the cost-grid calculation.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The authors would like to thank Samuel W. Williams and Jihan Kim for valuable suggestions regarding code optimization. We would also like to thank NERSC for access to GPU computing facilities.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure" id="fn1-1094342011431591">
<label>Funding</label>
<p>This work was supported by the Director, Office of Advanced Scientific Computing Research, Office of Science, of the U.S. Department of Energy through the Scientific Discovery through Advanced Computing (SciDAC) program’s Visualization and Analytics Center for Enabling Technologies (VACET) (Contract No. DE-AC02-05CH11231).</p>
<p>This work was also supported in part by the Applied Mathematical Science subprogram of the Office of Energy Research, U.S. Department of Energy (Contract Number DE-AC03-76SF00098), and by the Computational Mathematics Program of the National Science Foundation.</p>
</fn>
<fn fn-type="other" id="fn2-1094342011431591">
<label>Conflict of interest</label>
<p>None declared.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1094342011431591">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Auerbach</surname>
<given-names>SM</given-names>
</name>
<name>
<surname>Carrado</surname>
<given-names>KA</given-names>
</name>
<name>
<surname>Dutta</surname>
<given-names>PK</given-names>
</name>
</person-group> (<year>2004</year>) <source>Handbook of Zeolite Science and Technology</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Marcel Dekker</publisher-name>.</citation>
</ref>
<ref id="bibr2-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Banerjee</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Phan</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Knobler</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Furukawa</surname>
<given-names>H</given-names>
</name>
</person-group>, O’Keeffe M et al. (<year>2008</year>) <article-title>High-throughput synthesis of zeolitic imidazolate frameworks and application to CO<sub>2</sub> capture</article-title>. <source>Science</source> <volume>319</volume>: <fpage>939</fpage>–<lpage>943</lpage>.</citation>
</ref>
<ref id="bibr3-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bates</surname>
<given-names>SP</given-names>
</name>
<name>
<surname>van Well</surname>
<given-names>WJM</given-names>
</name>
<name>
<surname>van Santen</surname>
<given-names>RA</given-names>
</name>
<name>
<surname>Smit</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>Energetics of n-Alkanes in zeolites: a configurational-bias Monte Carlo investigation into pore size dependence</article-title>. <source>Journal of the American Chemical Society</source> <volume>118</volume>: <fpage>6753</fpage>.</citation>
</ref>
<ref id="bibr4-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Baumes</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Kruger</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Jimenez</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Collet</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Corma</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Boosting theoretical zeolitic framework generation for the determination of new materials structures using GPU programming</article-title>. <source>Physical Chemistry Chemical Physics</source> <volume>13</volume>: <fpage>4674</fpage>–<lpage>4678</lpage>.</citation>
</ref>
<ref id="bibr5-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Blatov</surname>
<given-names>VA</given-names>
</name>
<name>
<surname>Ilyushin</surname>
<given-names>GD</given-names>
</name>
<name>
<surname>Blatova</surname>
<given-names>OA</given-names>
</name>
<name>
<surname>Anurova</surname>
<given-names>NA</given-names>
</name>
<name>
<surname>Ivanov-Schits</surname>
<given-names>AK</given-names>
</name>
<name>
<surname>Dem’yanets</surname>
<given-names>LN</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Analysis of migration paths in fast-ion conductors with Voronoi-Dirichlet partition</article-title>. <source>Acta Crystallographica</source> <volume>B62</volume>: <fpage>1010</fpage>–<lpage>1018</lpage>.</citation>
</ref>
<ref id="bibr6-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Choi</surname>
<given-names>HJ</given-names>
</name>
<name>
<surname>Dinca</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Long</surname>
<given-names>JR</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Broadly hysteretic H2 adsorption in the microporous metal–organic framework Co (1,4-benzenedipyrazolate)</article-title>. <source>Journal of the American Chemical Society</source> <volume>130</volume>: <fpage>7848</fpage>–<lpage>7850</lpage>.</citation>
</ref>
<ref id="bibr7-1094342011431591">
<citation citation-type="web">
<collab collab-type="author">CUDPP</collab> (<year>2011</year>). <article-title>CUDA Data Parallel Primitives Library</article-title>. <ext-link ext-link-type="uri" xlink:href="http://code.google.com/p/cudpp/">http://code.google.com/p/cudpp/</ext-link>.</citation>
</ref>
<ref id="bibr8-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Deem</surname>
<given-names>MW</given-names>
</name>
<name>
<surname>Pophale</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Cheeseman</surname>
<given-names>PA</given-names>
</name>
<name>
<surname>Earl</surname>
<given-names>DJ</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Computational discovery of new zeolite-like materials</article-title>. <source>Journal of Physical Chemistry C</source> <volume>113</volume>: <fpage>21353</fpage>–<lpage>21360</lpage>.</citation>
</ref>
<ref id="bibr9-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dijkstra</surname>
<given-names>EW</given-names>
</name>
</person-group> (<year>1959</year>) <article-title>A note on two problems in connection with graphs</article-title>. <source>Numerische Mathematic</source> <volume>1</volume>: <fpage>269</fpage>–<lpage>271</lpage>.</citation>
</ref>
<ref id="bibr10-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dubbeldam</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Smit</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>2003</year>) <article-title>Computer simulation of incommensurate diffusion in zeolites: understanding window effects</article-title>. <source>Journal of Physical Chemistry B</source> <volume>107</volume>: <fpage>12138</fpage>.</citation>
</ref>
<ref id="bibr11-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Earl</surname>
<given-names>DJ</given-names>
</name>
<name>
<surname>Deem</surname>
<given-names>MW</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Toward a database of hypothetical zeolite structures</article-title>. <source>Industrial and Engineering Chemistry Research</source> <volume>45</volume>: <fpage>5449</fpage>–<lpage>5454</lpage>.</citation>
</ref>
<ref id="bibr12-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>First</surname>
<given-names>EL</given-names>
</name>
<name>
<surname>Gounaris</surname>
<given-names>CE</given-names>
</name>
<name>
<surname>Wei</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Floudas</surname>
<given-names>CA</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Computational characterization of zeolite porous networks: an automated approach</article-title>. <source>Physical Chemistry Chemical Physics</source> <volume>13</volume>: <fpage>17339</fpage>–<lpage>17358</lpage>.</citation>
</ref>
<ref id="bibr13-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Foster</surname>
<given-names>MD</given-names>
</name>
<name>
<surname>Rivin</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Treacy</surname>
<given-names>MMJ</given-names>
</name>
<name>
<surname>Friedrichs</surname>
<given-names>OD</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>A geometric solution to the largest-free-sphere problem in zeolite frameworks</article-title>. <source>Microporous and Mesoporous Materials</source> <volume>90</volume>: <fpage>32</fpage>–<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr14-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Foster</surname>
<given-names>MD</given-names>
</name>
<name>
<surname>Treacy</surname>
<given-names>MMJ</given-names>
</name>
</person-group> (<year>2010</year>) <source>The Hypothetical Zeolites Database. http://www.hypotheticalzeolites.net (accessed Nov</source> <volume>13</volume>, <fpage>2010</fpage>).</citation>
</ref>
<ref id="bibr15-1094342011431591">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Frenkel</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Smit</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>2002</year>) <source>Understanding molecular simulations</source>, <edition>2nd ed</edition>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>, <fpage>23</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr16-1094342011431591">
<citation citation-type="web">
<collab collab-type="author">GPGPU.org</collab> (<year>2011</year>). <article-title>General-purpose computation on graphics hardware</article-title>. <ext-link ext-link-type="uri" xlink:href="http://www.gpgpu.org/">http://www.gpgpu.org/</ext-link>.</citation>
</ref>
<ref id="bibr17-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haldoupis</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Nair</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Sholl</surname>
<given-names>DS</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Efficient calculation of diffusion limitations in metal organic framework materials: a tool for identifying materials for kinetic separations</article-title>. <source>Journal of the American Chemical Society</source> <volume>132</volume>: <fpage>7528</fpage>–<lpage>7539</lpage>.</citation>
</ref>
<ref id="bibr18-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haranczyk</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Sethian</surname>
<given-names>JA</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Navigating molecular worms inside chemical labyrinths</article-title>. <source>Proceedings of the National Academy of Sciences USA (PNAS)</source> <volume>106</volume>: <fpage>21472</fpage>–<lpage>21477</lpage>.</citation>
</ref>
<ref id="bibr19-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haranczyk</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Sethian</surname>
<given-names>JA</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Automatic structure analysis in high-throughput characterization of porous materials</article-title>. <source>Journal of Chemical Theory and Computation</source> <volume>6</volume>: <fpage>3472</fpage>–<lpage>3480</lpage>.</citation>
</ref>
<ref id="bibr20-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jeong</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Whitaker</surname>
<given-names>RT</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>A Fast Eikonal Equation Solver for Parallel Systems</article-title>. In <source>Proceedings of the SIAM Conference on Computational Science and Engineering</source>.</citation>
</ref>
<ref id="bibr21-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jiang</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Jorda</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Yu</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Baumes</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Mugnaioli</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Diaz-Cabanas</surname>
<given-names>J-M</given-names>
</name>
<etal/>
</person-group> (<year>2011</year>) <article-title>Synthesis and structure determination of the hierarchical meso-microporous zeolite ITQ-43</article-title>. <source>Science</source> <volume>333</volume>: <fpage>1131</fpage>–<lpage>1134</lpage>.</citation>
</ref>
<ref id="bibr22-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Keffer</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Gupta</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Lenz</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Davis</surname>
<given-names>HT</given-names>
</name>
<name>
<surname>McCormick</surname>
<given-names>AV</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>A compendium of potential energy maps of zeolites and molecular sieves</article-title>. <source>Journal of Molecular Graphics</source> <volume>14</volume>: <fpage>108</fpage>–<lpage>116</lpage>.</citation>
</ref>
<ref id="bibr23-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krishna</surname>
<given-names>R</given-names>
</name>
<name>
<surname>van Baten</surname>
<given-names>JM</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Using molecular simulations for screening of zeolites for separation of CO<sub>2</sub>/CH<sub>4</sub> mixtures</article-title>. <source>Chemical Engineering Journal</source> <volume>133</volume>: <fpage>121</fpage>–<lpage>131</lpage>.</citation>
</ref>
<ref id="bibr24-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krishna</surname>
<given-names>R</given-names>
</name>
<name>
<surname>van Baten</surname>
<given-names>JM</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Comment on comparative molecular simulation study of CO<sub>2</sub>/N<sub>2</sub> and CH<sub>4</sub>/N<sub>2</sub> separation in zeolites and metal–organic frameworks</article-title>. <source>Langmuir</source> <volume>26</volume>: <fpage>2975</fpage>–<lpage>2978</lpage>.</citation>
</ref>
<ref id="bibr25-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krüger</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Maitre</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Jimnez</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Baumes</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Collet</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Speedups between × 70 and × 120 for a generic local search (memetic) algorithm on a single GPGPU chip</article-title>. In <source>Proceedings of EvoApplications (1)</source>, pp. <fpage>501</fpage>–<lpage>511</lpage>.</citation>
</ref>
<ref id="bibr26-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Maitre</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Baumes</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Lachiche</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Corma</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Collet</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2009a</year>) <article-title>Coarse grain parallelization of evolutionary algorithms on GPGPU cards with EASEA</article-title>. In <source>Proceedings of the 11th Annual Genetic and Evolutionary Computation Conference, GECCO-2009</source>, pp. <fpage>1403</fpage>–<lpage>1410</lpage>.</citation>
</ref>
<ref id="bibr27-1094342011431591">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Maitre</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Lachiche</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Clauss</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Baumes</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Corma</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Collet</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2009b</year>) <article-title>Efficient parallel implementation of evolutionary algorithms on GPGPU cards</article-title>. In <source>EuroPar</source> <volume>2009</volume> <issue>5704</issue>: <fpage>974</fpage>–<lpage>985</lpage>.</citation>
</ref>
<ref id="bibr28-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Millward</surname>
<given-names>AR</given-names>
</name>
<name>
<surname>Yaghi</surname>
<given-names>OM</given-names>
</name>
</person-group> (<year>2005</year>) <article-title>Metal–organic frameworks with exceptionally high capacity for storage of carbon dioxide at room temperature</article-title>. <source>Journal of the American Chemical Society</source> <volume>127</volume>: <fpage>17998</fpage>–<lpage>17999</lpage>.</citation>
</ref>
<ref id="bibr29-1094342011431591">
<citation citation-type="web">
<collab collab-type="author">NVIDIA</collab> (<year>2011a</year>) <article-title>CUDA Developer Zone</article-title>. <ext-link ext-link-type="uri" xlink:href="http://www.nvidia.com/object/cuda_home_new.html">http://www.nvidia.com/object/cuda_home_new.html</ext-link>.</citation>
</ref>
<ref id="bibr30-1094342011431591">
<citation citation-type="web">
<collab collab-type="author">NVIDIA</collab> (<year>2011b</year>) <article-title>GPU Computing</article-title>. <ext-link ext-link-type="uri" xlink:href="http://www.nvidia.com/object/GPU_Computing.html">http://www.nvidia.com/object/GPU_Computing.html</ext-link>.</citation>
</ref>
<ref id="bibr31-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Petrek</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Otyepka</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Banas</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Kosinova</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Koca</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Damborsky</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>CAVER: a new tool to explore routes from protein clefts, pockets and cavities</article-title>. <source>BMC Bioinformatics</source> <volume>7</volume>: <fpage>316</fpage>–<lpage>325</lpage>.</citation>
</ref>
<ref id="bibr32-1094342011431591">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sethian</surname>
<given-names>JA</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>A fast marching level set method for monotonically advancing fronts</article-title>. In: <source>Proceedings of the National Academy of Science (PNAS)</source> <volume>93</volume>: <fpage>1591</fpage>–<lpage>1595</lpage>.</citation>
</ref>
<ref id="bibr33-1094342011431591">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Sethian</surname>
<given-names>JA</given-names>
</name>
</person-group> (<year>1999</year>). <source>Level Set Methods and Fast Marching Methods</source>, <edition>2nd ed</edition>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>, <fpage>86</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr34-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smit</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Maesen</surname>
<given-names>TLM</given-names>
</name>
</person-group> (<year>2008a</year>) <article-title>Towards a molecular understanding of shape selectivity</article-title>. <source>Nature</source> <volume>451</volume>: <fpage>671</fpage>–<lpage>677</lpage>.</citation>
</ref>
<ref id="bibr35-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smit</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Maesen</surname>
<given-names>TLM</given-names>
</name>
</person-group> (<year>2008b</year>) <article-title>Molecular simulations of zeolites: adsorption, diffusion, and shape selectivity</article-title>. <source>Chemical Reviews</source> <volume>108</volume>: <fpage>4125</fpage>–<lpage>4184</lpage>.</citation>
</ref>
<ref id="bibr36-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stone</surname>
<given-names>JE</given-names>
</name>
<name>
<surname>Hardy</surname>
<given-names>DJ</given-names>
</name>
<name>
<surname>Ufimtsev</surname>
<given-names>IS</given-names>
</name>
<name>
<surname>Schulten</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>GPU-accelerated molecular modeling coming of age</article-title>. <source>Journal of Molecular Graphics and Modelling</source> <volume>29</volume>: <fpage>116</fpage>–<lpage>125</lpage>.</citation>
</ref>
<ref id="bibr37-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sumida</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>MR</given-names>
</name>
<name>
<surname>Horike</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Dailly</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Long</surname>
<given-names>JR</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Synthesis and hydrogen storage properties of Be<sub>12</sub>(OH)<sub>12</sub>(1,3,5-benzenetribenzoate)<sub>4</sub>
</article-title>. <source>Journal of the American Chemical Society</source> <volume>131</volume>: <fpage>15120</fpage>–<lpage>15121</lpage>.</citation>
</ref>
<ref id="bibr38-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Theisen</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Smit</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Haranczyk</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Chemical hieroglyphs: abstract depiction of complex void space topology of nanoporous materials</article-title>. <source>Journal of Chemical Information and Modeling</source> <volume>50</volume>: <fpage>461</fpage>–<lpage>469</lpage>.</citation>
</ref>
<ref id="bibr39-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Till</surname>
<given-names>MS</given-names>
</name>
<name>
<surname>Ullmann</surname>
<given-names>GM</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>McVol - a program for calculating protein volumes and identifying cavities by a Monte Carlo algorithm</article-title>. <source>Journal of Molecular Modeling</source> <volume>16</volume>: <fpage>419</fpage>–<lpage>429</lpage>.</citation>
</ref>
<ref id="bibr40-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ufimtsev</surname>
<given-names>IS</given-names>
</name>
<name>
<surname>Martinez</surname>
<given-names>TJ</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Quantum chemistry on graphical processing units. 1. strategies for two-electron integral evaluation</article-title>. <source>Journal of Chemical Theory and Computation</source> <volume>4</volume>: <fpage>222</fpage>–<lpage>231</lpage>.</citation>
</ref>
<ref id="bibr41-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ufimtsev</surname>
<given-names>IS</given-names>
</name>
<name>
<surname>Martinez</surname>
<given-names>TJ</given-names>
</name>
</person-group> (<year>2009a</year>) <article-title>Quantum chemistry on graphical processing units. 2. direct self-consistent-field implementation</article-title>. <source>Journal of Chemical Theory and Computation</source> <volume>5</volume>: <fpage>1004</fpage>–<lpage>1015</lpage>.</citation>
</ref>
<ref id="bibr42-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ufimtsev</surname>
<given-names>IS</given-names>
</name>
<name>
<surname>Martinez</surname>
<given-names>TJ</given-names>
</name>
</person-group> (<year>2009b</year>) <article-title>Quantum chemistry on graphical processing units. 3. analytical energy gradients, geometry optimization, and first principles molecular dynamics</article-title>. <source>Journal of Chemical Theory and Computation</source> <volume>5</volume>: <fpage>2619</fpage>–<lpage>2628</lpage>.</citation>
</ref>
<ref id="bibr43-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Walton</surname>
<given-names>KS</given-names>
</name>
<name>
<surname>Millward</surname>
<given-names>AR</given-names>
</name>
<name>
<surname>Dubbeldam</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Frost</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Low</surname>
<given-names>JJ</given-names>
</name>
<name>
<surname>Yaghi OM et</surname>
<given-names>al.</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Understanding inflections and steps in carbon dioxide adsorption isotherms in metal-organic frameworks</article-title>. <source>Journal of the American Chemical Society</source> <volume>130</volume>: <fpage>406</fpage>–<lpage>407</lpage>.</citation>
</ref>
<ref id="bibr44-1094342011431591">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Willems</surname>
<given-names>TF</given-names>
</name>
<name>
<surname>Rycroft</surname>
<given-names>CH</given-names>
</name>
<name>
<surname>Kazi</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Meza</surname>
<given-names>JC</given-names>
</name>
<name>
<surname>Haranczyk</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Algorithms and tools for high-throughput geometry-based analysis of crystalline porous materials</article-title>. <source>Microporous and Mesoporous Materials</source> <volume>149</volume>: <fpage>134</fpage>–<lpage>141</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>