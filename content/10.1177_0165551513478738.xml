<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JIS</journal-id>
<journal-id journal-id-type="hwp">spjis</journal-id>
<journal-title>Journal of Information Science</journal-title>
<issn pub-type="ppub">0165-5515</issn>
<issn pub-type="epub">1741-6485</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0165551513478738</article-id>
<article-id pub-id-type="publisher-id">10.1177_0165551513478738</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Leveraging microblogging big data with a modified density-based clustering approach for event awareness and topic ranking</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Lee</surname><given-names>Chung-Hong</given-names></name>
<aff id="aff1-0165551513478738">Department of Electrical Engineering, National Kaohsiung University of Applied Sciences, Taiwan</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Chien</surname><given-names>Tzan-Feng</given-names></name>
<aff id="aff2-0165551513478738">Department of Electrical Engineering, National Kaohsiung University of Applied Sciences, Taiwan</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0165551513478738">Chung-Hong Lee, Department of Electrical Engineering, National Kaohsiung University of Applied Sciences, Kaohsiung, Taiwan. Email: <email>leechung@mail.ee.kuas.edu.tw</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2013</year>
</pub-date>
<volume>39</volume>
<issue>4</issue>
<fpage>523</fpage>
<lpage>543</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">Chartered Institute of Library and Information Professionals</copyright-holder>
</permissions>
<abstract>
<p>Although diverse groups argue about the potential and true value benefits from social-media big data, there is no doubt that the era of big data exploitation has begun, driving the development of novel data-centric applications. Big data is notable not only because of its size, but also because of the complexity caused by its relationality to other data. In the past, owing to the limited possibilities of accessing big data, few data sources were available to allow researchers to develop advanced data-driven applications, such as monitoring of emerging real-world events. In fact, social media is greatly impacting the growth of big data; and big data is providing enterprises with the data to help them understand how to better detect marketing demands. Microblogging is a social network service capable of aggregating messages to explore facts and unknown knowledge. Nowadays, people often attempt to search for trending news and hot topics in real time from microblogging messages to satisfy their information needs. Under such a circumstance, a real demand is to find a way to allow users to organize a large number of microblogging messages into understandable events. In this work, we attempt to tackle such challenges by developing an online text-stream clustering approach using a modified density-based clustering model with collected microblogging big data. The system kernel combines three technical components, including a dynamic term weighting scheme, a neighbourhood generation algorithm and an online density-based clustering technique. After acquiring detected event topics by the system, our system provides functions for recommending top-priority event information to assist people to effectively organize emerging event data through the developed topic ranking algorithm.</p>
</abstract>
<kwd-group>
<kwd>big data</kwd>
<kwd>microblog</kwd>
<kwd>online computation</kwd>
<kwd>social networks</kwd>
<kwd>text mining</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0165551513478738" sec-type="intro">
<title>1. Introduction</title>
<p>Big data denotes the data sets that are too ‘big’ to be handled using the existing database management tools and methods. Big data has existed for a long time, but few application systems have been able to access it until recent years. Social media is greatly impacting the growth of big data; and big data is providing enterprises with the information to help them to better understand customers’ preferences, and use the information to analyse new business opportunities. Ford Motors, PepsiCo and Southwest Airlines, for example, analyse consumer postings about them on social-media sites such as Twitter and Facebook to evaluate the immediate impact of their marketing strategies and to understand how customer sentiment about their brands is changing [<xref ref-type="bibr" rid="bibr1-0165551513478738">1</xref>]. Another example, an experimental application investigated in this work, is the utilization of the contents of social media messages (e.g. Twitter data sets) to collect real-world event data to support understanding and status updates of emerging events. Because new events continually evolve, it is difficult to have an overview of the structure and dynamic development of emerging events. For example, some emerging events caused by severe natural disasters such as earthquakes and tsunami require new scientific methodologies for risk management and control. With the help of social-media big data like Twitter data sets, people can carry out the task of event awareness by mining the large scale event-related social content contributed by users around the world. Novel online event detection techniques, which incorporate streaming models with online clustering algorithms, provide feasible solutions to deal with the social streams for event mining in real time. However, although some stream mining approaches have been successfully developed to analyse social big data for event detection, little research effort has been spent on integrating microblog-based event monitoring subsystems, including online event detection, dynamic term weighting and online ranking of detected events to satisfy the information needs of event awareness. For this reason, in this work we established a framework of event detection systems on Twitter data, and further developed algorithms for ranking detected events. The term ‘event’, in this work, is defined as ‘something happened at a specific location during a specific period of time’, and ‘topic’ represents ‘a set of messages concentrating on some specific issues, which are continuously discussed by users who are concerned with the newest event development in the real world’. For real-time event discovery, however, it is not sufficient to provide users with the newest microblogging messages that happen to contain the requested keywords. It is normally expected that, if the users want fresh information about important on-going events and hot topics, they will be able to hear it from responsible sources and reliable discussions, not just from anyone who happens to include the keywords (e.g. ‘Japan earthquake’) in microblogging messages. Still, we believe that more is needed to accomplish a challenging task: using live microblogging data to automatically identify emerging events and rank the topics in a near-real-time manner. Once dealing with microblogging text streams, one important indication of evolution is the presence of bursts. For microblogs, a burst indicates that the occurrence of a certain message feature is unexpectedly frequent in a short period of time. The burst detection methods can be applied to automatic detection of sudden events, providing useful insights into the unusual events and in turn supporting situation awareness in real time. In this work, therefore, we use Twitter messages (i.e. tweets) to develop an online event clustering and topic ranking methods for real-time event detection.</p>
<p>The rest of the paper is organized as follows. Section 2 surveys several related work in the literature. The developed system architecture is described in Section 3. Section 4 reports on online text stream clustering methods for mining microblogging messages. We introduce our developed online clustering method, including three components: a dynamic term weighting scheme, a neighbourhood generation algorithm and an online density-based clustering approach. In Section 5, we describe our experiments on collected Twitter data sets, and discuss their evaluation results. Finally, Section 6 concludes the work by summarizing our research contributions.</p>
</sec>
<sec id="section2-0165551513478738">
<title>2. Related work</title>
<p>Recently research on social networking applications has drawn increasing attention. For example, Otte and Rousseau [<xref ref-type="bibr" rid="bibr2-0165551513478738">2</xref>] studied the influence of social network analysis in several application fields, such as publication citation and co-citation networks, collaboration structures and other forms of social interaction networks. Recently, Ross et al. explored the use of a Twitter-enabled backchannel to enhance the conference experience, collaboration and the co-construction of knowledge [<xref ref-type="bibr" rid="bibr3-0165551513478738">3</xref>]. Microblogging, such as Twitter, is one of popular social networking applications, representing a simple yet powerful way to allow enormous numbers of users every day to post messages related to everything ranging from mundane daily life routines to breaking news events. Over the past few years, data mining on microblog-based big data [<xref ref-type="bibr" rid="bibr4-0165551513478738">4</xref>, <xref ref-type="bibr" rid="bibr5-0165551513478738">5</xref>] has rapidly emerged as a popular research topic in the areas of text mining, information retrieval and social media. In addition, much research work has focused on applying Twitter for sentiment analysis and opinion mining applications, such as Thelwall et al. [<xref ref-type="bibr" rid="bibr6-0165551513478738">6</xref>] and Jansen et al. [<xref ref-type="bibr" rid="bibr7-0165551513478738">7</xref>]. One of the key advantages regarding microblogs is that it enables people to acquire up-to-the-minute information ubiquitously. Many developed recommendation systems are based on such a characteristic to discovery popular movies [<xref ref-type="bibr" rid="bibr8-0165551513478738">8</xref>] and RSS news topics [<xref ref-type="bibr" rid="bibr9-0165551513478738">9</xref>], etc., in near real time.</p>
<p>In a study of the decision-making uses on microblogs, Cheong and Lee [<xref ref-type="bibr" rid="bibr10-0165551513478738">10</xref>] presented an excellent view of trending topics on microblogs. The topics on Twitter were categorized into short-term, medium-term and long-term topics, and finally utilized an off-line SOM approach for analysis of trend patterns. Becker et al. [<xref ref-type="bibr" rid="bibr11-0165551513478738">11</xref><xref ref-type="bibr" rid="bibr12-0165551513478738"/><xref ref-type="bibr" rid="bibr13-0165551513478738"/>–<xref ref-type="bibr" rid="bibr14-0165551513478738">14</xref>] proposed a series of work regarding topic discovery on Twitter, which is perhaps the most similar research related to our work. Naaman et al. [<xref ref-type="bibr" rid="bibr11-0165551513478738">11</xref>] developed a trending topic detection algorithm in local areas including burst detection algorithm and local trending terms detection. Also, in their later work [<xref ref-type="bibr" rid="bibr12-0165551513478738">12</xref>, <xref ref-type="bibr" rid="bibr13-0165551513478738">13</xref>], they developed an online event identification framework that uses online clustering and ﬁltering technologies to identify topics on Twitter. In particular, the goal of their research [<xref ref-type="bibr" rid="bibr14-0165551513478738">14</xref>] is similar to our topic ranking algorithms, which tried to develop a variety of event-based re-ranking techniques, and evaluated the ranking results of tweets with aspects of quality, relevance and usefulness. Furthermore, they also developed a topic tracking system [<xref ref-type="bibr" rid="bibr15-0165551513478738">15</xref>]. In this work, a planned event, a so-called scheduled event, means that the events are known to the machine, which is suitable of utilizing a topic tracking method. The differences between Becker’s work and our work are listed as follows: (1) we do not only focus on the events at the specific location, but cluster messages which come from every corner of the world; and (2) the detected topics in our system are not limited to known events. The other microblogging topic detection system [<xref ref-type="bibr" rid="bibr15-0165551513478738">15</xref>] introduced an idea of finding real-time local topics using micorblogging data. TwitterMonitor [<xref ref-type="bibr" rid="bibr16-0165551513478738">16</xref>] utilized trending word detection to recognize hot topics. Sankaranarayanan et al. [<xref ref-type="bibr" rid="bibr17-0165551513478738">17</xref>] developed a system so-called TwitterStand, which captures tweets that correspond to breaking news by means of utilizing a clustering approach for mining tweets.</p>
<p>In most data stream applications, burst detection is an important task to discover increasingly shapely patterns, which may be trending ones or unusual activities in the non-stationary stream. Related idea of the state-based method was proposed by Kleinberg [<xref ref-type="bibr" rid="bibr18-0165551513478738">18</xref>]. Their work considers the arrival rate of messages as the main factor in feature extraction, and the result yields a nested representation of the set of bursts that impose a hierarchical structure on the overall stream. Regarding the different lines of though in the threshold-based method, Swan [<xref ref-type="bibr" rid="bibr19-0165551513478738">19</xref><xref ref-type="bibr" rid="bibr20-0165551513478738"/>–<xref ref-type="bibr" rid="bibr21-0165551513478738">21</xref>] believed that each feature in a random time period always maintains a certain average rate; the mean of the average rate is the frequency of features in the time period divided by the total time interval. Therefore the burst detection algorithm in their work performs the results of the chi-square test as their threshold; once the average rate of a feature overtakes the threshold, it is recognized as a significant feature. Alternatively, a trend-based method [<xref ref-type="bibr" rid="bibr22-0165551513478738">22</xref>] treats a word as a falling or rising word by measuring absolute or relative change. In this work, we do not compare two event times (current and the last record), but consider the long-term expectation value. In addition, as the weights of features in dynamic stream have been computed, the next step is to group relevant text documents into thematic collections. This is called the task of data stream clustering [<xref ref-type="bibr" rid="bibr23-0165551513478738">23</xref><xref ref-type="bibr" rid="bibr24-0165551513478738"/>–<xref ref-type="bibr" rid="bibr25-0165551513478738">25</xref>].</p>
<p>STREAM [<xref ref-type="bibr" rid="bibr24-0165551513478738">24</xref>] was the first data stream clustering technique, proposed by Guha. The <italic>k</italic>-median clustering algorithm was adopted with a simple algorithm based on divide-and-conquer to solve the space limitation problem. In addition, CluStream [<xref ref-type="bibr" rid="bibr26-0165551513478738">26</xref>] is a stream clustering process that generates an online component that periodically stores detailed summary statistics and an offline component which uses only these summary statistics. A modification of CluStream technique, HPstream [<xref ref-type="bibr" rid="bibr27-0165551513478738">27</xref>], is a projected clustering method to reduce the dimensions of the data stream. Another similar work of CluStream is Birch [<xref ref-type="bibr" rid="bibr28-0165551513478738">28</xref>]. Birch (Balanced Iterative Reducing and Clustering using Hierarchies) is a well-known incremental clustering that summarizes online information into offline records and uses developed measurements to cope with the natural closeness of points to prevent scanning all data points. Zhong [<xref ref-type="bibr" rid="bibr29-0165551513478738">29</xref>, <xref ref-type="bibr" rid="bibr30-0165551513478738">30</xref>] combined an online spherical <italic>k</italic>-means algorithm with an existing scalable clustering strategy to achieve fast and adaptive clustering of text streams. Generally speaking, in our survey most text stream clustering works use online <italic>k-</italic>means-based techniques as their major text stream clustering algorithm. The main drawback of the <italic>k-</italic>means based online clustering method is that it should determine the fixed parameter of <italic>k</italic> (i.e. the topic), and it is thus unsuitable for some real world applications in the problem domain, especially in dealing with the topic detection task with dynamic topics. Such issues were discussed in these research work [<xref ref-type="bibr" rid="bibr30-0165551513478738">30</xref>, <xref ref-type="bibr" rid="bibr31-0165551513478738">31</xref>], and some solutions for avoiding empty cluster problems and choices of <italic>k</italic> were addressed. To avoid the problems of <italic>k-</italic>means-based clustering methods, we used online density-based approaches for mining topics from microblogging data collection.</p>
<p>Since the results of data stream clustering evolve with time, some authors have also addressed them as evolutionary clustering [<xref ref-type="bibr" rid="bibr32-0165551513478738">32</xref>]. This allows new incoming data to be compared with current ones, but one-pass clustering systems attempt to forget data when they have passed away. Chakrabarti et al. [<xref ref-type="bibr" rid="bibr32-0165551513478738">32</xref>] extended two widely used clustering algorithms, namely <italic>k-</italic>means and agglomerative hierarchical clustering, into an evolutionary method. The authors claimed that the evolutionary clustering is good at noise removal and masters catching the topic shift over time. Similar to evolutionary clustering, an incremental approach extended to a DBSCAN clustering method called <italic>IncrementalDBSCAN</italic> [<xref ref-type="bibr" rid="bibr33-0165551513478738">33</xref>, <xref ref-type="bibr" rid="bibr34-0165551513478738">34</xref>] also preserves the data in memory. The algorithm of <italic>IncrementalDBSCAN</italic> operates on the insertion and deletion of updates, and all situations that consider the linkage of objects’ density-connectivity in algorithms (e.g. absorption, merging) are event-driven. Owing to the advantages of density-based clustering, we modified and enhanced the original <italic>IncrementalDBSCAN</italic> clustering method for implementation of event detection.</p>
<p>Streaming text means that its concept may change over time like a water flow; such a characteristic is known as concept drift [<xref ref-type="bibr" rid="bibr35-0165551513478738">35</xref>, <xref ref-type="bibr" rid="bibr36-0165551513478738">36</xref>]. Concept drift is an intractable problem that violates the rule of training data. Intuitively, a priori knowledge is a useful justification that machine learning algorithms and data mining algorithms attempt to acquire by the training process. However, in streaming data, the patterns of a priori knowledge may possibly cause errors because the concept of streaming data is rapidly changing. Hence a good text stream clustering should not segment an evolving topic into separated topics [<xref ref-type="bibr" rid="bibr37-0165551513478738">37</xref>]. To overcome this problem, Aggarwal et al. [<xref ref-type="bibr" rid="bibr26-0165551513478738">26</xref>] proposed a micro-clustering approach to storing summaries in macro-clusters as snapshots. This two-phased approach enables the user to explore the nature of the evolution of the clusters over time. On the other hand, some literature has revealed that the sliding window process is a natural choice to handle this problem. Zhou et al. proposed SWClustering [<xref ref-type="bibr" rid="bibr38-0165551513478738">38</xref>], which stores temporal information in EHCF (Histogram of Cluster Features) over a sliding window for handling the clusters’ evolution.</p>
</sec>
<sec id="section3-0165551513478738">
<title>3. System architecture</title>
<p>The aim of this work was to provide a solution to allow users to quickly and accurately discover emerging events to satisfy their information needs. To achieve this goal, we focused on developing functions for detecting real-time topics in a timely updated manner. The system architecture developed for mining microblogging message streams is presented in <xref ref-type="fig" rid="fig1-0165551513478738">Figure 1</xref>. In <xref ref-type="fig" rid="fig1-0165551513478738">Figure 1</xref>, the online text-stream clustering we develop is based on a sliding window model and it combines three technical components: a dynamic term weighting scheme, a neighbourhood generation algorithm and an online density-based clustering. After acquiring the detected event topics by the system module, a topic ranking algorithm is performed for recommending urgent event information with a ranking to assist people to effectively organize emerging event information.</p>
<fig id="fig1-0165551513478738" position="float">
<label>Figure 1.</label>
<caption>
<p>Illustration of the system framework.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig1.tif"/>
</fig>
<p>As the system starts to process the message streams, the language filter will filter out some incoming messages that contain non-ASCII characters (i.e. Chinese, Japanese, etc.), and transform the message contents into bag-of-words features. In this work, we do not filter out messages that contain abbreviations and text message shorthand in the content. This is because we believe that every feature in message flows might contain inexplicitly temporal information, even where the message contains only one word (e.g. ‘earthquake!!’). A detailed description of the subsystems is addressed in the following section.</p>
</sec>
<sec id="section4-0165551513478738">
<title>4. The proposed methods for stream mining and clustering on microblogs</title>
<p>In this section, the kernel approach of this work, the developed online text-stream clustering approach for mining the microblogging message stream, is described. The developed online clustering method, which is based on a sliding window model, includes three components: a dynamic term weighting scheme, a neighbourhood generation algorithm and an online density-based clustering approach.</p>
<sec id="section5-0165551513478738">
<title>4.1. The dynamic term weighting technique and a sliding window approach</title>
<p>To process texts with a chronological order, a fundamental problem is how to find the significant features in text streams. Specifically, the trends of a concept are often not stable but change with time, which is known as <italic>concept drift</italic>. Under such circumstances, the design of a weighting scheme for a microblogging message should be constantly updated. However, it is worth mentioning that almost all terms occur in each message only once owing to the length limitation of messages. Therefore, the computation overhead of term frequency, <italic>tf</italic>, is strongly affected by the length of messages. In addition, the document frequency, <italic>df</italic>, conflicts with the operation of topic mining since a higher <italic>df</italic> value of the words implies that the terms occur in many documents, which might lead to the problem of missing topic words in messages to some extent. Here we apply the developed term weighting scheme <italic>BursT</italic>, which was described in our previous work [<xref ref-type="bibr" rid="bibr39-0165551513478738">39</xref>]. Our strategy in determining <italic>BursT</italic> value is that a heavier weight is achieved by a higher burstiness, in which some word occurs frequently in the window. The formula of <italic>BursT</italic> is presented in <xref ref-type="disp-formula" rid="disp-formula1-0165551513478738">equation 1</xref> [<xref ref-type="bibr" rid="bibr40-0165551513478738">40</xref>]:</p>
<p>
<disp-formula id="disp-formula1-0165551513478738">
<label>(1)</label>
<mml:math display="block" id="math1-0165551513478738">
<mml:mrow>
<mml:mi>Burs</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>T</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>w</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>B</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>w</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>*</mml:mo>
<mml:mi>TO</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>w</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0165551513478738" xlink:href="10.1177_0165551513478738-eq1.tif"/>
</disp-formula>
</p>
<p>where the weight of the word <italic>w</italic> at time <italic>t</italic> will be constituted by two factors –<italic>BS</italic> (<italic>Burst Score</italic>) and <italic>TOP</italic> (<italic>Term Occurrence Probability</italic>). The basic idea of the <italic>BS</italic> factor is to calculate the arrival rate of words, and each word will be compared with its long-time average of arrival rates, so a word will be recognized as a rising feature when the current arrival rate surpasses its average value. On the other hand, the <italic>TOP</italic> (term occurrence probability) factor represents the probability of the word occurrence in the sliding window. This factor enables the weight of the word to grow with its occurrence frequency in messages, in order to identify trending topics. For the operation of mining hot news topics from messages, if a word occurs in more messages, it is more likely to be a trending topic. For example, the word ‘mac’ may be contributed from ‘Mac OS’ as a new Macintosh computer will be available shortly; meanwhile, some people may be talking about ‘Mac Taylor’ (i.e. a character in the well-known TV drama <italic>CSI: NY</italic>). In this case, the word ‘mac’ can be correctly detected as a topic word in the appropriate trending topic associated with a specific emerging event through applying the <italic>BursT</italic> weighting formula. A more detailed description of the weighting factors can be found in our previous work [<xref ref-type="bibr" rid="bibr40-0165551513478738">40</xref>].</p>
<sec id="section6-0165551513478738">
<title>4.1.1. Incorporating a sliding window model</title>
<p>Prior to microblogging stream mining, the first challenging task is to process the never-ending data streams. Previous related work in exploring the concept of temporal locality [<xref ref-type="bibr" rid="bibr41-0165551513478738">41</xref>] has proven that we do not need to keep vast volume messages in memory, because message distribution of a topic in a temporal domain is largely centralized in a period of time. This implies that the method of storing a subset of entire datasets for a process is feasible. If an event is very frequently discussed, relevant messages will consecutively appear to prolong the life of a topic. Also, it is almost impossible to store all messages at one time owing to the restrictions of memory limitation and constant time lapsing. As a result, in this work we adopted the sliding window model [<xref ref-type="bibr" rid="bibr42-0165551513478738">42</xref>] to tackle the issue by means of moving time frames to process incoming messages. Briefly, the steps of sliding window technique include: (1) the insertion operation in which a new index entry is built when a message comes in; (2) reservation of the message until its lifetime exceeds the fixed length of time window <italic>tw</italic>; and (3) the deletion operation in which the message is removed from memory.</p>
</sec>
</sec>
<sec id="section7-0165551513478738">
<title>4.2. Neighbourhood generation algorithm</title>
<p>In this work, we applied density-based clustering in an incremental manner. Before detecting real-time topics by clustering algorithm, the first step is to build neighbourhood relationships among messages. The most frequently used method to analyse relations between texts is a nearest-neighbour based approach. When a message comes into the system, neighbours should be picked up to establish relations with it. The simplest method to select neighbours is scanning the entire corpus to discover the neighbours of the message, but it is time consuming and inefficient. In order to reduce the computational cost, in this work we utilize an inverted table to record that the word appears in messages in the sliding window. In particular, the deployment of the inverted table enhances computational efficiency. Thus, when a new message comes into the system, it is only calculated with the messages which have at least one feature the same, namely candidate neighbours. These candidate neighbours will be taken to calculate the distance that represents the extent of temporal text similarity between these messages. The similarity measure also considers the timing effects for the reduction of similarity for two messages with a different time distance [<xref ref-type="bibr" rid="bibr37-0165551513478738">37</xref>]. Consequently, the exact neighbour set of the message will be established to further support text clustering.</p>
<p>Thus, if <italic>Sim</italic>(<italic>m<sub>a</sub>,m<sub>b</sub></italic>) is exceed over the given threshold radius <italic>r, m<sub>b</sub></italic> will be <italic>m<sub>a</sub></italic>’s neighbour and <italic>m<sub>a</sub></italic> is also the neighbour message of <italic>m<sub>b</sub></italic>. The correlation function of <italic>m<sub>a</sub></italic> and <italic>m<sub>b</sub></italic> can be denoted as:</p>
<p>
<disp-formula id="disp-formula2-0165551513478738">
<label>(2)</label>
<mml:math display="block" id="math2-0165551513478738">
<mml:mrow>
<mml:mi>TTSim</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>cos</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>*</mml:mo>
<mml:mi>tp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>b</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0165551513478738" xlink:href="10.1177_0165551513478738-eq2.tif"/>
</disp-formula>
</p>
<p>In <xref ref-type="disp-formula" rid="disp-formula2-0165551513478738">equation (2)</xref>, the standard cosine function of similarity computation is used for content-based similarity measurement. For the consideration of temporal information, the <italic>temporal penalty tp</italic>(<italic>m<sub>a</sub>,m<sub>b</sub></italic>) is an exponential distribution that can calculate the timing effects for the reduction of similarity for two documents with different time distances [<xref ref-type="bibr" rid="bibr37-0165551513478738">37</xref>]. Consequently, the exact neighbour set of the message <italic>m</italic> will be established to further support text clustering.</p>
</sec>
<sec id="section8-0165551513478738">
<title>4.3. The online density-based clustering approach</title>
<p>As the neighbour relations are updated, the next step is to incrementally gather them into appropriate thematic topics. In this part of our work, an online text-stream clustering approach is adopted. The goal of clustering text stream is to detect a set of clusters in near real time from a never-ending text stream; these clusters are called <italic>topic clusters</italic>. To reach the goal, a modification version of <italic>IncrementalDBSCAN</italic> is developed in this work. The pros and cons for practical considerations are discussed in the following sections.</p>
<sec id="section9-0165551513478738">
<title>4.3.1. The <italic>IncrementalDBSCAN</italic> approach</title>
<p>With operations of the sliding window, text stream clustering should also be designed in functions of insertion and deletion. The operations of text stream clustering algorithm must include the response to situations that occur when a new object comes into the system and a strategy for deleting objects. In this work, we adopted a density-based clustering called <italic>IncrementalDBSCAN</italic> to group relevant messages into topic clusters thematically (see workflow in <xref ref-type="fig" rid="fig2-0165551513478738">Figure 2</xref>). In our preliminary system, <italic>DBHTE</italic> (<italic>Density-based Hot Topic Extraction</italic>) was tested with <italic>IncrementalDBSCAN</italic>, and the results show that it is a feasible solution for incrementally clustering microblogging for topic detection. The reasons for adopting density-based clustering are as follows: (1) there is no assumption about the number of clusters with fixed or flexile parameter of <italic>k</italic> (i.e. topic) in density-based clustering. Several methods need to initial the number of topics that are thus unsuitable for some real-world applications in the problem domain, especially in dealing with the topic detection task with dynamic topics around the world. (2) It has the ability to detect arbitrarily shaped clusters (see sketch in <xref ref-type="fig" rid="fig3-0165551513478738">Figure 3</xref>). (3) Messages collected from microblogs normally contain much noise. Once mining microblogging messages, the clustering algorithm should perform at its best to filter out noise in processing the contents. Density-based clustering groups objects based on their density connectivity and treats noises as outliers that would not be involved in any cluster.</p>
<fig id="fig2-0165551513478738" position="float">
<label>Figure 2.</label>
<caption>
<p>Two phases of text stream clustering in the <italic>IncrementalDBSCAN</italic> approach with the sliding window model.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig2.tif"/>
</fig>
<fig id="fig3-0165551513478738" position="float">
<label>Figure 3.</label>
<caption>
<p><italic>IncrementalDBSCAN</italic> updates clusters by four conditions of the insertion phase (a1, noise; a2, creation; a3, absorption; a4, merge) and three conditions of the deletion phase (b1, removal; b2, reduction; and b3, potential split).</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig3.tif"/>
</fig>
<p>The most interesting feature of <italic>IncrementalDBSCAN</italic> is that it has a ‘transitive’ characteristic. In <xref ref-type="fig" rid="fig4-0165551513478738">Figure 4</xref>, suppose there exists a situation in which A is density-reachable to B, and B is density-reachable to C. Although there is no direct relation between A and C, there must exist a transitive relation between A and C through B. For example, when an earthquake event happens, the topic cluster may contain many groups about ‘earthquake’. After a while, some messages about ‘tsunami’ appear; in other words, the earthquake event starts drifting in its concept imperceptibly to a ‘tsunami’ event, and then moves on the topic of ‘nuclear’. This is a typical pattern of topic evolution or concept evolution [<xref ref-type="bibr" rid="bibr43-0165551513478738">43</xref>]. Transitive characteristics may help us to establish a hidden relation that indicates that ‘earthquake’ and ‘nuclear’ are both on the same topic. This kind of transitive absorption might benefit from adapting concept drift and preventing segment topics becoming independent ones.</p>
<fig id="fig4-0165551513478738" position="float">
<label>Figure 4.</label>
<caption>
<p>(a) Transitive absorption benefits of adapting concept drift among topic evolution, and (b) transitive merging is able to merge separated topics when they have causality.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig4.tif"/>
</fig>
<p>Another transitive phenomenon also exists in the algorithm of <italic>IncrementalDBSCAN</italic>, namely <italic>transitive merging</italic>. Suppose there are two cluster topics <italic>α</italic> and <italic>β</italic>; at first, they do not share any bursty word and so are treated as two independent topics. After a moment, amounts of <italic>γ</italic> messages frequently appear and the message <italic>γ</italic> has both the bursty features of <italic>α</italic> and <italic>β</italic>. This indicates that there is a causality relationship between topics <italic>α</italic> (cause) and <italic>β</italic> (effect), and the transitive merging will be triggered to merge them into a single topic.</p>
<p><xref ref-type="fig" rid="fig4-0165551513478738">Figure 4</xref> shows two topics, one discussing the Grammy Awards and another talking about the American singer Lady Gaga. At first there seems to be no relation between them, but with time, many messages mention both Grammy and Lady Gaga, which points out that Lady Gaga was performing a song on the Grammy Award show. Thus all messages about these topics should be properly merged. However, for the updating requirement, some algorithms maintain clusters independently and assign an incoming message to the nearest cluster. Thus two separated topics will not be merged and the additional checking is needed in these methods to periodically compare the distributions of the pair-wise topics to merge relevant topics. Contrariwise, <italic>IncrementalDBSCAN</italic> provides a merge operation to dynamically change the assignments of messages, and the transitive merging has the ability to merge separated topics that have causality, so as to make our system more effective.</p>
</sec>
<sec id="section10-0165551513478738">
<title>4.3.2. The modified <italic>IncrementalDBSCAN</italic> approach</title>
<p>Unfortunately, <italic>IncrementalDBSCAN</italic> is not a fully compatible algorithm for mining topics in user-generated content. Here we point out two problems in <italic>IncrementalDBSCAN</italic> and modify the algorithm to make our system more robust. First, in our observation, there exists minority noise in which a single message mentions a mixture of trending topics. That would cause the ‘transitive merging’ condition to be carried out. Imagining a scenario, the topic detection system maintains three topic clusters that were originally independent. They are discussing the topics of the Royal wedding, Sam Adams and Osama being killed, respectively. And now, here comes a message the content of which is ‘royal wedding on friday, sam adams on saturday, and osama killed on sunday … how can this weekend get any damn better!?’ At this time, it may trigger the merge condition owing to the message establishing neighbourhood relationships with others from the three topics. As a result, separated topics will be merged into single topic, as shown in <xref ref-type="fig" rid="fig5-0165551513478738">Figure 5</xref>.</p>
<fig id="fig5-0165551513478738" position="float">
<label>Figure 5.</label>
<caption>
<p>Illustration of transitive merging in <italic>IncrementalDBSCAN</italic> method.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig5.tif"/>
</fig>
<p>Transitive merging has two sides: positive and negative. The modification we are going to perform is to adjust the merge judgment by adding some constraints. They are listed as follows:</p>
<list id="list1-0165551513478738" list-type="order">
<list-item>
<p>In the first step, ensuring object <italic>γ</italic> has enough influence to trigger the merge condition. For instance, the incoming message should be a core object.</p>
</list-item>
<list-item>
<p>Subsequently, calculating the merge score for the pair-wise candidate clusters to make sure that they are extremely similar. For example, the merge score can be measured by bursty words and it should exceed the given threshold (i.e. double Minpts). The design of merge score calculation algorithm is listed as shown in the mergeScore().</p>
</list-item>
<list-item>
<p>Otherwise, the incoming message should be absorbed by the most relevant topic cluster (<xref ref-type="fig" rid="fig16-0165551513478738">Scheme 1</xref>).</p>
</list-item>
</list>
<fig id="fig16-0165551513478738" position="float">
<label>Scheme 1.</label>
<graphic xlink:href="10.1177_0165551513478738-fig16.tif"/>
</fig>
<p>The second problem of <italic>IncrementalDBSCAN</italic> is the potential split condition in the deletion phase. Potential split means that it has split and a non-split situations. The judgment for identifying these situations needs to make a traversal (BSF) to every affected object, which is time-consuming and inefficient. Hence we suggest removing the potential split condition because an ordinary event would not be split into two events.</p>
<p>According to our modification to the <italic>IncrementalDBSCAN</italic> method, our system is more robust on clustering messages into topics. In addition, based on the original version of <italic>IncrementalDBSCAN</italic>, the shape of clusters will change over time when a message is inserted or a victim message is deleted from sliding window with its message density properties. Certainly the less dense area would not be a topic, because the distances between messages are much greater according to the calculations of temporal text distance. Meanwhile, the text stream clustering algorithm will generate several clusters each time, owing to its dynamic nature. Also, people can monitor well-processed clustering results at each moment.</p>
</sec>
</sec>
<sec id="section11-0165551513478738">
<title>4.4. Evaluation metrics</title>
<p>In <xref ref-type="fig" rid="fig6-0165551513478738">Figure 6</xref>, we explained the relationship between <italic>CR<sub>k</sub></italic> and <italic>ETRSet<sub>k</sub></italic>. The intersection of <italic>CR<sub>k</sub></italic> and <italic>ETRSet<sub>k</sub></italic> is the set of hit messages, {<italic>m: m</italic>∈<italic>CR<sub>k</sub> and m</italic>∈<italic>ETRSet<sub>k</sub></italic>}, which is recorded as <italic>ETRSet<sub>k</sub>+</italic>. Another part <italic>ETRSet<sub>k</sub>−</italic> represents the highly relevant messages that are not found in the cluster result. Further, the difference in the cluster result {<italic>m: m</italic>∈<italic>CR<sub>k</sub> and m∈ETRSet<sub>k</sub></italic>} is represented as <italic>Potential Hidden Context</italic> (<italic>PHC<sub>k</sub></italic>). This part can be considered as additional information produced by clustering algorithms. To discriminate messages of hidden context from noise, the true <italic>hidden context</italic> (<italic>HC<sub>k</sub>+</italic>) in this work is selected by human judges, in order to understand how much additional information the clustering approach provides.</p>
<fig id="fig6-0165551513478738" position="float">
<label>Figure 6.</label>
<caption>
<p>Illustration of our evaluation strategy.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig6.tif"/>
</fig>
<p>In order to measure the performance of clustering results, there are three criteria for evaluation in this work, as listed below.</p>
<p><italic>Approximate Topic Recall (ATR)</italic><bold>–</bold> One of our critically concerned factors is the recall performance of the system. Unfortunately, owing to the difficulties of finding a gold standard, we used explicit topic-related set (<italic>ETRSet<sub>k</sub></italic>) as our approximate gold standard result. The approximate topic recall rate for a cluster result is defined as:</p>
<p>
<disp-formula id="disp-formula3-0165551513478738">
<label>(3)</label>
<mml:math display="block" id="math3-0165551513478738">
<mml:mrow>
<mml:mi>atr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ETRSe</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ETRSe</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0165551513478738" xlink:href="10.1177_0165551513478738-eq3.tif"/>
</disp-formula>
</p>
<p>Let <italic>ETRSet<sub>k</sub></italic> represent the approximate gold standard, and then <italic>atr</italic> is measured by the number of messages in the intersection part (<italic>ETRSet<sub>k</sub>+</italic>) divided by the total number of approximate gold standards <italic>ETRSet<sub>k</sub></italic>. A higher <italic>atr</italic>(<italic>k<sub>i</sub></italic>) value means that the system is more capable of retrieving relevant messages. To evaluate the performance of <italic>K</italic> selected topic clusters, the approximate topic recall rate of overall selected topic clusters is represented as follows:</p>
<p>
<disp-formula id="disp-formula4-0165551513478738">
<label>(4)</label>
<mml:math display="block" id="math4-0165551513478738">
<mml:mrow>
<mml:mi>ATR</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>K</mml:mi>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>·</mml:mo>
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>K</mml:mi>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mi>atr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0165551513478738" xlink:href="10.1177_0165551513478738-eq4.tif"/>
</disp-formula>
</p>
<p>A higher ATR value means that the system is more capable of finding more relevant messages.</p>
<p><italic>Topic Precision (TP)</italic><bold>–</bold> As mentioned previously, the clustering-based approach is of great potential to involve more hidden context messages in the clustering results than information retrieval-based methods. Essentially, this approach allows not only additional information to be absorbed, but also some irrelevant messages (noises) likely to be incorporated into clusters. To measure the quality of a topic cluster, we define a topic precision for a topic cluster as follows:</p>
<p>
<disp-formula id="disp-formula5-0165551513478738">
<label>(5)</label>
<mml:math display="block" id="math5-0165551513478738">
<mml:mrow>
<mml:mi>tp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>C</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>C</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ETRSe</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>PH</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>C</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0165551513478738" xlink:href="10.1177_0165551513478738-eq5.tif"/>
</disp-formula>
</p>
<p>In general, the <italic>tp</italic> criteria for a topic <italic>k<sub>i</sub></italic> can be regarded as the precision of the cluster. Compared with the typical precision factor, the difference is that non-relevant messages of cluster results are only contributed by wrong additional information (<italic>PHC<sub>k</sub>−</italic>). Hence the <italic>tp</italic> solution is expressed as the proportion of a sum of the number of messages in <italic>ETRSet<sub>k</sub>+</italic> and <italic>PHC<sub>k</sub>−</italic> to the total number of <italic>CR<sub>k</sub></italic>. The overall topic precision is addressed as:</p>
<p>
<disp-formula id="disp-formula6-0165551513478738">
<label>(6)</label>
<mml:math display="block" id="math6-0165551513478738">
<mml:mrow>
<mml:mi>TP</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>K</mml:mi>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>·</mml:mo>
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>K</mml:mi>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:msubsup>
<mml:mi>tp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0165551513478738" xlink:href="10.1177_0165551513478738-eq6.tif"/>
</disp-formula>
</p>
<p>Similarily, a good clustering algorithm should have higher topic precision.</p>
</sec>
<sec id="section12-0165551513478738">
<title>4.5. Topic ranking algorithm</title>
<p>The challenges of ranking microblogging posts mainly come from the briefness of user-generated content and its real-time characteristics. Therefore, the developers should design more efficient algorithms to rank posts, especially avoiding the use of a factor that will calculate the entire collection each time. In order to satisfy such an information need, we developed an approach called <italic>topic energy</italic> [<xref ref-type="bibr" rid="bibr37-0165551513478738">37</xref>] to evaluate the significance of each topic. To understand the topic evolution over time, the topic energy uses records to evaluate the extent of significance of a given topic at each time point over a time period. After aggregating messages into topics thematically, users may want to know how many hot topics there are on microblogs and how popular they are.</p>
<sec id="section13-0165551513478738">
<title>4.5.1. Representation of a resulting cluster for a topic event and ranking of related messages</title>
<p>Subsequently, the intensity of a cluster can be recognized by utilizing the energy function. It is necessary to identify the central concept of a topic cluster. Some researchers have employed the technique of topic summarization by selecting representative sentences in each topic cluster. In an attempt to keep the content original, we proposed a ranking function for online sorting messages in each topic cluster.</p>
<p>Instead of re-calculating entire message collection for ranking, we performed a process of ranking messages after clustering operation, based on the following considerations: (1) sorting messages for each topic is faster than directly sorting all messages; and (2) users can view ranked messages with a topical structure.</p>
<p>To score a message at time <italic>t</italic>, we define the <italic>message score MS<sub>m</sub></italic> (7) and <italic>scoring function</italic> (8) as:</p>
<p>
<disp-formula id="disp-formula7-0165551513478738">
<label>(7)</label>
<mml:math display="block" id="math7-0165551513478738">
<mml:mrow>
<mml:mi>M</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>weigh</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>m</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>*</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>w</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>∈</mml:mo>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>w</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0165551513478738" xlink:href="10.1177_0165551513478738-eq7.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula8-0165551513478738">
<label>(8)</label>
<mml:math display="block" id="math8-0165551513478738">
<mml:mrow>
<mml:mi>scor</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>M</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>*</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mtext>e</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>t</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>/</mml:mo>
<mml:mi>τ</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0165551513478738" xlink:href="10.1177_0165551513478738-eq8.tif"/>
</disp-formula>
</p>
<p>The message score <italic>MS<sub>m</sub></italic> is calculated when the message enters the system by accumulating the <italic>BursT</italic> weighting values of the word <italic>j</italic>, producing the ratio of word <italic>j</italic> appearing in the topic cluster at time point <italic>TC<sub>t</sub></italic>. Furthermore the scoring function is measured using the message score and an aging factor. The aging factor panelizes the older message by comparing the current time <italic>c<sub>t</sub></italic> with the timestamp of this message <italic>t<sub>m</sub></italic>. Here,<italic>τ</italic> is an exponential time constant, in this work we usually set it to 600. Thus the scores for a message may change over time. According to the operations of the sliding window model, the results of ranking order may also change over time. Even if a very high scoring message appeared in a topic, the next time it would be replaced by a message with a higher score, or removed as its life time exceeds the time-length of the sliding window.</p>
</sec>
</sec>
</sec>
<sec id="section14-0165551513478738">
<title>5. Experiments and discussion</title>
<sec id="section15-0165551513478738">
<title>5.1. Preliminary experiment</title>
<p>First, we performed a small preliminary experiment to identify the feasibility and potential of the developed system. The experiment aimed to compare our detection result with the event situation in the real world, therefore the operational result of Google Trends,<sup><xref ref-type="fn" rid="fn1-0165551513478738">1</xref></sup> which reflects what keywords people are searching for on a daily basis, was selected as a baseline to evaluate our system performance. We applied the developed topic detection method (previously known as the <italic>DBHTE</italic> algorithm) with the parameter settings Eps = 0.4, MinPts = 10, and the length of time window <italic>W</italic> was set to 1 hour. We submitted a keyword ‘Microsoft’ to Google Trends, and there was an event news ‘Microsoft launches Kin phones’ reported by Times Live at 09:14 AM, 13 April 2010, shown in <xref ref-type="fig" rid="fig7-0165551513478738">Figure 7</xref>. In comparison, we examined the sample messages which contained the ‘Microsoft’ string in the collection, shown in <xref ref-type="fig" rid="fig8-0165551513478738">Figure 8</xref>. <xref ref-type="fig" rid="fig8-0165551513478738">Figure 8</xref> shows that the maximum peak in our tweets collection was at 03:00 AM, 13 April 2010.</p>
<fig id="fig7-0165551513478738" position="float">
<label>Figure 7.</label>
<caption>
<p>Query result of a keyword ‘Microsoft’ in Google Trends in the preliminary experiment.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig7.tif"/>
</fig>
<fig id="fig8-0165551513478738" position="float">
<label>Figure 8.</label>
<caption>
<p>Tweets containing ‘Microsoft’ keyword in the preliminary experiment.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig8.tif"/>
</fig>
<p>The results in <xref ref-type="fig" rid="fig7-0165551513478738">Figures 7</xref> and <xref ref-type="fig" rid="fig8-0165551513478738">8</xref> indicate that, in this case, the result in the microblogging system was more sensitive and clearer than the one in Google Trends for event detection before the news was reported. There were 20 messages in the cluster related to ‘Microsoft launches Kin phones’ generated at 02:56:35, 13 April 2010.</p>
</sec>
<sec id="section16-0165551513478738">
<title>5.2. Running time</title>
<p>To get an initial picture about how long it takes for our system to carry out a task in all stages, we also conducted a measure to evaluate its real-time performance. The result indicates the timings of processing steps regarding the information flow within our system. The running time for a task includes: (1) collecting the input data through Twitter API, 0.04347 seconds; (2) decomposing each message into keywords and filtering out stop words, 0.0023 seconds; (3) the term-weighting process for each message, 0.00023 seconds; (4) the neighbourhood generation operation for each message, 0.00015 seconds; (5) the density-based clustering process, 0.000228 seconds; and (6) the ranking operation, 0.000002565 seconds. On average, the memory space consumed in performing a task is about 1.2G Bytes, and the length of the time window (i.e. the window size of the sliding window) is normally set to 1–2 hours. In our example, the longer parameter setting of window-size (i.e. 2 hours) consumed more memory space than the shorter one (i.e. 1 hour). However, the longer window-size will reduce the probability of missing messages within an event life cycle. A detailed discussion of more experiments is provided in the following sections.</p>
</sec>
<sec id="section17-0165551513478738">
<title>5.3. Collecting data sets from microblogging big data</title>
<p>To detect topics in microblogs, a total number of 170,427,512 microblogging posts were collected from Twitter over a period of 140 days (dating from 6 January to 26 May 2011). The test samples were collected through Twitter Stream API<sup><xref ref-type="fn" rid="fn2-0165551513478738">2</xref></sup> by Twitter4J<sup><xref ref-type="fn" rid="fn3-0165551513478738">3</xref></sup> library and the timestamp is based on Taipei time (GMT +8:00). After filtering out non-ASCII tweets, 88,682,820 available tweets were utilized as our data source. It is worth mentioning that all online tweets were stored in a static corpus, and then our algorithms processed them in an online manner (i.e. time sequence order). Subsequently, we partitioned messages into unigrams and removed the substring ‘RT @username:’. In this work, the stopword list contains stopwords in several different languages<sup><xref ref-type="fn" rid="fn4-0165551513478738">4</xref></sup> since the collected tweets contain multilingual texts. Finally, all capital letters in each tweet were converted into lowercase for our experiments.</p>
</sec>
<sec id="section18-0165551513478738">
<title>5.4. Evaluating trends of features with timelines</title>
<p>In order to examine the system performance in reflecting the trends of words, we selected the ‘President Obama delivers statement on death of Osama Bin Laden’ event as our case study. Our experiment drew the trends of the string ‘Obama’ with the timeline. <xref ref-type="fig" rid="fig9-0165551513478738">Figure 9</xref> indicates the intensity of the inter-arrival gap of the feature word ‘Obama’, and is an enlarged drawing. In these figures, the expected values for ‘Obama’ had decreased when the inter-arrival gaps suddenly dropped owing to the event occurring. The burst period can be identified once the gap-value is under the line of expected value. It is worth mentioning that the historical case investigated in this context is only for our empirical study, without any political motivation.</p>
<fig id="fig9-0165551513478738" position="float">
<label>Figure 9.</label>
<caption>
<p>Inter-arrival gaps using the feature word ‘Obama’ in the period of the event of ‘President Obama delivers statement on death of Osama Bin Laden’.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig9.tif"/>
</fig>
<p>In the task of topic detection, the <italic>TFPDF</italic> term-weighting scheme is a well-known method that gives a higher weight to a term that has occurred frequently in many documents from the newswire sources to find emerging topics. <italic>PDF</italic> weighting represents an exponential distribution of the number of documents containing the term compared with the total number of documents in the channel. The <italic>TFPDF</italic> scheme benefits topic detection tasks particularly for finding significant words, but it over-emphasizes the extraction of frequent features, which may enable oral words to have heavier weights.</p>
<p>Subsequently, we compared the weighting values of <italic>BursT</italic> and <italic>TFIDF</italic> methods, as shown in <xref ref-type="fig" rid="fig10-0165551513478738">Figure 10</xref>, and found that the incremental <italic>TFIDF</italic> cannot reflect the actual trends in the sliding window algorithm, although <italic>TFPDF</italic> and our approach performed well in topic words. However, in the outcome of oral word analysis, we demonstrated that the word ‘lol’, which has both a high density of collection and a high arrival rate, as an example, and obviously it might not be suitable to define ‘lol’ as a valid feature. It is worth mentioning that some popular oral words might be easily over-weighted in <italic>TFPDF</italic> because it places too much emphasis on document frequency. As shown in <xref ref-type="fig" rid="fig10-0165551513478738">Figure 10D</xref> and <xref ref-type="fig" rid="fig10-0165551513478738">E</xref>, the weighted number of ‘lol’ in <italic>TFPDF</italic> is still higher than in incremental <italic>TFIDF</italic>, even when the event is still happening.</p>
<fig id="fig10-0165551513478738" position="float">
<label>Figure 10.</label>
<caption>
<p>Evaluation of <italic>BursT</italic>, incremental <italic>TFIDF</italic> and <italic>TFPDF</italic> weighting techniques.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig10.tif"/>
</fig>
</sec>
<sec id="section19-0165551513478738">
<title>5.5. Distributions of bursty features and oral features</title>
<p>Using the collected Twitter data sets, we evaluated our system using the weight distribution of <italic>BS</italic> and <italic>TOP</italic> in snapshots. In this section, we experimented with our data sets by taking the event ‘Japan earthquake on 11 March 2011’ as an example. The ‘Japan earthquake’ topic cluster was created by our system on 11 March 2011 14:03:28; the first time, there were no weights heavier than 0.5 (<xref ref-type="fig" rid="fig11-0165551513478738">Figure 11</xref>). We found that some bursty features like ‘earthquake’ and ‘scares’ are the major key terms in forming a new topic. In our weight design, a heavy weight is assigned by a word that has a higher burst rate than expected within a certain range of document frequency. Obviously, in the oral features listed in <xref ref-type="table" rid="table1-0165551513478738">Table 1</xref>, all samples have a higher <italic>TOP</italic> value than bursty features, but they are not in the bursty state to be qualified as important features.</p>
<fig id="fig11-0165551513478738" position="float">
<label>Figure 11.</label>
<caption>
<p>Term weight distribution with <italic>BS</italic> and <italic>TOP</italic> factors on 11 March 2011, 14:03:28 (the time at which the earthquake was detected by our system), 11 March 2011, 21:34:59 (the time at which the tsunami caused by the Japan earthquake headed towards Hawaii) and 12 March 2011, 18:14:06 (the time at which the Japanese government confirmed the radiation leak).</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig11.tif"/>
</fig>
<table-wrap id="table1-0165551513478738" position="float">
<label>Table 1.</label>
<caption>
<p>Top-10 bursty features and oral features</p>
</caption>
<graphic alternate-form-of="table1-0165551513478738" xlink:href="10.1177_0165551513478738-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="4">Bursty features<hr/></th>
<th align="left" colspan="4">Oral features<hr/></th>
</tr>
<tr>
<th align="left">Term</th>
<th align="left"><italic>BS</italic></th>
<th align="left"><italic>TOP</italic></th>
<th align="left"><italic>BursT</italic></th>
<th align="left">Term</th>
<th align="left"><italic>BS</italic></th>
<th align="left"><italic>TOP</italic></th>
<th align="left"><italic>BursT</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="8"><italic>11 March 2011, 14:03:28 BursT(w) &gt; 0.15</italic></td>
</tr>
<tr>
<td>basi</td>
<td>2043.98</td>
<td>1.22 × 10<sup>−4</sup></td>
<td>0.24</td>
<td>back</td>
<td>0</td>
<td>0.007</td>
<td>0</td>
</tr>
<tr>
<td>earthquake</td>
<td>281.62</td>
<td>8.73 × 10<sup>−4</sup></td>
<td>0.24</td>
<td>shit</td>
<td>0</td>
<td>0.003</td>
<td>0</td>
</tr>
<tr>
<td>scares</td>
<td>919.211</td>
<td>2.64 × 10<sup>−4</sup></td>
<td>0.24</td>
<td>night</td>
<td>0</td>
<td>0.003</td>
<td>0</td>
</tr>
<tr>
<td>nebeng</td>
<td>1636.96</td>
<td>1.42 × 10<sup>−4</sup></td>
<td>0.23</td>
<td>watch</td>
<td>0</td>
<td>0.003</td>
<td>0</td>
</tr>
<tr>
<td>bracelet</td>
<td>1895.51</td>
<td>1.22 × 10<sup>−4</sup></td>
<td>0.23</td>
<td>bad</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>pones</td>
<td>1379.71</td>
<td>1.62 × 10<sup>−4</sup></td>
<td>0.22</td>
<td>nice</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>hardbody</td>
<td>5486.16</td>
<td>4.06 × 10<sup>−4</sup></td>
<td>0.22</td>
<td>youtube</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>aires</td>
<td>1648.78</td>
<td>1.22 × 10<sup>−4</sup></td>
<td>0.2</td>
<td>phone</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>lmbo</td>
<td>599.02</td>
<td>3.25 × 10<sup>−4</sup></td>
<td>0.19</td>
<td>open</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>irfan</td>
<td>1570.89</td>
<td>1.22 × 10<sup>−4</sup></td>
<td>0.19</td>
<td>wanna</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td colspan="8"><italic>11 March 2011, 21:34:59 BursT(w)&gt;0.5</italic></td>
</tr>
<tr>
<td>hawaii</td>
<td>336.49</td>
<td>0.012</td>
<td>4.05</td>
<td>back</td>
<td>0</td>
<td>0.007</td>
<td>0</td>
</tr>
<tr>
<td>japan</td>
<td>63.98</td>
<td>0.049</td>
<td>3.13</td>
<td>shit</td>
<td>0</td>
<td>0.003</td>
<td>0</td>
</tr>
<tr>
<td>earthquake</td>
<td>98.72</td>
<td>0.017</td>
<td>1.753</td>
<td>night</td>
<td>0</td>
<td>0.003</td>
<td>0</td>
</tr>
<tr>
<td>affected</td>
<td>356.36</td>
<td>0.004</td>
<td>1.62</td>
<td>watch</td>
<td>0</td>
<td>0.003</td>
<td>0</td>
</tr>
<tr>
<td>devastating</td>
<td>2336.25</td>
<td>6.15 × 10<sup>−4</sup></td>
<td>1.43</td>
<td>bad</td>
<td>0</td>
<td>0.0028</td>
<td>0</td>
</tr>
<tr>
<td>jepang</td>
<td>166.76</td>
<td>0.007</td>
<td>1.3</td>
<td>nice</td>
<td>0</td>
<td>0.0028</td>
<td>0</td>
</tr>
<tr>
<td>prayers</td>
<td>145.8</td>
<td>0.008</td>
<td>1.28</td>
<td>youtube</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>praying</td>
<td>163.33</td>
<td>0.004</td>
<td>0.66</td>
<td>phone</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>coast</td>
<td>134.34</td>
<td>0.0046</td>
<td>0.62</td>
<td>wanna</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td>disaster</td>
<td>218.71</td>
<td>0.00281</td>
<td>0.61</td>
<td>followers</td>
<td>0</td>
<td>0.002</td>
<td>0</td>
</tr>
<tr>
<td colspan="8"><italic>12 March 2011, 18:14:06 BursT(w) &gt; 0.15</italic></td>
</tr>
<tr>
<td>plant</td>
<td>111.46</td>
<td>0.009571</td>
<td>1.06</td>
<td>lol</td>
<td>0</td>
<td>0.021</td>
<td>0</td>
</tr>
<tr>
<td>japanese</td>
<td>222.87</td>
<td>0.003539</td>
<td>0.78</td>
<td>love</td>
<td>0</td>
<td>0.015</td>
<td>0</td>
</tr>
<tr>
<td>jepang</td>
<td>132.78</td>
<td>0.004216</td>
<td>0.55</td>
<td>out</td>
<td>0</td>
<td>0.014</td>
<td>0</td>
</tr>
<tr>
<td>escape</td>
<td>522.47</td>
<td>9.23 × 10<sup>−4</sup></td>
<td>0.5</td>
<td>photo</td>
<td>0</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr>
<td>japan</td>
<td>16.15</td>
<td>0.024067</td>
<td>0.38</td>
<td>time</td>
<td>0</td>
<td>0.009</td>
<td>0</td>
</tr>
<tr>
<td>residents</td>
<td>708.81</td>
<td>5.23 × 10<sup>−4</sup></td>
<td>0.37</td>
<td>day</td>
<td>0</td>
<td>0.007</td>
<td>0</td>
</tr>
<tr>
<td>towel</td>
<td>777.34</td>
<td>4.62 × 10<sup>−4</sup></td>
<td>0.35</td>
<td>night</td>
<td>0</td>
<td>0.007</td>
<td>0</td>
</tr>
<tr>
<td>explosion</td>
<td>37.04</td>
<td>0.006401</td>
<td>0.23</td>
<td>xd</td>
<td>0</td>
<td>0.005</td>
<td>0</td>
</tr>
<tr>
<td>dealin</td>
<td>7219</td>
<td>3.08 × 10<sup>−5</sup></td>
<td>0.22</td>
<td>home</td>
<td>0</td>
<td>0.005</td>
<td>0</td>
</tr>
<tr>
<td>radiation</td>
<td>86.51</td>
<td>0.002524</td>
<td>0.21</td>
<td>free</td>
<td>0</td>
<td>0.005</td>
<td>0</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>After a period of time, at 21:34:59 the concept of the topic started to change; there were many people talking about the tsunami that might possibly affect Hawaii. In <xref ref-type="fig" rid="fig11-0165551513478738">Figure 11</xref>, there appear some features whose weight is &gt;0.5 as being a powerful influential feature. Additionally, from the effects of news media, the list of bursty features gradually includes the explicit words (<xref ref-type="table" rid="table1-0165551513478738">Table 1</xref>) and there is an interesting finding that the word ‘jepang’ also belongs to a bursty feature, which is ‘japan’ in Bahasa Indonesia. Also, although ‘hawaii’ has a lower <italic>TOP</italic> value than ‘japan’ at that time, the <italic>BS</italic> raised its priority to indicate ‘hawaii’ to be more important that ‘japan’. That confirms that our burst detection in term weighting method is effective.</p>
</sec>
<sec id="section20-0165551513478738">
<title>5.6. Evaluation of system performance</title>
<p>In our system, the radius threshold (Eps) of our online text-stream clustering approach is one of the controllable parameters affecting the performance, and the threshold of minimum messages of a topic (minPts) is set to 15. All of the settings of these parameters (i.e. Eps and MinPts) in this work have been well tuned and verified. In the context of this work, we applied an evaluation metrics to investigate the reliability of our algorithm with the 2 hour length of sliding window and show how the radius affects the system performance. The approximate topic recall and topic precision values of 10 selected topic clusters are shown in <xref ref-type="fig" rid="fig12-0165551513478738">Figure 12</xref>. Ideally, the lower similarity threshold may have a higher approximate topic recall. This means that the system is more capable of retrieving relevant messages. On the other hand it may pose a higher probability of gathering noise and become a low-quality cluster. However, in the set of the fourth, sixth, eighth and tenth selected clusters with Eps 0.3, the system has a lower approximate topic recall since the <italic>ETRSet<sub>k</sub></italic> for each topic cluster <italic>k</italic> is independent. Obviously, the ninth topic cluster ‘Osama Bin Laden killed by U.S.’ has a low approximate topic recall in Eps = 0.4 and Eps = 0.5 owing to the low radius threshold. According to the experimental result, on average our system achieved a high topic precision performance except for the case of the second topic cluster ‘Super Bowl 2011’ with Eps = 0.3. That was due to numerous errors occuring in clustering the messages about ‘puppy bowl’ and ‘Chelsea vs. Liverpool football game’. To sum up, the aim of this work is to help effectively resolve the problems of information overload. As a result, in this work the performance trade-off we are particularly concerned with is the topic precision (i.e. precision), rather than approximate topic recall (i.e. recall). The experimental results show that our system is effective in online text-stream clustering, specifically for the topic precision of topics, as shown in <xref ref-type="fig" rid="fig13-0165551513478738">Figure 13</xref>.</p>
<fig id="fig12-0165551513478738" position="float">
<label>Figure 12.</label>
<caption>
<p>(a) ATR and (b) TP evaluations with parameter settings of Eps = 0.5, 0.4 and 0.3.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig12.tif"/>
</fig>
<fig id="fig13-0165551513478738" position="float">
<label>Figure 13.</label>
<caption>
<p>Overall performance of our system.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig13.tif"/>
</fig>
</sec>
<sec id="section21-0165551513478738">
<title>5.7. Evaluation of the topic ranking algorithm through a real-world case study</title>
<p>In order to examine our topic ranking algorithm, the results of detecting the event of ‘Japan earthquake’ have been investigated. This event happened at 13:46 (GMT +8:00), and the first related post received is the message of ‘Quake!’ from Tokyo at 13:50:53 (GMT +8:00). The topic cluster was established by our system at 14:03:28 (GMT +8:00). <xref ref-type="fig" rid="fig14-0165551513478738">Figure 14</xref> illustrates the topic energy situation during the time period of the event.</p>
<fig id="fig14-0165551513478738" position="float">
<label>Figure 14.</label>
<caption>
<p>Diagram of topic energy situation during the period of ‘Japan earthquake’ event.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig14.tif"/>
</fig>
<p>In <xref ref-type="fig" rid="fig14-0165551513478738">Figure 14</xref>, the calculated value of the topic energy of the event ‘Japan earthquake’ was far larger than those of other events. Once a sudden disaster occurs, the impact of the burstiness factor will be stronger than popularity and informativeness factors, which is due to some bursty words simultaneously appearing in most event-related messages at the time point.</p>
<p>In <xref ref-type="fig" rid="fig15-0165551513478738">Figure 15</xref>, the result indicates that the impact of the burstiness factor was stronger than popularity and informativeness factors at the time points. In addition, following the event, the information diversity was increased, as shown in <xref ref-type="fig" rid="fig15-0165551513478738">Figure 15b</xref>. This demonstrates that our system has the capacity to detect concept drift, since the system did not separate them into three different topics.</p>
<fig id="fig15-0165551513478738" position="float">
<label>Figure 15.</label>
<caption>
<p>Topic precision experiment with parameter settings of Eps = 0.5, 0.4 and 0.3.</p>
</caption>
<graphic xlink:href="10.1177_0165551513478738-fig15.tif"/>
</fig>
<p>Eventually, the messages in the topic were ranked by our algorithm. In this case we ranked messages every 5 minutes with the selected three primary time points mentioned previously. The resulting top-five posts and their bursty words are shown in <xref ref-type="table" rid="table2-0165551513478738">Table 2</xref>. They indicate that the ranking order is not simply determined by either timing or content factor. It also considers both bursty weights (i.e. content) and aging factor (i.e. time). The ranking list was changing over time to provide the newest event information.</p>
<table-wrap id="table2-0165551513478738" position="float">
<label>Table 2.</label>
<caption>
<p>Top-five posts and bursty words</p>
</caption>
<graphic alternate-form-of="table2-0165551513478738" xlink:href="10.1177_0165551513478738-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Topic energy</th>
<th align="left">Top-five posts</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="2"><italic>11 March 2011, 14:03:28</italic></td>
</tr>
<tr>
<td>0.063</td>
<td>36146830 | Fri Mar 11 14:02:42 CST 2011 | Singapore | RT @stcom: BREAKING: <bold>Magnitude</bold> 7.9 <bold>earthquake</bold> hits <bold>Japan</bold>, rattling buildings in <bold>Tokyo</bold>. <bold>Tsunami</bold> alert was issued.</td>
</tr>
<tr>
<td>0.062</td>
<td>36145421 | Fri Mar 11 13:58:59 CST 2011 | Central Time (US &amp; Canada) | RT @BreakingNews: Strong <bold>earthquake</bold> strikes northern <bold>Japan</bold>, rattlingbuildings in <bold>Tokyo</bold>; <bold>tsunami</bold> warning issued – AP</td>
</tr>
<tr>
<td>0.057</td>
<td>36146497 | Fri Mar 11 14:01:49 CST 2011 | Tokyo | RT @CBCAlerts: 7.2 <bold>magnitude earthquake</bold> hits Northern <bold>Japan</bold>. <bold>Tsunami</bold> alert has been issued. #<bold>Japan</bold> #Quake</td>
</tr>
<tr>
<td>0.056</td>
<td>36146241 | Fri Mar 11 14:01:08 CST 2011 | Tokyo | RT @BreakingNews: <bold>Japan</bold> update: Agency says <bold>earthquake magnitude</bold> 7.9</td>
</tr>
<tr>
<td>0.056</td>
<td>36146382 | Fri Mar 11 14:01:30 CST 2011 | Abu Dhabi | RT @ProducerMatthew: More information on the 7.9-<bold>magnitude earthquake</bold> that just hit <bold>Japan</bold> - <ext-link ext-link-type="uri" xlink:href="http://t.co/tGLml6d">http://t.co/tGLml6d</ext-link> |</td>
</tr>
<tr>
<td>Bursty words</td>
<td><bold>magnitude</bold>: 0.00346452637, <bold>tsunami</bold>: 0.02789596796, <bold>earthquake</bold>: 0.242462589, <bold>japan</bold>: 0.1775319869,<break/><bold>tokyo</bold>: 0.078453986</td>
</tr>
<tr>
<td colspan="2"><italic>11 March 2011, 21:34:59</italic></td>
</tr>
<tr>
<td>0.453</td>
<td>36302792 | Fri Mar 11 21:26:01 CST 2011 | Eastern Time (US &amp; Canada) | RT @peoplemag: Sending love and prayers to everyone affected by the <bold>earthquake</bold> and the <bold>tsunami disaster</bold> in <bold>Japan</bold>…<bold>Hawaii</bold>… Wst coas…</td>
</tr>
<tr>
<td>0.453</td>
<td>36306331 | Fri Mar 11 21:33:41 CST 2011 | Greenland | Thoughts n prayers with all affected my #<bold>earthquake</bold> n #<bold>tsunami</bold>… #<bold>japan</bold> #<bold>hawaii</bold>:(</td>
</tr>
<tr>
<td>0.421</td>
<td>36304157 | Fri Mar 11 21:29:04 CST 2011 | Central Time (US &amp; Canada) | <bold>Earthquake</bold> hit <bold>Japan</bold> and <bold>Hawaii</bold>; <bold>Tsunami</bold> headed toward <bold>Hawaii</bold>. Pray for <bold>Japan</bold> and my home and al the people</td>
</tr>
<tr>
<td>0.421</td>
<td>36304258 | Fri Mar 11 21:29:15 CST 2011 | Eastern Time (US &amp; Canada) | RT @GMA: BREAKING: @AP reporting <bold>tsunami</bold> waves slam <bold>Hawaii</bold>, sweeping through islands after massive <bold>earthquake</bold> in <bold>Japan</bold></td>
</tr>
<tr>
<td>0.364</td>
<td>36306106 | Fri Mar 11 21:33:14 CST 2011 | Bogota | RT @velezcnn: URG #<bold>CNN</bold> #<bold>Japan</bold> #<bold>Japon</bold> #<bold>Tsunami</bold> hitting #<bold>Hawaii</bold> rigth now - #<bold>Tsunami</bold> golpea #<bold>Hawaii</bold> en este <bold>momento</bold></td>
</tr>
<tr>
<td>Bursty word</td>
<td><bold>tsunami</bold>: 0.071463817, <bold>japan</bold>: 0.02848438, <bold>japon</bold>: 0.04315333, <bold>hawaii</bold>: 4.05886315, <bold>earthquake</bold>: 1.756118123,<break/> disaster: 0.62424273</td>
</tr>
<tr>
<td colspan="2"><italic>12 March 2011, 18:14:06</italic></td>
</tr>
<tr>
<td>0.105</td>
<td>36889184 | Sat Mar 12 18:13:45 CST 2011 | London | RT @itv_news: <bold>Japanese</bold> government <bold>confirms</bold> there has been a <bold>radiation leak</bold> after an <bold>explosion</bold> at the <bold>Fukushima</bold> No.1 power plant #<bold>japan</bold> #…</td>
</tr>
<tr>
<td>0.102</td>
<td>36888591 | Sat Mar 12 18:11:38 CST 2011 | Singapore | RT @gingerconejero: Two massive calamities yesterday and a <bold>nuclear plant</bold> explosion today in <bold>Japan</bold>. Please..enough.</td>
</tr>
<tr>
<td>0.102</td>
<td>36886979 | Sat Mar 12 18:05:43 CST 2011 | International Date Line West | RT @paul_steele: Video of the <bold>explosion</bold> at <bold>nuclear plant</bold> in #<bold>Japan</bold>: <ext-link ext-link-type="uri" xlink:href="http://t.co/WinOKcw">http://t.co/WinOKcw</ext-link> liv event page: <ext-link ext-link-type="uri" xlink:href="http://t.co/g9Aoi5r">http://t.co/g9Aoi5r</ext-link> rt @bbcnews</td>
</tr>
<tr>
<td>0.100</td>
<td>36887454 | Sat Mar 12 18:07:24 CST 2011 | Quito | RT @BreakingNews: <bold>Japan nuclear plant</bold> update: Hourly <bold>radiation</bold> leaking from <bold>Fukushima</bold> is equal to amount ermitted in one year, official…</td>
</tr>
<tr>
<td>0.093</td>
<td>36887747 | Sat Mar 12 18:08:26 CST 2011 | Eastern Time (US &amp; Canada) | RT @Reuters: FLASH: #<bold>Japan</bold> chief cabinet secretary Edano: <bold>confirms radiation</bold> leak at <bold>Fukushima plant</bold></td>
</tr>
<tr>
<td>Bursty words</td>
<td><bold>radiation:</bold> 2.303558 × 10<sup>−4</sup>, <bold>nuclear:</bold> 0.04980415, <bold>japan</bold>: 3.13926528, <bold>japanese</bold>: 0.20153408, <bold>fukushima</bold>: 0.00554549, <bold>plant</bold>: 0.233838422</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
</sec>
<sec id="section22-0165551513478738" sec-type="conclusions">
<title>6. Conclusions</title>
<p>In this paper we have developed an online event clustering and topic ranking method for real-time event monitoring using big data collected from Twitter data sets, through a computation of burst detection and clustering algorithms. To the end, the conclusions of this work are listed as follows.</p>
<p>We implemented a set of technical solutions for event detection from microblogging message streams, which integrate an online text-stream clustering method combining a dynamic term weighting scheme, neighbourhood generation algorithm and text stream clustering methods, as well as a topic ranking approach.</p>
<p>The aim of our approach is to establish a comprehensive way to organize real-time event topics, allowing users to quickly find information related to emerging events across the world. Compared with most real-time information search services, our method does not require any form of user query for acquisition of information regarding event development.</p>
<p>Our approach is also designed to cope with the effects of concept drift in the tasks of online topic detection and tracking, especially the design of bursty features for topic shifting in microblogging streams.</p>
<p>The length of each message leads to a problem with the lack of semantic integrality in tweets. This makes it more difficult to design a workable ranking algorithm. In this work, we overcame such a challenge. The preliminary results show that our algorithmic model has the potential for event detection and topic ranking.</p>
<p>With the limitation of memory and other computational resources, the computing of topic ranking avoids calculating entire corpus, and pays more attention to dealing with dynamic text streams.</p>
<p>For business decision making, the techniques developed in this work can be applied to support companies in designing experiments with microblogging big data to obtain the real-time information to explore new business opportunities, and develop appropriate processes to extract business value from social-streaming big data.</p>
</sec>
</body>
<back>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0165551513478738">
<label>1.</label>
<p><ext-link ext-link-type="uri" xlink:href="http://www.google.com/trends">http://www.google.com/trends</ext-link></p>
</fn>
<fn fn-type="other" id="fn2-0165551513478738">
<label>2.</label>
<p><ext-link ext-link-type="uri" xlink:href="https://dev.twitter.com/docs/streaming-api">https://dev.twitter.com/docs/streaming-api</ext-link></p>
</fn>
<fn fn-type="other" id="fn3-0165551513478738">
<label>3.</label>
<p><ext-link ext-link-type="uri" xlink:href="http://twitter4j.org/en/index.html">http://twitter4j.org/en/index.html</ext-link></p>
</fn>
<fn fn-type="other" id="fn4-0165551513478738">
<label>4.</label>
<p>Including Bahasa Indonesia, Danish, Dutch, English, Finnish, French, German, Italian, Norwegian, Polish, Portuguese, Spanish and Turkish.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0165551513478738">
<label>[1]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bughin</surname><given-names>J</given-names></name>
<name><surname>Chui</surname><given-names>M</given-names></name>
<name><surname>Clouds</surname><given-names>Manyika J</given-names></name>
</person-group>. <article-title>Big data, and smart assets: Ten tech-enabled business trends to watch</article-title>. <source>McKinsey Quarterly</source> <year>2010</year>; <volume>4</volume>: <fpage>26</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr2-0165551513478738">
<label>[2]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Otte</surname><given-names>E</given-names></name>
<name><surname>Rousseau</surname><given-names>R</given-names></name>
</person-group>. <article-title>Social network analysis: A powerful strategy, also for the information sciences</article-title>. <source>Information Science</source> <year>2002</year>; <volume>28</volume>: <fpage>441</fpage>–<lpage>453</lpage>.</citation>
</ref>
<ref id="bibr3-0165551513478738">
<label>[3]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ross</surname><given-names>C</given-names></name>
<name><surname>Terras</surname><given-names>M</given-names></name>
<name><surname>Warwick</surname><given-names>C</given-names></name><etal/>
</person-group>. <article-title>Enabled backchannel: Conference Twitter use by digital humanists</article-title>. <source>Journal of Documentation</source> <year>2011</year>; <volume>67</volume>: <fpage>214</fpage>–<lpage>237</lpage>.</citation>
</ref>
<ref id="bibr4-0165551513478738">
<label>[4]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Banerjee</surname><given-names>N</given-names></name>
<name><surname>Chakraborty</surname><given-names>D</given-names></name>
<name><surname>Dasgupta</surname><given-names>K</given-names></name><etal/>
</person-group>. <article-title>User interests in social media sites: An exploration with micro-blogs</article-title>. In: <conf-name>Proceedings of the 18th ACM conference on information and knowledge management</conf-name>, <conf-loc>Hong Kong</conf-loc>, <year>2009</year>.</citation>
</ref>
<ref id="bibr5-0165551513478738">
<label>[5]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Java</surname><given-names>A</given-names></name>
<name><surname>Song</surname><given-names>X</given-names></name>
<name><surname>Finin</surname><given-names>T</given-names></name><etal/>
</person-group>. <article-title>Why we Twitter: Understanding microblogging usage and communities</article-title>. In: <conf-name>Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on web mining and social network analysis</conf-name>, <conf-loc>San Jose, CA</conf-loc>, <year>2007</year>.</citation>
</ref>
<ref id="bibr6-0165551513478738">
<label>[6]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thelwall</surname><given-names>M</given-names></name>
<name><surname>Buckley</surname><given-names>K</given-names></name>
<name><surname>Paltoglou</surname><given-names>G</given-names></name>
</person-group>. <article-title>Sentiment in Twitter events</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <year>2011</year>; <volume>62</volume>: <fpage>406</fpage>–<lpage>418</lpage>.</citation>
</ref>
<ref id="bibr7-0165551513478738">
<label>[7]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jansen</surname><given-names>BJ</given-names></name>
<name><surname>Zhang</surname><given-names>M</given-names></name>
<name><surname>Sobel</surname><given-names>K</given-names></name>
<name><surname>Chowdury</surname><given-names>A</given-names></name>
</person-group>. <article-title>Twitter power: Tweets as electronic word of mouth</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <year>2009</year>; <volume>60</volume>: <fpage>2169</fpage>–<lpage>2188</lpage>.</citation>
</ref>
<ref id="bibr8-0165551513478738">
<label>[8]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Esparza</surname><given-names>SG</given-names></name>
<name><surname>O’Mahony</surname><given-names>MP</given-names></name>
<name><surname>Smyth</surname><given-names>B</given-names></name>
</person-group>. <article-title>On the real-time web as a source of recommendation knowledge</article-title>. In: <conf-name>Proceedings of the fourth ACM conference on recommender systems</conf-name>, <conf-loc>Barcelona</conf-loc>, <year>2010</year>.</citation>
</ref>
<ref id="bibr9-0165551513478738">
<label>[9]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Phelan</surname><given-names>O</given-names></name>
<name><surname>McCarthy</surname><given-names>K</given-names></name>
<name><surname>Smyth</surname><given-names>B</given-names></name>
</person-group>. <article-title>Using Twitter to recommend real-time topical news</article-title>. In: <conf-name>Proceedings of the third ACM Conference on Recommender Systems</conf-name>, <conf-loc>New York</conf-loc>, <year>2009</year>.</citation>
</ref>
<ref id="bibr10-0165551513478738">
<label>[10]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Cheong</surname><given-names>M</given-names></name>
<name><surname>Lee</surname><given-names>V</given-names></name>
</person-group>. <article-title>Integrating web-based intelligence retrieval and decision-making from the Twitter trends knowledge base</article-title>. In: <conf-name>Proceedings of the 2nd ACM workshop on social web search and mining</conf-name>, <conf-loc>Hong Kong</conf-loc>, <year>2009</year>.</citation>
</ref>
<ref id="bibr11-0165551513478738">
<label>[11]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Naaman</surname><given-names>M</given-names></name>
<name><surname>Becker</surname><given-names>H</given-names></name>
<name><surname>Gravano</surname><given-names>L</given-names></name>
</person-group>. <article-title>Hip and trendy: Characterizing emerging trends on Twitter</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <year>2011</year>; <volume>62</volume>: <fpage>902</fpage>–<lpage>918</lpage>.</citation>
</ref>
<ref id="bibr12-0165551513478738">
<label>[12]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Becker</surname><given-names>H</given-names></name>
<name><surname>Naaman</surname><given-names>M</given-names></name>
<name><surname>Gravano</surname><given-names>L</given-names></name>
</person-group>. <article-title>Beyond trending topics: Real-world event identiﬁcation on Twitter</article-title>. In: <conf-name>Proceedings of the fifth international AAAI conference on weblogs and social media</conf-name>, <conf-loc>Barcelona</conf-loc>, <year>2011</year>.</citation>
</ref>
<ref id="bibr13-0165551513478738">
<label>[13]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Becker</surname><given-names>H</given-names></name>
<name><surname>Naaman</surname><given-names>M</given-names></name>
<name><surname>Gravano</surname><given-names>L</given-names></name>
</person-group>. <article-title>Selecting quality Twitter content for events</article-title>. In: <conf-name>Proceedings of the fifth international AAAI conference on weblogs and social media</conf-name>, <conf-loc>Barcelona</conf-loc>, <year>2011</year>.</citation>
</ref>
<ref id="bibr14-0165551513478738">
<label>[14]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Becker</surname><given-names>H</given-names></name>
<name><surname>Chen</surname><given-names>F</given-names></name>
<name><surname>Iter</surname><given-names>D</given-names></name><etal/>
</person-group>. <article-title>Automatic identiﬁcation and presentation of Twitter content for planned events</article-title>. In: <conf-name>Proceedings of the fifth international AAAI conference on weblogs and social media</conf-name>, <conf-loc>Barcelona</conf-loc>, <year>2011</year>.</citation>
</ref>
<ref id="bibr15-0165551513478738">
<label>[15]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Han</surname><given-names>P</given-names></name>
<name><surname>Xie</surname><given-names>X</given-names></name>
<name><surname>Woo</surname><given-names>W</given-names></name>
</person-group>. <article-title>Context-based local hot topic detection for mobile user</article-title>. In: <conf-name>Proceedings of the adjunct pervasive computing conference</conf-name>, <conf-loc>Helsinki</conf-loc>, <year>2010</year>.</citation>
</ref>
<ref id="bibr16-0165551513478738">
<label>[16]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Mathioudakis</surname><given-names>M</given-names></name>
<name><surname>Koudas</surname><given-names>N</given-names></name>
</person-group>. <article-title>TwitterMonitor: Trend detection over the Twitter stream</article-title>. In: <conf-name>Proceedings of the 2010 international conference on management of data</conf-name>, <conf-loc>Indiana</conf-loc>, <year>2010</year>.</citation>
</ref>
<ref id="bibr17-0165551513478738">
<label>[17]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Sankaranarayanan</surname><given-names>J</given-names></name>
<name><surname>Samet</surname><given-names>H</given-names></name>
<name><surname>Teitler</surname><given-names>BE</given-names></name><etal/>
</person-group>. <article-title>TwitterStand: News in Tweets</article-title>. In: <conf-name>Proceedings of the 17th ACM SIGSPATIAL international conference on advances in geographic information systems</conf-name>, <conf-loc>Seattle, WA</conf-loc>, <year>2009</year>.</citation>
</ref>
<ref id="bibr18-0165551513478738">
<label>[18]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Kleinberg</surname><given-names>J</given-names></name>
</person-group>. <article-title>Bursty and hierarchical structure in streams</article-title>. In: <conf-name>Proceedings of the eighth ACM SIGKDD international conference on knowledge discovery and data mining</conf-name>, <conf-loc>Alberta</conf-loc>, <year>2002</year>.</citation>
</ref>
<ref id="bibr19-0165551513478738">
<label>[19]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Swan</surname><given-names>R</given-names></name>
<name><surname>Allan</surname><given-names>J</given-names></name>
</person-group>. <article-title>Extracting significant time varying features from text</article-title>. In: <conf-name>Proceedings of the eighth international conference on information and knowledge management</conf-name>, <conf-loc>Missouri</conf-loc>, <year>1999</year>.</citation>
</ref>
<ref id="bibr20-0165551513478738">
<label>[20]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Swan</surname><given-names>R</given-names></name>
<name><surname>Allan</surname><given-names>J</given-names></name>
</person-group>. <article-title>Automatic generation of overview timelines</article-title>. In: <conf-name>Proceedings of the 23rd annual international ACM SIGIR conference on research and development in information retrieval</conf-name>, <conf-loc>Athens</conf-loc>, <year>2000</year>.</citation>
</ref>
<ref id="bibr21-0165551513478738">
<label>[21]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Swan</surname><given-names>R</given-names></name>
<name><surname>Jensen</surname><given-names>D</given-names></name>
</person-group>. <article-title>TimeMines: Constructing timelines with statistical models of word usage</article-title>. In: <conf-name>Proceedings of the ACM KDD-2000 workshop on text mining</conf-name>, <conf-loc>Massachusetts</conf-loc>, <year>2000</year>.</citation>
</ref>
<ref id="bibr22-0165551513478738">
<label>[22]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kleinberg</surname><given-names>J</given-names></name>
</person-group>. <article-title>Temporal dynamics of on-line information streams</article-title>. In: <source>Proceedings of data stream management: Processing high-speed data streams</source>, <year>2005</year>.</citation>
</ref>
<ref id="bibr23-0165551513478738">
<label>[23]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gaber</surname><given-names>MM</given-names></name>
<name><surname>Zaslavsky</surname><given-names>A</given-names></name>
<name><surname>Krishnaswamy</surname><given-names>S</given-names></name>
</person-group>. <article-title>Mining data streams: A Review</article-title>. <source>SIGMOD Record</source> <year>2005</year>; <volume>34</volume>: <fpage>18</fpage>–<lpage>26</lpage>.</citation>
</ref>
<ref id="bibr24-0165551513478738">
<label>[24]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Guha</surname><given-names>S</given-names></name>
<name><surname>Meyerson</surname><given-names>A</given-names></name>
<name><surname>Mishra</surname><given-names>N</given-names></name><etal/>
</person-group>. <article-title>Clustering data streams: Theory and practice</article-title>. <source>IEEE Transaction on Knowledge and Data Engineering</source> <year>2003</year>; <volume>15</volume>: <fpage>515</fpage>–<lpage>528</lpage>.</citation>
</ref>
<ref id="bibr25-0165551513478738">
<label>[25]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Khalilian</surname><given-names>M</given-names></name>
<name><surname>Mustapha</surname><given-names>N</given-names></name>
</person-group>. <article-title>Data stream clustering: Challenges and issues</article-title>. In: <conf-name>Proceedings of the international multiconference of engineers and computer scientists</conf-name>, <conf-loc>Hong Kong</conf-loc>, <year>2010</year>.</citation>
</ref>
<ref id="bibr26-0165551513478738">
<label>[26]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Aggarwal</surname><given-names>CC</given-names></name>
<name><surname>Han</surname><given-names>J</given-names></name>
<name><surname>Wang</surname><given-names>J</given-names></name><etal/>
</person-group>. <article-title>A framework for clustering evolving data streams</article-title>. In: <conf-name>Proceedings of the 29th international conference on very large data bases</conf-name>, <conf-loc>Berlin</conf-loc>, <year>2003</year>.</citation>
</ref>
<ref id="bibr27-0165551513478738">
<label>[27]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Aggarwal</surname><given-names>CC</given-names></name>
<name><surname>Han</surname><given-names>J</given-names></name>
<name><surname>Wang</surname><given-names>J</given-names></name><etal/>
</person-group>. <article-title>A framework for projected clustering of high dimensional data streams</article-title>. In: <conf-name>Proceedings of the thirtieth international conference on very large data bases</conf-name>, <conf-loc>Toronto</conf-loc>, <year>2004</year>.</citation>
</ref>
<ref id="bibr28-0165551513478738">
<label>[28]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>T</given-names></name>
<name><surname>Ramakrishnan</surname><given-names>R</given-names></name>
<name><surname>Livny</surname><given-names>M</given-names></name>
</person-group>. <article-title>BIRCH: An efficient data clustering method for very large databases</article-title>. <source>SIGMOD Record</source> <year>1996</year>; <volume>25</volume>: <fpage>103</fpage>–<lpage>114</lpage>.</citation>
</ref>
<ref id="bibr29-0165551513478738">
<label>[29]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Zhong</surname><given-names>S</given-names></name>
</person-group>. <article-title>Efficient online spherical <italic>k</italic>-means clustering</article-title>. In: <conf-name>Proceedings of the IEEE international joint conference on neural networks</conf-name>, <conf-loc>Montreal</conf-loc>, <year>2005</year>.</citation>
</ref>
<ref id="bibr30-0165551513478738">
<label>[30]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zhong</surname><given-names>S</given-names></name>
</person-group>. <article-title>Efficient streaming text clustering</article-title>. <source>Neural Networks</source>, <volume>18</volume>(<issue>5–6</issue>) (<year>2005</year>) <fpage>790</fpage>–<lpage>798</lpage>.</citation>
</ref>
<ref id="bibr31-0165551513478738">
<label>[31]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roxy</surname><given-names>P</given-names></name>
<name><surname>Toshniwal</surname><given-names>D</given-names></name>
</person-group>. <article-title>Clustering unstructured text documents using fading function</article-title>. <source>Journal of World Academy of Science, Engineering and Technology</source> <year>2009</year>; <volume>52</volume>: <fpage>149</fpage>–<lpage>156</lpage>.</citation>
</ref>
<ref id="bibr32-0165551513478738">
<label>[32]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Chakrabarti</surname><given-names>D</given-names></name>
<name><surname>Kumar</surname><given-names>R</given-names></name>
<name><surname>Tomkins</surname><given-names>A</given-names></name>
</person-group>. <article-title>Evolutionary clustering</article-title>. In: <conf-name>Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name>, <conf-loc>Philadelphia, PA</conf-loc>, <year>2006</year>.</citation>
</ref>
<ref id="bibr33-0165551513478738">
<label>[33]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ester</surname><given-names>M</given-names></name>
<name><surname>Kriegel</surname><given-names>HP</given-names></name>
<name><surname>Sander</surname><given-names>J</given-names></name><etal/>
</person-group>. <article-title>Incremental clustering for mining in a data warehousing environment</article-title>. In: <conf-name>Proceedings of the 24th international conference on very large databases</conf-name>, <conf-loc>New York</conf-loc>, <year>1998</year>.</citation>
</ref>
<ref id="bibr34-0165551513478738">
<label>[34]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>CH</given-names></name>
<name><surname>Chien</surname><given-names>TF</given-names></name>
<name><surname>Yang</surname><given-names>HC</given-names></name>
</person-group>. <article-title>DBHTE: A novel algorithm for extracting real-time microblogging topics</article-title>. In: <conf-name>Proceedings of the 23rd international conference on computer applications in industry and engineering</conf-name>, <conf-loc>Las Vegas, NV</conf-loc>, <year>2010</year>.</citation>
</ref>
<ref id="bibr35-0165551513478738">
<label>[35]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tsymbal</surname><given-names>A</given-names></name>
</person-group>. <article-title>The problem of concept drift: Definitions and related work</article-title>. Technical report, <publisher-name>Department of Computer Science, Trinity College</publisher-name>, <publisher-loc>Ireland</publisher-loc>, <year>2004</year>.</citation>
</ref>
<ref id="bibr36-0165551513478738">
<label>[36]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Widmer</surname><given-names>G</given-names></name>
<name><surname>Kubat</surname><given-names>M</given-names></name>
</person-group>. <article-title>Learning in the presence of concept drift and hidden contexts</article-title>. <source>Machine Learning</source> <year>1996</year>; <volume>23</volume>: <fpage>69</fpage>–<lpage>101</lpage>.</citation>
</ref>
<ref id="bibr37-0165551513478738">
<label>[37]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>CH</given-names></name>
<name><surname>Chien</surname><given-names>TF</given-names></name>
<name><surname>Yang</surname><given-names>HC</given-names></name>
</person-group>. <article-title>An automatic topic ranking approach for event detection on microblogging messages</article-title>. In: <conf-name>Proceedings of the 2011 IEEE international conference on systems, man, and cybernetics</conf-name>, <conf-loc>Alaska</conf-loc>, <year>2011</year>.</citation>
</ref>
<ref id="bibr38-0165551513478738">
<label>[38]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zhou</surname><given-names>A</given-names></name>
<name><surname>Cao</surname><given-names>F</given-names></name>
<name><surname>Qian</surname><given-names>W</given-names></name><etal/>
</person-group>. <article-title>Tracking clusters in evolving data streams over sliding windows</article-title>. <source>Knowledge Information System</source> <year>2008</year>; <volume>15</volume>: <fpage>181</fpage>–<lpage>214</lpage>.</citation>
</ref>
<ref id="bibr39-0165551513478738">
<label>[39]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>CH</given-names></name>
<name><surname>Wu</surname><given-names>CH</given-names></name>
<name><surname>Chien</surname><given-names>TF</given-names></name>
</person-group>. <article-title>BursT: A dynamic term weighting scheme for mining microblogging messages</article-title>. In: <conf-name>Proceedings of the 8th international symposium on neural networks</conf-name>, <conf-loc>Guilin, China</conf-loc>, <year>2011</year>.</citation>
</ref>
<ref id="bibr40-0165551513478738">
<label>[40]</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>CH</given-names></name>
</person-group>. <article-title>Mining spatio-temporal information on microblogging streams using a density-based online clustering method</article-title>. <source>Expert Systems with Applications</source> <year>2012</year>; <volume>39</volume>: <fpage>9623</fpage>–<lpage>9641</lpage>.</citation>
</ref>
<ref id="bibr41-0165551513478738">
<label>[41]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Aggarwal</surname><given-names>CC</given-names></name>
<name><surname>Yu</surname><given-names>PS</given-names></name>
</person-group>. <article-title>A framework for clustering massive text and categorical data streams</article-title>. In: <conf-name>Proceedings of the ACM SIAM conference on data mining</conf-name>, <conf-loc>Bethesda, MD</conf-loc>, <year>2006</year>.</citation>
</ref>
<ref id="bibr42-0165551513478738">
<label>[42]</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bifet</surname><given-names>A</given-names></name>
</person-group>. <source>Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>IOS Press</publisher-name>, <year>2010</year>.</citation>
</ref>
<ref id="bibr43-0165551513478738">
<label>[43]</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Masud</surname><given-names>MM</given-names></name>
<name><surname>Chen</surname><given-names>Q</given-names></name>
<name><surname>Khan</surname><given-names>L</given-names></name><etal/>
</person-group>. <article-title>Addressing concept-evolution in concept-drifting data streams</article-title>. In: <conf-name>Proceedings of the 2010 IEEE international conference on data mining</conf-name>, <conf-loc>Sydney</conf-loc>, <year>2010</year>.</citation>
</ref>
</ref-list>
</back>
</article>