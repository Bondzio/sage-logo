<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">JHI</journal-id>
<journal-id journal-id-type="hwp">spjhi</journal-id>
<journal-id journal-id-type="nlm-ta">Health Informatics J</journal-id>
<journal-title>Health Informatics Journal</journal-title>
<issn pub-type="ppub">1460-4582</issn>
<issn pub-type="epub">1741-2811</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1460458212437008</article-id>
<article-id pub-id-type="publisher-id">10.1177_1460458212437008</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>How will we know if it’s working? A multi-faceted approach to measuring usability of a specialty-specific electronic medical record</article-title>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Bouamrane</surname><given-names>Matt-Mouley</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Hollin</surname><given-names>Ilene</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Griffin</surname><given-names>Margaret</given-names></name>
<aff id="aff1-1460458212437008">Healthcare Innovation and Technology Lab, USA</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Kachnowski</surname><given-names>Stan</given-names></name>
<aff id="aff2-1460458212437008">Indian Institute of Technology, India Healthcare Innovation and Technology Lab, USA</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-1460458212437008">Ilene Hollin, 3960 Broadway, Room 410, New York, NY 10024, USA. Email: <email>author@hitlab.org</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2012</year>
</pub-date>
<volume>18</volume>
<issue>3</issue>
<issue-title>Special Issue: Independent and Assisted Living Technologies for Healthcare Applications</issue-title>
<fpage>219</fpage>
<lpage>232</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The most effective use of electronic medical records (EMRs) will result from wide-scale adoption and appropriate use of the technology—two factors that rely heavily on a system’s usability. We conducted a qualitative and quantitative usability assessment of an EMR developed specifically for treating the HIV/AIDS patient population. The purpose of this study was to inform developers on how to prioritize resources for their impending software rebuild initiative and to evaluate a dual methodology consisting of both quantitative and qualitative components. The results indicated that the methodology was valid, although there were some variations recommended for future usability assessments of EMRs. The study also underscored the need to assess usability based on user feedback and to employ multiple methods to elicit information; this research revealed many insights into the software that contradicted initial assumptions and also found that asking questions in multiple ways yielded more complete feedback.</p>
</abstract>
<kwd-group>
<kwd>Computer-human interaction</kwd>
<kwd>electronic medical records</kwd>
<kwd>HIV/AIDS</kwd>
<kwd>usability assessment</kwd>
<kwd>user feedback</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1460458212437008" sec-type="intro">
<title>Introduction</title>
<p>In 2009 the USA passed the American Recovery and Reinvestment Act (ARRA), allocating $36 billion for healthcare information technology (HIT). More than half of that was earmarked to spur the adoption of electronic medical records (EMRs),<sup><xref ref-type="bibr" rid="bibr1-1460458212437008">1</xref></sup> with the aims of removing financial barriers, improving patient outcomes and reducing costs of care delivery. However, to attain these goals, an EMR must effectively meet the needs of caregivers and support care processes without substantial workflow interruption. In other words, it must have a high level of usability. Evaluating EMR usability is vital to ensuring it performs as intended and for identifying areas for design improvement and development.</p>
<p>If implementation and design are not properly executed, there is a risk that EMRs will fail for one of two major reasons: EMRs will not be adopted at large or EMRs will be adopted but not properly utilized and will therefore be seen as a wasted investment. The first scenario is the status quo we face today. According to the Healthcare Information and Management Systems Society’s Electronic Health Record Usability Task Force, usability issues are a key reason cited for slower-than-expected EMR adoption rates in the USA.<sup><xref ref-type="bibr" rid="bibr2-1460458212437008">2</xref></sup> The latter scenario is one fear for the future. If EMRs are implemented on a wide scale but not used appropriately or effectively, the large investment would realize too little return—both financially and clinically. Despite the need to understand EMR usability, few vendors conduct formal usability testing during design and development.<sup><xref ref-type="bibr" rid="bibr3-1460458212437008">3</xref></sup></p>
<p>We conducted a qualitative study with some quantitative components to measure and improve the usability of an EMR developed specifically for treating the HIV/AIDS patient population. The object of our study was Lab Tracker, an EMR that was owned and operated by Ground Zero from 1993 until Virco Inc. acquired it in December 2009. Currently, it is used to varying degrees in HIV/AIDS specialty clinics across the USA, but the software will soon undergo a complete overhaul.</p>
<p>There were three main drivers behind the usability assessment of Lab Tracker. First, preliminary feedback from clinics indicated they were not using all of the system’s functionality. This seemed like a necessary point of exploration given that the HIV/AIDS population stands to gain tremendously from an investment in health information technology (HIT). In recent years, HIV has transitioned from an acute disease to a manageable, chronic disease, but still requires substantial attention and tracking of key health indicators by the physician and patient. The emphasis on biomarkers such as CD4 count and viral load make HIV/AIDS particularly suited to benefit from EMR usage, but this made understanding why sites were not using the system to its fullest extent even more confounding.</p>
<p>Second, an impending system rebuild meant that the software’s new owner needed to know where to focus resources. The company anticipated that users were satisfied with the system’s reporting capabilities and was planning to overhaul the graphics and interface. However, as the company found, without confirming their assumptions, developers risk wasting significant resources by altering parts of the system that users feel work well and ignoring the areas that users feel warrant a rebuild.</p>
<p>In addition, despite Lab Tracker’s origination as a tool for physicians to help patients understand and manage their care, it also has evolved as a useful reporting tool at the population level; the EMR aggregates data for government reporting requirements. This is a crucial component of what the HIT investment aims to achieve, as it is only through the analysis of these large-scale data sets that we can begin to identify areas to improve care delivery and quality and reduce costs. The usability assessment provided a crucial opportunity to review this system’s data aggregation capabilities.</p>
<p>Our assessment shed light on the real world usability of the EMR, provided clear directives for the comprehensive redesign and also yielded valuable lessons about the process of conducting a usability assessment itself. This article addresses all three issues.</p>
</sec>
<sec id="section2-1460458212437008" sec-type="methods">
<title>Research methods</title>
<sec id="section3-1460458212437008">
<title>Sample selection</title>
<p>The study involved field research in a purposeful sample of five HIV clinics across five unique US cities. For maximum variation in our sample, we aimed to include at least one clinic from each of five levels of system usage: low, low-mid, mid, mid-high and high. In addition, we selected a wide-ranging sample in terms of location and size; our sample included a geographically diverse group of sites in California, Indiana, Maryland and New York with staff sizes of 2–30 and patient loads of 270–1100 (see <xref ref-type="table" rid="table1-1460458212437008">Table 1</xref> for site demographics). There were no specified exclusion criteria.</p>
<table-wrap id="table1-1460458212437008" position="float">
<label>Table 1.</label>
<caption>
<p>Site demographics</p>
</caption>
<graphic alternate-form-of="table1-1460458212437008" xlink:href="10.1177_1460458212437008-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Clinic</th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
<th align="left">5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Staff size (FTEs)</td>
<td>2 (1.8)</td>
<td>19 (18)</td>
<td>22 (18)</td>
<td>30 (28)</td>
<td>17 (13)</td>
</tr>
<tr>
<td>Patient load</td>
<td>273</td>
<td>760</td>
<td>800</td>
<td>1,100</td>
<td>710</td>
</tr>
<tr>
<td>Patients per provider per day</td>
<td>15</td>
<td>12</td>
<td>12</td>
<td>12</td>
<td>14</td>
</tr>
<tr>
<td>Clinic hours per week</td>
<td>12</td>
<td>40</td>
<td>40</td>
<td>40</td>
<td>16</td>
</tr>
<tr>
<td>Use paper chart</td>
<td>Yes</td>
<td>No</td>
<td>Partial</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Other EHR System</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Lab Tracker user category level</td>
<td>Low</td>
<td>High</td>
<td>High</td>
<td>High</td>
<td>Mid/Low</td>
</tr>
<tr>
<td>Assessment length (in hours)</td>
<td>4</td>
<td>8</td>
<td>8</td>
<td>8</td>
<td>3.5</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1460458212437008">
<p>FTE = Full-Time Equivalent.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>To achieve maximum variation among individual users, we selected a sample to include a range of profile types at each clinic. We defined user type by individual roles (e.g. physician, nurse, analyst, etc.). We aimed to interview five individuals in each user category, as this is the target sample size to uncover most important usability issues.<sup><xref ref-type="bibr" rid="bibr4-1460458212437008">4</xref></sup> Overall, we conducted 43 interviews across staff categories; interview subjects had titles ranging from medical assistant to medical director. The only inclusion criterion for the interviewee was that he/she had to use the EMR system in some capacity, regardless of experience level (see <xref ref-type="table" rid="table2-1460458212437008">Table 2</xref> for a distribution of distinct user types).</p>
<table-wrap id="table2-1460458212437008" position="float">
<label>Table 2.</label>
<caption>
<p>User distribution</p>
</caption>
<graphic alternate-form-of="table2-1460458212437008" xlink:href="10.1177_1460458212437008-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Distinct user types</th>
<th align="left">Users interviewed (percent total)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Administrator/coordinator/managers</td>
<td>6 (13.95%)</td>
</tr>
<tr>
<td>Physician</td>
<td>5 (11.62%)</td>
</tr>
<tr>
<td>Physician assistant and nurse practitioners</td>
<td>5 (11.62%)</td>
</tr>
<tr>
<td>Nurse</td>
<td>5 (11.62%)</td>
</tr>
<tr>
<td>Data analyst/data quality and clinical research specialist</td>
<td>5 (11.62%)</td>
</tr>
<tr>
<td>Health educator/adherence counselor</td>
<td>4 (9.30%)</td>
</tr>
<tr>
<td>Medical assistant</td>
<td>4 (9.30%)</td>
</tr>
<tr>
<td>Case manager</td>
<td>3 (6.98%)</td>
</tr>
<tr>
<td>Social worker</td>
<td>3 (6.98%)</td>
</tr>
<tr>
<td>Admin/program assist</td>
<td>2 (4.35%)</td>
</tr>
<tr>
<td>Pharmacist</td>
<td>1 (2.33%)</td>
</tr>
<tr>
<td><bold>Total</bold></td>
<td><bold>43</bold></td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section4-1460458212437008">
<title>Evaluation tools</title>
<p>We developed a Usability Study Evaluation (USE) Tool to gauge the usability of the EMR in HIV outpatient settings. The main goal of the evaluation was to benchmark user experiences for the legacy system in order to inform decisions about the next generation of the software. It is widely understood that one of the best ways to create systems and products that meet users’ needs is to incorporate direct user feedback throughout the development lifecycle.<sup><xref ref-type="bibr" rid="bibr5-1460458212437008">5</xref>,<xref ref-type="bibr" rid="bibr6-1460458212437008">6</xref></sup></p>
<p>The USE tool was a combination of existing and self-designed instruments, developed specifically with the usability recommendations of the Agency for Healthcare Research and Quality (AHRQ) in mind and tailored in light of the recently released meaningful use guidelines. With a mixed-method, between-subjects design, the tool incorporated a variety of channels to collect data: self-designed semi-structured in-depth interviews (IDIs), a written survey and an online questionnaire.</p>
<p>The IDIs involved a series of open-ended questions to facilitate discussion. For each user participant we asked six background questions (about the user’s role, historical experience with EMRs, usage level and purpose for using the EMR under study) and conducted an IDI of 11 questions about his/her feelings on the EMR (likes, dislikes, value-add to workflow, preferences, thoughts for redesign, etc.). For each site, one staff member was designated as site host—typically an administrator who managed the EMR or worked intimately with the reporting elements of the system. This site host participated in an extended IDI made up of an additional 17 questions designed by the authors, which yielded a description of the clinic as a whole and the clinic’s use of the EMR. It was semi-structured in nature to allow for flexibility, new and follow-up question generation, and freedom to vary the order or context in which questions were answered. A list of IDI questions can be found in <xref ref-type="app" rid="app1-1460458212437008">Appendix A</xref>.</p>
<p>Next, all respondents were given a paper and pencil general software usability survey. We developed the evaluation tool to address eight pertinent categories of usability and design based on the Multiple Heuristics Evaluation Table (MHET) by Wheeler-Atkinson et al.<sup><xref ref-type="bibr" rid="bibr7-1460458212437008">7</xref></sup> The eight categories are: software user interaction, learnability, cognition facilitation, user control and software flexibility, system-real world match, graphic design, navigation and editing, and consistency (although we merged navigation and editing with consistency). The tool included 57 statements that the user scored on a five-point Likert scale from ‘strongly disagree’ to ‘strongly agree’. We incorporated skip-outs for irrelevant statements based on system use and staff role. Some statements were adapted from the Certification Commission for Health Information Technology<sup><xref ref-type="bibr" rid="bibr8-1460458212437008">8</xref></sup> and others were designed by the authors but based on the EMR-specific design principles outlined by AHRQ.<sup><xref ref-type="bibr" rid="bibr9-1460458212437008">9</xref></sup>A list of questions can be found in <xref ref-type="app" rid="app2-1460458212437008">Appendix B</xref>.</p>
<p>Finally, users in our sample were asked to complete an online general software usability questionnaire. We used the Computer System Usability Questionnaire,<sup><xref ref-type="bibr" rid="bibr10-1460458212437008">10</xref></sup> which has 19 statements that the user must score on a seven-point Likert scale from ‘strongly disagree’ to ‘strongly agree’. This was given in addition to the pencil and paper general software usability survey because it could be completed independently and returned via email.</p>
<p>We aimed to concurrently perform a usability assessment using a think-aloud protocol of direct observation of real-world scenarios but, for many of the clinics, this was not feasible. Many clinicians feared that direct observations would not account for Health Insurance Portability and Accountability Act (HIPAA) privacy regulations. In contrast, the survey methodology worked best within the constraints of clinician time and workflow. We found that some approaches that are accepted in theory and the laboratory are not viable in practice and therefore focused on the other activities that were highly effective at obtaining clinician feedback in the field.</p>
</sec>
<sec id="section5-1460458212437008">
<title>Analysis</title>
<p>The authors collected quantitative data from the written and online survey, organized it by site and tabulated and calculated the mean and standard deviation for each statement. Negatively worded questions were reverse coded to match positively worded questions so results could be aggregated. Survey statements with non-neutral (defined as a score other than a three on a five-point scale or a four on a seven-point scale) averages were reported as positive or negative aspects of the EMR.</p>
<p>Authors reviewed and organized qualitative data derived from extensive notes produced during all interviews. Notes were cleaned for irrelevant information, codified and analyzed for usability themes within and across sites.</p>
</sec>
</sec>
<sec id="section6-1460458212437008" sec-type="results">
<title>Results</title>
<sec id="section7-1460458212437008">
<title>Interview subjects and their EMR usage</title>
<p>The users were all relatively experienced with the EMR at the time of the interview; the mean length of time using the system was 3.52 years, with a standard deviation of 2.45 years. Ninety-five percent of users interviewed reported using the EMR all day, every day. Many said it was the first program they initialized upon starting their workday. The majority were using the EMR for clinical data capture (92%) and retrieval (96%), whereas only 31 percent reported using the EMR for running aggregate data reports.</p>
</sec>
<sec id="section8-1460458212437008">
<title>Clinician response</title>
<p>All five hosts filled out the questionnaire and 43 users completed the in-depth interview. All 43 received the written and online surveys, but only 34 users completed the written survey and 24 users completed the online survey. No users completed the think-aloud protocol.</p>
</sec>
<sec id="section9-1460458212437008">
<title>Categories of usability and design</title>
<p>The concepts of usability were organized into manageable and measurable categories. We used Wheeler Atkinson et al.’s eight categories of usability and design,<sup><xref ref-type="bibr" rid="bibr7-1460458212437008">7</xref></sup> but the categories’ designations are secondary to their ability to achieve the specific study aims.<sup><xref ref-type="bibr" rid="bibr9-1460458212437008">9</xref></sup></p>
</sec>
<sec id="section10-1460458212437008">
<title>Overall system usability</title>
<p>Overall, users felt satisfied with the ease of using the EMR system. On a 7-point scale, the average rating for overall satisfaction was 5.5 and simplicity of use was 5.58.</p>
<p>Furthermore, users indicated that the EMR was highly supportive of both their individual tasks (4.66 out of 5) and collaboration between individuals within the clinic (4.45 out of 5). This is indicative of the EMR’s ability to match with the real-world team environment of healthcare.</p>
<sec id="section11-1460458212437008">
<title>Software user interaction</title>
<p>Software user interaction refers to the design characteristics that directly support user-system interaction. To rate user perception of this function, we asked about the display’s intuitiveness, the system’s support for tasks performed by individuals and between individuals (i.e. shared tasks), and relevance of information displayed at proper times. We asked clinicians about how they integrated the system into their workflow. For instance, we collected data on whether or not the system was used during or after the physician-patient encounter and what specific functions were accessed at different points along the encounter. We calculated a mean score for all users across all sites (3.68 out of 5, with a standard deviation of 1.07). In addition, we calculated a score for each site. All sites scored positively with results ranging from 3.37 to 4.16 (see <xref ref-type="table" rid="table3-1460458212437008">Table 3</xref> for the usability scores of individual sites).</p>
<table-wrap id="table3-1460458212437008" position="float">
<label>Table 3.</label>
<caption>
<p>Usability scores</p>
</caption>
<graphic alternate-form-of="table3-1460458212437008" xlink:href="10.1177_1460458212437008-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Sites</th>
<th align="left">Usability score<sup><xref ref-type="table-fn" rid="table-fn2-1460458212437008">a</xref></sup> (standard deviation)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All Sites</td>
<td>3.68 (1.07)</td>
</tr>
<tr>
<td>1</td>
<td>3.86 (0.64)</td>
</tr>
<tr>
<td>2</td>
<td>3.37 (1.17)</td>
</tr>
<tr>
<td>3</td>
<td>4.14 (0.73)</td>
</tr>
<tr>
<td>4</td>
<td>4.16 (0.99)</td>
</tr>
<tr>
<td>5</td>
<td>3.57 (0.84)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1460458212437008">
<label>a</label>
<p>Out of a five-point Likert scale.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>We also asked follow-up questions to understand reasoning behind certain decisions. For example, a physician’s failure to use the system during an encounter may be related to poor software-user interaction, such as difficulty locating needed information. Alternatively, it may be unrelated to the system itself and based on dislike for the placement of the computer in the exam room, for example.</p>
</sec>
<sec id="section12-1460458212437008">
<title>Learnability</title>
<p>Learnability refers to the software’s ability to minimize the learning curve associated with use; it speaks to the system’s intuitiveness. This study asked about the resources required for training, ability to self-learn, rates of ‘quitting’ or avoiding the system because of difficulty and reliance on coworkers for help. Overall, users reported that it was easy to learn the system.</p>
<p>However, there was a discrepancy between the learnability results from the survey and questionnaire and the IDI results. Responses to the statement ‘It was easy to learn this system’ from the online questionnaire resulted in an overall positive average score (5.96 out of 7). Responses to the written survey questions on learnability were neutral-to-positive, but overall indicated that the system was easy to learn, did not require extensive training for everyday use and users rarely needed to ask for help.</p>
<p>However, IDIs shed light on the difference between learnability for data capture/retrieval and for running reports. On one hand, users reported having received little-to-no training on the system and were still able to use the system easily for data capture and retrieval. On the other hand, users reported that it was more difficult to learn how to run reports on aggregate patient data and, as a result, clinics had a designated data analyst responsible for this function.</p>
</sec>
<sec id="section13-1460458212437008">
<title>Cognition facilitation</title>
<p>Cognition facilitation refers to the cognitive load experienced when using the system. Respondents rated how well the display enabled users to interpret information, gauging the organization of information to minimize bouncing back and forth between pages, the accuracy of field and section headings and the appropriate prioritization of data. Results indicated neutral-to-positive attitudes about the EMR’s cognitive facilitation. Most users did not think Lab Tracker was cluttered and could access relevant patient information. However, the IDIs indicated specific instances where the EMR did not align with the order in which users needed to accomplish tasks or did not display information appropriately.</p>
</sec>
<sec id="section14-1460458212437008">
<title>User control and software flexibility</title>
<p>User control and software flexibility refer to the extent that users feel in control of the system and can tailor it to meet their needs. This study asked about the desire for additional free text space, the display’s adaptability to the individual patient and tailor ability. Results indicated neutral-to-negative attitudes about the EMR’s user control and software flexibility. IDIs revealed there is a difference in the level of flexibility desired from administrative users versus clinicians, because they have very different expectations for the system. Clinical users wanted more flexibility to alter fields and make other changes to meet their individual needs. However, users that manage and aggregate data sought tighter control over what other users could do with this system to minimize redundancies and support data integrity. More often, managers and administrators wanted to modify system functionality at the site level. For this reason, it is especially relevant to have a diversified sample of users.</p>
</sec>
<sec id="section15-1460458212437008">
<title>System-real world match</title>
<p>System-real world match indicates whether the EMR accurately and logically represents care delivery in the real world. For instance, is the information presented to naturally align with the expectations and previous knowledge of the user? Is terminology appropriate and are icons consistent with user practices? Study results indicated neutral-to-positive attitudes about the metric. Users agreed that the terminology, units and icons were appropriate. Respondents especially appreciated the specificity with the HIV/AIDS specialty.</p>
</sec>
<sec id="section16-1460458212437008">
<title>Graphic design</title>
<p>Graphic design refers to the color, layout, placement, readability and use of text, numbers and symbols, which all contribute to the user’s ability to accurately interpret and use the interface. Results from the survey and questionnaire indicated a positive attitude about graphic design, but users placed little-to-no emphasis on this category in the IDIs, indicating that it was not a concern.</p>
</sec>
<sec id="section17-1460458212437008">
<title>Navigation, editing and consistency</title>
<p>Wheeler Atkinson et al.<sup><xref ref-type="bibr" rid="bibr7-1460458212437008">7</xref></sup> separate navigation and editing from consistency. Navigation and editing refer to the system’s ability to support the user’s mental model and allow for easy reversal of actions. Consistency relates to uniformity across all screens and functions, which is important for reducing the effort required to navigate the system, locate necessary links and information, and interpret details. We combined these two categories because consistency is such a crucial and significant component of navigation that it cannot be separated. Specifically, we asked about efficiency of the click-through process, accuracy of field labels and consistency of navigational hierarchy. On average, users responded positively when asked whether the site was easy to navigate and overall results indicated a neutral to positive attitude about the editing and consistency. The complete breakdown of mean responses to survey statements by usability and design category can be found in <xref ref-type="table" rid="table4-1460458212437008">Table 4</xref>.</p>
<table-wrap id="table4-1460458212437008" position="float">
<label>Table 4.</label>
<caption>
<p>Mean responses to survey statements by category</p>
</caption>
<graphic alternate-form-of="table4-1460458212437008" xlink:href="10.1177_1460458212437008-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Survey sections</th>
<th align="left">Mean response (standard deviation)<sup><xref ref-type="table-fn" rid="table-fn3-1460458212437008">a</xref></sup></th>
</tr>
</thead>
<tbody>
<tr>
<td>Software user Interactions</td>
<td>3.68 (1.07)</td>
</tr>
<tr>
<td>Learnability</td>
<td>3.37 (1.26)</td>
</tr>
<tr>
<td>Cognitive facilitation</td>
<td>3.53 (0.98)</td>
</tr>
<tr>
<td>User control and software/flexibility</td>
<td>2.94 (1.11)</td>
</tr>
<tr>
<td>System-real world match</td>
<td>3.75 (0.92)</td>
</tr>
<tr>
<td>Graphics</td>
<td>3.83 (0.83)</td>
</tr>
<tr>
<td>Navigation and editing/Consistency</td>
<td>3.55 (0.92)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-1460458212437008">
<label>a</label>
<p>Mean response out of a five-point Likert scale.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="section18-1460458212437008" sec-type="discussion">
<title>Discussion</title>
<sec id="section19-1460458212437008">
<title>Usability assessment methodology</title>
<p>The results outlined above, although specific to the EMR under study and valued for its intrinsic interest, have provided some important lessons about the methodology of a usability assessment.</p>
</sec>
<sec id="section20-1460458212437008">
<title>Quantitative data in conjunction with qualitative data</title>
<p>It is beneficial to leverage mixed methodologies that include complementary quantitative (e.g. surveys and questionnaires) and qualitative components (e.g. IDIs). IDI provides more detail and nuance than quantitative results. For example, when asked about learnability on the surveys, people responded favorably. However, we later realized from our discussions that they were answering the learnability questions based solely on what they do every day, disregarding what they failed to learn. So an individual who only uses the system for data capture and retrieval provided ratings based on those functions only, ignoring the idea that they do not run reports because of learnability issues.</p>
<p>Conversely, the quantitative data provides objective, numerical support for more subjective assessment of the IDIs. This reduces the risk that a few stronger opinions will dominate the analysis. In addition, qualitative data helps spawn new hypotheses and themes.</p>
</sec>
<sec id="section21-1460458212437008">
<title>Directed questions versus open-ended questions</title>
<p>While open-ended questions are preferable to elicit a detailed conversation, in some portions of this study more directed questions may have been useful. For instance, when asked open-ended questions about negative experiences, users often had trouble distinguishing between operator errors, the clinic’s server or IT infrastructure issues and glitches with the EMR system itself—issues that were irrelevant to the design and structure of the EMR.</p>
<p>Additionally, when asked what they would like to see in future versions of the software, many users could not envision what they did not already know to exist. Those users who were more versed in EMR features were able to develop a list of innovative ideas, but from others we simply received nuanced answers about fixing current glitches.</p>
</sec>
<sec id="section22-1460458212437008">
<title>Difficulty assessing ‘live’ conditions</title>
<p>We were unable to complete the walk-through ‘think aloud’ portion of the study for various reasons. First, many users were not comfortable with our exposure to live patient data, despite the fact that we were covered under a HIPAA business service agreement. Therefore, at some sites we did not operate with the EMR on screen and relied on user descriptions. For most sites, however, users demonstrated on dummy data to avoid exposure of personal health information. In some situations, users were able to walk through some simulated tasks with test cases using a think-aloud approach, but often they could not replicate certain glitches and issues with the software.</p>
<p>Second, it proved increasingly difficult to attempt a walk-through without being disruptive to the clinic or an annoyance to the patients. Thus, we had to learn about the integration of the EMR into workflow via conversations in a conference room after a brief clinic tour, instead of observing it first-hand.</p>
</sec>
<sec id="section23-1460458212437008">
<title>Categories of usability and design</title>
<p>Overall, the categories of usability and design were effective, with one exception: user control and software flexibility. Results from the IDIs highlighted the need to emphasize the difference between software flexibility and user control. We treated this as one category and asked questions accordingly. However, distinct types of users understood this category differently. Administrative users, such as data analysts, wanted more control to limit clinical users’ ability to alter the structured fields and to set mandatory fields for users. Clinical users wanted more free space for notes to accompany structured fields.</p>
<p>The category should be divided. User control should refer to the system’s tailorability to meet specific user needs. Software flexibility should refer to the extent users feel it can be tailored to meet the organization’s needs as a whole. Part of the consideration when evaluating software flexibility should assess administrators’ ability to restrict user control.</p>
</sec>
<sec id="section24-1460458212437008">
<title>The EMR: Lessons learned</title>
<p>A specialty EMR must work twice as hard as a more universal, comprehensive EMR. It must provide the full range of functionality, while offering the specialty service that is beyond the customization ability of its comprehensive counterparts. Similarly, it must be an indispensable reporting tool for grants and disease management. Along these lines, a specialty EMR must keep up-to-date with all the reporting requirements to ensure availability of the appropriate and necessary fields.</p>
<p>The in-depth interviews revealed several themes on improvements for future development that can be universally applicable to other disease-specific EMRs.</p>
<list id="list1-1460458212437008" list-type="bullet">
<list-item><p>All users agreed that redundant data entry should be eliminated as much as possible. There was no preference as to whether or not this is done on the back end, by eliminating all repeat fields, or if the fields remain in duplicate but are linked to auto-fill when one field is completed. Similarly, they would like to see auto-filling as much as possible. For instance, if a user enters in a positive reading for a tuberculosis test then ‘latent TB’ should auto-populate as one of the diagnoses.</p></list-item>
<list-item><p>Clinicians wanted to see a clinical research support component of the EMR. An ideal scenario would allow a research coordinator to set parameters by which eligible potential study subjects are identified and then physicians are alerted to their eligibility status and can discuss the subject during a clinic visit.</p></list-item>
<list-item><p>In terms of reporting capabilities, clinicians would like to have an integrated tool that produces graphs or charts for some basic quality indicators in order to eliminate the need to export data to other programs. This would make queries and reports for basic measures more accessible to different users with various computer skill levels. Clinicians’ need for more robust reporting functionality is consistent with the findings across the industry.<sup><xref ref-type="bibr" rid="bibr11-1460458212437008">11</xref></sup></p></list-item>
<list-item><p>Improvements in the reporting and querying capabilities boil down to the EMR’s ability to produce a denominator. For quality improvement purposes, users need to be able to extract a ratio from the data to determine how many patients should have received a particular service versus how many patients actually did, to highlight what hasn’t been done. The current version of the software produces reports about what clinicians have completed, but is less adept at reporting on what hasn’t been done, which is ultimately what is needed.</p></list-item>
<list-item><p>Finally, specialty-specific EMRs will not be operating in isolation for much longer as more institutions bring in electronic charting for their larger patient populations. As a result, facilitating interfaces with institution-wide software will be a key component to the usability of a specialty-specific EMR.</p></list-item>
</list>
</sec>
<sec id="section25-1460458212437008">
<title>Limitations</title>
<p>There were a few limitations to our study. First, we used a purposeful sample somewhat based on clinics’ likely willingness to participate, which may have introduced selection bias. As a result, the users interviewed for this study may be more enthusiastic about the software than the average user.</p>
<p>Second, there were some communication difficulties. Each clinic presented a different environment with which the user expected the software to interact. As assessors, it was imperative for us to understand the complete workflow so that we could evaluate the use of the system within its surroundings. Users were not always clear in communicating the aspects surrounding the software that helped us grasp their exact intentions for using the system in a particular way.</p>
</sec>
</sec>
<sec id="section26-1460458212437008" sec-type="conclusions">
<title>Conclusion</title>
<p>The study showed that the EMR was user-friendly for most day-to-day tasks, such as data capture and retrieval, but needed significant improvement from the standpoint of extracting aggregate data and reporting—functions that are especially important because of the clinics’ reporting requirements for public health funding. In addition, there was a great need for substantial improvement in terms of interoperability with other IT systems, something that will be further complicated as more clinics continue to implement additional IT systems, as well as a trend that is likely generalizable to other specialty-specific records.</p>
<p>These outcomes were valuable because they contradicted the assumptions of the technology vendor going into this project, and may materially change the company’s development strategy. Prior to the study, the vendor was under the impression that the reporting capabilities of the system were in little need of upgrading and they planned to invest in overhauling the graphical user interface. The study showed that, in fact, the opposite was true. Users were pleased with the graphical user interface and identified only a small number of instances where graphic upgrades were needed to address minor workflow and cognitive load issues. However, the assessment revealed that the most important changes would come from updates to the system’s reporting capabilities. This revelation underscores the need to thoroughly examine usability and experience at the user level. Doing so enables the vendor to base business decisions on structured evaluation rather than assumptions, which ultimately lends credibility to investment decisions towards change. Additionally, usability assessments are beneficial for the users themselves because it will ensure that the system will be designed to fit their needs.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-1460458212437008">
<title>Appendix A</title>
<p>The following questions pertained to the clinic as a whole and were directed at our site host. They were asked once per site and designed to be open-ended to let the interviewee share as much information as possible.</p>
<list id="list2-1460458212437008" list-type="order">
<list-item><p>Site name:</p></list-item>
<list-item><p>Total number of staff (stratified by roles: physician, non-physician clinical, non-clinical, person(s) designated for data):</p></list-item>
<list-item><p>What is the turn-over like for staff? Residents in rotation?</p></list-item>
<list-item><p>Active patients:</p></list-item>
<list-item><p>Clinic days per week and hours per day:</p></list-item>
<list-item><p>Number of patients seen per day:</p></list-item>
<list-item><p>Types of services offered:</p></list-item>
<list-item><p>How many of the above have access to the system? Use the system regularly?</p></list-item>
<list-item><p>Do you have any other EMR/EHR system? Which one?</p></list-item>
<list-item><p>Do you have a Practice Management system? Which one? Would you be interested in interfacing the system with PM software?</p></list-item>
<list-item><p>Please describe in detail how the system is used in your clinic.</p></list-item>
<list-item><p>Are additional medical records stored? (Paper, other EMR, etc?)</p></list-item>
<list-item><p>What do you feel is the overall impression of the current version of system from your clinic’s staff?</p></list-item>
<list-item><p>What sort of training/support would you like to see for system users?</p></list-item>
<list-item><p>What are the clinic’s future growth and expansion plans? How could expansion points be factored into the new application to plan for inevitable expansion?</p></list-item>
<list-item><p>Would your clinic be interested in being part of a community?</p></list-item>
<list-item><p>Have you heard of the possibility of federal aid for using an EMR? If so, how familiar are you with the economic stimulus funds available? Are you planning to demonstrate meaningful use and apply for funds?</p></list-item>
</list>
<p>We also asked for a copy of a sample hospital report that came from the system under study.</p>
<p>Questions addressed during one-on-one in-depth interviews with all users.</p>
<list id="list3-1460458212437008" list-type="order">
<list-item><p>What do you like the most about the system?</p></list-item>
<list-item><p>What do you like the least about the system?</p></list-item>
<list-item><p>In a rebuild of the software, if you could change any three things, what would they be?</p></list-item>
<list-item><p>Is there anything that you would hope would not be altered in a software rebuild?</p></list-item>
<list-item><p>Do you consider the system a valuable tool for your work?</p></list-item>
<list-item><p>Does it make you more efficient or does it slow you down? How so?</p></list-item>
<list-item><p>Is the work you do in the system redundant with any other documentation system in the clinic?</p></list-item>
<list-item><p>Would you like to see your clinic increase the extent to which they use the system?</p></list-item>
<list-item><p>What level of flexibility do you expect to have from your EHR?</p></list-item>
<list-item><p>What limitations of the current software are you and your staff working around on a regular basis?</p></list-item>
<list-item><p>How could the new application be designed to remove these limitations?</p></list-item>
</list>
</app>
<app id="app2-1460458212437008">
<title>Appendix B</title>
<p>Each of the following statements was scored on a five-point Likert scale from “strongly disagree” (1) to “strongly agree” (5). There was also an option for “not applicable.” The binary yes/no questions were used to direct users to skip over certain statements that would not apply to their role.</p>
<list id="list4-1460458212437008" list-type="simple">
<list-item><p>A. Software User Interaction</p>
<list id="list5-1460458212437008" list-type="order">
<list-item><p>The display is intuitive.</p></list-item>
<list-item><p>The display supports the collaborative and integrated work process of medical care delivery.</p></list-item>
<list-item><p>The system supports overall integrated care process.</p></list-item>
<list-item><p>The system is a tool that supports my individual tasks.</p></list-item>
<list-item><p>The system supports collaboration between individuals within the clinic.</p></list-item>
<list-item><p>The display facilitates safe, efficient, quality care.</p></list-item>
<list-item><p>The display is action-oriented; it provides a mechanism to act on a decision efficiently.</p></list-item>
<list-item><p>The right information is presented at the right time and place to facilitate decision-making.</p></list-item>
<list-item><p>Displayed data includes the source of the information so I can determine my level of confidence in the data.</p></list-item>
<list-item><p>The display supports privacy and security.</p></list-item>
<list-item><p>The display includes the ability to mask specific data elements.</p></list-item>
<list-item><p>The display includes the ability to alert providers to the fact that the medical record is incomplete.</p></list-item>
<list-item><p>Do you provide clinical care? If yes, go to question 14. If no, skip ahead to question 23.</p></list-item>
<list-item><p>Does the physician use the system during the physician-patient encounter?</p></list-item>
</list>
</list-item>
</list>
<p>If yes answer questions 15-20. If no skip to question 21.</p>
<p>During a physician-patient encounter…</p>
<list id="list6-1460458212437008" list-type="simple">
<list-item><p>15. … the physician consults the system to review a patient’s history or test results.</p></list-item>
<list-item><p>16. … the physician consults the system to identify appropriate treatment plans.</p></list-item>
<list-item><p>17. … the physician consults the system to access knowledge resources.</p></list-item>
<list-item><p>18. … the physician consults other information sources to review a patient’s history or test results.</p></list-item>
<list-item><p>19. … the physician consults other information sources to identify appropriate treatment plans.</p></list-item>
<list-item><p>20. … the physician consults other information sources to access knowledge resources.</p></list-item>
</list>
<p>Skip questions 21-22 and go directly to question 23.</p>
<p>The physician does not use the system during a patient-physician encounter…</p>
<list id="list7-1460458212437008" list-type="simple">
<list-item><p>21. …due to difficulty locating needed information.</p></list-item>
<list-item><p>22. …because he/she has doubt as to the existence of information which will fit his/her specific needs.</p></list-item>
</list>
<list id="list8-1460458212437008" list-type="simple">
<list-item><p>B. Learnability</p>
<list id="list9-1460458212437008" list-type="simple">
<list-item><p>23. Planning/training for the system was resource intensive.</p></list-item>
<list-item><p>24. The system is intuitive. In other words, I can learn the software without being taught.</p></list-item>
<list-item><p>25. I often walk away from using the system when trying to use it because I can’t figure out how to do something.</p></list-item>
<list-item><p>26. I often avoid using the system for a task because I think it will be too difficult to do something.</p></list-item>
<list-item><p>27. I frequently ask other staff how to do something.</p></list-item>
<list-item><p>28. I am frequently asked by other staff how to do something.</p></list-item>
<list-item><p>29. If I don’t know how to do something with the system, I attempt to learn how to do it myself.</p></list-item>
</list>
</list-item>
</list>
<list id="list10-1460458212437008" list-type="simple">
<list-item><p>C. Cognition Facilitation</p>
<list id="list11-1460458212437008" list-type="simple">
<list-item><p>31. The display allows me to interpret multiple pieces of patient information and clinical knowledge.</p></list-item>
<list-item><p>32. I find clusters of needed patient information in one view/page.</p></list-item>
<list-item><p>33. I find that many tasks require a lot of bouncing back and forth.</p></list-item>
<list-item><p>34. The available information is prioritized so I can efficiently locate and act on required information.</p></list-item>
<list-item><p>35. The screen is cluttered.</p></list-item>
<list-item><p>36. Headings for tables and lists accurately describe data.</p></list-item>
</list>
</list-item>
</list>
<list id="list12-1460458212437008" list-type="simple">
<list-item><p>D. User Control and Software Flexibility</p>
<list id="list13-1460458212437008" list-type="simple">
<list-item><p>36. There are fields that I wish had free text available instead of limited choice.</p></list-item>
<list-item><p>37. The EHR reflects the breadth of types of healthcare encounters for HIV patients.</p></list-item>
<list-item><p>38. The display adapts to the individual patient while maintaining a level of consistency.</p></list-item>
<list-item><p>39. It is clear which entry fields are required and which are not.</p></list-item>
<list-item><p>40. I have appropriate flexibility to tailor the system to meet my needs.</p></list-item>
</list>
</list-item>
</list>
<list id="list14-1460458212437008" list-type="simple">
<list-item><p>E. System-Real World Match</p>
<list id="list15-1460458212437008" list-type="simple">
<list-item><p>41. Use of terminology is appropriate.</p></list-item>
<list-item><p>42. Icons and functions logically represent real-world.</p></list-item>
<list-item><p>43. The meaning of icons and symbols is obvious or properly labeled.</p></list-item>
<list-item><p>44. The units (mg, lb) included with information entry fields are appropriate.</p></list-item>
<list-item><p>45. Visual highlighting is used to draw my attention to important information.</p></list-item>
</list>
</list-item>
</list>
<list id="list16-1460458212437008" list-type="simple">
<list-item><p>E. Graphic design</p>
<list id="list17-1460458212437008" list-type="simple">
<list-item><p>46. The text is easily readable and distinguishable from the background.</p></list-item>
<list-item><p>47. The colors are visually appealing.</p></list-item>
<list-item><p>48. The layout and placement of data contributes to my readability.</p></list-item>
</list>
</list-item>
</list>
<list id="list18-1460458212437008" list-type="simple">
<list-item><p>F. Navigation and editing/consistency</p>
<list id="list19-1460458212437008" list-type="simple">
<list-item><p>49. The click through process is efficient.</p></list-item>
<list-item><p>50. Navigating the site is difficult.</p></list-item>
<list-item><p>51. Field labels accurately describe what data needs to be entered.</p></list-item>
<list-item><p>52. Seeing data requires a lot of scrolling and clicking through.</p></list-item>
<list-item><p>53. Seeing data is properly arranged on one screen.</p></list-item>
<list-item><p>54. The system uses a consistent navigational hierarchy so I understand where to find information.</p></list-item>
<list-item><p>55. Critical information is in consistent locations across screens.</p></list-item>
<list-item><p>56. The use of text/numbers/symbols is appropriate and enables me to accurately interpret/use the interface.</p></list-item>
<list-item><p>57. Error messages are clear and explain the reason for the error and suggest actions to correct it.</p></list-item>
</list>
</list-item>
</list>
</app>
</app-group>
<ack>
<p>The authors wish to acknowledge Annie Alley for her assistance in preparing the manuscript.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This study was supported by a grant from Virco Lab, Inc. Virco did not participate in the design, conduct or analysis of the assessment, nor were they involved in the approval of the manuscript for publication.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1460458212437008">
<label>1.</label>
<citation citation-type="gov">
<collab>DesRoches CM and Campbell. Recovery: Track the Money</collab> (<year>2009</year>). Available at: <ext-link ext-link-type="uri" xlink:href="http://www.recovery.gov/Transparency/agency/Pages/AgencyLanding.aspx">http://www.recovery.gov/Transparency/agency/Pages/AgencyLanding.aspx</ext-link> (<access-date>accessed March 18, 2011</access-date>).</citation>
</ref>
<ref id="bibr2-1460458212437008">
<label>2.</label>
<citation citation-type="web">
<collab>HIMSS EHR Usability Task Force. Defining and testing EMR usability: Principles and proposed methods of EMR usability evaluation and rating</collab>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Healthcare Information Management Systems Society</publisher-name> (<year>2009</year>). Available at: <ext-link ext-link-type="uri" xlink:href="http://www.himss.org/content/files/HIMSS_DefiningandTestingEMRUsability.pdf">http://www.himss.org/content/files/HIMSS_DefiningandTestingEMRUsability.pdf</ext-link> (<access-date>accessed September 23, 2010</access-date>).</citation>
</ref>
<ref id="bibr3-1460458212437008">
<label>3.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McDonnell</surname><given-names>C</given-names></name>
<name><surname>Werner</surname><given-names>K</given-names></name>
<name><surname>Wendel</surname><given-names>L</given-names></name>
</person-group>. <article-title>Electronic health record usability: vendor practices and perspectives</article-title>. <publisher-loc>Rockville, MD</publisher-loc>: <publisher-name>Agency for Healthcare Research and Quality;</publisher-name> <year>2010</year> <month>May</month>. Publication No. 09(10)-0091-3-EF.</citation>
</ref>
<ref id="bibr4-1460458212437008">
<label>4.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tullis</surname><given-names>T</given-names></name>
<name><surname>Albert</surname><given-names>B</given-names></name>
</person-group>. <article-title>Measuring the User Experience: collecting, analyzing, and presenting usability metrics</article-title>. <publisher-loc>Burlington, MA</publisher-loc>: <publisher-name>Morgan Kaufmann</publisher-name>, <year>2008</year>.</citation>
</ref>
<ref id="bibr5-1460458212437008">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bruseberg</surname><given-names>A</given-names></name>
<name><surname>McDonagh-Philp</surname><given-names>D</given-names></name>
</person-group> (<year>2001</year>) <article-title>New product development by eliciting user experience and aspirations</article-title>. <source>Int J Hum-Comput St</source> <volume>55</volume>: <fpage>435</fpage>–<lpage>452</lpage>.</citation>
</ref>
<ref id="bibr6-1460458212437008">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gould</surname><given-names>JD</given-names></name>
<name><surname>Lewis</surname><given-names>C</given-names></name>
</person-group> (<year>1985</year>) <article-title>Designing for usability: key principles and what designers think</article-title>. <source>Commun ACM</source> <volume>28</volume>: <fpage>300</fpage>–<lpage>311</lpage>.</citation>
</ref>
<ref id="bibr7-1460458212437008">
<label>7.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wheeler Atkinson</surname><given-names>BF</given-names></name>
<name><surname>Bennett</surname><given-names>TO</given-names></name>
<name><surname>Bahr</surname><given-names>G</given-names></name>
<name><surname>Walwanis Nelson</surname><given-names>MM</given-names></name>
</person-group>. <article-title>Development of a Multiple Heuristics Evaluation Table (MHET) to support software development and usability analysis</article-title>. In: <source>Lecture notes in computer science</source>, <volume>Vol. 4554</volume>, Universal access in human-computer interaction: coping with diversity. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <year>2007</year>, pp. <fpage>563</fpage>–<lpage>572</lpage>.</citation>
</ref>
<ref id="bibr8-1460458212437008">
<label>8.</label>
<citation citation-type="web">
<collab>Certification Commission for Health Information Technology. CCHIT Usability Testing Guide for Comprehensive Ambulatory EHR’s</collab> (<year>2009</year>). Available at: <ext-link ext-link-type="uri" xlink:href="http://www.cchit.org/sites/all/files/CCHIT%20Usability%20Testing%20Guide%20Ambulatory%20EHRs%20v7.pdf">http://www.cchit.org/sites/all/files/CCHIT%20Usability%20Testing%20Guide%20Ambulatory%20EHRs%20v7.pdf</ext-link> (<access-date>accessed March 11, 2010</access-date>)</citation>
</ref>
<ref id="bibr9-1460458212437008">
<label>9.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Armijo</surname><given-names>D</given-names></name>
<name><surname>McDonnell</surname><given-names>C</given-names></name>
<name><surname>Werner</surname><given-names>K</given-names></name>
</person-group>. <article-title>Electronic health record usability: evaluation and use case framework</article-title>. <publisher-loc>Rockville, MD</publisher-loc>: <publisher-name>Agency for Healthcare Research and Quality</publisher-name>, <year>2009</year>. Publication No. 09(10)-0091-1-EF.</citation>
</ref>
<ref id="bibr10-1460458212437008">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lewis</surname><given-names>JR</given-names></name>
</person-group> (<year>1995</year>) <article-title>IBM computer usability satisfaction questionnaires: psychometric evaluation and instructions for use</article-title>. <source>Int J Hum-ComputInt</source> <volume>7</volume>: <fpage>57</fpage>–<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr11-1460458212437008">
<label>11.</label>
<citation citation-type="web">
<collab>American College of Physicians. EHR – based quality measurement &amp; reporting: critical for meaningful use and health care improvement</collab> (<year>2010</year>). Available at: <ext-link ext-link-type="uri" xlink:href="http://www.acponline.org/advocacy/where_we_stand/health_information_technology/ehrs.pdf">http://www.acponline.org/advocacy/where_we_stand/health_information_technology/ehrs.pdf</ext-link> (<access-date>accessed March 20, 2012</access-date>)</citation>
</ref>
</ref-list>
</back>
</article>