<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PIH</journal-id>
<journal-id journal-id-type="hwp">sppih</journal-id>
<journal-title>Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine</journal-title>
<issn pub-type="ppub">0954-4119</issn>
<issn pub-type="epub">2041-6518</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0954411913480669</article-id>
<article-id pub-id-type="publisher-id">10.1177_0954411913480669</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Decision support system for breast cancer detection using mammograms</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Ganesan</surname><given-names>Karthikeyan</given-names></name>
<xref ref-type="aff" rid="aff1-0954411913480669">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Acharya</surname><given-names>Rajendra U</given-names></name>
<xref ref-type="aff" rid="aff1-0954411913480669">1</xref>
<xref ref-type="aff" rid="aff2-0954411913480669">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Chua</surname><given-names>Chua K</given-names></name>
<xref ref-type="aff" rid="aff1-0954411913480669">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Min</surname><given-names>Lim C</given-names></name>
<xref ref-type="aff" rid="aff1-0954411913480669">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Mathew</surname><given-names>Betty</given-names></name>
<xref ref-type="aff" rid="aff3-0954411913480669">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Thomas</surname><given-names>Abraham K</given-names></name>
<xref ref-type="aff" rid="aff3-0954411913480669">3</xref>
</contrib>
</contrib-group>
<aff id="aff1-0954411913480669">
<label>1</label>Department of ECE, Ngee Ann Polytechnic, Singapore, Singapore</aff>
<aff id="aff2-0954411913480669">
<label>2</label>Department of Biomedical Engineering, School of Engineering, University of Malaya, Kuala Lumpur, Malaysia</aff>
<aff id="aff3-0954411913480669">
<label>3</label>SATA CommHealth, Singapore, Singapore</aff>
<author-notes>
<corresp id="corresp1-0954411913480669">Karthikeyan Ganesan, Department of ECE, Ngee Ann Polytechnic, Clementi Road, Singapore 599489, Singapore. Email: <email>g.karthikeya@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>227</volume>
<issue>7</issue>
<fpage>721</fpage>
<lpage>732</lpage>
<history>
<date date-type="received">
<day>24</day>
<month>10</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>1</month>
<year>2013</year>
</date>
</history>
<permissions>
<copyright-statement>© IMechE 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="society">Institution of Mechanical Engineers</copyright-holder>
</permissions>
<abstract>
<p>Mammograms are by far one of the most preferred methods of screening for breast cancer. Early detection of breast cancer can improve survival rates to a greater extent. Although the analysis and diagnosis of breast cancer are done by experienced radiologists, there is always the possibility of human error. Interobserver and intraobserver errors occur frequently in the analysis of medical images, given the high variability between every patient. Also, the sensitivity of mammographic screening varies with image quality and expertise of the radiologist. So, there is no golden standard for the screening process. To offset this variability and to standardize the diagnostic procedures, efforts are being made to develop automated techniques for diagnosis and grading of breast cancer images. This article presents a classification pipeline to improve the accuracy of differentiation between normal, benign, and malignant mammograms. Several features based on higher-order spectra, local binary pattern, Laws’ texture energy, and discrete wavelet transform were extracted from mammograms. Feature selection techniques based on sequential forward, backward, plus-l-takeaway-r, individual, and branch-and-bound selections using the Mahalanobis distance criterion were used to rank the features and find classification accuracies for combination of several features based on the ranking. Six classifiers were used, namely, decision tree classifier, fisher classifier, linear discriminant classifier, nearest mean classifier, Parzen classifier, and support vector machine classifier. We evaluated our proposed methodology with 300 mammograms obtained from the Digital Database for Screening Mammography and 300 mammograms from the Singapore Anti-Tuberculosis Association CommHealth database. Sensitivity, specificity, and accuracy values were used to compare the performances of the classifiers. Our results show that the decision tree classifier demonstrated an excellent performance compared to other classifiers with classification accuracy, sensitivity, and specificity of 91% for the Digital Database for Screening Mammography database and 96.8% for the Singapore Anti-Tuberculosis Association CommHealth database.</p>
</abstract>
<kwd-group>
<kwd>Mammogram</kwd>
<kwd>texture</kwd>
<kwd>feature selection</kwd>
<kwd>classification</kwd>
<kwd>cancer</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0954411913480669" sec-type="intro">
<title>Introduction</title>
<p>Cancer refers to the uncontrolled multiplication of a group of cells in a particular location of the body. A group of rapidly dividing cells may form a lump or mass of extra tissue. These masses are usually referred to as tumors. Cancer cells are termed as malignant tumors. Breast cancer is any form of malignant tumor that develops from breast cells. Important signs to look for in the case of breast cancer are clusters of microcalcifications, masses, and architectural distortions. In recent years, the incidence rate of breast cancer has considerably increased. Simultaneously, breast cancer survival rate has also improved over the past few years with the development of more effective diagnostic techniques and improvements in treatment methodologies.</p>
<p>The American Cancer Society has predicted that about 230,480 new cases of invasive breast cancer and about 57,650 new cases of noninvasive breast cancer will be diagnosed in the United States in 2011, and around 39,520 women will die from breast cancer.<sup><xref ref-type="bibr" rid="bibr1-0954411913480669">1</xref></sup> The most popular diagnostic technique called mammography uses low dose X-ray, high-contrast and high-resolution detectors, and an X-ray system designed specifically for imaging the breasts. Mammography has found its application in both screening and diagnosis of breast cancer. There are two types of mammography systems, film-screen mammography (FSM), wherein the end-recording device is a film screen, and full-field digital mammography (FFDM), which uses digital detectors as the recording media. The digital images provided by FFDM offer many advantages over its film counterpart in terms of ease of image processing and enhancement.<sup><xref ref-type="bibr" rid="bibr2-0954411913480669">2</xref><xref ref-type="bibr" rid="bibr3-0954411913480669"/>–<xref ref-type="bibr" rid="bibr4-0954411913480669">4</xref></sup></p>
<p>In spite of the use of ionizing radiation that may turn out to be potentially harmful on repeated use and its lower sensitivity in detecting cancers in dense breasts, mammography is still the most recommended examination for breast cancer screening and detection.<sup><xref ref-type="bibr" rid="bibr5-0954411913480669">5</xref></sup> Early and more accurate detection of breast cancer not only improves the survival rate but also avoids unnecessary biopsies. Studies show that mammography can be used for early detection and treatment of breast lesions.<sup><xref ref-type="bibr" rid="bibr6-0954411913480669">6</xref><xref ref-type="bibr" rid="bibr7-0954411913480669"/>–<xref ref-type="bibr" rid="bibr8-0954411913480669">8</xref></sup> However, interpretation of mammograms is a subjective process, and hence, interobserver variability is common. Therefore, computer-aided diagnostic (CAD) tools are being developed and studied in order to assist the radiologists in relatively better objective interpretation of mammograms. The application of classifiers in medical diagnosis is increasing gradually. There is no doubt that evaluation of data taken from patients and decisions of medical experts are the most important factors in diagnosis.</p>
<p>Classification systems<sup><xref ref-type="bibr" rid="bibr9-0954411913480669">9</xref></sup> can help in minimizing possible errors and also can provide instant examination of medical data in shorter time and in a more detailed manner. CAD systems combine a variety of techniques from the fields of artificial intelligence and digital image processing along with the domain knowledge from the medical experts to support cancer detection. CAD software help radiologists better detect masses and microcalcifications in mammograms, and hence can improve the accuracy of mammography and also reduce the subjectivity associated with the manual interpretation process. In CAD software, the mammograms are first enhanced using standard image enhancement methods mainly to sharpen the boundaries of the region of interest (ROI) and to increase the contrast between the ROI and the nearby normal tissue. The ROIs are then segmented through common statistical, region-based, or morphological approaches, and significant features are extracted for subsequent clustering or classification. Reviews on CAD tools and techniques for microcalcification and mass detection can be found in the studies by Cheng et al.<sup><xref ref-type="bibr" rid="bibr10-0954411913480669">10</xref>,<xref ref-type="bibr" rid="bibr11-0954411913480669">11</xref></sup> and Elter and Horsch.<sup><xref ref-type="bibr" rid="bibr12-0954411913480669">12</xref></sup></p>
<p>In 2009, Sadaf et al.<sup><xref ref-type="bibr" rid="bibr13-0954411913480669">13</xref></sup> studied the performance of FFDM augmented with CAD tools. The study showed that CAD combined with mammography presented 100% sensitivity in identifying cancers manifesting as microcalcifications only and 86% sensitivity for other mammographic appearances of cancer. In another recent study by Karssemeijer et al.,<sup><xref ref-type="bibr" rid="bibr14-0954411913480669">14</xref></sup> FFDM using CAD was compared with FSM in a population-based breast cancer screening program. They found that the detection rate with FFDM–CAD was as good as that with FSM, with FFDM–CAD providing better detection of ductal carcinoma in situ and microcalcification clusters. They also found that the recall rate of FFDM–CAD was higher. Thus, CAD in mammography shows great promise in being used as an adjunct tool for early breast cancer detection.</p>
<p>In the current study, a classification framework involving a set of features based on local binary pattern (LBP), Laws’ texture energy (LTE), discrete wavelet transform (DWT), and higher-order spectra (HOS) has been used. The best combination of features was studied using three different feature selection techniques based on forward selection, backward selection, and individual selection using the Mahalanobis distance. The best classifier among six classifiers including decision tree (DT) classifier, fisher classifier, linear discriminant classifier (LDC), nearest mean classifier (NMC), Parzen classifier, and support vector machine (SVM) classifier was selected based on the classification accuracy.</p>
</sec>
<sec id="section2-0954411913480669" sec-type="materials|methods">
<title>Materials and methods</title>
<p>Three hundred mammograms from the Digital Database for Screening Mammography (DDSM)<sup><xref ref-type="bibr" rid="bibr15-0954411913480669">15</xref>,<xref ref-type="bibr" rid="bibr16-0954411913480669">16</xref></sup> were used for evaluating the proposed classification framework. The DDSM database contains approximately 2620 mammogram images of normal, benign, and malignant classes in 43 volumes. Four medical institutions from the United States have contributed to the DDSM database: Massachusetts General Hospital (MGH), Wake Forest University School of Medicine (WFUSM), Sacred Heart Hospital (SHH), and Washington University in St Louis (WU). Along with the digitized mammograms, the DDSM contains “boundary” files of the abnormalities. The outlines (thumbnails) of the abnormalities as indicated by a radiologist are stored in “chain code” in these files. Using this “chain code,” borders of the abnormalities can be reconstructed. In this study, we have used 100 normal and 100 malignant images from MGH and 100 benign images from SHH. The original image file is very large because the films were scanned with a resolution between 42 and 100 µm manually. These images were cropped to leave out any dark space and to extract only the breast area, and then the images were resized to 512 × 512. Apart from working on these images, we also tested our framework on 125 mammograms provided by Singapore Anti-Tuberculosis Association (SATA) CommHealth, Singapore. Sample mammograms taken from normal, benign, and cancerous breasts are depicted in <xref ref-type="fig" rid="fig1-0954411913480669">Figure 1</xref>. All the mammograms used in the study were collected from subjects between the ages of 40–70 years with the majority of images lying in the age group of 40–65 years. In this study, the main focus was identifying textural changes occurring in mammograms of cancerous breasts, rather than their pathological identifications. Hence, feature extraction techniques focussing on textural changes were used to study the images.</p>
<fig id="fig1-0954411913480669" position="float">
<label>Figure 1.</label>
<caption>
<p>Sample mammograms: (a and b) normal, (c and d) benign, and (d and e) malignant.</p>
</caption>
<graphic xlink:href="10.1177_0954411913480669-fig1.tif"/>
</fig>
<sec id="section3-0954411913480669">
<title>Feature extraction</title>
<p>In this section, we briefly describe the features, namely, HOS, LBP, Laws’ mask energy (LME), and DWT that were extracted from the normal, benign, and malignant images.</p>
<sec id="section4-0954411913480669">
<title>HOS-based features</title>
<p>The gray scale images shown in <xref ref-type="fig" rid="fig1-0954411913480669">Figure 1</xref> are first subjected to the Radon transform to convert the image into one-dimensional (1D) data, and then they are subjected to HOS analysis to extract the relevant bispectral features. HOS techniques are used in different fields such as economics, speech, seismic data processing, plasma physics, and optics.<sup><xref ref-type="bibr" rid="bibr17-0954411913480669">17</xref></sup> Second-order statistics deal with the <inline-formula id="inline-formula1-0954411913480669">
<mml:math display="inline" id="math1-0954411913480669">
<mml:mrow>
<mml:mi>mean</mml:mi>
</mml:mrow>
</mml:math></inline-formula> value <inline-formula id="inline-formula2-0954411913480669">
<mml:math display="inline" id="math2-0954411913480669">
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:math></inline-formula> and variance <inline-formula id="inline-formula3-0954411913480669">
<mml:math display="inline" id="math3-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>. They are defined by expectation operation as follows</p>
<p>
<disp-formula id="disp-formula1-0954411913480669">
<label>(1)</label>
<mml:math display="block" id="math4-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0954411913480669" xlink:href="10.1177_0954411913480669-eq1.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula2-0954411913480669">
<label>(2)</label>
<mml:math display="block" id="math5-0954411913480669">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>A</mml:mi>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0954411913480669" xlink:href="10.1177_0954411913480669-eq2.tif"/>
</disp-formula>
</p>
<p>where “<italic>a</italic>” is the result of a random process.</p>
<p>If “<italic>a</italic>” is the discrete-time signal, the second-order moment autocorrelation function is defined as</p>
<p>
<disp-formula id="disp-formula3-0954411913480669">
<label>(3)</label>
<mml:math display="block" id="math6-0954411913480669">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>a</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0954411913480669" xlink:href="10.1177_0954411913480669-eq3.tif"/>
</disp-formula>
</p>
<p>In addition to these moments, HOS provide higher-order moments <inline-formula id="inline-formula4-0954411913480669">
<mml:math display="inline" id="math7-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo><mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> and nonlinear combinations of the higher-order moments called cumulants <inline-formula id="inline-formula5-0954411913480669">
<mml:math display="inline" id="math8-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo><mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>. Thus, HOS consist of moment and cumulant spectra and can be defined for both deterministic signals and random processes.<sup><xref ref-type="bibr" rid="bibr18-0954411913480669">18</xref></sup> In this study, we have used third-order statistics of the signal called “<italic>bispectrum</italic>.” It is the Fourier transform of the third-order correlation of the data and is given by</p>
<p>
<disp-formula id="disp-formula4-0954411913480669">
<label>(4)</label>
<mml:math display="block" id="math9-0954411913480669">
<mml:mrow>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0954411913480669" xlink:href="10.1177_0954411913480669-eq4.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula6-0954411913480669">
<mml:math display="inline" id="math10-0954411913480669">
<mml:mrow>
<mml:mi>A</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>f</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> is the Fourier transform of the signal <inline-formula id="inline-formula7-0954411913480669">
<mml:math display="inline" id="math11-0954411913480669">
<mml:mrow>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>nT</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula8-0954411913480669">
<mml:math display="inline" id="math12-0954411913480669">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mo>·</mml:mo>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula> is an average over an ensemble of realizations of a random signal. For deterministic signals, the relationship holds without an expectation operation with the third-order correlation being a time-average. For deterministic sampled signals, <inline-formula id="inline-formula9-0954411913480669">
<mml:math display="inline" id="math13-0954411913480669">
<mml:mrow>
<mml:mi>A</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>f</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> is the discrete-time Fourier transform, and in practice, is computed using the fast Fourier transform (FFT) algorithm. The frequency “<italic>f</italic>” may be normalized by the Nyquist frequency to be between 0 and 1 (<xref ref-type="fig" rid="fig2-0954411913480669">Figure 2</xref>).</p>
<fig id="fig2-0954411913480669" position="float">
<label>Figure 2.</label>
<caption>
<p>Nonredundant region of computation of the bispectrum for real signals. Features are calculated by integrating the bispectrum along the dashed line with slope “<italic>a</italic>.” Frequencies are normalized by the Nyquist frequency.</p>
</caption>
<graphic xlink:href="10.1177_0954411913480669-fig2.tif"/>
</fig>
<p>The features used in our study are based on the phases of the integrated bispectrum<sup><xref ref-type="bibr" rid="bibr19-0954411913480669">19</xref></sup> and are described briefly in the following: assuming that there is no bispectral aliasing, the bispectrum of a real signal is uniquely defined with the triangle <inline-formula id="inline-formula10-0954411913480669">
<mml:math display="inline" id="math14-0954411913480669">
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>≤</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>≤</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>≤</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>≤</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math></inline-formula>. Parameters are obtained by integrating along the straight lines passing through the origin in bifrequency space. The region of computation and the line of integration are depicted in <xref ref-type="fig" rid="fig3-0954411913480669">Figure 3</xref>. The bispectral invariant, <inline-formula id="inline-formula11-0954411913480669">
<mml:math display="inline" id="math15-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, is the phase of the integrated bispectrum along the radial line with the slope equal to “<italic>a</italic>.” This is defined by</p>
<p>
<disp-formula id="disp-formula5-0954411913480669">
<label>(5)</label>
<mml:math display="block" id="math16-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mi>arctan</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0954411913480669" xlink:href="10.1177_0954411913480669-eq5.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula6-0954411913480669">
<label>(6)</label>
<mml:math display="block" id="math17-0954411913480669">
<mml:mrow>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mi>j</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∫</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>a</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:munderover>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mi>a</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>d</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0954411913480669" xlink:href="10.1177_0954411913480669-eq6.tif"/>
</disp-formula>
</p>
<p>for <inline-formula id="inline-formula12-0954411913480669">
<mml:math display="inline" id="math18-0954411913480669">
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>&lt;</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo>≤</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula13-0954411913480669">
<mml:math display="inline" id="math19-0954411913480669">
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math></inline-formula>. The variables <inline-formula id="inline-formula14-0954411913480669">
<mml:math display="inline" id="math20-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>r</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula15-0954411913480669">
<mml:math display="inline" id="math21-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> refer to the real and imaginary parts of the integrated bispectrum, respectively.</p>
<fig id="fig3-0954411913480669" position="float">
<label>Figure 3.</label>
<caption>
<p>Circularly symmetric neighbor sets for different <italic>P</italic> and <italic>R</italic>.<sup><xref ref-type="bibr" rid="bibr20-0954411913480669">20</xref></sup></p>
</caption>
<graphic xlink:href="10.1177_0954411913480669-fig3.tif"/>
</fig>
<p>It has been shown that these bispectral invariants, <inline-formula id="inline-formula16-0954411913480669">
<mml:math display="inline" id="math22-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, contain information about the shape of the waveform within the window and are invariant to shift and amplification and robust to time-scale changes.<sup><xref ref-type="bibr" rid="bibr19-0954411913480669">19</xref></sup> They are particularly sensitive to changes in the left–right asymmetry of the waveform. For windowed segments of a white Gaussian random process, these features will tend to be distributed symmetrically and uniformly about zero in the interval <inline-formula id="inline-formula17-0954411913480669">
<mml:math display="inline" id="math23-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">[</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>π</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>π</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula>. If the process is chaotic and exhibits a colored spectrum with third-order time-correlations or phase coupling between Fourier components, the mean value and the distribution of the invariant feature may be used to identify the process. By changing the value of the slope <inline-formula id="inline-formula18-0954411913480669">
<mml:math display="inline" id="math24-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, one can obtain different sets of <inline-formula id="inline-formula19-0954411913480669">
<mml:math display="inline" id="math25-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> to train a classifier. In this study, we derived the mean magnitude of the spectrum <inline-formula id="inline-formula20-0954411913480669">
<mml:math display="inline" id="math26-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ave</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, bispectral phase entropy <inline-formula id="inline-formula21-0954411913480669">
<mml:math display="inline" id="math27-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ePRes</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, entropy 1 <inline-formula id="inline-formula22-0954411913480669">
<mml:math display="inline" id="math28-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, entropy 2 <inline-formula id="inline-formula23-0954411913480669">
<mml:math display="inline" id="math29-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, and entropy 3 <inline-formula id="inline-formula24-0954411913480669">
<mml:math display="inline" id="math30-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>. The two entropies<sup><xref ref-type="bibr" rid="bibr21-0954411913480669">21</xref></sup> are similar to spectral entropy.<sup><xref ref-type="bibr" rid="bibr22-0954411913480669">22</xref></sup> The equations for determining the mean of magnitude and phase entropy for HOS are given as follows<sup><xref ref-type="bibr" rid="bibr23-0954411913480669">23</xref></sup></p>
<p>
<disp-formula id="disp-formula7-0954411913480669">
<label>(7)</label>
<mml:math display="block" id="math31-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ave</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0954411913480669" xlink:href="10.1177_0954411913480669-eq7.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula8-0954411913480669">
<label>(8)</label>
<mml:math display="block" id="math32-0954411913480669">
<mml:mrow>
<mml:mi>ePRes</mml:mi>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mi>p</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ψ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mi>logp</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ψ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0954411913480669" xlink:href="10.1177_0954411913480669-eq8.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula9-0954411913480669">
<label>(9)</label>
<mml:math display="block" id="math33-0954411913480669">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ψ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mi>l</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>ϕ</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>∈</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ψ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0954411913480669" xlink:href="10.1177_0954411913480669-eq9.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula10-0954411913480669">
<label>(10)</label>
<mml:math display="block" id="math34-0954411913480669">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>ψ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">{</mml:mo>
<mml:mi>ϕ</mml:mi>
<mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>π</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:mi>π</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>≤</mml:mo>
<mml:mi>ϕ</mml:mi>
<mml:mo>&lt;</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>π</mml:mi>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mo>+</mml:mo>
<mml:mn>2</mml:mn>
<mml:mi>π</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">}</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="left" columnspan="1">
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0954411913480669" xlink:href="10.1177_0954411913480669-eq10.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula25-0954411913480669">
<mml:math display="inline" id="math35-0954411913480669">
<mml:mrow>
<mml:mi>L</mml:mi>
</mml:mrow>
</mml:math></inline-formula> is the number of points within the region <inline-formula id="inline-formula26-0954411913480669">
<mml:math display="inline" id="math36-0954411913480669">
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula27-0954411913480669">
<mml:math display="inline" id="math37-0954411913480669">
<mml:mrow>
<mml:mi>ϕ</mml:mi>
</mml:mrow>
</mml:math></inline-formula> is the phase angle of the bispectrum, and <inline-formula id="inline-formula28-0954411913480669">
<mml:math display="inline" id="math38-0954411913480669">
<mml:mrow>
<mml:mi>l</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>·</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> is an indicator function that gives a value of 1 when the phase angle is within the range bin <inline-formula id="inline-formula29-0954411913480669">
<mml:math display="inline" id="math39-0954411913480669">
<mml:mrow>
<mml:mi>ψ</mml:mi>
</mml:mrow>
</mml:math></inline-formula> depicted in <xref ref-type="disp-formula" rid="disp-formula8-0954411913480669">equation (8)</xref>. Bispectrum entropies are defined as</p>
<p>
<disp-formula id="disp-formula11-0954411913480669">
<label>(11)</label>
<mml:math display="block" id="math40-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>log</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0954411913480669" xlink:href="10.1177_0954411913480669-eq11.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula12-0954411913480669">
<label>(12)</label>
<mml:math display="block" id="math41-0954411913480669">
<mml:mrow>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0954411913480669" xlink:href="10.1177_0954411913480669-eq12.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula13-0954411913480669">
<label>(13)</label>
<mml:math display="block" id="math42-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>log</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula13-0954411913480669" xlink:href="10.1177_0954411913480669-eq13.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula14-0954411913480669">
<mml:math display="block" id="math43-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>q</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula14-0954411913480669" xlink:href="10.1177_0954411913480669-eq14.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula15-0954411913480669">
<label>(14)</label>
<mml:math display="block" id="math44-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>r</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mi>log</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>r</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula15-0954411913480669" xlink:href="10.1177_0954411913480669-eq15.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula16-0954411913480669">
<label>(15)</label>
<mml:math display="block" id="math45-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>r</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>Ω</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula16-0954411913480669" xlink:href="10.1177_0954411913480669-eq16.tif"/>
</disp-formula>
</p>
<p>
<?h4?>In this study, we extracted the above described five bispectrum invariants for each Radon-transformed normal, benign, and malignant images. Then, clinically significant parameters among them were chosen for classifier training.</p>
</sec>
<sec id="section5-0954411913480669">
<title>LBP</title>
<p>LBP<sup><xref ref-type="bibr" rid="bibr24-0954411913480669">24</xref></sup> is a simple and fast method for multiscale local texture analysis. The spatial structure information is combined with contrast, which is a measure of the amount of local texture. Texture analysis has been carried out using LBP on normal, benign, and malignant images. To calculate LBP, consider a circular neighborhood around a pixel. <inline-formula id="inline-formula30-0954411913480669">
<mml:math display="inline" id="math46-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:math></inline-formula> points are chosen on the circumference of the circle with radius <inline-formula id="inline-formula31-0954411913480669">
<mml:math display="inline" id="math47-0954411913480669">
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:math></inline-formula> such that they are all equidistant from the center pixel. The gray values at points on the circular neighborhood that do not coincide exactly with pixel locations are estimated by interpolation. Let <inline-formula id="inline-formula32-0954411913480669">
<mml:math display="inline" id="math48-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> be the gray value of the center pixel, and <inline-formula id="inline-formula33-0954411913480669">
<mml:math display="inline" id="math49-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula34-0954411913480669">
<mml:math display="inline" id="math50-0954411913480669">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo><mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>P</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math></inline-formula>, corresponds to the gray values of the <inline-formula id="inline-formula35-0954411913480669">
<mml:math display="inline" id="math51-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:math></inline-formula> points. These <inline-formula id="inline-formula36-0954411913480669">
<mml:math display="inline" id="math52-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:math></inline-formula> points are converted into a circular bit-stream of 0s and 1s according to whether the gray value of the pixel is less than or greater than the gray value of the center pixel. <xref ref-type="fig" rid="fig4-0954411913480669">Figure 4</xref> depicts circularly symmetric neighbor sets for different values of <inline-formula id="inline-formula37-0954411913480669">
<mml:math display="inline" id="math53-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula38-0954411913480669">
<mml:math display="inline" id="math54-0954411913480669">
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:math></inline-formula>.</p>
<fig id="fig4-0954411913480669" position="float">
<label>Figure 4.</label>
<caption>
<p>Spread of the feature vectors for DDSM database.</p>
</caption>
<graphic xlink:href="10.1177_0954411913480669-fig4.tif"/>
</fig>
<p>Ojala et al.<sup><xref ref-type="bibr" rid="bibr20-0954411913480669">20</xref></sup> introduced the concept of uniformity in texture analysis.<sup><xref ref-type="bibr" rid="bibr20-0954411913480669">20</xref></sup> They did so by classifying each pixel as uniform or nonuniform and used the uniform pixels for further computation of texture descriptor. These “uniform” fundamental patterns have a uniform circular structure that contains very few spatial transitions <inline-formula id="inline-formula39-0954411913480669">
<mml:math display="inline" id="math55-0954411913480669">
<mml:mrow>
<mml:mi>U</mml:mi>
</mml:mrow>
</mml:math></inline-formula> (number of spatial bitwise <inline-formula id="inline-formula40-0954411913480669">
<mml:math display="inline" id="math56-0954411913480669">
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:math></inline-formula> transitions), and thus, function as templates for microstructures such as bright spot <inline-formula id="inline-formula41-0954411913480669">
<mml:math display="inline" id="math57-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, flat area or dark spot <inline-formula id="inline-formula42-0954411913480669">
<mml:math display="inline" id="math58-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>8</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, and edges of varying positive and negative curvature (<italic>U</italic> = 1–7). Therefore, a rotation invariant measure called <inline-formula id="inline-formula43-0954411913480669">
<mml:math display="inline" id="math59-0954411913480669">
<mml:mrow>
<mml:mi>LB</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> using uniformity measure <inline-formula id="inline-formula44-0954411913480669">
<mml:math display="inline" id="math60-0954411913480669">
<mml:mrow>
<mml:mi>U</mml:mi>
</mml:mrow>
</mml:math></inline-formula> is calculated based on the number of transitions in the neighborhood pattern. Only patterns with <inline-formula id="inline-formula45-0954411913480669">
<mml:math display="inline" id="math61-0954411913480669">
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo>≤</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:math></inline-formula> are assigned the LBP code as depicted in <xref ref-type="disp-formula" rid="disp-formula15-0954411913480669">equation (15)</xref>, that is, if the number of bit-transitions in the circular bit-stream is less than or equal to 2, the center pixel is labeled as uniform. A lookup table is generally used to compute the bit-transitions to reduce computational complexity</p>
<p>
<disp-formula id="disp-formula17-0954411913480669">
<label>(16)</label>
<mml:math display="block" id="math62-0954411913480669">
<mml:mrow>
<mml:mi>LB</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mi>s</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
<mml:mrow>
<mml:mtext>if</mml:mtext>
</mml:mrow>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>≤</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mtext>otherwise</mml:mtext>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula17-0954411913480669" xlink:href="10.1177_0954411913480669-eq17.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula18-0954411913480669">
<label>(17)</label>
<mml:math display="block" id="math63-0954411913480669">
<mml:mrow>
<mml:mi>s</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>x</mml:mi>
<mml:mo>≥</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>x</mml:mi>
<mml:mo>&lt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula18-0954411913480669" xlink:href="10.1177_0954411913480669-eq18.tif"/>
</disp-formula>
</p>
<p>
<?h4?>Rotation invariance is achieved by rotating the neighbor set clockwise such that maximal number of most significant bits is zero in the LBP code</p>
<p>
<disp-formula id="disp-formula19-0954411913480669">
<label>(18)</label>
<mml:math display="block" id="math64-0954411913480669">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>LBP</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ri</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mi>min</mml:mi>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mrow>
<mml:mi>ROR</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>LB</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>P</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula19-0954411913480669" xlink:href="10.1177_0954411913480669-eq19.tif"/>
</disp-formula>
</p>
<p>
<?h4?>To improve the discrimination power of <inline-formula id="inline-formula46-0954411913480669">
<mml:math display="inline" id="math65-0954411913480669">
<mml:mrow>
<mml:mi>LB</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ri</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula47-0954411913480669">
<mml:math display="inline" id="math66-0954411913480669">
<mml:mrow>
<mml:mi>LB</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>riu</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math></inline-formula> using a uniformity measure <inline-formula id="inline-formula48-0954411913480669">
<mml:math display="inline" id="math67-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>U</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> is calculated based on the number of transitions in the neighborhood pattern. Only patterns with <inline-formula id="inline-formula49-0954411913480669">
<mml:math display="inline" id="math68-0954411913480669">
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo>≤</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:math></inline-formula> are assigned the LBP code</p>
<p>
<disp-formula id="disp-formula20-0954411913480669">
<label>(19)</label>
<mml:math display="block" id="math69-0954411913480669">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>LBP</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>riu</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mi>s</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>c</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center">
<mml:mrow>
<mml:mrow>
<mml:mtext>if</mml:mtext>
</mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mi>U</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>LB</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd columnalign="center" columnspan="1">
<mml:mrow>
<mml:mtext>otherwise</mml:mtext>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula20-0954411913480669" xlink:href="10.1177_0954411913480669-eq20.tif"/>
</disp-formula>
</p>
<p>
<?h4?>To include the local image texture contrast, we define a rotation invariant measure of local variance given by</p>
<p>
<disp-formula id="disp-formula21-0954411913480669">
<label>(20)</label>
<mml:math display="block" id="math70-0954411913480669">
<mml:mrow>
<mml:mi>VA</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mi>μ</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula21-0954411913480669" xlink:href="10.1177_0954411913480669-eq21.tif"/>
</disp-formula>
</p>
<p>where</p>
<p>
<disp-formula id="disp-formula22-0954411913480669">
<label>(21)</label>
<mml:math display="block" id="math71-0954411913480669">
<mml:mrow>
<mml:mi>μ</mml:mi>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>p</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula22-0954411913480669" xlink:href="10.1177_0954411913480669-eq22.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The <inline-formula id="inline-formula50-0954411913480669">
<mml:math display="inline" id="math72-0954411913480669">
<mml:mrow>
<mml:mi>LB</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>riu</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math></inline-formula> code and local contrast values <inline-formula id="inline-formula51-0954411913480669">
<mml:math display="inline" id="math73-0954411913480669">
<mml:mrow>
<mml:mi>VA</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>R</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> are computed for three radius values: <inline-formula id="inline-formula52-0954411913480669">
<mml:math display="inline" id="math74-0954411913480669">
<mml:mrow>
<mml:mi>R</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mrow>
<mml:mtext>and</mml:mtext>
</mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math></inline-formula> with the corresponding pixel count <inline-formula id="inline-formula53-0954411913480669">
<mml:math display="inline" id="math75-0954411913480669">
<mml:mrow>
<mml:mi>P</mml:mi>
</mml:mrow>
</mml:math></inline-formula> being 8, 16, and 24, respectively. The mean and variance of each of the LBP output image are calculated that is combined with the mean local contrast of the image to yield nine features corresponding to each pixel of the mammogram images.</p>
</sec>
<sec id="section6-0954411913480669">
<title>LTE</title>
<p>Laws’ mask has evolved with the idea of representing image features without referring to the frequency domain.<sup><xref ref-type="bibr" rid="bibr25-0954411913480669">25</xref></sup> The idea of inferring as what looks like where, instead of the conventional what happens where, is the essence of using this approach as a conjunction to the human visual perception.<sup><xref ref-type="bibr" rid="bibr26-0954411913480669">26</xref></sup> Laws empirically determined that several masks of appropriate sizes were very informative for discriminating between different kinds of texture.<sup><xref ref-type="bibr" rid="bibr27-0954411913480669">27</xref></sup> Originally, he classified samples based on expected values of variance-like square measures of these convolutions, called texture energy measures.<sup><xref ref-type="bibr" rid="bibr27-0954411913480669">27</xref></sup> The method is based on texture energy transforms applied to the image to estimate the energy within the pass region of filters.<sup><xref ref-type="bibr" rid="bibr27-0954411913480669">27</xref></sup> All the masks were derived from 1D vectors: <inline-formula id="inline-formula54-0954411913480669">
<mml:math display="inline" id="math76-0954411913480669">
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">[</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">[</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mrow>
<mml:mtext>and</mml:mtext>
</mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">[</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula> that describe the following features: level, edge, and spot, respectively. By convolving any vertical 1D vector with a horizontal one, 9 two-dimensional (2D) masks <inline-formula id="inline-formula55-0954411913480669">
<mml:math display="inline" id="math77-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mrow>
<mml:mtext>and</mml:mtext>
</mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mi>S</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> were generated. All these 2D masks, except <inline-formula id="inline-formula56-0954411913480669">
<mml:math display="inline" id="math78-0954411913480669">
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math></inline-formula>, have zero mean. In this study, we used eight zero-sum masks numbered 1–8. To extract texture information from an image <inline-formula id="inline-formula57-0954411913480669">
<mml:math display="inline" id="math79-0954411913480669">
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, the image is convolved with each 2D mask. For example, the texture image <inline-formula id="inline-formula58-0954411913480669">
<mml:math display="inline" id="math80-0954411913480669">
<mml:mrow>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> is obtained by convolving the image with <inline-formula id="inline-formula59-0954411913480669">
<mml:math display="inline" id="math81-0954411913480669">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math></inline-formula></p>
<p>
<disp-formula id="disp-formula23-0954411913480669">
<label>(22)</label>
<mml:math display="block" id="math82-0954411913480669">
<mml:mrow>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>×</mml:mo>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula23-0954411913480669" xlink:href="10.1177_0954411913480669-eq23.tif"/>
</disp-formula>
</p>
<p>
<?h4?>To make the resultant images contrast independent, the texture image <inline-formula id="inline-formula60-0954411913480669">
<mml:math display="inline" id="math83-0954411913480669">
<mml:mrow>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> was used to normalize the contrast of all other texture images, as shown in <xref ref-type="disp-formula" rid="disp-formula23-0954411913480669">equation (23)</xref></p>
<p>
<disp-formula id="disp-formula24-0954411913480669">
<label>(23)</label>
<mml:math display="block" id="math84-0954411913480669">
<mml:mrow>
<mml:mi>Normalize</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>mask</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>TI</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>mask</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mn>3</mml:mn>
<mml:mi>L</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula24-0954411913480669" xlink:href="10.1177_0954411913480669-eq24.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The resultant normalized <italic>TI</italic>s were filtered using texture energy measurement (TEM) filters that were made up of a moving nonlinear window average of absolute values</p>
<p>
<disp-formula id="disp-formula25-0954411913480669">
<label>(24)</label>
<mml:math display="block" id="math85-0954411913480669">
<mml:mrow>
<mml:mi>TE</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>u</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>v</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:munderover>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>T</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>I</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>v</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula25-0954411913480669" xlink:href="10.1177_0954411913480669-eq25.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The image under inspection is filtered using these eight masks, and their energies are computed and used as the feature descriptors.</p>
</sec>
<sec id="section7-0954411913480669">
<title>DWT-based features</title>
<p>In this study, we used 2D DWT and averaging algorithms for feature extraction.<sup><xref ref-type="bibr" rid="bibr28-0954411913480669">28</xref>,<xref ref-type="bibr" rid="bibr29-0954411913480669">29</xref></sup> The DWT transform of a signal <italic>x</italic> is evaluated by sending it through a sequence of down-sampling high-pass and low-pass filters. The low-pass filter is defined by the transfer function <inline-formula id="inline-formula61-0954411913480669">
<mml:math display="inline" id="math86-0954411913480669">
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, and the high-pass filter is defined by the transfer function <inline-formula id="inline-formula62-0954411913480669">
<mml:math display="inline" id="math87-0954411913480669">
<mml:mrow>
<mml:mi>h</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula>. The output of the high-pass filter <inline-formula id="inline-formula63-0954411913480669">
<mml:math display="inline" id="math88-0954411913480669">
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula> is known as the detail coefficients. The following equation shows how these coefficients are obtained</p>
<p>
<disp-formula id="disp-formula26-0954411913480669">
<label>(25)</label>
<mml:math display="block" id="math89-0954411913480669">
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>∞</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>∞</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mi>x</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mi>h</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mn>2</mml:mn>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula26-0954411913480669" xlink:href="10.1177_0954411913480669-eq26.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The output of the low-pass filter is known as the approximation coefficients. These coefficients are found as</p>
<p>
<disp-formula id="disp-formula27-0954411913480669">
<label>(26)</label>
<mml:math display="block" id="math90-0954411913480669">
<mml:mrow>
<mml:mi>A</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>∞</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>∞</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:mi>x</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mi>g</mml:mi>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mn>2</mml:mn>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula27-0954411913480669" xlink:href="10.1177_0954411913480669-eq27.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The frequency resolution is further increased by cascading the two basic filter operations. To be specific, the output of the first-level low-pass filter is fed into the same low-pass and high-pass filter combinations. The detailed coefficients are output at each level, and they form the level coefficients. In general, each level halves the sample number and doubles the frequency resolution. Consequently, in the final level, both detail and approximation coefficients are obtained as level coefficients. For 2D signals, the 2D DWT can be used. Our discussion focuses on wavelet packets (WPs) for images. These images are represented as an <inline-formula id="inline-formula64-0954411913480669">
<mml:math display="inline" id="math91-0954411913480669">
<mml:mrow>
<mml:mi>m</mml:mi>
<mml:mo>×</mml:mo>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:math></inline-formula> gray scale matrix <inline-formula id="inline-formula65-0954411913480669">
<mml:math display="inline" id="math92-0954411913480669">
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula> where each element of the matrix represents the intensity of one pixel. All nonborder pixels in <inline-formula id="inline-formula66-0954411913480669">
<mml:math display="inline" id="math93-0954411913480669">
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, where <inline-formula id="inline-formula67-0954411913480669">
<mml:math display="inline" id="math94-0954411913480669">
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mo stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>m</mml:mi>
<mml:mo stretchy="false">}</mml:mo>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula68-0954411913480669">
<mml:math display="inline" id="math95-0954411913480669">
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>∈</mml:mo>
<mml:mo stretchy="false">{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">}</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, have eight immediate neighboring pixels. These eight neighbors can be used to traverse through the matrix. However, changing the direction with which the matrix is traversed just inverts the sequence of pixels, and the 2D DWT coefficients are the same. For example, the WP result is the same when the matrix is traversed from left to right as from right to left. Therefore, we are left with four possible directions, which are known as decomposition corresponding to <inline-formula id="inline-formula69-0954411913480669">
<mml:math display="inline" id="math96-0954411913480669">
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>∘</mml:mo>
</mml:mrow>
</mml:math></inline-formula> (horizontal, <inline-formula id="inline-formula70-0954411913480669">
<mml:math display="inline" id="math97-0954411913480669">
<mml:mrow>
<mml:mi>Dh</mml:mi>
</mml:mrow>
</mml:math></inline-formula>), <inline-formula id="inline-formula71-0954411913480669">
<mml:math display="inline" id="math98-0954411913480669">
<mml:mrow>
<mml:mn>90</mml:mn>
<mml:mo>∘</mml:mo>
</mml:mrow>
</mml:math></inline-formula> (vertical, <inline-formula id="inline-formula72-0954411913480669">
<mml:math display="inline" id="math99-0954411913480669">
<mml:mrow>
<mml:mi>Dv</mml:mi>
</mml:mrow>
</mml:math></inline-formula>), and <inline-formula id="inline-formula73-0954411913480669">
<mml:math display="inline" id="math100-0954411913480669">
<mml:mrow>
<mml:mn>45</mml:mn>
<mml:mo>∘</mml:mo>
</mml:mrow>
</mml:math></inline-formula> or <inline-formula id="inline-formula74-0954411913480669">
<mml:math display="inline" id="math101-0954411913480669">
<mml:mrow>
<mml:mn>135</mml:mn>
<mml:mo>∘</mml:mo>
</mml:mrow>
</mml:math></inline-formula> (diagonal, <inline-formula id="inline-formula75-0954411913480669">
<mml:math display="inline" id="math102-0954411913480669">
<mml:mrow>
<mml:mi>Dd</mml:mi>
</mml:mrow>
</mml:math></inline-formula>) orientations.</p>
<p>In this study, we have evaluated 54 wavelet functions. Each of these wavelet functions has both a unique low-pass filter transfer function <inline-formula id="inline-formula76-0954411913480669">
<mml:math display="inline" id="math103-0954411913480669">
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula> and a unique high-pass filter transfer function <inline-formula id="inline-formula77-0954411913480669">
<mml:math display="inline" id="math104-0954411913480669">
<mml:mrow>
<mml:mi>h</mml:mi>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math></inline-formula>. Among these 54 wavelet functions, Biorthogonal 3.1 <inline-formula id="inline-formula78-0954411913480669">
<mml:math display="inline" id="math105-0954411913480669">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>bior</mml:mi>
<mml:mn>3</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> performed well. Biorthogonal wavelet is a wavelet where the associated wavelet transform is invertible but not necessarily orthogonal. Biorthogonal wavelets allow more degrees of freedoms than orthogonal wavelets. The first-level 2D DWT yields four result matrices, namely <inline-formula id="inline-formula79-0954411913480669">
<mml:math display="inline" id="math106-0954411913480669">
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula80-0954411913480669">
<mml:math display="inline" id="math107-0954411913480669">
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>v</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula81-0954411913480669">
<mml:math display="inline" id="math108-0954411913480669">
<mml:mrow>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, and <inline-formula id="inline-formula82-0954411913480669">
<mml:math display="inline" id="math109-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, whose elements are intensity values. These matrixes cannot be used for classification directly, because the number of elements is too high. Therefore, we defined two averaging methods that represent result matrixes with just one number. The first method is used to extract average measures from 2D DWT result vectors</p>
<p>
<disp-formula id="disp-formula28-0954411913480669">
<label>(27)</label>
<mml:math display="block" id="math110-0954411913480669">
<mml:mrow>
<mml:mi>Average</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Ah</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
<mml:mo>×</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munder>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula28-0954411913480669" xlink:href="10.1177_0954411913480669-eq28.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula29-0954411913480669">
<label>(28)</label>
<mml:math display="block" id="math111-0954411913480669">
<mml:mrow>
<mml:mi>Average</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>v</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Av</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
<mml:mo>×</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munder>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>v</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula29-0954411913480669" xlink:href="10.1177_0954411913480669-eq29.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula30-0954411913480669">
<label>(29)</label>
<mml:math display="block" id="math112-0954411913480669">
<mml:mrow>
<mml:mi>Average</mml:mi>
<mml:mspace width="0.25em"/>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Ad</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
<mml:mo>×</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munder>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:munder>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula30-0954411913480669" xlink:href="10.1177_0954411913480669-eq30.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The final averaging method uses averages and not the intensity values as such; it averages the energy of the intensity values</p>
<p>
<disp-formula id="disp-formula31-0954411913480669">
<label>(30)</label>
<mml:math display="block" id="math113-0954411913480669">
<mml:mrow>
<mml:mi>Energy</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Ed</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>×</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munder>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula31-0954411913480669" xlink:href="10.1177_0954411913480669-eq31.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula32-0954411913480669">
<label>(31)</label>
<mml:math display="block" id="math114-0954411913480669">
<mml:mrow>
<mml:mi>Energy</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>Ev</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>×</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>M</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munder>
<mml:munder>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>y</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>M</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msup>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>D</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>v</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula32-0954411913480669" xlink:href="10.1177_0954411913480669-eq32.tif"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="section8-0954411913480669">
<title>Feature selection</title>
<p>Class separability measures are used to estimate the best feature sets for a classification problem. It is necessary to carefully choose features since the choice of features is critical in the final accuracy. For a given set of features with dimensionality <inline-formula id="inline-formula83-0954411913480669">
<mml:math display="inline" id="math115-0954411913480669">
<mml:mrow>
<mml:mi>d</mml:mi>
</mml:mrow>
</mml:math></inline-formula> and desired number of features <inline-formula id="inline-formula84-0954411913480669">
<mml:math display="inline" id="math116-0954411913480669">
<mml:mrow>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, every possible subset of the feature vectors can be studied individually in the best individual feature method of feature selection. This is an exhaustive search algorithm and can produce an optimal subset of features. But, this would take a tremendous amount of computational complexity to complete it. As a result, suboptimal selection techniques that have a balanced trade-off between optimality and computational efficiency have been proposed and developed. This can be done in both bottom-up and top-down approaches. In this study, both the approaches were studied along with best-p (individual) feature selection technique, branch-and-bound techniques, and plus-l-takeaway-r technique.</p>
<p>When several features are selected, the correlation between the features is studied, and features with heavy overlap are ranked lower in the feature vector. If <inline-formula id="inline-formula85-0954411913480669">
<mml:math display="inline" id="math117-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>nk</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> is the <italic>k</italic>th feature of the <italic>n</italic>th pattern, with <italic>n</italic> = 1, 2, …, <italic>N</italic> and <italic>k</italic> = 1, 2, …, <italic>m</italic>, the cross correlation between any two of them is given by</p>
<p>
<disp-formula id="disp-formula33-0954411913480669">
<label>(32)</label>
<mml:math display="block" id="math118-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ij</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ni</mml:mi>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>nj</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ni</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:munderover>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>N</mml:mi>
</mml:mrow>
</mml:munderover>
<mml:msubsup>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>nj</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula33-0954411913480669" xlink:href="10.1177_0954411913480669-eq33.tif"/>
</disp-formula>
</p>
<p>
<?h4?>The feature selection procedure is carried out by selecting a class separability criterion <italic>C</italic> and computing its value for all available features <inline-formula id="inline-formula86-0954411913480669">
<mml:math display="inline" id="math119-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula87-0954411913480669">
<mml:math display="inline" id="math120-0954411913480669">
<mml:mrow>
<mml:mi>k</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo><mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>m</mml:mi>
</mml:mrow>
</mml:math></inline-formula>. The <inline-formula id="inline-formula88-0954411913480669">
<mml:math display="inline" id="math121-0954411913480669">
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
</mml:math></inline-formula> value is then ranked in descending order. The one with the best <inline-formula id="inline-formula89-0954411913480669">
<mml:math display="inline" id="math122-0954411913480669">
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
</mml:math></inline-formula> value is named as <inline-formula id="inline-formula90-0954411913480669">
<mml:math display="inline" id="math123-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>. The cross-correlation coefficient between <inline-formula id="inline-formula91-0954411913480669">
<mml:math display="inline" id="math124-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> and the remaining features as in <xref ref-type="disp-formula" rid="disp-formula31-0954411913480669">equation (31)</xref> is calculated to select the second best feature. The feature <inline-formula id="inline-formula92-0954411913480669">
<mml:math display="inline" id="math125-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> for which <inline-formula id="inline-formula93-0954411913480669">
<mml:math display="inline" id="math126-0954411913480669">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>arg</mml:mi>
<mml:mspace width="0.25em"/>
<mml:munder>
<mml:mrow>
<mml:mi>max</mml:mi>
<mml:mo stretchy="false">{</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mi>C</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>j</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>α</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">|</mml:mo>
<mml:mo stretchy="false">}</mml:mo>
</mml:mrow>
</mml:math></inline-formula>, for all <inline-formula id="inline-formula94-0954411913480669">
<mml:math display="inline" id="math127-0954411913480669">
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mo>≠</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>, is calculated to find the next best feature, and the procedure is carried on further for all values of <inline-formula id="inline-formula95-0954411913480669">
<mml:math display="inline" id="math128-0954411913480669">
<mml:mrow>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:math></inline-formula> to rank the best features. From this ranked list of features, the required number of features is then chosen. For studying the separability and distance, the Mahalanobis distance measure was used.</p>
<p>We used a total of 103 features with 29 LBP + LTE features, 4 DWT features, and 70 HOS features. Feature ranking and selection were done on this set of 103 features.</p>
</sec>
<sec id="section9-0954411913480669">
<title>Classifiers</title>
<sec id="section10-0954411913480669">
<title>SVM</title>
<p>The SVM<sup><xref ref-type="bibr" rid="bibr30-0954411913480669">30</xref></sup> classifier uses data from two classes to determine a maximum margin hyperplane between the two classes. The hyperplane is determined in such a way that the distance from this hyperplane to the nearest data points on each side, called the support vectors, is maximal. SVM classifiers can be extended to nonlinearly separable data with the help of kernel function application on the data to make them linearly separable.<sup><xref ref-type="bibr" rid="bibr31-0954411913480669">31</xref></sup> In this study, we have used linear kernel, polynomial kernel of orders 1–3, and the radial basis function (RBF) kernel.</p>
</sec>
<sec id="section11-0954411913480669">
<title>NMC</title>
<p>NMC is quite similar to the nearest neighbor (NN) classifier. In this classifier, a group of data is classified into the class of the nearest training sample in the dataset according to a Euclidean distance measure.<sup><xref ref-type="bibr" rid="bibr32-0954411913480669">32</xref></sup> The Euclidean distance from each class mean is computed to classify the data into different classes. Once the Euclidean distance is computed to calculate the distance to each class mean, the dataset in consideration is classified into the class with a minimum Euclidean distance.</p>
</sec>
<sec id="section12-0954411913480669">
<title>LDC</title>
<p>The LDC refers to the technique in which a transformation is performed such that it maximizes between-class separability and minimizes within-class variability. LDC tries to discriminate the input data by dimensionality reduction. LDC searches for the best projection to project the input data on a lower dimensional space where the patterns are discriminated to the maximum extent.<sup><xref ref-type="bibr" rid="bibr32-0954411913480669">32</xref></sup> A linear separability measure is utilized in this classifier and hence is not suitable for datasets with a varied and highly nonuniform scattering, which are difficult to classify using a linear classifier.</p>
</sec>
<sec id="section13-0954411913480669">
<title>NMC</title>
<p>The NMC is quite similar to the NN algorithm. In the NMC, after a classification system is trained with training data, test data are fed into the classifier, and classification is done according to the class of the nearest training sample in the data space according to the Euclidean distance from each class mean.<sup><xref ref-type="bibr" rid="bibr32-0954411913480669">32</xref></sup></p>
</sec>
<sec id="section14-0954411913480669">
<title>Parzen classifier</title>
<p>Parzen classifier works on a nonparametric kernel density estimation method to estimate the probability density function of the classes involved. A smoothing parameter is considered to vary the size of the bins, and a probability density estimate is found depending on the peaks of the data in consideration. This technique also uses the <italic>k</italic>-NN rule to gauge the size of the windows <inline-formula id="inline-formula96-0954411913480669">
<mml:math display="inline" id="math129-0954411913480669">
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:math></inline-formula>.<sup><xref ref-type="bibr" rid="bibr32-0954411913480669">32</xref></sup></p>
</sec>
<sec id="section15-0954411913480669">
<title>DTs</title>
<p>In a DT classifier, a set of rules for the different classes are derived from the tree that is constructed using the input features from the training data.<sup><xref ref-type="bibr" rid="bibr33-0954411913480669">33</xref></sup> These rules are used to predict the class of the test data.</p>
</sec>
</sec>
</sec>
<sec id="section16-0954411913480669" sec-type="results">
<title>Results</title>
<p>The features selected using the techniques described in previous sections were passed through a feature selection routine to rank the features. Feature selection was done using a <italic>bottom-up</italic> or a <italic>top-down</italic> approach, best-p (<inline-formula id="inline-formula97-0954411913480669">
<mml:math display="inline" id="math130-0954411913480669">
<mml:mrow>
<mml:mi>individual</mml:mi>
</mml:mrow>
</mml:math></inline-formula>) feature selection technique, branch-and-bound technique and plus-l-takeaway-r technique. After ranking the features, five classifiers including SVM, NMC, LDC, NMC, and DT were used to study the classification accuracy, sensitivity, and specificity of the classifiers. Ranking of the features produces different accuracy results as seen from the accuracy tables. <italic>k</italic>-fold cross validation (10-fold) was done for studying the classification accuracies, and the mean of accuracies obtained from the 10-fold were calculated to be the accuracy for the classification algorithms. For this study, we used the open-source DDSM database to benchmark our classification framework. To cross-check the robustness of our algorithm, we used a different set of data from SATA CommHealth, Singapore. This dataset was processed, and the image resolution and properties were made to match with the DDSM benchmark database.</p>
<p>Five feature selection methods were used in this study: <inline-formula id="inline-formula98-0954411913480669">
<mml:math display="inline" id="math131-0954411913480669">
<mml:mrow>
<mml:mi>forward</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, <inline-formula id="inline-formula99-0954411913480669">
<mml:math display="inline" id="math132-0954411913480669">
<mml:mrow>
<mml:mi>backward</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, <italic>plus-l-takeaway-r</italic>, <inline-formula id="inline-formula100-0954411913480669">
<mml:math display="inline" id="math133-0954411913480669">
<mml:mrow>
<mml:mi>individual</mml:mi>
</mml:mrow>
</mml:math></inline-formula>, and <italic>branch-and-bound</italic> procedures. All these feature selection methods were used in combination with six classifiers as discussed in the previous section. <xref ref-type="table" rid="table1-0954411913480669">Tables 1</xref> and <xref ref-type="table" rid="table2-0954411913480669">2</xref> provide the classification accuracy for DDSM and SATA CommHealth database, respectively.</p>
<table-wrap id="table1-0954411913480669" position="float">
<label>Table 1.</label>
<caption>
<p>Classification results for the DDSM database.</p>
</caption>
<graphic alternate-form-of="table1-0954411913480669" xlink:href="10.1177_0954411913480669-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Classification technique</th>
<th align="left" colspan="2">LBP + LTE<hr/></th>
<th align="left" colspan="2">LBP + LTE + DWT<hr/></th>
<th align="left" colspan="2">LBP + LTE + DWT + HOS<hr/></th>
</tr>
<tr>
<th/>
<th align="left">Number of features (%)</th>
<th align="left">Accuracy (%)</th>
<th align="left">Number of features (%)</th>
<th align="left">Accuracy (%)</th>
<th align="left">Number of features (%)</th>
<th align="left">Accuracy (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fisher classifier</td>
<td>6</td>
<td>23.33</td>
<td>6</td>
<td>53.30</td>
<td>2</td>
<td>20</td>
</tr>
<tr>
<td>Linear discriminant classifier</td>
<td>22</td>
<td>64.33</td>
<td>10</td>
<td>26.67</td>
<td>6</td>
<td>66.67</td>
</tr>
<tr>
<td>Nearest mean classifier</td>
<td>4</td>
<td>61.32</td>
<td>10</td>
<td>31.66</td>
<td>8</td>
<td>76.67</td>
</tr>
<tr>
<td>Parzen classifier</td>
<td>13</td>
<td>52.27</td>
<td>15</td>
<td>41.67</td>
<td>7</td>
<td>66.67</td>
</tr>
<tr>
<td>Decision tree</td>
<td>20</td>
<td>81</td>
<td>25</td>
<td>57.87</td>
<td>34</td>
<td>91.6</td>
</tr>
<tr>
<td>SVM</td>
<td>5</td>
<td>33.33</td>
<td>9</td>
<td>58.33</td>
<td>14</td>
<td>66.67</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0954411913480669">
<p>LBP: local binary pattern; LTE: Laws’ texture energy; DWT: discrete wavelet transform; HOS: higher-order spectra; SVM: support vector machine.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table2-0954411913480669" position="float">
<label>Table 2.</label>
<caption>
<p>Classification results for the SATA CommHealth database.</p>
</caption>
<graphic alternate-form-of="table2-0954411913480669" xlink:href="10.1177_0954411913480669-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Classification technique</th>
<th align="left" colspan="2">LBP + LTE<hr/></th>
<th align="left" colspan="2">LBP + LTE + DWT<hr/></th>
<th align="left" colspan="2">LBP + LTE + DWT + HOS<hr/></th>
</tr>
<tr>
<th/>
<th align="left">Number of eatures (%)</th>
<th align="left">Accuracy (%)</th>
<th align="left">Number of features (%)</th>
<th align="left">Accuracy (%)</th>
<th align="left">Number of eatures (%)</th>
<th align="left">Accuracy (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fisher classifier</td>
<td>22</td>
<td>75</td>
<td>2</td>
<td>60</td>
<td>4</td>
<td>75</td>
</tr>
<tr>
<td>Linear discriminant classifier</td>
<td>28</td>
<td>74.5</td>
<td>6</td>
<td>50</td>
<td>18</td>
<td>75</td>
</tr>
<tr>
<td>Nearest mean classifier</td>
<td>3</td>
<td>77</td>
<td>21</td>
<td>41.67</td>
<td>10</td>
<td>76</td>
</tr>
<tr>
<td>Parzen classifier</td>
<td>23</td>
<td>66.67</td>
<td>10</td>
<td>46.54</td>
<td>12</td>
<td>91.67</td>
</tr>
<tr>
<td>Decision tree</td>
<td>27</td>
<td>92</td>
<td>24</td>
<td>66.66</td>
<td>29</td>
<td>96.30</td>
</tr>
<tr>
<td>SVM</td>
<td>10</td>
<td>51</td>
<td>8</td>
<td>46.34</td>
<td>8</td>
<td>58.33</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0954411913480669">
<p>LBP: local binary pattern; LTE: Laws’ texture energy; DWT: discrete wavelet transform; HOS: higher-order spectra; SVM: support vector machine.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>The accuracy percentages varied from 23% for the worst-performing feature selection–classifier combination to 91.6% for the best-performing feature selection–classifier combination. While the Fisher classifier proved to be least effective in classifying the DDSM database, DT turned out to be the most effective classifier, which in combination with a forward feature selection scheme gave an accuracy percentage of 91.6%. The DT gave constantly good accuracies in excess of 85% for every feature selection scheme chosen. While the other classifiers were quite ineffective in classification of the dataset, NMC and SVM fared quite badly. This is counter-intuitive to what we see in the dataset as we would expect the SVM to perform well for this kind of a dataset. But because of the highly complicated dataset structure, as seen from the scatter plot in <xref ref-type="fig" rid="fig4-0954411913480669">Figures 4</xref> and <xref ref-type="fig" rid="fig5-0954411913480669">5</xref>, this result can be justified.</p>
<fig id="fig5-0954411913480669" position="float">
<label>Figure 5.</label>
<caption>
<p>Spread of the feature vectors for SATA CommHealth database.</p>
</caption>
<graphic xlink:href="10.1177_0954411913480669-fig5.tif"/>
</fig>
<p>From the results, we also find that the best accuracy is obtained for the best 30–35 ranked vectors, which are dominated by HOS sprinkled with LBP, LTE, and DWT. This can be seen from the ranked feature list obtained during the feature ranking process. Also, it is seen that DT provides a much higher classification accuracy compared to the other classifier types. From the results, we see that there is not much difference in classification accuracy for various feature selection techniques, as far as DT is concerned. But, the classification accuracies of other classifiers vary considerably for the type of feature selection technique used. This can be understood by observing the feature ranking trend that shows a considerably different significant feature ranking for each technique. This can quite evidently affect classification accuracy.</p>
<p>From the accuracy percentages, we note that the accuracy rates for SATA CommHealth database are significantly higher than that of the DDSM database. While the DDSM database gave a best classification result of 91.6% for the DT classifier, the SATA CommHealth database gave a classification accuracy of 96.8% for the DT classifier in combination with the backward feature selection algorithm. The worst-performing classifier in the case of SATA CommHealth database was the LDC. The reason for this can be easily explained by observing the scatter plot in <xref ref-type="fig" rid="fig5-0954411913480669">Figure 5</xref>, which shows a highly overlapping feature vector. Also, it is noted that not all classifiers provide a good result for the DDSM database, while most classifiers provide comparable results for the SATA CommHealth database. Possible reasons for these observations are discussed in section “Discussion.”</p>
</sec>
<sec id="section17-0954411913480669" sec-type="discussion">
<title>Discussion</title>
<p>From the results, we see that DT gives the best classification results of all the classifiers, and the accuracy rates do not vary much between different feature selection techniques. Though this is the case, we also see that other classifiers, except SVM and Parzen, do not show promising results in classifying datasets. A look at the data spread of the feature set (103 features) might provide an insight into why DTs work well in this kind of a dataset. <xref ref-type="fig" rid="fig4-0954411913480669">Figure 4</xref> shows a scatter plot of the features from the three classes of the DDSM database, while <xref ref-type="fig" rid="fig5-0954411913480669">Figure 5</xref> provides a scatter plot of the features from three classes of the SATA CommHealth database. While <xref ref-type="fig" rid="fig4-0954411913480669">Figure 4</xref> shows a clear overlap between the two abnormal classes (benign and malignant), the normal feature class is evidently well separable. This might explain why the accuracy rate of classifiers other than the DT proved too bad to be conclusive as robust (<xref ref-type="table" rid="table1-0954411913480669">Tables 1</xref> and <xref ref-type="table" rid="table2-0954411913480669">2</xref>).</p>
<p>Given the fact that DT works quite well for a small sample size and highly overlapping data, the effectiveness of DT as a conclusive classifier for our problem is in fact justified. This argument can be further considered with respect to the data spread of SATA CommHealth database feature spread, where we see that there is a quite a good separability between the classes. This explains the increased accuracy rate for all the classifiers in this database compared to the DDSM database. This also explains a very high classification accuracy for DT with the SATA CommHealth database. It is quite evident that the low performance of these classifiers is due to the inherent qualities of the database. This provides space for introspection of the data samples in consideration. One possible solution to this problem is to increase the sample size. Though increase in accuracy with increase in sample size is not given, with a constant feature space, an increase in sample size and an increase in data variability can aid in the improvement of classification accuracy for all the classifiers. This can also help in preventing spurious outliers for classifier performances. Also, feature selection has indeed played an important role in determining the classification accuracy. This can be seen from the varying accuracy rates for different feature ranking schemes. Here, we see that the most significant features prove to be a mixture of LBP, LTE, DWT, and HOS features. Though HOS features are dominant, we also see other features being involved in the significant feature list.</p>
<p>The other problem to be tackled is the overlap between benign and malignant datasets that cause a high percentage of error. This can be tackled by increasing data variability as already discussed or by reducing a three-class problem into a two-class problem, which in turn can be handled as a one-class classification set up. But, we need to classify three classes, which would end up translating into a normal–abnormal two-class problem, followed by a classification of a benign–malignant two-class problem. So, it would be a two-stage two-class classification framework. Though it is theoretically possible, practically, it might give the same result or a reduced result as an error would creep in during each stage of the classification. Also, since the two abnormal classes already have a huge overlap, splitting the three-class problem into 2 two-class problems will not provide a good result.</p>
<p>From this experimental framework and set up, it is seen that the classification framework works reasonably well with a particular classifier for a particular data sample. But, it is to be verified with a higher data variability and a bigger data sample if the same framework holds good for a generalized system.</p>
<p>
<xref ref-type="table" rid="table3-0954411913480669">Table 3</xref> shows a review of results obtained using different combinations of feature extraction techniques and classifiers in previous studies. It should be noted that the results tabulated in <xref ref-type="table" rid="table1-0954411913480669">Table 1</xref> were obtained from different datasets and thus cannot be compared to the results obtained in this study. <xref ref-type="table" rid="table1-0954411913480669">Table 1</xref> is provided just as a reference to the current scenario in computer-aided breast cancer detection.</p>
<table-wrap id="table3-0954411913480669" position="float">
<label>Table 3.</label>
<caption>
<p>Summary of studies on mammographic image classification.</p>
</caption>
<graphic alternate-form-of="table3-0954411913480669" xlink:href="10.1177_0954411913480669-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Authors</th>
<th align="left">Features</th>
<th align="left">Classifier</th>
<th align="left">Accuracy (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Christoyianni et al.<sup><xref ref-type="bibr" rid="bibr34-0954411913480669">34</xref></sup></td>
<td>Central moments</td>
<td>RBF</td>
<td>75.2</td>
</tr>
<tr>
<td>Youssry et al.<sup><xref ref-type="bibr" rid="bibr35-0954411913480669">35</xref></sup></td>
<td>GLCM feature</td>
<td>Neurofuzzy</td>
<td>80</td>
</tr>
<tr>
<td>Acharya et al.<sup><xref ref-type="bibr" rid="bibr36-0954411913480669">36</xref></sup></td>
<td>Area, homogeneity, and microcalcification</td>
<td>ANN and GMM</td>
<td>ANN: 88.89 and GMM: 94.44</td>
</tr>
<tr>
<td>Chen and Chang<sup><xref ref-type="bibr" rid="bibr37-0954411913480669">37</xref></sup></td>
<td>Texture shape feature coding</td>
<td>SVM</td>
<td>86</td>
</tr>
<tr>
<td>Andre and Rangayyan<sup><xref ref-type="bibr" rid="bibr38-0954411913480669">38</xref></sup></td>
<td>Shape factor measures and GLCM features</td>
<td>Perceptron with several topologies</td>
<td>Shape factors: 99 and texture feature: 63</td>
</tr>
<tr>
<td>Mu et al.<sup><xref ref-type="bibr" rid="bibr39-0954411913480669">39</xref></sup></td>
<td>Shape factors, edge sharpness, and texture features</td>
<td>Kernel-based nonlinear classifiers</td>
<td>95</td>
</tr>
<tr>
<td>Singh et al.<sup><xref ref-type="bibr" rid="bibr40-0954411913480669">40</xref></sup></td>
<td>Shape, texture, and statistical properties</td>
<td>SVM with RBF kernel and SVM with polynomial kernel</td>
<td>97, 95</td>
</tr>
<tr>
<td>Dehghan et al.<sup><xref ref-type="bibr" rid="bibr41-0954411913480669">41</xref></sup></td>
<td>Wavelet features and gray-level statistical features</td>
<td>SVM classifier with RBF kernel</td>
<td>89.55</td>
</tr>
<tr>
<td>Rangayyan et al.<sup><xref ref-type="bibr" rid="bibr42-0954411913480669">42</xref></sup></td>
<td>Region-based edge profile</td>
<td>Acutance measures</td>
<td>92</td>
</tr>
<tr>
<td>Petrosian et al.<sup><xref ref-type="bibr" rid="bibr43-0954411913480669">43</xref></sup></td>
<td>Spatial gray-level dependence and textural features</td>
<td>DT</td>
<td>76–89</td>
</tr>
<tr>
<td>Polakowski et al.<sup><xref ref-type="bibr" rid="bibr44-0954411913480669">44</xref></sup></td>
<td>Model-based vision algorithm and difference of Gaussians with texture features</td>
<td>Multilayer perceptron neural network</td>
<td>92</td>
</tr>
<tr>
<td>Priebe et al.<sup><xref ref-type="bibr" rid="bibr45-0954411913480669">45</xref></sup></td>
<td>Fractal texture measures</td>
<td>Finite mixture model probability density estimation</td>
<td>88</td>
</tr>
<tr>
<td>Wei et al.<sup><xref ref-type="bibr" rid="bibr46-0954411913480669">46</xref></sup></td>
<td>Statistical features</td>
<td>SVM and kernel fisher discriminant</td>
<td>85</td>
</tr>
<tr>
<td>Szekely et al.<sup><xref ref-type="bibr" rid="bibr47-0954411913480669">47</xref></sup></td>
<td>Texture features</td>
<td>Combined classifier of DT and multiresolution Markov random models</td>
<td>88–94</td>
</tr>
<tr>
<td>Verma and Zakos.<sup><xref ref-type="bibr" rid="bibr48-0954411913480669">48</xref></sup></td>
<td>Statistical features</td>
<td>Fuzzy neural network</td>
<td>83</td>
</tr>
<tr>
<td>Kinoshita et al.<sup><xref ref-type="bibr" rid="bibr49-0954411913480669">49</xref></sup></td>
<td>Shape and texture features</td>
<td>Three-layer feed-forward neural network</td>
<td>81</td>
</tr>
<tr>
<td>Chitre et al.<sup><xref ref-type="bibr" rid="bibr50-0954411913480669">50</xref></sup></td>
<td>Texture measures</td>
<td>Neural network classifier</td>
<td>87</td>
</tr>
<tr>
<td>Mudigonda et al.<sup><xref ref-type="bibr" rid="bibr51-0954411913480669">51</xref></sup></td>
<td>GLCMs and polygonal modeling</td>
<td>Jackknife classification</td>
<td>83</td>
</tr>
<tr>
<td>Yoshida et al.<sup><xref ref-type="bibr" rid="bibr52-0954411913480669">52</xref></sup></td>
<td>Wavelet features</td>
<td>Canny and Marr–Hildreth detectors</td>
<td>90</td>
</tr>
<tr>
<td>Alolfe et al.<sup><xref ref-type="bibr" rid="bibr53-0954411913480669">53</xref></sup></td>
<td>Wavelet features</td>
<td>SVM + LDA</td>
<td>82.5–90</td>
</tr>
<tr>
<td>The current study</td>
<td>HOS, LBP, LME, and DWT features</td>
<td>DT, NMC, LDC, Fisher, Parzen, and SVM</td>
<td>DT: 96.3</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0954411913480669">
<p>ANN: artificial neural network; DT: decision tree; GMM: Gaussian mixture model; GLCM: gray-level co-occurrence matrix; SVM: support vector machine; LDA: linear discriminant analysis; NMC: nearest mean classifier; LDC: linear discriminant classifier; RBF: radial basis function; HOS: higher-order spectra; LBP: local binary pattern; LME: Laws’ mask energy; DWT: discrete wavelet transform.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section18-0954411913480669" sec-type="conclusions">
<title>Conclusion</title>
<p>We have proposed a framework for the automated detection of normal, benign, and cancerous mammograms using a combination of texture, HOS, and DWT features extracted from digitized mammograms. These features capture the subtle variation in the pixel intensities and contours in the images and serve as significant indicators for classification. DT, Fisher, LDC, NMC, Parzen, and SVM classifiers were used to classify the features. We used five feature selection methods for ranking the features: forward, backward, plus-l-takeaway-r, individual, and branch-and-bound techniques. Among the classifiers evaluated, DT classifier has shown the best performance, suggesting the highest accuracy of 91.6% for the DDSM database and 96.8% for the SATA CommHealth database using the most significant features. The performance of the proposed system can be further increased with better features, more diverse mammograms, and robust classifiers.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors thank SATA CommHealth, Singapore for funding the research.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0954411913480669">
<label>1.</label>
<citation citation-type="web">
<collab>ACS</collab>. <ext-link ext-link-type="uri" xlink:href="http://www.cancer.org/cancer/breastcancer/detailedguide/breast-cancer-key-statistics">http://www.cancer.org/cancer/breastcancer/detailedguide/breast-cancer-key-statistics</ext-link> (<access-date>accessed July 2011</access-date>).</citation>
</ref>
<ref id="bibr2-0954411913480669">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pisano</surname><given-names>ED</given-names></name>
<name><surname>Gatsonis</surname><given-names>C</given-names></name>
<name><surname>Hendrick</surname><given-names>E</given-names></name><etal/>
</person-group>. <article-title>Diagnostic performance of digital versus film mammography for breast-cancer screening</article-title>. <source>N Engl J Med</source> <year>2005</year>; <volume>353</volume>(<issue>17</issue>): <fpage>1773</fpage>–<lpage>1783</lpage>.</citation>
</ref>
<ref id="bibr3-0954411913480669">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pisano</surname><given-names>ED</given-names></name>
<name><surname>Hendrick</surname><given-names>RE</given-names></name>
<name><surname>Yaffe</surname><given-names>MJ</given-names></name><etal/>
</person-group>. <article-title>Diagnostic accuracy of digital versus film mammography: exploratory analysis of selected population subgroups in DMIST</article-title>. <source>Radiology</source> <year>2008</year>; <volume>246</volume>(<issue>2</issue>): <fpage>376</fpage>–<lpage>383</lpage>.</citation>
</ref>
<ref id="bibr4-0954411913480669">
<label>4.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schulz-Wendtland</surname><given-names>R</given-names></name>
<name><surname>Fuchsjägerb</surname><given-names>M</given-names></name>
<name><surname>Wackerc</surname><given-names>T</given-names></name><etal/>
</person-group>. <article-title>Digital mammography: an update</article-title>. <source>Eur J Radiol</source> <year>2009</year>; <volume>72</volume>(<issue>2</issue>): <fpage>258</fpage>–<lpage>265</lpage>.</citation>
</ref>
<ref id="bibr5-0954411913480669">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kearney</surname><given-names>AJ</given-names></name>
<name><surname>Murray</surname><given-names>M</given-names></name>
</person-group>. <article-title>Breast cancer screening recommendations: is mammography the only answer?</article-title> <source>J Midwifery Women’s Health</source> <year>2009</year>; <volume>54</volume>(<issue>5</issue>): <fpage>393</fpage>–<lpage>400</lpage>.</citation>
</ref>
<ref id="bibr6-0954411913480669">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wang</surname><given-names>X</given-names></name>
<name><surname>Chao</surname><given-names>L</given-names></name>
<name><surname>Chen</surname><given-names>L</given-names></name><etal/>
</person-group>. <article-title>The mammographic correlations with basal-like phenotype of invasive breast cancer</article-title>. <source>Acad Radiol</source> <year>2010</year>; <volume>17</volume>(<issue>3</issue>): <fpage>333</fpage>–<lpage>339</lpage>.</citation>
</ref>
<ref id="bibr7-0954411913480669">
<label>7.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Suri</surname><given-names>JS</given-names></name>
<name><surname>Rangayyan</surname><given-names>RM</given-names></name>
<name><surname>Laxminarayan</surname><given-names>S</given-names></name>
</person-group> <source>Emerging Technologies in Breast and Mammography Imaging and Its Applications</source>, <publisher-name>American Scientific Publishers</publisher-name>, <publisher-loc>Stevenson Ranch, CA, USA</publisher-loc> (<year>2006</year>).</citation>
</ref>
<ref id="bibr8-0954411913480669">
<label>8.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Suri</surname><given-names>JS</given-names></name>
<name><surname>Rangayyan</surname><given-names>RM</given-names></name>
</person-group>. <source>Recent advances in breast imaging, mammography and computer aided diagnosis of breast cancer</source>. <publisher-loc>Bellingham, WA</publisher-loc>: <publisher-name>SPIE Press</publisher-name>, <year>2006</year>.</citation>
</ref>
<ref id="bibr9-0954411913480669">
<label>9.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Huang</surname><given-names>CL</given-names></name>
<name><surname>Liao</surname><given-names>HC</given-names></name>
<name><surname>Chen</surname><given-names>MC</given-names></name>
</person-group>. <article-title>Prediction model building and feature selection with support vector machines in breast cancer diagnosis</article-title>. <source>Expert Syst Appl</source> <year>2008</year>; <volume>34</volume>(<issue>1</issue>): <fpage>578</fpage>–<lpage>587</lpage>.</citation>
</ref>
<ref id="bibr10-0954411913480669">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>HD</given-names></name>
<name><surname>Cai</surname><given-names>X</given-names></name>
<name><surname>Chen</surname><given-names>X</given-names></name><etal/>
</person-group>. <article-title>Computer-aided detection and classification of microcalcifications in mammograms: a survey</article-title>. <source>Pattern Recognit</source> <year>2003</year>; <volume>36</volume>(<issue>12</issue>): <fpage>2967</fpage>–<lpage>2991</lpage>.</citation>
</ref>
<ref id="bibr11-0954411913480669">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>HD</given-names></name>
<name><surname>Shi</surname><given-names>XJ</given-names></name>
<name><surname>Min</surname><given-names>R</given-names></name><etal/>
</person-group>. <article-title>Approaches for automated detection and classification of masses in mammograms</article-title>. <source>Pattern Recognit</source> <year>2006</year>; <volume>39</volume>(<issue>4</issue>): <fpage>646</fpage>–<lpage>668</lpage>.</citation>
</ref>
<ref id="bibr12-0954411913480669">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Elter</surname><given-names>M</given-names></name>
<name><surname>Horsch</surname><given-names>A</given-names></name>
</person-group>. <article-title>CADx of mammographic masses and clustered microcalcifications: a review</article-title>. <source>Med Phys</source> <year>2009</year>; <volume>36</volume>(<issue>6</issue>): <fpage>2052</fpage>–<lpage>2068</lpage>.</citation>
</ref>
<ref id="bibr13-0954411913480669">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sadaf</surname><given-names>A</given-names></name>
<name><surname>Crystal</surname><given-names>P</given-names></name>
<name><surname>Scaranelo</surname><given-names>A</given-names></name><etal/>
</person-group>. <article-title>Performance of computer-aided detection applied to full-field digital mammography in detection of breast cancers</article-title>. <source>Eur J Radiol</source> <year>2009</year>; <volume>77</volume>(<issue>3</issue>): <fpage>457</fpage>–<lpage>461</lpage>.</citation>
</ref>
<ref id="bibr14-0954411913480669">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Karssemeijer</surname><given-names>N</given-names></name>
<name><surname>Bluekens</surname><given-names>AM</given-names></name>
<name><surname>Beijerinck</surname><given-names>D</given-names></name><etal/>
</person-group>. <article-title>Breast cancer screening results 5 years after introduction of digital mammography in a population-based screening program</article-title>. <source>Radiology</source> <year>2009</year>; <volume>253</volume>(<issue>2</issue>): <fpage>353</fpage>–<lpage>358</lpage>.</citation>
</ref>
<ref id="bibr15-0954411913480669">
<label>15.</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Heath</surname><given-names>M</given-names></name>
<name><surname>Bowyer</surname><given-names>K</given-names></name>
<name><surname>Kopans</surname><given-names>D</given-names></name>
<etal/>
</person-group>. <article-title>The Digital Database for Screening Mammography</article-title>. In: <conf-name>Proceedings of the 5th international workshop on digital mammography</conf-name>, <conf-loc>Toronto, ON, Canada</conf-loc>, <year>2000</year>, pp.<fpage>212</fpage>–<lpage>218</lpage>, <ext-link ext-link-type="uri" xlink:href="http://marathon.csee.usf.edu/Mammography/Databaseb.html">http://marathon.csee.usf.edu/Mammography/Databaseb.html</ext-link>.</citation>
</ref>
<ref id="bibr16-0954411913480669">
<label>16.</label>
<citation citation-type="web">
<comment>University of South Florida Digital Mammography Home Page. DDSM: Digital Database for Screening Mammography</comment>, <ext-link ext-link-type="uri" xlink:href="http://marathon.csee.usf.edu/Mammography/Database.html">http://marathon.csee.usf.edu/Mammography/Database.html</ext-link> (<access-date>accessed July 2011</access-date>).</citation>
</ref>
<ref id="bibr17-0954411913480669">
<label>17.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chua</surname><given-names>KC</given-names></name>
<name><surname>Chandranb</surname><given-names>V</given-names></name>
<name><surname>Acharya</surname><given-names>UR</given-names></name><etal/>
</person-group>. <article-title>Application of higher order statistics/spectra in biomedical signals—a review</article-title>. <source>Med Eng Phys</source> <year>2010</year>; <volume>32</volume>(<issue>7</issue>): <fpage>679</fpage>–<lpage>689</lpage>.</citation>
</ref>
<ref id="bibr18-0954411913480669">
<label>18.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Nikias</surname><given-names>CL</given-names></name>
<name><surname>Petropulu</surname><given-names>AP</given-names></name>
</person-group>. <source>Higher-order spectra analysis: a nonlinear signal processing framework</source>. <publisher-loc>Englewood Cliffs, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>, <year>1993</year>.</citation>
</ref>
<ref id="bibr19-0954411913480669">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chandran</surname><given-names>V</given-names></name>
<name><surname>Carswell</surname><given-names>B</given-names></name>
<name><surname>Boashash</surname><given-names>B</given-names></name><etal/>
</person-group>. <article-title>Pattern recognition using invariants defined from higher order spectra: 2-D image inputs</article-title>. <source>IEEE Trans Image Process</source> <year>1997</year>; <volume>6</volume>(<issue>5</issue>): <fpage>703</fpage>–<lpage>712</lpage>.</citation>
</ref>
<ref id="bibr20-0954411913480669">
<label>20.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ojala</surname><given-names>T</given-names></name>
<name><surname>Pietikäinen</surname><given-names>M</given-names></name>
<name><surname>Maenpaa</surname><given-names>T</given-names></name>
</person-group>. <article-title>Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> <year>2002</year>; <volume>24</volume>(<issue>7</issue>): <fpage>971</fpage>–<lpage>987</lpage>.</citation>
</ref>
<ref id="bibr21-0954411913480669">
<label>21.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chua</surname><given-names>KC</given-names></name>
<name><surname>Chandran</surname><given-names>V</given-names></name>
<name><surname>Acharya</surname><given-names>UR</given-names></name><etal/>
</person-group>. <article-title>Analysis of epileptic EEG signals using higher order spectra</article-title>. <source>J Med Eng Technol</source> <year>2009</year>; <volume>33</volume>(<issue>1</issue>): <fpage>42</fpage>–<lpage>50</lpage>.</citation>
</ref>
<ref id="bibr22-0954411913480669">
<label>22.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Inouye</surname><given-names>T</given-names></name>
<name><surname>Shinosaki</surname><given-names>K</given-names></name>
<name><surname>Sakamoto</surname><given-names>H</given-names></name><etal/>
</person-group>. <article-title>Quantification of EEG irregularity by use of the entropy of the power spectrum</article-title>. <source>Electroencephalogr Clin Neurophysiol</source> <year>1991</year>; <volume>79</volume>(<issue>3</issue>): <fpage>204</fpage>–<lpage>210</lpage>.</citation>
</ref>
<ref id="bibr23-0954411913480669">
<label>23.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ng</surname><given-names>TT</given-names></name>
<name><surname>Chang</surname><given-names>SF</given-names></name>
<name><surname>Sun</surname><given-names>Q</given-names></name>
</person-group>. <article-title>Blind detection of photomontage using higher order statistics</article-title>. In: <conf-name>IEEE international symposium on circuits and systems (ISCAS)</conf-name>, <conf-loc>IEEE, Vancouver, BC, Canada</conf-loc>, <conf-date>23rd May- 26th May 2004</conf-date>, DOI: <pub-id pub-id-type="doi">10.1109/ISCAS.2004.1329432</pub-id>.</citation>
</ref>
<ref id="bibr24-0954411913480669">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ojala</surname><given-names>T</given-names></name>
<name><surname>Pietikäinen</surname><given-names>M</given-names></name>
<name><surname>Harwood</surname><given-names>D</given-names></name>
</person-group>. <article-title>A comparative study of texture measures with classification based on feature distributions</article-title>. <source>Pattern Recognit</source> <year>1996</year>; <volume>29</volume>(<issue>1</issue>): <fpage>51</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr25-0954411913480669">
<label>25.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gupta</surname><given-names>R</given-names></name>
<name><surname>Undrill</surname><given-names>PE</given-names></name>
</person-group>. <article-title>The use of texture analysis to delineate suspicious masses in mammography</article-title>. <source>Phys Med Biol</source> <year>1995</year>; <volume>40</volume>(<issue>5</issue>): <fpage>835</fpage>–<lpage>855</lpage>.</citation>
</ref>
<ref id="bibr26-0954411913480669">
<label>26.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Petrou</surname><given-names>M</given-names></name>
<name><surname>Sevilla</surname><given-names>PG</given-names></name>
</person-group>. <source>Image processing—dealing with texture</source>. <publisher-name>John Wiley &amp; Sons</publisher-name>, <year>2006</year>, DOI: <pub-id pub-id-type="doi">10.1002/047003534X</pub-id>.</citation>
</ref>
<ref id="bibr27-0954411913480669">
<label>27.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Laws</surname><given-names>KI</given-names></name>
</person-group>. <article-title>Rapid texture identification</article-title>. In: <conf-name>SPIE conference series</conf-name>, <year>1980</year>, <volume>vol. 238</volume>, pp.<fpage>376</fpage>–<lpage>380</lpage>.</citation>
</ref>
<ref id="bibr28-0954411913480669">
<label>28.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chih-Chin</surname><given-names>L</given-names></name>
<name><surname>Cheng-Chih</surname><given-names>T</given-names></name>
</person-group>. <article-title>Digital image watermarking using discrete wavelet transform and singular value decomposition</article-title>. <source>IEEE Trans Instrum Meas</source> <year>2010</year>; <volume>59</volume>(<issue>11</issue>): <fpage>3060</fpage>–<lpage>3063</lpage>.</citation>
</ref>
<ref id="bibr29-0954411913480669">
<label>29.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hui</surname><given-names>Y</given-names></name>
<name><surname>Jie</surname><given-names>G</given-names></name>
<name><surname>Hua</surname><given-names>GZ</given-names></name><etal/>
</person-group>. <article-title>An efficient method to process the quantized acoustoelectric current: wavelet transform</article-title>. <source>IEEE Trans Instrum Meas</source> <year>2011</year>; <volume>60</volume>(<issue>3</issue>): <fpage>696</fpage>–<lpage>702</lpage>.</citation>
</ref>
<ref id="bibr30-0954411913480669">
<label>30.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>David</surname><given-names>V</given-names></name>
<name><surname>Sanchez</surname><given-names>A</given-names></name>
</person-group>. <article-title>Advanced support vector machines and kernel methods</article-title>. <source>Neurocomputing</source> <year>2003</year>; <volume>55</volume>: <fpage>5</fpage>–<lpage>20</lpage>.</citation>
</ref>
<ref id="bibr31-0954411913480669">
<label>31.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Muller</surname><given-names>KR</given-names></name>
<name><surname>Mika</surname><given-names>S</given-names></name>
<name><surname>Ratsch</surname><given-names>G</given-names></name><etal/>
</person-group>. <article-title>An introduction to kernel based learning algorithms</article-title>. <source>IEEE Trans Neural Netw</source> <year>2001</year>; <volume>12</volume>(<issue>2</issue>): <fpage>181</fpage>–<lpage>201</lpage>.</citation>
</ref>
<ref id="bibr32-0954411913480669">
<label>32.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Theodoris</surname><given-names>S</given-names></name>
<name><surname>Koutroumbas</surname><given-names>K</given-names></name>
</person-group>. <source>Pattern recognition</source>. <edition>3rd ed.</edition> <publisher-name>Academic Press</publisher-name>, <publisher-loc>London, UK</publisher-loc>, <year>2006</year>.</citation>
</ref>
<ref id="bibr33-0954411913480669">
<label>33.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ross</surname><given-names>TJ</given-names></name>
</person-group>. <source>Fuzzy logic with engineering applications</source>. <publisher-loc>West Sussex</publisher-loc>: <publisher-name>John Wiley &amp; Sons Ltd.</publisher-name>, <year>2004</year>.</citation>
</ref>
<ref id="bibr34-0954411913480669">
<label>34.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Christoyianni</surname><given-names>I</given-names></name>
<name><surname>Dermatas</surname><given-names>E</given-names></name>
<name><surname>Kokkinakis</surname><given-names>G</given-names></name>
</person-group>. <article-title>Fast detection of masses in computer-aided mammography</article-title>. <source>IEEE Signal Process Mag</source> <year>2000</year>; <volume>17</volume>(<issue>1</issue>): <fpage>54</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr35-0954411913480669">
<label>35.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Youssry</surname><given-names>N</given-names></name>
<name><surname>Abou-Chadi</surname><given-names>FEZ</given-names></name>
<name><surname>El-Sayad</surname><given-names>AM</given-names></name>
</person-group>. <article-title>Early detection of masses in digitized mammograms using texture features and neuro-fuzzy model</article-title>. In: <conf-name>4th international IEEE EMBS special topic conference on information technology applications in biomedicine</conf-name>, <conf-date>24-26 April 2003</conf-date>, <conf-loc>Birmingham, UK IEEE</conf-loc>, pp.<fpage>226</fpage>–<lpage>229</lpage>.</citation>
</ref>
<ref id="bibr36-0954411913480669">
<label>36.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Acharya</surname><given-names>UR</given-names></name>
<name><surname>Ng</surname><given-names>EYK</given-names></name>
<name><surname>Hong</surname><given-names>Y</given-names></name><etal/>
</person-group>. <article-title>Automatic identification of breast cancer using mammogram</article-title>. <source>J Med Syst</source> <year>2008</year>; <volume>32</volume>: <fpage>499</fpage>–<lpage>507</lpage>.</citation>
</ref>
<ref id="bibr37-0954411913480669">
<label>37.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>Y</given-names></name>
<name><surname>Chang</surname><given-names>CI</given-names></name>
</person-group>. <article-title>New texture shape feature coding-based computer aided diagnostic methods for classification of masses on mammograms</article-title>. <source>Conf Proc IEEE Eng Med Biol Soc</source> <year>2004</year>; <volume>2</volume>: <fpage>1275</fpage>–<lpage>1278</lpage>.</citation>
</ref>
<ref id="bibr38-0954411913480669">
<label>38.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Andre</surname><given-names>TCSS</given-names></name>
<name><surname>Rangayyan</surname><given-names>RM</given-names></name>
</person-group>. <article-title>Classification of tumors and masses in mammograms using neural networks with shape and texture features</article-title>. In: <conf-name>Proceedings of the 25th annual international conference of the IEEE EMBS</conf-name>, <conf-date>17-21 September 2003</conf-date>, <conf-loc>Cancun Mexico, IEEE</conf-loc>, <volume>vol. 3</volume>, pp.<fpage>2261</fpage>–<lpage>2264</lpage>.</citation>
</ref>
<ref id="bibr39-0954411913480669">
<label>39.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mu</surname><given-names>T</given-names></name>
<name><surname>Nandi</surname><given-names>AK</given-names></name>
<name><surname>Rangayyan</surname><given-names>RM</given-names></name>
</person-group>. <article-title>Classification of breast masses using selected shape, edge-sharpness, and texture features with linear and kernel-based classifiers</article-title>. <source>J Digit Imaging</source> <year>2008</year>; <volume>21</volume>(<issue>2</issue>): <fpage>153</fpage>–<lpage>169</lpage>.</citation>
</ref>
<ref id="bibr40-0954411913480669">
<label>40.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Singh</surname><given-names>S</given-names></name>
<name><surname>Kumar</surname><given-names>V</given-names></name>
<name><surname>Verma</surname><given-names>HK</given-names></name><etal/>
</person-group>. <article-title>SVM based system for classification of microcalcifications in digital mammograms</article-title>. <source>Conf Proc IEEE Eng Med Biol Soc</source> <year>2006</year>; <volume>1</volume>: <fpage>4747</fpage>–<lpage>4750</lpage>.</citation>
</ref>
<ref id="bibr41-0954411913480669">
<label>41.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Dehghan</surname><given-names>F</given-names></name>
<name><surname>Abrishami-Moghaddam</surname><given-names>H</given-names></name>
<name><surname>Giti</surname><given-names>M</given-names></name>
</person-group>. <article-title>Automatic detection of clustered microcalcifications in digital mammograms: Study on applying adaboost with SVM-based component classifiers</article-title>. <conf-name>Conf Proc IEEE Eng Med Biol Soc 2008</conf-name>; <conf-date>21-24 August 2008</conf-date>, <conf-loc>Vancouver, Canada, IEEE</conf-loc>, <year>2008</year>: <fpage>4789</fpage>–<lpage>4792</lpage>.</citation>
</ref>
<ref id="bibr42-0954411913480669">
<label>42.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rangayyan</surname><given-names>RM</given-names></name>
<name><surname>El-Faramawy</surname><given-names>NM</given-names></name>
<name><surname>Desautels</surname><given-names>JEL</given-names></name>
<etal/>
</person-group>. <article-title>Measures of acutance and shape for classification of breast tumours</article-title>. <source>IEEE Trans Med Imaging</source> <year>1997</year>; <volume>16</volume>: <fpage>799</fpage>–<lpage>810</lpage>.</citation>
</ref>
<ref id="bibr43-0954411913480669">
<label>43.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Petrosian</surname><given-names>A</given-names></name>
<name><surname>Chan</surname><given-names>HP</given-names></name>
<name><surname>Helvie</surname><given-names>MA</given-names></name><etal/>
</person-group>. <article-title>Computer-aided diagnosis in mammography: classification of mass and normal tissue by texture analysis</article-title>. <source>Phys Med Biol</source> <year>1994</year>; <volume>39</volume>: <fpage>2273</fpage>–<lpage>2288</lpage>.</citation>
</ref>
<ref id="bibr44-0954411913480669">
<label>44.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Polakowski</surname><given-names>WE</given-names></name>
<name><surname>Cournoyer</surname><given-names>DA</given-names></name>
<name><surname>Rogers</surname><given-names>SK</given-names></name><etal/>
</person-group>. <article-title>Computer-aided breast cancer detection and diagnosis of masses using difference of Gaussians and derivative-based feature saliency</article-title>. <source>IEEE Trans Med Imaging</source> <year>1997</year>; <volume>16</volume>(<issue>6</issue>): <fpage>811</fpage>–<lpage>819</lpage>.</citation>
</ref>
<ref id="bibr45-0954411913480669">
<label>45.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Priebe</surname><given-names>CE</given-names></name>
<name><surname>Lorey</surname><given-names>RA</given-names></name>
<name><surname>Marchette</surname><given-names>DJ</given-names></name>
<etal/>
</person-group>. <article-title>Nonparametric spatio-temporal change point analysis for early detection in mammography</article-title>. In: <conf-name>Proceedings of 2nd international workshop on digital mammography</conf-name> (eds <person-group person-group-type="editor">
<name><surname>Gale</surname><given-names>AG</given-names></name>
<name><surname>Astley</surname><given-names>SM</given-names></name>
<name><surname>Dance</surname><given-names>DR</given-names></name>
<etal/>
</person-group>.), <publisher-name>Elsevier Press</publisher-name>, <publisher-loc>York, UK</publisher-loc>, <conf-date>10–12 July 1994</conf-date>, pp.<fpage>111</fpage>–<lpage>120</lpage>.</citation>
</ref>
<ref id="bibr46-0954411913480669">
<label>46.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wei</surname><given-names>L</given-names></name>
<name><surname>Yang</surname><given-names>Y</given-names></name>
<name><surname>Nishikawa</surname><given-names>RM</given-names></name><etal/>
</person-group>. <article-title>A study on several machine-learning methods for classification of malignant and benign clustered microcalcifications</article-title>. <source>IEEE Trans Med Imaging</source> <year>2005</year>; <volume>24</volume>(<issue>3</issue>): <fpage>371</fpage>–<lpage>380</lpage>.</citation>
</ref>
<ref id="bibr47-0954411913480669">
<label>47.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Szekely</surname><given-names>N</given-names></name>
<name><surname>Toth</surname><given-names>N</given-names></name>
<name><surname>Pataki</surname><given-names>B</given-names></name>
</person-group>. <article-title>A hybrid system for detecting masses in mammographic images</article-title>. <source>IEEE Trans Instrum Meas</source> <year>2006</year>; <volume>55</volume>(<issue>3</issue>): <fpage>944</fpage>–<lpage>952</lpage>.</citation>
</ref>
<ref id="bibr48-0954411913480669">
<label>48.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Verma</surname><given-names>B</given-names></name>
<name><surname>Zakos</surname><given-names>J</given-names></name>
</person-group>. <article-title>A computer-aided diagnosis system for digital mammograms based on fuzzy-neural and feature extraction techniques</article-title>. <source>IEEE Trans Inf Technol Biomed</source> <year>2001</year>; <volume>5</volume>(<issue>1</issue>): <fpage>46</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr49-0954411913480669">
<label>49.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Kinoshita</surname><given-names>SK</given-names></name>
<name><surname>Marques</surname><given-names>PMA</given-names></name>
<name><surname>Slates</surname><given-names>AFF</given-names></name>
<etal/>
</person-group>. <article-title>Detection and characterization of mammographic masses by artificial neural network</article-title>. In: <conf-name>Proceedings of the 4th international workshop on digital mammography</conf-name> (eds <person-group person-group-type="editor">
<name><surname>Karssemeijer</surname><given-names>N</given-names></name>
<name><surname>Thijssen</surname><given-names>M</given-names></name>
<name><surname>Hendriks</surname><given-names>J</given-names></name>
<etal/>
</person-group>.), <conf-loc>Nijmegen, The Netherlands</conf-loc>, <conf-date>June 1998</conf-date>, pp.<fpage>489</fpage>–<lpage>490</lpage>.</citation>
</ref>
<ref id="bibr50-0954411913480669">
<label>50.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chitre</surname><given-names>Y</given-names></name>
<name><surname>Dhawan</surname><given-names>AP</given-names></name>
<name><surname>Moskowitz</surname><given-names>M</given-names></name>
</person-group>. <article-title>Artificial neural network based classification of mammographic microcalcifications using image structure features</article-title>. <source>Int J Pattern Recogn</source> <year>1993</year>; <volume>7</volume>(<issue>12</issue>): <fpage>1377</fpage>–<lpage>1402</lpage>.</citation>
</ref>
<ref id="bibr51-0954411913480669">
<label>51.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mudigonda</surname><given-names>NR</given-names></name>
<name><surname>Rangayyan</surname><given-names>R</given-names></name>
<name><surname>Desautels</surname><given-names>JEL</given-names></name>
</person-group>. <article-title>Gradient and texture analysis for the classification of mammographic masses</article-title>. <source>IEEE Trans Med Imaging</source> <year>2000</year>; <volume>19</volume>(<issue>10</issue>): <fpage>1032</fpage>–<lpage>1043</lpage>.</citation>
</ref>
<ref id="bibr52-0954411913480669">
<label>52.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Yoshida</surname><given-names>H</given-names></name>
<name><surname>Nishikawa</surname><given-names>R</given-names></name>
<name><surname>Maryellen</surname><given-names>G</given-names></name>
<etal/>
</person-group>. <article-title>Computer-aided diagnosis in mammography: detection of clustered microcalcifications based on multiscale edge representation</article-title>. In: <source>Computer assisted radiology</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>, <year>1996</year>.</citation>
</ref>
<ref id="bibr53-0954411913480669">
<label>53.</label>
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Alolfe</surname><given-names>MA</given-names></name>
<name><surname>Mohamed</surname><given-names>WA</given-names></name>
<name><surname>Youssef</surname><given-names>A-B</given-names></name>
<etal/>
</person-group>. <article-title>Computer aided diagnosis in digital mammography using support vector machine and linear discriminant analysis classification</article-title>. In: <conf-name>16th IEEE international conference on image processing (ICIP)</conf-name>, <conf-date>7–10 November 2009</conf-date>, <conf-loc>Cairo, Egypt, IEEE</conf-loc>, pp.<fpage>2609</fpage>–<lpage>2612</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>