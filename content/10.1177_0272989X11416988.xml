<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MDM</journal-id>
<journal-id journal-id-type="hwp">spmdm</journal-id>
<journal-id journal-id-type="nlm-ta">Med Decis Making</journal-id>
<journal-title>Medical Decision Making</journal-title>
<issn pub-type="ppub">0272-989X</issn>
<issn pub-type="epub">1552-681X</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0272989X11416988</article-id>
<article-id pub-id-type="publisher-id">10.1177_0272989X11416988</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles: Health-Related Quality of Life</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Regression Estimators for Generic Health-Related Quality of Life and Quality-Adjusted Life Years</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Basu</surname><given-names>Anirban</given-names></name>
<degrees>PhD</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Manca</surname><given-names>Andrea</given-names></name>
<degrees>PhD</degrees>
</contrib>
</contrib-group>
<aff id="aff1-0272989X11416988">Departments of Health Services and Pharmacy, University of Washington, Seattle, WA (AB)</aff>
<aff id="aff2-0272989X11416988">The National Bureau of Economic Research, Cambridge MA (AB)</aff>
<aff id="aff3-0272989X11416988">Centre for Health Economics, The University of York, York, UK (AM)</aff>
<author-notes>
<corresp id="corresp1-0272989X11416988">Anirban Basu, 1959 NE Pacific St, Box 357660, Seattle, WA, 98195-7660; telephone: (206) 616-2986; fax: (206) 543-3964; e-mail: <email>basua@uw.edu</email>.</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2012</year>
</pub-date>
<volume>32</volume>
<issue>1</issue>
<fpage>56</fpage>
<lpage>69</lpage>
<history>
<date date-type="received">
<day>27</day>
<month>1</month>
<year>2010</year>
</date>
<date date-type="accepted">
<day>23</day>
<month>5</month>
<year>2011</year>
</date>
</history>
<abstract>
<p><bold>Purpose</bold>. To develop regression models for outcomes with truncated supports, such as health-related quality of life (HRQoL) data, and account for features typical of such data such as a skewed distribution, spikes at 1 or 0, and heteroskedasticity. <bold>Methods</bold>. Regression estimators based on features of the Beta distribution. First, both a single equation and a 2-part model are presented, along with estimation algorithms based on maximum-likelihood, quasi-likelihood, and Bayesian Markov-chain Monte Carlo methods. A novel Bayesian quasi-likelihood estimator is proposed. Second, a simulation exercise is presented to assess the performance of the proposed estimators against ordinary least squares (OLS) regression for a variety of HRQoL distributions that are encountered in practice. Finally, the performance of the proposed estimators is assessed by using them to quantify the treatment effect on QALYs in the EVALUATE hysterectomy trial. Overall model fit is studied using several goodness-of-fit tests such as Pearson’s correlation test, link and reset tests, and a modified Hosmer-Lemeshow test. <bold>Results</bold>. The simulation results indicate that the proposed methods are more robust in estimating covariate effects than OLS, especially when the effects are large or the HRQoL distribution has a large spike at 1. Quasi-likelihood techniques are more robust than maximum likelihood estimators. When applied to the EVALUATE trial, all but the maximum likelihood estimators produce unbiased estimates of the treatment effect. <bold>Conclusion</bold>. One and 2-part Beta regression models provide flexible approaches to regress the outcomes with truncated supports, such as HRQoL, on covariates, after accounting for many idiosyncratic features of the outcomes distribution. This work will provide applied researchers with a practical set of tools to model outcomes in cost-effectiveness analysis.</p>
</abstract>
<kwd-group>
<kwd>regression</kwd>
<kwd>quality of life</kwd>
<kwd>QALYs</kwd>
<kwd>Beta distribution</kwd>
<kwd>quasi-likelihood</kwd>
<kwd>Bayesian</kwd>
</kwd-group>
<custom-meta-wrap>
<custom-meta>
<meta-name>cover-date</meta-name>
<meta-value>January–February 2012</meta-value>
</custom-meta>
</custom-meta-wrap>
</article-meta>
</front>
<body>
<p>In cost-effectiveness analysis (CEA), treatment effects on costs and health outcomes and the heterogeneity in these effects across observed patients’ characteristics are often estimated using regression estimators. A large literature exists on how to develop and identify appropriate regression models for cost data, primarily developed to deal with the idiosyncrasies in the distribution of costs (e.g., nonnegative values, skewness to the right, and heteroskedasticity), features that make additive models and ordinary least squares (OLS) regression inapplicable to such data.<sup><xref ref-type="bibr" rid="bibr1-0272989X11416988">1</xref>–<xref ref-type="bibr" rid="bibr5-0272989X11416988">5</xref></sup> However, less attention has been paid to the appropriate use of regression estimators on the health outcomes side of the cost-effectiveness equation, especially when dealing with generic health-related quality of life (HRQoL) and quality-adjusted life years (QALYs),<sup><xref ref-type="fn" rid="fn1-0272989X11416988">a</xref></sup> despite these sharing many of the idiosyncrasies observed in cost data.</p>
<p>HRQoL data are typically characterized by a truncated support at both ends of the distribution (usually ranging between 0 and 1). They are typically negatively skewed, with most of the sample’s HRQoL values lying at the higher end of the measurement scale and some observations displaying extremely low levels of HRQoL. In fact, much like cost data, where there usually is a spike at 0, we often see a spike at 1 in HRQoL data. Examples of these are data generated from the EQ5D<sup><xref ref-type="bibr" rid="bibr6-0272989X11416988">6</xref></sup> and SF6D<sup><xref ref-type="bibr" rid="bibr7-0272989X11416988">7</xref></sup> instruments. Right-skewed distributions of HRQoL are occasionally observed among certain groups of patients (e.g., terminally ill patients or individuals with chronic conditions) where most of the individuals in the sample report poor health states. Spikes at 0 in such cases are usually not observed. In any case, heteroskedasticity is an integral part of such limited dependent variables.</p>
<p>The primary goal of this article is to develop a particular class of regression models based on Beta distribution (originally proposed by Mullahy<sup><xref ref-type="bibr" rid="bibr8-0272989X11416988">8</xref></sup> for such applications) to address the aforementioned characteristics of the HRQoL data.<sup><xref ref-type="fn" rid="fn2-0272989X11416988">b</xref></sup> Although a wider range of regression models has been proposed to analyze HRQoL data,<sup><xref ref-type="bibr" rid="bibr9-0272989X11416988">9</xref>–<xref ref-type="bibr" rid="bibr13-0272989X11416988">13</xref></sup> we compare the performance of the proposed models only against OLS regression. There are 2 main reasons for this: 1st because OLS has been used in the majority of the applications that analyzed HRQoL and QALYs, and 2nd because recent simulation studies<sup><xref ref-type="bibr" rid="bibr14-0272989X11416988">14</xref></sup> found OLS to be superior to many of the alternative approaches that have been proposed. The Beta distribution is a very flexible starting point in that it allows modeling left and right skewed (and heteroskedastic) distributed outcomes.</p>
<p>All our regression models fall under the purview of the generalized linear model (GLM),<sup><xref ref-type="bibr" rid="bibr15-0272989X11416988">15</xref>–<xref ref-type="bibr" rid="bibr17-0272989X11416988">17</xref></sup> although we often do not rely on full distributional assumption. For example, we study the quasi-likelihood estimator for a Beta-based mean-variance model that is similar to maximizing a Bernoulli likelihood function. Such regressions are also popular in the econometrics literature under the name of “fractional models.”<sup><xref ref-type="bibr" rid="bibr17-0272989X11416988">17</xref></sup> Our choice is dictated by the fact that a Beta regression model has been found to be superior to alternative regression strategies in comparative studies,<sup><xref ref-type="bibr" rid="bibr18-0272989X11416988">18</xref>,<xref ref-type="bibr" rid="bibr19-0272989X11416988">19</xref></sup> although full distributional assumptions for the Beta distribution have been found to be restrictive.<sup><xref ref-type="bibr" rid="bibr20-0272989X11416988">20</xref></sup></p>
<p>The rationale for moving beyond a standard linear regression model, often estimated using least squares minimization, is that predictions from such a model are never guaranteed to lie within the unit interval even when nonlinearity in responses may be addressed using added interaction terms. Consequently, these out-of-range predictions may yield inconsistent estimates of covariate effects. For binary data, similar limitations of the linear probability models have led to the development of the <italic>logit</italic> and the <italic>probit</italic> models.</p>
<p>We propose both a single equation and a 2-part version of the Beta regression estimator, with the 2-part model extension developed to address the challenges posed by the presence of a spike at 1 in the HRQoL distribution. This article defines incremental and marginal effects of covariates on the mean HRQoL and shows how to estimate these effects and associated standard errors. Algorithms based on maximum-likelihood estimation (MLE), quasi-likelihood estimation (QMLE) and Bayesian Markov-chain Monte Carlo (McMC) estimation methods are presented. We also propose a novel Bayesian QMLE approach to model such data. Relevant codes to implement these methods are produced in STATA<sup><xref ref-type="bibr" rid="bibr21-0272989X11416988">21</xref></sup> (for the MLE and QMLE) and WinBUGs<sup><xref ref-type="bibr" rid="bibr22-0272989X11416988">22</xref></sup> (for McMC estimation) and reported in the Web appendix. Finally, we discuss choice among alternative estimators through a variety of goodness of fit measures.</p>
<p>In the next section, we motivate the readers by illustrating a typical HRQoL distribution that arises within a randomized controlled clinical trial context. We then build on this early example to compare the effect of alternative regression models in estimating treatment effects on HRQoL. We further motivate the reader by illustrating a variety of shapes that HRQoL distributions can take in real applications. The article lays out the model’s definition, basic assumptions, and estimation methods for model parameters and the marginal and incremental effects. Next, we present a simulation study comparing the performance of the proposed estimators under different data generating processes. Finally, we illustrate the application of the proposed method to the analysis of HRQoL data from the case study presented.</p>
<sec id="section1-0272989X11416988">
<title>Observed Distribution of HRQOL and QALYs in Real Applications</title>
<p>The EVALUATE trial is the largest comparison of laparoscopic-assisted hysterectomy with standard methods yet undertaken. Details of the results of the clinical and economic analyses from the trial have been published elsewhere.<sup><xref ref-type="bibr" rid="bibr23-0272989X11416988">23</xref>,<xref ref-type="bibr" rid="bibr24-0272989X11416988">24</xref></sup> The time horizon for this initial analysis was 1 year. In this article, we revisit the comparative effectiveness of abdominal laparoscopic-assisted hysterectomy (ALH; <italic>n</italic> = 487) relative to abdominal hysterectomy (AH; <italic>n</italic> = 263) in women for whom the latter would be the conventional procedure of choice. QALYs were calculated, for each participant in the trial, on the basis of her responses to the EQ 5D<sup><xref ref-type="bibr" rid="bibr6-0272989X11416988">6</xref></sup> at baseline and at up to 3 points post-operatively (6 weeks, 4 months, and 1 year). Given the time horizon of the analysis, total QALYs remained undiscounted. Administrative censoring will be ignored in the present application for simplicity.</p>
<p><xref ref-type="table" rid="table1-0272989X11416988">Table 1</xref> reports the descriptive statistics for the baseline characteristics of patients in the trial as well as their total QALY for the comparison of interest. <xref ref-type="fig" rid="fig1-0272989X11416988">Figure 1</xref> shows the histogram of the QALY by treatment groups. Within each treatment group, QALYs were negatively skewed. The QALY distribution in the ALH group appears to have a greater skewness and kurtosis than the AH group (ALH: skewness = −1.9, kurtosis = 7.6; AH: skewness = −2.4, kurtosis = 12.0).</p>
<fig id="fig1-0272989X11416988" position="float">
<label>Figure 1</label>
<caption><p>Distribution of QALYs by treatment arms of abdominal hysterectomy and laparoscopic-assisted hysterectomy in the EVALUATE trial.</p></caption>
<graphic xlink:href="10.1177_0272989X11416988-fig1.tif"/>
</fig>
<table-wrap id="table1-0272989X11416988" position="float">
<label>Table 1</label>
<caption><p>Baseline Characteristics of Patients in the EVALUATE Trial (Selected Covariates)</p></caption>
<graphic alternate-form-of="table1-0272989X11416988" xlink:href="10.1177_0272989X11416988-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">AH (<italic>n</italic> = 263)</th>
<th align="center">ALH (<italic>n</italic> = 487)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Smoker, %</td>
<td>51 (19.4)</td>
<td>58 (11.9)</td>
</tr>
<tr>
<td>Unexpected pathological abnormality, %</td>
<td>13 (4.9)</td>
<td>22 (4.5)</td>
</tr>
<tr>
<td>Age, y, <italic>x</italic> (<italic>s</italic>)</td>
<td>41.3 (7.65)</td>
<td>41.6 (6.94)</td>
</tr>
<tr>
<td>BMI, kg, <italic>x</italic> (<italic>s</italic>)</td>
<td>25.89 (5.49)</td>
<td>26.57 (5.15)</td>
</tr>
<tr>
<td>QALYs = 1, %</td>
<td>3 (1.1)</td>
<td>8 (1.6)</td>
</tr>
<tr>
<td>Total QALYs at 1 y, <italic>x</italic> (<italic>s</italic>)</td>
<td>0.861 (0.138)</td>
<td>0.870 (0.133)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0272989X11416988">
<p>AH, abdominal hysterectomy; ALH, abdominal laparoscopic-assisted hysterectomy; BMI, body mass index; QALY, quality-adjusted life year.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Other plausible HRQoL data distributions typically encountered in real practice are illustrated in <xref ref-type="fig" rid="fig2-0272989X11416988">Figure 2</xref>. These distributions jointly illustrate many of the idiosyncratic characteristics that we discussed in the introduction.</p>
<fig id="fig2-0272989X11416988" position="float">
<label>Figure 2</label>
<caption><p>Gallery of distributions for generic and health-related quality of life from selected clinical trials and observational studies.</p></caption>
<graphic xlink:href="10.1177_0272989X11416988-fig2.tif"/>
</fig>
</sec>
<sec id="section2-0272989X11416988">
<title>Regression Estimators for Quality of Life Data</title>
<sec id="section3-0272989X11416988">
<title>Model</title>
<p>Consider <italic>N iid</italic> observations ( Y<sub>i</sub>,X<sub>i</sub>), where <italic>Y<sub>i</sub></italic> is a nonnegative response variable with <italic>Y</italic> ϵ [0, 1],<sup><xref ref-type="fn" rid="fn3-0272989X11416988">c</xref></sup> and <italic>X<sub>i</sub></italic> = (<italic>X<sub>i1</sub>, …, X<sub>ip</sub></italic>)<sup><italic>T</italic></sup> is a vector of covariates that may include an intercept. Interest here is in modeling the mean function <inline-formula id="inline-formula1-0272989X11416988">
<mml:math display="inline" id="math1-0272989X11416988">
<mml:mrow>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>≡</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> and functionals thereof. Two particular models for the mean function are proposed: a single-equation and a 2-part model.</p>
<sec id="section4-0272989X11416988">
<title>Single-equation model</title>
<p>Letting µ<sub><italic>i</italic></sub> = µ(<italic>X<sub>i</sub></italic>), we posit a generalized linear model (GLM) wherein logit(µ<sub><italic>i</italic></sub>) = η<sub><italic>i</italic></sub>, <inline-formula id="inline-formula2-0272989X11416988">
<mml:math display="inline" id="math2-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mi>η</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo><mml:msubsup>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, and β is a <italic>p</italic> × 1 vector of regression parameters. Here, the <italic>logit</italic> link function is selected because of the unit-support of the outcome variable.<sup><xref ref-type="fn" rid="fn4-0272989X11416988">d</xref></sup> The <italic>logit</italic> is a strictly monotone differentiable link function that relates µ<sub><italic>i</italic></sub> to the linear predictor η<sub><italic>i</italic></sub>.</p>
<p>A special case of a single equation model is the linear model where the link function is <italic>identity</italic>, <inline-formula id="inline-formula3-0272989X11416988">
<mml:math display="inline" id="math3-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>η</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>.</p>
</sec>
<sec id="section5-0272989X11416988">
<title>Two-part model</title>
<p>As discussed earlier, HRQoL distributions often carry a spike at 1 (e.g., <xref ref-type="fig" rid="fig2-0272989X11416988">Figure 2a</xref>).<sup><xref ref-type="fn" rid="fn5-0272989X11416988">e</xref></sup> In such cases, modeling the complement <italic>Y</italic>′ = ( 1 − <italic>Y</italic>) is most convenient, in that the spike is moved to 0 and the overall expectation <italic>E</italic>(<italic>Y</italic>′) = (1 − <italic>E</italic>(<italic>Y</italic>)) is then given by:</p>
<p>
<disp-formula id="disp-formula1-0272989X11416988">
<mml:math display="block" id="math4-0272989X11416988">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>Pr</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo>&gt;</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo>|</mml:mo>
<mml:msup>
<mml:mi>Y</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mo>&gt;</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq1.tif"/>
</disp-formula>
</p>
<p>For each individual <italic>i</italic>, Pr(Y′<sub><italic>i</italic></sub> &gt; 0) can be modeled using a traditional <italic>logit</italic> or <italic>probit</italic> model, whereas <italic>E</italic>(<italic>Y</italic>′<sub><italic>i</italic></sub>|Y′<sub><italic>i</italic></sub> &gt; 0) can be modeled using the GLM described above.</p>
</sec>
</sec>
<sec id="section6-0272989X11416988">
<title>Parameters Estimation in the Single-Equation Model</title>
<p>For a linear model, the traditional estimation technique follows the least squares (LQ) regression, which is semiparametric in nature. Coefficient estimates are obtained by minimizing the sum of squares of residuals from the regression model, that is, <inline-formula id="inline-formula4-0272989X11416988">
<mml:math display="inline" id="math5-0272989X11416988">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mi>arg</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mi>min</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula>. Although it is not required that <italic>Y</italic> be normally distributed for such a least squares estimation method, the support of <italic>Y</italic> is not assumed to be restricted and therefore may not properly represent the distribution of <italic>Y</italic> that naturally has a (0,1) range.</p>
<p>As indicated in the introduction, the Beta distribution is a natural candidate for modeling the distribution of <italic>Y</italic> as it supports the (0,1) range, while handling both negatively and positively skewed distributions. Assuming that <italic>Y<sub>i</sub></italic> ~ <italic>Beta</italic>(µ<sub><italic>i</italic></sub>, φ), with mean µ<sub><italic>i</italic></sub> = <italic>E</italic>(<italic>Y<sub>i</sub></italic>), µ<sub><italic>i</italic></sub> ∊ [0, 1], and variance</p>
<p>
<disp-formula id="disp-formula2-0272989X11416988">
<mml:math display="block" id="math6-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>φ</mml:mi>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq2.tif"/>
</disp-formula>
</p>
<p>with φ = 1/(1 + ξ) representing the over-dispersion term, one can write the Beta density function as<sup><xref ref-type="fn" rid="fn6-0272989X11416988">f</xref></sup>:</p>
<p>
<disp-formula id="disp-formula3-0272989X11416988">
<mml:math display="block" id="math7-0272989X11416988">
<mml:mrow>
<mml:mtext>f</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>Yi</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mspace width="0.5em"/>
<mml:mi>α</mml:mi>
<mml:mspace width="0.5em"/>
<mml:msubsup>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mi>ξ</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq3.tif"/>
</disp-formula>
</p>
<p>One obvious caveat of the Beta distribution standard formulation is that by definition it excludes the values 0 and 1 from its support, that is, <italic>Y</italic> ∊ (0, 1). However, this limitation can be overcome using quasi-likelihood techniques that do not require the full distributional characteristics of the Beta but only its 1st and 2nd moments (as described below).</p>
<p>It is interesting to contrast the likelihood function in (3) to that of a Bernoulli likelihood where <inline-formula id="inline-formula5-0272989X11416988">
<mml:math display="inline" id="math8-0272989X11416988">
<mml:mrow>
<mml:mi>f</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mspace width="0.5em"/>
<mml:mi>α</mml:mi>
<mml:mspace width="0.5em"/>
<mml:msubsup>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msubsup>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula>. Although the maximum likelihood estimator for these 2 distributions may be dissimilar, quasi-likelihood estimators, as shown below, are identical as they share the same mean and variance function models.</p>
<sec id="section7-0272989X11416988">
<title>Estimation using maximum likelihood (Beta-MLE)</title>
<p>Parameters estimation in the Beta regression can be carried out via maximum-likelihood (ML) techniques. The log likelihood function of the Beta, following <xref ref-type="disp-formula" rid="disp-formula3-0272989X11416988">Equation 3</xref>, can be written as</p>
<p>
<disp-formula id="disp-formula4-0272989X11416988">
<mml:math display="block" id="math9-0272989X11416988">
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:msub>
<mml:mi>L</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>constant</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mo>+</mml:mo>
<mml:mspace width="0.5em"/>
<mml:mi>ln</mml:mi>
<mml:mi>Γ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>ln</mml:mi>
<mml:mi>Γ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>ln</mml:mi>
<mml:mi>Γ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>⋅</mml:mo>
<mml:mi>ln</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo>⋅</mml:mo>
<mml:mi>ln</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq4.tif"/>
</disp-formula>
</p>
<p>One can solve for the parameter values using the 1st and the 2nd derivatives of the log-likelihood function with respect to the parameters and follow a Newton-Raphson or a Fisher scoring algorithm for the maximum estimation procedure. As evident from <xref ref-type="disp-formula" rid="disp-formula4-0272989X11416988">Equation 4</xref>, values of 0 and 1 cannot be supported by the distribution of <italic>Y</italic>. A computational solution to this problem often used in practice is to add a very small positive (negative) noise (~1.0E-06) to values of 0 (1) to facilitate the MLE (this is automatically implemented in our STATA code). The same solution can be implemented for Bayesian estimation purposes as described below.</p>
</sec>
<sec id="section8-0272989X11416988">
<title>Estimation using quasi-likelihood (Beta-QMLE)</title>
<p>The quasi-likelihood approach can overcome the problems of excluding values of 0 and 1 in the Beta regression. It also relaxes dependence on the full distributional assumption as in the maximum likelihood-based estimator. In the quasi-likelihood approach, the regression parameters are estimated using the well-known quasi-score equations<sup><xref ref-type="bibr" rid="bibr15-0272989X11416988">15</xref></sup>:</p>
<p>
<disp-formula id="disp-formula5-0272989X11416988">
<mml:math display="block" id="math10-0272989X11416988">
<mml:mrow>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>β</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq5.tif"/>
</disp-formula>
</p>
<p>McCullagh and Nelder<sup><xref ref-type="bibr" rid="bibr16-0272989X11416988">16</xref></sup> showed that solving <xref ref-type="disp-formula" rid="disp-formula5-0272989X11416988">Equation 5</xref> is equivalent to maximizing a quasi-likelihood function that behaves in many ways as a likelihood function for the regression parameters. Note that using the mean-variance relationship of a Beta distribution generates a quasi-score equation (given in <xref ref-type="disp-formula" rid="disp-formula5-0272989X11416988">Equation 5</xref>) that is identical to the maximum likelihood score equation under a Bernoulli likelihood function<sup><xref ref-type="bibr" rid="bibr17-0272989X11416988">17</xref></sup> with an additional overdispersion parameter ξ.</p>
<p>We use estimating functions <inline-formula id="inline-formula6-0272989X11416988">
<mml:math display="inline" id="math11-0272989X11416988">
<mml:mrow>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>ξ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> for the overdispersion parameter ξ that is unbiased and therefore provide consistent estimators of ξ under the assumption that the mean model µ<sub><italic>i</italic></sub> and the variance model <italic>h</italic>(µ<sub><italic>i</italic></sub>;ξ) are correct.<sup><xref ref-type="bibr" rid="bibr25-0272989X11416988">25</xref>,<xref ref-type="bibr" rid="bibr26-0272989X11416988">26</xref><xref ref-type="fn" rid="fn7-0272989X11416988">g</xref></sup></p>
<p>
<disp-formula id="disp-formula6-0272989X11416988">
<mml:math display="block" id="math12-0272989X11416988">
<mml:mrow>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>ξ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mo stretchy="false">[</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">]</mml:mo>
<mml:msubsup>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>V</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mo>∂</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mi>j</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq6.tif"/>
</disp-formula>
</p>
<p>Define <inline-formula id="inline-formula7-0272989X11416988">
<mml:math display="inline" id="math13-0272989X11416988">
<mml:mrow>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:mo>…</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mi>p</mml:mi>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>ξ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mi>T</mml:mi>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula> and the extended estimating function for γ as <inline-formula id="inline-formula8-0272989X11416988">
<mml:math display="inline" id="math14-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>. We estimate γ by solving for <italic>G<sub>γ</sub></italic> = 0, which yields the estimator <inline-formula id="inline-formula9-0272989X11416988">
<mml:math display="inline" id="math15-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>N</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. Under mild regularity conditions, <inline-formula id="inline-formula10-0272989X11416988">
<mml:math display="inline" id="math16-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>N</mml:mi>
</mml:msub>
<mml:mover>
<mml:mo>→</mml:mo>
<mml:mi>p</mml:mi>
</mml:mover>
<mml:msub>
<mml:mi>γ</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> as <italic>N</italic> → ∞ and <inline-formula id="inline-formula11-0272989X11416988">
<mml:math display="inline" id="math17-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>N</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>γ</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is asymptotically normal with mean 0 and covariance matrix <bold>A</bold><sub><italic>N</italic></sub> given by</p>
<p>
<disp-formula id="disp-formula7-0272989X11416988">
<mml:math display="block" id="math18-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mi>A</mml:mi>
<mml:mi>N</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>−</mml:mo>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
</mml:msub>
<mml:mo>/</mml:mo>
<mml:mo>∂</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mfrac>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
<mml:mo>(</mml:mo>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>)</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>−</mml:mo>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
</mml:msub>
<mml:mo>/</mml:mo>
<mml:mo>∂</mml:mo>
<mml:mi>γ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq7.tif"/>
</disp-formula>
</p>
<p>Replacing by <inline-formula id="inline-formula12-0272989X11416988">
<mml:math display="inline" id="math19-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>N</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> and <inline-formula id="inline-formula13-0272989X11416988">
<mml:math display="inline" id="math20-0272989X11416988">
<mml:mrow>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> with <inline-formula id="inline-formula14-0272989X11416988">
<mml:math display="inline" id="math21-0272989X11416988">
<mml:mrow>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msubsup>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>γ</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula> in the above equation yields a sandwich estimator of the variance-covariance of <inline-formula id="inline-formula15-0272989X11416988">
<mml:math display="inline" id="math22-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>N</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula>.<sup><xref ref-type="bibr" rid="bibr27-0272989X11416988">27</xref>,<xref ref-type="bibr" rid="bibr28-0272989X11416988">28</xref></sup></p>
</sec>
<sec id="section9-0272989X11416988">
<title>Estimation using Bayesian McMC</title>
<p>There are several advantages (and some potential caveats) associated with estimating the proposed models within a Bayesian framework. These have been well rehearsed in various textbooks (see, for instance, Reference 29) and more recently by Luce and O’Hagan.<sup><xref ref-type="bibr" rid="bibr30-0272989X11416988">30</xref></sup> Briefly, compared with frequentist methods, a Bayesian approach (1) offers a more natural and intuitive framework for statistical inference; (2) can make use of all existing evidence prior to the experiment by using prior distributions; (3) can address more complex models (that sometimes cannot be examined under a standard classical framework); and (4) it is ideal for decision making given the way we can interpret the output of Bayesian analyses. However, one may need to be very careful when using Bayesian methods to make sure that subjectivity is not an issue and the application of the methods is as transparent as it can possibly be.</p>
<p>Traditional Bayesian models usually assume parametric distributions for the outcomes of interest. For example, for modeling outcomes such as the generic HRQoL measure EQ5D, one can assume that the outcome follows a Beta distribution. However, following the quasi-likelihood principle, it is often more robust to relax such distribution assumptions. Because quasi-likelihood estimation based on Beta distribution corresponds to a Bernoulli likelihood model, one can “trick” the WinBUGS software to implement a quasi-likelihood estimator.[<xref ref-type="bibr" rid="bibr31-0272989X11416988">31</xref>] We present both versions here.</p>
<p>(a) Bayesian Beta-MLE:</p>
<p>The Bayesian Beta regression model can be expressed as</p>
<p><disp-formula id="disp-formula8-0272989X11416988">
<mml:math display="block" id="math23-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mi>ξ</mml:mi>
<mml:mo>,</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>≡</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mtext>logi</mml:mtext>
<mml:msup>
<mml:mtext>t</mml:mtext>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq8.tif"/>
</disp-formula>
</p>
<p>Following the likelihood function in <xref ref-type="disp-formula" rid="disp-formula3-0272989X11416988">Equation 3</xref>, the posterior joint distribution for (β, ξ) is given as</p>
<p><disp-formula id="disp-formula9-0272989X11416988">
<mml:math display="block" id="math24-0272989X11416988">
<mml:mrow>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:msup>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∫</mml:mo>
</mml:mstyle>
<mml:mtext>​</mml:mtext>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>d</mml:mi>
<mml:mi>β</mml:mi>
<mml:mi>d</mml:mi>
<mml:mi>ξ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mi>∞</mml:mi>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∏</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:munderover>
<mml:mi>Γ</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msup>
<mml:mo>.</mml:mo>
<mml:mi>Γ</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>.</mml:mo>
<mml:mi>Γ</mml:mi>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:msubsup>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
<mml:mrow>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>ξ</mml:mi>
</mml:mrow>
</mml:msubsup>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msup>
<mml:mo>×</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>⋅</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq9.tif"/>
</disp-formula>
</p>
<p>For priors, we assume <italic>p</italic>(β, ξ) = <italic>p</italic>(β) <italic>p</italic>(ξ) and define vague priors on the unknown parameters. More specifically, the regression coefficients β are assigned normal distributions with mean 0 and large variance (see the code in appendix). Similarly, instead of specifying a prior for ξ, one can directly specify a prior for the overdispersion parameter φ = 1/(1 + ξ), which can be assumed to follow a gamma or a uniform distribution with large dispersion.</p>
<p>This model can be estimated in Bayesian terms using McMC simulation techniques,<sup><xref ref-type="bibr" rid="bibr32-0272989X11416988">32</xref></sup> via the freely available software WinBUGS 1.4.3,<sup><xref ref-type="bibr" rid="bibr22-0272989X11416988">22</xref></sup> by iterative sampling of the full conditional distributions <italic>p</italic>(β | ξ, <italic>y</italic>) \propto <italic>L</italic>(β, ξ) <italic>p</italic>(β) and <italic>p</italic>(ξ |β, <italic>y</italic>) \propto <italic>L</italic>(β, ξ) <italic>p</italic>(ξ) . Posterior inference for the parameter β, ξ and the mean response µ(x) can be easily obtained in WinBUGS.</p>
<p>(b) Bayesian Beta-QMLE:</p>
<p>The idea behind Bayesian QMLE is to specify a Bernoulli-type likelihood for maximization. Because our outcome variable is not a 0/1 (binary) variable, we follow the zeros-trick in WinBUGS to implement this.</p>
<p>First, we create a new variable <italic>Z<sub>i</sub></italic> that takes the value of 0 for all observations; then we specify the following model:</p>
<p><disp-formula id="disp-formula10-0272989X11416988">
<mml:math display="block" id="math25-0272989X11416988">
<mml:mrow>
<mml:mtable columnalign="left">
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:msub>
<mml:mi>Z</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mi>λ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>∼</mml:mo>
<mml:mi>P</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>n</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>λ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:msub>
<mml:mi>λ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>⋅</mml:mo>
<mml:mtext>ln</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>⋅</mml:mo>
<mml:mtext>ln</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:msub>
<mml:mi>µ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>≡</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mtext>logi</mml:mtext>
<mml:msup>
<mml:mtext>t</mml:mtext>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>x</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq10.tif"/>
</disp-formula>
</p>
<p>Because the likelihood for the Poisson distribution when <italic>Z<sub>i</sub></italic> = 0 is given by <inline-formula id="inline-formula16-0272989X11416988">
<mml:math display="inline" id="math26-0272989X11416988">
<mml:mrow>
<mml:msup>
<mml:mi>e</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>λ</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula>, maximizing the Poisson likelihood corresponds to maximizing the Bernoulli likelihood given by the 2nd expression in <xref ref-type="disp-formula" rid="disp-formula10-0272989X11416988">Equation 10</xref>.</p>
<p>All priors are specified the same way as in the Bayesian MLE estimation.</p>
</sec>
</sec>
<sec id="section10-0272989X11416988">
<title>Parameters Estimation in the 2-Part Model</title>
<p>Estimation for the 2nd part of the 2-part model follows the same estimation methods described under single-equation models (LQ, Beta-MLE, Beta-QMLE, Bayesian Beta-MLE and Bayesian Beta-QMLE).</p>
<p>For the 1st part of the 2-part model, one can use a traditional logistic regression to model the 0/1 binary outcome. The logistic regression can be implemented either by using a full maximum likelihood method, quasi-likelihood estimation technique or by using Bayesian analogs of these methods. Details of estimating a logistic regression using these methods are standard practice and their details can be found elsewhere.<sup><xref ref-type="bibr" rid="bibr33-0272989X11416988">33</xref></sup></p>
</sec>
<sec id="section11-0272989X11416988">
<title>Estimation of Marginal and Incremental Effects</title>
<p>Because the regression coefficients from single and 2-part models have different interpretations, it is useful to focus on a metric that would be comparable across models. The marginal and incremental effects of a covariate on outcomes on their original scale are 2 such metrics. The estimation of marginal and incremental effects follows the procedures detailed in Basu and Rathouz.<sup><xref ref-type="bibr" rid="bibr26-0272989X11416988">26</xref></sup> The marginal effect, ψ<sub><italic>j</italic></sub> of any continuous covariate <italic>X<sub>j</sub></italic> on <italic>Y</italic> is the estimated partial derivative of µ(<italic>x<sub>i</sub></italic>) with respect to a covariate <italic>X<sub>j</sub></italic>, averaged over all <italic>i</italic>. For the single-equation model proposed, an estimator of the marginal effect is given by</p>
<p><disp-formula id="disp-formula11-0272989X11416988">
<mml:math display="block" id="math27-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>E</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>x</mml:mi>
</mml:msub>
<mml:mo>{</mml:mo>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>X</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mo>{</mml:mo>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>X</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula11-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq11.tif"/>
</disp-formula>
</p>
<p>Here the hat ^ on <inline-formula id="inline-formula17-0272989X11416988">
<mml:math display="inline" id="math28-0272989X11416988">
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> indicates that the β coefficients have been estimated and the hat on Ê<sub><italic>X</italic></sub> indicates that the sample expected value has replaced the population expected value. To estimate the incremental effect, Δ<sub><italic>j</italic></sub> of an indicator variable <italic>X<sub>j</sub></italic>, we use the method of <italic>recycled predictions</italic>.<sup><xref ref-type="bibr" rid="bibr34-0272989X11416988">34</xref></sup> This method estimates Δ<sub><italic>j</italic></sub> as</p>
<p><disp-formula id="disp-formula12-0272989X11416988">
<mml:math display="block" id="math29-0272989X11416988">
<mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Δ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mo>{</mml:mo>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula12-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq12.tif"/>
</disp-formula>
</p>
<p>where <italic>X<sub>i, −j</sub></italic> represents the vector of all other <italic>X</italic>’s except for <italic>X<sub>i,j</sub></italic>. Robust variance estimators for the marginal and incremental effect estimators can be obtained using Taylor series approximations (formulas are given in the appendix). Alternatively, variance estimators can be obtained by using nonparametric methods such as bootstrap or by using McMC.</p>
<p>For the 2-part model, the marginal effect is computed using the chain rule used in expressing the partial derivative of a product. Specifically, if <inline-formula id="inline-formula18-0272989X11416988">
<mml:math display="inline" id="math30-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula19-0272989X11416988">
<mml:math display="inline" id="math31-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math></inline-formula> are the predicted means and <inline-formula id="inline-formula20-0272989X11416988">
<mml:math display="inline" id="math32-0272989X11416988">
<mml:mover accent="true">
<mml:mi>α</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> and <inline-formula id="inline-formula21-0272989X11416988">
<mml:math display="inline" id="math33-0272989X11416988">
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math></inline-formula> are the estimated coefficients from the 2 parts, respectively, then an estimator of the marginal effect is given by</p>
<p><disp-formula id="disp-formula13-0272989X11416988">
<mml:math display="block" id="math34-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>⋅</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>α</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>X</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mover accent="true">
<mml:mi>α</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>⋅</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msup>
<mml:mi>X</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula13-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq13.tif"/>
</disp-formula>
</p>
<p>An estimate of the incremental effect in a 2-part model is identical to that given in <xref ref-type="disp-formula" rid="disp-formula12-0272989X11416988">Equation 12</xref>, where <inline-formula id="inline-formula22-0272989X11416988">
<mml:math display="inline" id="math35-0272989X11416988">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>.</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>,</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>k</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. Again, standard errors for these effects in 2 part models can be more conveniently estimated via simulation methods (e.g., bootstrap or McMC).</p>
</sec>
</sec>
<sec id="section12-0272989X11416988">
<title>Simulations</title>
<sec id="section13-0272989X11416988">
<title>Designs</title>
<p>Our primary goal is to estimate the effect of a continuous covariate <italic>X</italic> on the outcome <italic>Y</italic> ∊ [0, 1]. We generate <italic>X</italic> using a uniform distribution between 0 and 1 and <italic>Y</italic> following a variety of distributions. The data generating mechanisms (DGPs) for Y are broadly grouped into 2 sets. In the 1st set, the true marginal effect of a standard-deviation change in <italic>X</italic> was designed to be much greater than 0.03. In the 2nd set, the data were designed for a true marginal effect of a standard deviation change in <italic>X</italic> to be less than 0.03. The 0.03 cutoff was chosen arbitrarily, with the primary rationale being that in outcome distributions that are truncated at both sides, the effect of a covariate is usually small, in which case the biases due to model misspecification may not appear so obvious. Each of the DGP from either DGP set carries the typical idiosyncratic characteristics of HRQoL data described in the introduction.</p>
<p>Specifically, the following data generating processes were used:</p>
<list id="list1-0272989X11416988" list-type="simple">
<list-item>
<p>SET 1</p>
<p><disp-formula id="disp-formula14-0272989X11416988">
<mml:math display="block" id="math36-0272989X11416988">
<mml:mrow>
<mml:mtable columnalign="left">
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>DGP</mml:mtext>
<mml:mn>1</mml:mn>
<mml:mo>:</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>DGP</mml:mtext>
<mml:mn>2</mml:mn>
<mml:mo>:</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>DGP</mml:mtext>
<mml:mn>3</mml:mn>
<mml:mo>:</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>⋅</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>p</mml:mi>
<mml:mo>⋅</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>where</mml:mtext>
<mml:mspace style="0.5em"/>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mn>1</mml:mn>
</mml:msub>
<mml:mo>∼</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>and</mml:mtext>
<mml:mspace style="0.5em"/>
<mml:mi>p</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>U</mml:mi>
</mml:msub>
<mml:mo>{</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>20</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mi>U</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>U</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>f</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>m</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>;</mml:mo>
<mml:msub>
<mml:mi>F</mml:mi>
<mml:mi>U</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>C</mml:mi>
<mml:mi>D</mml:mi>
<mml:mi>F</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula14-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq14.tif"/>
</disp-formula>
</p>
</list-item>
</list>
<p>Interest lies in estimating the marginal effect of <italic>X</italic> on <italic>Y</italic>: Δ = <italic>E<sub>X</sub></italic>{∂<italic>E</italic>(<italic>Y</italic>|<italic>X</italic>)/∂<italic>X</italic>. The true values for this quantity are −0.833, −0.493, and 0.673, respectively, and the corresponding values for a standard deviation change in <italic>X</italic> are −0.24, −0.14, and 0.19, respectively.</p>
<list id="list2-0272989X11416988" list-type="simple">
<list-item><p>SET 2</p>
<p><disp-formula id="disp-formula15-0272989X11416988">
<mml:math display="block" id="math37-0272989X11416988">
<mml:mrow>
<mml:mtable columnalign="left">
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>DGP</mml:mtext>
<mml:mn>4</mml:mn>
<mml:mo>:</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>DGP</mml:mtext>
<mml:mn>5</mml:mn>
<mml:mo>:</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>01</mml:mn>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>E</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>|</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>/</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>3</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>·</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtext>DGP</mml:mtext>
<mml:mn>6</mml:mn>
<mml:mo>:</mml:mo>
<mml:mi>Y</mml:mi>
<mml:mo>∼</mml:mo>
<mml:mi>A</mml:mi>
<mml:mspace style="0.5em"/>
<mml:mi>m</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>x</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>u</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>f</mml:mi>
<mml:mspace style="0.5em"/>
<mml:mo stretchy="false">[</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>01</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">]</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mtext>with probability</mml:mtext>
<mml:mspace style="0.5em"/>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>20</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mtable columnalign="left">
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>10</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mtext>with probability</mml:mtext>
<mml:mspace style="0.5em"/>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>20</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>20</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>5</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mtext>with probability</mml:mtext>
<mml:mspace style="0.5em"/>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>40</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mtext>and</mml:mtext>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr columnalign="left">
<mml:mtd columnalign="left">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>50</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>B</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>t</mml:mi>
<mml:mi>a</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>exp</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>3</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>⋅</mml:mo>
<mml:mi>X</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mspace style="0.5em"/>
<mml:mtext>with probability</mml:mtext>
<mml:mspace style="0.5em"/>
<mml:mn>0.20.</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula15-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq15.tif"/>
</disp-formula>
</p>
</list-item>
</list>
<p>Again, interest lies in estimating the marginal effect of <italic>X</italic> on <italic>Y</italic>: Δ = <italic>E<sub>X</sub></italic>{∂<italic>E</italic>(<italic>Y</italic>|<italic>X</italic>)/∂<italic>X</italic>. The true values for this quantity are −0.063, −0.068, and −0.087, respectively, and the corresponding values for a standard deviation change in <italic>X</italic> are −0.02, −0.02, and 0.025, respectively.</p>
</sec>
<sec id="section14-0272989X11416988">
<title>Estimators</title>
<p>We compare the performance of 5 estimators using a single equation model under each DGP. These estimators are (1) simple OLS regression with an identify link, (2) Beta MLE, (3) Beta QMLE, (4) Bayesian-Beta MLE, and (5) Bayesian-Beta QMLE, which are described in above. Under DGPs 3 and 5, because of the spike at 0 in the distribution of <italic>Y</italic>, we additionally run 2 estimators for a 2-part model : (6) 1st part logistic regression and 2nd part Beta QMLE and (7) 1st part Bayesian logistic regression and 2nd part Bayesian-Beta QMLE, which are described above. We also study the use of Beta-MLE for the 2-part model but do not present results for clarity because the results for Beta-MLE from the single equation models carry over to the 2-part ones.</p>
</sec>
<sec id="section15-0272989X11416988">
<title>Evaluations</title>
<p>We generate 1000 replicate samples of 500 each under each data-generating mechanism. For each replicate data set and under each of 5 different estimators (<italic>k</italic> = 1,2, . . ., 5), we estimate the marginal effect, <inline-formula id="inline-formula23-0272989X11416988">
<mml:math display="inline" id="math38-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> with respect to <italic>X</italic> that is computed using <xref ref-type="disp-formula" rid="disp-formula11-0272989X11416988">Equation 11</xref> or <xref ref-type="disp-formula" rid="disp-formula13-0272989X11416988">13</xref>. For Bayesian estimations, we run 3 chains and discard the 1st 5000 iterations from each chain as burn-ins. We then compute the posterior mean of the parameters over the next 10,000 replicates from each chain that were sampled with a thinning of 5.<sup><xref ref-type="fn" rid="fn8-0272989X11416988">h</xref></sup> We report the percentage mean bias (and 95% confidence interval) in estimating ψ<sub><italic>k</italic></sub> under each method that is given by <inline-formula id="inline-formula24-0272989X11416988">
<mml:math display="inline" id="math39-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>k</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ψ</mml:mi>
<mml:mrow>
<mml:mi>T</mml:mi>
<mml:mi>r</mml:mi>
<mml:mi>u</mml:mi>
<mml:mi>e</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. (95% central confidence interval (CCI) calculated using the empirical distribution of <inline-formula id="inline-formula25-0272989X11416988">
<mml:math display="inline" id="math40-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>k</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> across replicates).</p>
<p>We also report and compare the root mean squared error (RMSE) for predictions, <inline-formula id="inline-formula26-0272989X11416988">
<mml:math display="inline" id="math41-0272989X11416988">
<mml:mrow>
<mml:msqrt>
<mml:mrow>
<mml:msup>
<mml:mi>n</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>⋅</mml:mo>
<mml:munder>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mi>i</mml:mi>
</mml:munder>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>k</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
</inline-formula>, under each model averaged over all replicates from a DGP. All work was done using Stata 10.0.<sup><xref ref-type="bibr" rid="bibr21-0272989X11416988">21</xref></sup> and WinBUGS 1.4.3.<sup><xref ref-type="bibr" rid="bibr22-0272989X11416988">22</xref></sup> Bayesian estimations were done on the same replicate data sets as other estimators. We use the winbugsfromstata package in Stata to iteratively call WinBUGS from within Stata 10.0, import the output from WinBUGS and produce graphics.<sup><xref ref-type="bibr" rid="bibr35-0272989X11416988">35</xref></sup></p>
</sec>
<sec id="section16-0272989X11416988">
<title>Results</title>
<p>Typical distributions arising from each of the 6 DGPs are summarized in <xref ref-type="fig" rid="fig3-0272989X11416988">Figure 3</xref>. DGP 1 generates a Beta distribution that is positively skewed; all the remaining DGPs generate distributions that are negatively skewed; DGP 6 generates a categorical distribution with multiple modes and DGPs 3 and 5 generate modified Beta distributions with a large spike at 1.</p>
<fig id="fig3-0272989X11416988" position="float">
<label>Figure 3</label>
<caption><p>Typical distributions for the data generating processes (DGPs) used in simulations.</p></caption>
<graphic xlink:href="10.1177_0272989X11416988-fig3.tif"/>
</fig>
<p><xref ref-type="table" rid="table2-0272989X11416988">Table 2</xref> presents our simulation results for the set 1 DGPs where the true marginal effects of a standard deviation change in <italic>X</italic> were all much greater than 0.03. We find that linear OLS provides biased results for estimating the marginal effect under DGPs 1, 2, and 3. The (single equation) Beta MLE does well in terms of bias and RMSE on data from DGPs 1 and 2 given that it is the minimum variance unbiased estimator (MVUE) for these data. However, Beta MLE shows statistically significant bias under DGP 3 as this does not correspond to a Beta distribution. The (single equation) Beta QMLE does reasonably well under all DGPs. The Bayesian counterparts of the (single equation) MLE and QMLE estimators mirror the results from the frequentist (single equation) Beta MLE and QMLE estimators. One surprising exception is that we find the (single equation) Bayesian MLE to generate biased estimates under DGP 2, which itself is a Beta distribution. The biases were consistent across alternative specification of priors; for example, we also tried the prior, exp(β)/(1+ exp(β)) ~ Uniform(0,1). The (single equation) Beta QMLE again performs well and shows no sign of bias. The 2-part models, both the frequentist and the Bayesian approach, perform better than any other estimator under DGP 3 where there was a large spike at 1.</p>
<table-wrap id="table2-0272989X11416988" position="float">
<label>Table 2</label>
<caption><p>Simulation Results for Set 1 DGPs</p></caption>
<graphic alternate-form-of="table2-0272989X11416988" xlink:href="10.1177_0272989X11416988-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Data</th>
<th align="center">DGP 1</th>
<th align="center">DGP 2</th>
<th align="center">DGP 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model</td>
<td>Estimators</td>
<td>Mean % Bias (95% CCI)</td>
<td>Mean % QALY (<italic>s</italic>) % Bias (95% CCI)</td>
<td>Mean % QALY (<italic>s</italic>) % Bias (95% CCI)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Linear OLS</td>
<td><bold>13.7 (9.9, 17.3)</bold></td>
<td><bold>−9.1 (−13.5, −4.7)</bold></td>
<td><bold>−12.3 (−22.9, −1.2)</bold></td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta MLE</td>
<td>−0.5 (−4.2, 3.5)</td>
<td>0.4 (−7.4, 8)</td>
<td><bold>67.7 (53.1, 80.1)</bold></td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta QMLE</td>
<td>0.01 (−3.9, 4.0)</td>
<td>0.1 (−7.7, 7.7)</td>
<td>−5.1 (−14.0, 4.2)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian MLE</td>
<td>−3.5 (−8.0, 0.9)</td>
<td><bold>−12.4 (−18.0, −6.9)</bold></td>
<td><bold>67.5 (56.2, 79.0)</bold></td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian QMLE</td>
<td>−0.1 (−4.8, 4.8)</td>
<td>−0.6 (−12.9, 7.7)</td>
<td>−5.2 (−13.7, 3.1)</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Beta QMLE</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.2 (−9.2, 10.2)</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Bayesian QMLE</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.05 (−8.4, 9.2)</td>
</tr>
<tr>
<td>Model</td>
<td>Estimators</td>
<td>RMSE</td>
<td>RMSE</td>
<td>RMSE</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Linear OLS</td>
<td>0.1051</td>
<td>0.0592</td>
<td>0.2268</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta MLE</td>
<td>0.0989</td>
<td>0.0222</td>
<td>0.2838</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta QMLE</td>
<td>0.0982</td>
<td>0.0221</td>
<td>0.2249</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian MLE</td>
<td>0.1004</td>
<td>0.0421</td>
<td>0.2835</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian QMLE</td>
<td>0.1011</td>
<td>0.0312</td>
<td>0.2256</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Beta QMLE</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.2244</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Bayesian QMLE</td>
<td align="center">—</td>
<td align="center">—</td>
<td>0.2251</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0272989X11416988">
<p>CCI, central confidence interval; DPG, data-generating mechanism; MLE, maximum-likelihood estimation; OLS, ordinary least squares; QMLE, quasi-likelihood estimation.</p>
</fn>
<fn id="table-fn3-0272989X11416988">
<p>The true values for the marginal effect under DGPs 1–3 are −0.833, −0.493, and 0.673, respectively. Boldface indicates significant bias at the 5% level.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In terms of efficiency, the RMSE for predictions were fairly similar across all estimators. The Bayesian estimators showed slightly higher RMSEs. However, the dispersion in estimating the marginal effect varied widely across estimators as evident from the 95% CCI for the biases. In DGPs 1 and 2, Bayesian QMLE produced slightly wider 95% CCI whereas in DGPs 3 the Bayesian QMLE produced better results.</p>
<p><xref ref-type="table" rid="table3-0272989X11416988">Table 3</xref> presents our simulation results for the 2nd set of DGPs where the true marginal effects of a standard deviation change in <italic>X</italic> were all less than 0.03. Here we find OLS to perform well and estimate the marginal effect without bias except under DGP 5, where there is a large spike at 1. Under DGP 5, both OLS and the MLE methods show significant bias. All estimators perform well under DGP 4, given the additive nature of the data generation process. In terms of efficiency, the RMSE for predictions were again fairly similar across all estimators.</p>
<table-wrap id="table3-0272989X11416988" position="float">
<label>Table 3</label>
<caption><p>Simulation Results for Set 2 DGPs</p></caption>
<graphic alternate-form-of="table3-0272989X11416988" xlink:href="10.1177_0272989X11416988-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center">Data</th>
<th align="center">DGP 4</th>
<th align="center">DGP 5</th>
<th align="center">DGP 6</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model</td>
<td>Estimators</td>
<td>Mean % Bias (95% CCI)</td>
<td>Mean % Bias (95% CCI)</td>
<td>Mean % Bias (95% CCI)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Linear OLS</td>
<td>−0.5 (−57.4, 59.4)</td>
<td><bold>−24.3 (−38.1, −8.9)</bold></td>
<td>−1.4 (−47.5, 46.7)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta MLE</td>
<td>4.1 (−47.4, 55.0)</td>
<td><bold>−36.3 (−50.2, −21.7)</bold></td>
<td>30.5 (−13, 71)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta QMLE</td>
<td>−0.4 (−57.4, 59.6)</td>
<td>0.9 (−22.9, 27.8)</td>
<td>−1.6 (−47.4, 46.6)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian MLE</td>
<td>2.75 (−47.0, 53.3)</td>
<td><bold>−14.0 (−26.7, −0.7)</bold></td>
<td>2.8 (−1.0, 5.7)</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian QMLE</td>
<td>−2.26 (−55.7, 55.3)</td>
<td>8.85 (−17.9, 37.8)</td>
<td>−0.06 (−5.4, 4.0)</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Beta QMLE</td>
<td align="center">—</td>
<td>−8.4 (−31.2, 17.2)</td>
<td align="center">—</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Bayesian QMLE</td>
<td align="center">—</td>
<td>2.0 (−23.2, 30.3)</td>
<td align="center">—</td>
</tr>
<tr>
<td>Model</td>
<td>Estimators</td>
<td>RMSE</td>
<td>RMSE</td>
<td>RMSE</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Linear OLS</td>
<td>0.1138</td>
<td>0.0263</td>
<td>0.1409</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta MLE</td>
<td>0.1139</td>
<td>0.0256</td>
<td>0.1413</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta QMLE</td>
<td>0.1138</td>
<td>0.0248</td>
<td>0.1410</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian MLE</td>
<td>0.1139</td>
<td>0.0267</td>
<td>0.1415</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian QMLE</td>
<td>0.1158</td>
<td>0.0266</td>
<td>0.1429</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Beta QMLE</td>
<td align="center">—</td>
<td>0.0249</td>
<td align="center">—</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Bayesian QMLE</td>
<td align="center">—</td>
<td>0.0266</td>
<td align="center">—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn4-0272989X11416988">
<p>CCI, central confidence interval; DPG, data-generating mechanism; MLE, maximum-likelihood estimation; OLS, ordinary least squares; QMLE, quasi-likelihood estimation.</p>
</fn>
<fn id="table-fn5-0272989X11416988">
<p>The true values for the marginal effect under DGPs 4–6 are −0.063, −0.068, and −0.087 respectively; Boldface indicates significant bias at the 5% level.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section17-0272989X11416988">
<title>Summary of Results</title>
<p>Our simulations show that 1- and 2-part Beta regression models, especially the quasi-likelihood estimators, provide flexible approaches to regress the mean of an outcome with truncated support such as HRQoL on a covariate. We find substantial benefits, both in terms of bias and efficiency, of these regression estimators over traditional OLS approaches.</p>
<p>The fact that (single equation) Beta-MLE and Beta-QMLE produce different results in DGPs 3 and 5 indicates that the issue is more than just misspecification of the <italic>logit</italic> mean function. Results from these DGPs highlight the advantage of QMLE over MLE methods.</p>
<p>Moreover, both the linear and the <italic>logit</italic> specifications only provide approximations to the conditional mean under DGP 6. However, both these approximations turn out to be good enough for estimating the marginal effect of <italic>X</italic> because the effect is small and the residual bias cannot be detected with any precision. In contrast, in DGP3, where both the linear and the <italic>logit</italic> specifications provide again approximations to the true mean function, the linear approximation fails whereas the <italic>logit</italic> is successful. Here, the bias with linear approximation is larger than that with the <italic>logit</italic> specification, and this bias is detected because the overall effect is large.</p>
<p>One can conclude that when the marginal effects of covariates are small, the biases in estimating marginal effect using OLS may also be small, even if OLS does not provide the optimal fit to the data. However, this luxury for OLS no longer holds when there is a large spike at 1. Overall, the Beta-based regression estimators and especially their quasi-likelihood based variants provide a flexible approach to model HRQoL data. In specific instances, it is quite possible that even the logit link used by the Beta-based regression may provide poor fit to the data. Therefore, a rigorous set of goodness of fit test should always be applied to study the appropriateness of a model and to choose among alternative estimators. We present a variety of such tests in our empirical section.</p>
</sec>
</sec>
<sec id="section18-0272989X11416988">
<title>Empirical Example</title>
<p>Let us now turn the attention to the case study introduced in section 2: the EVALUATE trial. Although the 2 groups are well balanced in many baseline characteristics, <xref ref-type="table" rid="table1-0272989X11416988">Table 1</xref> suggests that the laparoscopic-assisted arm (ALH) includes a higher proportion of current smokers and women who were found to have unexpected pathological abnormalities during surgery. In terms of QALYs—which is the outcome of interest here—a higher proportion of women in the ALH arm had a computed QALY of 1 at the end of the follow up period.</p>
<p>We applied the same regression methods used in our simulations and as discussed to the EVALUATE data. In addition to the treatment indicator, we adjusted for baseline values of smoking, unexpected pathological abnormality, age, and body mass index (<xref ref-type="table" rid="table1-0272989X11416988">Table 1</xref>). Specifically, we compare the performance of 5 estimators using a single equation model. These estimators are (1) simple OLS regression, (2) Beta MLE, (3) Beta QMLE, (4) Bayesian-Beta MLE, and (5) Bayesian-Beta QMLE. In addition we ran 2 estimators for a 2-part model: (6) 1st part logistic regression and 2nd part Beta QMLE and (7) 1st part Bayesian Logistic regression and 2nd part Bayesian-Beta QMLE, as described previously.</p>
<p><xref ref-type="table" rid="table4-0272989X11416988">Table 4</xref> reports the incremental (treatment effect) estimates together with the RMSE and the predicted QALYs (and related standard deviation) for each treatment group in the EVALUATE trial. To facilitate model comparison we evaluate the following goodness of fit criteria:</p>
<list id="list3-0272989X11416988" list-type="order">
<list-item><p>The mean residuals across deciles of the corresponding linear predictor <inline-formula id="inline-formula27-0272989X11416988">
<mml:math display="inline" id="math42-0272989X11416988">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>η</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mi>x</mml:mi>
<mml:mi>T</mml:mi>
</mml:msup>
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>. By looking at the pattern in the residuals as a function of <inline-formula id="inline-formula28-0272989X11416988">
<mml:math display="inline" id="math43-0272989X11416988">
<mml:mover accent="true">
<mml:mi>η</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> we can determine whether there is a systematic pattern of misfits in the forecasts. A formal version of this test is provided by the test of goodness of fit proposed by Hosmer and Lemeshow<sup><xref ref-type="bibr" rid="bibr36-0272989X11416988">36</xref></sup> and is implemented by using an <italic>F</italic>-test that the mean residuals across all 10 of the deciles are not significantly different from 0. Note that the original Hosmer and Lemeshow test was devised on a binary outcome whose mean possesses similar distributional characteristics as the mean of a fractional response. If the residual pattern is U-shaped, then there is evidence for a more nonlinear response than was assumed.</p></list-item>
<list-item><p>We present the Pearson correlation between the raw-scale (y-scale) residual and <inline-formula id="inline-formula29-0272989X11416988">
<mml:math display="inline" id="math44-0272989X11416988">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. If this statistic is significantly different from 0, then the model is providing a poor prediction of µ(<italic>x</italic>) .</p></list-item>
<list-item><p>A more parsimonious test for nonlinearity is Pregibon’s link test.<sup><xref ref-type="bibr" rid="bibr37-0272989X11416988">37</xref></sup> Based on the initial estimate of the regression coefficients, <inline-formula id="inline-formula30-0272989X11416988">
<mml:math display="inline" id="math45-0272989X11416988">
<mml:mover accent="true">
<mml:mi>η</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math></inline-formula> and its square are included as the only covariates in a 2nd version of the model. If there is no additional nonlinearity in the specification, then the coefficient on the square of the linear predictor should not be significantly different from 0.</p></list-item>
<list-item><p>Similar to the Link test, another test of misspecification is Ramsey’s reset test.<sup><xref ref-type="bibr" rid="bibr38-0272989X11416988">38</xref></sup> We run a modified version of the Reset test where <inline-formula id="inline-formula31-0272989X11416988">
<mml:math display="inline" id="math46-0272989X11416988">
<mml:mover accent="true">
<mml:mi>η</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math></inline-formula> its square, and its cube are included.<sup><xref ref-type="fn" rid="fn9-0272989X11416988">i</xref></sup> If there is no additional nonlinearity in the specification, then the joint test for the coefficients on the higher-order terms should not be significantly different from 0.</p>
<p>For the 2-part models, the Hosmer-Lemeshow and the Pearson correlation tests were run based on the overall predictions of QALYs generated after combining estimates from both parts of the 2-part models.</p></list-item>
</list>
<table-wrap id="table4-0272989X11416988" position="float">
<label>Table 4</label>
<caption><p>Predicted QALYs and Incremental (Treatment Effect) Estimates in the EVALUATE Trial</p></caption>
<graphic alternate-form-of="table4-0272989X11416988" xlink:href="10.1177_0272989X11416988-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center">Estimators</th>
<th align="center">AH (<italic>n</italic> = 263), <italic>x</italic> QALY (<italic>s</italic>)</th>
<th align="center">ALH (<italic>n</italic> = 487), <italic>x</italic> QALY (<italic>s</italic>)</th>
<th align="center">Incremental Effect (<italic>s</italic>)</th>
<th align="center">RMSE</th>
</tr>
</thead>
<tbody>
<tr>
<td>Single-equation</td>
<td>Linear OLS</td>
<td>.862 (.008)</td>
<td>.870 (.006)</td>
<td>.008 (.016)</td>
<td>.1249</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta MLE</td>
<td>.850 (.009)</td>
<td>.880 (.006)</td>
<td>.030<sup><xref ref-type="table-fn" rid="table-fn7-0272989X11416988">a</xref></sup> (.014)</td>
<td>.1300</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Beta QMLE</td>
<td>.861 (.008)</td>
<td>.870 (.006)</td>
<td>.009 (.011)</td>
<td>.1260</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian MLE</td>
<td>.850 (0.009)</td>
<td>.880 (0.006)</td>
<td>.030<sup><xref ref-type="table-fn" rid="table-fn7-0272989X11416988">a</xref></sup> (.009)</td>
<td>.1340</td>
</tr>
<tr>
<td>Single-equation</td>
<td>Bayesian QMLE</td>
<td>.862 (0.023)</td>
<td>.869 (0.015)</td>
<td>.007 (.028)</td>
<td>.1371</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Beta QMLE</td>
<td>.864 (.008)</td>
<td>.871 (.006)</td>
<td>.007 (.016)</td>
<td>.1260</td>
</tr>
<tr>
<td>Two-part</td>
<td>Two-part Bayesian QMLE</td>
<td>.863 (0.023)</td>
<td>.868 (0.015)</td>
<td>.005 (.150)</td>
<td>.1371</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-0272989X11416988">
<p>AH, abdominal hysterectomy; ALH, abdominal laparoscopic-assisted hysterectomy; MLE, maximum-likelihood estimation; OLS, ordinary least squares; QMLE, quasi-likelihood estimation; RMSE, root mean squared error; SD, standard deviation.</p>
</fn>
<fn id="table-fn7-0272989X11416988">
<label>a</label>
<p>95% central interval excludes 0.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Examining the incremental effects reported in <xref ref-type="table" rid="table4-0272989X11416988">Table 4</xref> for the EVALUATE trial data, it appears that the frequentist and Bayesian Beta MLE produced identical results showing a significant improvement of 0.03 QALYs for patients receiving ALH versus AH. In contrast, OLS, frequentist, and Bayesian Beta QMLE and their 2-part extensions all estimated the incremental effect to lie between 0.004 and 0.007, which was not statistically significant under any of the estimators. To further understand the differences in results we look at the goodness of fit tests in <xref ref-type="table" rid="table5-0272989X11416988">Table 5</xref> and <xref ref-type="fig" rid="fig4-0272989X11416988">Figure 4</xref>. We suppressed test results for the Bayesian estimators because they were identical to their frequentist counterparts. <xref ref-type="table" rid="table5-0272989X11416988">Table 5</xref> shows that the all estimators passed all the tests with the exception of the Beta MLE, which failed the Pearson correlation test showing significant correlation between residuals and prediction. This is evident from <xref ref-type="fig" rid="fig4-0272989X11416988">Figure 4</xref>, which plots the mean residuals over the deciles of the linear predictor. Beta MLE underestimated the mean at the lower end of the distribution while overestimating the mean at the higher end of the distribution. Our empirical results are consistent with the simulation results in that we found the Beta MLE to produce biased estimates of the incremental effect. This is probably due to the continuity correction implemented by subtracting a small noise to the observations with QALY = 1 and the fact that the 2 treatment groups differ in the proportion of observations with QALY = 1. Also, because the correct incremental effect appears to be small and insignificant in this example and the distribution of QALY did not have a spike at 1, the OLS estimate of the effect is believed to be potentially unbiased.</p>
<fig id="fig4-0272989X11416988" position="float">
<label>Figure 4</label>
<caption><p>Mean residuals across deciles of linear predictors (or predictor) across alternative estimators.</p></caption>
<graphic xlink:href="10.1177_0272989X11416988-fig4.tif"/>
</fig>
<p>All models have the same RMSE, which may indicate that this diagnostic is not of great help with limited dependent variables.</p>
<table-wrap id="table5-0272989X11416988" position="float">
<label>Table 5</label>
<caption><p>Results for Goodness-of-Fit Tests for Alternative Estimators</p></caption>
<graphic alternate-form-of="table5-0272989X11416988" xlink:href="10.1177_0272989X11416988-table5.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center" colspan="2">Single-Equation</th>
<th align="center" colspan="2">Two-Part</th>
</tr>
</thead>
<tbody>
<tr>
<td>Estimators</td>
<td>Linear OLS</td>
<td>Beta MLE</td>
<td>Beta QMLE</td>
<td>Beta QMLE</td>
</tr>
<tr>
<td>Hosmer and Lemeshow, <italic>F</italic>-stat (<italic>P</italic> value)</td>
<td>0.76 (0.67)</td>
<td>1.14 (0.17)</td>
<td>0.80 (0.63)</td>
<td>0.94 (0.50)</td>
</tr>
<tr>
<td>Pearson correlation, Rho (<italic>P</italic> value)</td>
<td>.00000 (1.00)</td>
<td>−0.08 (0.03)</td>
<td>0.001 (0.98)</td>
<td>−0.002 (0.96)</td>
</tr>
<tr>
<td>Link Test, <italic>t</italic> stat (<italic>P</italic> value)</td>
<td>−1.09 (0.77)</td>
<td>0.32 (0.41)</td>
<td>−0.08 (0.88)</td>
<td align="center">—</td>
</tr>
<tr>
<td>Reset Test <italic>F</italic>-stat (<italic>P</italic> value)</td>
<td>1.14 (0.32)</td>
<td>1.69 (0.43)</td>
<td/>
<td align="center">—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn8-0272989X11416988">
<p>MLE, maximum-likelihood estimation; OLS, ordinary least squares; QMLE, quasi-likelihood estimation.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section19-0272989X11416988">
<title>Conclusions</title>
<p>In this article, we discuss and compare the performance of a wide range of estimators that can be used to model an outcome variable with truncated support on both ends. Our focus was on modeling HRQoL and QALY data, because these outcomes share the same features in their distributions. Our estimators are primarily based on the Beta distribution, although we also studied a quasi-likelihood estimation technique that relaxes the full distributional assumptions required by maximum likelihood based estimation methods. We present a novel Bayesian estimator that possesses the robustness of a quasi-likelihood technique. Our simulation results indicate that when the effect of a standard deviation change in covariate value is small (our general rule is &lt;0.03) and there are no spikes at 1, OLS provides an unbiased estimate of the covariate effect. When the covariate effect is large, OLS can produce substantially biased results. Although we think that such a cutoff is a conservative estimate of the threshold below which OLS may work fine, more work and simulations are needed to validate such a conclusion. When effects are large, Beta QMLE appears to be the most robust alternative. When there are large spikes at 1, a 2-part Beta QMLE can improve the fit and produce both unbiased and more efficient estimates of covariate effects compared with Beta QMLE. Both the Beta QMLE and the 2-part Beta QMLE can be implemented using Bayesian methods, and our results still hold.</p>
<p>We provide detailed Stata and WinBUGS codes in the Web Appendix to implement each of the estimators that we studied. We hope these will provide researchers with the tools to apply and appropriately model quality of life outcomes and other data with similar features.</p>
</sec>
</body>
<back>
<ack><p>We are grateful for comments from 2 anonymous reviewers that have helped in our presentation of the scientific material. The views expressed in this publication are those of the authors and not necessarily those of the Universities of York and Washington, NBER, the NHS, NIHR, or the Department of Health in the UK.</p></ack>
<sec id="section20-0272989X11416988">
<title>Analytical Variance Estimators</title>
<p>The analytical variance estimator for <inline-formula id="inline-formula32-0272989X11416988">
<mml:math display="inline" id="math47-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> (<xref ref-type="disp-formula" rid="disp-formula11-0272989X11416988">Equation 11</xref>) will depend both on the variance of (<inline-formula id="inline-formula33-0272989X11416988">
<mml:math display="inline" id="math48-0272989X11416988">
<mml:mover accent="true">
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math>
</inline-formula>) and on the variance of covariates <italic>X</italic> in the population of interest. The variance for the estimator in (11) is given by</p>
<p><disp-formula id="disp-formula16-0272989X11416988">
<mml:math display="block" id="math49-0272989X11416988">
<mml:mrow>
<mml:mi>V</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>r</mml:mi>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>}</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>V</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>r</mml:mi>
<mml:mo>{</mml:mo>
<mml:mover accent="true">
<mml:mi>E</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo>;</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
<mml:mo>}</mml:mo>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>ψ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>γ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>|</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:msub>
<mml:mi>A</mml:mi>
<mml:mi>N</mml:mi>
</mml:msub>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:msub>
<mml:mi>ψ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mrow>
<mml:mo>∂</mml:mo>
<mml:mi>γ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>|</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mi>T</mml:mi>
</mml:msup>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula16-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq16.tif"/>
</disp-formula>
</p>
<p>In <xref ref-type="disp-formula" rid="disp-formula16-0272989X11416988">Equation A.1</xref>, the 1st term is the sample variance of <inline-formula id="inline-formula34-0272989X11416988">
<mml:math display="inline" id="math50-0272989X11416988">
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math></inline-formula> attributable to using the empirical expected value over <inline-formula id="inline-formula35-0272989X11416988">
<mml:math display="inline" id="math51-0272989X11416988">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>E</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:msub>
<mml:mi>x</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>µ</mml:mi>
<mml:mo>;</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math></inline-formula> rather than the population expected value. Here <italic>X<sub>− j</sub></italic> represents the vector of all other covariates besides <italic>X<sub>j</sub></italic>. The 2nd term is due to the fact that is estimated. An estimator of the variance (<xref ref-type="disp-formula" rid="disp-formula16-0272989X11416988">Equation A.1</xref>) is obtained by replacing with <inline-formula id="inline-formula36-0272989X11416988">
<mml:math display="inline" id="math52-0272989X11416988">
<mml:mover accent="true">
<mml:mi>γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:math>
</inline-formula> and replacing the 1st term in <xref ref-type="disp-formula" rid="disp-formula16-0272989X11416988">Equation A.1</xref> with</p>
<p>
<disp-formula id="disp-formula17-0272989X11416988">
<mml:math display="block" id="math53-0272989X11416988">
<mml:mrow>
<mml:msup>
<mml:mi>N</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>{</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:munderover>
<mml:mstyle displaystyle="true" mathsize="140%">
<mml:mo>∑</mml:mo>
</mml:mstyle>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>N</mml:mi>
</mml:munderover>
<mml:msup>
<mml:mrow>
<mml:mo>{</mml:mo>
<mml:msub>
<mml:mi>D</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mover accent="true">
<mml:mi>µ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>;</mml:mo>
<mml:msub>
<mml:mi>X</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mover accent="true">
<mml:mi>ψ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>}</mml:mo>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>}</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula17-0272989X11416988" xlink:href="10.1177_0272989X11416988-eq17.tif"/>
</disp-formula>
</p>
<p>An estimator for <inline-formula id="inline-formula37-0272989X11416988">
<mml:math display="inline" id="math54-0272989X11416988">
<mml:mrow>
<mml:mi>V</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>r</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mover accent="true">
<mml:mi>Δ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> analogous to (A.1) may be obtained through a similar approach.</p>
</sec>
<fn-group>
<fn fn-type="supported-by">
<p>Dr. Basu acknowledges support from the Alan Williams Health Economics Fellowship from the University of York and research grants from the National Institute of Mental Health 1R01MH083706 and the National Cancer Institute 1RC4 CA155809-01</p>
</fn>
<fn fn-type="other">
<p>This work is produced by Dr Manca under the terms of a Career Development Fellowship issued by the UK National Institute for Health Research (NIHR).</p>
</fn>
<fn fn-type="other" id="fn1-0272989X11416988">
<label>a</label>
<p>We will only use the term <italic>quality of life</italic> to represent the effectiveness data. Quality adjusted life-years (QALYs) can be readily converted to a per year quality of life estimate by dividing by the number of years over which QALYs are calculated.</p>
</fn>
<fn fn-type="other" id="fn2-0272989X11416988">
<label>b</label>
<p>In this article we focus on the analysis of HRQoL data collected alongside randomized controlled clinical trials and do not deal with the issues related to selection bias in nonrandomized settings.</p>
</fn>
<fn fn-type="other" id="fn3-0272989X11416988">
<label>c</label>
<p>The methods presented here can be readily extended to outcomes with any truncated support <italic>Y</italic> ∊ [<italic>a,b</italic>] where <italic>b</italic> &gt; <italic>a</italic> and <italic>b</italic>, <italic>a</italic> ∊ ℝ. One can scale the response variable so that <italic>Y</italic>′ = (<italic>Y</italic> − <italic>a</italic>)/(<italic>y</italic> − <italic>b</italic>). Because <italic>Y</italic>′ ∊ [0,1], one can model <italic>Y</italic>′ with the methods presented here. Note that in such cases, we can relax the assumption of nonnegativeness of <italic>Y</italic>, that is, <italic>Y</italic> ∊ ℝ.</p>
</fn>
<fn fn-type="other" id="fn4-0272989X11416988">
<label>d</label>
<p>Alternative options (e.g., <italic>probit</italic> or complementary log-log link) may also be used.</p>
</fn>
<fn fn-type="other" id="fn5-0272989X11416988">
<label>e</label>
<p>If the spike is at 0 instead, the 2-part model can be directly applied to <italic>Y</italic>.</p>
</fn>
<fn fn-type="other" id="fn6-0272989X11416988">
<label>f</label>
<p>This formulation is slightly different to the traditional formulation of a Beta density, where <italic>f</italic>(<italic>Y</italic>) ∞ <italic>Y</italic><sup>α−1</sup>(1−<italic>Y</italic>)β-1. The cross walk between these 2 formulas is straightforward: µ = α/(α + β) and ξ = (α + β). The formulation we use is usually suitable for a generalized linear model.</p>
</fn>
<fn fn-type="other" id="fn7-0272989X11416988">
<label>g</label>
<p>The inclusion of ξ is not necessary for estimating the mean model parameters as it is just a constant scaling factor. However, its use serves 2 purposes: (1) a large estimated variance of ξ indicates that there might be residual heteroskedasticity that remains unaccounted for, and (2) it sets up the estimating algorithm to let ξ vary by <italic>X</italic>, thereby accounting for the residual over dispersion in the variance model. We delegate these aspects to our future work.</p>
</fn>
<fn fn-type="other" id="fn8-0272989X11416988">
<label>h</label>
<p>In our dry-runs before the simulation, we assessed reasonable convergence of parameters values using these specifications.</p>
</fn>
<fn fn-type="other" id="fn9-0272989X11416988">
<label>i</label>
<p>We do not use the fourth power term as used in traditional reset test given the small sample size.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0272989X11416988">
<label>1.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Manning</surname><given-names>WG</given-names></name>
</person-group>. <article-title>The logged dependent variable, heteroscedasticity, and the retransformation problem</article-title>. <source>J Health Econ</source>. <year>1998</year>;<volume>17</volume>(<issue>3</issue>):<fpage>283</fpage>–<lpage>95</lpage>.</citation>
</ref>
<ref id="bibr2-0272989X11416988">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mullahy</surname><given-names>J</given-names></name>
</person-group>. <article-title>Much ado about two: reconsidering retransformation and the two-part model in health econometrics</article-title>. <source>J Health Econ</source>. <year>1998</year>;<volume>17</volume>(<issue>3</issue>):<fpage>247</fpage>–<lpage>81</lpage>.</citation>
</ref>
<ref id="bibr3-0272989X11416988">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Manning</surname><given-names>WG</given-names></name>
<name><surname>Basu</surname><given-names>A</given-names></name>
<name><surname>Mullahy</surname><given-names>J</given-names></name>
</person-group>. <article-title>Generalized modeling approaches to risk adjustment of skewed outcomes data</article-title>. <source>J Health Econ</source>. <year>2005</year>;<volume>24</volume>(<issue>3</issue>):<fpage>465</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr4-0272989X11416988">
<label>4.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Manning</surname><given-names>WG</given-names></name>
<name><surname>Mullahy</surname><given-names>J</given-names></name>
</person-group>. <article-title>Estimating log models: To transform or not to transform?</article-title> <source>J Health Econ</source>. <year>2001</year>;<volume>20</volume>(<issue>4</issue>):<fpage>461</fpage>–<lpage>94</lpage>.</citation>
</ref>
<ref id="bibr5-0272989X11416988">
<label>5.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Manning</surname><given-names>W</given-names></name>
</person-group>. <article-title>Dealing with skewed data on costs and expenditures</article-title>. In: <person-group person-group-type="editor">
<name><surname>Jones</surname><given-names>AM</given-names></name>
</person-group>, ed. <source>The Elgar Companion to Health Economics</source>. <publisher-loc>Cheltenham, UK</publisher-loc>: <publisher-name>Edward Elgar</publisher-name>; <year>2006</year>. p <fpage>439</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr6-0272989X11416988">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brooks</surname><given-names>R</given-names></name>
</person-group>. <article-title>EuroQol: the current state of play</article-title>. <source>Health Policy</source>. <year>1996</year>;<volume>37</volume>(<issue>1</issue>):<fpage>53</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr7-0272989X11416988">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brazier</surname><given-names>J</given-names></name>
<name><surname>Roberts</surname><given-names>J</given-names></name>
<name><surname>Deverill</surname><given-names>M</given-names></name>
</person-group>. <article-title>The estimation of a preference-based measure of health from the SF-36</article-title>. <source>J Health Econ</source>. <year>2002</year>;<volume>21</volume>(<issue>2</issue>):<fpage>271</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr8-0272989X11416988">
<label>8.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mullahy</surname><given-names>J</given-names></name>
</person-group>. <source>Regression models and transformations for beta-distributed outcomes</source>. <publisher-name>Department of Economics, Trinity College</publisher-name>; <publisher-loc>Dublin, Ireland</publisher-loc>; <year>1990</year>.</citation>
</ref>
<ref id="bibr9-0272989X11416988">
<label>9.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Austin</surname><given-names>PC</given-names></name>
</person-group>. <article-title>A comparison of methods for analyzing health-related quality-of-life measures</article-title>. <source>Value Health</source>. <year>2002</year>;<volume>5</volume>(<issue>4</issue>):<fpage>329</fpage>–<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr10-0272989X11416988">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Austin</surname><given-names>PC</given-names></name>
</person-group>. <article-title>Bayesian extensions of the tobit model for analyzing measures of health status</article-title>. <source>Med Decis Making</source>. <year>2002</year>;<volume>22</volume>(<issue>2</issue>):<fpage>152</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr11-0272989X11416988">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clarke</surname><given-names>P</given-names></name>
<name><surname>Gray</surname><given-names>A</given-names></name>
<name><surname>Holman</surname><given-names>R</given-names></name>
</person-group>. <article-title>Estimating utility values for health states of type 2 diabetic patients using the EQ-5D (UKPDS 62)</article-title>. <source>Med Decis Making</source>. <year>2002</year>;<volume>22</volume>(<issue>4</issue>):<fpage>340</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr12-0272989X11416988">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Grootendorst</surname><given-names>P</given-names></name>
</person-group>. <article-title>Censoring in statistical models of health status: what happens when one can do better than “1</article-title>.<source>” Qual Life Res</source>. <year>2000</year>;<volume>9</volume>(<issue>8</issue>):<fpage>911</fpage>–<lpage>4</lpage>.</citation>
</ref>
<ref id="bibr13-0272989X11416988">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Huang</surname><given-names>IC</given-names></name>
<name><surname>Frangakis</surname><given-names>C</given-names></name>
<name><surname>Atkinson</surname><given-names>MJ</given-names></name><etal/>
</person-group>. <article-title>Addressing ceiling effects in health status measures: a comparison of techniques applied to measures for people with HIV disease</article-title>. <source>Health Serv Res</source>. <year>2008</year>;<volume>43</volume>(<issue>1</issue> <supplement>Pt 1</supplement>):<fpage>327</fpage>–<lpage>39</lpage>.</citation>
</ref>
<ref id="bibr14-0272989X11416988">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pullenayegum</surname><given-names>EM</given-names></name>
<name><surname>Tarride</surname><given-names>JE</given-names></name>
<name><surname>Xie</surname><given-names>F</given-names></name>
<name><surname>Goeree</surname><given-names>R</given-names></name>
<name><surname>Gerstein</surname><given-names>HC</given-names></name>
<name><surname>O’Reilly</surname><given-names>D</given-names></name>
</person-group>. <article-title>Analysis of health utility data when some subjects attain the upper bound of 1: are Tobit and CLAD models appropriate?</article-title> <source>Value Health</source>. <year>2010</year>;<volume>13</volume>(<issue>4</issue>):<fpage>487</fpage>-<lpage>94</lpage>.</citation>
</ref>
<ref id="bibr15-0272989X11416988">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wedderburn</surname><given-names>RWM</given-names></name>
</person-group>. <article-title>Quasi-likelihood functions, generalized linear models, and the Gauss-Newton method</article-title>. <source>Biometrika</source>. <year>1974</year>;<volume>61</volume>:<fpage>439</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr16-0272989X11416988">
<label>16.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McCullagh</surname><given-names>P</given-names></name>
<name><surname>Nelder</surname><given-names>JA</given-names></name>
</person-group>. <source>Generalized Linear Model</source>. <edition>2nd ed.</edition> <publisher-loc>New York</publisher-loc>: <publisher-name>Chapman and Hall</publisher-name>; <year>1989</year>.</citation>
</ref>
<ref id="bibr17-0272989X11416988">
<label>17.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Papke</surname><given-names>LE</given-names></name>
<name><surname>Wooldridge</surname><given-names>JM</given-names></name>
</person-group>. <article-title>Econometric methods for fractional response variables with an application to 401 (K) plan participation rates</article-title>. <source>J Appl Econ</source>. <year>1996</year>;<volume>11</volume>(<issue>6</issue>):<fpage>619</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr18-0272989X11416988">
<label>18.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kieschnick</surname><given-names>R</given-names></name>
<name><surname>McCullough</surname><given-names>BD</given-names></name>
</person-group>. <article-title>Regression analysis of variates observed on (0,1): percentages, proportions and fractions</article-title>. <source>Stat Modelling</source>. <year>2003</year>;<volume>3</volume>:<fpage>193</fpage>–<lpage>213</lpage>.</citation>
</ref>
<ref id="bibr19-0272989X11416988">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Smithson</surname><given-names>M</given-names></name>
<name><surname>Verkuilen</surname><given-names>J</given-names></name>
</person-group>. <article-title>A better lemon squeezer? Maximum-likelihood regression with beta-distributed dependent variables</article-title>. <source>Psychol Methods</source>. <year>2006</year>;<volume>11</volume>(<issue>1</issue>):<fpage>54</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr20-0272989X11416988">
<label>20.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gourieroux</surname><given-names>C</given-names></name>
<name><surname>Monfort</surname><given-names>A</given-names></name>
<name><surname>Trognon</surname><given-names>A</given-names></name>
</person-group>. <article-title>Pseudo-maximum likelihood methods: theory</article-title>. <source>Econometrica</source>. <year>1984</year>;<volume>52</volume>(<issue>3</issue>):<fpage>681</fpage>–<lpage>700</lpage>.</citation>
</ref>
<ref id="bibr21-0272989X11416988">
<label>21.</label>
<citation citation-type="book">
<collab>StataCorp</collab>. <article-title>Stata Statistical Software: Release 10</article-title>. <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>StataCorp LP;</publisher-name> <year>2008</year>.</citation>
</ref>
<ref id="bibr22-0272989X11416988">
<label>22.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lunn</surname><given-names>DJ</given-names></name>
<name><surname>Thomas</surname><given-names>T</given-names></name>
<name><surname>Best</surname><given-names>N</given-names></name>
<name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name>
</person-group>. <article-title>WinBUGS—A Bayesian modelling framework: Concepts, structure, and extensibility</article-title>. <source>Stat Comput</source>. <year>2000</year>;<volume>10</volume>(<issue>4</issue>):<fpage>325</fpage>–<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr23-0272989X11416988">
<label>23.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Garry</surname><given-names>R</given-names></name>
<name><surname>Hawe</surname><given-names>J</given-names></name>
<name><surname>Abbott</surname><given-names>J</given-names></name><etal/>
</person-group>. <article-title>The EVALUATE study: randomised trials comparing laparoscopic with abdominal and vaginal hysterectomy</article-title>. <source>Br Med J</source>. <year>2004</year>;<volume>328</volume>:<fpage>129</fpage>–<lpage>33</lpage>.</citation>
</ref>
<ref id="bibr24-0272989X11416988">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sculpher</surname><given-names>MJ</given-names></name>
<name><surname>Manca</surname><given-names>A</given-names></name>
<name><surname>Abbott</surname><given-names>J</given-names></name>
<name><surname>Fountain</surname><given-names>J</given-names></name>
<name><surname>Mason</surname><given-names>S</given-names></name>
<name><surname>Garry</surname><given-names>R</given-names></name>
</person-group>. <article-title>the cost-effectiveness of laparoscopic-assisted hysterectomy in comparison with standard hysterectomy: the EVALUATE trial</article-title>. <source>Br Med J</source>. <year>2004</year>;<volume>328</volume>:<fpage>134</fpage>–<lpage>9</lpage>.</citation>
</ref>
<ref id="bibr25-0272989X11416988">
<label>25.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hall</surname><given-names>DB</given-names></name>
<name><surname>Sevrini</surname><given-names>TA</given-names></name>
</person-group>. <article-title>Extended generalized estimating equations for clustered data</article-title>. <source>J Am Stat Assoc</source>. <year>1998</year>;<volume>93</volume>(<issue>444</issue>):<fpage>1365</fpage>–<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr26-0272989X11416988">
<label>26.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Basu</surname><given-names>A</given-names></name>
<name><surname>Rathouz</surname><given-names>PJ</given-names></name>
</person-group>. <article-title>Estimating marginal and incremental effects on health outcomes using flexible link and variance function models</article-title>. <source>Biostatistics</source>. <year>2005</year>;<volume>6</volume>(<issue>1</issue>):<fpage>93</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr27-0272989X11416988">
<label>27.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Huber</surname><given-names>PJ</given-names></name>
</person-group>. <article-title>Robust statistics: A review</article-title>. <source>Annals of Mathematical Statistics</source>. <year>1972</year>;<volume>43</volume>:<fpage>1041</fpage>–<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr28-0272989X11416988">
<label>28.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liang</surname><given-names>KY</given-names></name>
<name><surname>Zeger</surname><given-names>SL</given-names></name>
</person-group>. <article-title>Longitudinal data analysis using generalized linear models</article-title>. <source>Biometrika</source>. <year>1986</year>;<volume>73</volume>:<fpage>13</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr29-0272989X11416988">
<label>29.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>O’Hagan</surname><given-names>A</given-names></name>
<name><surname>Foster</surname><given-names>J.</given-names></name>
</person-group> <source>Kendall’s Advanced Theory of Statistics: Bayesian Inference</source>. <edition>2nd ed.</edition> <publisher-loc>London</publisher-loc>: <publisher-name>Edward Arnold</publisher-name>; <year>2004</year>.</citation>
</ref>
<ref id="bibr30-0272989X11416988">
<label>30.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>O’Hagan</surname><given-names>A</given-names></name>
<name><surname>Luce</surname><given-names>BR</given-names></name>
</person-group>. <source>A Primer on Bayesian Statistics in Health Economics and Outcomes Research</source>. <publisher-loc>Bethesda, MD</publisher-loc>: <publisher-name>MEDTAP International</publisher-name>; <year>2003</year>.</citation>
</ref>
<ref id="bibr31-0272989X11416988">
<label>31.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name>
<name><surname>Thomas</surname><given-names>A</given-names></name>
<name><surname>Best</surname><given-names>N</given-names></name>
<name><surname>Lunn</surname><given-names>D</given-names></name>
</person-group>. <source>WinBUGS User Manual</source>. <comment>Version 1</comment>. <edition>4 ed</edition>. <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>MRC Biostatistics Unit</publisher-name>; <year>2003</year>.</citation>
</ref>
<ref id="bibr32-0272989X11416988">
<label>32.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gilks</surname><given-names>WR</given-names></name>
<name><surname>Richardson</surname><given-names>S</given-names></name>
<name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name>
</person-group>. <source>Markov Chain Monte Carlo in practice</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Chapman and Hall</publisher-name> <year>1996</year>.</citation>
</ref>
<ref id="bibr33-0272989X11416988">
<label>33.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gelman</surname><given-names>A</given-names></name>
<name><surname>Hill</surname><given-names>J</given-names></name>
</person-group>. <source>Data analysis using regression and multilevel/hierarchical models</source>. <source>1st ed</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2007</year>.</citation>
</ref>
<ref id="bibr34-0272989X11416988">
<label>34.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Oaxaca</surname><given-names>R</given-names></name>
</person-group>. <article-title>Male-female Wage Differentials In Urban Labor Markets</article-title>. <source>Int Econ Rev</source>. <year>1973</year>;<volume>14</volume>(<issue>3</issue>):<fpage>693</fpage>–<lpage>709</lpage>.</citation>
</ref>
<ref id="bibr35-0272989X11416988">
<label>35.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>J</given-names></name>
<name><surname>Palmer</surname><given-names>T</given-names></name>
<name><surname>Moreno</surname><given-names>S</given-names></name>
</person-group>. <article-title>Bayesian analysis in Stata with WinBUGS</article-title>. <source>Stata J</source>. <year>2006</year>;<volume>6</volume>(<issue>4</issue>):<fpage>530</fpage>–<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr36-0272989X11416988">
<label>36.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hosmer</surname><given-names>DW</given-names></name>
<name><surname>Lemeshow</surname><given-names>S</given-names></name>
</person-group>. <source>Applied Logistic Regression</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>; <year>1995</year>.</citation>
</ref>
<ref id="bibr37-0272989X11416988">
<label>37.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pregibon</surname><given-names>D</given-names></name>
</person-group>. <article-title>Goodness of link tests for generalized linear models</article-title>. <source>Appl Stat</source>. <year>1980</year>;<volume>29</volume>:<fpage>15</fpage>–<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr38-0272989X11416988">
<label>38.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ramsey</surname><given-names>JB</given-names></name>
</person-group>. <article-title>Tests for specification error in classical linear least squares regression analysis</article-title>. <source>J R Stat Soc Series B Stat Methodol</source>. <year>1969</year>;<volume>31</volume>:<fpage>350</fpage>–<lpage>71</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>