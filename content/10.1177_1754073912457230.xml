<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EMR</journal-id>
<journal-id journal-id-type="hwp">spemr</journal-id>
<journal-title>Emotion Review</journal-title>
<issn pub-type="ppub">1754-0739</issn>
<issn pub-type="epub">1754-0747</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1754073912457230</article-id>
<article-id pub-id-type="publisher-id">10.1177_1754073912457230</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Special Section: Facial Expressions</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Contextualizing Facial Activity</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Parkinson</surname><given-names>Brian</given-names></name>
</contrib>
<aff id="aff1-1754073912457230">Department of Experimental Psychology, University of Oxford, UK</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1754073912457230">Brian Parkinson, Department of Experimental Psychology, University of Oxford, South Parks Road, Oxford OX1 3UD, UK. <italic>Email</italic>: <email>brian.parkinson@psy.ox.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>5</volume>
<issue>1</issue>
<fpage>97</fpage>
<lpage>103</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">ISRE and SAGE</copyright-holder>
</permissions>
<abstract>
<p>Drawing on research reviewed in this special section, the present article discusses how various contextual factors impact on production and decoding of emotion-related facial activity. Although emotion-related variables often contribute to activation of prototypical “emotion expressions” and perceivers can often infer emotional meanings from these facial configurations, neither process is invariant or direct. Many facial movements are directed towards or away from events in the shared environment, and their effects depend on these relational orientations. Facial activity is not only a medium for descriptive representation of internal affective states, but also a means of adjusting to, and operating on, external objects, and of influencing other people’s appraisals of those objects.</p>
</abstract>
<kwd-group>
<kwd>affect program theory</kwd>
<kwd>context</kwd>
<kwd>facial expression</kwd>
<kwd>relational orientation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>What do facial movements mean? Psychologists typically research this question in one of two ways (see <xref ref-type="bibr" rid="bibr50-1754073912457230">Russell &amp; Fernández-Dols, 1997</xref>). The first seeks meaning in processes leading to production of facial activity, focusing on how information is encoded in faces. The second (more common) approach is to investigate meanings that other people attribute to facial configurations, focusing on how information is decoded from faces. Although few studies collect both kinds of data, most theorists assume that information encoded in facial configurations broadly corresponds to information subsequently extracted by perceivers (see <xref ref-type="bibr" rid="bibr51-1754073912457230">Scherer, Mortillaro, &amp; Mehu, 2013</xref>). From this perspective, emotion communication may be disrupted by factors moderating production of facial response (e.g., display rules; <xref ref-type="bibr" rid="bibr14-1754073912457230">Ekman, 1972</xref>) or decoding of facial meaning (e.g., decoding rules; <xref ref-type="bibr" rid="bibr35-1754073912457230">Matsumoto, 1989</xref>).</p>
<p>A popular strategy for investigating both production and decoding is to focus on a highly selected set of static facial configurations assumed to reflect the basic emotions specified by affect program theory (APT; e.g., <xref ref-type="bibr" rid="bibr14-1754073912457230">Ekman 1972</xref>). Partly because of the methods originally used to compile these facial stimuli (e.g., <xref ref-type="bibr" rid="bibr16-1754073912457230">Ekman &amp; Friesen, 1976</xref>), they provide sufficient emotion-relevant information to permit some degree of within-culture consistency in decoders’ attributions of emotional meaning, especially when the judgment context prespecifies emotion-category labels as required responses (see <xref ref-type="bibr" rid="bibr42-1754073912457230">Nelson &amp; Russell, 2013</xref>). Thus, English-language speakers tend to favor “disgust” over “anger” as the label for a scrunched-nose face. However, these circumscribed consistencies in judgment do not necessarily mean that the investigated facial configurations have special status as symptoms of emotion, or that their communicative meaning is normally transmitted independent of context (see also <xref ref-type="bibr" rid="bibr20-1754073912457230">Fernández-Dols, 2013</xref>). Instead, APT faces may simply encapsulate certain patterns of relational orientation. For example, nose-scrunching might make decoders think that the sender smells something bad (or is trying to communicate that something smells bad) and infer that disgust is more strongly associated with such a situation than anger.</p>
<p>Evidence reviewed in this special section unsettles APT approaches in a number of ways. First, studies of antecedents of APT facial configurations usually find low to moderate associations with emotions even when interference from display rules or conflicting emotions seems unlikely (e.g., <xref ref-type="bibr" rid="bibr21-1754073912457230">Fernández-Dols &amp; Crivelli, 2013</xref>; <xref ref-type="bibr" rid="bibr45-1754073912457230">Reisenzein, Studtmann, &amp; Horstmann, 2013</xref>). Second, interpretation of APT faces depends on information presented either simultaneously or previously (<xref ref-type="bibr" rid="bibr27-1754073912457230">Hassin, Aviezer, &amp; Bentin, 2013</xref>; <xref ref-type="bibr" rid="bibr30-1754073912457230">Krumhuber, Kappas, &amp; Manstead, 2013</xref>), and on availability of linguistic categories (e.g., <xref ref-type="bibr" rid="bibr33-1754073912457230">Lindquist &amp; Gendron, 2013</xref>). Thus, static facial configurations do not seem to carry intrinsic, context-independent emotional meanings. Third, decoders’ cultural background affects attribution of emotional meaning to APT faces, suggesting that they are not universally perceived as markers of categorical emotions (<xref ref-type="bibr" rid="bibr18-1754073912457230">Elfenbein, 2013</xref>; <xref ref-type="bibr" rid="bibr42-1754073912457230">Nelson &amp; Russell, 2013</xref>). In the following sections, I review evidence for these conclusions before considering more generally how facial activity relates to its dynamic context in practical and communicative situations. Not only are the meanings reflected in and conveyed by faces context-dependent, but also strategic facial communication can exploit relations between face and context.</p>
<sec id="section1-1754073912457230">
<title>Antecedents</title>
<p>Studying antecedents of facial configurations is far from straightforward. Emotional and nonemotional predictors and moderators are so diverse that they cannot all be investigated at once (e.g., <xref ref-type="bibr" rid="bibr51-1754073912457230">Scherer et al., 2013</xref>). Partly for this reason, researchers typically control for contextual factors rather than treating them as theoretically important antecedents in their own right. On the output side, most studies measure effects on tightly delimited aspects of facial activity instead of the full range of possible facial movements. Accordingly, the reviews by <xref ref-type="bibr" rid="bibr45-1754073912457230">Reisenzein et al. (2013)</xref> and by <xref ref-type="bibr" rid="bibr21-1754073912457230">Fernández-Dols and Crivelli (2013)</xref> focus on the issue of whether APT configurations consistently depend on the basic emotions they are said to express.</p>
<p><xref ref-type="bibr" rid="bibr45-1754073912457230">Reisenzein et al.’s (2013)</xref> review of experimental research finds that close associations between emotions and APT faces are the exception rather than the rule. For example, contraction of the zygomatic major is strongly related to amusement, but not to other forms of “happiness.” What accounts for these differences?</p>
<p>Social factors moderate some of emotion’s effects on facial activity (e.g., <xref ref-type="bibr" rid="bibr23-1754073912457230">Fridlund, 1994</xref>). Indeed, several studies show that smiling is more likely during direct interaction with other people, and is absent, infrequent, or evanescent in private or low-sociality situations, even when happiness is intense (see <xref ref-type="bibr" rid="bibr21-1754073912457230">Fernández-Dols &amp; Crivelli, 2013</xref>). This context-dependence suggests that some facial movements are communicative rather than directly expressive (<xref ref-type="bibr" rid="bibr10-1754073912457230">Chovil, 1997</xref>; <xref ref-type="bibr" rid="bibr23-1754073912457230">Fridlund, 1994</xref>). Thus, relatively greater smiling in amusement situations may reflect their actual or implicit sociality (e.g., <xref ref-type="bibr" rid="bibr22-1754073912457230">Fridlund, 1991</xref>).</p>
<p>One study that apparently fails to find weaker happiness–smiling associations in noninteractive settings is <xref ref-type="bibr" rid="bibr36-1754073912457230">Matsumoto and Willingham’s (2006)</xref> investigation of judo medalists at the 2004 Olympic Games. These authors reported that smiling followed victory across all sampled levels of sociality. Leaving aside the issue of whether interpersonal interaction was genuinely absent during purportedly nonsocial periods (see <xref ref-type="bibr" rid="bibr21-1754073912457230">Fernández-Dols &amp; Crivelli, 2013</xref>), it is worth considering how facial movements were recorded in this particular study. Instead of assessing smile frequency or duration across preset time intervals, Matsumoto and Willingham coded still photographs taken at the moment when facial activity reached maximal intensity. Thus, their results tell us whether gold medalists smiled at any moment after winning their event, but permit only limited comparisons of the amount of smiling between contexts.</p>
<p>Inconsistent measurement practices are also apparent across the laboratory studies reviewed by <xref ref-type="bibr" rid="bibr45-1754073912457230">Reisenzein et al. (2013)</xref>. For example, the anomalously high intraindividual correlations between sadness and observer-coded “sad” expressions reported in <xref ref-type="bibr" rid="bibr38-1754073912457230">Mauss, Levenson, McCarter, Wilhelm, and Gross’s (2005)</xref> study may partly reflect their specific method of calculation. In particular, a range of possible time lags was sampled to determine the maximal level of association. Although this procedure is justifiable on theoretical grounds, the resulting coefficients cannot be directly compared with standard nonlagged correlations.</p>
<p>Theorists disagree not only about the temporal onset of facial movement (e.g., <xref ref-type="bibr" rid="bibr37-1754073912457230">Matsumoto, Willingham, &amp; Olide, 2009</xref>), but also its typical duration. Some proponents of APT imply that emotions and their corresponding facial expressions typically last only a matter of seconds (e.g., <xref ref-type="bibr" rid="bibr15-1754073912457230">Ekman, 1992</xref>; <xref ref-type="bibr" rid="bibr17-1754073912457230">Ekman &amp; Friesen, 1982</xref>). Does this mean that an athlete who has just won an Olympic event stops being happy well before a minute has passed? Maybe repeated reactivation of thoughts (and/or social motives) relating to the recent victory continually reignites emotional and facial reactions. Conversing with someone else might similarly remind victors of different aspects and implications of their success. If so, APT facial configurations might only be observed intermittently, at moments when there is some transition in appraisal, emotion intensity, or social relations. Perhaps, then, some of the documented effects of sociality depend on it triggering such transitions.</p>
<p>Although emotion–face associations clearly vary, both naturalistic and laboratory findings suggest that APT-predicted configurations accompany targeted emotions in some contexts. Is there something special about these contexts? One possibility is that they resemble those in which prototypic representations of the associated emotion concept (e.g., <xref ref-type="bibr" rid="bibr19-1754073912457230">Fehr &amp; Russell, 1984</xref>) originally developed. For example, even if episodes labeled as “anger” are not consistently associated with APT anger faces, those more central to the anger prototype may be (cf. <xref ref-type="bibr" rid="bibr28-1754073912457230">Horstmann, 2002</xref>). When face to face with an antagonist, our facial muscles tense and we stare back with gritted teeth. Such a stance may demonstrate determination to hold firm (action readiness; <xref ref-type="bibr" rid="bibr24-1754073912457230">Frijda &amp; Tcherkassof, 1997</xref>), and communicate the danger of escalating hostilities, much like the words “I am angry with you.” However, neither these words nor the “anger” face necessarily accompany angry situations when interpersonal contact is less direct, or when any impulsive aggression would take forms other than physical resistance.</p>
<p>Seeing facial expressions as part of prototypical emotion representations rather than actual emotion episodes helps explain common beliefs that emotions and expressions are tightly correlated (as well as exaggerated perceptions of own expressiveness; e.g., <xref ref-type="bibr" rid="bibr5-1754073912457230">Barr &amp; Kleck, 1995</xref>; <xref ref-type="bibr" rid="bibr26-1754073912457230">Gilovich, Savitsky, &amp; Medvec, 1998</xref>; see also <xref ref-type="bibr" rid="bibr44-1754073912457230">Parkinson, 2008</xref>). When people think about anger or happiness, the APT-endorsed facial configuration may readily come to mind. Correspondingly, when people are inclined to convey anger interpersonally without explicitly describing their emotional state, the fact that shared representations feature this configuration permits its use as a shorthand encapsulation of relational meaning (a facial metonym that represents the emotion episode in terms of one of its possible aspects). Another reason for the moderating effect of sociality, then, is that people may use facial metonyms to communicate emotion to other people, drawing on their shared knowledge of prototypes.</p>
</sec>
<sec id="section2-1754073912457230">
<title>Decoding</title>
<p>Most articles in this special section focus on extraction of meaning from facial configurations rather than factors leading to their original production. At least some facial movements probably evolved as signals that communicate information about processes underlying their production (see <xref ref-type="bibr" rid="bibr55-1754073912457230">Waller &amp; Micheletta, 2013</xref>). However, explicit meanings decoded from facial configurations need not always reflect their antecedent conditions (see also <xref ref-type="bibr" rid="bibr21-1754073912457230">Fernández-Dols &amp; Crivelli, 2013</xref>). The following subsections address processes involved in perception and interpretation of facial meaning, and consider how various contextual factors affect these processes.</p>
<sec id="section3-1754073912457230">
<title>Visual Processing</title>
<p><xref ref-type="bibr" rid="bibr2-1754073912457230">Atkinson and Smithson (2013)</xref> and <xref ref-type="bibr" rid="bibr56-1754073912457230">Whalen et al. (2013)</xref> present evidence concerning registration, uptake, and subsequent processing of visual information contained in APT faces and the neural correlates of these processes. Atkinson and Smithson focus on distinctions between foveal and extrafoveal processing, and show how subcortical representations contribute to active redirection of gaze towards diagnostic features. In particular, the amygdala is implicated in guiding saccadic movements to the eye region of APT “fear,” faces allowing perceivers to detect their most informative cues.</p>
<p><xref ref-type="bibr" rid="bibr56-1754073912457230">Whalen et al. (2013)</xref> also show that amygdala activity during exposure to these facial stimuli reflects information value relating to predictive uncertainty, rather than immediate affective responses. These findings complement <xref ref-type="bibr" rid="bibr51-1754073912457230">Scherer et al.’s (2013)</xref> argument that novelty detection triggers eye-widening during the production of facial movements (see <xref ref-type="bibr" rid="bibr40-1754073912457230">Mortillaro, Mehu, &amp; Scherer, 2011</xref>). Thus, perceivers may learn that this facial stimulus predicts novel and potentially significant events. Relations between encoded and decoded information become more complicated when two or more parties actively interact with one another in real time and selectively present and seek information from each other’s dynamic facial presentations.</p>
<p>Even during noninteractive exposure to static facial stimuli, Atkinson and Smithson argue that gaze fixation patterns depend partly on contextual factors, potentially including postural stimuli (<xref ref-type="bibr" rid="bibr4-1754073912457230">Aviezer et al., 2008</xref>; <xref ref-type="bibr" rid="bibr27-1754073912457230">Hassin et al., 2013</xref>), and experimenters’ instructions to identify specific emotion categories. These effects on early stages of information uptake may bring downstream consequences for explicit interpretations of emotional meaning. Thus, context brings both implicit and explicit effects operating sequentially or in parallel at a variety of levels.</p>
</sec>
<sec id="section4-1754073912457230">
<title>Category Information</title>
<p>Three articles in this special section address the role of the linguistic context in shaping perceptions and interpretations of APT faces. <xref ref-type="bibr" rid="bibr57-1754073912457230">Widen (2013)</xref> shows that young children initially interpret facial stimuli in terms of good or bad feelings, and only later deploy more differentiated categorical representations. <xref ref-type="bibr" rid="bibr33-1754073912457230">Lindquist and Gendron (2013)</xref> present evidence that facial configurations encode dimensional information relating to pleasure and arousal, which needs to be supplemented by the conceptual knowledge embodied in emotion categories before adult perceivers can infer discrete APT meanings. <xref ref-type="bibr" rid="bibr25-1754073912457230">Fugate (2013)</xref> focuses on the role of emotion labels in generating categorical discrimination of dimensional facial stimuli, and demonstrates a conceptual (i.e., top–down) rather than merely perceptual (i.e., bottom–up) basis for such effects. Taken together, the evidence unsettles any assumption that discrete emotions are intrinsically embodied in decontextualized APT faces. Socialized emotion categories provide a frame of reference that attunes perceivers to distinctions between loosely structured classes of facial stimuli. Contextual data from the environment and from other aspects of the sender’s presentation may also play a similar role.</p>
</sec>
<sec id="section5-1754073912457230">
<title>Target Information</title>
<p>Over the years, many researchers have investigated effects of situational context on interpretation of facial configurations (see <xref ref-type="bibr" rid="bibr27-1754073912457230">Hassin et al., 2013</xref>, for a review). Contextual information is usually manipulated by varying narrative or pictorial representations of emotional situations. For certain judgment tasks, contextual information that is sufficiently salient can override facial information (see <xref ref-type="bibr" rid="bibr3-1754073912457230">Aviezer et al., 2009</xref>). In this special section, attention shifts from the external context to simultaneous or consecutive information from the target of judgment. How, then, are emotional attributions affected by senders’ nonfacial cues, and by the dynamic features of facial information itself?</p>
<p><xref ref-type="bibr" rid="bibr27-1754073912457230">Hassin et al. (2013)</xref> provide evidence that presenting discrepant bodily postures can influence processing and categorization of an associated facially expressed emotion. Effects depend on the perceptual similarity between the APT stimulus face and the face prototypically associated with the bodily posture. For example, because APT “anger” faces resemble APT “disgust” faces more than they resemble APT “fear” faces, “disgust” postures have a greater impact than “fear” postures on interpretation of simultaneous “anger” faces. Such “confusability effects” may also depend on compatibility of the relational orientations conveyed by facial and bodily stimuli and their relevance to any simultaneously presented objects (such as the dirty nappies included in Hassin et al.’s stimulus materials).</p>
<p><xref ref-type="bibr" rid="bibr47-1754073912457230">Rigato and Farroni (2013)</xref> demonstrate that targets’ gaze direction also shapes perceivers’ responses to APT facial stimuli. For example, from an early age smiling faces accompanied by direct gaze have special significance as signals facilitating social interaction and the development of intersubjectivity. However, “fear” expressions accompanied by direct gaze may be ambiguous because fear involves avoidance, whereas direct gaze often implies approach (an incompatible relational orientation). Such effects probably depend on whether there is a clear object at which the sender’s gaze is directed. Indeed, direct gaze is consistent with fear of the perceiver, whereas averted gaze is consistent with fear of something else. Relatedly, research by <xref ref-type="bibr" rid="bibr7-1754073912457230">Bayliss, Frischen, Fenske, and Tipper (2007)</xref> and <xref ref-type="bibr" rid="bibr41-1754073912457230">Mumenthaler and Sander (2012)</xref> shows that gaze direction moderates effects of APT faces on appraisal of simultaneously presented objects.</p>
<p><xref ref-type="bibr" rid="bibr30-1754073912457230">Krumhuber et al. (2013)</xref> focus on how the dynamic quality of facial movements shapes their interpretation. The central message is that static facial images are less diagnostic than moving images, especially when expressions are subtle or degraded (e.g., <xref ref-type="bibr" rid="bibr8-1754073912457230">Bould &amp; Morris, 2008</xref>) and when participants are free to mimic the presented stimuli (e.g., <xref ref-type="bibr" rid="bibr34-1754073912457230">Maringer, Krumhuber, Fischer, &amp; Niedenthal, 2011</xref>). Information about the trajectory of facial movements provides stronger cues about the nature of relational activity, including emotional orientation to current circumstances. Adding further information about the dynamic attunement (or disattunement) of bodily, eye, and facial movements to unfolding environmental events (including other dynamic bodies, eyes, and faces) is likely to be even more revealing.</p>
</sec>
</sec>
<sec id="section6-1754073912457230">
<title>Universality</title>
<p><xref ref-type="bibr" rid="bibr18-1754073912457230">Elfenbein (2013)</xref> focuses on one set of factors that might contribute to cultural differences in nonverbal communication. In her view, facial configurations provide a universal language for expressing emotions (as in APT), but different cultural “accents” subtly alter these basic expressions. Decoders who are unfamiliar with these accents (e.g., because of their different cultural background) will therefore be less accurate than in-group members in their judgment of encoders’ facially expressed emotions (<italic>ingroup advantage</italic>).</p>
<p>However, other cultural differences, such as availability of matching linguistic categories, may also contribute to decoding (see <xref ref-type="bibr" rid="bibr33-1754073912457230">Lindquist &amp; Gendron, 2013</xref>), as suggested by comparisons between judgment tasks using Indo-European and other languages (<xref ref-type="bibr" rid="bibr42-1754073912457230">Nelson &amp; Russell, 2013</xref>). Indeed, nonverbal accents are unlikely to provide an exclusive explanation of all cultural differences in emotion attribution to APT faces. For example, the more dramatic differences in so-called recognition accuracy observed in isolated cultures seem to go beyond subtle differences in expression of identical emotional meanings.</p>
<p><xref ref-type="bibr" rid="bibr42-1754073912457230">Nelson and Russell (2013)</xref> update <xref ref-type="bibr" rid="bibr49-1754073912457230">Russell’s (1994)</xref> influential review of studies assessing cross-cultural consistency of emotion attributions to APT facial stimuli, and confirm that judgments depend on both the nature of the facial stimulus and the decoder’s cultural background. Any culture-independent interpretations of faces may reflect processes and factors broadly correlated with emotional meanings, rather than emotions themselves. For example, the evidence is consistent with dimensional accounts, or with the view that APT faces carry information about relational orientation (including direction of attention, approach, and withdrawal).</p>
</sec>
<sec id="section7-1754073912457230">
<title>Relational Orientation</title>
<p>This special section’s articles review a wide range of factors that moderate or directly influence production or decoding of facial activity, including culture, language, judgment tasks, posture, gaze, and facial dynamics. Despite psychological research’s predominant focus on static, isolated, and disembodied faces (see <xref ref-type="bibr" rid="bibr20-1754073912457230">Fernández-Dols, 2013</xref>), the data make it clear that emotional meaning is neither encoded in, nor decoded from, internal features of static facial configurations alone. Taking this conclusion further, I argue that the operation of facial activity often depends on its dynamic mode of relation to the situational context. Most previous research has treated contextual factors as independent or extraneous variables. Investigating facial activity that is embedded in unfolding meaningful contexts rather than abstracted from those contexts may lead to different conclusions (see also <xref ref-type="bibr" rid="bibr21-1754073912457230">Fernández-Dols &amp; Crivelli, 2013</xref>). For example, ethological approaches showing how facial movements of nonhuman animals reflect and communicate relational activity (e.g., <xref ref-type="bibr" rid="bibr55-1754073912457230">Waller &amp; Micheletta, 2013</xref>) might profitably be extended to humans.</p>
<p>Future research should focus on the relational orientations of facial configurations and movements, as embodied in directedness of sensory organs and more general movements, and their spatial and temporal relations to events in the shared environment. For instance, facial activity often serves practical functions as part of more articulated movements involving the whole body (e.g., <xref ref-type="bibr" rid="bibr13-1754073912457230">Dewey, 1895</xref>) that are directed at or away from objects (including other people). Thus, facial actions may serve as constituents of approach or withdrawal (e.g., <xref ref-type="bibr" rid="bibr1-1754073912457230">Arnold, 1960</xref>), as well as more specific defensive, aggressive, or accepting orientations (<xref ref-type="bibr" rid="bibr12-1754073912457230">de Rivera, 1984</xref>). For example, people turn away from or turn their nose up at objects that look or smell disgusting. These activities directly serve the purpose of regulating contact with unpleasant stimulation and may occur irrespective of the availability of appropriate addressees.</p>
<p>Facial activity directed towards objects in the sight of other perceivers may also influence their orientations to those objects (<xref ref-type="bibr" rid="bibr39-1754073912457230">Mead, 1934</xref>). For example, <xref ref-type="bibr" rid="bibr53-1754073912457230">Sorce, Emde, Campos, and Klinnert’s (1985)</xref> classic study of social referencing suggests that a mother’s “fear” expression directed at the visual cliff confronting her 1-year-old offspring leads the toddler to avoid that object. Further, in <xref ref-type="bibr" rid="bibr46-1754073912457230">Repacholi and Meltzoff’s (2007)</xref> study, 18-month-old infants who had observed someone directing anger towards another person who was playing with an object, subsequently played with and looked at that object less, especially when in view of the previously angry person.</p>
<p>Facial features and their movements probably evolved partly to permit communication of relational orientation to others. For example, the contrast ratio between iris and sclera permits easy tracking of the human eye’s movements by others (<xref ref-type="bibr" rid="bibr29-1754073912457230">Kobayashi &amp; Kohshima, 1997</xref>). Similarly, eyebrows may enhance the visibility of eye-widening (<xref ref-type="bibr" rid="bibr9-1754073912457230">Buck, 1984</xref>). Despite the adaptive functions of facial communication, it is also likely that socialization plays a role in the development of its specific meanings and uses. For example, facial configurations may acquire symbolic meaning from repeated associations with the performance of practical or communicative functions. As suggested earlier, people may learn to use certain patterns of facial movement as metonymic representations standing for more extended sequences of relational activity. Thus, widening eyes in response to uncertain or unexpected visual stimuli may come to be used as an indication of confusion or surprise. Some of these symbolic facial movements may also be given more articulated conventionalized meanings within a given culture (especially when the relational orientation they represent is hypercognized; <xref ref-type="bibr" rid="bibr32-1754073912457230">Levy, 1973</xref>). Depending on the prototypic representation of the society’s emotion concepts, they may develop meanings that go beyond the occasions for their original unselfconscious occurrence.</p>
<p>Relational orientations of facial activity do not operate unidirectionally on objects (or persons), but are also attuned to the reciprocal orientations of other people (<xref ref-type="bibr" rid="bibr44-1754073912457230">Parkinson, 2008</xref>). The facial movements involved in mutual adjustments of orientations are likely to be acutely sensitive to the perceptual availability of other parties to the interpersonal exchange (cf. <xref ref-type="bibr" rid="bibr6-1754073912457230">Bavelas, Black, Lemery, &amp; Mullett, 1986</xref>).</p>
<p>Of course, emotions and appraisals are not always oriented entirely at perceptually available objects. In some private situations lacking even implicit sociality, facial activity may be entirely absent, or else take idiosyncratic forms depending on mental transactions with imagined, remembered, or anticipated objects. In public, even facial orientations to mental objects can serve communicative functions. For example, I may be attentive to a ticking clock that signals the impending proximity of an unwanted rendezvous, even when those around me attach different meanings to time passing. When interacting with others, mutual regulation and adjustment of facial activity can help to calibrate relational orientations of parties approaching the same situation from different perspectives (e.g., <xref ref-type="bibr" rid="bibr31-1754073912457230">Latané &amp; Darley, 1968</xref>), establishing “common ground” (e.g., <xref ref-type="bibr" rid="bibr11-1754073912457230">Clark, 1993</xref>) between interactants before referential communication is effective. Clearly, these processes also depend on any verbal messages that are exchanged. Indeed, more research should focus on how nonverbal and verbal aspects of communication interact or perform independent functions in social interaction (e.g., <xref ref-type="bibr" rid="bibr54-1754073912457230">Wagner &amp; Lee, 1999</xref>). In any case, an important part of the context for emotion-related facial activity is the ongoing responsivity of others, including their facial responsivity.</p>
<p>Recent investigations of facial activity’s interpersonal effects go beyond extraction of explicit meaning and include implicit measures of priming and performance (e.g., <xref ref-type="bibr" rid="bibr48-1754073912457230">Roelofs, Hagenaars, &amp; Stins, 2010</xref>; <xref ref-type="bibr" rid="bibr56-1754073912457230">Whalen et al., 2013</xref>; <xref ref-type="bibr" rid="bibr58-1754073912457230">Wilkowski &amp; Meier, 2010</xref>). Such studies reinforce the conclusion that facial activity not only functions to influence attributions of basic emotions, but also brings more direct consequences for relational orientations. Apart from emotion, it is self-evident that faces are involved in a wide range of psychological function (including respiration, nutrition, thermoregulation, perception, attention, grooming, and communication; <xref ref-type="bibr" rid="bibr43-1754073912457230">Parkinson, 2005</xref>). In each case, what the face does (or what is done to the face) is part of a wider system that also involves other organs, systems, and external events. Depending on its relation to these other aspects, the same facial movement can serve a variety of purposes.</p>
</sec>
<sec id="section8-1754073912457230">
<title>Summary and Conclusions</title>
<p>At the start of this article, I asked what facial configurations mean. Based on evidence from this special section, it seems unlikely that even the highly selected set of facial configurations said to represent basic emotions are always produced in response to those emotions, or that they directly express those emotions to others irrespective of context. APT faces do not always appear when the predicted emotion is present, and sometimes do appear when it is not (e.g., <xref ref-type="bibr" rid="bibr52-1754073912457230">Schneider &amp; Josephs, 1991</xref>). Further, adults who are not explicitly provided with basic emotion categories do not automatically allocate APT expressions to these categories, and neither do young children yet to acquire categorical emotion representations. Finally, the meanings that perceivers do extract depend on processing constraints and contextual information deriving from prior and simultaneous gaze, gesture, and posture, together with external circumstances.</p>
<p>Building on these insights, I have argued that APT-inspired research has been limited in at least three general ways. First, the focus on categorical emotions as causes and meanings of facial configurations draws attention away from the wider range of processes that affect and are affected by facial configurations. Second, investigating faces in isolation from context makes it difficult to detect consequences of faces’ orientation to objects and events in the wider environment (see also <xref ref-type="bibr" rid="bibr20-1754073912457230">Fernández-Dols, 2013</xref>). Third, treatment of faces as either antecedents or consequences, independent or dependent variables, ignores dynamic processes of relational activity, in which facial movements unfold over time to perform practical and communicative functions (in relation to the objects and events to which they are directed). Facial movements can be actions as well as reactions, and their relation to emotional processes is rarely simply expressive.</p>
<p>Instead of treating facial configurations as descriptive representations of intrapsychically specified meanings, researchers need to develop ways of investigating facial activity as it operates between people and in relation to the environments they share. Explicit and implicit processes of meaning transmission are certainly an important part of the phenomenon in question. However, facial movements also play more direct roles in adjusting relations with objects and other people. It is not enough to look for emotional meanings in facial configurations, focusing on separable encoding and decoding processes. We also need to explore the roles played by facial activity in broader embodied adjustments to, and operations on, the responsive practical and social environment.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other">
<label>Author note:</label>
<p>Work on this article was conducted as part of project EROS (Emotion Regulation of Others and Self, RES-060-25-0044) and supported by the Economic and Social Research Council, UK. I am grateful to Rainer Reisenzein, José-Miguel Fernández-Dols, and an anonymous reviewer for their comments on an earlier version of this article.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Arnold</surname><given-names>M. B.</given-names></name>
</person-group> (<year>1960</year>). <source>Emotion and personality, Volume 1: Psychological aspects</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Columbia University Press</publisher-name>.</citation>
</ref>
<ref id="bibr2-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Atkinson</surname><given-names>A. P.</given-names></name>
<name><surname>Smithson</surname><given-names>H. E.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Distinct contributions to facial emotion perception of foveated versus nonfoveated facial features</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>30</fpage>–<lpage>35</lpage>.</citation>
</ref>
<ref id="bibr3-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aviezer</surname><given-names>H.</given-names></name>
<name><surname>Bentin</surname><given-names>S.</given-names></name>
<name><surname>Hassin</surname><given-names>R. R.</given-names></name>
<name><surname>Meschino</surname><given-names>W. S.</given-names></name>
<name><surname>Kennedy</surname><given-names>J.</given-names></name>
<name><surname>Grewal</surname><given-names>S.</given-names></name>
<name><surname>… Moscovitch</surname><given-names>M.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Not on the face alone: Perception of contextualized face expressions in Huntington’s disease</article-title>. <source>Brain</source>, <volume>132</volume>, <fpage>1633</fpage>–<lpage>1644</lpage>.</citation>
</ref>
<ref id="bibr4-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Aviezer</surname><given-names>H.</given-names></name>
<name><surname>Hassin</surname><given-names>R. R.</given-names></name>
<name><surname>Ryan</surname><given-names>J.</given-names></name>
<name><surname>Grady</surname><given-names>C.</given-names></name>
<name><surname>Susskind</surname><given-names>J.</given-names></name>
<name><surname>Anderson</surname><given-names>A.</given-names></name>
<name><surname>… Bentin</surname><given-names>S.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Angry, disgusted, or afraid? Studies on the malleability of emotion perception</article-title>. <source>Psychological Science</source>, <volume>19</volume>, <fpage>724</fpage>–<lpage>732</lpage>.</citation>
</ref>
<ref id="bibr5-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barr</surname><given-names>C. L.</given-names></name>
<name><surname>Kleck</surname><given-names>R. E.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Self–other perception of the intensity of facial expressions of emotion: Do we know what we show?</article-title> <source>Journal of Personality and Social Psychology</source>, <volume>68</volume>, <fpage>608</fpage>–<lpage>618</lpage>.</citation>
</ref>
<ref id="bibr6-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bavelas</surname><given-names>J. B.</given-names></name>
<name><surname>Black</surname><given-names>A.</given-names></name>
<name><surname>Lemery</surname><given-names>C. R.</given-names></name>
<name><surname>Mullett</surname><given-names>J.</given-names></name>
</person-group> (<year>1986</year>). <article-title>“I show how you feel”: Motor mimicry as a communicative act</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>50</volume>, <fpage>322</fpage>–<lpage>329</lpage>.</citation>
</ref>
<ref id="bibr7-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bayliss</surname><given-names>A.</given-names></name>
<name><surname>Frischen</surname><given-names>A.</given-names></name>
<name><surname>Fenske</surname><given-names>M.</given-names></name>
<name><surname>Tipper</surname><given-names>S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Affective evaluations of objects are influenced by observed gaze direction and emotional expression</article-title>. <source>Cognition</source>, <volume>104</volume>, <fpage>644</fpage>–<lpage>653</lpage>.</citation>
</ref>
<ref id="bibr8-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bould</surname><given-names>E.</given-names></name>
<name><surname>Morris</surname><given-names>N.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Role of motion signals in recognizing subtle facial expressions of emotion</article-title>. <source>British Journal of Psychology</source>, <volume>99</volume>, <fpage>167</fpage>–<lpage>189</lpage>.</citation>
</ref>
<ref id="bibr9-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Buck</surname><given-names>R.</given-names></name>
</person-group> (<year>1984</year>). <source>The communication of emotion</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chovil</surname><given-names>N.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Facing others: A social communicative perspective on facial displays</article-title>. In <person-group person-group-type="editor">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>The psychology of facial expression</source> (pp. <fpage>321</fpage>–<lpage>333</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr11-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Clark</surname><given-names>H. H.</given-names></name>
</person-group> (<year>1993</year>). <source>Arenas of language use</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr12-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>De Rivera</surname><given-names>J. H.</given-names></name>
</person-group> (<year>1984</year>). <article-title>The structure of emotional relationships</article-title>. In <person-group person-group-type="editor">
<name><surname>Shaver</surname><given-names>P.</given-names></name>
</person-group> (Ed.), <source>Review of personality and social psychology 5: Emotions, relationships, and health</source> (pp. <fpage>116</fpage>–<lpage>145</lpage>). <publisher-loc>Beverly Hills, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr13-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dewey</surname><given-names>J.</given-names></name>
</person-group> (<year>1895</year>). <article-title>The theory of emotion, II: The significance of emotional attitudes</article-title>. <source>Psychological Review</source>, <volume>2</volume>, <fpage>13</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr14-1754073912457230">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
</person-group> (<year>1972</year>). <article-title>Universals and cultural differences in facial expressions of emotion</article-title>. In <person-group person-group-type="editor">
<name><surname>Cole</surname><given-names>J.</given-names></name>
</person-group> (Ed.), <conf-name>Nebraska Symposium on Motivation</conf-name> (pp. <fpage>207</fpage>–<lpage>283</lpage>). <publisher-loc>Lincoln, NE</publisher-loc>: <publisher-name>University of Nebraska Press</publisher-name>.</citation>
</ref>
<ref id="bibr15-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
</person-group> (<year>1992</year>). <article-title>An argument for basic emotions</article-title>. <source>Cognition &amp; Emotion</source>, <volume>6</volume>, <fpage>169</fpage>–<lpage>200</lpage>.</citation>
</ref>
<ref id="bibr16-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
<name><surname>Friesen</surname><given-names>W. V.</given-names></name>
</person-group> (<year>1976</year>). <source>Pictures of facial affect</source>. <publisher-loc>Palo Alto, CA</publisher-loc>: <publisher-name>Consulting Psychologists Press</publisher-name>.</citation>
</ref>
<ref id="bibr17-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>P.</given-names></name>
<name><surname>Friesen</surname><given-names>W. V.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Felt, false, and miserable smiles</article-title>. <source>Journal of Nonverbal Behavior</source>, <volume>6</volume>, <fpage>238</fpage>–<lpage>258</lpage>.</citation>
</ref>
<ref id="bibr18-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Elfenbein</surname><given-names>H. A.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Nonverbal dialects and accents in facial expressions of emotion</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>90</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr19-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fehr</surname><given-names>B.</given-names></name>
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Concept of emotion viewed from a prototype perspective</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>113</volume>, <fpage>464</fpage>–<lpage>486</lpage>.</citation>
</ref>
<ref id="bibr20-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Advances in the study of facial expression: An introduction to the special section</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>3</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr21-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
<name><surname>Crivelli</surname><given-names>C.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Emotion and expression: Naturalistic studies</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>24</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr22-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fridlund</surname><given-names>A. J.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Sociality of solitary smiling: Potentiation by an implicit audience</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>60</volume>, <fpage>229</fpage>–<lpage>240</lpage>.</citation>
</ref>
<ref id="bibr23-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fridlund</surname><given-names>A. J.</given-names></name>
</person-group> (<year>1994</year>). <source>Human facial expression: An evolutionary view</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr24-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Frijda</surname><given-names>N. H.</given-names></name>
<name><surname>Tcherkassof</surname><given-names>A.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Facial expressions as modes of action readiness</article-title>. In <person-group person-group-type="editor">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>The psychology of facial expression</source> (pp. <fpage>78</fpage>–<lpage>102</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr25-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fugate</surname><given-names>J. M. B.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Categorical perception for emotional faces</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>84</fpage>–<lpage>89</lpage>.</citation>
</ref>
<ref id="bibr26-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilovich</surname><given-names>T.</given-names></name>
<name><surname>Savitsky</surname><given-names>K.</given-names></name>
<name><surname>Medvec</surname><given-names>V. H.</given-names></name>
</person-group> (<year>1998</year>). <article-title>The illusion of transparency: Biased assessment of others’ ability to read ones’ emotional states</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>75</volume>, <fpage>332</fpage>–<lpage>346</lpage>.</citation>
</ref>
<ref id="bibr27-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hassin</surname><given-names>R. R.</given-names></name>
<name><surname>Aviezer</surname><given-names>H.</given-names></name>
<name><surname>Bentin</surname><given-names>S.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Inherently ambiguous: Facial expressions of emotions, in context</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>60</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr28-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Horstmann</surname><given-names>G.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Facial expressions of emotion: Does the prototype represent central tendency, frequency of instantiation, or an ideal?</article-title> <source>Emotion</source>, <volume>2</volume>, <fpage>297</fpage>–<lpage>305</lpage>.</citation>
</ref>
<ref id="bibr29-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kobayashi</surname><given-names>H.</given-names></name>
<name><surname>Kohshima</surname><given-names>S.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Unique morphology of the human eye</article-title>. <source>Nature</source>, <volume>387</volume>, <fpage>767</fpage>–<lpage>768</lpage>.</citation>
</ref>
<ref id="bibr30-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Krumhuber</surname><given-names>E. G.</given-names></name>
<name><surname>Kappas</surname><given-names>A.</given-names></name>
<name><surname>Manstead</surname><given-names>A. S. R.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Effects of dynamic aspects of facial expressions: A review</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>41</fpage>–<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr31-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Latané</surname><given-names>B.</given-names></name>
<name><surname>Darley</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1968</year>). <article-title>Group inhibition of bystander intervention in emergencies</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>10</volume>, <fpage>215</fpage>–<lpage>221</lpage>.</citation>
</ref>
<ref id="bibr32-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Levy</surname><given-names>R.</given-names></name>
</person-group> (<year>1973</year>). <source>Tahitians</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Chicago University Press</publisher-name>.</citation>
</ref>
<ref id="bibr33-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lindquist</surname><given-names>K. A.</given-names></name>
<name><surname>Gendron</surname><given-names>M.</given-names></name>
</person-group> (<year>2013</year>). <article-title>What’s in a word? Language constructs emotion perception</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>66</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr34-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Maringer</surname><given-names>M.</given-names></name>
<name><surname>Krumhuber</surname><given-names>E.</given-names></name>
<name><surname>Fischer</surname><given-names>A. H.</given-names></name>
<name><surname>Niedenthal</surname><given-names>P. M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Beyond smile dynamics: Mimicry and beliefs in judgments of smiles</article-title>. <source>Emotion</source>, <volume>11</volume>, <fpage>181</fpage>–<lpage>187</lpage>.</citation>
</ref>
<ref id="bibr35-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Matsumoto</surname><given-names>D.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Cultural influences on the perception of emotion</article-title>. <source>Journal of Cross-Cultural Psychology</source>, <volume>20</volume>, <fpage>92</fpage>–<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr36-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Matsumoto</surname><given-names>D.</given-names></name>
<name><surname>Willingham</surname><given-names>B.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The thrill of victory and the agony of defeat: Spontaneous expressions of medal winners of the 2004 Athens Olympic Games</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>91</volume>, <fpage>568</fpage>–<lpage>581</lpage>.</citation>
</ref>
<ref id="bibr37-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Matsumoto</surname><given-names>D.</given-names></name>
<name><surname>Willingham</surname><given-names>B.</given-names></name>
<name><surname>Olide</surname><given-names>A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Sequential dynamics of culturally-moderated facial expressions of emotion</article-title>. <source>Psychological Science</source>, <volume>20</volume>, <fpage>1269</fpage>–<lpage>1274</lpage>.</citation>
</ref>
<ref id="bibr38-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mauss</surname><given-names>I. B.</given-names></name>
<name><surname>Levenson</surname><given-names>R. W.</given-names></name>
<name><surname>McCarter</surname><given-names>L.</given-names></name>
<name><surname>Wilhelm</surname><given-names>F. L.</given-names></name>
<name><surname>Gross</surname><given-names>J. J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The tie that binds? Coherence among emotion experience, behavior, and physiology</article-title>. <source>Emotion</source>, <volume>5</volume>, <fpage>175</fpage>–<lpage>190</lpage>.</citation>
</ref>
<ref id="bibr39-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Mead</surname><given-names>G. H.</given-names></name>
</person-group> (<year>1934</year>). <source>Mind, self, and society</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Chicago University Press</publisher-name>.</citation>
</ref>
<ref id="bibr40-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mortillaro</surname><given-names>M.</given-names></name>
<name><surname>Mehu</surname><given-names>M.</given-names></name>
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Subtly different positive emotions can be distinguished by their facial expressions</article-title>. <source>Social, Psychological and Personality Science</source>, <volume>2</volume>, <fpage>262</fpage>–<lpage>271</lpage>.</citation>
</ref>
<ref id="bibr41-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mumenthaler</surname><given-names>C.</given-names></name>
<name><surname>Sander</surname><given-names>D.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Social appraisal influences recognition of emotions</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>102</volume>, <fpage>1118</fpage>–<lpage>1135</lpage>.</citation>
</ref>
<ref id="bibr42-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nelson</surname><given-names>N. L.</given-names></name>
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Universality revisited</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>8</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr43-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parkinson</surname><given-names>B.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Do facial movements express emotions or communicate motives?</article-title> <source>Personality and Social Psychology Review</source>, <volume>9</volume>, <fpage>278</fpage>–<lpage>311</lpage>.</citation>
</ref>
<ref id="bibr44-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parkinson</surname><given-names>B.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Emotions in direct and remote social interaction: Getting through the spaces between us</article-title>. <source>Computers in Human Behavior</source>, <volume>24</volume>, <fpage>1510</fpage>–<lpage>1529</lpage>.</citation>
</ref>
<ref id="bibr45-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Reisenzein</surname><given-names>R.</given-names></name>
<name><surname>Studtmann</surname><given-names>M.</given-names></name>
<name><surname>Horstmann</surname><given-names>G.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Coherence between emotion and facial expression: Evidence from laboratory experiments</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>16</fpage>–<lpage>23</lpage>.</citation>
</ref>
<ref id="bibr46-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Repacholi</surname><given-names>B. M.</given-names></name>
<name><surname>Meltzoff</surname><given-names>A. N.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Emotional eavesdropping: Infants selectively respond to indirect emotional signals</article-title>. <source>Child Development</source>, <volume>78</volume>, <fpage>503</fpage>–<lpage>521</lpage>.</citation>
</ref>
<ref id="bibr47-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rigato</surname><given-names>S.</given-names></name>
<name><surname>Farroni</surname><given-names>T.</given-names></name>
</person-group> (<year>2013</year>). <article-title>The role of gaze in the processing of emotional facial expressions</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>36</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr48-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Roelofs</surname><given-names>K.</given-names></name>
<name><surname>Hagenaars</surname><given-names>M. A.</given-names></name>
<name><surname>Stins</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Facing freeze: Social threat induces bodily freeze in humans</article-title>. <source>Psychological Science</source>, <volume>21</volume>, <fpage>1575</fpage>–<lpage>1581</lpage>.</citation>
</ref>
<ref id="bibr49-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Is there universal recognition of emotion from facial expressions? A review of the cross cultural studies</article-title>. <source>Psychological Bulletin</source>, <volume>115</volume>, <fpage>102</fpage>–<lpage>141</lpage>.</citation>
</ref>
<ref id="bibr50-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>What does a facial expression mean?</article-title> In <person-group person-group-type="editor">
<name><surname>Russell</surname><given-names>J. A.</given-names></name>
<name><surname>Fernández-Dols</surname><given-names>J. M.</given-names></name>
</person-group> (Eds.), <source>The psychology of facial expression</source> (pp. <fpage>3</fpage>–<lpage>30</lpage>). <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr51-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scherer</surname><given-names>K. R.</given-names></name>
<name><surname>Mortillaro</surname><given-names>M.</given-names></name>
<name><surname>Mehu</surname><given-names>M.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Understanding the mechanisms underlying the production of facial expression of emotion: A componential perspective</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>47</fpage>–<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr52-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schneider</surname><given-names>K.</given-names></name>
<name><surname>Josephs</surname><given-names>I.</given-names></name>
</person-group> (<year>1991</year>). <article-title>The expressive and communicative functions of preschool children’s smiles in an achievement situation</article-title>. <source>Journal of Nonverbal Behavior</source>, <volume>15</volume>, <fpage>185</fpage>–<lpage>198</lpage>.</citation>
</ref>
<ref id="bibr53-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sorce</surname><given-names>J. F.</given-names></name>
<name><surname>Emde</surname><given-names>R. N.</given-names></name>
<name><surname>Campos</surname><given-names>J.</given-names></name>
<name><surname>Klinnert</surname><given-names>M. D.</given-names></name>
</person-group> (<year>1985</year>). <article-title>Maternal emotional signaling: Its effect on the visual cliff behavior of 1 year olds</article-title>. <source>Developmental Psychology</source>, <volume>21</volume>, <fpage>195</fpage>–<lpage>200</lpage>.</citation>
</ref>
<ref id="bibr54-1754073912457230">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wagner</surname><given-names>H. L.</given-names></name>
<name><surname>Lee</surname><given-names>V.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Facial behavior alone and in the presence of others</article-title>. In <person-group person-group-type="editor">
<name><surname>Philippot</surname><given-names>P.</given-names></name>
<name><surname>Feldman</surname><given-names>R. S.</given-names></name>
<name><surname>Coats</surname><given-names>E. J.</given-names></name>
</person-group> (Eds.), <source>The social context of nonverbal behavior</source> (pp. <fpage>262</fpage>–<lpage>286</lpage>). <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr55-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Waller</surname><given-names>B. M.</given-names></name>
<name><surname>Micheletta</surname><given-names>J.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Facial expression in nonhuman animals</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>54</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr56-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Whalen</surname><given-names>P. J.</given-names></name>
<name><surname>Raila</surname><given-names>H.</given-names></name>
<name><surname>Bennett</surname><given-names>R.</given-names></name>
<name><surname>Mattek</surname><given-names>A.</given-names></name>
<name><surname>Brown</surname><given-names>A.</given-names></name>
<name><surname>Taylor</surname><given-names>J.</given-names></name>
<name><surname>… Palmer</surname><given-names>A.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Neuroscience and facial expressions of emotion: The role of amygdala–prefrontal interactions</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>78</fpage>–<lpage>83</lpage>.</citation>
</ref>
<ref id="bibr57-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Widen</surname><given-names>S. C.</given-names></name>
</person-group> (<year>2013</year>). <article-title>Children’s interpretation of facial expressions: The long path from valence-based to specific discrete categories</article-title>. <source>Emotion Review</source>, <volume>5</volume>, <fpage>72</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr58-1754073912457230">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilkowski</surname><given-names>B. M.</given-names></name>
<name><surname>Meier</surname><given-names>B. P.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Bring it on: Angry facial expressions potentiate approach-motivated motor behavior</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>98</volume>, <fpage>201</fpage>–<lpage>210</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>