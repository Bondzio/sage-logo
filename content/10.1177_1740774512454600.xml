<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">CTJ</journal-id>
<journal-id journal-id-type="hwp">spctj</journal-id>
<journal-id journal-id-type="nlm-ta">Clin Trials</journal-id>
<journal-title>Clinical Trials</journal-title>
<issn pub-type="ppub">1740-7745</issn>
<issn pub-type="epub">1740-7753</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1740774512454600</article-id>
<article-id pub-id-type="publisher-id">10.1177_1740774512454600</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Stopping a trial early – and then what?</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Wittes</surname><given-names>Janet</given-names></name>
</contrib>
<aff id="aff1-1740774512454600">Statistics Collaborative, Inc., Washington, DC, USA</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1740774512454600">Janet Wittes, Statistics Collaborative, Inc., 1625 Massachusetts Avenue, NW, Suite 600, Washington, DC 20036, USA. Email: <email>janet@statcollab.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>12</month>
<year>2012</year>
</pub-date>
<volume>9</volume>
<issue>6</issue>
<issue-title>University of Pennsylvania Conference on Statistical Issues in Clinical Trials: Emerging statistical issues in the conduct and monitoring of clinical trials</issue-title>
<fpage>714</fpage>
<lpage>720</lpage>
<permissions>
<copyright-statement>© The Author(s), 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">The Society for Clinical Trials</copyright-holder>
</permissions>
<abstract>
<sec id="section1-1740774512454600">
<title>Background</title>
<p>This article addresses a problem arising when a trial shows such strong evidence of benefit of the tested intervention that it stops early with an observed effect size for the experimental treatment that is statistically significantly better than the control. Within the classical frequentist framework of group sequential trials, the observed estimated effect size, the associated naïve confidence interval, and the p-value are all biased estimates of the true values. The bias is in the direction of the overestimation of the treatment effect, creation of narrower confidence intervals than appropriate, and a p-value that is too small.</p>
</sec>
<sec id="section2-1740774512454600">
<title>Purpose</title>
<p>To discuss methods for correcting the bias in observed effect sizes, confidence intervals, and p-values for trials stopped early and to show the extent to which such correction would have modified the conclusions of the Randomized Aldactone Evaluation Study (RALES).</p>
</sec>
<sec id="section3-1740774512454600">
<title>Results</title>
<p>In RALES, the effect of not correcting for bias is negligible.</p>
</sec>
<sec id="section4-1740774512454600">
<title>Limitations</title>
<p>This article does not show general results; it only explores a few examples that use conservative methods for early stopping. It does not consider sequential methods that allow a relatively high probability of stopping early.</p>
</sec>
<sec id="section5-1740774512454600">
<title>Conclusions</title>
<p>This article points out that there is no unique solution to the correction of the p-value, but it recommends stagewise ordering, which states that earlier stopping of a trial is ipso facto stronger evidence of effect than later stopping so long as the stopping is governed by a monitoring boundary that preserves the Type I error rate. Associated with stagewise ordering is a method for calculating the estimated effect size and its confidence interval. In the RALES trial, which stopped at 50% information time, the corrections to the estimated values are small.</p>
</sec>
</abstract>
</article-meta>
</front>
<body>
<sec id="section6-1740774512454600" sec-type="intro">
<title>Introduction</title>
<p>This article addresses a problem faced by investigators lucky enough to be involved in a trial with such strong evidence of benefit of the tested intervention that the trial stops early with an observed effect size for the experimental treatment that is statistically significantly better than the control. Statisticians are aware that the observed p-value and effect size from such a trial overstate the evidence of benefit; the question is how profound is the overstatement and what values should be reported in the articles describing the results. Throughout this article, I shall assume that the recommendation for early stopping arose because the trajectory of the data from the trial crossed a prespecified statistical boundary constructed in a way that preserved the desired Type I error rate α of the trial. For simplicity of presentation, I shall assume that the boundary used is either the original O’Brien–Fleming [<xref ref-type="bibr" rid="bibr1-1740774512454600">1</xref>] boundary or, more likely, a Lan–DeMets [<xref ref-type="bibr" rid="bibr2-1740774512454600">2</xref>] spending function that mimics it; however, the discussion is relevant to any reasonably conservative α-preserving boundary and trial that does not stop very early. Several articles have addressed the problem; see, for example, a series of articles by DeMets and coauthors [<xref ref-type="bibr" rid="bibr3-1740774512454600">3</xref><xref ref-type="bibr" rid="bibr4-1740774512454600"/><xref ref-type="bibr" rid="bibr5-1740774512454600"/>–<xref ref-type="bibr" rid="bibr6-1740774512454600">6</xref>].</p>
<p>A comment about the words ‘boundary’ and ‘guideline’ is as follows: I refer to a set of numerical criteria for early stopping as a ‘boundary’ in the sense that the rigidity of the criteria allows the conduct of the trial to be α-preserving. In practice, however, the Data Monitoring Committee (DMC) tracking the course of the trial uses the criteria as ‘guidelines’ not as rules because the DMC might recommend stopping prior to crossing the boundary (in which case the investigators cannot rigorously claim to have demonstrated efficacy) or it might recommend not stopping even if the boundary is crossed (e.g., see the report of the Clopidogrel in Unstable Angina to Prevent Recurrent Events (CURE) Trial study [<xref ref-type="bibr" rid="bibr7-1740774512454600">7</xref>]).</p>
<p>One purpose of this article is to right a wrong I committed about a decade ago as part of the group reporting the results of The Randomized Aldactone Evaluation Study (RALES) [<xref ref-type="bibr" rid="bibr8-1740774512454600">8</xref>]. The trial compared spironolactone to placebo with respect to total mortality in patients with Classes 3 and 4 heart failure. The trial stopped early after crossing an O’Brien–Fleming-like boundary (calculated through a Lan–DeMets spending function), and we reported the results as we saw them; we corrected neither the p-value nor the effect size for having stopped early. I have consoled myself for this lapse because I knew that other trials that had stopped early had also failed to correct the observed results for having stopped early. Another source of consolation has been that I have been aware that frequentists have many ways of correcting the estimates. Therefore, because the analysis plan had not specified the method to be used for correction, any correction would have been post hoc. Nonetheless, in this article, I will provide a reasonable update, though post hoc, to the reported results of RALES [<xref ref-type="bibr" rid="bibr8-1740774512454600">8</xref>].</p>
<p>Before proceeding, I shall mention two other trials that stopped early for benefit, neither of which corrected their estimated effect sizes for having stopped early. These two trials are typical of the reporting of trials that stop early for benefit. The Metoprolol CR/XL Randomized Intervention Trial in Congestive Heart Failure (MERIT-HF) [<xref ref-type="bibr" rid="bibr9-1740774512454600">9</xref>] tested the effect of metoprolol on total mortality in heart failure patients. On the recommendation of its Independent Data Monitoring Committee, the investigators stopped the trial at the second interim analysis. At that point, the observed relative risk of death was 0.66 with an uncorrected 95% confidence interval of (0.53–0.81). The article describing the primary results reported those estimates. The article does report a corrected p-value. MERIT-HF is often used as an example of how to interpret data when the results from the United States differ from the results elsewhere (e.g., Ref. [<xref ref-type="bibr" rid="bibr10-1740774512454600">10</xref>]).</p>
<p>Another example is a trial that studied patients with pancreatic islet cell tumors [<xref ref-type="bibr" rid="bibr11-1740774512454600">11</xref>]. The study, which compared progression-free survival in patients treated with sunitinib or placebo, stopped with half the number of prespecified events. At that time, the median time to progression or death in the sunitinib group was 11 months compared to 5 months in the placebo group. The observed hazard ratio was 0.42 with an uncorrected p-value less than 0.001. The article describing the results did not correct the estimates or p-value for having stopped early.</p>
<p>In 2010, Bassler <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr12-1740774512454600">12</xref>] compared the treatment effects from what the authors called ‘truncated’ randomized clinical trials (RCTs), that is, trials that stopped early for benefit, against trials addressing similar questions, but not stopped early. The authors said their objective was ‘to compare the treatment effect from truncated RCTs with that from meta-analyses of RCTs addressing the same question but not stopped early (nontruncated RCTs) and to explore factors associated with overestimates of effect.’ The authors concluded that ‘truncated’ RCTs were associated with larger effect sizes than those not stopped early. They said that the difference was independent of the presence of statistical stopping rules and greatest with smaller sample sizes. The journal published four letters to the editor criticizing the article from different angles. Berry <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr13-1740774512454600">13</xref>] and Goodman <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr14-1740774512454600">14</xref>] pointed to logical and mathematical flaws. The other two letters lamented the article’s suggestion not to stop trial early. Korn <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr15-1740774512454600">15</xref>] wrote, ‘Stopping a trial and releasing the information early allows current and future patients to benefit from new therapies as soon as possible’. Ellenberg <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr16-1740774512454600">16</xref>] wrote, ‘They seem to be warning against early trial termination. This is a much more complex issue on which the problem of modest upward bias of the effect estimate, readily remediable by existing methodology, should have little bearing’. Those words ‘readily remediable’ spurred me to reconsider how we should have reported the results of RALES. In general, ensuring that the reports of trials that stop early appropriately correct for the early stopping should alleviate the problems to which Bassler <italic>et al</italic>. refer.</p>
<p>The following section presents several methods for correcting p-values and recommends one in particular. This article then discusses how to calculate confidence intervals and estimates after early stopping for efficacy along with what the corrected estimates would have been in RALES (‘Confidence intervals and estimates after early stopping’ section). The final section summarizes recommendations. The entire article remains within the frequentist paradigm; in this sphere, however, the Bayesians have a major advantage: as results emerge, the Bayesian framework naturally updates estimates in a way that pulls back an observed overestimated effect.</p>
</sec>
<sec id="section7-1740774512454600">
<title>How to report p-values after early stopping for efficacy</title>
<p>This section describes methodology presented by Proschan <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr17-1740774512454600">17</xref>] for calculating an appropriate p-value when a trial stops early for efficacy. Throughout this article, all p-values come from one-sided tests. In a clinical trial without interim monitoring, calculating a p-value is simple. Elementary classical statistics show that a p-value has two dissimilar sounding definitions that are, in fact, equivalent. One definition states that the p-value from an experiment is the smallest Type I error rate for which the results would have been statistically significant. The alternative definition states that the p-value is the probability under the null hypothesis that the test statistic would be at least as large as the value observed. A typical homework problem in elementary statistics is to show that these two definitions are equivalent.</p>
<p>Now consider sequential or group sequential trials: here the two definitions do not produce the same p-values. Suppose, for example, we use the first definition when a trial has crossed a boundary for significance, and we look for the smallest α for which the results would have been statistically significant. Imagine, for example, a trial using O’Brien–Fleming boundaries with five equally spaced looks. To find the smallest α that would have shown statistical significance, we consider the class of similar boundaries differing only by the choice of α. Our task is to find the α that just ‘hits’ significance. As shown in <xref ref-type="fig" rid="fig1-1740774512454600">Figure 1</xref>, the cutoffs for the five looks are Z = 4.88, 3.36, 2.68, 2.29, and 2.03. Suppose at the third look, the observed Z-value is 2.94, which is higher than the cutoff of 2.68.</p>
<fig id="fig1-1740774512454600" position="float">
<label>Figure 1.</label>
<caption>
<p>Five look O’Brien–Fleming Boundary with Z-value and B-value cutoffs and a trial that crossed the boundary at Look 3.</p>
</caption>
<graphic xlink:href="10.1177_1740774512454600-fig1.tif"/></fig>
<p>A naïve uncorrected calculation would report that the two-sided p-value is 0.002, corresponding to a Z = 2.94. That clearly does not satisfy the first definition of a p-value. To perform the calculation, instead of the Z-value, it is easier to determine the correct p-value using the boundary defined by the B-value [<xref ref-type="bibr" rid="bibr18-1740774512454600">18</xref>], which is Z(t) × √t, where t is information time and Z(t) is the Z-value at time t. As Proschan <italic>et al</italic>. show, the O’Brien–Fleming boundary in terms of B-values rather than Z-values is a horizontal line defined by the number of looks. In this case, with five looks, the line is B<sup>b</sup>(t) = 2.03, where B<sup>b</sup>(t) represents the B-value boundary. For the example, Z(3/5) = 2.94, and therefore, the observed B-value at 3/5 is B<sup>Obs</sup>(3/5) = 2.28. The α for which B<sup>Obs</sup>(3/5) = 2.28 would just hit statistical significance is 0.013. So 0.013 is a first approximation to the p-value under Definition 1.</p>
<p>The value 0.013 is only a first approximation because some paths of the trajectory of the data would have been impossible. The trial could have stopped at the first or second look; if so, paths corresponding to those early stops could not have occurred. For example, if the B-values at the first and second looks had been B<sup>Obs</sup>(1/5) = 1.8 and B<sup>Obs</sup> (2/5) = 2.2, the trial could have stopped at the second look. As shown in the previous paragraph, failure to account for the paths that would have been consistent with stopping earlier than the third look would have produced a p-value of 0.013; taking those aborted paths into account gives p = 0.01. Notice how different these p-values are from 0.002, the naïve value. So what looked like a very small p-value, 0.002, should be closer to 0.01.</p>
<p>The p-value of 0.01, however, may not be correct either because the aborted exit probabilities depended on what we had planned. At the first and second look, the future had not yet occurred. An assertion that the trial would have stopped had the data crossed at either of those looks is therefore a condition contrary to fact: we cannot be certain what the DMC would have recommended had the boundary been crossed earlier. The DMC, like the DMC in CURE [<xref ref-type="bibr" rid="bibr7-1740774512454600">7</xref>], may have recommended continuing the trial in spite of the fact that the boundary had been crossed. So under Definition 1 of the p-value, the best we can say is that p-value corrected for early stopping falls somewhere between 0.01 and 0.013; where it falls depends on what the DMC would have recommended had the boundary been crossed at the first or second look. And that is unknowable.</p>
<p>Consider now Definition 2, the probability under the null hypothesis that the test statistic is at least as great as observed. Unfortunately, the test statistic has not one, but two, relevant quantities: the information time t and the associated Z(t), or equivalently, B<sup>Obs</sup>(t). In the example at hand, t = 0.6, Z(3/5) = 2.94, and B<sup>Obs</sup>(3/5) = 2.28. To find the p-value, we must define what other <italic>pairs</italic> of observations would have been more extreme than the observed pair. Ordering pairs can be ambiguous. Consider four different cases with two trials and ask which trial shows more extreme data (see <xref ref-type="fig" rid="fig2-1740774512454600">Figure 2</xref>). In each case, one trial is represented by a triangle and the other by a square. The first case, shown in Panel A, is easy. The Triangle Trial crossed the boundary at the second look with Z(2/5) = 4; the Square Trial still hadn’t stopped by the third look with Z(3/5) = 3. No matter what you value more, early stopping or a larger Z-value, the trajectory for the Triangle Trial is clearly more extreme than the one for the Square Trial. The other three cases are more ambiguous. In Panel B, both trials have Z-values of 2.03; for the Triangle Trial, Z(1/5) = 2.03, while for the Square Trial, Z(1) = 2.03. It is not clear which pair is more extreme – the decision depends on one’s view of ‘extreme’. Some people might find pair (1, 2.03) more extreme than (1/5, 2.03) because the former hit the prespecified boundary; others might say the latter is more extreme because Z(t) was large early. Panels C and D show the same Z-values, but the values occur closer in time than they did in Panel B. Some people might consider in their ordering how far above the boundary the point sits; others may not consider this relevant to their ordering. The point is that the p-value under Definition 2 depends on how we order the observed pairs, and ordering is not unique.</p>
<fig id="fig2-1740774512454600" position="float">
<label>Figure 2.</label>
<caption>
<p>Which point is more extreme?</p>
</caption>
<graphic xlink:href="10.1177_1740774512454600-fig2.tif"/></fig>
<p>In our example, if we order by the observed B-value, the p-value is 0.01. If we order by the z-values, then p = 0.003. If we decided instead to calculate the maximum likelihood estimate and calculate the p-value for that, we would find p = 0.002. What is troubling here is that not only is the p-value not uniquely determined but also all three of these methods require us to assume that the trial would have stopped earlier had the trajectory of the data crossed the boundary.</p>
<p>Rather than second guess what would have happened in an unknowable situation, we could insist on ordering by stages, thus defining early stopping as ipso facto determining how to order events. For two trials that stop at the same time t, declare the one with the larger Z(t) to represent more extreme evidence of benefit. If the observation that led to crossing the boundary and stopping the study is (t<sub>j</sub>, Z(t<sub>j</sub>)), the p-value is the probability under the null of stopping before time t<sub>j</sub> plus the probability of not stopping before t<sub>j</sub> and observing a z-value at least as great as Z<sub>j</sub>. So in our example, the p-value would have been P<sub>Ho</sub> {stop before t<sub>j</sub>} + P<sub>Ho</sub> {don’t stop before t<sub>j</sub> and Z(t<sub>j</sub> ≥ z<sub>j</sub>)} = 0.000395 + (0.999605)(0.001568) = 0.0020. This is called ‘stagewise ordering’.</p>
<p>Thus, as seen in <xref ref-type="table" rid="table1-1740774512454600">Table 1</xref>, we have four possible definitions of a p-value corrected for early stopping. Three of them require an assumption about what would have happened under conditions contrary to fact. The fourth, the stagewise ordering, is attractive because it is natural to accept the principle that in terms of evidence of effect, early stopping trumps stopping later. It turns out that in the example at hand, this ordering produces a p-value only slightly larger than the naïve unadjusted p-value (0.0020 vs. 0.0016).</p>
<table-wrap id="table1-1740774512454600" position="float">
<label>Table 1.</label>
<caption>
<p>The p-values for example: O’Brien–Fleming boundary with five equally spaced planned looks and an observed Z = 2.94 at Look 3</p>
</caption>
<graphic alternate-form-of="table1-1740774512454600" xlink:href="10.1177_1740774512454600-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th align="left">Method</th>
<th align="left">p-value</th>
<th align="left">Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Unadjusted</td>
<td>0.0016</td>
<td>This is the naïve p-value not corrected for early stopping.</td>
</tr>
<tr>
<td>B-value ordering</td>
<td>0.010</td>
<td rowspan="3">These three methods require the user to assume that had the study data crossed the prespecified boundaries at an earlier look, the study in fact would have stopped.</td>
</tr>
<tr>
<td>Z-value ordering</td>
<td>0.003</td>
</tr>
<tr>
<td>MLE ordering</td>
<td>0.002</td>
</tr>
<tr>
<td>Stagewise ordering</td>
<td>0.002</td>
<td>The method does not make any assumption about whether or not the study would have stopped earlier if the data had crossed the prespecified boundary.</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1740774512454600"><p>MLE: Maximum likelihood ordering.</p></fn>
</table-wrap-foot></table-wrap>
</sec>
<sec id="section8-1740774512454600">
<title>Confidence intervals and estimates after early stopping</title>
<p>Emerson and Fleming [<xref ref-type="bibr" rid="bibr19-1740774512454600">19</xref>] present a method, extended by Liu and Hall [<xref ref-type="bibr" rid="bibr20-1740774512454600">20</xref>], for providing an unbiased estimate of the parameter of interest after a trial stops. In this section, I instead recommend adopting a method that is more closely tied to the stagewise ordering. See Kim and DeMets [<xref ref-type="bibr" rid="bibr21-1740774512454600">21</xref>] and Kim [<xref ref-type="bibr" rid="bibr22-1740774512454600">22</xref>] for earlier discussions of this and related methodology.</p>
<p>To calculate confidence intervals, start with a p-value from stagewise ordering then back-calculate from the p-value, either by numerical integration or by performing a grid search using the program Landem [<xref ref-type="bibr" rid="bibr23-1740774512454600">23</xref>]. Then, define the middle of the interval as the estimate of the effect making sure, of course, to be calculating the confidence interval in the correct scale. For hazard ratios, for example, the confidence interval should be on the logarithmic scale leading to an estimated log(hazard ratio) in the middle of the interval. As Proschan <italic>et al</italic>. [<xref ref-type="bibr" rid="bibr17-1740774512454600">17</xref>] point out, in some situations, the confidence interval defined in this stagewise manner might exclude the uncorrected maximum likelihood estimate.</p>
<p>Application of the above approach allows an answer to what really should have been the p-value and estimated hazard ratio for RALES, a study of spironolactone in patients with Classes 3 and 4 heart failure [<xref ref-type="bibr" rid="bibr8-1740774512454600">8</xref>]. The study had two primary outcomes with Type I error rate of 0.04 assigned to total mortality and 0.01 assigned to hospitalization for heart failure. Its monitoring plan was based on a Lan–DeMets spending function with O’Brien–Fleming-like boundaries. The study stopped at 50% information time when the observed hazard ratio was 0.70 with a nominal 95% confidence interval (0.60–0.82). The uncorrected p-value, 0.00018, was less than the p-value of 0.001 that was required for early stopping (see Ref. [<xref ref-type="bibr" rid="bibr24-1740774512454600">24</xref>] for details about the monitoring plan). Had we used stagewise calculation, the p-value would have been 0.016. The confidence interval, calculated from a grid search using the program Landem, would have widened to (0.57–0.88). To calculate the estimated hazard ratio, one would calculate the half-way point between ln(0.57) and ln(0.88), giving −0.345 for an estimated hazard ratio of exp(−0.345) or 0.71, hardly a material change from 0.70 (see <xref ref-type="table" rid="table2-1740774512454600">Table 2</xref>). So in this case, even though the study stopped very early, the corrections to the estimates are negligibly small and (much to my relief!) would not have changed the interpretation of the study.</p>
<table-wrap id="table2-1740774512454600" position="float">
<label>Table 2.</label>
<caption>
<p>RALES: statistics as reported and what would have been reported under stagewise ordering</p>
</caption>
<graphic alternate-form-of="table2-1740774512454600" xlink:href="10.1177_1740774512454600-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Estimated statistic</th>
<th align="left" colspan="2">Method of calculation<hr/></th>
</tr>
<tr>
<th/>
<th align="left">Naïve</th>
<th align="left">Stagewise</th>
</tr>
</thead>
<tbody>
<tr>
<td>p-value</td>
<td>0.00018<sup><xref ref-type="table-fn" rid="table-fn3-1740774512454600">a</xref></sup></td>
<td>0.016</td>
</tr>
<tr>
<td>95% Confidence limits</td>
<td>(0.60–0.82)</td>
<td>(0.57–0.88)</td>
</tr>
<tr>
<td>Hazard ratio</td>
<td>0.70</td>
<td>0.71</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-1740774512454600"><p>RALES: Randomized Aldactone Evaluation Study.</p></fn>
<fn id="table-fn3-1740774512454600">
<label>a</label>
<p>Reported as ‘p &lt; 0.001’ in Ref. [<xref ref-type="bibr" rid="bibr8-1740774512454600">8</xref>] but as 0.00018 in Ref. [<xref ref-type="bibr" rid="bibr24-1740774512454600">24</xref>].</p></fn>
</table-wrap-foot></table-wrap>
</sec>
<sec id="section9-1740774512454600">
<title>Recommendations</title>
<p>When a trial allows early stopping for efficacy, if the Type I error rate is to be preserved, its protocol should have described the monitoring plan and the roles of the DMC with respect to that plan. Protocols rarely, if ever, describe the process to be used to report p-values, confidence intervals, and estimates if the trial actually stops early for efficacy. Given the nonuniqueness of those calculations, I recommend including in the protocol the planned methods. I prefer stagewise ordering because it is readily interpretable and it avoids the need to make assumptions about what might have happened.</p>
<p>If the authors choose a method of reporting other than stagewise ordering, then when a trial stops early, the primary article should include the information time at the time of stopping and at what information time the previous looks occurred. That would allow the reader to calculate the stagewise p-value and the associated estimates and confidence intervals.</p>
<p>From a practical point of view, the treatment effect estimated from a trial cannot be assumed to translate directly to the population that will actually use the product. Characteristics that would exclude someone from participating in a trial may not prevent a physician from prescribing the product in practice. The degree of adherence to drug is likely to be greater within trials than outside of them. For these reasons and others, one should not interpret the effect size estimated from a trial as a precise predictor of the effect size in practice. Nonetheless, an interesting exercise would be to review publications from studies that have stopped early and calculate the extent of correction that should have been performed. If RALES is typical of other trials that have stopped early, then the actual corrections would have been small.</p>
</sec>
</body>
<back>
<ack><p>I thank Gordon Lan, David DeMets, and an anonymous reviewer for helpful comments on an earlier version of this article.</p></ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This study had no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p></fn>
<fn fn-type="conflict">
<label>Conflict of interest</label>
<p>None declared.</p></fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-1740774512454600">
<label>1.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>O’Brien</surname><given-names>PC</given-names></name>
<name><surname>Fleming</surname><given-names>TR</given-names></name>
</person-group>. <article-title>A multiple testing procedure for clinical trials</article-title>. <source>Biometrics</source> <year>1979</year>; <volume>35</volume>: <fpage>549</fpage>–<lpage>56</lpage>.</citation>
</ref>
<ref id="bibr2-1740774512454600">
<label>2.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lan</surname><given-names>K</given-names></name>
<name><surname>DeMets</surname><given-names>D</given-names></name>
</person-group>. <article-title>Discrete sequential boundaries for clinical trials</article-title>. <source>Biometrika</source> <year>1983</year>; <volume>70</volume>: <fpage>659</fpage>–<lpage>63</lpage>.</citation>
</ref>
<ref id="bibr3-1740774512454600">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pinheiro</surname><given-names>JC</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
</person-group>. <article-title>Estimating and reducing bias in group sequential designs with Gaussian independent structure</article-title>. <source>Biometrika</source> <year>1997</year>; <volume>84</volume>: <fpage>831</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr4-1740774512454600">
<label>4.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Qu</surname><given-names>RP</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
</person-group>. <article-title>Bias correction in group sequential analysis with correlated data</article-title>. <source>Stat Sin</source> <year>1999</year>; <volume>9</volume>: <fpage>939</fpage>–<lpage>52</lpage>.</citation>
</ref>
<ref id="bibr5-1740774512454600">
<label>5.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Li</surname><given-names>Z</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
</person-group>. <article-title>On the bias of estimation of a Brownian motion drift following group sequential tests</article-title>. <source>Stat Sin</source> <year>1999</year>; <volume>9</volume>: <fpage>923</fpage>–<lpage>37</lpage>.</citation>
</ref>
<ref id="bibr6-1740774512454600">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lee</surname><given-names>JW</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
</person-group>. <article-title>Estimation following group sequential tests with repeated measurements data</article-title>. <source>Comput Stat Data Anal</source> <year>1999</year>; <volume>32</volume>: <fpage>69</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr7-1740774512454600">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Yusuf</surname><given-names>S</given-names></name>
<name><surname>Zhao</surname><given-names>F</given-names></name>
<name><surname>Mehta</surname><given-names>SR</given-names></name>
<etal/>
</person-group>.; <article-title>The Clopidogrel in Unstable Angina to Prevent Recurrent Events Trial Investigators. Effects of clopidogrel in addition to aspirin in patients with acute coronary syndromes without ST-segment elevation</article-title>. <source>N Engl J Med</source> <year>2001</year>; <volume>345</volume>: <fpage>494</fpage>–<lpage>502</lpage>.</citation>
</ref>
<ref id="bibr8-1740774512454600">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pitt</surname><given-names>B</given-names></name>
<name><surname>Zannad</surname><given-names>F</given-names></name>
<name><surname>Remme</surname><given-names>WJ</given-names></name>
<etal/>
</person-group>. <article-title>The effect of spironolactone on morbidity and mortality in patients with severe heart failure</article-title>. <source>N Engl J Med</source> <year>1999</year>; <volume>341</volume>: <fpage>709</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr9-1740774512454600">
<label>9.</label>
<citation citation-type="journal">
<collab>MERIT-HF Study Group</collab>. <article-title>Effect of metoprolol CR/XL in chronic heart failure: Metoprolol CR/XL Randomized Intervention Trial in Congestive Heart Failure (MERIT-HF)</article-title>. <source>Lancet</source> <year>1999</year>; <volume>353</volume>: <fpage>2001</fpage>–<lpage>07</lpage>.</citation>
</ref>
<ref id="bibr10-1740774512454600">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wedel</surname><given-names>H</given-names></name>
<name><surname>DeMets</surname><given-names>D</given-names></name>
<name><surname>Deedwania</surname><given-names>P</given-names></name>
<etal/>
</person-group>. <article-title>Challenges of subgroup analyses in multinational clinical trials: Experiences from the MERIT-HF trial</article-title>. <source>American Heart Journal</source> <year>2001</year>; <volume>142</volume>: <fpage>502</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr11-1740774512454600">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Motzer</surname><given-names>RJ</given-names></name>
<name><surname>Hutson</surname><given-names>TE</given-names></name>
<name><surname>Tomczak</surname><given-names>P</given-names></name>
<etal/>
</person-group>. <article-title>Sunitinib versus interferon alfa in metastatic renal-cell carcinoma</article-title>. <source>N Engl J Med</source> <year>2007</year>; <volume>356</volume>: <fpage>115</fpage>–<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr12-1740774512454600">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bassler</surname><given-names>D</given-names></name>
<name><surname>Briel</surname><given-names>M</given-names></name>
<name><surname>Montori</surname><given-names>VM</given-names></name>
<etal/>
</person-group>. <article-title>Stopping randomized trials early for benefit and estimation of treatment effects: Systematic review and meta-regression analysis</article-title>. <source>JAMA</source> <year>2010</year>; <volume>303</volume>: <fpage>1180</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr13-1740774512454600">
<label>13.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Berry</surname><given-names>SM</given-names></name>
<name><surname>Carlin</surname><given-names>BP</given-names></name>
<name><surname>Connor</surname><given-names>J</given-names></name>
</person-group>. <article-title>Letter: Bias and trials stopped early for benefit</article-title>. <source>JAMA</source> <year>2010</year>; <volume>304</volume>: <fpage>156</fpage>.</citation>
</ref>
<ref id="bibr14-1740774512454600">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goodman</surname><given-names>S</given-names></name>
<name><surname>Berry</surname><given-names>D</given-names></name>
<name><surname>Wittes</surname><given-names>J</given-names></name>
</person-group>. <article-title>Letter: Bias and trials stopped early for benefit</article-title>. <source>JAMA</source> <year>2010</year>; <volume>304</volume>: <fpage>157</fpage>.</citation>
</ref>
<ref id="bibr15-1740774512454600">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Korn</surname><given-names>EL</given-names></name>
<name><surname>Freidlin</surname><given-names>B</given-names></name>
<name><surname>Mooney</surname><given-names>M</given-names></name>
</person-group>. <article-title>Letter: Bias and trials stopped early for benefit</article-title>. <source>JAMA</source> <year>2010</year>; <volume>304</volume>: <fpage>157</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr16-1740774512454600">
<label>16.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ellenberg</surname><given-names>SS</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
<name><surname>Fleming</surname><given-names>TR</given-names></name>
</person-group>. <article-title>Letter: Bias and trials stopped early for benefit</article-title>. <source>JAMA</source> <year>2010</year>; <volume>304</volume>: <fpage>158</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr17-1740774512454600">
<label>17.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Proschan</surname><given-names>M</given-names></name>
<name><surname>Lan</surname><given-names>K</given-names></name>
<name><surname>Wittes</surname><given-names>J</given-names></name>
</person-group>. <source>Statistical Monitoring of Clinical Trials: A Unified Approach</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>New York</publisher-loc>, <year>2006</year>.</citation>
</ref>
<ref id="bibr18-1740774512454600">
<label>18.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lan</surname><given-names>K</given-names></name>
<name><surname>Wittes</surname><given-names>J</given-names></name>
</person-group>. <article-title>The B-value: A tool for monitoring data</article-title>. <source>Biometrics</source> <year>1988</year>; <volume>44</volume>: <fpage>579</fpage>–<lpage>85</lpage>.</citation>
</ref>
<ref id="bibr19-1740774512454600">
<label>19.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Emerson</surname><given-names>SS</given-names></name>
<name><surname>Fleming</surname><given-names>TR</given-names></name>
</person-group>. <article-title>Parameter estimation following sequential hypothesis testing</article-title>. <source>Biometrika</source> <year>1990</year>; <volume>77</volume>: <fpage>875</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr20-1740774512454600">
<label>20.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Liu</surname><given-names>A</given-names></name>
<name><surname>Hall</surname><given-names>WJ</given-names></name>
</person-group>. <article-title>Unbiased estimation following a group sequential test</article-title>. <source>Biometrika</source> <year>1999</year>; <volume>86</volume>: <fpage>71</fpage>–<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr21-1740774512454600">
<label>21.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kim</surname><given-names>K</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
</person-group>. <article-title>Confidence intervals following group sequential tests in clinical trials</article-title>. <source>Biometrics</source> <year>1987</year>; <volume>43</volume>: <fpage>857</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr22-1740774512454600">
<label>22.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kim</surname><given-names>K</given-names></name>
</person-group>. <article-title>Point estimation following group sequential tests</article-title>. <source>Biometrics</source> <year>1989</year>; <volume>45</volume>: <fpage>613</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr23-1740774512454600">
<label>23.</label>
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Reboussin</surname><given-names>DM</given-names></name>
<name><surname>DeMets</surname><given-names>DL</given-names></name>
<name><surname>Kim</surname><given-names>K</given-names></name>
<etal/>
</person-group>. <article-title>Programs for computing group sequential boundaries using the Lan-DeMets method, v. 2.1, 2003</article-title>. Available at: <ext-link ext-link-type="uri" xlink:href="http://www.biostat.wisc.edu/landemets">http://www.biostat.wisc.edu/landemets</ext-link></citation>
</ref>
<ref id="bibr24-1740774512454600">
<label>24.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wittes</surname><given-names>J</given-names></name>
<name><surname>Palensky</surname><given-names>J</given-names></name>
<name><surname>Asner</surname><given-names>D</given-names></name>
<etal/>
</person-group>. <article-title>Experience collecting interim data on mortality: An example from the RALES study</article-title>. <source>Curr Control Trials Cardiovasc Med</source> <year>2001</year>; <volume>2</volume>: <fpage>59</fpage>–<lpage>62</lpage>.</citation>
</ref></ref-list>
</back>
</article>