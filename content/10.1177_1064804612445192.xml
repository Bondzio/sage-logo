<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ERG</journal-id>
<journal-id journal-id-type="hwp">sperg</journal-id>
<journal-title>Ergonomics in Design: The Quarterly of Human Factors Applications</journal-title>
<issn pub-type="ppub">1064-8046</issn>
<issn pub-type="epub">XXXX-XXXX</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1064804612445192</article-id>
<article-id pub-id-type="publisher-id">10.1177_1064804612445192</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Departments</subject>
<subj-group subj-group-type="heading">
<subject>Views</subject>
</subj-group>
</subj-group>
</article-categories>
<title-group>
<article-title>Human Response Is Lognormal; Plan on Waiting If You Want Reliability</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Sheridan</surname><given-names>Thomas B.</given-names></name>
</contrib>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>21</volume>
<issue>1</issue>
<fpage>4</fpage>
<lpage>6</lpage>
<permissions>
<copyright-statement>© 2013 Human Factors and Ergonomics Society</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="society">Human Factors and Ergonomics Society</copyright-holder>
</permissions>
<abstract>
<p>Human response times fit a lognormal probability function, which poses severe constraints on the time a system designer must allow to accommodate a significant fraction of respondents; for example, 6 standard deviations for 95% confidence and 11 standard deviations for 99% confidence. When a human operates in series with machine elements, there may be no justification for demanding a quick response from the machine.</p>
</abstract>
<kwd-group>
<kwd>decision making</kwd>
<kwd>design strategies</kwd>
<kwd>risk analysis</kwd>
<kwd>system analysis</kwd>
<kwd>test and evaluation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Evidence shows that human/team response times follow a lognormal probability function, which means long delays to accommodate the slowest operators or teams.</p>
<p>Humans can sometimes enhance the reliability of otherwise fully automated systems. Everyone knows that there are instances when machines make colossal failures and humans come to the rescue by their inventiveness. An example is <italic>Apollo 13</italic>; in that situation, astronauts and ground crew innovated in real time under extreme pressure to save the mission. However, for well-defined tasks that involve humans operating in serial with machines, and when time is a critical factor in reliability, there may be instances when requiring high reliability of the machine components is simply not warranted. Examples occur in communication systems, such as those used in air traffic control or military operations, when unexpected events are encountered and demand immediate response.</p>
<p>In this article, I review evidence that if designers want to accommodate all the operators or teams, they will need to plan for some long delays waiting for the humans to respond.</p>
<sec id="section1-1064804612445192">
<title>What the Lognormal Data Fit Implies</title>
<p>It is well known that for a series of independent operations, the variances of the component operations add up and their success probabilities multiply, as in <xref ref-type="fig" rid="fig1-1064804612445192">Figure 1</xref>.</p>
<fig id="fig1-1064804612445192" position="float">
<label>Figure 1.</label>
<caption>
<p>Human in series with machine operations: Combined effects.</p>
</caption>
<graphic xlink:href="10.1177_1064804612445192-fig1.tif"/>
</fig>
<p>What may not be so well known is that the best model of human response times is a lognormal probability density distribution; that is, the logarithm of the response time is normally distributed (Gaussian). <xref ref-type="fig" rid="fig2-1064804612445192">Figure 2</xref> shows a lognormal probability distribution (abscissa <italic>x</italic> would correspond to response time). There are no responses at less than zero, and the right-hand tail is very long, meaning that some responses are very much longer than the median.</p>
<fig id="fig2-1064804612445192" position="float">
<label>Figure 2.</label>
<caption>
<p>Lognormal distribution. <italic>P</italic>(log <italic>x</italic>) would be normally distributed.</p>
</caption>
<graphic xlink:href="10.1177_1064804612445192-fig2.tif"/>
</fig>
<p>To consider the probability that enough responses have been properly completed, one must use the integral (from left to right) of <xref ref-type="fig" rid="fig2-1064804612445192">Figure 2</xref>, which results in a cumulative lognormal function, as shown in <xref ref-type="fig" rid="fig3-1064804612445192">Figure 3</xref>. (Note that <italic>D</italic>(<italic>x</italic>) asymptotes to 1.) It is evident that to ensure that, for example, 99% of responses have been completed, one must wait a long time, very much longer than the mean or median response time.</p>
<fig id="fig3-1064804612445192" position="float">
<label>Figure 3.</label>
<caption>
<p>Cumulative lognormal function.</p>
</caption>
<graphic xlink:href="10.1177_1064804612445192-fig3.tif"/>
</fig>
<p><xref ref-type="fig" rid="fig4-1064804612445192">Figure 4</xref> illustrates the cumulative lognormal fit for a large number of nuclear power plant operator teams, in a simulator experiment, to have successfully completed an emergency task. The task entails being alerted to the danger (in this case, an alarm that signaled a large pipe break and loss of core reactor cooling), deciding what to do, and taking proper action (<xref ref-type="bibr" rid="bibr1-1064804612445192">Kozinsky, 1982</xref>). I was a participant and was responsible for fitting this model. Each dot represents one new operator team to have completed the task. In this case, the logarithmic plot of time is on the <italic>y</italic>-axis, and probability is shown on the <italic>x</italic>-axis so as to make the cumulative probability function a straight line. One can observe that the fit is excellent. In many other response time experiments, the resulting data have been shown to fit the lognormal function (e.g., see <xref ref-type="bibr" rid="bibr2-1064804612445192">Van der Linden, 2006</xref>).</p>
<fig id="fig4-1064804612445192" position="float">
<label>Figure 4.</label>
<caption>
<p>Cumulative lognormal fit of data from a nuclear power plant simulator experiment. Each dot represents a different team of reactor operators having performed a Òread-and-executeÓ procedural step in recovering after an alarm signaling the pipe break. From <italic>Performance Measurement System for Training Simulator</italic>, by <xref ref-type="bibr" rid="bibr1-1064804612445192">E. J. Kozinsky, 1982</xref>, Atlanta, GA: Electric Power Research Institute. Copyright 1982 by Electric Power Research Institute. Reprinted with permission.</p>
</caption>
<graphic xlink:href="10.1177_1064804612445192-fig4.tif"/>
</fig>
<p>I believe the circumstances of this nuclear plant experiment closely fit the situations that air traffic controllers and pilots face when they encounter unexpected and threatening events and are under time pressure to absorb information, communicate, and decide what to do. Similar situations occur in hospital operating rooms and in military operations.</p>
<p>Although the cumulative lognormal plots do not extend clearly to probabilities very close to 1, it is instructive to consider the cumulative lognormal in that region in relation to the independent variable, which one assumes here to be time. To that end, one can tabulate values close to unity in <xref ref-type="table" rid="table1-1064804612445192">Table 1</xref> and compare that table to the standard cumulative normal distribution for values close to 1. One can see that the standard normal (Gaussian) cumulative probability function converges relatively rapidly (2 standard deviations to accommodate 95% of respondents and 4 standard deviations to get to 99%), whereas the lognormal requires 6 and 11 standard deviations, respectively, to meet the same criteria! That means that if system designers want to accommodate 95% or 99% of the population, they may have to plan on long delays for humans to observe alarms or critical signals, figure out what to do, and execute appropriate action.</p>
<table-wrap id="table1-1064804612445192" position="float">
<label>Table 1.</label>
<caption>
<p>Cumulative Lognormal (CumLogNormal) and Cumulative Normal (CumNormal) Distributions Close to 100% Probability</p>
</caption>
<graphic alternate-form-of="table1-1064804612445192" xlink:href="10.1177_1064804612445192-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Number of Standard Deviations From Mean</th>
<th align="center">CumLogNormal</th>
<th align="center">CumNormal</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0.5</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.84134</td>
</tr>
<tr>
<td>2</td>
<td>0.75589</td>
<td>0.97725</td>
</tr>
<tr>
<td>3</td>
<td>0.86403</td>
<td>0.99865</td>
</tr>
<tr>
<td>4</td>
<td>0.91717</td>
<td>0.99997</td>
</tr>
<tr>
<td>5</td>
<td>0.94624</td>
<td/>
</tr>
<tr>
<td>6</td>
<td>0.96341</td>
<td/>
</tr>
<tr>
<td>7</td>
<td>0.97417</td>
<td/>
</tr>
<tr>
<td>8</td>
<td>0.98121</td>
<td/>
</tr>
<tr>
<td>9</td>
<td>0.986</td>
<td/>
</tr>
<tr>
<td>10</td>
<td>0.98935</td>
<td/>
</tr>
<tr>
<td>11</td>
<td>0.99176</td>
<td/>
</tr>
<tr>
<td>12</td>
<td>0.99352</td>
<td/>
</tr>
<tr>
<td>13</td>
<td>0.99484</td>
<td/>
</tr>
<tr>
<td>14</td>
<td>0.99584</td>
<td/>
</tr>
<tr>
<td>15</td>
<td>0.99662</td>
<td/>
</tr>
<tr>
<td>16</td>
<td>0.99722</td>
<td/>
</tr>
<tr>
<td>17</td>
<td>0.9977</td>
<td/>
</tr>
<tr>
<td>18</td>
<td>0.99808</td>
<td/>
</tr>
<tr>
<td>19</td>
<td>0.99828</td>
<td/>
</tr>
<tr>
<td>20</td>
<td>0.99863</td>
<td/>
</tr>
<tr>
<td>30</td>
<td>0.99966</td>
<td/>
</tr>
<tr>
<td>40</td>
<td>0.99988</td>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-1064804612445192">
<p><italic>Note</italic>. For cumulative lognormal having mean (of log <italic>x</italic>) = 0 and standard deviation = 1, and for cumulative normal having mean = 0 and standard deviation = 1.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>In summary, human response times tend to follow a lognormal function and certainly do not match the standard normal distribution, meaning that high confidence in whether responses have been completed requires waits that are many times the median or mean response time.</p>
<p>Returning to the statistics of serial operations, there is nothing wrong with requiring very high reliability for electromechanical components that are amenable to rapid bench testing and that must combine in serial fashion to constitute larger electromechanical systems. However, there is often loose talk, for example, of so-called four nines reliability. Keep in mind that verifying 99.99% confidence for components would require a statistically valid number of test runs, more than 10,000. The same could be said for validating any system, were such a reliability requirement to make sense.</p>
</sec>
<sec id="section2-1064804612445192">
<title>Conclusion</title>
<p>Even apart from the stringent validation requirements stated previously, for larger machine subsystems that must operate in series with a human operator, there is little point in requiring very fast response (or high reliability, if reliability is largely a function of time) for those machine components, because the (lognormal) properties of the human component response in the series easily dominate and determine the temporal reliability of the whole human-machine system. Spending large sums for reliably fast machine components is simply not warranted. One solution, if at all feasible, and for that part of the task that requires fast response, is to replace the human(s) with automation.</p>
</sec>
</body>
<back>
<bio>
<p><bold>Thomas B. Sheridan</bold> is professor emeritus of engineering and applied psychology in the Departments of Mechanical Engineering and of Aeronautics and Astronautics at Massachusetts Institute of Technology. He has served as president of both the Human Factors and Ergonomics Society and the IEEE Systems, Man and Cybernetics Society and is a member of the National Academy of Engineering. He consults for the government on the NextGen air traffic control project.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1064804612445192">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kozinsky</surname><given-names>E. J.</given-names></name>
</person-group> (<year>1982</year>, <month>November</month>). <source>Performance measurement system for training simulators</source> (Report No. NP-2719). <publisher-loc>Atlanta, GA</publisher-loc>: <publisher-name>Electric Power Research Institute</publisher-name>.</citation>
</ref>
<ref id="bibr2-1064804612445192">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Van der Linden</surname><given-names>W. J.</given-names></name>
</person-group> (<year>2006</year>). <article-title>A lognormal model for response times on test items</article-title>. <source>Journal of Educational and Behavioral Statistics</source>, <volume>31</volume>, <fpage>181</fpage>–<lpage>204</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>