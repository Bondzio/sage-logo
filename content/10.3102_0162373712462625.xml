<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EPA</journal-id>
<journal-id journal-id-type="hwp">spepa</journal-id>
<journal-title>Educational Evaluation and Policy Analysis</journal-title>
<issn pub-type="ppub">0162-3737</issn>
<issn pub-type="epub">1935-1062</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.3102/0162373712462625</article-id>
<article-id pub-id-type="publisher-id">10.3102_0162373712462625</article-id>
<title-group>
<article-title>Incentive Pay Programs Do Not Affect Teacher Motivation or Reported Practices</article-title>
<subtitle>Results From Three Randomized Studies</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Yuan</surname><given-names>Kun</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Le</surname><given-names>Vi-Nhuan</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>McCaffrey</surname><given-names>Daniel F.</given-names></name>
<aff id="aff1-0162373712462625">RAND Corporation</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Marsh</surname><given-names>Julie A.</given-names></name>
<aff id="aff2-0162373712462625">University of Southern California, Los Angeles</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Hamilton</surname><given-names>Laura S.</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Stecher</surname><given-names>Brian M.</given-names></name>
<aff id="aff3-0162373712462625">RAND Corporation</aff>
</contrib>
<contrib contrib-type="author">
<name><surname>Springer</surname><given-names>Matthew G.</given-names></name>
<aff id="aff4-0162373712462625">Vanderbilt University</aff>
</contrib>
</contrib-group>
<pub-date pub-type="epub-ppub">
<month>3</month>
<year>2013</year>
</pub-date>
<volume>35</volume>
<issue>1</issue>
<fpage>3</fpage>
<lpage>22</lpage>
<history>
<date date-type="received">
<day>3</day>
<month>4</month>
<year>2012</year>
</date>
<date date-type="rev-recd">
<day>29</day>
<month>8</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>4</day>
<month>9</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© 2012 AERA</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">American Educational Research Association</copyright-holder>
</permissions>
<abstract>
<p>This study drew on teacher survey responses from randomized experiments exploring three different pay-for-performance programs to examine the extent to which these programs motivated teachers to improve student achievement and the impact of such programs on teachers' instruction, number of hours worked, job stress, and collegiality. Results showed that most teachers did not report their program as motivating. Moreover, the survey responses suggest that none of the three programs changed teachers' instruction, increased their number of hours worked or job stress, or damaged their collegiality. Future research needs to further examine the logic model of pay-for-performance programs and test alternative incentive models such as rewarding teachers based on their practices and job responsibilities rather than on student outcomes.</p>
</abstract>
<kwd-group>
<kwd>pay-for-performance program</kwd>
<kwd>randomized experimental studies</kwd>
<kwd>teacher</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0162373712462625" sec-type="intro">
<title>Introduction</title>
<p>Traditionally, teachers have been paid on a single salary schedule, in which teacher salary is based on their years of experience and education level (<xref ref-type="bibr" rid="bibr34-0162373712462625">Podgursky &amp; Springer, 2006</xref>). Recently, there have been a number of reform initiatives that have attempted to change the manner in which teachers are compensated. In particular, pay-for-performance programs, also referred to as incentive pay programs, in which teachers’ pay is linked to some aspects of their performance, have gained substantial popularity in the last decade (<xref ref-type="bibr" rid="bibr34-0162373712462625">Podgursky &amp; Springer, 2006</xref>). Various efforts at the national, state, and district levels have been made to design, implement, and study the effectiveness of performance pay programs on educators’ attitudes and students’ learning (<xref ref-type="bibr" rid="bibr6-0162373712462625">Center for Educator Compensation Reform, n.d</xref>.; <xref ref-type="bibr" rid="bibr23-0162373712462625">Koppich &amp; Rigby, 2009</xref>; <xref ref-type="bibr" rid="bibr40-0162373712462625">Schuermann, 2009</xref>).</p>
<p>For incentive pay programs to lead to improved student outcomes in the short run, the programs must motivate teachers to make changes that effectively lead to the accomplishment of program goals (<xref ref-type="bibr" rid="bibr22-0162373712462625">Kelley, Odden, Milanowski, &amp; Heneman, 2000</xref>). However, the literature paints a mixed picture of the extent to which incentive pay programs motivate teachers. Some studies suggest that most teachers are supportive of tying pay to performance and feel motivated by incentive pay programs (<xref ref-type="bibr" rid="bibr24-0162373712462625">Langdon &amp; Vesper, 2000</xref>), whereas other studies find that the majority of teachers oppose linking pay increases to performance (<xref ref-type="bibr" rid="bibr45-0162373712462625">Teaching Commission, 2004</xref>).</p>
<sec id="section2-0162373712462625">
<title>Purpose and Structure of This Article</title>
<p>Despite the increasingly popular practice of using pay-for-performance programs to reward educators in the United States (<xref ref-type="bibr" rid="bibr12-0162373712462625">Fryer, 2012</xref>) and the fact that the impact of incentive pay programs on student achievement depends in part on how teachers respond to such programs, only a few studies have examined teachers’ responses to incentive pay programs (notable exceptions include <xref ref-type="bibr" rid="bibr13-0162373712462625">Glewwe, Ilias, &amp; Kremer, 2010</xref>; <xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>; <xref ref-type="bibr" rid="bibr32-0162373712462625">Muralidharan &amp; Sundararaman, 2008</xref>; <xref ref-type="bibr" rid="bibr43-0162373712462625">Springer et al., 2010</xref>; <xref ref-type="bibr" rid="bibr44-0162373712462625">Springer et al., 2012</xref>; <xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley, Spindler, &amp; Subert, 2010</xref>). The goal of this study is to examine whether three recently implemented pay-for-performance programs had similar effects on teachers’ motivation and reported practices. These programs were (a) the Project on Incentives in Teaching (POINT) in Tennessee’s Metropolitan Nashville Public Schools (MNPS) (<xref ref-type="bibr" rid="bibr43-0162373712462625">Springer et al., 2010</xref>), (b) the Pilot Project on Team Incentives (PPTI) in Texas’s Round Rock Independent School District (RRISD) (<xref ref-type="bibr" rid="bibr44-0162373712462625">Springer et al., 2012</xref>), and (c) the School-Wide Performance Bonus Program (SPBP) in New York City Public Schools (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>).</p>
<p>All three programs rewarded teachers primarily on the basis of student achievement gains but differed in program design, such as unit of accountability and incentive structure. Across the three sites, teachers were surveyed about their attitudes toward the incentive pay programs, their instructional practices, and about ways in which the implementation of the incentive pay programs changed their teaching behaviors or working conditions. Drawing on teacher survey data to explore commonalities and differences across the three different incentive programs, we addressed the following research questions:</p>
<list id="list1-0162373712462625" list-type="order">
<list-item><p>Did teachers find these three incentive pay programs to be motivating?</p></list-item>
<list-item><p>In response to the implementation of these programs, did teachers report changes in their practices or their working conditions?</p></list-item>
</list>
<p>In the following sections, we review the rationale for pay-for-performance programs and prior research findings about their impact on teachers’ motivation, practices, and working conditions.<sup><xref ref-type="fn" rid="fn1-0162373712462625">1</xref></sup> Next, we describe the three programs as well as the surveys and analytical approach used in this study. Finally, we present findings and discuss the implications for future policy and research on incentive pay programs.</p>
</sec>
<sec id="section3-0162373712462625">
<title>Rationale for Pay-for-Performance Programs</title>
<p>There are three primary methods by which pay-for-performance programs are thought to improve student achievement. The first mechanism by which pay-for-performance programs can improve student achievement is by motivating existing teachers to improve or innovate their teaching practices. The theory posits that teachers will respond to financial incentives by altering their teaching practices, which may include changing the way they teach, modifying the content of their curriculum, working longer hours, undergoing more professional development, or engaging in different types of professional development activities. These efforts are believed to result in better student achievement (<xref ref-type="bibr" rid="bibr31-0162373712462625">Milanowski, 2003</xref>; <xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al., 2010</xref>).</p>
<p>The second mechanism is to improve student learning by changing teachers’ working environment. Although much of the rationale for pay-for-performance programs focuses on improvement of student achievement, there has been an increasing recognition that such programs may have consequences on teachers’ work environment. Namely, the extent to which teachers are motivated to improve their teaching will depend on the outcomes that arise from trying to attain the program goals (<xref ref-type="bibr" rid="bibr15-0162373712462625">Goodman &amp; Turner, 2011</xref>). In theory, pay-for-performance programs that award bonuses based on teams of teachers may encourage cooperation and teamwork, which in turn could support improvements in instruction and ultimately student learning.<sup><xref ref-type="fn" rid="fn2-0162373712462625">2</xref></sup></p>
<p>The third method is by changing the supply of teaching candidates through incentives that attract or retain more highly qualified candidates. The prospect of a salary structure that awards bonuses for higher student achievement may attract a more highly qualified pool of candidates who feel they could thrive under this type of salary structure (<xref ref-type="bibr" rid="bibr3-0162373712462625">Barnett &amp; Ritter, 2008</xref>). Alternatively, given that teachers who tend to leave the field are the most highly skilled (<xref ref-type="bibr" rid="bibr28-0162373712462625">Margolis, 2008</xref>) and that teachers who had higher compensation stayed in teaching longer (<xref ref-type="bibr" rid="bibr7-0162373712462625">Clotfleter, Glennie, Ladd, &amp; Vigdor, 2008</xref>; <xref ref-type="bibr" rid="bibr16-0162373712462625">Guarino, Santibanez, &amp; Daley, 2006</xref>), pay-for-performance programs may retain more talented teachers who would otherwise leave the field for other higher paying opportunities.</p>
<p>The first and second mechanisms were the primary basis for the adoption of the pay-for-performance programs included in our study. Although an important rationale for pay-for-performance programs, the third mechanism was not tested in the evaluation of any of the three programs given the short duration of the programs and limited data, and we will not consider this mechanism for change in this article.</p>
<p>It is important to recognize that the mechanisms examined by our study and the tension between rewarding individuals versus groups reflect a long-running debate in social theory. The “utilitarian tradition”—associated with John Locke, Adam Smith, and in later years economists such as Milton Friedman—argues that the individual is the starting point of society and that rational individuals attempt to maximize their utility, calculating their self-interest and how they make social exchanges (<xref ref-type="bibr" rid="bibr8-0162373712462625">Collins, 1994</xref>). In contrast, the “Durkheimian tradition” rejects the idea that individual action can explain societal features and instead asserts that society determines the individual. In other words, structural relations among people—social and moral ties, rituals, norms—hold society together and greatly affect individual behavior and ideas (<xref ref-type="bibr" rid="bibr8-0162373712462625">Collins, 1994</xref>).</p>
<p>The study of individual versus group incentives is one particular case of this deeper, theoretical discussion and set of tensions. Echoing the utilitarian tradition, the first mechanism asserts that individual rewards will have the greatest motivational effect: Individuals will alter their behavior to maximize their probability of earning a reward. Falling clearly within the Durkheimian tradition, the second mechanism argues that collective rewards will show more of an effect. Group-based rewards rest on a belief that the quality of the school as a whole takes priority over the success of the individual teachers (<xref ref-type="bibr" rid="bibr11-0162373712462625">Ford, 2012</xref>) and that individual performance is dependent on the collective efforts of a school community and the quality of the school environment. Those advocating for collective rewards further argue that although the first mechanism may motivate individual teachers, it may not improve the educational experiences for all students in the schools. Depending on program design, the pursuit of individual rewards may also create a competitive environment that negatively affects collective teacher motivation and performance. Although the second mechanism has the possibility of improving the educational experiences for groups of students, it also suffers from a collective action problem, in which individuals may still benefit, despite not contributing to the group (<xref ref-type="bibr" rid="bibr35-0162373712462625">Oliver, 1980</xref>). This may lead to teacher inaction due to the belief that individual contributions will have little influence on obtaining a bonus or to teacher resentment due to the perceived free-rider problem (<xref ref-type="bibr" rid="bibr48-0162373712462625">Willer, 2009</xref>). In this article, we examine these two competing strategies for incentivizing teachers, albeit with limited data from three programs.</p>
</sec>
<sec id="section4-0162373712462625">
<title>Motivational Theories Underlying Pay-for-Performance Programs</title>
<p>Although none of the programs in our study included an explicit theoretical framework underlying their designs, the literature generally puts forth two theoretical frameworks that help us understand the possible effects of performance incentives on teachers’ motivation: expectancy theory (<xref ref-type="bibr" rid="bibr46-0162373712462625">Vroom, 1964</xref>) and goal-setting theory (<xref ref-type="bibr" rid="bibr26-0162373712462625">Locke, 1968</xref>).</p>
<p>We selected these psychological theories to guide our analysis for several reasons. First, we believed these theories could apply to the heterogeneity of the programs studied and of the underlying rationales. Although subscribing to slightly different ideas of how to leverage change, all three programs emphasized the motivational aspects of incentives. One could argue expectancy theory applies not only to individuals—rewards boost individual expectancy—but also to groups—rewards could also boost collective expectancy. Our surveys were also developed to test individual psychological differences, making the choice of these theories appropriate for framing. Finally, our selection of these theories was further influenced by past studies of similar pay-for-performance programs that relied on these same theoretical frameworks (<xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins, 2004</xref>; <xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley, Heneman, &amp; Milanowski, 2002</xref>).</p>
<p>Expectancy theory identifies three factors that contribute to motivating teachers to engage in certain behaviors: expectancy, instrumentality, and valence. According to this theory, the amount of effort that teachers expend to meet the program goals is a function of teachers’ perceptions that their personal efforts will lead to their students reaching the expected achievement goals (expectancy), the likelihood that meeting the achievement goals will result in a financial reward (instrumentality), and the desirability of attaining the bonus (valence).</p>
<p>Goal-setting theory complements expectancy theory by further describing the conditions under which teachers’ actions are likely to be changed by the incentive. Under goal-setting theory, teachers are predicted to respond to the incentives if the goals under the performance pay systems are clearly defined, moderately challenging, and accepted by teachers. In addition, goal-setting theory suggests that teachers’ effort will be influenced by a number of factors, such as their understanding of the incentive pay program and its goals (<xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>) and perceptions of the fairness of the program (<xref ref-type="bibr" rid="bibr19-0162373712462625">Heneman &amp; Milanowski, 1999</xref>).</p>
<sec id="section5-0162373712462625">
<title>Evidence related to expectancy theory</title>
<p>Recent evaluations of pay-for-performance programs suggest that incentive pay programs may have mixed effects on teachers’ motivation. For instance, <xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al. (2002)</xref> reported that 56% of teachers in the Charlotte-Mecklenburg Schools (CMS) and 39% in Kentucky estimated that their school would meet its program goals if they put in a high level of personal effort. The fact that the rewards were given at the school level may have contributed to the modest expectancy estimates from individual teachers. Examining a program in a Florida district that rewarded individual teachers based on performance measures such as student achievement gains and participation in staff development, <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> noted that 65% of teachers believed that their individual performance as an educator had little influence on whether or not they would earn a bonus. In a survey with Maryland teachers in a school district where the compensation system included incentives for various aspects of teaching, such as school-wide achievement growth and teaching evaluations, approximately one-third of teachers did not think their payouts were linked to their performance in the classroom (<xref ref-type="bibr" rid="bibr36-0162373712462625">Rice, Jackson, Hoyer, Malen, &amp; Hyde, 2011</xref>).</p>
<p>The relatively low expectancy may stem from teachers’ concerns that student achievement is influenced by factors that are outside of their control (<xref ref-type="bibr" rid="bibr18-0162373712462625">Heneman, 1998</xref>). For example, <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> found that although nearly all teachers believed that their individual performance as an educator could significantly influence their students’ achievement, the majority also believed that the classroom composition would have a greater impact on whether they met their achievement goals than did their individual effort as educators.</p>
<p>Studies also suggest that teachers do not always have high estimates of instrumentality with respect to performance pay systems. <xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al. (2002)</xref> asked teachers to estimate the probability of receiving a bonus if the school met its achievement goals. Nearly 30% of CMS teachers and 45% of Kentucky teachers did not believe a bonus would be awarded, even if the school attained its achievement goals.</p>
<p>With respect to valence, the literature generally suggests that teachers value the opportunity to win a bonus. The majority of teachers in the <xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al. (2002)</xref>, <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref>, and <xref ref-type="bibr" rid="bibr36-0162373712462625">Rice et al. (2011)</xref> studies indicated they wanted to receive a bonus, although teachers also indicated that their efforts to improve student achievement were driven by other nonfinancial reasons (e.g., helping students learn). In some instances, although teachers valued the award, they also believed the award was too small to be worth any additional effort (<xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al., 2002</xref>; <xref ref-type="bibr" rid="bibr36-0162373712462625">Rice et al., 2011</xref>).</p>
<sec id="section6-0162373712462625">
<title>Evidence related to goal-setting theory</title>
<p>Similar to the results from an expectancy theory perspective, studies using a goal-setting theory framework paint a mixed picture as to whether incentive pay programs motivate teachers. In general, teachers understand the overarching goals of the pay-for-performance programs. For example, the majority of teachers in the <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> study agreed with the premise that educators should receive additional compensation for meeting achievement goals and indicated that they understood the process for awarding incentive pay to teachers. Similarly, most teachers in CMS and Kentucky believed the program goals were clear (<xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al., 2002</xref>). Examining Denver Public Schools’ Professional Compensation System for Teachers (ProComp), <xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al. (2010)</xref> reported that most teachers felt the program’s goals of improving student achievement and retaining and attracting qualified teachers were aligned with the district’s and their own goals.</p>
<p>However, teachers were more cautious with respect to whether the programs were fair. For example, most Kentucky teachers disagreed that it was fair to pay bonuses to teachers for achievement gains and to hold teachers accountable for student achievement (<xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al., 2002</xref>). Similarly, three-quarters of responding teachers in the <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> study believed that their program was not fair in how it distributed the bonuses. In the <xref ref-type="bibr" rid="bibr36-0162373712462625">Rice et al. (2011)</xref> study, about one-third of the teachers questioned the fairness in how teaching was evaluated and the bonus was distributed.</p>
</sec>
</sec>
</sec>
<sec id="section7-0162373712462625">
<title>Effects of Pay-for-Performance Programs on Teacher Practices and Working Conditions</title>
<sec id="section8-0162373712462625">
<title>Teacher practices</title>
<p>The literature on whether teachers change their practices in response to incentive pay programs is mixed. Two experimental studies in India and Kenya that examined the effect of incentive pay programs on teachers’ practices found no significant differences in teachers’ practices between treatment and control group teachers based on observations of instruction (<xref ref-type="bibr" rid="bibr13-0162373712462625">Glewwe et al., 2010</xref>; <xref ref-type="bibr" rid="bibr32-0162373712462625">Muralidharan &amp; Sundararaman, 2008</xref>). In contrast, using a regression discontinuity and matching methods design to study a pay-for-performance program in Israel, <xref ref-type="bibr" rid="bibr25-0162373712462625">Lavy (2009)</xref> found that treatment group teachers reported greater use of individualized instruction, more tracking in the classroom by ability, and longer instructional time than control group teachers.</p>
<p>Bonus-eligible teachers in observational studies of incentive pay programs conducted in the United States also report mixed results. For example, only 27% of teachers who were required to participate in the Denver ProComp system reported using different teaching methods and even fewer (14%) reported changing the content of instruction (<xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al., 2010</xref>). Similarly, about 80% of teachers in the <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> study reported that they did not change their instruction, assessment methods, or professional development activities as a result of teacher performance pay.</p>
<p>In contrast, more than two-thirds of teachers in Kentucky and CMS reported making changes in instruction, including changing instructional content, increasing instructional time on teaching tasks, and collaborating more with colleagues (<xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>). However, the teachers in these studies were concurrently undergoing standards and assessment-based reforms. In the absence of responses from a control group, it is unclear the extent to which the changes were due to the pay-for-performance programs, as opposed to the other reform efforts.</p>
</sec>
<sec id="section9-0162373712462625">
<title>Number of hours worked</title>
<p>Many studies have found that the implementation of pay-for-performance programs is associated with increases in the number of hours teachers report working. For example, 37% of responding teachers in the <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> study reported working longer hours since the implementation of the program. Upwards of two-thirds of CMS teachers and three-quarters of Kentucky teachers indicated they worked longer hours since their program started in the <xref ref-type="bibr" rid="bibr21-0162373712462625">Kelley et al. (2002)</xref> study. However, again, because these studies only examined bonus-eligible teachers, changes in the number of hours worked may have partly resulted from other reform efforts that happened concurrently with the incentive pay programs.</p>
</sec>
<sec id="section10-0162373712462625">
<title>Job stress</title>
<p>Many studies have also found that teachers report an increase in their job stress after the implementation of incentive pay programs. For instance, 72% of CMS teachers and 87% of Kentucky teachers reported the award program put more job pressure and stress on them (<xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>). Nearly half of the responding teachers in the <xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins (2004)</xref> study reported they experienced increased stress as a result of the pay-for-performance program. Half of the teachers who were required to participate in ProComp reported increased stress (<xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al., 2010</xref>). However, given the lack of control group teachers’ responses, it is unknown whether the increased job stress was due solely to the incentive pay programs.</p>
</sec>
<sec id="section11-0162373712462625">
<title>Collegiality</title>
<p>Although there are few studies that have examined the issue of collegiality, the general consensus of these studies is that the implementation of pay-for-performance program is associated with slightly higher levels of collegiality. <xref ref-type="bibr" rid="bibr20-0162373712462625">Kelly (1999)</xref> reported that the school-wide performance pay programs might have helped teacher collaboration and increased teacher collegiality in the CMS and Kentucky programs. <xref ref-type="bibr" rid="bibr17-0162373712462625">Hall and Caffarella (1997)</xref> reported similar findings about the positive association between the implementation of a group-based incentive pay program and collegiality in Douglas County, Colorado. About half of the incentive eligible teachers in the individual-based ProComp program reported that the program helped create a collaborative working environment (<xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al., 2010</xref>).</p>
<p>In summary, existing findings about the impact of incentive pay programs on teachers’ practices are inconclusive. The literature is more consistent with respect to the effects on number of hours worked, job stress, and collegiality, with studies generally reporting increases in these areas after the implementation of pay-for-performance programs. However, it is difficult to disentangle the effects of the pay-for-performance programs from the effects of other concurrent reform efforts due to the lack of responses from control group teachers in the latter findings.</p>
</sec>
</sec>
</sec>
<sec id="section12-0162373712462625" sec-type="methods">
<title>Method</title>
<p>In this study, we examined three randomized controlled trials of pay-for-performance programs, in which the units of accountability were randomly assigned to either the treatment group (who were eligible to receive the bonus) or the control group (who were not eligible to receive the bonus). Below we provide an overview of each program.</p>
<sec id="section13-0162373712462625">
<title>Sample</title>
<sec id="section14-0162373712462625">
<title>POINT</title>
<p>The POINT experiment was conducted in the MNPS from 2006–2007 through 2008–2009, during which the district served about 73,000 students annually. Slightly more than one-third of the students were White. Half were Black. Hispanic students were 15% of the student population. About 65% of the students in the district were eligible for free and reduced-price lunch (FRPL). Ten percent were English language learners (ELLs). The district’s performance on the statewide mathematics and reading tests was below the state average.</p>
<p>POINT is an individual-based bonus program that rewarded teachers based on their value-added scores, which were calculated as the average of their students’ year-to-year growth on the statewide mathematics test, adjusted by the statewide average gain. All teachers who met fixed performance thresholds would earn bonuses. Teachers in the treatment group were eligible for a financial reward of $5,000, $10,000, or $15,000, if their value-added scores, respectively, reached the 80th, 85th, and 95th percentile of the historic, school year, and distribution of teachers’ value-added scores from the 2004–2005 and 2005–2006 school years. Teachers in both the treatment and the control groups received a stipend of $750 for each year of participation.</p>
<p>In the initial year of the study, 296 mathematics teachers in fifth through eighth grade who taught at least 10 students volunteered to participate in POINT. In total, 143 and 140 teachers<sup><xref ref-type="fn" rid="fn3-0162373712462625">3</xref></sup> were randomly assigned to the treatment and control group, respectively, and were expected to remain in the same experimental condition for all three program years. By the final program year, only 84 treatment group teachers and 64 control group teachers remained in the study. The rate of attrition observed among the sample participants was consistent with historical rates of turnover among middle school mathematics teachers in the district and reflected attrition due to teachers leaving the district, teachers moving to elementary or high school, teachers no longer teaching mathematics, or teachers teaching fewer than 10 mathematics students.<sup><xref ref-type="fn" rid="fn4-0162373712462625">4</xref></sup></p>
<p>The number of bonus winners in each year ranged from 41 to 44. In total, 51 treatment group teachers received a bonus during the three years of the POINT study. Among them, 16 teachers won a bonus once, 17 won twice, and 18 won a bonus in all three years. The average bonus award distributed to teachers each year ranged from $9,623 to $11,370.</p>
</sec>
<sec id="section15-0162373712462625">
<title>PPTI</title>
<p>The RRISD is a suburban district in Texas with above average achievement on the state accountability tests. During the implementation of PPTI, it served about 43,000 students annually, which comprised of 46% White, 30% Hispanic, 10% Asian, and 8% Black students. About one-quarter of the students were eligible for FRPL. Seven percent of the district’s student population was ELL.</p>
<p>RRISD organized middle school teachers into multiple grade-level interdisciplinary teams in each school consisting of at least one teacher for each core subject of mathematics, reading/English language arts, science, and social studies. Some teams also included special education teachers and specialists for ELL. Teams could change across years but always included at least one teacher from each of the core subject areas. Teams were randomized to either the bonus intervention or control condition using a block-randomized design. Blocks were defined by grades within school. Within each block, there were multiple teams. When there was an even number of teams, half the teams in each block were randomized to treatment and half to control. In blocks with three teams (no blocks had more than four teams), two teams were randomly assigned to treatment or control, and the remaining team was assigned to the other condition. The randomizations were constrained so that the number of treatment and control teams was balanced at each grade level.</p>
<p>PPTI rewarded teaching teams based on the team’s average value-added scores. Value-added scores for teachers in each subject area were calculated, and the overall performance measure for the team was the average of its contributions to each of the four subject areas. Bonuses were awarded to a team whose score ranked in the top third of all teams at the same grade level in the treatment group. If a team fell just below the bonus threshold and would have earned a bonus had another team in the same school not out-performed it, the nonqualifying team was also designated a bonus winner. This stipulation ensured that no team close to earning a bonus would be denied a bonus because another team in the same school had outperformed it.</p>
<p>In 2008–2009, 78 teaching teams at the sixth-, seventh-, and eighth-grade levels participated in PPTI. They were randomly assigned to either the treatment or control group. Thirty-nine out of 78 participating teams were assigned to the treatment group. In the first program year, 67 teachers on 14 teams won bonuses, with an average bonus of $5,373 per teacher. Teams of teachers were rerandomized to the treatment or the control group in the second program year, in which 40 out of 81 teams were assigned to the treatment group. In the second program year, 52 teachers on 12 teams received a bonus, with an average payout of $5,862 per teacher.</p>
</sec>
<sec id="section16-0162373712462625">
<title>SPBP</title>
<p>From 2007–2008 to 2009–2010, the New York City Department of Education (NYCDOE) and United Federation of Teachers (UFT) implemented SPBP, a school-based performance pay program for high-needs K-12 schools, as defined by their poverty rates, student demographic characteristics, and fourth- and eighth-grade scores on the statewide mathematics and English language arts tests (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>). The district identified 427 eligible schools at the beginning of the program. The percentage of Hispanic and Black students was 55% and 40%, respectively. Over 80% of the students were eligible for FRPL, and 45% were ELL.</p>
<p>SPBP rewarded schools according to their Progress Report scores issued by the NYCDOE. Schools’ Progress Report scores were calculated based on a number of criteria, including student test scores, graduation rates (for high schools), student attendance, and school environment, as measured by student, teacher, and parent responses to a district-administered survey. However, the most important factor for awarding bonuses was student achievement. Schools that met their annual performance targets, as defined by the Progress Reports, were eligible to receive full bonuses equal to $3,000 per full-time UFT-represented staff member working at each school. Schools that met 75% of their targets received a school-level partial bonus of $1,500 per full-time UFT-represented staff member. Within each school, a four-person compensation committee was established to determine how to distribute the bonus among staff members. Most compensation committees decided to distribute the bonus equally among eligible staff members or give smaller awards to teachers who did not work in the school all year.</p>
<p>The initial randomization of schools resulted in 234 treatment schools and 168 control schools,<sup><xref ref-type="fn" rid="fn5-0162373712462625">5</xref></sup> and they remained in their assigned group for the entire duration of the study. Each year, eligible treatment schools needed to secure approval of at least 55% of its UFT-represented staff to participate. After staff voting and some withdrawals and school closings in later years, the number of treatment group schools was 199, 191, and 189 in each of the three program years, respectively. The number of schools in the control group was 168, 167, and 167, respectively, in each of the three program years. In each of the three years of SPBP, 62%, 84%, and 13% of schools won full or partial bonuses.<sup><xref ref-type="fn" rid="fn6-0162373712462625">6</xref></sup> The within-school average payout was $2,857, $2,841, and $2,812 per staff member in each of the three program years, respectively.</p>
</sec>
</sec>
<sec id="section17-0162373712462625">
<title>Surveys</title>
<p>All three studies conducted online surveys of participating teachers from both groups. For POINT, teachers were surveyed once during each of the three program years. For PPTI, teachers were surveyed twice during each of the two program years, once in the fall or winter and once in the spring. For SPBP, seven classroom teachers were randomly selected from each participating school and surveyed during the last program year.<sup><xref ref-type="fn" rid="fn7-0162373712462625">7</xref></sup> Four of them taught subjects or grades that were included in the statewide achievement assessment program, including mathematics or English language arts teachers at the elementary and middle school levels and high school teachers who taught subjects tested by the Regents exam. The remaining three teachers taught nontested subjects or grades.</p>
<p>Teachers took the surveys online. An initial email contained information about survey content, details about the stipend offered for participating in the survey, and an explanation of how confidentiality would be protected. Response rates for the final program year were 98% for POINT, 91% for PPTI, and 58% for SPBP.</p>
<p>Surveys used in all three programs asked teachers about their understanding of the program, motivation, and practices. Most of the survey questions were either on a 4-point Likert-type scale that asked about the extent to which teachers agreed with the item (e.g., where 1 indicated <italic>strongly disagree</italic> and 4 indicated <italic>strongly agree</italic>) or a 6-point Likert-type scale that asked about the extent that teachers engaged in a particular practice (e.g., where 1 indicated <italic>never</italic> and 6 indicated <italic>almost daily</italic>). Surveys used in PPTI and SPBP also collected teachers’ demographic information such as gender, ethnicity, highest education level attained, and years of teaching experience. We collected the same type of information from district records for POINT teachers.</p>
<p>Across the three studies, there were similarly worded items that assessed teachers’ perceptions and understanding of the incentive pay program, as well as various practices that teachers may be likely to change as a result of being eligible to receive a bonus. Based upon these common survey items, we created 10 scales measuring key constructs related to teachers’ motivation and practices. To create these composite measures, we reviewed each of the survey questions, computed descriptive statistics for all item-level responses, and conducted exploratory factor analyses where appropriate. Scale scores were calculated by averaging item scores over all responded items in a scale. In other instances, we created item-level scales by dichotomizing the 4-point Likert-type responses (<italic>strongly agree/agree</italic> vs. <italic>strongly disagree/disagree</italic>). Thus, these scales represented the percentage of teachers who endorsed the items. The complete list of items and scales, along with the internal consistency reliability of each scale, is presented in <xref ref-type="table" rid="table1-0162373712462625">Table 1</xref>.<sup><xref ref-type="fn" rid="fn8-0162373712462625">8</xref></sup></p>
<table-wrap id="table1-0162373712462625" position="float">
<label>Table 1</label>
<caption><p>Common Survey Scales and Reliability Coefficients for Composite Scales</p></caption>
<graphic alternate-form-of="table1-0162373712462625" xlink:href="10.3102_0162373712462625-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="center"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Scale</th>
<th align="center">Description of the Scale/Item With Score Scale in Parenthesis</th>
<th align="center">Number of Items</th>
<th align="center">Alpha</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="4"><bold>Goal acceptance</bold></td>
</tr>
<tr>
<td> Skill-based pay</td>
<td>Teachers should be compensated for demonstrating outstanding teaching skills (A)<sup><xref ref-type="table-fn" rid="table-fn2-0162373712462625">a</xref></sup></td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Performance measure</td>
<td>Rewarding teachers based on test score gains is problematic (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Program understanding</td>
<td>I have a clear understanding of the performance criteria for earning a bonus award (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Program fairness</td>
<td>The method used to award bonuses is fair to teachers (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="4"><bold>Expectancy</bold></td>
</tr>
<tr>
<td> Teachers’ self-efficacy</td>
<td>Teachers’ confidence in teaching (A)</td>
<td>4</td>
<td>0.65</td>
</tr>
<tr>
<td> Teachers’ impact on student achievement</td>
<td>Teachers’ impact on student achievement is limited due to the effect of home environment (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Chance to win a bonus</td>
<td>What is the chance you/your team will receive a bonus based on this year’s performance (N)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="4"><bold>Valence</bold></td>
</tr>
<tr>
<td> Desire to earn a bonus</td>
<td>I have a strong desire to earn a bonus (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Motivating effect of bonuses</td>
<td>The chance to earn a bonus award has energized me to improve my teaching (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Desirability of bonuses</td>
<td>The bonus amount is not large enough to motivate extra effort (for POINT and SPBP)<sup><xref ref-type="table-fn" rid="table-fn3-0162373712462625">b</xref></sup> (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="4"><bold>Instruction</bold></td>
</tr>
<tr>
<td> Focus on standards</td>
<td>Frequency of activities to align instruction with state standards (F) (G)<sup><xref ref-type="table-fn" rid="table-fn4-0162373712462625">c</xref></sup></td>
<td>2</td>
<td>0.51</td>
</tr>
<tr>
<td> Data-driven decision-making</td>
<td>Use of student test scores to guide instruction (E)</td>
<td>9</td>
<td>0.89</td>
</tr>
<tr>
<td> Test preparation</td>
<td>Importance teachers placed on test-preparation activities (I)</td>
<td>4</td>
<td>0.81</td>
</tr>
<tr>
<td> Changes in instruction</td>
<td>Changes made in classroom emphasis on state standards and tests (C)</td>
<td>6</td>
<td>0.84</td>
</tr>
<tr>
<td> Changes in student learning</td>
<td>Changes made in the emphasis on hands-on activities and having students work in groups (C)</td>
<td>2</td>
<td>0.77</td>
</tr>
<tr>
<td> No program impact on practices</td>
<td>The program did not affect my teaching practices or professional behaviors (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="4"><bold>Number of hours worked</bold></td>
</tr>
<tr>
<td> Total extra working hours per week</td>
<td>Number of hours worked outside of formal school hours on a weekly basis (N)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td> Portion of extra working hour on routine tasks</td>
<td>Portion of extra working hours spent on preparing lessons, grading, and administrative tasks (P)</td>
<td>3</td>
<td>0.53</td>
</tr>
<tr>
<td> Portion of extra working hour on other tasks</td>
<td>Portion of extra working hours spent on professional development, meeting with students, colleagues, and parents, and maintaining class website (P)</td>
<td>6</td>
<td>0.67</td>
</tr>
<tr>
<td colspan="4"><bold>Job stress</bold></td>
</tr>
<tr>
<td> Program impact on job stress</td>
<td>I have experienced increased job stress as a result of the program (for POINT)<sup><xref ref-type="table-fn" rid="table-fn5-0162373712462625">d</xref></sup> (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
<tr>
<td colspan="4"><bold>Collegiality</bold></td>
</tr>
<tr>
<td> Positive relationship with colleagues</td>
<td>Positively worded items about relationship with colleagues such as cooperation and mutual help (A)</td>
<td>2</td>
<td>0.76</td>
</tr>
<tr>
<td> Negative relationship with colleagues</td>
<td>Negatively worded items about relationship with colleagues such as competitiveness and lack of trust (A)</td>
<td>2</td>
<td>0.72</td>
</tr>
<tr>
<td> Negative program impact on relationships among colleagues</td>
<td>I have noticed increased resentment among teachers since the start of the program (A)</td>
<td>1</td>
<td align="center">—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0162373712462625">
<p><italic>Note</italic>. POINT = Project on Incentives in Teaching; SPBP = School-Wide Performance Bonus Program; PPTI = Pilot Project on Team Incentives.</p>
</fn>
<fn id="table-fn2-0162373712462625">
<label>a.</label>
<p>Please refer to the following notation for the score scale used for each scale/item. A: 4-point Likert-type scale, with 1 = <italic>strongly disagree</italic>, 2 = <italic>disagree</italic>, 3 = <italic>agree</italic>, and 4 = <italic>strongly agree</italic>. C: 5-point Likert-type scale, with 1 = <italic>much less than last year</italic>, 2 = <italic>a little less than last year</italic>, 3 = <italic>the same as last year</italic>, 4 = <italic>a little more than last year</italic>, and 5 = <italic>much more than last year</italic>. E: 4-point Likert-type scale, with 1 = <italic>not used in this way</italic>, 2 = <italic>used minimally</italic>, 3 = <italic>used moderately</italic>, and 4 = <italic>used extensively</italic>. F: 6-point Likert-type scale, with 1 = <italic>never</italic>, 2 = <italic>once or twice a year</italic>, 3 = <italic>once or twice a semester</italic>, 4 = <italic>once or twice a month</italic>, 5 = <italic>once or twice a week</italic>, and 6 = <italic>almost daily</italic>. G: 5-point Likert-type scale, with 1 = <italic>never</italic>, 2 = <italic>every few months</italic>, 3 = <italic>once or twice a month</italic>, 4 = <italic>once or twice a week</italic>, 5 = <italic>almost daily</italic>. N: numerical scale. P: 4-point Likert-type scale, with 1 = <italic>none</italic>, 2 = <italic>a small portion</italic>, 3 = <italic>a moderate portion</italic>, and 4 = <italic>a major portion</italic>.</p>
</fn>
<fn id="table-fn3-0162373712462625">
<label>b.</label>
<p>The corresponding PPTI survey item was “The size of the bonus award is too small to motivate me to work harder” (A).</p>
</fn>
<fn id="table-fn4-0162373712462625">
<label>c.</label>
<p>POINT and PPTI survey items used a 6-point scale, whereas SPBP survey items used a 5-point scale.</p>
</fn>
<fn id="table-fn5-0162373712462625">
<label>d.</label>
<p>The corresponding SPBP survey items asked teachers to report changes in their relationships with administrators, other teachers, and other nonclassroom teaching staff members. The score scale was a 5-point Likert-type scale, with 1 = <italic>changed significantly for the worse</italic>, 2 = <italic>changed slightly for the worse</italic>, 3 = <italic>did not change</italic>, 4 = <italic>changed slightly for the better</italic>, and 5 = <italic>changed significantly for the better</italic>.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section18-0162373712462625">
<title>Analytic Approach</title>
<p>We analyzed teachers’ motivation and attitudes toward incentive pay programs based on responses from incentive eligible teachers in three programs. To allow teachers maximum time to fully understand the program and its effects, we examined the survey responses obtained in the final year for each program. In addition, we examined the effects of incentive pay programs on teachers’ instruction, number of hours worked, job stress, and collegial relationships based on three types of results, including differences in teachers’ practices between the treatment and control group in each program,<sup><xref ref-type="fn" rid="fn9-0162373712462625">9</xref></sup> teachers’ reported changes in practices, and changes in the responses of POINT teachers who remained in the program for three years (referred to as POINT persistent teachers below) between the first and third program year surveys.</p>
<p>We used a two-level mixed-effects hierarchical linear model to analyze differences between treatment and control group teachers within each program. Level 1 models individual teacher survey responses (<italic>Y<sub>ij</sub></italic>) as a function of a team or school mean (θ<sub><italic>j</italic></sub>), teacher-level covariates () such as teachers’ demographic characteristics (i.e., gender, ethnicity, years of teaching experience, whether the teachers had a master’s degree or higher), and a teacher-specific error term (ε<sub><italic>ij</italic></sub>). The Level 1 model used for PPTI included indicators for whether the teacher was an English language arts, mathematics, science, and social studies teacher. For SPBP, whether the teacher taught tested subject or grade was also included as a Level 1 covariate.</p>
<p>Level 2 models the team or school mean (θ<sub><italic>j</italic></sub>) as a function of the team’s or school’s treatment status (<italic>T<sub>j</sub></italic>) and random effects for teams or schools (ξ<sub><italic>j</italic></sub>) to account for the clustering of teachers within course-groups, teams, or schools. For POINT, the Level 2 models included fixed effects (<italic>u<sub>jg</sub></italic>) for the course-group randomized block to which teachers were assigned and an indicator for treatment condition. For PPTI, the Level 2 modeled the team components as a function of the team’s intervention status, fixed effects (<italic>u<sub>jg</sub></italic>) for the blocks with which teams were randomly assigned to interventions, and random effects for team, which accommodates the fact that responses from teachers on the same team may be correlated. For SPBP, we also controlled for grade- and school-level demographic variables (), including enrollment size, percentage of ELL, percentage of students eligible for individual education program, percentage of Hispanic and Black students, and percentage of students eligible for FRPL.</p>
<p>
<disp-formula id="disp-formula1-0162373712462625">
<mml:math display="block" id="math1-0162373712462625">
<mml:mrow>
<mml:msub>
<mml:mi>Y</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>θ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>X</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ε</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0162373712462625" xlink:href="10.3102_0162373712462625-eq1.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula2-0162373712462625">
<mml:math display="block" id="math2-0162373712462625">
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>v</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>l</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mn>2</mml:mn>
<mml:mspace width="0.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>P</mml:mi>
<mml:mi>O</mml:mi>
<mml:mi>I</mml:mi>
<mml:mi>N</mml:mi>
<mml:mi>T</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>d</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mi>P</mml:mi>
<mml:mi>P</mml:mi>
<mml:mi>T</mml:mi>
<mml:mi>I</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mi>θ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>μ</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mi>δ</mml:mi>
<mml:mo>+</mml:mo>
<mml:mstyle displaystyle="true">
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>γ</mml:mi>
<mml:mi>g</mml:mi>
</mml:msub>
<mml:msub>
<mml:mi>u</mml:mi>
<mml:mrow>
<mml:mi>j</mml:mi>
<mml:mi>g</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ζ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mspace width="0.5em"/>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>d</mml:mi>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0162373712462625" xlink:href="10.3102_0162373712462625-eq2.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula3-0162373712462625">
<mml:math display="block" id="math3-0162373712462625">
<mml:mrow>
<mml:mi>L</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>v</mml:mi>
<mml:mi>e</mml:mi>
<mml:mi>l</mml:mi>
<mml:mspace width="0.5em"/>
<mml:mn>2</mml:mn>
<mml:mspace width="0.5em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>S</mml:mi>
<mml:mi>P</mml:mi>
<mml:mi>B</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mi>θ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>μ</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>T</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mi>δ</mml:mi>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>G</mml:mi>
<mml:mi>j</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>γ</mml:mi>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>S</mml:mi>
<mml:mi>j</mml:mi>
<mml:mi>T</mml:mi>
</mml:msubsup>
<mml:mi>λ</mml:mi>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ζ</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0162373712462625" xlink:href="10.3102_0162373712462625-eq3.tif"/>
</disp-formula>
</p>
<p><xref ref-type="disp-formula" rid="disp-formula1-0162373712462625">Equations 1</xref> to <xref ref-type="disp-formula" rid="disp-formula3-0162373712462625">3</xref> summarize the model used for composite outcome measures. <italic>i</italic> index teachers and <italic>j</italic> index course-groups (POINT) or teaching teams (PPTI) or schools (SPBP). β is the vector of parameters for teacher-level covariates. ε<sub><italic>ij</italic></sub> are independently normally distributed residual errors. µ is the population mean. δ is the parameter for the treatment effect. <italic>u<sub>jg</sub></italic> equals 1 if the team is in randomization course-group (POINT) or block (PPTI) <italic>g</italic> and 0 otherwise. γ and <italic>λ</italic> are the coefficient vectors for grade- and school-level covariates, respectively. ξ<sub><italic>j</italic></sub> are the random effects for the course-groups, teaching teams, or schools.</p>
<p>We applied an ologit (ordinal logit) regression model for 4-point Likert-type scale items and a logit regression model for the dichotomized scores, with the same set of teacher- and school-level covariates and adjustment for clustered data (<xref ref-type="bibr" rid="bibr27-0162373712462625">Long &amp; Freese, 2006</xref>).<sup><xref ref-type="fn" rid="fn10-0162373712462625">10</xref></sup> When analyzing changes in POINT persistent teachers’ responses between the first and final program year, we used the same model to compare treatment and control group teachers in POINT with teachers’ responses in the final program year as the outcome variable and their first year responses as one additional Level 1 covariate. We used the <xref ref-type="bibr" rid="bibr4-0162373712462625">Benjamini and Hochberg (1995)</xref> method to control for false significant rate at 5% across all tests to adjust for multiple comparisons.</p>
<p>Results showed some differences among programs on certain measures we examined. Multiple reasons might have contributed to these differences, such as differences in the program features, site effects, program implementation, and other unobserved factors that might have affected teachers’ motivation and behavior. Unfortunately, it is impossible to specifically link any differences in teachers’ motivation and behavioral changes to differences in program features based on the data we had. Thus, when reporting the results, we focused on the commonalities across programs by studying the general patterns in the results among programs.</p>
<p>We present results on the common items and scales generated for this comparative analysis. Where applicable, we also refer to results from the evaluation of each program, in which the same teaching practice variables as those we examined (e.g., instruction) were measured using slightly different scales. The original scales usually included a few more items than the scales we generated based on common items across surveys and had higher internal consistency reliability than the corresponding measures used in this study.</p>
</sec>
</sec>
<sec id="section19-0162373712462625" sec-type="results">
<title>Results</title>
<p>The number of teachers included in the analysis was 145 for POINT (<italic>N</italic><sub>treat</sub> = 82, <italic>N</italic><sub>control</sub> = 63), 355 for PPTI (<italic>N</italic><sub>treat</sub> = 175, <italic>N</italic><sub>control</sub> = 180), and 1,407 for SPBP (<italic>N</italic><sub>incentive eligible</sub> = 798, <italic>N</italic><sub>control</sub> = 609). Seventy-seven percent of the respondents were female. The percentage of teachers with a master’s degree or higher was 66%, 29%, and 55% in POINT, PPTI, and SPBP, respectively. More than two-thirds of teachers in POINT and PPTI were White. In SPBP, 36% of teachers were White and 27% were Black. The average years of teaching experience were 14 (<italic>SD</italic> = 8), 10 (<italic>SD =</italic> 8), and 13 (<italic>SD =</italic> 8) for POINT, PPTI, and SPBP, respectively.</p>
<sec id="section20-0162373712462625">
<title>Teachers’ Motivation</title>
<sec id="section21-0162373712462625">
<title>Goal acceptance</title>
<p>As shown by <xref ref-type="table" rid="table2-0162373712462625">Table 2</xref>, teachers accepted the general idea of rewarding teachers based on teaching performance. Namely, 80% of POINT teachers and 75% of PPTI teachers believed teachers should be rewarded for outstanding teaching skills.<sup><xref ref-type="fn" rid="fn11-0162373712462625">11</xref></sup> However, teachers do not appear to equate teaching skills with student achievement on standardized tests. The majority of POINT (90%) and SPBP (81%) teachers agreed that rewarding teachers based on student test score gains was problematic because student test scores did not capture important aspects of teaching performance. In addition, teachers’ understanding of the program and perceptions of fairness differed by program. The majority of SPBP teachers (85%) reported that they understood the Progress Report and contributing factors. However, about one-third of SPBP teachers reported not understanding several aspects of the program very well, such as the amount of funding a school would receive if it met 100% of the target, the criteria for receiving a partial bonus, and the source of funding for this program (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>). Only half of PPTI bonus eligible teachers (48%) reported having a good understanding of the program’s criteria. With respect to fairness, many teachers in all three programs had concerns. Only slightly over half (55%) of the bonus eligible teachers in POINT and SPBP and one-third of the PPTI treatment group teachers agreed that the method for awarding bonuses in their programs was fair to all program participants.<sup><xref ref-type="fn" rid="fn12-0162373712462625">12</xref></sup></p>
<table-wrap id="table2-0162373712462625" position="float">
<label>Table 2</label>
<caption><p>Incentive Eligible Teachers’ Responses About Goal Acceptance, Expectancy, and Valence</p></caption>
<graphic alternate-form-of="table2-0162373712462625" xlink:href="10.3102_0162373712462625-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Scale</th>
<th align="center">Program</th>
<th align="center"><italic>N</italic></th>
<th align="center">% Agree / <italic>M</italic> (<italic>SD</italic>)</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="4"><bold>Goal acceptance</bold></td>
</tr>
<tr>
<td> Teachers should be rewarded for demonstrating outstanding teaching skills</td>
<td>POINT</td>
<td>80</td>
<td>80%</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>163</td>
<td>75%</td>
</tr>
<tr>
<td> Rewarding teachers based on test score gains is problematic</td>
<td>POINT</td>
<td>82</td>
<td>90%</td>
</tr>
<tr>
<td/>
<td>SPBP</td>
<td>747</td>
<td>81%</td>
</tr>
<tr>
<td> I have a clear understanding of the performance criteria for earning a bonus award</td>
<td>PPTI</td>
<td>172</td>
<td>48%</td>
</tr>
<tr>
<td/>
<td>SPBP</td>
<td>773</td>
<td>85%</td>
</tr>
<tr>
<td> The method used to award bonuses is fair to all program participants</td>
<td>POINT</td>
<td>81</td>
<td>55%</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>172</td>
<td>34%</td>
</tr>
<tr>
<td/>
<td>SPBP</td>
<td>648</td>
<td>55%</td>
</tr>
<tr>
<td colspan="4"><bold>Expectancy</bold></td>
</tr>
<tr>
<td> Teachers’ confidence in teaching</td>
<td>POINT</td>
<td>81</td>
<td>3.17 (0.39)</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>164</td>
<td>3.05 (0.36)</td>
</tr>
<tr>
<td> Teacher’s impact on student achievement is limited due to the effect of home environment</td>
<td>POINT</td>
<td>82</td>
<td>50%</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>165</td>
<td>40%</td>
</tr>
<tr>
<td> What is the chance you/your team will receive a bonus based on this year’s performance</td>
<td>POINT</td>
<td>81</td>
<td>46.05 (28.72)</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>164</td>
<td>51.68 (24.87)</td>
</tr>
<tr>
<td colspan="4"><bold>Valence</bold></td>
</tr>
<tr>
<td> I have a strong desire to earn a bonus</td>
<td>POINT</td>
<td>81</td>
<td>77%</td>
</tr>
<tr>
<td/>
<td>SPBP</td>
<td>753</td>
<td>64%</td>
</tr>
<tr>
<td> The chance to earn a bonus award has energized me to improve my teaching</td>
<td>POINT</td>
<td>82</td>
<td>42%</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>174</td>
<td>19%</td>
</tr>
<tr>
<td> The bonus amount is not large enough to motivate extra effort (PPTI survey item was “The size of the bonus award is too small to motivate me to work harder”)</td>
<td>POINT</td>
<td>81</td>
<td>49%</td>
</tr>
<tr>
<td/>
<td>PPTI</td>
<td>169</td>
<td>16%</td>
</tr>
<tr>
<td/>
<td>SPBP</td>
<td>684</td>
<td>42%</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn6-0162373712462625">
<p><italic>Note</italic>. POINT = Project on Incentives in Teaching; SPBP = School-Wide Performance Bonus Program; PPTI = Pilot Project on Team Incentives.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section22-0162373712462625">
<title>Expectancy</title>
<p>Although teachers had confidence in their teaching abilities, they doubted that their personal efforts would lead to the expected student achievement goals. Moreover, teachers had concerns about the influence of family on student achievement. Overall, they did not have high expectancy of achieving the program goals through personal efforts.</p>
<p>Specifically, POINT and PPTI treatment group teachers were confident about their abilities to reach the most difficult students, help students retain information learned, manage disruptive behaviors during class, and evaluate the appropriate level of assignments for students. The average score of the teachers’ confidence in teaching scale was above 3 on a 4-point scale (see <xref ref-type="table" rid="table2-0162373712462625">Table 2</xref>). However, about half of POINT (50%) and PPTI (40%) teachers agreed that teachers were limited in what they could achieve because family environment had a large influence on student achievement. When asked to estimate the probability that they would win a bonus, both POINT and PPTI teachers estimated their chances to be around 50%. This indicates that teachers’ expectancy was at breakeven. Given that people often report 50% for an unknown or uncertain probability, this may indicate that many teachers did not have a strong sense of the likelihood they would win a bonus.</p>
<sec id="section23-0162373712462625">
<title>Valence<sup><xref ref-type="fn" rid="fn13-0162373712462625">13</xref></sup></title>
<p>Results showed that although about two-thirds of teachers in POINT (77%) and SPBP (64%) wanted to earn a bonus (see <xref ref-type="table" rid="table2-0162373712462625">Table 2</xref>), teachers’ interest in earning a bonus was not associated with taking actions to win it. Only slightly over 40% of POINT teachers and 20% of PPTI teachers reported that the chance to earn a bonus energized them to improve teaching. In addition, 42% of SPBP bonus eligible teachers and about half of POINT treatment group teachers reported that the bonus was not large enough to motivate extra effort. In contrast, only 16% of PPTI teachers reported that the bonus was too small to motivate them to work harder.<sup><xref ref-type="fn" rid="fn14-0162373712462625">14</xref></sup></p>
</sec>
</sec>
</sec>
<sec id="section24-0162373712462625">
<title>Teachers’ Practices and Working Conditions</title>
<sec id="section25-0162373712462625">
<title>Instruction</title>
<p>Comparisons between treatment and control group teachers within each program on three measures of teaching practices (i.e., focus on standards, data-driven decision-making, and test preparation) found only one significant difference between two groups in POINT (see <xref ref-type="table" rid="table3-0162373712462625">Table 3</xref>). Treatment group teachers reported greater emphasis on test preparation than control group teachers in the last program year. However, analysis did not find a positive, significant association between teachers’ reported classroom time on test preparation and student achievement (<xref ref-type="bibr" rid="bibr43-0162373712462625">Springer et al., 2010</xref>). Both treatment and control group teachers in POINT and PPTI reported making little change to their instruction and student learning due to the implementation of the incentive pay program. The average scores of the scales on changes made in classroom emphasis on state standards and tests and on student engagement in hands-on activities and group learning represent a level of change that was between no change and a little more than last year. In addition, the majority of incentive eligible teachers in all three programs reported that their programs had no effect on teaching, with 85% in POINT, 78% in PPTI, and 90% in SPBP. Moreover, analyses of differences in POINT persistent teachers’ responses between the first and the final program year did not find any significant changes in teachers’ reported instructional practices during the program. Overall, there is limited evidence that any of the three programs changed teachers’ instructional practices, especially practices significantly associated with student achievement.</p>
<table-wrap id="table3-0162373712462625" position="float">
<label>Table 3</label>
<caption><p>Teachers’ Responses About Instruction, Number of Hours Worked, Job Stress, and Collegiality</p></caption>
<graphic alternate-form-of="table3-0162373712462625" xlink:href="10.3102_0162373712462625-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="6">POINT<sup><xref ref-type="table-fn" rid="table-fn7-0162373712462625">a</xref></sup><hr/></th>
<th align="center" colspan="3">PPTI<hr/></th>
<th align="center" colspan="3">SPBP<hr/></th>
</tr>
<tr>
<th align="left">Scale</th>
<th align="center">T_3</th>
<th align="center">C_3</th>
<th align="center">Dif</th>
<th align="center">T_31</th>
<th align="center">C_31</th>
<th align="center">Dif</th>
<th align="center">T</th>
<th align="center">C</th>
<th align="center">Dif</th>
<th align="center">T</th>
<th align="center">C</th>
<th align="center">Dif</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="13"><bold>Instruction</bold></td>
</tr>
<tr>
<td colspan="13"> Focus on standards</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>5.1</td>
<td>5.02</td>
<td>0.08</td>
<td>−0.03</td>
<td>0.16</td>
<td>−0.19</td>
<td>5.04</td>
<td>5.12</td>
<td>−0.08</td>
<td>4.43<sup><xref ref-type="table-fn" rid="table-fn8-0162373712462625">b</xref></sup></td>
<td>4.52</td>
<td>−0.09</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.81</td>
<td>0.97</td>
<td/>
<td>0.89</td>
<td>0.95</td>
<td/>
<td>0.75</td>
<td>0.72</td>
<td/>
<td>0.68</td>
<td>0.6</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>82</td>
<td>63</td>
<td/>
<td>81</td>
<td>61</td>
<td/>
<td>172</td>
<td>171</td>
<td/>
<td>793</td>
<td>608</td>
<td/>
</tr>
<tr>
<td colspan="13"> Data-driven decision-making</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>3.04</td>
<td>2.98</td>
<td>0.06</td>
<td>0.17</td>
<td>0.15</td>
<td>0.02</td>
<td>3.21</td>
<td>3.25</td>
<td>−0.04</td>
<td>3.55</td>
<td>3.57</td>
<td>−0.02</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.68</td>
<td>0.55</td>
<td/>
<td>0.64</td>
<td>0.58</td>
<td/>
<td>0.53</td>
<td>0.52</td>
<td/>
<td>0.7</td>
<td>0.69</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>80</td>
<td>63</td>
<td/>
<td>78</td>
<td>62</td>
<td/>
<td>172</td>
<td>172</td>
<td/>
<td>723</td>
<td>542</td>
<td/>
</tr>
<tr>
<td colspan="13"> Test preparation</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>3.55</td>
<td>3.28</td>
<td>0.27<xref ref-type="table-fn" rid="table-fn11-0162373712462625">*</xref></td>
<td>0.06</td>
<td>0.03</td>
<td>0.03</td>
<td>3.34</td>
<td>3.29</td>
<td>0.05</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.5</td>
<td>0.56</td>
<td/>
<td>0.42</td>
<td>0.58</td>
<td/>
<td>0.57</td>
<td>0.59</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>82</td>
<td>61</td>
<td/>
<td>81</td>
<td>60</td>
<td/>
<td>173</td>
<td>172</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"> Changes made in instruction</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>3.66</td>
<td>3.59</td>
<td>0.07</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>3.43</td>
<td>3.41</td>
<td>0.02</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.57</td>
<td>0.54</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
<td>0.52</td>
<td>0.52</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>66</td>
<td>49</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
<td>169</td>
<td>167</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"> Changes made in student learning</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>3.48</td>
<td>3.34</td>
<td>0.14</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>3.51</td>
<td>3.57</td>
<td>−0.06</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.78</td>
<td>0.6</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
<td>0.66</td>
<td>0.69</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>82</td>
<td>63</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
<td>170</td>
<td>167</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"> No program impact on practices</td>
</tr>
<tr>
<td>  Pct</td>
<td>85%</td>
<td>89%</td>
<td>−4%</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td>78%</td>
<td align="center">—</td>
<td align="center">—</td>
<td>90%</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>82</td>
<td>63</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
<td>174</td>
<td align="center">—</td>
<td/>
<td>759</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"><bold>Number of hours worked</bold></td>
</tr>
<tr>
<td colspan="13"> Total extra working hours per week</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>14.26</td>
<td>12.83</td>
<td>1.43</td>
<td>2</td>
<td>−0.78</td>
<td>2.78</td>
<td>12.79</td>
<td>11.97</td>
<td>0.82</td>
<td>12.77</td>
<td>13.18</td>
<td>−0.41</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>10.11</td>
<td>8.9</td>
<td/>
<td>11</td>
<td>7.46</td>
<td/>
<td>9.56</td>
<td>7.15</td>
<td/>
<td>7.96</td>
<td>8.56</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>54</td>
<td>46</td>
<td/>
<td>52</td>
<td>45</td>
<td/>
<td>172</td>
<td>171</td>
<td/>
<td>788</td>
<td>603</td>
<td/>
</tr>
<tr>
<td colspan="13"> Portion of extra working hours on routine tasks</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>3.15</td>
<td>3.1</td>
<td>0.05</td>
<td/>
<td/>
<td/>
<td>3.15</td>
<td>3.08</td>
<td>0.07</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.66</td>
<td>0.66</td>
<td/>
<td/>
<td/>
<td/>
<td>0.52</td>
<td>0.55</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>81</td>
<td>63</td>
<td/>
<td/>
<td/>
<td/>
<td>172</td>
<td>172</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"> Portion of extra working hours on other tasks</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>2.26</td>
<td>2.14</td>
<td>0.12</td>
<td/>
<td/>
<td/>
<td>2.28</td>
<td>2.3</td>
<td>−0.02</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.53</td>
<td>0.5</td>
<td/>
<td/>
<td/>
<td/>
<td>0.44</td>
<td>0.53</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>81</td>
<td>63</td>
<td/>
<td/>
<td/>
<td/>
<td>172</td>
<td>172</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"> Job stress</td>
</tr>
<tr>
<td colspan="13">  Program impact on job stress<sup><xref ref-type="table-fn" rid="table-fn9-0162373712462625">c</xref></sup></td>
</tr>
<tr>
<td>   Pct</td>
<td>17%</td>
<td align="center">—</td>
<td align="center">—</td>
<td>12%</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>   <italic>N</italic></td>
<td>82</td>
<td align="center">—</td>
<td/>
<td>81</td>
<td align="center">—</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
<tr>
<td colspan="13"><bold>Collegiality</bold></td>
</tr>
<tr>
<td colspan="13"> Positive relationships with colleagues</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>3.01</td>
<td>2.69</td>
<td>0.32<xref ref-type="table-fn" rid="table-fn11-0162373712462625">*</xref></td>
<td>−0.01</td>
<td>0.01</td>
<td>−0.02</td>
<td>3.22</td>
<td>3.32</td>
<td>−0.1</td>
<td>2.94</td>
<td>2.96</td>
<td>−0.02</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.61</td>
<td>0.62</td>
<td/>
<td>0.82</td>
<td>0.58</td>
<td/>
<td>0.66</td>
<td>0.62</td>
<td/>
<td>0.69</td>
<td>0.69</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>82</td>
<td>63</td>
<td/>
<td>81</td>
<td>61</td>
<td/>
<td>166</td>
<td>176</td>
<td/>
<td>782</td>
<td>600</td>
<td/>
</tr>
<tr>
<td colspan="13"> Negative relationship with colleagues</td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>1.92</td>
<td>2.08</td>
<td>−0.16</td>
<td>0.14</td>
<td>0.01</td>
<td>0.13</td>
<td>1.72</td>
<td>1.72</td>
<td>0</td>
<td>2.19</td>
<td>2.19</td>
<td>0</td>
</tr>
<tr>
<td>  <italic>SD</italic></td>
<td>0.67</td>
<td>0.58</td>
<td/>
<td>0.83</td>
<td>0.78</td>
<td/>
<td>0.65</td>
<td>0.69</td>
<td/>
<td>0.66</td>
<td>0.67</td>
<td/>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>82</td>
<td>63</td>
<td/>
<td>81</td>
<td>61</td>
<td/>
<td>166</td>
<td>176</td>
<td/>
<td>781</td>
<td>598</td>
<td/>
</tr>
<tr>
<td colspan="13"> Negative impact on relationships among colleagues<sup><xref ref-type="table-fn" rid="table-fn10-0162373712462625">d</xref></sup></td>
</tr>
<tr>
<td>  <italic>M</italic></td>
<td>13%</td>
<td>14%</td>
<td>−1%</td>
<td/>
<td/>
<td/>
<td>36%</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
<td align="center">—</td>
</tr>
<tr>
<td>  <italic>N</italic></td>
<td>81</td>
<td>63</td>
<td/>
<td/>
<td/>
<td/>
<td>171</td>
<td align="center">—</td>
<td/>
<td align="center">—</td>
<td align="center">—</td>
<td/>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn7-0162373712462625">
<label>a</label>
<p>T = Treatment; C = Control; 3 = the third program year; 31 = difference in POINT persistent teachers' responses between the first and third program year; POINT = Project on Incentives in Teaching; SPBP = School-Wide Performance Bonus Program; PPTI = Pilot Project on Team Incentives.</p>
</fn>
<fn id="table-fn8-0162373712462625">
<label>b</label>
<p>Items used in SPBP were on a 5-point Likert scale.</p>
</fn>
<fn id="table-fn9-0162373712462625">
<label>c</label>
<p>The percentage of SPBP teachers who reported that their level of job stress had changed for worse, did not change, or changed for better as a result of their school's participation in the program was 24%, 50%, and 21%, respectively.</p>
</fn>
<fn id="table-fn10-0162373712462625">
<label>d</label>
<p>The percentage of SPBP teachers who reported that their relationships with administrators, other teachers, and other nonclassroom staff members changed for worse during the program was 9%, 3%, and 4%, respectively.</p>
</fn>
<fn id="table-fn11-0162373712462625">
<label>*</label>
<p>indicates significant differences at 0.05 level after adjustment for multiple comparisons, ** indicates significant differences at 0.01 level after adjustment for multiple comparisons. The <italic>p</italic> values are available from the authors upon request.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section26-0162373712462625">
<title>Number of hours worked</title>
<p>Analyses did not find any evidence that incentive pay programs increased teachers’ number of hours worked (see <xref ref-type="table" rid="table3-0162373712462625">Table 3</xref>). Teachers in the treatment and control groups of all three programs reported that they worked for 2.6 to 2.8 extra hours beyond their contracted hours per work day, on average. No difference was found in the reported numbers of extra working hours between two groups in any program. Treatment and control group teachers in POINT and PPTI were also asked about how they used the extra working hour and reported similar ways of allocating this time. They spent a moderate to major portion of their extra working hours on routine tasks such as preparing lessons, grading, and completing administrative tasks and a small to moderate portion of extra working hours on other tasks such as professional development training and meeting with students, colleagues, and parents. In addition, no significant difference was found in the reported number of extra working hours per week between the first and final program year among POINT persistent teachers. Overall, results show that these incentive pay programs did not affect teachers’ number of hours worked.</p>
<sec id="section27-0162373712462625">
<title>Job stress</title>
<p>Results about job stress are available only from incentive eligible teachers in SPBP and POINT (see <xref ref-type="table" rid="table3-0162373712462625">Table 3</xref>). Only a minority of teachers in both programs reported their job stress increased as the result of the implementation of the program. For SPBP, 24% of the incentive eligible teachers indicated their level of job stress changed for worse due to the implementation of the program. Half of the incentive eligible teachers reported that participation in the program did not increase their level of job stress. In POINT, 17% of treatment group teachers reported that job stress level increased as a result of this program in the final program year, which is up 12 percentage points from the 5% who felt the program increased stress in the first program year.</p>
</sec>
<sec id="section28-0162373712462625">
<title>Collegiality</title>
<p>Analyses of the impact of pay-for-performance programs on collegiality did not find evidence that such programs damaged teachers’ relationships with their colleagues (see <xref ref-type="table" rid="table3-0162373712462625">Table 3</xref>). Comparisons between treatment and control group teachers’ reported relationships with colleagues did not find any significant difference between two groups in any programs except that POINT treatment group teachers reported greater collaboration than control group teachers. Additionally, analyses of changes in POINT persistent teachers’ report of collegial relationships between the first and last program year did not find any evidence that POINT damaged the relationships among teachers.</p>
</sec>
</sec>
</sec>
</sec>
<sec id="section29-0162373712462625" sec-type="discussion">
<title>Discussion</title>
<p>This study examines the extent to which three incentive pay programs motivated teachers to achieve program goals and changed teachers’ instruction, number of hours worked, job stress, and collegiality. Results showed that teachers did not consider their programs as motivating. First, teachers’ level of goal acceptance was not high due to a lack of understanding of the program among some teachers and teachers’ concerns about using student test scores to measure teaching performance and the fairness of the program. Second, teachers did not have high expectancy that their personal efforts would lead to student achievement gains due to concerns about the influence of family environment on student achievement. Third, although teachers would have liked to earn a bonus, they did not see the opportunity as worthy of changing behavior.</p>
<p>With respect to the impact of three incentive pay programs on teachers’ practices and working conditions, our analyses did not find that any of the three programs had affected teachers’ reported instructional practices, number of hours worked, or collegiality, except that POINT treatment group teachers reported greater emphasis on test preparation and collaboration among colleagues than their counterparts in the control group. However, classroom time on test preparation was not associated with student achievement. Although a minority of bonus eligible teachers in three programs reported increased job stress, no comparison data were available for the control group. Therefore, we could not conclude that the implementation of these pay-for-performance programs increased teachers’ job stress.</p>
<p>Notably, our findings did not differ across the different types of programs. We found no effects on teachers regardless of the choice of individual versus collective motivational mechanisms. Of course, a study of three programs cannot definitively answer the empirical question and more research is needed to shed light on this enduring social debate.</p>
<p>Connecting our findings with results from prior studies, we found both similarities and differences. For instance, we found that teachers had doubts about their control over student achievement, given the influence of family environment on student learning, and challenged the fairness of the programs’ methods used to determine the bonuses. Although studies using value-added modeling to examine student performance on standardized tests showed that teachers have a large impact on student test score growth (<xref ref-type="bibr" rid="bibr37-0162373712462625">Rivkin, Hanushek, &amp; Kain, 2005</xref>; <xref ref-type="bibr" rid="bibr38-0162373712462625">Rowan, Correnti, &amp; Miller, 2002</xref>), prior studies also found a variety of family, student, classroom, and school factors associated with student performance on standardized tests, such as student socioeconomic status (<xref ref-type="bibr" rid="bibr5-0162373712462625">Caro, 2009</xref>), parents’ expectation for student academic performance and involvement in student education (<xref ref-type="bibr" rid="bibr9-0162373712462625">Davis-Kean &amp; Sexton, 2009</xref>), and composition of peers (<xref ref-type="bibr" rid="bibr39-0162373712462625">Rubin, Bukowski, &amp; Parker, 2006</xref>). Because teachers lack control over many factors that might affect student achievement, it is not surprising that teachers question the strength of the link between their personal effort and the increase in student achievement.</p>
<p>Related to teachers’ doubts about their control over student achievement, teachers questioned using student test score gains to measure teaching performance. Most prior studies on teachers’ attitudes about pay-for-performance programs reported that teachers objected to the idea of measuring teaching performance based on student test scores or test score gains (<xref ref-type="bibr" rid="bibr2-0162373712462625">Ballou &amp; Podgursky, 1993</xref>; <xref ref-type="bibr" rid="bibr10-0162373712462625">Farkas, Johnson, Duffet, Moye, &amp; Vine, 2003</xref>; <xref ref-type="bibr" rid="bibr14-0162373712462625">Goldhaber, DeArmond, &amp; DeBurgomaster, 2011</xref>; <xref ref-type="bibr" rid="bibr24-0162373712462625">Langdon &amp; Vesper, 2000</xref>), although a study on teachers in the Texas Governor’s Educator Excellence Grant found that more than 90% of respondents considered student test score gains as moderately or highly important for evaluating teaching performance in an incentive pay program (<xref ref-type="bibr" rid="bibr41-0162373712462625">Springer et al., 2007</xref>). It is difficult to obtain teachers’ support of incentive pay programs if they think the performance measure is problematic. However, given the current emphasis on educational accountability, it is also difficult for incentive pay programs to totally ignore student test scores or test score gains when measuring teaching performance. Combinations of multiple teaching performance measures might help to gain teachers’ support of the program and boost their motivation to make behavioral changes. However, which teaching performance measures should be included and what formula should be used to combine them remain as questions to be answered.</p>
<p>We found that although teachers had a strong desire to earn a bonus, bonuses had a limited reported motivating effect, which is consistent with findings from prior studies (<xref ref-type="bibr" rid="bibr18-0162373712462625">Heneman, 1998</xref>; <xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>). Bonuses may have a limited motivating effect on teachers because teachers view the receipt of a bonus as an acknowledgement of their hard work rather than an incentive to work harder (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>). Teachers may also consider meeting performance goals and the associated pride more important than the bonus. We found that the large size of an award, such as in POINT, is not enough to offset other problems with the program such as teachers’ concerns about the teaching performance measure. Although the average bonus size of POINT tripled that of SPBP, teachers in the two programs showed similar attitudes about the motivating effect of bonuses. Program features and other contextual factors in the implementation of the program might affect the relationship between bonus size and the motivational effect of the bonus (<xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>).</p>
<p>Teachers included in this study reported little impact of the program on their instructional practices, which is a departure from findings in several previous observational studies that did not include control groups (<xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins, 2004</xref>; <xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>) but consistent with results based on observation of instruction in international experimental studies on pay-for-performance programs that also compared treatment and control group teachers (<xref ref-type="bibr" rid="bibr13-0162373712462625">Glewwe et al., 2010</xref>; <xref ref-type="bibr" rid="bibr32-0162373712462625">Muralidharan &amp; Sundararaman, 2008</xref>). A few factors might have contributed to the lack of changes in instruction. First, the lack of motivation among teachers to achieve program goals might have led to little program effect on teachers’ practices. Second, existing accountability pressure or intrinsic motivators may have had a stronger motivational effect on teachers than financial incentives (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>). For instance, test scores increased in Nashville, Tennessee, for students taught by teachers in both the treatment and control groups, as well as for students taught by other middle school teachers who did not participate in the program and for fourth-grade students during the study period, a period when the district was threatened with state takeover due to the <xref ref-type="bibr" rid="bibr33-0162373712462625">No Child Left Behind Act of 2001</xref> (20 U.S.C. 6311 <italic>et seq</italic>.). Third, although these programs lasted for two or three years, it still might not be enough time for teachers to make substantial changes in instruction. Fourth, it is questionable whether teachers have the time and energy to make any additional changes in instruction given that they report working an additional two or three hours per day to fulfill their routine responsibilities, such as grading, preparing for lessons, and completing administrative tasks. Fifth, teachers might not be well equipped with the knowledge and skills required to improve student achievement. If teachers had known how to effectively improve student achievement, they might have done their best to achieve this goal, given that most teachers reported that seeing students increase their achievement gives them high motivation to work hard (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al., 2011</xref>).</p>
<p>We did not find evidence that the implementation of incentive pay programs increased teachers’ number of hours worked or job stress, which is different from findings of prior observational studies (<xref ref-type="bibr" rid="bibr1-0162373712462625">Adkins, 2004</xref>; <xref ref-type="bibr" rid="bibr22-0162373712462625">Kelley et al., 2000</xref>; <xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al., 2010</xref>). The types of analyses conducted might have contributed to differences in results among studies (<xref ref-type="bibr" rid="bibr32-0162373712462625">Muralidharan &amp; Sundararaman, 2008</xref>). Previous studies mainly analyzed incentive eligible teachers’ reported data, whereas our study examined not only incentive eligible teachers’ reported data but also compared differences between treatment and control groups and, in one case, analyzed changes in POINT persistent teachers’ responses between the first and final program year.</p>
<p>We also did not find evidence that the implementation of incentive pay programs damaged teachers’ collegial relationships. This is consistent with findings from prior studies of both school-based and individual-based pay-for-performance programs (<xref ref-type="bibr" rid="bibr20-0162373712462625">Kelley, 1999</xref>; <xref ref-type="bibr" rid="bibr47-0162373712462625">Wiley et al., 2010</xref>). However, it is important to understand these findings in the context of the teachers’ responses to these programs. Teachers’ collegial relationships might have changed had they actively competed for awards, which is not suggested by the lack of changes in instructional practices and the numbers of hours worked.</p>
<p>Overall, our findings showed that these three incentive pay programs did not motivate teachers to make behavioral changes that lead to student achievement gains, nor did these programs increase teachers’ number of hours worked or damage teachers’ collegial relationships. The lack of program impact on teachers’ practices suggests that more careful thinking about the logic model of incentive pay programs is necessary. For instance, is the marginal motivational effect of bonus strong enough to lead to teachers’ behavioral changes in instruction, especially in the context of high-stakes accountability? Should teachers’ knowledge and skills be incorporated in the logic model of pay-for-performance program—for example, by adding professional development and other capacity-building mechanisms to the program? If so, how do these new mechanisms interact with other components of the logic model? How should teaching performance be measured to maximize teachers’ acceptance of the program and its goals?</p>
<p>Given our findings and the previous literature that finds weak effect of performance pay for teachers, policymakers might favor other reforms. For instance, compensation tied to career lattice and other professional growth and goals or compensation for work in challenging schools might be alternatives to bonus-based compensation reform. If bonus-based policy is pursued, policymakers need to recognize this lack of evidence and take steps to monitor program implementation and evaluate program impact on targeted outcomes.</p>
<p>Alternatively, policymakers can try out some untested new designs that reward teachers based on specific teaching behavior. Recent studies suggest that when people do not know how to achieve a complex goal, incentives on specific input behaviors that are directly linked to the achievement of the final goal are more effective than incentives on the output in reaching the final program goal (<xref ref-type="bibr" rid="bibr30-0162373712462625">Mehrotra, Sorbero, &amp; Damberg, 2010</xref>). For instance, <xref ref-type="bibr" rid="bibr12-0162373712462625">Fryer (2012)</xref> conducted school-based randomized trials in four large urban school districts to examine whether incentives on students’ specific learning input behaviors such as reading a book or turning in homework on time are more effective than incentives on the output of student behaviors (e.g., increased test scores) in increasing student achievement. Results showed that incentives based on students’ inputs were more effective than incentives on the output in increasing student achievement. Based on interviews with students, Fryer concluded that the major reason for differences in the effectiveness of incentives on input versus output might be because students did not know the strategies they could use to increase their achievement. Thus, students in the incentives on input group acted upon behaviors that are useful for increasing their engagement and learning outcomes, whereas students in the incentives on output group could not transform their excitement about the incentives into effective actions that lead to increased test scores, although they were excited about the incentives on increased achievement. Based on these findings and the assumption that increasing student achievement is a complex goal that teachers might not know how to achieve, Fryer inferred that teacher incentive pay based on input (i.e., certain instructional behaviors) might be more effective than rewards on output (e.g., increase in their students’ test scores) in increasing students’ achievement. This new model of teacher incentive pay programs might be beneficial, but it would require identifying specific practices that teachers should follow to yield better student outcomes. If such practices can be found, Fryer’s and others’ work suggests financial rewards might help in the uptake of the practices, but other means of motivation might also be explored.</p>
<p>The current study had several limitations. First, it is based on teacher self-reported data, which suffer from a variety of response biases such as biases caused by social desirability (<xref ref-type="bibr" rid="bibr19-0162373712462625">Heneman &amp; Milanowski, 1999</xref>). However, it is usually necessary to rely on self-reported data when it comes to measuring teachers’ opinions. Future studies could consider multiple data collection methods, such as teaching logs and classroom observation, which may provide more detailed information about teachers’ behavioral changes and opportunities for triangulation. Second, teacher attrition in POINT and the relatively low response rate in SPBP might have affected the results. Our analyses on differences in the background characteristics between participating teachers in the first and last year of POINT and differences between the weighted and unweighted results for SPBP show that any such differences are likely to be small. Third, it is possible that teachers in different programs interpreted the same item differently due to other contextual factors such as district and program policies and professional development. It is also possible that the experimental nature of the intervention in POINT and PPTI influenced teachers’ responses, since they knew that the program was short-term and was not intended to become district policy. Finally, all three studies focus only on existing teachers and cannot comment on the potential effects that pay-for-performance programs might have on the composition of the teacher labor force.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by the National Center on Performance Incentives, which is funded by the United States Department of Education’s Institute of Education Sciences (R305A06034) and the New York City Fund for Public Schools (071609). We are grateful for the officials and teachers in three participating districts. The content or opinions expressed do not necessarily reflect the views of the funders of this project. A version of this research was presented at the Annual Meeting of the American Educational Association (April, 2012).</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0162373712462625">
<label>1.</label>
<p>None of the three programs found any significant impact of teacher incentive pay programs on student achievement. Because the focus of this study is on teachers, we did not review results regarding the effect of teacher incentive pay programs on student achievement across three projects. Interested readers are referred to <xref ref-type="bibr" rid="bibr43-0162373712462625">Springer et al. (2010)</xref>, <xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al. (2011)</xref>, and <xref ref-type="bibr" rid="bibr44-0162373712462625">Springer et al. (2012)</xref> for the details of analyses on student achievement.</p>
</fn>
<fn fn-type="other" id="fn2-0162373712462625">
<label>2.</label>
<p>On the other hand, as teachers put in additional effort to win a bonus, teachers may experience increased job stress. These types of externalities bear on the extent to which teachers will feel motivated by incentive pay programs.</p>
</fn>
<fn fn-type="other" id="fn3-0162373712462625">
<label>3.</label>
<p>These numbers represent the number of teachers in each group at the end of each academic year.</p>
</fn>
<fn fn-type="other" id="fn4-0162373712462625">
<label>4.</label>
<p>We compared POINT teachers who persisted through Year 3 with those who dropped out during the program on their Year 1 and Year 3 survey responses. We did not find any significant differences between these two groups of teachers.</p>
</fn>
<fn fn-type="other" id="fn5-0162373712462625">
<label>5.</label>
<p>The district removed 25 eligible schools before the randomization. We have very limited information about school removal decisions.</p>
</fn>
<fn fn-type="other" id="fn6-0162373712462625">
<label>6.</label>
<p>The percentage of schools winning bonuses greatly decreased in the final year due to the state’s decision to change proficiency cutoff scores.</p>
</fn>
<fn fn-type="other" id="fn7-0162373712462625">
<label>7.</label>
<p>All classroom teachers were surveyed in schools where the total number of classroom teachers was less than seven.</p>
</fn>
<fn fn-type="other" id="fn8-0162373712462625">
<label>8.</label>
<p>Readers interested in details of each survey are referred to <xref ref-type="bibr" rid="bibr43-0162373712462625">Springer et al. (2010)</xref>, <xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al. (2011)</xref>, and <xref ref-type="bibr" rid="bibr44-0162373712462625">Springer et al. (2012)</xref>.</p>
</fn>
<fn fn-type="other" id="fn9-0162373712462625">
<label>9.</label>
<p>We examined differences between the treatment and control groups at baseline based on teacher administrative data and student achievement data for each program. In POINT and PPTI, treatment group teachers’ classes contained slightly greater portions of ELLs than those of control teachers. In PPTI, the percentage of talented and gifted students was greater in the control group than that in the treatment group. No significant difference was found between the treatment and control groups for SPBP. We also tested whether the treatment and control groups had differential nonresponse patterns based on teacher administrative data and student achievement data. Overall, we did not find any evidence of differential nonresponse patterns except on one variable for POINT. POINT treatment teachers who stayed in the program for 3 years had about half a day more of absences than their counterparts in the control group. These differences are substantively small. Moreover, we controlled for available covariates at the teacher and school levels in the analysis to mitigate the influence of potential imbalance and differential nonresponse patterns between two groups of teachers. Interested readers are referred to <xref ref-type="bibr" rid="bibr43-0162373712462625">Springer et al. (2010)</xref>, <xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al. (2011)</xref>, and <xref ref-type="bibr" rid="bibr44-0162373712462625">Springer et al. (2012)</xref> for the details of these analyses and results. Results are also available from the authors.</p>
</fn>
<fn fn-type="other" id="fn10-0162373712462625">
<label>10.</label>
<p>Details of the equations used for items scales are available from the authors upon request.</p>
</fn>
<fn fn-type="other" id="fn11-0162373712462625">
<label>11.</label>
<p>Because the response rates of POINT and PPTI were high, and there were few differences between weighted and unweighted results in SPBP (<xref ref-type="bibr" rid="bibr29-0162373712462625">Marsh et al. 2011</xref>), we reported the unweighted results in this study.</p>
</fn>
<fn fn-type="other" id="fn12-0162373712462625">
<label>12.</label>
<p>The response rate for POINT was calculated based on teachers who remained in the program. There were limited differences between teachers who remained in or dropped out of the study.</p>
</fn>
<fn fn-type="other" id="fn13-0162373712462625">
<label>13.</label>
<p>None of the surveys used in three programs asked teachers questions about instrumentality (i.e., the likelihood that meeting the achievement goals will result in a financial reward).</p>
</fn>
<fn fn-type="other" id="fn14-0162373712462625">
<label>14.</label>
<p>It is important to note that the wording of the PPTI item was different from the wording of the SPBP and POINT items, which renders it difficult to directly compare the motivating effects of the bonus across programs.</p>
</fn>
</fn-group>
</notes>
<bio>
<title>Authors</title>
<p>KUN YUAN is a Behavioral Scientist at RAND Corporation, 4570 Fifth Avenue, Suite 600, Pittsburgh, PA 15213; <email>kyuan@rand.org</email>. Her areas of specialization are educational measurement and program evaluation.</p>
<p>VI-NHUAN LE is a Behavioral Scientist at RAND Corporation, 1776 Main Street, Santa Monica, CA 90407; <email>vinhuan@rand.org</email>. Her areas of specialization are educational measurement and early childhood education.</p>
<p>DANIEL F. MCCAFFREY is a Senior Statistician at RAND Corporation, 4570 Fifth Avenue, Suite 600, Pittsburgh, PA 15213; <email>danielm@rand.org</email>. His areas of specialization are value-added modeling and program evaluation.</p>
<p>JULIE A. MARSH is an Associate Professor at the University of Southern California Rossier School of Education, 3470 Trousdale Parkway, Waite Phillips Hall, 904B, Los Angeles, CA 90089; <email>julie.marsh@usc.edu</email>. Her areas of specialization are accountability policy and policy implementation.</p>
<p>LAURA S. HAMILTON is a Senior Behavioral Scientist at RAND Corporation, 4570 Fifth Avenue, Suite 600, Pittsburgh, PA 15213; <email>laurah@rand.org</email>. Her areas of specialization are assessment, accountability, and school reform evaluation.</p>
<p>BRAIN M. STECHER is a Senior Behavioral Scientist at RAND Corporation, 1776 Main Street, Santa Monica, CA 90407; <email>stecher@rand.org</email>. His areas of specialization are assessment, accountability, classroom practices, and program evaluation.</p>
<p>MATTHEW G. SPRINGER is an Assistant Professor of Public Policy and Education at the Peabody College of Vanderbilt University, Peabody #43, 230 Appleton Place, Nashville, TN 37203; <email>matthew.g.springer@vanderbilt.edu</email>. His areas of specialization are teacher performance incentives, school choice, and education policy.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0162373712462625">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Adkins</surname><given-names>G. K.</given-names></name>
</person-group> (<year>2004</year>). <source>Teacher performance pay: The perceptions of certified school-based personnel</source> (doctoral dissertation, <publisher-name>University of Central Florida</publisher-name>). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://accountability.leeschools.net/research_projects/pdf/Adkins">http://accountability.leeschools.net/research_projects/pdf/Adkins</ext-link> _Gregory_K_200412_EdD.pdf</citation>
</ref>
<ref id="bibr2-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ballou</surname><given-names>D.</given-names></name>
<name><surname>Podgursky</surname><given-names>M.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Teacher attitudes toward merit pay: Examining conventional wisdom</article-title>. <source>Industrial and Labor Relations Review</source>, <volume>47</volume>, <fpage>50</fpage>–<lpage>61</lpage>.</citation>
</ref>
<ref id="bibr3-0162373712462625">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Barnett</surname><given-names>J. H.</given-names></name>
<name><surname>Ritter</surname><given-names>G. W.</given-names></name>
</person-group> (<year>2008</year>, <month>October</month>). <article-title>When merit pay is worth pursuing</article-title>. <source>Educational Leadership, 66</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.ascd">http://www.ascd</ext-link> .org/publications/educational_leadership</citation>
</ref>
<ref id="bibr4-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Benjamini</surname><given-names>Y.</given-names></name>
<name><surname>Hochberg</surname><given-names>Y.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Controlling the false discovery rate: A practical and powerful approach to multiple testing</article-title>. <source>Journal of the Royal Statistical Society, Series B</source>, <volume>57</volume>, <fpage>289</fpage>–<lpage>300</lpage>.</citation>
</ref>
<ref id="bibr5-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Caro</surname><given-names>D. H.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Socio-economic status and academic achievement trajectories from childhood to adolescence</article-title>. <source>Canadian Journal of Education</source>, <volume>32</volume>, <fpage>558</fpage>–<lpage>590</lpage>.</citation>
</ref>
<ref id="bibr6-0162373712462625">
<citation citation-type="gov">
<collab>Center for Educator Compensation Reform</collab>. (<year>n.d.</year>). <source>List of TIF grants</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://cecr.ed">http://cecr.ed</ext-link> .gov/TIFgrantees/list.cfm</citation>
</ref>
<ref id="bibr7-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clotfelter</surname><given-names>C.</given-names></name>
<name><surname>Glennie</surname><given-names>E.</given-names></name>
<name><surname>Ladd</surname><given-names>H.</given-names></name>
<name><surname>Vigdor</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Would higher salaries keep teachers in high-poverty schools? Evidence from a policy intervention in North Carolina</article-title>. <source>Journal of Public Economics</source>, <volume>92</volume>, <fpage>1352</fpage>–<lpage>1370</lpage>.</citation>
</ref>
<ref id="bibr8-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Collins</surname><given-names>R.</given-names></name>
</person-group> (<year>1994</year>). <source>Four sociological traditions</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</citation>
</ref>
<ref id="bibr9-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Davis-Kean</surname><given-names>P. E.</given-names></name>
<name><surname>Sexton</surname><given-names>H. R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Race differences in parental influences on child achievement: Multiple pathways to success</article-title>. <source>Merrill-Palmer Quarterly: Journal of Developmental Psychology</source>, <volume>55</volume>, <fpage>285</fpage>–<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr10-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Farkas</surname><given-names>S.</given-names></name>
<name><surname>Johnson</surname><given-names>J.</given-names></name>
<name><surname>Duffet</surname><given-names>A.</given-names></name>
<name><surname>Moye</surname><given-names>L.</given-names></name>
<name><surname>Vine</surname><given-names>J.</given-names></name>
</person-group> (<year>2003</year>). <source>Stand by me: What teachers really think about unions, merit pay, and other professional matters</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Public Agenda</publisher-name>.</citation>
</ref>
<ref id="bibr11-0162373712462625">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Ford</surname><given-names>M.</given-names></name>
</person-group> (<year>2012</year>). <source>A modern teacher compensation for Wisconsin</source> (<volume>Vol. 25</volume>, No. <issue>1</issue>). <publisher-loc>Hartland</publisher-loc>: <publisher-name>The Wisconsin Policy Research Institute</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.wpri.org/Reports/Volume25/Vol25No1/Vol25No1.html">http://www.wpri.org/Reports/Volume25/Vol25No1/Vol25No1.html</ext-link></citation>
</ref>
<ref id="bibr12-0162373712462625">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Fryer</surname><given-names>R. G.</given-names></name>
</person-group> (<year>2012</year>). <source>Aligning student, parent, and teacher incentives: Evidence from Houston Public Schools</source> (Working Paper 17752). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>National Bureau of Economic Research</publisher-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.nber.org/papers/w17752">http://www.nber.org/papers/w17752</ext-link></citation>
</ref>
<ref id="bibr13-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Glewwe</surname><given-names>P.</given-names></name>
<name><surname>Ilias</surname><given-names>N.</given-names></name>
<name><surname>Kremer</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Teacher incentives</article-title>. <source>American Economic Journal: Applied Economics</source>, <volume>2</volume>, <fpage>1</fpage>–<lpage>25</lpage>.</citation>
</ref>
<ref id="bibr14-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goldhaber</surname><given-names>D.</given-names></name>
<name><surname>DeArmond</surname><given-names>M.</given-names></name>
<name><surname>DeBurgomaster</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Teacher attitudes about compensation reform: Implications for reform implementation</article-title>. <source>Industrial and Labor Relations Review</source>, <volume>64</volume>, <fpage>441</fpage>–<lpage>463</lpage>.</citation>
</ref>
<ref id="bibr15-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goodman</surname><given-names>S.</given-names></name>
<name><surname>Turner</surname><given-names>L.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Does whole-school performance pay improve student learning? Evidence from the New York City schools</article-title>. <source>Education Next</source>, <volume>11</volume>, <fpage>66</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr16-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Guarino</surname><given-names>C. M.</given-names></name>
<name><surname>Santibanez</surname><given-names>L.</given-names></name>
<name><surname>Daley</surname><given-names>G.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Teacher recruitment and retention: A review of the recent empirical literature</article-title>. <source>Review of Educational Research</source>, <volume>76</volume>, <fpage>173</fpage>–<lpage>208</lpage>.</citation>
</ref>
<ref id="bibr17-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hall</surname><given-names>G. E.</given-names></name>
<name><surname>Caffarella</surname><given-names>E. P.</given-names></name>
</person-group> (<year>1997</year>). <source>Third-year implementation assessment of the Douglas County, Colorado School District Performance Pay Plan for Teachers</source>. <publisher-loc>Castle Rock, CO</publisher-loc>: <publisher-name>Douglas County School District</publisher-name>.</citation>
</ref>
<ref id="bibr18-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heneman</surname><given-names>H. G.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Assessment of the motivational reactions of teachers to a school-based performance award program</article-title>. <source>Journal of Personnel Evaluation in Education</source>, <volume>12</volume>, <fpage>43</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr19-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heneman</surname><given-names>H. G.</given-names></name>
<name><surname>Milanowski</surname><given-names>A. T.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Teachers attitudes about teacher bonuses under school-based performance award programs</article-title>. <source>Journal of Personnel Evaluation in Education</source>, <volume>12</volume>, <fpage>327</fpage>–<lpage>341</lpage>.</citation>
</ref>
<ref id="bibr20-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kelley</surname><given-names>C.</given-names></name>
</person-group> (<year>1999</year>). <article-title>The motivational impact of school-based performance awards</article-title>. <source>Journal of Personnel Evaluation in Education</source>, <volume>12</volume>, <fpage>309</fpage>–<lpage>326</lpage>.</citation>
</ref>
<ref id="bibr21-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kelley</surname><given-names>C.</given-names></name>
<name><surname>Heneman</surname><given-names>H. G.</given-names><suffix>III</suffix></name>
<name><surname>Milanowski</surname><given-names>A.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Teacher motivation and school-based performance awards</article-title>. <source>Educational Administration Quarterly</source>, <volume>38</volume>, <fpage>372</fpage>–<lpage>401</lpage>.</citation>
</ref>
<ref id="bibr22-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kelley</surname><given-names>C.</given-names></name>
<name><surname>Odden</surname><given-names>A.</given-names></name>
<name><surname>Milanowski</surname><given-names>A. T.</given-names></name>
<name><surname>Heneman</surname><given-names>H. G.</given-names></name>
</person-group> (<year>2000</year>). <source>The motivational effects of school-based performance awards</source> (RB-29). <publisher-loc>Philadelphia</publisher-loc>: <publisher-name>Consortium for Policy Research in Education</publisher-name>.</citation>
</ref>
<ref id="bibr23-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Koppich</surname><given-names>J. E.</given-names></name>
<name><surname>Rigby</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <source>Alternative teacher compensation: A primer</source>. <publisher-loc>Berkeley, CA</publisher-loc>: <publisher-name>Policy Analysis for California Education</publisher-name>.</citation>
</ref>
<ref id="bibr24-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Langdon</surname><given-names>C.</given-names></name>
<name><surname>Vesper</surname><given-names>N.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The sixth Phi Delta Kappa poll of teachers’ attitudes toward the public schools</article-title>. <source>Phi Delta Kappan</source>, <volume>81</volume>, <fpage>607</fpage>–<lpage>611</lpage>.</citation>
</ref>
<ref id="bibr25-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lavy</surname><given-names>V.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Performance pay and teachers’ effort, productivity, and grading ethics</article-title>. <source>American Economic Review</source>, <volume>99</volume>, <fpage>1979</fpage>–<lpage>2011</lpage>.</citation>
</ref>
<ref id="bibr26-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Locke</surname><given-names>E. A.</given-names></name>
</person-group> (<year>1968</year>). <article-title>Toward a theory of task motivation and incentives</article-title>. <source>Organizational Behavior and Human Performance</source>, <volume>3</volume>, <fpage>157</fpage>–<lpage>189</lpage>.</citation>
</ref>
<ref id="bibr27-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Long</surname><given-names>J. S.</given-names></name>
<name><surname>Freese</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <source>Regression models for categorical dependent variables using Stata</source> (<edition>2nd ed.</edition>). <publisher-loc>College Station, TX</publisher-loc>: <publisher-name>StataCorp</publisher-name>.</citation>
</ref>
<ref id="bibr28-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Margolis</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>What will keep today’s teachers teaching? Looking for a hook as a new career cycle emerges</article-title>. <source>Teachers College Record</source>, <volume>110</volume>, <fpage>160</fpage>–<lpage>194</lpage>.</citation>
</ref>
<ref id="bibr29-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>J. A.</given-names></name>
<name><surname>Springer</surname><given-names>M. G.</given-names></name>
<name><surname>McCaffrey</surname><given-names>D. F.</given-names></name>
<name><surname>Yuan</surname><given-names>K.</given-names></name>
<name><surname>Epstein</surname><given-names>S.</given-names></name>
<name><surname>Koppich</surname><given-names>J. E.</given-names></name>
<name><surname>Kalra</surname><given-names>N.</given-names></name>
<name><surname>DiMartino</surname><given-names>C.</given-names></name>
<name><surname>Peng</surname><given-names>A.</given-names></name>
</person-group> (<year>2011</year>). <source>A big apple for educators: New York City’s experiment with schoolwide performance bonuses</source>. <publisher-loc>Santa Monica, CA</publisher-loc>: <publisher-name>RAND Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr30-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mehrotra</surname><given-names>A.</given-names></name>
<name><surname>Sorbero</surname><given-names>M. E.</given-names></name>
<name><surname>Damberg</surname><given-names>C. L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Using the lessons of behavioral economics to design more effective pay-for-performance programs</article-title>. <source>American Journal of Managed Care</source>, <volume>16</volume>, <fpage>497</fpage>–<lpage>503</lpage>.</citation>
</ref>
<ref id="bibr31-0162373712462625">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Milanowski</surname><given-names>A.</given-names></name>
</person-group> (<year>2003</year>). <article-title>The varieties of knowledge and skill-based pay design: A comparison of seven new pay systems for K-12 teachers</article-title>. <source>Education Policy Analysis Archives</source>, <volume>11</volume>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://epaa.asu.edu/epaa/v2011n2014/">http://epaa.asu.edu/epaa/v2011n2014/</ext-link></citation>
</ref>
<ref id="bibr32-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Muralidharan</surname><given-names>K.</given-names></name>
<name><surname>Sundararaman</surname><given-names>V.</given-names></name>
</person-group> (<year>2008</year>). <source>Teacher incentives in developing countries: Experimental evidence from India</source> (Working Paper No. 2008-13). <publisher-loc>Nashville, TN</publisher-loc>: <publisher-name>National Center on Performance Incentives at Vanderbilt University</publisher-name>.</citation>
</ref>
<ref id="bibr33-0162373712462625">
<citation citation-type="journal">
No Child Left Behind Act of 2001. 20 U.S.C. 6311 et seq.</citation>
</ref>
<ref id="bibr34-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Podgursky</surname><given-names>M. J.</given-names></name>
<name><surname>Springer</surname><given-names>M. G.</given-names></name>
</person-group> (<year>2006</year>). <source>Teacher performance pay: A review</source>. <publisher-loc>Nashville, TN</publisher-loc>: <publisher-name>National Center on Performance Incentives at Vanderbilt University</publisher-name>.</citation>
</ref>
<ref id="bibr35-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Oliver</surname><given-names>P. E.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Rewards and punishments as selective incentives for collective action: Theoretical investigations</article-title>. <source>American Sociological Review</source>, <volume>85</volume>, <fpage>1356</fpage>–<lpage>1375</lpage>.</citation>
</ref>
<ref id="bibr36-0162373712462625">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Rice</surname><given-names>J. K.</given-names></name>
<name><surname>Jackson</surname><given-names>C.</given-names></name>
<name><surname>Hoyer</surname><given-names>K. M.</given-names></name>
<name><surname>Malen</surname><given-names>B.</given-names></name>
<name><surname>Hyde</surname><given-names>L.</given-names></name>
</person-group> (<year>2011</year>, <month>March</month>). <source>Time to pay up: Distribution patterns and perceived effects of financial awards in a Teacher Incentive Fund (TIF) program</source>. <conf-name>Paper presented at the Annual Meeting of the Association for Education Finance and Policy</conf-name>, <conf-loc>Seattle, Washington</conf-loc>.</citation>
</ref>
<ref id="bibr37-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rivkin</surname><given-names>S. G.</given-names></name>
<name><surname>Hanushek</surname><given-names>E. A.</given-names></name>
<name><surname>Kain</surname><given-names>J. F.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Teachers, schools, and academic achievement</article-title>. <source>Econometrica</source>, <volume>73</volume>, <fpage>417</fpage>–<lpage>458</lpage>.</citation>
</ref>
<ref id="bibr38-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rowan</surname><given-names>B.</given-names></name>
<name><surname>Correnti</surname><given-names>R.</given-names></name>
<name><surname>Miller</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2002</year>). <article-title>What large-scale, survey research tells us about teacher effects on student achievement: Insights from the Prospects study of elementary schools</article-title>. <source>Teacher College Record</source>, <volume>104</volume>, <fpage>1525</fpage>–<lpage>1567</lpage>.</citation>
</ref>
<ref id="bibr39-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rubin</surname><given-names>K. H.</given-names></name>
<name><surname>Bukowski</surname><given-names>W.</given-names></name>
<name><surname>Parker</surname><given-names>J. G.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Peer interactions, relationships, and groups</article-title>. In <person-group person-group-type="editor">
<name><surname>Eisenberg</surname><given-names>N.</given-names></name>
</person-group> (Ed.), <source>Handbook of child psychology: Social, emotional, and personality development</source> (<volume>Vol. 3</volume>, pp. <fpage>571</fpage>–<lpage>645</lpage>). <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr40-0162373712462625">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Schuermann</surname><given-names>P.</given-names></name>
</person-group> (<year>2009</year>). <source>Current status of district and state performance pay initiatives in the U.S</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.learningpt.org/rel/archive/Schuermann_Oct15_162009.pdf">http://www.learningpt.org/rel/archive/Schuermann_Oct15_162009.pdf</ext-link></citation>
</ref>
<ref id="bibr41-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Springer</surname><given-names>M. G.</given-names></name>
<name><surname>Podgursky</surname><given-names>M.</given-names></name>
<name><surname>Lewis</surname><given-names>J. L.</given-names></name>
<name><surname>Ehlert</surname><given-names>M. W.</given-names></name>
<name><surname>Gardner</surname><given-names>C. D.</given-names></name>
<name><surname>Gosh-Dastidar</surname><given-names>B.</given-names></name>
<name><surname>Lopez</surname><given-names>O.</given-names></name>
<name><surname>Patterson</surname><given-names>C. H.</given-names></name>
<name><surname>Taylor</surname><given-names>L. L.</given-names></name>
</person-group> (<year>2007</year>). <source>Governor's Educator Excellence Grant (GEEG) Program: Year one evaluation report</source>. <publisher-loc>Austin, TX</publisher-loc>: <publisher-name>Texas Education Agency</publisher-name>.</citation>
</ref>
<ref id="bibr42-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Springer</surname><given-names>M. G.</given-names></name>
<name><surname>Lewis</surname><given-names>J. L.</given-names></name>
<name><surname>Podgursky</surname><given-names>M.</given-names></name>
<name><surname>Ehlert</surname><given-names>M. W.</given-names></name>
<name><surname>Gronberg</surname><given-names>T. J.</given-names></name>
<name><surname>Hamilton</surname><given-names>L.</given-names></name>
<name><surname>Jansen</surname><given-names>D. W.</given-names></name>
<name><surname>Stecher</surname><given-names>B. M.</given-names></name>
<name><surname>Taylor</surname><given-names>L. L.</given-names></name>
<name><surname>Lopez</surname><given-names>O.</given-names></name>
<name><surname>Peng</surname><given-names>X.</given-names></name>
</person-group> (<year>2009</year>). <source>Texas Educator Excellence Grant (TEEG) Program: Year three evaluation report</source>. <publisher-loc>Austin, TX</publisher-loc>: <publisher-name>Texas Education Agency</publisher-name>.</citation>
</ref>
<ref id="bibr43-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Springer</surname><given-names>M. G.</given-names></name>
<name><surname>Ballou</surname><given-names>D.</given-names></name>
<name><surname>Hamilton</surname><given-names>L.</given-names></name>
<name><surname>Le</surname><given-names>V.</given-names></name>
<name><surname>Lockwood</surname><given-names>J. R.</given-names></name>
<name><surname>McCaffrey</surname><given-names>D. F.</given-names></name>
<name><surname>Pepper</surname><given-names>M.</given-names></name>
<name><surname>Stecher</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <source>Teacher pay for performance: Experimental evidence from the Project on Incentives in Teaching</source>. <publisher-loc>Nashville, TN</publisher-loc>: <publisher-name>National Center on Performance Incentives at Vanderbilt University</publisher-name>.</citation>
</ref>
<ref id="bibr44-0162373712462625">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Springer</surname><given-names>M. G.</given-names></name>
<name><surname>Pane</surname><given-names>J. F.</given-names></name>
<name><surname>Le</surname><given-names>V.</given-names></name>
<name><surname>McCaffrey</surname><given-names>D. F.</given-names></name>
<name><surname>Burns</surname><given-names>S. F.</given-names></name>
<name><surname>Hamilton</surname><given-names>L. S.</given-names></name>
<name><surname>Stecher</surname><given-names>B.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Team pay for performance: Experimental evidence from the Round Rock Pilot Project on Team Incentives</article-title>. <source>Educational Evaluation and Policy Analysis</source>, XX, XXXX–XXXX. doi: <pub-id pub-id-type="doi">10.3102/0162373712439094</pub-id></citation>
</ref>
<ref id="bibr45-0162373712462625">
<citation citation-type="book">
<collab>Teaching Commission</collab>. (<year>2004</year>). <source>Teaching at risk: A call to action</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr46-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vroom</surname><given-names>V. H.</given-names></name>
</person-group> (<year>1964</year>). <source>Work and motivation</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr47-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wiley</surname><given-names>E. W.</given-names></name>
<name><surname>Spindler</surname><given-names>E. R.</given-names></name>
<name><surname>Subert</surname><given-names>A. N.</given-names></name>
</person-group> (<year>2010</year>). <source>Denver ProComp: An outcomes evaluation of Denver’s Alternative Teacher Compensation System</source>. <publisher-loc>Boulder</publisher-loc>: <publisher-name>University of Colorado at Boulder</publisher-name>.</citation>
</ref>
<ref id="bibr48-0162373712462625">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Willer</surname><given-names>R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A status theory of collective action</article-title>. In <person-group person-group-type="editor">
<name><surname>Thye</surname><given-names>S. R.</given-names></name>
<name><surname>Lawler</surname><given-names>E. J.</given-names></name>
</person-group> (Eds.), <source>Advances in group processes</source> (<volume>Vol. 26</volume>, pp. <fpage>133</fpage>–<lpage>163</lpage>). <publisher-loc>London</publisher-loc>: <publisher-name>Emerald</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>