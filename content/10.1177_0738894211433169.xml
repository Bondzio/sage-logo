<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">CMP</journal-id>
<journal-id journal-id-type="hwp">spcmp</journal-id>
<journal-title>Conflict Management and Peace Science</journal-title>
<issn pub-type="ppub">0738-8942</issn>
<issn pub-type="epub">1549-9219</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0738894211433169</article-id>
<article-id pub-id-type="publisher-id">10.1177_0738894211433169</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Phantom Menace of Omitted Variables</article-title>
<subtitle>A Comment<xref ref-type="fn" rid="fn1-0738894211433169">*</xref></subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Vance</surname><given-names>Colin</given-names></name>
</contrib>
<aff id="aff1-0738894211433169">Rheinisch-Westfälisches Institut für Wirtschaftsforschung (RWI) and Jacobs University Bremen</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Ritter</surname><given-names>Nolan</given-names></name>
</contrib>
<aff id="aff2-0738894211433169">Rheinisch-Westfälisches Institut für Wirtschaftsforschung (RWI)</aff>
</contrib-group>
<author-notes>
<fn fn-type="other" id="bio1-0738894211433169">
<p>Colin Vance is a professor of quantitative methods at Jacobs University Bremen and concurrently serves as a senior analyst with RWI, an economics research institute in Essen, Germany. His research focuses on energy and transportation policy, economic development, and global environmental change.</p>
</fn>
<fn fn-type="other" id="bio2-0738894211433169">
<p>Nolan Ritter is a researcher with RWI and is currently completing his dissertation on the economics of household transportation choices. His other research interests include topics in empirical methodology and the analysis of renewable energy policies.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2012</year>
</pub-date>
<volume>29</volume>
<issue>2</issue>
<fpage>233</fpage>
<lpage>238</lpage>
<permissions>
<copyright-statement>© The Author(s). 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Peace Science Society (International)</copyright-holder>
</permissions>
<abstract>
<p>This note demonstrates that in applied regression analysis, the variance of a coefficient of interest may decrease from the inclusion of a control variable, contrasting with Clarke’s assertion (2005, 2009) that the variance can only increase or stay the same. Practitioners may thus be well advised to include a relevant control variable on this basis alone, particularly when it is weakly correlated with the variable of interest.</p>
</abstract>
<kwd-group>
<kwd>control variables</kwd>
<kwd>model specification</kwd>
<kwd>variance</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0738894211433169" sec-type="intro">
<title>Introduction</title>
<p>This note clarifies a point made in two articles appearing in this journal by Clarke (<xref ref-type="bibr" rid="bibr2-0738894211433169">2005</xref>, <xref ref-type="bibr" rid="bibr3-0738894211433169">2009</xref>) that explore the implications of omitted variable bias in regression analysis. Among the issues taken up by Clarke is whether the inclusion of relevant control variables decreases the variance of the coefficient of interest. He states that the quick answer is no, and elaborates:</p>
<disp-quote>
<p>Adding a variable [therefore] can never decrease the variance of the coefficient of interest; the variance can only increase or stay the same. (<xref ref-type="bibr" rid="bibr2-0738894211433169">Clarke, 2005</xref>: 347; <xref ref-type="bibr" rid="bibr3-0738894211433169">Clarke, 2009</xref>: 48)</p>
</disp-quote>
<p>The aim of this note is to demonstrate why, in practice, the estimated variance of a coefficient of interest may well decrease from the inclusion of a control variable; whether this happens depends on the correlation of the included variable and the variable of interest.</p>
</sec>
<sec id="section2-0738894211433169">
<title>Demonstration</title>
<p>Following <xref ref-type="bibr" rid="bibr2-0738894211433169">Clarke’s 2005</xref> article, we assume that the true regression model is:</p>
<p>
<disp-formula id="disp-formula1-0738894211433169">
<label>(1)</label>
<mml:math display="block" id="math1-0738894211433169">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>4</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ϵ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ϵ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0738894211433169" xlink:href="10.1177_0738894211433169-eq1.tif"/>
</disp-formula>
</p>
<p>Clarke then considers two misspecified models, Model 1 and 2, respectively:</p>
<p>
<disp-formula id="disp-formula2-0738894211433169">
<label>(2)</label>
<mml:math display="block" id="math2-0738894211433169">
<mml:mrow>
<mml:mtext>Model</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mn>1</mml:mn>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>11</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>21</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ϵ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ϵ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0738894211433169" xlink:href="10.1177_0738894211433169-eq2.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula3-0738894211433169">
<label>(3)</label>
<mml:math display="block" id="math3-0738894211433169">
<mml:mrow>
<mml:mtext>Model</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mn>2</mml:mn>
<mml:mo>:</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Y</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>12</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>22</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>32</mml:mn>
</mml:mrow>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mi>X</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ϵ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ϵ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:mi>N</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0738894211433169" xlink:href="10.1177_0738894211433169-eq3.tif"/>
</disp-formula>
</p>
<p>and notes that the error variance of the OLS estimate <inline-formula id="inline-formula1-0738894211433169"><mml:math display="inline" id="math4-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> in Model 1 is given by:</p>
<p>
<disp-formula id="disp-formula4-0738894211433169">
<label>(4)</label>
<mml:math display="block" id="math5-0738894211433169">
<mml:mrow>
<mml:mi>Var</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mover>
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>21</mml:mn>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0738894211433169" xlink:href="10.1177_0738894211433169-eq4.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula2-0738894211433169"><mml:math display="inline" id="math6-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The error variance of the OLS estimate <inline-formula id="inline-formula3-0738894211433169"><mml:math display="inline" id="math7-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> in Model 2 is given by:</p>
<p>
<disp-formula id="disp-formula5-0738894211433169">
<label>(5)</label>
<mml:math display="block" id="math8-0738894211433169">
<mml:mrow>
<mml:mi>Var</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mover>
<mml:mi>β</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>22</mml:mn>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>s</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msubsup>
<mml:mrow>
<mml:mi>r</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>23</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0738894211433169" xlink:href="10.1177_0738894211433169-eq5.tif"/>
</disp-formula>
</p>
<p>where <inline-formula id="inline-formula4-0738894211433169"><mml:math display="inline" id="math9-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the correlation coefficient of <inline-formula id="inline-formula5-0738894211433169"><mml:math display="inline" id="math10-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula6-0738894211433169"><mml:math display="inline" id="math11-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Implicitly assuming that <inline-formula id="inline-formula7-0738894211433169"><mml:math display="inline" id="math12-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula8-0738894211433169"><mml:math display="inline" id="math13-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are equal, and recognizing that <inline-formula id="inline-formula9-0738894211433169"><mml:math display="inline" id="math14-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> falls somewhere along the 0 to 1 interval, Clarke concludes that the variance of <inline-formula id="inline-formula10-0738894211433169"><mml:math display="inline" id="math15-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> must necessarily be less than or equal to the variance of <inline-formula id="inline-formula11-0738894211433169"><mml:math display="inline" id="math16-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. This conclusion, however, is predicated upon a strong assumption that is rarely met in practice: <inline-formula id="inline-formula12-0738894211433169"><mml:math display="inline" id="math17-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula13-0738894211433169"><mml:math display="inline" id="math18-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> will only be equal in the special case when <inline-formula id="inline-formula14-0738894211433169"><mml:math display="inline" id="math19-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> adds no explanatory power to the regression in Model 2 (<inline-formula id="inline-formula15-0738894211433169"><mml:math display="inline" id="math20-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, which corresponds to the familiar result that the addition of irrelevant variables to a model unambiguously reduces the efficiency of the estimates.</p>
<p>But consider the difference in the variance estimate between Model 1 and Model 2 when <inline-formula id="inline-formula16-0738894211433169"><mml:math display="inline" id="math21-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is relevant. The formulae for the estimates of the residual variances are:</p>
<p>
<disp-formula id="disp-formula6-0738894211433169">
<label>(6)</label>
<mml:math display="block" id="math22-0738894211433169">
<mml:mrow>
<mml:msubsup>
<mml:mover>
<mml:mi>σ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>1</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∑</mml:mo>
<mml:msubsup>
<mml:mover>
<mml:mi>ε</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mspace width="0.25em"/>
<mml:mtext>and</mml:mtext>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0738894211433169" xlink:href="10.1177_0738894211433169-eq6.tif"/>
</disp-formula>
</p>
<p>
<disp-formula id="disp-formula7-0738894211433169">
<label>(7)</label>
<mml:math display="block" id="math23-0738894211433169">
<mml:mrow>
<mml:msubsup>
<mml:mover>
<mml:mi>σ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mn>2</mml:mn>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mo>∑</mml:mo>
<mml:msubsup>
<mml:mover>
<mml:mi>ε</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
<mml:mo>−</mml:mo>
<mml:mn>3</mml:mn>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0738894211433169" xlink:href="10.1177_0738894211433169-eq7.tif"/>
</disp-formula>
</p>
<p>Further recognizing that <inline-formula id="inline-formula17-0738894211433169"><mml:math display="inline" id="math24-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and that <inline-formula id="inline-formula18-0738894211433169"><mml:math display="inline" id="math25-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, it becomes clear that there is no a priori reason for us to expect that <inline-formula id="inline-formula19-0738894211433169"><mml:math display="inline" id="math26-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula20-0738894211433169"><mml:math display="inline" id="math27-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and, hence, the estimated residual variances, <inline-formula id="inline-formula21-0738894211433169"><mml:math display="inline" id="math28-0738894211433169"><mml:mrow><mml:msubsup><mml:mover><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula22-0738894211433169"><mml:math display="inline" id="math29-0738894211433169"><mml:mrow><mml:msubsup><mml:mover><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, are equal. In fact, if <inline-formula id="inline-formula23-0738894211433169"><mml:math display="inline" id="math30-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a relevant determinant of <italic>Y</italic>, it is quite plausible that <inline-formula id="inline-formula24-0738894211433169"><mml:math display="inline" id="math31-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is greater than <inline-formula id="inline-formula25-0738894211433169"><mml:math display="inline" id="math32-0738894211433169"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> because <inline-formula id="inline-formula26-0738894211433169"><mml:math display="inline" id="math33-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains part of <inline-formula id="inline-formula27-0738894211433169"><mml:math display="inline" id="math34-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bibr7-0738894211433169">Wooldridge, 2003</xref>: 101). Assuming this is the case, the question then turns to the magnitude of <inline-formula id="inline-formula28-0738894211433169"><mml:math display="inline" id="math35-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. If <inline-formula id="inline-formula29-0738894211433169"><mml:math display="inline" id="math36-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is relatively low, then a small drop in <inline-formula id="inline-formula30-0738894211433169"><mml:math display="inline" id="math37-0738894211433169"><mml:mrow><mml:msubsup><mml:mover><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> relative to <inline-formula id="inline-formula31-0738894211433169"><mml:math display="inline" id="math38-0738894211433169"><mml:mrow><mml:msubsup><mml:mover><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> would suffice to make the magnitude of the estimate for <inline-formula id="inline-formula32-0738894211433169"><mml:math display="inline" id="math39-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><italic>less</italic> than that of the estimate for <inline-formula id="inline-formula33-0738894211433169"><mml:math display="inline" id="math40-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, contrasting with Clarke’s theoretical assertion.</p>
<p>Does this occur with any frequency in applied empirical work? Absolutely, which is one reason Angrist and Pischke (<xref ref-type="bibr" rid="bibr1-0738894211433169">2009</xref>: 24) give for including control variables: to reduce the residual variance, thereby lowering the estimated variance (and hence the estimated standard errors) of the regression estimates. Using observed data on food demand, for example, Maddala (<xref ref-type="bibr" rid="bibr6-0738894211433169">2001</xref>: 161) presents a model that demonstrates how the variance may decrease with the inclusion of a control variable. In footnote 4 of his 2009 article, Clarke also acknowledges that the estimated variance is biased when the restriction in Model 1 is false. But he maintains that this bias is rarely large enough to affect his findings.</p>
<p>To illustrate a counterexample, we implement a simple Monte Carlo experiment for which annotated code, written using Stata, is included in the Appendix. Begin by assuming that the true model given by <xref ref-type="disp-formula" rid="disp-formula1-0738894211433169">equation (1)</xref> is the data generation process. Setting the population to 10,000 observations, we randomly draw from a uniform distribution to generate values for <inline-formula id="inline-formula34-0738894211433169"><mml:math display="inline" id="math41-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and do likewise for <inline-formula id="inline-formula35-0738894211433169"><mml:math display="inline" id="math42-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Values for <inline-formula id="inline-formula36-0738894211433169"><mml:math display="inline" id="math43-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are generated by drawing from a uniform distribution and adding to this the product of a scalar <italic>pi</italic> and <inline-formula id="inline-formula37-0738894211433169"><mml:math display="inline" id="math44-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, thereby allowing us to adjust the degree of correlation between <inline-formula id="inline-formula38-0738894211433169"><mml:math display="inline" id="math45-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula39-0738894211433169"><mml:math display="inline" id="math46-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> depending on the magnitude of <italic>pi</italic>. The error term <inline-formula id="inline-formula40-0738894211433169"><mml:math display="inline" id="math47-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is drawn from a normal distribution with a mean of 0 and variance of 1. Inserting these variables into the true model, setting <inline-formula id="inline-formula41-0738894211433169"><mml:math display="inline" id="math48-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, and selecting a value for <italic>pi</italic>, we generate 10,000 values of <inline-formula id="inline-formula42-0738894211433169"><mml:math display="inline" id="math49-0738894211433169"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:math></inline-formula>. The simulation then proceeds by drawing a 75% sample of the generated data and estimating Models 1 and 2. The process is repeated 1,000 times, yielding a distribution of estimates for <inline-formula id="inline-formula43-0738894211433169"><mml:math display="inline" id="math50-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula44-0738894211433169"><mml:math display="inline" id="math51-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, from which estimates of their respective variances can be calculated.</p>
<p>The graph in <xref ref-type="fig" rid="fig1-0738894211433169">Figure 1</xref> plots estimates of <inline-formula id="inline-formula45-0738894211433169"><mml:math display="inline" id="math52-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula46-0738894211433169"><mml:math display="inline" id="math53-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from distinct runs of the simulation, with <inline-formula id="inline-formula47-0738894211433169"><mml:math display="inline" id="math54-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> varying depending on the value of <italic>pi</italic> and hence the correlation between <inline-formula id="inline-formula48-0738894211433169"><mml:math display="inline" id="math55-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="inline-formula49-0738894211433169"><mml:math display="inline" id="math56-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. In this example, when the correlation is lower than −0.27, the inclusion of variable <inline-formula id="inline-formula50-0738894211433169"><mml:math display="inline" id="math57-0738894211433169"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in Model 2 makes the estimated variance of <inline-formula id="inline-formula51-0738894211433169"><mml:math display="inline" id="math58-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> higher than that of <inline-formula id="inline-formula52-0738894211433169"><mml:math display="inline" id="math59-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. When the correlation falls between −0.27 and 0.31, with the corresponding value of <italic>pi</italic> falling between −0.28 and 0.33, the opposite holds: <inline-formula id="inline-formula53-0738894211433169"><mml:math display="inline" id="math60-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, when the correlation is above 0.31, we again have the case in which <inline-formula id="inline-formula54-0738894211433169"><mml:math display="inline" id="math61-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, we see that for some 29% of the range in correlations between 1 and −1, the estimated variance of <inline-formula id="inline-formula55-0738894211433169"><mml:math display="inline" id="math62-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is reduced from the inclusion of the control variable.<sup><xref ref-type="fn" rid="fn2-0738894211433169">1</xref></sup></p>
<fig id="fig1-0738894211433169" position="float">
<label>Figure 1.</label>
<caption>
<p>Monte Carlo Simulations</p>
</caption>
<graphic xlink:href="10.1177_0738894211433169-fig1.tif"/>
</fig>
</sec>
<sec id="section3-0738894211433169" sec-type="conclusions">
<title>Conclusion</title>
<p>One of the key points made in Clarke’s highly insightful analysis is that there is a disconnect between textbook discussions of omitted variable bias and the real world confronted by practitioners. As he persuasively argues, the standard formula for omitted variable bias is of little use when the correct specification of the model is unknown; without this knowledge, the analyst is unable to determine whether adding a control variable or set of controls makes the bias on the coefficient of interest better or worse.</p>
<p>In this note, we suggest that the analyst likewise runs the risk of falling into the void between theory and practice when assessing the effect of the inclusion of a control variable on the variance of the estimate of the coefficient of interest. Clarke argues that this variance can only increase or stay the same. While this result is always true for the special case in which the coefficient on the control variable is zero, our analysis shows that the estimated variance may well decrease in the more realistic case when the control variable explains variation in <inline-formula id="inline-formula56-0738894211433169"><mml:math display="inline" id="math63-0738894211433169"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:math></inline-formula>, which has relevance for the specification of the model. Specifically, if controls are available that are weakly correlated or uncorrelated with the variable of interest, but are relevant determinants of the dependent variable, a circumstance that is not uncommon in natural experiments (e.g. <xref ref-type="bibr" rid="bibr4-0738894211433169">Galiani et al., 2005</xref>; <xref ref-type="bibr" rid="bibr5-0738894211433169">Little et al., 2009</xref>), then their inclusion can serve to increase the precision of the coefficient estimates without imparting bias.</p>
</sec>
</body>
<back>
<app-group>
<app id="app1-0738894211433169">
<title>Appendix</title>
<p>The following presents annotated Stata code, Version 10.0, for implementing the Monte Carlo simulation. Users can change the value of pi, currently set at 0.325, to explore the implications of different degrees of correlation (r23) between x2 and x3.</p>
<p>*** PROGRAMMING OF MONTE-CARLO-ROUTINE STARTS</p>
<p>capture program drop monte /* drops any existing components of program “monte” to assure a clean start */</p>
<p>program monte, rclass /* program monte definition begins */</p>
<p>version 10.0 /* command interpreter set to STATA version 10.0 */</p>
<p>capture drop uniform</p>
<p>gen uniform = uniform() /* the variable “uniform” is drawn from a uniform distribution with values between 0 and 1 */</p>
<p>regress y x2 if uniform &gt; 0.25 /* regresses y on x2 on a subsample where the variable “uniform” is greater than 0.25 */</p>
<p>return scalar beta_21 = _b[x2] /* stores the estimated coefficient of beta_21 */</p>
<p>regress y x2 x3 if uniform &gt; 0.25 /* regresses y on x2 and x3 on the same sample as above */</p>
<p>return scalar beta_22 = _b[x2] /* stores the estimated coefficient of beta_22 */</p>
<p>corr x2 x3 /* calculates the empirical correlation between x2 and x3 */</p>
<p>return scalar correlation = r(rho) /* stores the correlation */</p>
<p>regress y x2 x3 x4 if uniform &gt; 0.25 /* regresses y on x2, x3 and x4 on the same sample as above */</p>
<p>return scalar beta_2 = _b[x2] /* stores the estimated coefficient of beta_2 */</p>
<p>end /* definition of program monte ends */</p>
<p>*** CREATE DATASET</p>
<p>clear</p>
<p>set seed 1111 /* random number generator set to seed 1111 to make sure the dataset is always the same */</p>
<p>set obs 10000 /* sets the number of observations to 10000 */</p>
<p>capture drop beta_1 x2 x3 x4 y</p>
<p>generate beta_1 = 1 /* the intercept takes on the value 1 */</p>
<p>generate double x2 = uniform() /* x2 is drawn from a uniform distribution with values between 0 and 1 */</p>
<p>generate double x3 = uniform() + 0.325 * x2 /* pi is set at 0.325. */</p>
<p>generate double x4 = uniform() /* x4 is drawn from a uniform distribution with values between 0 and 1 */</p>
<p>generate double y = beta_1 + x2 + x3 + x4 + rnormal(0,1) /* build y from generated components assuming slope coefficients of 1 plus a normally distributed error term with expected value 0 and variance 1 */</p>
<p>*** SIMULATION BEGINS</p>
<p>simulate correlation = r(correlation) beta_2 = r(beta_2) beta_21 = r(beta_21) beta_22 = r(beta_22), reps(1000): monte /* runs monte-carlo simulation with 1000 repetitions */</p>
<p>*** LABEL VARIABLES</p>
<p>label var beta_21 “coefficient estimates for beta_21”</p>
<p>label var beta_22 “coefficient estimates for beta_22”</p>
<p>label var beta_2 “coefficient estimates for beta_2 from full model”</p>
<p>*** GET VARIANCE ESTIMATES</p>
<p>sum beta_21, detail /*Compare presented variance estimate with that of beta_22.*/</p>
<p>sum beta_22, detail /*Compare presented variance estimate with that of beta_21.*/</p>
<p>display correlation</p>
<p>/* To generate the data to make the graph presented in the paper, repeat the Monte-Carlo simulation for various values of pi and store the results for the correlation of x2 and x3 (r23) and the variances of the betas along with pi in a separate data set. Additional code to automate this process is available from the authors upon request. */</p>
</app>
</app-group>
<fn-group>
<fn fn-type="other" id="fn1-0738894211433169">
<label>*</label>
<p>We thank Manuel Frondel for his technical and editorial remarks. We are also indebted to Alfredo Payolo, Christoph Schmidt, and Harald Tauchmann for helpful discussions during the drafting of this note. Finally, we wish to express our gratitude to three anonymous reviewers for their insightful comments.</p>
</fn>
<fn fn-type="other" id="fn2-0738894211433169">
<label>1</label>
<p><xref ref-type="bibr" rid="bibr2-0738894211433169">Clarke (2005)</xref> additionally argues that whenever the bias on <inline-formula id="inline-formula57-0738894211433169"><mml:math display="inline" id="math64-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is less than the bias on <inline-formula id="inline-formula58-0738894211433169"><mml:math display="inline" id="math65-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, the mean squared error (MSE) of <inline-formula id="inline-formula59-0738894211433169"><mml:math display="inline" id="math66-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> must be less than the MSE of <inline-formula id="inline-formula60-0738894211433169"><mml:math display="inline" id="math67-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. This assertion can also be contradicted with Monte Carlo simulation: If <inline-formula id="inline-formula61-0738894211433169"><mml:math display="inline" id="math68-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is greater than <inline-formula id="inline-formula62-0738894211433169"><mml:math display="inline" id="math69-0738894211433169"><mml:mrow><mml:mi>Var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, then the MSE of <inline-formula id="inline-formula63-0738894211433169"><mml:math display="inline" id="math70-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> may be greater than the MSE of <inline-formula id="inline-formula64-0738894211433169"><mml:math display="inline" id="math71-0738894211433169"><mml:mrow><mml:msub><mml:mover><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>22</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, even when the bias on the former is greater than the bias on the latter. Demonstration code is available upon request.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0738894211433169">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Angrist</surname><given-names>Joshua</given-names></name>
<name><surname>Pischke</surname><given-names>Jörn-Steffen</given-names></name>
</person-group>. <year>2009</year>. <source>Mostly Harmless Econometrics: An Empiricist’s Companion</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr2-0738894211433169">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clarke</surname><given-names>Kevin A.</given-names></name>
</person-group> <year>2005</year>. <article-title>The phantom menace: Omitted variable bias in econometric research</article-title>. <source>Conflict Management and Peace Science</source> <volume>22</volume>(<issue>4</issue>): <fpage>341</fpage>–<lpage>352</lpage>.</citation>
</ref>
<ref id="bibr3-0738894211433169">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clarke</surname><given-names>Kevin A.</given-names></name>
</person-group> <year>2009</year>. <article-title>Return of the phantom menace: Omitted variable bias in political research</article-title>. <source>Conflict Management and Peace Science</source> <volume>26</volume>(<issue>1</issue>): <fpage>46</fpage>–<lpage>66</lpage>.</citation>
</ref>
<ref id="bibr4-0738894211433169">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Galiani</surname><given-names>Sebastian</given-names></name>
<name><surname>Gertler</surname><given-names>Paul</given-names></name>
<name><surname>Schargrodsky</surname><given-names>Ernesto</given-names></name>
</person-group>. <year>2005</year>. <article-title>Water for life: The impact of the privatization of water services on child mortality</article-title>. <source>Journal of Political Economy</source> <volume>113</volume>: <fpage>83</fpage>–<lpage>120</lpage>.</citation>
</ref>
<ref id="bibr5-0738894211433169">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Little</surname><given-names>Roderick J.</given-names></name>
<name><surname>Long</surname><given-names>Qi</given-names></name>
<name><surname>Lin</surname><given-names>Xihong</given-names></name>
</person-group>. <year>2009</year>. <article-title>A comparison of methods for estimating the causal effect of a treatment in randomized clinical trials subject to noncompliance</article-title>. <source>Biometrics</source> <volume>65</volume>(<issue>June</issue>): <fpage>640</fpage>–<lpage>649</lpage>.</citation>
</ref>
<ref id="bibr6-0738894211433169">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Maddala</surname><given-names>G. S.</given-names></name>
</person-group> <year>2001</year>. <source>Introduction to Econometrics</source>. <edition>3rd edn.</edition> <publisher-loc>Chichester</publisher-loc>: <publisher-name>John Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr7-0738894211433169">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wooldridge</surname><given-names>Jeffrey M.</given-names></name>
</person-group> <year>2003</year>. <source>Introductory Econometrics: A Modern Approach</source>. <edition>2nd edn.</edition> <publisher-loc>Cincinnatti, OH</publisher-loc>: <publisher-name>South-Western College Publishing</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>