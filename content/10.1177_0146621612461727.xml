<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">APM</journal-id>
<journal-id journal-id-type="hwp">spapm</journal-id>
<journal-title>Applied Psychological Measurement</journal-title>
<issn pub-type="ppub">0146-6216</issn>
<issn pub-type="epub">1552-3497</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0146621612461727</article-id>
<article-id pub-id-type="publisher-id">10.1177_0146621612461727</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Influence of Item Calibration Error on Variable-Length Computerized Adaptive Testing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Patton</surname><given-names>Jeffrey M.</given-names></name>
<xref ref-type="aff" rid="aff1-0146621612461727">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Cheng</surname><given-names>Ying</given-names></name>
<xref ref-type="aff" rid="aff1-0146621612461727">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Yuan</surname><given-names>Ke-Hai</given-names></name>
<xref ref-type="aff" rid="aff1-0146621612461727">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Diao</surname><given-names>Qi</given-names></name>
<xref ref-type="aff" rid="aff2-0146621612461727">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0146621612461727"><label>1</label>University of Notre Dame, Notre Dame, IN, USA</aff>
<aff id="aff2-0146621612461727"><label>2</label>CTB/McGraw-Hill, Monterey, CA, USA</aff>
<author-notes>
<corresp id="corresp1-0146621612461727">Jeffrey M. Patton, 209 Haggar Hall, University of Notre Dame, Notre Dame, IN 46556, USA Email: <email>jpatton1@nd.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>37</volume>
<issue>1</issue>
<fpage>24</fpage>
<lpage>40</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Variable-length computerized adaptive testing (VL-CAT) allows both items and test length to be “tailored” to examinees, thereby achieving the measurement goal (e.g., scoring precision or classification) with as few items as possible. Several popular test termination rules depend on the standard error of the ability estimate, which in turn depends on the item parameter values. However, items are chosen on the basis of their parameter estimates, and capitalization on chance may occur. In this article, the authors investigated the effects of capitalization on chance on test length and classification accuracy in several VL-CAT simulations. The results confirm that capitalization on chance occurs in VL-CAT and has complex effects on test length, ability estimation, and classification accuracy. These results have important implications for the design and implementation of VL-CATs.</p>
</abstract>
<kwd-group>
<kwd>variable-length computerized adaptive testing</kwd>
<kwd>test termination</kwd>
<kwd>test length</kwd>
<kwd>classification</kwd>
<kwd>ability estimation</kwd>
<kwd>item calibration</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>The fundamental goal of computerized adaptive testing (CAT) is to match items with examinee ability using an intelligent item selection algorithm. By tailoring the test to the examinee, this procedure yields tests that are more efficient than traditional paper-and-pencil tests. Another layer of test adaptation is possible by using a flexible termination rule that allows the test length to vary across examinees. A test that is adaptive in terms of both item selection and test length is often referred to as a variable-length CAT (VL-CAT). Although many termination rules have been proposed in the literature, the choice of rule depends on the purpose of the test. For example, if the goal is to achieve uniform measurement precision for all examinees, the test may end when the standard error (<italic>SE</italic>) of the ability estimate is sufficiently small (<xref ref-type="bibr" rid="bibr15-0146621612461727">Thissen &amp; Mislevy, 2000</xref>). If instead the goal is to classify examinees, the test may end when the confidence interval (CI) for ability does not include a predetermined cut point (<xref ref-type="bibr" rid="bibr17-0146621612461727">Thompson, 2007</xref>).</p>
<p>In the framework of item response theory (IRT), item selection, ability estimation, and test termination all ultimately depend on the values of the item parameters. However, only estimates of the item parameters are available in practice, and because item selection involves optimization, capitalization on chance may occur. This phenomenon has been demonstrated in the context of fixed-length CAT (<xref ref-type="bibr" rid="bibr11-0146621612461727">Olea, Barrada, Abad, Ponsoda, &amp; Cuevas, 2012</xref>; <xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden &amp; Glas, 2000</xref>). Specifically, adaptive item selection criteria tend to choose items with spuriously large discrimination estimates, which in turn yield spuriously large values of test information and spuriously low <italic>SE</italic>s of ability estimates. Because flexible termination rules often depend on the <italic>SE</italic> of the ability estimate, capitalization on chance may also influence test length and classification accuracy in VL-CAT. Thus, the goal of this study is to examine the effects of capitalization on chance on VL-CAT outcomes.</p>
<p>The rest of the article is organized as follows. First, the authors describe popular termination rules used in VL-CAT. Next, they review literature on the effects of item calibration error on adaptive item selection and ability estimation. Finally, they present the results of a simulation to demonstrate the effects of capitalization on chance on VL-CAT, followed by a discussion of practical implications.</p>
<sec id="section1-0146621612461727">
<title>Termination Rules in VL-CAT</title>
<p>As mentioned previously, several termination rules have been proposed for VL-CAT, but the choice of rule depends on the purpose of the test. To achieve uniform measurement precision for all examinees, a straightforward rule is to end the test when the <italic>SE</italic> of the ability estimate (denoted by <inline-formula id="inline-formula1-0146621612461727">
<mml:math display="inline" id="math1-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>) falls below a predetermined threshold (<xref ref-type="bibr" rid="bibr15-0146621612461727">Thissen &amp; Mislevy, 2000</xref>). Under this conditional standard error (CSE) rule, test length largely depends on the composition of the item pool. If the distribution of item difficulty is uniform, all examinees will have similar test lengths. If the distribution is unimodal, examinees with extreme θ values will tend to have very long tests, whereas examinees near the peak of pool information will tend to have much shorter tests. In the latter case, alternatives such as the minimum information and predicted <italic>SE</italic> reduction rules (<xref ref-type="bibr" rid="bibr4-0146621612461727">Choi, Grady, &amp; Dodd, 2011</xref>) aim to overcome some potential problems. In particular, these rules prevent unnecessarily long tests at extreme θ values where the target <italic>SE</italic> cannot be achieved, and at θ values where the target <italic>SE</italic> can be achieved, the test is allowed to continue if a meaningful reduction in the <italic>SE</italic> is possible. If instead the goal is to accurately classify examinees, the ability confidence interval (ACI) rule ends the test when the (1 − α)% CI for θ falls entirely above or below a predetermined cut point (<xref ref-type="bibr" rid="bibr17-0146621612461727">Thompson, 2007</xref>). In contrast with the CSE rule, test length depends primarily on the distance of the true θ value from the cut point. Examinees near the cut are difficult to classify and thus tend to have very long tests, whereas examinees farther from the cut tend to have very short tests.</p>
<p>Regardless of the purpose of testing, each of these termination rules depends on the <italic>SE</italic> of the ability estimate. An important question is whether capitalization on chance might affect <italic>SE</italic>s, and whether the <italic>SE</italic>s might influence VL-CAT outcomes, such as test length and classification accuracy. To explore this question, the authors next discuss adaptive item selection and the problem of capitalization on chance.</p>
</sec>
<sec id="section2-0146621612461727">
<title>Item Selection and Capitalization on Chance</title>
<p>Central to the goal of CAT is an item selection criterion that matches examinee ability with a function of the item parameters. Perhaps the most popular criterion is to maximize Fisher information at the current ability estimate. If the probability of a correct response is modeled by the two-parameter logistic model (2PLM),</p>
<p>
<disp-formula id="disp-formula1-0146621612461727">
<mml:math display="block" id="math2-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>θ</mml:mi>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>b</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>θ</mml:mi>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>b</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0146621612461727" xlink:href="10.1177_0146621612461727-eq1.tif"/>
</disp-formula></p>
<p>where <italic>a<sub>j</sub></italic> and <italic>b<sub>j</sub></italic> are item discrimination and difficulty, respectively, Fisher information is computed by</p>
<p>
<disp-formula id="disp-formula2-0146621612461727">
<mml:math display="block" id="math3-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mi>I</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mi>a</mml:mi>
<mml:mi>j</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0146621612461727" xlink:href="10.1177_0146621612461727-eq2.tif"/>
</disp-formula></p>
<p>When |<italic>b<sub>j</sub></italic> − θ| is small, <italic>I<sub>j</sub></italic> is increasing in <italic>a<sub>j</sub></italic> for the range of <italic>a<sub>j</sub></italic>values encountered in practice. So, if there are many items located near θ, this criterion tends to prefer items with the largest discrimination values. Under the three-parameter logistic model (3PLM),</p>
<p>
<disp-formula id="disp-formula3-0146621612461727">
<mml:math display="block" id="math4-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>θ</mml:mi>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>b</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:mtext>exp</mml:mtext>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mi>θ</mml:mi>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>b</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0146621612461727" xlink:href="10.1177_0146621612461727-eq3.tif"/>
</disp-formula></p>
<p>where <italic>c<sub>j</sub></italic> is the pseudo-guessing parameter, Fisher information is computed by</p>
<p>
<disp-formula id="disp-formula4-0146621612461727">
<mml:math display="block" id="math5-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mi>I</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msubsup>
<mml:mi>a</mml:mi>
<mml:mi>j</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mrow>
<mml:mo>[</mml:mo>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo>/</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>c</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
<mml:mrow>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mo>]</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>P</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0146621612461727" xlink:href="10.1177_0146621612461727-eq4.tif"/>
</disp-formula></p>
<p>Unlike the 2PLM, information under the 3PLM is no longer maximized at θ = <italic>b<sub>j</sub></italic>. However, information is still increasing in <italic>a<sub>j</sub></italic> (for the range of <italic>a<sub>j</sub></italic> values encountered in practice) for a fixed value of <italic>c<sub>j</sub></italic> when <italic>b<sub>j</sub></italic> is close to θ, and therefore also tends to prefer items with the largest discrimination values (<xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden &amp; Glas, 2000</xref>).</p>
<p>However, the true item parameter values are unknown in practice, so items are chosen on the basis of their parameter estimates, and capitalization on chance may occur. Specifically, the largest <italic>a</italic> estimates in an item pool tend to be spuriously large: the sum of large true <italic>a</italic> values and large, positive calibration errors (<xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden &amp; Glas, 2000</xref>). Because Fisher information is largely determined by the value of item discrimination, the maximum value of information evaluated with respect to item parameter estimates tends to be larger than that evaluated with respect to the true parameter values (<xref ref-type="bibr" rid="bibr6-0146621612461727">Hambleton &amp; Jones, 1994</xref>; <xref ref-type="bibr" rid="bibr7-0146621612461727">Hambleton, Jones, &amp; Rogers, 1993</xref>). This problem of capitalization on chance is exacerbated when item calibration errors tend to be large, for example, when the ratio of calibration sample size to the number of model parameters is small (<xref ref-type="bibr" rid="bibr6-0146621612461727">Hambleton &amp; Jones, 1994</xref>). The problem also depends on the ratio of test length to the conditional size of the item pool; when there are fewer items to choose from, it is less likely to systematically choose those items with spuriously large discrimination estimates (<xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden &amp; Glas, 2000</xref>). In addition to its effect on Fisher information, capitalization on chance has important practical effects on ability estimation, which the authors discuss in the following section.</p>
</sec>
<sec id="section3-0146621612461727">
<title>Calibration Error and Latent Trait Estimation</title>
<p>In treatments of ability estimation, it is customary to assume that the item parameter values are known (e.g., <xref ref-type="bibr" rid="bibr1-0146621612461727">Baker &amp; Kim, 2004</xref>; <xref ref-type="bibr" rid="bibr10-0146621612461727">Lord, 1983</xref>). Under this assumption, the <italic>SE</italic> of <inline-formula id="inline-formula2-0146621612461727">
<mml:math display="inline" id="math6-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> reflects only measurement error in ability estimation. In practice, however, scoring is conducted with respect to item parameter estimates; if this additional source of error is ignored, <italic>SE</italic>(<inline-formula id="inline-formula3-0146621612461727">
<mml:math display="inline" id="math7-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>) will be underestimated to some degree (<xref ref-type="bibr" rid="bibr18-0146621612461727">Tsutakawa &amp; Johnson, 1990</xref>). For example, assuming known item parameters, the asymptotic <italic>SE</italic> of the maximum likelihood (ML) ability estimate is approximated by <italic>I</italic><sup>−1/2</sup>, the inverse square root of test information. But if the item parameter values are unknown, the upward-corrected <italic>SE</italic> is given by</p>
<p>
<disp-formula id="disp-formula5-0146621612461727">
<mml:math display="block" id="math8-0146621612461727">
<mml:mrow>
<mml:mi>S</mml:mi>
<mml:mi>E</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:msqrt>
<mml:mrow>
<mml:msup>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:mo>+</mml:mo>
<mml:mstyle>
<mml:msup>
<mml:mi mathvariant="bold">v</mml:mi>
<mml:mo>′</mml:mo>
</mml:msup>
</mml:mstyle>
<mml:mo>∑</mml:mo>
<mml:mstyle>
<mml:mi mathvariant="bold">v</mml:mi>
</mml:mstyle>
<mml:msup>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:msqrt>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0146621612461727" xlink:href="10.1177_0146621612461727-eq5.tif"/>
</disp-formula></p>
<p>which incorporates an additional term that depends on Σ, the asymptotic covariance matrix of item parameter estimates, and <bold>v</bold>, a vector of partial derivatives that reflects how the likelihood of θ varies with respect to both θ and the item parameters (<xref ref-type="bibr" rid="bibr3-0146621612461727">Cheng &amp; Yuan, 2010</xref>; <xref ref-type="bibr" rid="bibr8-0146621612461727">Hoshino &amp; Shigemasu, 2008</xref>). If the item parameters are known, Σ = 0 and the <italic>SE</italic> only depends on test information. But if the item parameters are unknown, Σ ≠ 0 and the corrected <italic>SE</italic> will be larger than that based on test information alone. In general, the size of the correction will be large when the elements in Σ are large, for example, when the calibration sample is small.</p>
<p>In the context of CAT with unknown item parameters, estimation of <italic>SE</italic>(<inline-formula id="inline-formula4-0146621612461727">
<mml:math display="inline" id="math9-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>) is no longer so straightforward. First, the corrected <italic>SE</italic> in <xref ref-type="disp-formula" rid="disp-formula5-0146621612461727">Equation 5</xref> may not be readily implemented in CAT because Σ is difficult to come by. Estimation of Σ is straightforward when a single sample is used to calibrate all items. But in CAT, different sets of items are administered to different samples, and the items are then placed on a common scale through linking. Second, as discussed in the previous section, the item selection criterion tends to capitalize on spuriously large <italic>a</italic> estimates, which yield spuriously large values of test information. Accordingly, the <italic>SE</italic> of <inline-formula id="inline-formula5-0146621612461727">
<mml:math display="inline" id="math10-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> based on test information may be spuriously low.</p>
<p>Capitalization on chance also has implications for the bias of <inline-formula id="inline-formula6-0146621612461727">
<mml:math display="inline" id="math11-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. Simulation studies (e.g., <xref ref-type="bibr" rid="bibr22-0146621612461727">Wang &amp; Vispoel, 1998</xref>) as well as the asymptotic bias formula due to <xref ref-type="bibr" rid="bibr10-0146621612461727">Lord (1983)</xref> indicate that when the item parameters are known and the item pool contains sufficient numbers of items at each ability level, <inline-formula id="inline-formula7-0146621612461727">
<mml:math display="inline" id="math12-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> will be close to unbiased. However, <xref ref-type="bibr" rid="bibr23-0146621612461727">Zhang, Xie, Song, and Lu (2011)</xref> showed that in linear testing, the asymptotic bias of <inline-formula id="inline-formula8-0146621612461727">
<mml:math display="inline" id="math13-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> depends on the covariance matrix and biases of item parameter estimates. In adaptive testing, <xref ref-type="bibr" rid="bibr5-0146621612461727">Doebler (2012)</xref> demonstrated that, when the distribution of true item difficulty is unimodal and only difficulty estimates are available, capitalization on systematically over- or underestimated difficulty estimates can cause large, systematic bias in <inline-formula id="inline-formula9-0146621612461727">
<mml:math display="inline" id="math14-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, even when the difficulty estimates are themselves unbiased.</p>
</sec>
<sec id="section4-0146621612461727">
<title>Purpose of the Study</title>
<p>To our knowledge, two studies have examined the effects of capitalization on chance in fixed-length CAT (viz., <xref ref-type="bibr" rid="bibr11-0146621612461727">Olea et al., 2012</xref>; <xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden &amp; Glas, 2000</xref>). However, the situation becomes more complicated when a variable-length termination rule is used. For example, if the CSE rule is used and the <italic>SE</italic> of <inline-formula id="inline-formula10-0146621612461727">
<mml:math display="inline" id="math15-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is underestimated due to capitalization on chance, the test may end prematurely. Furthermore, the combined effects of estimating ability with item parameter estimates and prematurely ending the test may negatively affect ability recovery, and if the goal of testing is classification, classification accuracy may also suffer.</p>
<p>Thus, the goal of this study is to examine the effects of capitalization on chance on θ recovery, test length, and classification accuracy in simulated VL-CAT scenarios. In particular, the CSE and ACI rules are used because of their simplicity and popularity. To examine the effects of different magnitudes of item calibration error, the authors manipulated the size of the calibration sample, and because the degree of capitalization on chance also depends on model complexity, they also conducted simulations with the 2PLM or 3PLM as the true model.</p>
</sec>
<sec id="section5-0146621612461727" sec-type="methods">
<title>Method</title>
<p>Pools of “true” 2PLM and 3PLM parameters for 400 items were obtained from a retired item pool of a large-scale achievement test. Each pool was calibrated using sample sizes of 2,500, 1,000, or 500, yielding three sets of item parameter estimates that differ with respect to the average magnitude of calibration errors. Each calibrated pool was then “administered” to a future scoring sample in two VL-CAT scenarios that differed with respect to the termination rule (CSE or ACI). To mimic reality, item selection and examinee scoring were conducted with respect to item parameter estimates, whereas responses were generated using the true parameters of the corresponding items. The authors also included a baseline condition in which the true item parameters were used for item selection, response generation, and examinee scoring. This corresponds to the hypothetical situation in which the calibration sample size is infinite (i.e., <italic>N</italic> = ∞), and the item parameter values are known exactly.</p>
<sec id="section6-0146621612461727">
<title>Construction of Item Pools</title>
<p>To create the pools of true item parameters, 400 items were sampled without replacement from a retired pool of 540 items previously calibrated with the 3PLM. These items comprised the 3PLM pool, and the 2PLM pool was created by setting the <italic>c</italic> parameters to zero. Note that because the 2PLM pool was created in this way, the authors changed not only the model but also the pool information function. Thus, results from the two pools are not directly comparable. Descriptive statistics of the parameter values are shown in <xref ref-type="table" rid="table1-0146621612461727">Table 1</xref>, and histograms of the parameters are shown in <xref ref-type="fig" rid="fig1-0146621612461727">Figure 1</xref>. The distribution of item difficulty is roughly symmetric with a mean of 0.17, and the distributions of discrimination and pseudo-guessing parameters have a slight positive skew. Discrimination and difficulty exhibit a medium positive correlation (<italic>r<sub>a.b</sub></italic> = .48), whereas discrimination and difficulty each exhibit a small negative correlation with the guessing parameter (<italic>r<sub>a,c</sub></italic> = −.15 and <italic>r<sub>b,c</sub></italic> = −.18, respectively).</p>
<table-wrap id="table1-0146621612461727" position="float">
<label>Table 1.</label>
<caption>
<p>Descriptive Statistics of True Item Parameter Values</p>
</caption>
<graphic alternate-form-of="table1-0146621612461727" xlink:href="10.1177_0146621612461727-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="center"><italic>M</italic></th>
<th align="center"><italic>SD</italic></th>
<th align="center">Skewness</th>
</tr>
</thead>
<tbody>
<tr>
<td><italic>a</italic></td>
<td>1.02</td>
<td>0.32</td>
<td>0.44</td>
</tr>
<tr>
<td><italic>b</italic></td>
<td>0.17</td>
<td>1.00</td>
<td>−0.26</td>
</tr>
<tr>
<td><italic>c</italic></td>
<td>0.19</td>
<td>0.08</td>
<td>0.70</td>
</tr>
</tbody>
</table>
</table-wrap>
<fig id="fig1-0146621612461727" position="float">
<label>Figure 1.</label>
<caption>
<p>Histograms of true item parameter values</p>
</caption>
<graphic xlink:href="10.1177_0146621612461727-fig1.tif"/>
</fig>
<p>Next, each pool was calibrated with sample sizes of <italic>N</italic> = 2,500, 1,000, or 500. Rather than generate response data and estimate the item parameters, parameter estimates for a given item were drawn from their asymptotic normal sampling distribution, a method used in similar investigations (<xref ref-type="bibr" rid="bibr13-0146621612461727">Spray &amp; Reckase, 1987</xref>; <xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden &amp; Glas, 2000</xref>). This was done to avoid convergence problems during item calibration, which would almost surely occur during the calibration of 400 items with only 500 examinees. First, the authors computed the asymptotic covariance matrix Σ of ML item parameter estimates assuming a standard normal distribution of ability (see <xref ref-type="bibr" rid="bibr16-0146621612461727">Thissen &amp; Wainer, 1982</xref>). This method does not require observed data and uses Fisher information so that Σ is block diagonal with all inter-item covariances equal to zero. Second, to simulate the calibration of a given item, a random sample was drawn from a two- or three-variate normal distribution with mean vector <bold>0</bold> and covariance matrix from the appropriate 2 × 2 or 3 × 3 block in Σ. These “errors” were then added to the true parameter values. Finally, to avoid dependence of the simulation results on a particular set of parameter estimates, 25 sets of estimates were generated for each value of <italic>N</italic>. <xref ref-type="table" rid="table2-0146621612461727">Table 2</xref> displays the mean squared error (MSE) of item parameter estimates for each combination of parameter and sample size. As expected, smaller values of <italic>N</italic> yielded larger calibration errors and thus larger MSEs, regardless of model. In addition, recovery of the <italic>a</italic> and <italic>b</italic> parameters was noticeably worse for the 3PLM than for the 2PLM; it is well known that estimation of the <italic>c</italic> parameter has a detrimental effect on estimation of the other parameters (see <xref ref-type="bibr" rid="bibr16-0146621612461727">Thissen &amp; Wainer, 1982</xref>).</p>
<table-wrap id="table2-0146621612461727" position="float">
<label>Table 2.</label>
<caption>
<p>Item Parameter Recovery (MSE)</p>
</caption>
<graphic alternate-form-of="table2-0146621612461727" xlink:href="10.1177_0146621612461727-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="2">2PLM parameters<hr/></th>
<th align="center" colspan="3">3PLM parameters<sup><xref ref-type="table-fn" rid="table-fn2-0146621612461727">a</xref></sup><hr/></th>
</tr>
<tr>
<th align="left"><italic>N</italic></th>
<th align="center"><italic>a</italic></th>
<th align="center"><italic>b</italic></th>
<th align="center"><italic>a</italic></th>
<th align="center"><italic>b</italic></th>
<th align="center"><italic>c</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>2,500</td>
<td>0.003</td>
<td>0.006</td>
<td>0.022</td>
<td>0.552</td>
<td>0.010</td>
</tr>
<tr>
<td>1,000</td>
<td>0.009</td>
<td>0.016</td>
<td>0.056</td>
<td>1.290</td>
<td>0.016</td>
</tr>
<tr>
<td>500</td>
<td>0.018</td>
<td>0.031</td>
<td>0.109</td>
<td>2.605</td>
<td>0.022</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0146621612461727">
<p>Note: MSE = mean squared error; 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model.</p>
</fn>
<fn id="table-fn2-0146621612461727">
<label>a</label>
<p>The MSE of 3PLM parameter estimates is based on 399 of the 400 items; the easiest item in the pool exhibited very poor recovery.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section7-0146621612461727">
<title>VL-CAT Scenarios</title>
<p>Regardless of termination rule, the purpose of each VL-CAT simulation was to score examinees and classify them as passing or failing. (Although the main purpose of the CSE rule is to obtain accurate ability estimates, the authors also classified examinees to obtain a measure of the practical consequences of calibration error on ability estimation.) For accurate classifications, it is desirable for the peak of information in the item pool to be located near the cut point. On inspection of the plots of information in the 2PLM and 3PLM pools (evaluated with respect to the true parameters), the cut was chosen to be at θ = 0.5. However, they also conducted simulations with the cut located at θ = 1.5; this corresponds to a situation in which the goal is to identify high-ability examinees. Regardless of cut location, the classification decision was made by comparing the final ability estimate with the cut point.</p>
<p>For all simulations, ML was used to estimate ability. An initial ability estimate was obtained as follows: The item pool was ordered with respect to estimated difficulty; the 20 easiest items, 20 most difficult items, and 20 “middle” items were identified; and 1 item was randomly selected for administration from each group. For those examinees who responded incorrectly or correctly to all 3 items, the next item was chosen to maximize Fisher information at θ = −4 or 4, respectively, until a finite <inline-formula id="inline-formula11-0146621612461727">
<mml:math display="inline" id="math16-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> could be obtained. Thereafter, items were selected to maximize information at the current <inline-formula id="inline-formula12-0146621612461727">
<mml:math display="inline" id="math17-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>. Once a minimum of 15 items were administered, testing continued until the test termination rule was satisfied or a maximum of 40 items were administered.</p>
<p>Under the CSE rule, the <italic>SE</italic> of <inline-formula id="inline-formula13-0146621612461727">
<mml:math display="inline" id="math18-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mtext>ML</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> based on test information (i.e., treating the item parameter estimates as the true values) was compared with a threshold; if the <italic>SE</italic> fell below the threshold, the test ended. For all conditions, a threshold of .316 was used. Assuming the <italic>SE</italic> of <inline-formula id="inline-formula14-0146621612461727">
<mml:math display="inline" id="math19-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> does not depend on the true θ (which is the goal of the CSE rule), the authors use the formula for the classical <italic>SE</italic> of measurement</p>
<p>
<disp-formula id="disp-formula6-0146621612461727">
<mml:math display="block" id="math20-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mi>σ</mml:mi>
<mml:mi>e</mml:mi>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>σ</mml:mi>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:msub>
<mml:msqrt>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>ρ</mml:mi>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>,</mml:mo>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:msqrt>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0146621612461727" xlink:href="10.1177_0146621612461727-eq6.tif"/>
</disp-formula></p>
<p>to show that σ<sub><italic>e</italic></sub> = .316 corresponds to a reliability coefficient (<inline-formula id="inline-formula15-0146621612461727">
<mml:math display="inline" id="math21-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mo>,</mml:mo>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>) of .90 when the variance of <inline-formula id="inline-formula16-0146621612461727">
<mml:math display="inline" id="math22-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> in a sample of test takers (<inline-formula id="inline-formula17-0146621612461727">
<mml:math display="inline" id="math23-0146621612461727">
<mml:mrow>
<mml:msubsup>
<mml:mrow>
<mml:mi>σ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>) is equal to 1 (<xref ref-type="bibr" rid="bibr14-0146621612461727">Thissen, 2000</xref>). Under the ACI rule, the 95% asymptotic CI for θ was compared with the cut (θ<sub>0</sub>). The interval was based on the information-based <italic>SE</italic> and critical value from the standard normal density. If the CI fell entirely above or below θ<sub>0</sub>, the examinee was classified as passing or failing, respectively.</p>
<p>Together, this resulted in four fully crossed factors: IRT model (2PLM or 3PLM), termination rule (CSE or ACI), cut location (θ<sub>0</sub> = 0.5 or 1.5), and calibration sample size (<italic>N</italic> = ∞, 2,500, 1,000, or 500).</p>
</sec>
<sec id="section8-0146621612461727">
<title>Dependent Measures</title>
<p>The scoring sample consisted of 500 examinees at each θ value from −2 to 2 in increments of 0.25. Each of the 25 calibrated pools was administered to a separate scoring sample, and the dependent measures were averaged across the 25 replications. In this way, the outcomes at each θ value reflect two sources of error: random responses to items (i.e., measurement error) and capitalization on calibration error via item selection. To measure the degree to which capitalization on chance occurred, the authors computed relative test efficiency. First, they define test efficiency as the average information per item administered, computed as follows for variable-length tests (<xref ref-type="bibr" rid="bibr9-0146621612461727">Huo, 2009</xref>):</p>
<p>
<disp-formula id="disp-formula7-0146621612461727">
<mml:math display="block" id="math24-0146621612461727">
<mml:mrow>
<mml:mtext>Test efficieny</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msubsup>
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mstyle>
<mml:mover accent="true">
<mml:mi mathvariant="bold">γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msubsup>
<mml:mrow>
<mml:msub>
<mml:mi>L</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0146621612461727" xlink:href="10.1177_0146621612461727-eq7.tif"/>
</disp-formula></p>
<p>where <inline-formula id="inline-formula18-0146621612461727">
<mml:math display="inline" id="math25-0146621612461727">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mrow>
<mml:mi>i</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is the final ability estimate for examinee <italic>i</italic>, θ<sub><italic>i</italic></sub> is the vector of item parameter estimates for those items administered to examinee <italic>i, L<sub>i</sub></italic> is the test length, <italic>I</italic>(·) is the test information function, and <italic>n</italic> = 500 is the number of examinees at a given true value of θ. Due to capitalization on chance, information based on parameter estimates will generally be larger than that based on the corresponding true parameter values. Thus, the authors also evaluated <xref ref-type="disp-formula" rid="disp-formula7-0146621612461727">Equation 7</xref> with respect to θ<sub><italic>i</italic></sub>, the vector of true parameter values for those items administered to examinee <italic>i</italic>. They then took the ratio of estimated to “true” test efficiency, resulting in the following expression:</p>
<p>
<disp-formula id="disp-formula8-0146621612461727">
<mml:math display="block" id="math26-0146621612461727">
<mml:mrow>
<mml:mtext>Relative test efficiency</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msubsup>
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mstyle>
<mml:mover accent="true">
<mml:mi mathvariant="bold">γ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mstyle>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
<mml:mrow>
<mml:mstyle displaystyle="true">
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mi>n</mml:mi>
</mml:msubsup>
<mml:mrow>
<mml:mi>I</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mrow>
<mml:msub>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mstyle>
<mml:mi mathvariant="bold">γ</mml:mi>
</mml:mstyle>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mstyle>
</mml:mrow>
</mml:mfrac>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-0146621612461727" xlink:href="10.1177_0146621612461727-eq8.tif"/>
</disp-formula></p>
<p>The authors expect this ratio to be greater than one and to increase as the calibration sample size <italic>N</italic> decreases.</p>
<p>To evaluate ability recovery, the authors computed the bias and standard deviation of ability estimates at each true θ value. To evaluate the effect of capitalization on chance on test outcomes, they also computed the average test length and percentage of accurately classified examinees at each θ value. Finally, all data generation, simulations, and analyses were performed in R (<xref ref-type="bibr" rid="bibr12-0146621612461727">R Core Team, 2012</xref>) with codes written by the first author.</p>
</sec>
</sec>
<sec id="section9-0146621612461727" sec-type="results">
<title>Results</title>
<sec id="section10-0146621612461727">
<title>Capitalization on Chance</title>
<p>First, the authors wanted to determine whether the maximum information criterion capitalized on item calibration error. For those simulations using the CSE termination rule, the top row of <xref ref-type="fig" rid="fig2-0146621612461727">Figure 2</xref> displays plots of relative efficiency for each combination of IRT model and calibration sample size. (Although not shown, these plots look very similar under the ACI rule.) In all conditions, relative efficiency is greater than one, demonstrating that when items were chosen on the basis of their parameter estimates, test information evaluated with respect to item parameter estimates is (on average) greater than that evaluated with respect to the true parameter values. Moreover, the discrepancy between estimated and true test efficiency increases as <italic>N</italic> decreases, which reflects that the smaller calibration samples yielded larger calibration errors. As expected, values of estimated test efficiency are spuriously high due to capitalization on spuriously high discrimination estimates, but this is not always the case. Under the 3PLM, examinees with θ &lt; −1 were administered items with underestimated difficulty. This occurred because there are few very easy items in the pools (see <xref ref-type="fig" rid="fig1-0146621612461727">Figure 1</xref>), but after calibration, low-ability examinees were supplied additional items with difficulty estimates containing negative calibration errors.</p>
<fig id="fig2-0146621612461727" position="float">
<label>Figure 2.</label>
<caption>
<p>Test efficiency (CSE termination rule)</p>
<p>Note: 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model; CSE = conditional standard error.</p>
</caption>
<graphic xlink:href="10.1177_0146621612461727-fig2.tif"/>
</fig>
<p>Next, the authors wanted to compare estimated test efficiency across the different sample sizes; these results are shown in the bottom row of <xref ref-type="fig" rid="fig2-0146621612461727">Figure 2</xref>. (Note that there is no distinction between “estimated” and true efficiency in the baseline condition.) Regardless of <italic>N</italic>, estimated efficiency is greater for positive θ values because this is where the most discriminating items are located (recall that the true <italic>a</italic> and <italic>b</italic> values are positively correlated). At a given value of θ, estimated efficiency tends to increase as <italic>N</italic> decreases; this means that the items chosen in the <italic>N</italic> = 500 condition, for example, appear to be more informative than the items chosen in the baseline condition. This implies, in turn, that the <italic>SE</italic>s of ability estimates in the <italic>N</italic> = 500 condition are spuriously small.</p>
</sec>
<sec id="section11-0146621612461727">
<title>CSE Termination Rule</title>
<p>When the CSE termination rule is used, what are the implications of capitalization on chance for test length? The top row of <xref ref-type="fig" rid="fig3-0146621612461727">Figure 3</xref> displays the average test length for each combination of IRT model and calibration sample size. As expected, spuriously low <italic>SE</italic>s under small <italic>N</italic> caused the test to end prematurely, and consistent with the plots of estimated test efficiency (see the bottom row of <xref ref-type="fig" rid="fig2-0146621612461727">Figure 2</xref>), the effect of <italic>N</italic> on test length is proportional to the degree of capitalization on chance. This is apparent in the bottom row of <xref ref-type="fig" rid="fig3-0146621612461727">Figure 3</xref>, which displays the difference in average test length relative to the baseline condition (e.g., test length for <italic>N</italic> = 500 minus test length for <italic>N</italic> = ∞). Under the 2PLM, the effect of <italic>N</italic> is relatively uniform across the range of ability. In contrast, the effect of <italic>N</italic> under the 3PLM is quite large for θ &gt; 0 but negligible for θ &lt; 0.</p>
<fig id="fig3-0146621612461727" position="float">
<label>Figure 3.</label>
<caption>
<p>Average test length (CSE termination rule)</p>
<p>Note: 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model; CSE = conditional standard error.</p>
</caption>
<graphic xlink:href="10.1177_0146621612461727-fig3.tif"/>
</fig>
<p>Next, the authors examined the effect of capitalization on chance on ability recovery. The top row of <xref ref-type="fig" rid="fig4-0146621612461727">Figure 4</xref> displays bias under each IRT model, and the bottom row displays the empirical <italic>SE</italic> (i.e., the standard deviation of ability estimates). As expected, ability estimates in the baseline condition are close to unbiased, regardless of model. But as <italic>N</italic> decreases, the magnitude of bias tends to increase. Concerning the empirical <italic>SE</italic>s, the effect of <italic>N</italic> under the 2PLM is negligible, and under the 3PLM, the empirical <italic>SE</italic> increases as <italic>N</italic> decreases. These results are at odds with the information-based <italic>SE</italic>s, which suggest that ability estimates under small <italic>N</italic> are more accurate than those under large <italic>N</italic>. But in reality, ability estimates under small <italic>N</italic> are equally or even less accurate than those under large <italic>N</italic>.</p>
<fig id="fig4-0146621612461727" position="float">
<label>Figure 4.</label>
<caption>
<p>Ability recovery (CSE termination rule)</p>
<p>Note: 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model; <italic>SE</italic> = standard error; CSE = conditional standard error.</p>
</caption>
<graphic xlink:href="10.1177_0146621612461727-fig4.tif"/>
</fig>
<p>Finally, the authors were interested in the effect of capitalization on chance on classification accuracy. For those conditions with θ<sub>0</sub> = 0.5, the left half of <xref ref-type="table" rid="table3-0146621612461727">Table 3</xref> displays percentages of correctly classified examinees. Because nearly all examinees with θ values far from the cut were correctly classified, <xref ref-type="table" rid="table3-0146621612461727">Table 3</xref> focuses on a smaller range of θ values about the cut. Regardless of IRT model, the effect of <italic>N</italic> is quite small. Because the classification decision is made by comparing the final ability estimate with the cut, these results can be explained in terms of ability recovery. Specifically, the effect of <italic>N</italic> on the bias and empirical <italic>SE</italic> of <inline-formula id="inline-formula19-0146621612461727">
<mml:math display="inline" id="math27-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is quite small near the cut for each model (see <xref ref-type="fig" rid="fig4-0146621612461727">Figure 4</xref>), and thus, the percentage of correctly classified examinees is quite similar for each value of <italic>N</italic>. However, test termination under the CSE rule is independent of the cut location, so classification accuracy may suffer under small <italic>N</italic> if the cut was located at a more extreme θ value. Indeed this is the case; the right half of <xref ref-type="table" rid="table3-0146621612461727">Table 3</xref> displays classification accuracy results for θ<sub>0</sub> = 1.5. Now the effect of <italic>N</italic> is much larger. But interestingly, classifications are less accurate for small <italic>N</italic> above the cut but more accurate for small <italic>N</italic> below it. Again, this can be explained in terms of ability recovery. At θ = 1.5, <inline-formula id="inline-formula20-0146621612461727">
<mml:math display="inline" id="math28-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is negatively biased for small values of <italic>N</italic> under each model, whereas <inline-formula id="inline-formula21-0146621612461727">
<mml:math display="inline" id="math29-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is close to unbiased in the baseline condition. Accordingly, examinees above the cut in the small <italic>N</italic> conditions are misclassified as failing more often than are examinees in the baseline condition. Conversely, examinees below the cut in the small-<italic>N</italic> conditions are correctly classified as failing more often than are examinees in the baseline condition.</p>
<table-wrap id="table3-0146621612461727" position="float">
<label>Table 3.</label>
<caption>
<p>Percentages of Correctly Classified Examinees (CSE termination rule)</p>
</caption>
<graphic alternate-form-of="table3-0146621612461727" xlink:href="10.1177_0146621612461727-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="5">Cut = 0.5 θθ level<hr/></th>
<th align="center" colspan="5">Cut = 1.5 θθ level<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center"><italic>N</italic></th>
<th align="center">0.00</th>
<th align="center">0.25</th>
<th align="center">0.50</th>
<th align="center">0.75</th>
<th align="center">1.00</th>
<th align="center">1.00</th>
<th align="center">1.25</th>
<th align="center">1.50</th>
<th align="center">1.75</th>
<th align="center">2.00</th>
</tr>
</thead>
<tbody>
<tr>
<td>2PLM</td>
<td>∞</td>
<td>94.0</td>
<td>78.2</td>
<td>50.1</td>
<td>78.6</td>
<td>94.2</td>
<td>94.2</td>
<td>79.0</td>
<td>50.1</td>
<td>77.8</td>
<td>93.8</td>
</tr>
<tr>
<td/>
<td>2,500</td>
<td>94.2</td>
<td>77.8</td>
<td>50.2</td>
<td>78.1</td>
<td>94.3</td>
<td>94.9</td>
<td>80.2</td>
<td>47.6</td>
<td>75.6</td>
<td>92.8</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>93.7</td>
<td>77.9</td>
<td>49.7</td>
<td>77.6</td>
<td>93.0</td>
<td>94.9</td>
<td>80.8</td>
<td>45.0</td>
<td>75.0</td>
<td>91.6</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>92.8</td>
<td>78.7</td>
<td>48.0</td>
<td>75.6</td>
<td>91.3</td>
<td>95.3</td>
<td>82.6</td>
<td>40.5</td>
<td>68.8</td>
<td>88.6</td>
</tr>
<tr>
<td/>
<td>Difference<sup><xref ref-type="table-fn" rid="table-fn4-0146621612461727">a</xref></sup></td>
<td>−1.1</td>
<td>0.5</td>
<td>−2.0</td>
<td>−3.0</td>
<td>−2.8</td>
<td>1.1</td>
<td>3.6</td>
<td>−9.6</td>
<td>−9.0</td>
<td>−5.1</td>
</tr>
<tr>
<td>3PLM</td>
<td>∞</td>
<td>93.6</td>
<td>76.5</td>
<td>51.2</td>
<td>79.1</td>
<td>94.8</td>
<td>93.7</td>
<td>78.3</td>
<td>50.2</td>
<td>78.5</td>
<td>94.6</td>
</tr>
<tr>
<td/>
<td>2,500</td>
<td>92.7</td>
<td>76.7</td>
<td>51.5</td>
<td>79.1</td>
<td>95.0</td>
<td>93.6</td>
<td>78.9</td>
<td>46.9</td>
<td>75.6</td>
<td>93.0</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>92.0</td>
<td>74.7</td>
<td>52.4</td>
<td>79.3</td>
<td>94.4</td>
<td>93.1</td>
<td>79.9</td>
<td>45.3</td>
<td>71.7</td>
<td>89.4</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>91.5</td>
<td>75.9</td>
<td>49.8</td>
<td>77.2</td>
<td>92.2</td>
<td>93.1</td>
<td>81.7</td>
<td>39.3</td>
<td>64.9</td>
<td>84.9</td>
</tr>
<tr>
<td/>
<td>Difference</td>
<td>−2.1</td>
<td>−0.5</td>
<td>−1.4</td>
<td>−1.9</td>
<td>−2.6</td>
<td>−0.6</td>
<td>3.4</td>
<td>−10.8</td>
<td>−13.6</td>
<td>−9.6</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0146621612461727">
<p>Note: CSE = conditional standard error; 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model.</p>
</fn>
<fn id="table-fn4-0146621612461727">
<label>a</label>
<p>Difference is computed by subtracting <italic>N</italic> = ∞ results from <italic>N</italic> = 500 results.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section12-0146621612461727">
<title>ACI Termination Rule</title>
<p>Under the ACI termination rule, the effect of capitalization on chance on test length exhibits a different trend. For θ<sub>0</sub> = 0.5, the top row of <xref ref-type="fig" rid="fig5-0146621612461727">Figure 5</xref> displays the average test length for each combination of IRT model and calibration sample size, and the bottom row displays the difference in average test length, relative to the baseline condition. In contrast with the CSE rule, test length depends on the cut location; accordingly, tests are quite long near the cut but much shorter at extreme θ values. Moreover, the effect of <italic>N</italic> at a given θ value is quite small. This result was unexpected; the authors know that when <italic>N</italic> is small, the <italic>SE</italic> of <inline-formula id="inline-formula22-0146621612461727">
<mml:math display="inline" id="math30-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> tends to be underestimated, and thus, the CI for θ tends to be too narrow. The reason that tests did not end prematurely under small <italic>N</italic> is because the CI also depends on the point estimate of ability. This variability in the location of the interval apparently guarded test length from capitalization on chance.</p>
<fig id="fig5-0146621612461727" position="float">
<label>Figure 5.</label>
<caption>
<p>Average test length (ACI termination rule, θ<sub>0</sub> = 0.5)</p>
<p>Note: 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model; ACI = ability confidence interval.</p>
</caption>
<graphic xlink:href="10.1177_0146621612461727-fig5.tif"/>
</fig>
<p>Next, <xref ref-type="fig" rid="fig6-0146621612461727">Figure 6</xref> displays ability recovery results for θ<sub>0</sub> = 0.5; the top row displays bias under each IRT model, and the bottom row displays the empirical <italic>SE</italic>. Similar to the CSE results, the effect of <italic>N</italic> on the empirical <italic>SE</italic> is negligible under the 2PLM, whereas under the 3PLM, the empirical <italic>SE</italic> is inversely related to <italic>N</italic>. For all values of <italic>N</italic>, <inline-formula id="inline-formula23-0146621612461727">
<mml:math display="inline" id="math31-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> exhibits a strong “outward” bias in the vicinity of the cut, even though these examinees tend to have very long tests. The reason is that <inline-formula id="inline-formula24-0146621612461727">
<mml:math display="inline" id="math32-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is quite variable early in the test, and at any point when the CI does not include the cut, the test will end. In other words, the ACI rule capitalizes on variability in <inline-formula id="inline-formula25-0146621612461727">
<mml:math display="inline" id="math33-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> early in the test. So among those examinees with true θ values near the cut, a few of these examinees have both short tests and final ability estimates with a strong outward bias.</p>
<fig id="fig6-0146621612461727" position="float">
<label>Figure 6.</label>
<caption>
<p>Ability recovery (ACI termination rule, θ<sub>0</sub> = 0.5)</p>
<p>Note: 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model; <italic>SE</italic> = standard error; ACI = ability confidence interval.</p>
</caption>
<graphic xlink:href="10.1177_0146621612461727-fig6.tif"/>
</fig>
<p>Finally, the left half of <xref ref-type="table" rid="table4-0146621612461727">Table 4</xref> displays percentages of correctly classified examinees when θ<sub>0</sub> = 0.5. Similar to the CSE results, the effect of <italic>N</italic> is quite small, regardless of IRT model. Again, this is because the effect of <italic>N</italic> on the bias and empirical <italic>SE</italic> of <inline-formula id="inline-formula26-0146621612461727">
<mml:math display="inline" id="math34-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> is also small near the cut. What happens when the cut is located at θ = 1.5? Under the ACI rule, test length and ability recovery depend on the cut location. Compared with the conditions with θ<sub>0</sub> = 0.5, the effect of <italic>N</italic> on test length when θ<sub>0</sub> = 1.5 is similarly small, but the effect of <italic>N</italic> on the bias of <inline-formula id="inline-formula27-0146621612461727">
<mml:math display="inline" id="math35-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> near the cut is somewhat larger. Specifically, <inline-formula id="inline-formula28-0146621612461727">
<mml:math display="inline" id="math36-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> under small <italic>N</italic> is more negatively biased than in the baseline condition. The result is a much larger effect on classification accuracy; these results are shown in the right half of <xref ref-type="table" rid="table4-0146621612461727">Table 4</xref>. In particular, accuracy suffers under small <italic>N</italic> for examinees above the cut, whereas accuracy is slightly improved under small <italic>N</italic> below the cut.</p>
<table-wrap id="table4-0146621612461727" position="float">
<label>Table 4.</label>
<caption>
<p>Percentages of Correctly Classified Examinees (ACI termination rule)</p>
</caption>
<graphic alternate-form-of="table4-0146621612461727" xlink:href="10.1177_0146621612461727-table4.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="5">Cut = 0.5 θ level<hr/></th>
<th align="center" colspan="5">Cut = 1.5 θ level<hr/></th>
</tr>
<tr>
<th align="left">Model</th>
<th align="center"><italic>N</italic></th>
<th align="center">0.00</th>
<th align="center">0.25</th>
<th align="center">0.50</th>
<th align="center">0.75</th>
<th align="center">1.00</th>
<th align="center">1.00</th>
<th align="center">1.25</th>
<th align="center">1.50</th>
<th align="center">1.75</th>
<th align="center">2.00</th>
</tr>
</thead>
<tbody>
<tr>
<td>2PLM</td>
<td>∞</td>
<td>98.7</td>
<td>86.6</td>
<td>49.6</td>
<td>86.5</td>
<td>98.7</td>
<td>98.9</td>
<td>87.8</td>
<td>49.8</td>
<td>87.1</td>
<td>98.8</td>
</tr>
<tr>
<td/>
<td>2,500</td>
<td>98.7</td>
<td>86.9</td>
<td>48.9</td>
<td>86.7</td>
<td>98.8</td>
<td>99.0</td>
<td>88.3</td>
<td>48.0</td>
<td>85.6</td>
<td>98.3</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>98.9</td>
<td>86.8</td>
<td>48.6</td>
<td>85.8</td>
<td>98.6</td>
<td>99.2</td>
<td>89.0</td>
<td>45.0</td>
<td>84.6</td>
<td>97.9</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>98.4</td>
<td>87.3</td>
<td>47.2</td>
<td>84.2</td>
<td>98.0</td>
<td>99.3</td>
<td>91.2</td>
<td>40.1</td>
<td>80.4</td>
<td>97.3</td>
</tr>
<tr>
<td/>
<td>Difference<sup><xref ref-type="table-fn" rid="table-fn6-0146621612461727">a</xref></sup></td>
<td>−0.2</td>
<td>0.7</td>
<td>−2.4</td>
<td>−2.3</td>
<td>−0.7</td>
<td>0.4</td>
<td>3.4</td>
<td>−9.7</td>
<td>−6.8</td>
<td>−1.5</td>
</tr>
<tr>
<td>3PLM</td>
<td>∞</td>
<td>96.2</td>
<td>81.2</td>
<td>51.2</td>
<td>83.4</td>
<td>97.5</td>
<td>96.8</td>
<td>82.6</td>
<td>51.0</td>
<td>84.1</td>
<td>97.6</td>
</tr>
<tr>
<td/>
<td>2,500</td>
<td>95.6</td>
<td>81.2</td>
<td>50.6</td>
<td>83.2</td>
<td>97.6</td>
<td>97.0</td>
<td>84.2</td>
<td>47.3</td>
<td>81.3</td>
<td>96.7</td>
</tr>
<tr>
<td/>
<td>1,000</td>
<td>95.1</td>
<td>80.5</td>
<td>51.3</td>
<td>83.9</td>
<td>96.9</td>
<td>97.3</td>
<td>85.3</td>
<td>43.7</td>
<td>78.4</td>
<td>95.1</td>
</tr>
<tr>
<td/>
<td>500</td>
<td>94.8</td>
<td>80.5</td>
<td>49.1</td>
<td>81.5</td>
<td>95.9</td>
<td>97.2</td>
<td>87.5</td>
<td>39.2</td>
<td>72.9</td>
<td>93.0</td>
</tr>
<tr>
<td/>
<td>Difference</td>
<td>−1.4</td>
<td>−0.7</td>
<td>−2.1</td>
<td>−1.9</td>
<td>−1.5</td>
<td>0.3</td>
<td>4.9</td>
<td>−11.8</td>
<td>−11.2</td>
<td>−4.7</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn5-0146621612461727">
<p>Note: ACI = ability confidence interval; 2PLM = two-parameter logistic model; 3PLM = three-parameter logistic model.</p>
</fn>
<fn id="table-fn6-0146621612461727">
<label>a</label>
<p>Difference is computed by subtracting <italic>N</italic> = ∞ results from <italic>N</italic> = 500 results.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="section13-0146621612461727" sec-type="discussion">
<title>Discussion</title>
<p>The goal of this study was to examine the effects of capitalization on item calibration error in VL-CAT. Consistent with previous research on fixed-length CAT, the authors found that the maximum information criterion capitalized on item calibration error, yielding spuriously high values of test information, particularly when the calibration sample was small. Unsurprisingly, this resulted in spuriously short tests when the <italic>SE</italic> of the ability estimate was used as the test termination criterion. Relative to when the item parameters were known, the average reduction in test length was as much as three items. In contrast, using the 95% CI for θ as the termination criterion appeared to safeguard against spuriously short tests, particularly when the cut was located at θ = 0.5, where the test information function peaks. Although small calibration samples yielded spuriously narrow CIs, variability in the location of the intervals prevented tests from ending prematurely. Regardless of termination rule, the effect of calibration sample size on classification accuracy was quite small when the cut was located at θ = 0.5. This occurred because the empirical bias and variance of ability estimates for examinees near the cut were similar for all values of <italic>N</italic>. However, classification accuracy under small <italic>N</italic> was reduced by as much as 10% relative to the baseline condition when a more extreme cut point was used (i.e., θ<sub>0</sub> = 1.5). This larger effect was primarily due to the effect of <italic>N</italic> on the bias of ability estimates.</p>
<p>Although the authors have demonstrated the potential effects of capitalization on chance, they have not addressed ways to reduce its effects. One option is to use cross-validation to produce two sets of item parameter estimates. In this method, items are selected with respect to one set of estimates, and the other set is used for ability and <italic>SE</italic> estimation. <xref ref-type="bibr" rid="bibr20-0146621612461727">van der Linden and Glas (2001)</xref> found that this method effectively reduced the effects of capitalization on chance, though they note that this solution may not be ideal when the calibration sample is already small (e.g., 250 examinees or less). Also by imposing constraints on item selection, such as content constraints and exposure control, which are already implemented by many operational testing programs, the effect of capitalization on chance may be reduced. The reason is that these constraints reduce the dependence of item selection on purely statistical criteria. For example, <xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden and Glas (2000)</xref> demonstrated that implementing Sympson–Hetter exposure control in fixed-length CAT decreased the effects of capitalization on chance relative to when no exposure control was used.</p>
<p>It should be emphasized that the results are particular to the simulated conditions. The effects of capitalization on chance on VL-CAT outcomes depend on many factors that vary widely among operational testing programs. First, maximum Fisher information is but one of many possible item selection criteria (see <xref ref-type="bibr" rid="bibr21-0146621612461727">van der Linden &amp; Pashley, 2010</xref>). However, some research has suggested that different criteria, though conceptually different, tend to select very similar sets of items (e.g., <xref ref-type="bibr" rid="bibr2-0146621612461727">Chen, Ankenmann, &amp; Chang, 2000</xref>). Furthermore, <xref ref-type="bibr" rid="bibr19-0146621612461727">van der Linden and Glas (2000)</xref> demonstrated that the effects of capitalization on chance in fixed-length CAT were very similar for several different item selection criteria. Second, there are a number of variable-length termination rules that the authors did not implement. Two attractive alternatives are the minimum information and predicted <italic>SE</italic> reduction rules (<xref ref-type="bibr" rid="bibr4-0146621612461727">Choi et al., 2011</xref>). Whether or not a target <italic>SE</italic> for <inline-formula id="inline-formula29-0146621612461727">
<mml:math display="inline" id="math37-0146621612461727">
<mml:mrow>
<mml:mover>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mo>^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> has been met, these rules allow the test to end if no sufficiently informative items are available or continue if a meaningful decrease in the <italic>SE</italic> can be achieved. Because item calibration tends to increase the number of (apparently) highly informative items at a given θ value, use of these rules may actually increase test lengths relative to when the true item parameter values are known. Third, the effects of capitalization on chance depend heavily on the properties of the item pool, including the IRT model used for calibration and the joint distribution of item parameters.</p>
<p>In summary, the authors have demonstrated that capitalization on chance via item selection can have practically important consequences on VL-CAT outcomes. Specifically, if the <italic>SE</italic> of the ability estimate is used as the stopping criterion, the test may end prematurely when calibration errors are large. Although the goal of uniform measurement precision is a worthy one, this procedure may result in spuriously short tests and ability estimates that are less accurate than their <italic>SE</italic>s suggest. The current results also suggest that capitalization on chance may have large effects on classification accuracy when the cut point is located at an extreme θ value, regardless of the termination rule. An extreme cut point may be used to, for example, identify the highest or lowest performing examinees in a sample. Making classification decisions at a point where items are scarce is problematic when the item parameters are known. When only item parameter estimates are available, the accuracy of these classifications may suffer even more.</p>
</sec>
</body>
<back>
<ack>
<p>The authors would like to thank CTB/McGraw-Hill for supporting this research, as well as two anonymous reviewers for their insightful comments.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This research was supported by a 2010 CTB/McGraw-Hill Innovation Research and Development grant.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0146621612461727">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Baker</surname><given-names>F. B.</given-names></name>
<name><surname>Kim</surname><given-names>S.-H.</given-names></name>
</person-group> (<year>2004</year>). <source>Item response theory: Parameter estimation techniques</source> (<edition>2nd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Marcel Dekker</publisher-name>.</citation>
</ref>
<ref id="bibr2-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chen</surname><given-names>S.-Y.</given-names></name>
<name><surname>Ankenmann</surname><given-names>R. D.</given-names></name>
<name><surname>Chang</surname><given-names>H.-H.</given-names></name>
</person-group> (<year>2000</year>). <article-title>A comparison of item selection rules at the early stages of computerized adaptive testing</article-title>. <source>Applied Psychological Measurement</source>, <volume>24</volume>, <fpage>241</fpage>-<lpage>255</lpage>.</citation>
</ref>
<ref id="bibr3-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>Y.</given-names></name>
<name><surname>Yuan</surname><given-names>K.-H.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The impact of fallible item parameter estimates on latent trait recovery</article-title>. <source>Psychometrika</source>, <volume>75</volume>, <fpage>280</fpage>-<lpage>291</lpage>.</citation>
</ref>
<ref id="bibr4-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Choi</surname><given-names>S. W.</given-names></name>
<name><surname>Grady</surname><given-names>M. W.</given-names></name>
<name><surname>Dodd</surname><given-names>B. G.</given-names></name>
</person-group> (<year>2011</year>). <article-title>A new stopping rule for computerized adaptive testing</article-title>. <source>Educational and Psychological Measurement</source>, <volume>71</volume>, <fpage>37</fpage>-<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr5-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Doebler</surname><given-names>A.</given-names></name>
</person-group> (<year>2012</year>). <article-title>The problem of bias in person parameter estimation in adaptive testing</article-title>. <source>Applied Psychological Measurement</source>, <volume>36</volume>, <fpage>255</fpage>-<lpage>270</lpage>.</citation>
</ref>
<ref id="bibr6-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hambleton</surname><given-names>R. K.</given-names></name>
<name><surname>Jones</surname><given-names>R. W.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Item parameter estimation errors and their influence on test information functions</article-title>. <source>Applied Measurement in Education</source>, <volume>7</volume>, <fpage>171</fpage>-<lpage>186</lpage>.</citation>
</ref>
<ref id="bibr7-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hambleton</surname><given-names>R. K.</given-names></name>
<name><surname>Jones</surname><given-names>R. W.</given-names></name>
<name><surname>Rogers</surname><given-names>H. J.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Influence of item parameter estimation errors in test development</article-title>. <source>Journal of Educational Measurement</source>, <volume>30</volume>, <fpage>143</fpage>-<lpage>155</lpage>.</citation>
</ref>
<ref id="bibr8-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hoshino</surname><given-names>T.</given-names></name>
<name><surname>Shigemasu</surname><given-names>K.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Standard errors of estimated latent variable scores with estimated structural parameters</article-title>. <source>Applied Psychological Measurement</source>, <volume>32</volume>, <fpage>181</fpage>-<lpage>189</lpage>.</citation>
</ref>
<ref id="bibr9-0146621612461727">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Huo</surname><given-names>Y.</given-names></name>
</person-group> (<year>2009</year>). <source>Variable-length computerized adaptive testing: Adaptation of the a-stratified strategy in item selection with content balancing</source> (Unpublished doctoral dissertation). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://hdl.handle.net/2142/14715">http://hdl.handle.net/2142/14715</ext-link></citation>
</ref>
<ref id="bibr10-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lord</surname><given-names>F. M.</given-names></name>
</person-group> (<year>1983</year>). <article-title>Unbiased estimators of ability parameters, of their variance, and of their parallel-forms reliability</article-title>. <source>Psychometrika</source>, <volume>48</volume>, <fpage>233</fpage>-<lpage>245</lpage>.</citation>
</ref>
<ref id="bibr11-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Olea</surname><given-names>J.</given-names></name>
<name><surname>Barrada</surname><given-names>J. R.</given-names></name>
<name><surname>Abad</surname><given-names>F. J.</given-names></name>
<name><surname>Ponsoda</surname><given-names>V.</given-names></name>
<name><surname>Cuevas</surname><given-names>L.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Computerized adaptive testing: The capitalization on chance problem</article-title>. <source>Spanish Journal of Psychology</source>, <volume>15</volume>, <fpage>424</fpage>-<lpage>441</lpage>.</citation>
</ref>
<ref id="bibr12-0146621612461727">
<citation citation-type="web">
<collab>R Core Team</collab> (<year>2012</year>). <article-title>R: A language and environment for statistical computing (Version 2.13.2) [Computer software]</article-title>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing. Available</publisher-name> from <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org">http://www.R-project.org</ext-link></citation>
</ref>
<ref id="bibr13-0146621612461727">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Spray</surname><given-names>J. A.</given-names></name>
<name><surname>Reckase</surname><given-names>M. D.</given-names></name>
</person-group> (<year>1987</year>). <source>The effect of item parameter estimation error on decisions made using the sequential probability ratio test</source> (Research Report ONR 87-1). <publisher-loc>Iowa City, IA</publisher-loc>: <publisher-name>ACT</publisher-name>.</citation>
</ref>
<ref id="bibr14-0146621612461727">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thissen</surname><given-names>D.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Reliability and measurement precision</article-title>. In <person-group person-group-type="editor">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
</person-group> (Ed.), <source>Computerized adaptive testing: A primer</source> (pp. <fpage>159</fpage>-<lpage>184</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr15-0146621612461727">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thissen</surname><given-names>D.</given-names></name>
<name><surname>Mislevy</surname><given-names>R. J.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Testing algorithms</article-title>. In <person-group person-group-type="editor">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
</person-group> (Ed.), <source>Computerized adaptive testing: A primer</source> (pp. <fpage>101</fpage>-<lpage>133</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr16-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Thissen</surname><given-names>D.</given-names></name>
<name><surname>Wainer</surname><given-names>H.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Some standard errors in item response theory</article-title>. <source>Psychometrika</source>, <volume>47</volume>, <fpage>397</fpage>-<lpage>412</lpage>.</citation>
</ref>
<ref id="bibr17-0146621612461727">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Thompson</surname><given-names>N. A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A practitioner’s guide for variable-length computerized classification testing</article-title>. <source>Practical Assessment, Research, &amp; Evaluation</source>, <volume>12</volume>. Available from <ext-link ext-link-type="uri" xlink:href="http://pareonline.net">pareonline.net</ext-link></citation>
</ref>
<ref id="bibr18-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tsutakawa</surname><given-names>R. K.</given-names></name>
<name><surname>Johnson</surname><given-names>J. C.</given-names></name>
</person-group> (<year>1990</year>). <article-title>The effect of uncertainty of item parameter estimation on ability estimates</article-title>. <source>Psychometrika</source>, <volume>55</volume>, <fpage>371</fpage>-<lpage>390</lpage>.</citation>
</ref>
<ref id="bibr19-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van der Linden</surname><given-names>W. J.</given-names></name>
<name><surname>Glas</surname><given-names>C. A. W.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Capitalization on item calibration error in adaptive testing</article-title>. <source>Applied Measurement in Education</source>, <volume>13</volume>, <fpage>35</fpage>-<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr20-0146621612461727">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>van der Linden</surname><given-names>W. J.</given-names></name>
<name><surname>Glas</surname><given-names>C. A. W.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Cross-validating item parameter estimation in adaptive testing</article-title>. In <person-group person-group-type="editor">
<name><surname>Boomsma</surname><given-names>A.</given-names></name>
<name><surname>van Duijn</surname><given-names>M. A. J.</given-names></name>
<name><surname>Snijders</surname><given-names>T. A. B.</given-names></name>
</person-group> (Eds.), <source>Essays on item response theory</source> (pp. <fpage>205</fpage>-<lpage>219</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr21-0146621612461727">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>van der Linden</surname><given-names>W. J.</given-names></name>
<name><surname>Pashley</surname><given-names>P. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Item selection and ability estimation in adaptive testing</article-title>. In. <person-group person-group-type="editor">
<name><surname>van der Linden</surname><given-names>W. J.</given-names></name>
<name><surname>Glas</surname><given-names>C. A. W.</given-names></name>
</person-group> (Eds.), <source>Elements of adaptive testing</source> (pp. <fpage>3</fpage>-<lpage>30</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr22-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wang</surname><given-names>T.</given-names></name>
<name><surname>Vispoel</surname><given-names>W. P.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Properties of ability estimation methods in computerized adaptive testing</article-title>. <source>Journal of Educational Measurement</source>, <volume>35</volume>, <fpage>109</fpage>-<lpage>135</lpage>.</citation>
</ref>
<ref id="bibr23-0146621612461727">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>J.</given-names></name>
<name><surname>Xie</surname><given-names>M.</given-names></name>
<name><surname>Song</surname><given-names>X.</given-names></name>
<name><surname>Lu</surname><given-names>T.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Investigating the impact of uncertainty about item parameters on ability estimation</article-title>. <source>Psychometrika</source>, <volume>76</volume>, <fpage>97</fpage>-<lpage>118</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>