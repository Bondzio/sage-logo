<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">HPC</journal-id>
<journal-id journal-id-type="hwp">sphpc</journal-id>
<journal-title>The International Journal of High Performance Computing Applications</journal-title>
<issn pub-type="ppub">1094-3420</issn>
<issn pub-type="epub">1741-2846</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1094342011434814</article-id>
<article-id pub-id-type="publisher-id">10.1177_1094342011434814</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Characterization and transformation of unstructured control flow in bulk synchronous GPU applications</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Wu</surname>
<given-names>Haicheng</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011434814"/>
<xref ref-type="corresp" rid="corresp1-1094342011434814"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Diamos</surname>
<given-names>Gregory</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011434814"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Jin</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011434814"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Si</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011434814"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yalamanchili</surname>
<given-names>Sudhakar</given-names>
</name>
<xref ref-type="aff" rid="aff1-1094342011434814"/>
</contrib>
</contrib-group>
<aff id="aff1-1094342011434814">School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA</aff>
<author-notes>
<corresp id="corresp1-1094342011434814">Haicheng Wu, School of Electrical and Computer Engineering, Georgia Institute of Technology, 266 Ferst Drive, KACB 2316 Atlanta, GA 30332-0765, USA Email: <email>hwu36@gatech.edu</email>
</corresp>
<fn fn-type="other" id="fn1-1094342011434814">
<p>
<italic>Haicheng Wu</italic> is a PhD student in the Computer Architecture and Systems Lab at the Georgia Institute of Technology, under the direction of Professor Sudhakar Yalamanchili. He received his BS in Electrical Engineering from Shanghai Jiao Tong University in 2006 and his MS in Electrical and Computer Engineering from the Georgia Institute of Technology in 2009. He used to focus on the dynamic thread management in the mainframe computers. Currently, he is moving and extending his prior research results to the heterogeneous architectures.</p>
</fn>
<fn fn-type="other" id="fn2-1094342011434814">
<p>
<italic>Gregory Diamos</italic> is a PhD student in the Computer Architecture and Systems Lab at the Georgia Institute of Technology, under the direction of Professor Sudhakar Yalamanchili. He received his BS and MS in Electrical Engineering from the Georgia Institute of Technology in 2006 and 2008, respectively, where he focused on architecture techniques for controlling PVT variations. His current research interests follow the industry shift from ILP to many core architectures, where mounting communication requirements place increasing demands on on-chip interconnection and the ability to tightly integrate heterogeneous architectures offers the potential for dramatic improvements in efficiency at the cost of increased design complexity; his research is directed toward maintaining this efficiency while reducing design complexity.</p>
</fn>
<fn fn-type="other" id="fn3-1094342011434814">
<p>
<italic>Jin Wang</italic> is pursuing her PhD under the direction of Professor Sudhaka Yalamanchili in Georgia Institute of Technology. She received her BS in Electrical Engineering from Shanghai Jiao Tong University in 2007 and her MS in Electrical and Computer Engineering from the Georgia Institute of Technology in 2010. Her research interests are simulator and compiler support for heterogeneous computer architecture.</p>
</fn>
<fn fn-type="other" id="fn4-1094342011434814">
<p>
<italic>Si Li</italic> is a PhD student at Georgia Institute of Technology working in the area of computer architecture. His research interests involve the impact of on-chip interconnect on the unique memory demand and cache systems in the massively parallel environment of general purpose GPU architecture. His other interests include power and performance in the domain of computer architecture.</p>
</fn>
<fn fn-type="other" id="fn5-1094342011434814">
<p>
<italic>Sudhakar Yalamanchili</italic> earned his PhD degree in Electrical and Computer Engineering in 1984 from the University of Texas at Austin. Until 1989 he was a research scientist at Honeywell’s Systems and Research Center in Minneapolis. He joined the ECE faculty at Georgia Tech in 1989 where he is now a Joseph M. Pettit Professor of Computer Engineering. He is the author of <italic>VHDL Starters Guide</italic> (2nd edition, Prentice Hall, 2004), <italic>VHDL: From Simulation to Synthesis</italic> (Prentice Hall, 2000), and co-author with J. Duato and L. Ni of <italic>Interconnection Networks: An Engineering Approach</italic> (Morgan Kaufman, 2003). His current research foci lie in addressing the software challenges of heterogeneous architectures and solutions to power and thermal issues in many core architectures and data centers. Since 2003 he has been a Co-Director of the NSF Industry University Cooperative Research Center on Experimental Computer Systems at Georgia Tech. He continues to contribute professionally with service on editorial boards and conference program committees. His most recent service includes General Co-Chair of the 2010 IEEE/ACM International Symposium on Microarchitecture (MICRO) and Program Committees for the 2011 International Symposium on Networks on Chip (NOCS) and 2010 IEEE Micro: Top Picks from Computer Architecture Conferences.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>5</month>
<year>2012</year>
</pub-date>
<volume>26</volume>
<issue>2</issue>
<issue-title>Issues in Large Scale Computing Environments: Heterogeneous Computing and Operating Systems - two subjects, one special issue</issue-title>
<fpage>170</fpage>
<lpage>185</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>In this paper we identify important classes of program control flows in applications targeted to commercially available graphics processing units (GPUs) and characterize their presence in real workloads such as those that occur in CUDA and OpenCL. Broadly, control flow can be characterized as structured or unstructured. It is shown that most existing techniques for handling divergent control in bulk synchronous GPU applications handle structured control flow efficiently, some are incapable of executing unstructured control flow directly, and none handles unstructured control flow efficiently. An approach to reduce the impact of this problem is provided. An unstructured-to-structured control flow transformation for CUDA kernels is implemented and its performance impact on a large class of GPU applications is assessed. The results quantify the importance of improving support for programs with unstructured control flow on GPUs. The transformation can also be used in a JIT compiler pass to execute programs with unstructured control flow on the GPU devices that do not support unstructured control flow. This is an important capability for execution portability of applications using GPU accelerators.</p>
</abstract>
<kwd-group>
<kwd>branch divergence</kwd>
<kwd>GPU</kwd>
<kwd>unstructured control flow</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1094342011434814">
<title>1 Introduction</title>
<p>The transition to many-core computing has been accompanied by the emergence of heterogeneous architectures driven in large part by the major improvements in Joules/operation and further influenced by the evolution to throughput-oriented computing. This has coincided with the growth of data parallel computation that has become a pervasive and powerful model of computation. Its importance has been amplified by the rate at which raw data is being generated today in all sectors of the economy and rapidly growing in the foreseeable future. The emergence of low-cost programmable GPU computing substrates from NVIDIA, Intel, and AMD have made data parallel architectures commercially available from embedded systems through large scale clusters such as the Tsubame (<xref ref-type="bibr" rid="bibr20-1094342011434814">Matsuoka 2008</xref>) and Keeneland systems,<sup>
<xref ref-type="fn" rid="fn6-1094342011434814">1</xref></sup> hosting thousands of NVIDIA Fermi chips. Major research foci now include the development of programming models, algorithms, applications, performance analysis tools, productivity tools, and system software stacks.</p>
<p>Emerging data-parallel languages that implement <italic>single instruction stream multiple thread</italic> (SIMT) models (<xref ref-type="bibr" rid="bibr24-1094342011434814">Rixner et al. 1998</xref>) such as CUDA and OpenCL retain many of the control flow abstractions found in modern high level languages and simplify the task of programming these architectures. However, when the SIMT threads do not follow the same control path, performance suffers through poor hardware utilization and dynamic code expansion. This problem of <italic>branch divergence</italic> is critical to high performance and has attracted hardware and software support. The impact of branch divergence can be quite different depending on whether the program’s control flow is structured (control blocks have single entry and single exit such as if-then-else) or unstructured (control blocks have multiple entries or exits such as those using <italic>goto</italic> statements). In fact, some GPUs will only support (and hence their compilers will only generate) structured control flow. Therefore, it becomes important to understand the impact of unstructured control flow in GPU applications and performance effects of techniques developed to deal with it. This understanding is critical to the development of new techniques to improve the efficiency of support for unstructured control flow. This in turn can lead to the support of advanced features in GPGPU programming that produces unstructured control flow and are currently not supported in GPU architectures, such as try/catch.</p>
<p>A second reason for understanding the impact of unstructured control flow and the development of supporting compiler technology is the emerging importance of portability in future heterogeneous many-core architectures. Chips that support multiple instructions on a die, such as Intel’s Sandybridge (AVX, x86, GEN), will be common. Execution portability can be achieved via dynamic translation to support multiple GPU back-ends (<xref ref-type="bibr" rid="bibr7-1094342011434814">Diamos et al. 2010</xref>). The ability to execute a GPU kernel on multiple targets enhances portability and protects software investments. For example, transformations between unstructured and structured control flow implementations are necessary when one of the GPUs does not natively support unstructured control flow, e.g., AMD Radeon (<xref ref-type="bibr" rid="bibr8-1094342011434814">Dominguez et al. 2011</xref>). In reality, there already exists programs such as Optix (<xref ref-type="bibr" rid="bibr23-1094342011434814">Parker et al. 2010</xref>) that have complex unstructured control flow and need to be accelerated by GPUs. The current limited bandwidth between GPUs and CPUs forbids lots of data movement between them when running these programs in a high-throughput system and makes the support of unstructured control flow on GPUs a desirable solution in these cases. The future change of the balance between the bandwidth and the accelerator complexity may alter the design decision, but it remains to see.</p>
<p>In this paper we seek to analyze the occurrence and impact of unstructured control flow in GPU kernels. This paper makes the following contributions:<list list-type="bullet">
<list-item>
<p>Assesses the occurrence of unstructured control flow in several GPU benchmark suites.</p>
</list-item>
<list-item>
<p>Establishes that unstructured control flow necessarily causes dynamic and static code expansion for state-of-the-art hardware and compiler schemes. It shows that this code expansion can degrade performance in cases that occur in real applications.</p>
</list-item>
<list-item>
<p>Implements a compiler intermediate representation (IR) transformation that can turn unstructured control flow to a structured control flow implementation. This transformation is useful for researching the performance of arbitrary control flow on GPUs, and is also important for execution portability via dynamic translation.</p>
</list-item>
</list>
</p>
<p>The rest of the paper is organized as follows: Section 2 introduces unstructured control flow and its specific manifestation in GPU codes. Section 3 describes transformations for converting unstructured control flow to structured control flow. The experimental evaluation section, Section 4, assesses the impact of the transformations on several benchmark suites. Section 5 introduces the related work of this paper. The paper concludes with some general observations and directions for future work.</p>
</sec>
<sec id="section2-1094342011434814">
<title>2 GPU control flow support</title>
<p>Compilers can translate high-level imperative languages such as C/C++ or Java into an IR that resembles a low-level instruction set. Typical examples of IR are LLVM (<xref ref-type="bibr" rid="bibr18-1094342011434814">Lattner and Adve 2004</xref>), parallel thread execution (PTX) for CUDA GPU (<xref ref-type="bibr" rid="bibr22-1094342011434814">NVIDIA 2009</xref>), or AMD IL for AMD GPU (<xref ref-type="bibr" rid="bibr1-1094342011434814">AMD 2009</xref>). In IR, a control flow graph (CFG) represents the execution path of the program. Every node of the graph is a group of sequentially executed instructions, and the edges are the jumps which are usually caused by conditional/unconditional branches.</p>
<p>Previous work (zhang and D’Hollander 2004) classifies control flow patterns into two categories, structured and unstructured. In general, commonly used control flow patterns, such as those shown in <xref ref-type="fig" rid="fig1-1094342011434814">Figure 1</xref>
, are <italic>structured</italic>. These patterns correspond to <italic>hammock</italic> graphs in the CFG which are defined as subgraphs having a single entry node and a single exit node (<xref ref-type="bibr" rid="bibr11-1094342011434814">Ferrante et al. 1987</xref>). In contrast, <italic>unstructured</italic> control flow may have multiple entries or exits. <xref ref-type="fig" rid="fig2-1094342011434814">Figure 2</xref>
 adds some extra edges (dotted line), which may be caused by <italic>goto</italic> statements, to the structured control flow in <xref ref-type="fig" rid="fig1-1094342011434814">Figure 1</xref> and turns them into unstructured control flow. Based on the classification, <xref ref-type="bibr" rid="bibr25-1094342011434814">Zhang and D’Hollander (2004)</xref> introduced a generic approach to transform graphs with unstructured control flow to graphs possessing structured control flow. This transformation is explained in Section 3. The remainder of this section introduces the common sources of unstructured control flow and how they are supported in SIMT architectures.</p>
<fig id="fig1-1094342011434814" position="float">
<label>Figure 1.</label>
<caption>
<p>Examples of structured control flow: (a) if-then-else, (b) for-loop/while-loop, and (c) do-while-loop.</p>
</caption>
<graphic alternate-form-of="fig1-1094342011434814" xlink:href="10.1177_1094342011434814-fig1.tif"/>
</fig>
<fig id="fig2-1094342011434814" position="float">
<label>Figure 2.</label>
<caption>
<p>Examples of unstructured control flow: (a) if-then-else with extra outgoing edge, (b) if-then-else with extra incoming edge, (c) loop with extra outgoing edge and (d) loop with extra incoming edge.</p>
</caption>
<graphic alternate-form-of="fig2-1094342011434814" xlink:href="10.1177_1094342011434814-fig2.tif"/>
</fig>
<sec id="section3-1094342011434814">
<title>2.1 Sources of unstructured control flow</title>
<p>One of the most common sources is the <italic>goto</italic> statement used in C/C++ which allows control flow to jump to arbitrary nodes in the CFG. Similarly, longjumps and exceptions are two other sources of unstructured control flow.</p>
<p>However, even if the programming language forbids the use of <italic>goto</italic> statements (such as OpenCL), the compiler may also produce unstructured control flow in IR due to unintended side effects of the language semantics. For example, in the code segment of <xref ref-type="fig" rid="fig3-1094342011434814">Figure 3</xref>
(a), the compiler does not need to evaluate all four conditions (which is known as a short-circuit optimization) and the CFG of the generated IR looks like <xref ref-type="fig" rid="fig3-1094342011434814">Figure 3</xref>(b). This CFG has unstructured control flow because subgraph {B1, B2} and {B3, B4} both have two exits.</p>
<fig id="fig3-1094342011434814" position="float">
<label>Figure 3.</label>
<caption>
<p>Example showing a compound condition that creates unstructured control flow: (a) code segment, (b) CFG having unstructured control flow generated by short-circuit optimization and (c) CFG used in AMD GPUs.</p>
</caption>
<graphic alternate-form-of="fig3-1094342011434814" xlink:href="10.1177_1094342011434814-fig3.tif"/>
</fig>
<p>Moreover, CFG optimizations performed by compilers can also cause unstructured control flow (<xref ref-type="bibr" rid="bibr5-1094342011434814">Cooper et al. 2001</xref>). Considering <xref ref-type="fig" rid="fig4-1094342011434814">Figure 4</xref>
(a), if function <italic>foo()</italic> is inlined into the <italic>main()</italic> function, the early return statement in loop2 will create the second exit from the loop, which is shown in <xref ref-type="fig" rid="fig4-1094342011434814">Figure 4</xref>(b).</p>
<fig id="fig4-1094342011434814" position="float">
<label>Figure 4.</label>
<caption>
<p>Example showing function inlining that creates unstructured control flow: (a) code segment and (b) CFG having unstructured control flow.</p>
</caption>
<graphic alternate-form-of="fig4-1094342011434814" xlink:href="10.1177_1094342011434814-fig4.tif"/>
</fig>
<p>The first example highlights the difficulty in designing language semantics that require non-existence of unstructured control flow, while the second example shows that only a subset of existing compiler optimizations preserve the structured property of CFGs. As a result, designers of compilers for SIMD processors without hardware support for unstructured control flow must decide between performing existing optimization passes and then restructuring the program or avoiding certain optimizations altogether. This greatly increases the complexity of these compilers and potentially eliminates opportunities for optimization. Since the above examples are very common in modern programming languages, normal programs usually have both structured and unstructured control flow. The desires that unstructured parts should be executed efficiently to avoid hurting overall performance while not placing restrictions on language semantics and retaining the ability to perform arbitrary transformations on CFGs creates a clear advantage to support unstructured control flow on general-purpose SIMD processors.</p>
<p>In the above examples, if some edges are deleted, the control flow will become structured. These edges are called <italic>interacting edges</italic> (<xref ref-type="bibr" rid="bibr25-1094342011434814">Zhang and D’Hollander 2004</xref>), since they interact with two hammock graphs. There are two types of such edges:<list list-type="bullet">
<list-item>
<p>An <italic>interacting out-edge</italic> leaves a hammock graph from a point other than the exit block, such as edge E1 and E2 in <xref ref-type="fig" rid="fig3-1094342011434814">Figure 3</xref>(b). Edge E1 in <xref ref-type="fig" rid="fig4-1094342011434814">Figure 4</xref> is also an interacting out-edge.</p>
</list-item>
<list-item>
<p>An <italic>interacting in-edge</italic> enters a hammock graph from a point other than the entry block. The dotted line in <xref ref-type="fig" rid="fig2-1094342011434814">Figure 2</xref>(b) and <xref ref-type="fig" rid="fig2-1094342011434814">Figure 2</xref>(d) are two examples.</p>
</list-item>
</list>
</p>
</sec>
<sec id="section4-1094342011434814">
<title>2.2 Impact of branch divergence in modern GPUs</title>
<p>Modern programmable GPUs implement massively data parallel execution models. In this paper we analyze GPU kernels from CUDA applications compiled to NVIDIA’s PTX virtual instruction set architecture. PTX defines an execution model (see <xref ref-type="fig" rid="fig5-1094342011434814">Figure 5</xref>
) where an entire application is composed of a series of multi-threaded kernels. Kernels are composed of parallel work-units called <italic>cooperative thread arrays</italic> (CTAs), each of which can be executed in any order subject to an implicit barrier between kernel launches. Threads within a CTA are grouped together into logical units known as <italic>warps</italic> that are mapped to SIMD units using a combination of hardware support for predication, a thread context stack, and compiler support for identifying re-converge points at control-independent code.</p>
<fig id="fig5-1094342011434814" position="float">
<label>Figure 5.</label>
<caption>
<p>Execution model of NVIDIA CUDA PTX.</p>
</caption>
<graphic alternate-form-of="fig5-1094342011434814" xlink:href="10.1177_1094342011434814-fig5.tif"/>
</fig>
<p>Since threads within the same <italic>warp</italic> have to execute the same instructions, branch control flow can potentially cause inefficiencies if the branch condition is not evaluated identically across all threads in a <italic>warp</italic>. In this case, some threads may take a fall-through edge and the others may jump to the branch target, which is referred to as branch divergence. This can be handled by a process of serially enabling/disabling threads corresponding to the then/else branch. This effectively splits the <italic>warp</italic> into smaller subsets of threads which may then re-converge later in the execution. The execution model of other GPUs are similar, though they use different terminology.</p>
<p>The implementation details of re-convergence differ among GPUs. In AMD GPUs illustrated in <xref ref-type="fig" rid="fig6-1094342011434814">Figure 6</xref>
, its IR language (AMD IL) uses explicit instructions such as IF, ELSE, ENDIF, LOOP, ENDLOOP, etc., which means it only supports limited structured control flow (<xref ref-type="bibr" rid="bibr2-1094342011434814">AMD 2010</xref>). The mapping of these control flow to the hardware is simple and fixed. It executes all of the possible paths of the program (e.g. <italic>then</italic> part and <italic>else</italic> part for IF instructions) in a lock-step manner, and threads re-converge at the END instructions such as ENDIF or ENDLOOP. If the compound condition code in <xref ref-type="fig" rid="fig3-1094342011434814">Figure 3</xref>(a) is compiled for AMD GPUs, it has to generate CFG like <xref ref-type="fig" rid="fig3-1094342011434814">Figure 3</xref>(c) which uses nested if-then-else to form a structured control flow implementation. The Intel GEN5 graphics processors work in a similar manner (<xref ref-type="bibr" rid="bibr16-1094342011434814">Intel 2009</xref>).</p>
<fig id="fig6-1094342011434814" position="float">
<label>Figure 6.</label>
<caption>
<p>Example of AMD IL (a) C code and (b) corresponding AMD IL.</p>
</caption>
<graphic alternate-form-of="fig6-1094342011434814" xlink:href="10.1177_1094342011434814-fig6.tif"/>
</fig>
<p>However, mapping parallel programs with arbitrary control flow onto SIMD units is a difficult problem because there is generally no guarantee that different parallel threads will ever be executing the same instructions. Thus, the re-convergence point may impact the overall performance. This will be discussed in the following section.</p>
</sec>
<sec id="section5-1094342011434814">
<title>2.3 Unstructured control flow on GPUs</title>
<p>Although supporting structured control flow is sufficient for many graphics shading languages such as Microsoft DirectX and Khronos OpenGL, the migration to general purpose models such as OpenCL and CUDA that derive from C makes it advantageous to support unstructured control flow. Specifically, CUDA supports <italic>goto</italic> statements in the high level language. In addition, its IR language, PTX, has many features in common with RISC ISAs, which includes arbitrary branch instructions rather than explicit IF and LOOP instructions. Consequently, as discussed in Section 2.1, compilation of CUDA programs can employ common CFG optimizations that are already widely used in other C/C++ program compilation frameworks, and programmers do not need to worry about introducing unstructured control flow into programs that are not allowed on some GPU platforms.</p>
<p>The current state of the practice in determining re-convergence points for divergent SIMD threads is referred to as immediate post-dominator<sup>
<xref ref-type="fn" rid="fn7-1094342011434814">2</xref></sup> re-convergence (<xref ref-type="bibr" rid="bibr13-1094342011434814">Fung et al. 2007</xref>). By using this method, the re-converge point is fixed for every divergent branch and can be calculated statically during compilation. For structured control flow, this method would re-converge at the end of loops or if-else-endif control blocks, which are as efficient as AMD GPUs. However, it may execute inefficiently for unstructured control flow. For example, in <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>
, assume the <italic>warp</italic> size is seven and these seven threads take seven different paths as shown in <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(b), which is the worst case for this CFG. The immediate post-dominator of all branches is the exit node (see <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(a)). <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(c) shows how the SIMD unit executes these seven threads for re-converging at the immediate post-dominator. There are many empty slots in this figure and on average only 3.25 threads are enabled. It is also interesting to notice that the execution of the CFG of <xref ref-type="fig" rid="fig3-1094342011434814">Figure 3</xref>(c) is the same as <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(c), which means AMD GPUs are also inefficient for this example.</p>
<fig id="fig7-1094342011434814" position="float">
<label>Figure 7.</label>
<caption>
<p>Example of mapping unstructured control flow into a SIMD unit: (a) unstructured CFG, (b) execution path, (c) re-converge at the immediate post-dominator and (d) re-converge at the earliest point.</p>
</caption>
<graphic alternate-form-of="fig7-1094342011434814" xlink:href="10.1177_1094342011434814-fig7.tif"/>
</fig>
<p>
<italic>Dynamic code expansion</italic> occurs when different paths originating from a divergent branch pass through common basic blocks before the re-convergence point. For example, in <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(c), time slots 7–1 are running dynamically expanded code because B3, B4 and B5 have been already executed in time slots 4, 5 and 6. This concept is defined against <italic>static code expansion</italic>, which inserts new instructions and increases the static binary size. During execution, dynamically expanded instructions will use the same PC values while statically expanded instructions will use different PC values.</p>
<p>The solution that reduces dynamic code expansion is to re-converge as early as possible. <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(d) is an example where re-convergence happens much earlier than the immediate post-dominator. It saves execution time and has much better hardware resource occupancy. To achieve performance improvements as shown in <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(d), the compiler should be capable of identifying the potential early re-converge points and inserting necessary check instructions. It also needs the support from hardware to efficiently compare the program counter (PC) of each thread to check for re-convergence. There is no commercial technology that can achieve the efficiency shown in this example and thus there is still a great deal of room for improvement in executing unstructured control flow in SIMD processors.</p>
<p>The inefficiency of re-convergence at immediate post-dominators exacerbates the problem of branch divergence. If unstructured control flow can be handled more efficiently, some new language semantics, such as C++ try/catch style exceptions, can be added to current programming model. Furthermore, compilers do not have to generate structured control flow as in <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(c) if hardware more efficiently supports unstructured control flow.</p>
</sec>
<sec id="section6-1094342011434814">
<title>2.4 Executing arbitrary control flow on GPUs</title>
<p>Consequently, there are three ways to run programs with arbitrary control flow on different GPU platforms in an efficient (and, hence, portable) manner:<list list-type="bullet">
<list-item>
<p>The simplest method is to let compilers have the option to produce IR code only containing structured control flow. This IR code then can be compiled into different back-ends. This method may miss some optimization opportunities, but it is simplest to implement.</p>
</list-item>
<list-item>
<p>Use a just in time (JIT) compiler to dynamically transform the unstructured control flow to structured control flow online when necessary, i.e. the target GPU does not support unstructured control flow. The dynamic compilation may introduce some inevitable overhead.</p>
</list-item>
<list-item>
<p>The most promising method is to develop a new technology (with support from both compiler and hardware) to replace current approaches to fully utilize the early re-convergence opportunity that is illustrated in <xref ref-type="fig" rid="fig7-1094342011434814">Figure 7</xref>(d).</p>
</list-item>
</list>
</p>
<p>This paper presents an approach to the second option above: transformation of the unstructured control flow to structured control flow in Section 3. The third option remains as future work.</p>
</sec>
</sec>
<sec id="section14-1094342011434814">
<title>3 Control flow transformations</title>
<p>The principal result of <xref ref-type="bibr" rid="bibr25-1094342011434814">Zhang and D’Hollander’s (2004)</xref> work is that the repeated application of three primary transformations can provably convert all possible unstructured programs into a structured format. However, their technique only applies to the programming language level instead of the IR level. To perform similar transformations at the PTX IR level some extra work is needed and the three original transformations have to be adapted because there is no simple one-to-one mapping between CFG and syntactic constructs. For example, syntactic constructs are flat but CFG is a two-dimensional structure. The adapted transformations are conceptually and functionally equivalent to those used in Zhang’s work (the detailed algorithm and correctness proof can be found in their original work) and can be explained through the application of three primitive transformations.<list list-type="bullet">
<list-item>
<p>
<bold>Cut:</bold> The Cut transformation moves the outgoing edge of a loop to the outside of the loop. For example, the loop in <xref ref-type="fig" rid="fig8-1094342011434814">Figure 8</xref>
(a) has two unstructured outgoing edges, E1 and E2. What Cut transformations do is as follows: (i) using three flags to label the location of the loop exits (<italic>flag1</italic>, <italic>flag2</italic>, and <italic>exit</italic> in <xref ref-type="fig" rid="fig8-1094342011434814">Figure 8</xref>(b)); (ii) combining all exit edges to a single exit node; (iii) using three conditional checks to find the correct code to execute after the loop (<xref ref-type="fig" rid="fig8-1094342011434814">Figure 8</xref>(c)). It should be noted that after the transformation the CFG in this example is still unstructured and needs other transformations to make it structured.
</p>
</list-item>
<list-item>
<p>
<bold>Backward Copy:</bold> Backward Copy moves the incoming edges of a loop to the outside of the loop. For instance, <xref ref-type="fig" rid="fig9-1094342011434814">Figure 9</xref>
(a) has an unstructured incoming edge E1 into the loop. To transform it, the backward copy uses the loop peeling technique to unravel the first iteration of the loop (<xref ref-type="fig" rid="fig9-1094342011434814">Figure 9</xref>(b)) and points all incoming edges to the peeled part (<xref ref-type="fig" rid="fig9-1094342011434814">Figure 9</xref>(c)). In this example, the CFG after the transformation is also unstructured. This transformation is rarely needed (see the experiment part in Section 4) because usually neither programmers nor compilers would create loops with multiple entries.
</p>
</list-item>
<list-item>
<p>
<bold>Forward Copy:</bold> Forward Copy handles the unstructured control flow in the acyclic CFG. After Cut and Backward Copy transformations, there are no unstructured edges coming into or going out of loops. As a consequence, CFGs inside every loop can be handled individually and all structured loops can be collapsed into abstract single CFG nodes. Forward Copy eliminates all remaining unstructured branches by duplicating their target CFG nodes when traversing the CFG in the depth-first order. For example, in <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>
(a), B5 needs to be duplicated because edge E2: B4→B5 is unstructured (<xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(b)). Similarly, in <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(b), subgraph {B3, B4, B5 and B5’} also has to be duplicated because edge E1: B2→B3 is unstructured (<xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(c)). If Forward Copy is performed multiple times, some subgraphs may be duplicated more than once and it may eventually lead to exponential code expansion. The final result shown in <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(c) duplicates B5 three times and duplicates B4 and B3 once, respectively. Actually, every path between the entry node and the exit node of <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(c) is a possible execution path of <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>(a).
</p>
</list-item>
</list>
</p>
<fig id="fig8-1094342011434814" position="float">
<label>Figure 8.</label>
<caption>
<p>Example of a Cut transformation: (a) unstructured CFG; (b) three flags are used to denote the loop exit location (<italic>flag1</italic>, exit from B3 or not; <italic>flag2</italic>, exit from B4 or not; <italic>exit</italic>, loop terminates or not); (c) combine all exit edges to a single exit node and use three conditional checks to find the correct code to execute after the loop.</p>
</caption>
<graphic alternate-form-of="fig8-1094342011434814" xlink:href="10.1177_1094342011434814-fig8.tif"/>
</fig>
<fig id="fig9-1094342011434814" position="float">
<label>Figure 9.</label>
<caption>
<p>Example of a Backward Copy transformation: (a) unstructured CFG; (b) use loop peeling to unravel the first iteration; (c) point all incoming edges to the peeled part.</p>
</caption>
<graphic alternate-form-of="fig9-1094342011434814" xlink:href="10.1177_1094342011434814-fig9.tif"/>
</fig>
<fig id="fig10-1094342011434814" position="float">
<label>Figure 10.</label>
<caption>
<p>Example of a Forward Copy transformation: (a) unstructured CFG; (b) CFG after duplicating B5; (c) structured CFG.</p>
</caption>
<graphic alternate-form-of="fig10-1094342011434814" xlink:href="10.1177_1094342011434814-fig10.tif"/>
</fig>
<p>
<xref ref-type="fig" rid="fig11-1094342011434814">Figure 11</xref>
 compares the code duplicated by Forward Copy and the dynamically expanded code caused by re-convergence at the immediate post-dominator (<xref ref-type="fig" rid="fig11-1094342011434814">Figure 11</xref>(b) and (c) use the same color to represent the same basic block), it is interesting to see that they are exactly the same. Moreover, the execution of the re-convergence at the immediate post-dominator can be drawn as a tree (the red tree in <xref ref-type="fig" rid="fig11-1094342011434814">Figure 11</xref>(c)), where each path of the tree stands for an execution path of the program. This red tree is also the same as the CFG of <xref ref-type="fig" rid="fig11-1094342011434814">Figure 11</xref>(b). This is not a coincidence and can be generalized because they are both the depth-first spanning trees of the original CFG. A simple proof is like this: if all threads in a warp follow different paths, which is the worst case of the execution, the warp would diverge in every CFG node which is the same as traversing the CFG in the depth-first order. Meanwhile, Forward Copy duplicates all target node of the unstructured edges in the depth-first order and finally no node (except the exit node) has two or more parent nodes (otherwise, it is still unstructured) and the transformed CFG becomes a binary tree. Hence, Forward Copy, in general, can be used to measure the worst case of dynamic code expansion of immediate post-dominator re-convergence without running the program.</p>
<fig id="fig11-1094342011434814" position="float">
<label>Figure 11.</label>
<caption>
<p>Relationship between Forward Copy and re-convergence at the immediate post-dominator: (a) unstructured CFG; (b) result of Forward Copy/depth-first spanning tree; (c) re-convergence at the immediate post-dominator.</p>
</caption>
<graphic alternate-form-of="fig11-1094342011434814" xlink:href="10.1177_1094342011434814-fig11.tif"/>
</fig>
<p>All of the above three transformations will cause static code expansion since they insert new instructions into the original program. In single instruction single data (SISD) processors, static code expansion has disadvantages of increased binary size and instruction cache footprint. This code expansions is even more problematic for SIMD architectures because paths through duplicated blocks cannot be executed in lock-step by threads in a warp since these blocks use different PC values. Moreover, the cut transformation has to use several new variables to store flag values, which introduces new register pressure. It needs to use more conditional branches as well when exiting the loop, which may cause more divergence in the GPU architecture (see Section 2.2).</p>
<p>Only using the above three transformations is not sufficient since program structure must also be maintained: such as which basic blocks form a loop or the nesting level of a control block. A data structure called a <italic>control tree</italic> (<xref ref-type="bibr" rid="bibr21-1094342011434814">Muchnick 1997</xref>) can provide this information, which basically describes the components of all control flow patterns and their nested structures. <xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>
(b) shows a CFG and its corresponding control tree. It should be noted that all unstructured control flow, such as subgraph {B1, B2, B3} in <xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>(b), are also included in the tree.</p>
<fig id="fig12-1094342011434814" position="float">
<label>Figure 12.</label>
<caption>
<p>A complete example of unstructured to structured transformation (a) original CFG; (b) build the control tree; (c) collapses the structured node and update the control tree; (d) Forward Copy transformation; (e) update the control tree; and (f) final result.</p>
</caption>
<graphic alternate-form-of="fig12-1094342011434814" xlink:href="10.1177_1094342011434814-fig12.tif"/>
</fig>
<p>Including the control tree construction and the three primitive transformations, the process of transforming an unstructured CFG to a structured CFG has four steps:<list list-type="order">
<list-item>
<p>Build a control tree and identify unstructured branches and some basic structured control flow patterns in the CFG including if-then, if-then-else, self-loop, for-loop and do-while loop,</p>
</list-item>
<list-item>
<p>Collapse the detected structured control flow pattern into a single abstract node and update the control tree. The aim of this step is to simplify the search space of the following pattern matching steps.</p>
</list-item>
<list-item>
<p>If all of the children nodes of an unstructured node are structured, use the three primitive transformations to transform it into structured control flow. If the children nodes still contain unstructured control flow, wait until all children become structured. Otherwise, the transformation would introduce more unstructured parts into the CFG. For example, in <xref ref-type="fig" rid="fig10-1094342011434814">Figure 10</xref>, edge E2 must be transformed before edge E1.</p>
</list-item>
<list-item>
<p>Update the control tree to reflect the transformation. If there is no unstructured part remaining, the process finishes. Otherwise, go back to the second step to transform the remaining unstructured parts.</p>
</list-item>
</list>
</p>
<p>
<xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref> shows all steps of transforming an unstructured CFG into a structured CFG. It first builds a control tree and finds that subgraph B1, B2, B3 is unstructured (<xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>(b)). Second, it collapses the self-loop into a single node and updates the control tree (<xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>(c)). Third, it uses Forward Copy to duplicate B3 (<xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>(d)). Finally, it updates the control tree and determines that there are no more unstructured parts and the whole process is completed (<xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>(e)). <xref ref-type="fig" rid="fig12-1094342011434814">Figure 12</xref>(f) is the final result.</p>
<p>This transformation is not only useful in characterizing unstructured control flow as discussed above. It can also be used in dynamic compilers which are used in heterogeneous systems. Since the support for unstructured control flow in different GPU devices is different, this kind of transformation allows the program to run on several different back-ends which is very useful for large clusters comprised of different GPU backends.</p>
</sec>
<sec id="section7-1094342011434814">
<title>4 Experimental evaluation</title>
<p>This section evaluates how often unstructured control flow occurs in real GPU programs and how they may impact the performance over a large collection of CUDA benchmarks from the CUDA SDK 3.2,<sup><xref ref-type="fn" rid="fn7-1094342011434814">2</xref></sup> Parboil 2.0 (<xref ref-type="bibr" rid="bibr15-1094342011434814">Impact Research Group 2009</xref>), Rodinia 1.0 (<xref ref-type="bibr" rid="bibr4-1094342011434814">Che et al. 2009</xref>), Optix SDK 2.1 (<xref ref-type="bibr" rid="bibr23-1094342011434814">Parker et al. 2010</xref>) and some third-party applications. The CUDA SDK contains a large collection of simple GPU programs. Parboil benchmarks are compute intensive. Rodinia’s collection is chosen to represent different types of GPU parallel programs which are more complex than those in the CUDA SDK. Optix SDK includes several ray tracing applications. The third-party GPU applications used include a 3D renderer called <italic>Renderer</italic>,<sup><xref ref-type="fn" rid="fn8-1094342011434814">3</xref></sup> a radiative transport equation solver called <italic>mcrad</italic> (<xref ref-type="bibr" rid="bibr10-1094342011434814">Fernando 2004</xref>), and a Monte Carlo simulator called <italic>mcx</italic> (<xref ref-type="bibr" rid="bibr9-1094342011434814">Fang and Boas 2009</xref>).</p>
<p>As for the compilation tools, NVCC 3.2 is used to compile CUDA programs to PTX code. Optix SDK benchmarks are running under Optix’s own execution engine. A GPU compilation infrastructure, Ocelot 1.2.807 (<xref ref-type="bibr" rid="bibr7-1094342011434814">Diamos et al. 2010</xref>), is used for several other purposes: back-end code generation, PTX transformation, functional emulation, trace generation and performance analysis.</p>
<sec id="section8-1094342011434814">
<title>4.1 Static characterization</title>
<p>The first set of experiments attempts to characterize the existence of certain types of control flow in existing CUDA workloads by using the unstructured to structured transformations introduced in Section 3. The transformation is implemented as a static optimization pass in Ocelot, and it is applied to the PTX code of all benchmarks. The optimization can detect unstructured control flow and classify it by the type of transformations used (Cut, Backward Copy, or Forward Copy). The correctness of the transformation is verified by comparing the output results of the original program and the transformed program. <xref ref-type="table" rid="table1-1094342011434814">Table 1</xref> shows the number of applications having unstructured control flow in four examined GPU benchmark suites. Out of the 113 applications examined, 27 contain unstructured control flow, indicating that, at the very least an unstructured to structured compiler transformation is required to support general CUDA applications on all GPUs. It is also the case that more complex applications are more likely to include unstructured control flow. Almost half of the applications in the Rodinia and Optix benchmark suites include unstructured control flow.</p>
<table-wrap id="table1-1094342011434814" position="float">
<label>Table 1.</label>
<caption>
<p>Existence of unstructured control flow in different GPU benchmark suites.</p>
</caption>
<graphic alternate-form-of="table1-1094342011434814" xlink:href="10.1177_1094342011434814-table1.tif"/>
<table>
<thead>
<tr>
<th>Suite</th>
<th>Number of Benchmarks</th>
<th>Number of benchmarks with unstructured control flow</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA SDK</td>
<td>56</td>
<td>4</td>
</tr>
<tr>
<td>Parboil</td>
<td>12</td>
<td>3</td>
</tr>
<tr>
<td>Rodinia</td>
<td>20</td>
<td>9</td>
</tr>
<tr>
<td>Optix</td>
<td>25</td>
<td>11</td>
</tr>
<tr>
<td>Total</td>
<td>113</td>
<td>27</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>
<xref ref-type="table" rid="table2-1094342011434814">Table 2</xref> shows the usage of different transformations. The second column is the number of branch instructions in each benchmark. The third to the fifth columns show the number of times each transformation is used for every benchmark. The statistics show that Backward Copy appears to be non-existent in current workloads which follows the common practice that programmers rarely write a loop with multiple entries. Cut transformations are necessary in programs that involve loops, but the shallow levels of nesting of GPU programs, especially those simple programs, makes this operation less common. Forward transformations are used most often. Further analysis shows that short-circuiting is the main trigger of these transformations. As explained in Section 2.2, short-circuiting does not run efficiently on the GPU platform.</p>
<table-wrap id="table2-1094342011434814" position="float">
<label>Table 2.</label>
<caption>
<p>Unstructured to structured transformation statistics.</p>
</caption>
<graphic alternate-form-of="table2-1094342011434814" xlink:href="10.1177_1094342011434814-table2.tif"/>
<table>
<thead>
<tr>
<th>
<bold>Benchmark</bold>
</th>
<th>
<bold>Branch Instruction</bold>
</th>
<th>
<bold>Cut</bold>
</th>
<th>
<bold>Forward Copy</bold>
</th>
<th>
<bold>Backward Copy</bold>
</th>
<th>
<bold>Old Code Size</bold>
</th>
<th>
<bold>New Code Size</bold>
</th>
<th>
<bold>Static Code Expansion (%)</bold>
</th>
<th>
<bold>Transformation Overhead (ms)</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="9">
<bold>CUDA SDK</bold>
</td>
</tr>
<tr>
<td>mergeSort</td>
<td>160</td>
<td>0</td>
<td>4</td>
<td>0</td>
<td>1914</td>
<td>1946</td>
<td>1.67</td>
<td>0.085</td>
</tr>
<tr>
<td>particles</td>
<td>32</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>772</td>
<td>790</td>
<td>2.33</td>
<td>0.067</td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>340</td>
<td>6</td>
<td>6</td>
<td>0</td>
<td>3470</td>
<td>4072</td>
<td>17.35</td>
<td>3.000</td>
</tr>
<tr>
<td>eigenValues</td>
<td>431</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>4459</td>
<td>4519</td>
<td>1.35</td>
<td>0.113</td>
</tr>
<tr>
<td colspan="9">
<bold>PARBOIL</bold>
</td>
</tr>
<tr>
<td>bfs</td>
<td>65</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>684</td>
<td>689</td>
<td>0.73</td>
<td>0.036</td>
</tr>
<tr>
<td>mri-fhd</td>
<td>163</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1979</td>
<td>1984</td>
<td>0.25</td>
<td>0.193</td>
</tr>
<tr>
<td>tpacf</td>
<td>37</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>476</td>
<td>499</td>
<td>4.83</td>
<td>0.042</td>
</tr>
<tr>
<td colspan="9">
<bold>RODINIA</bold>
</td>
</tr>
<tr>
<td>heartwall</td>
<td>144</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>1683</td>
<td>1701</td>
<td>1.07</td>
<td>0.072</td>
</tr>
<tr>
<td>hotspot</td>
<td>19</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>237</td>
<td>242</td>
<td>2.11</td>
<td>0.038</td>
</tr>
<tr>
<td>particlefilter_naive</td>
<td>29</td>
<td>3</td>
<td>5</td>
<td>0</td>
<td>155</td>
<td>203</td>
<td>30.97</td>
<td>0.115</td>
</tr>
<tr>
<td>particlfilter_float</td>
<td>132</td>
<td>2</td>
<td>4</td>
<td>0</td>
<td>1524</td>
<td>1566</td>
<td>2.76</td>
<td>0.108</td>
</tr>
<tr>
<td>mummergpu</td>
<td>92</td>
<td>2</td>
<td>26</td>
<td>0</td>
<td>1112</td>
<td>2117</td>
<td>90.38</td>
<td>1.056</td>
</tr>
<tr>
<td>srad_v1</td>
<td>34</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>572</td>
<td>595</td>
<td>4.02</td>
<td>0.031</td>
</tr>
<tr>
<td>Myocyte</td>
<td>4452</td>
<td>2</td>
<td>55</td>
<td>0</td>
<td>54,993</td>
<td>62,800</td>
<td>14.20</td>
<td>7.677</td>
</tr>
<tr>
<td>Cell</td>
<td>74</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>507</td>
<td>512</td>
<td>0.99</td>
<td>0.076</td>
</tr>
<tr>
<td>PathFinder</td>
<td>9</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>136</td>
<td>141</td>
<td>3.68</td>
<td>0.024</td>
</tr>
<tr>
<td colspan="9">
<bold>OPTIX</bold>
</td>
</tr>
<tr>
<td>glass</td>
<td>157</td>
<td>0</td>
<td>7</td>
<td>0</td>
<td>4385</td>
<td>4892</td>
<td>11.56</td>
<td>0.412</td>
</tr>
<tr>
<td>julia</td>
<td>1634</td>
<td>14</td>
<td>22</td>
<td>0</td>
<td>14,097</td>
<td>18,191</td>
<td>29.04</td>
<td>4.509</td>
</tr>
<tr>
<td>mcmc_sampler</td>
<td>101</td>
<td>0</td>
<td>3</td>
<td>0</td>
<td>4225</td>
<td>4702</td>
<td>11.29</td>
<td>0.319</td>
</tr>
<tr>
<td>whirligig</td>
<td>143</td>
<td>0</td>
<td>8</td>
<td>0</td>
<td>4533</td>
<td>5303</td>
<td>16.99</td>
<td>5.663</td>
</tr>
<tr>
<td>whitted</td>
<td>173</td>
<td>0</td>
<td>6</td>
<td>0</td>
<td>5389</td>
<td>5841</td>
<td>8.39</td>
<td>0.334</td>
</tr>
<tr>
<td>zoneplate</td>
<td>297</td>
<td>0</td>
<td>3</td>
<td>0</td>
<td>3397</td>
<td>3400</td>
<td>0.09</td>
<td>0.073</td>
</tr>
<tr>
<td>collision</td>
<td>101</td>
<td>0</td>
<td>4</td>
<td>0</td>
<td>2585</td>
<td>2595</td>
<td>0.39</td>
<td>0.034</td>
</tr>
<tr>
<td>progressive PhotonMap</td>
<td>127</td>
<td>0</td>
<td>4</td>
<td>0</td>
<td>3905</td>
<td>3960</td>
<td>1.41</td>
<td>0.077</td>
</tr>
<tr>
<td>path_trace</td>
<td>29</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1870</td>
<td>1875</td>
<td>0.27</td>
<td>0.028</td>
</tr>
<tr>
<td>heightfield</td>
<td>46</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1761</td>
<td>1771</td>
<td>0.57</td>
<td>0.097</td>
</tr>
<tr>
<td>swimmingShark</td>
<td>51</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1990</td>
<td>2000</td>
<td>0.50</td>
<td>0.067</td>
</tr>
<tr>
<td>
<bold>mcrad</bold>
</td>
<td>415</td>
<td>11</td>
<td>10</td>
<td>0</td>
<td>4552</td>
<td>5238</td>
<td>15.07</td>
<td>1.491</td>
</tr>
<tr>
<td>
<bold>Renderer</bold>
</td>
<td>7148</td>
<td>943</td>
<td>179</td>
<td>0</td>
<td>70,176</td>
<td>111,540</td>
<td>58.94</td>
<td>105.160</td>
</tr>
<tr>
<td>
<bold>mcx</bold>
</td>
<td>178</td>
<td>0</td>
<td>9</td>
<td>0</td>
<td>2957</td>
<td>5527</td>
<td>86.91</td>
<td>2.489</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The sixth and seventh column of <xref ref-type="table" rid="table2-1094342011434814">Table 2</xref> is the static code size of the benchmarks before and after the transformation. Static Code size is calculated by counting the PTX instructions of the benchmark. Usually the larger its code size is, the more complex control flow the program may have and the more transformations it needs. Benchmarks that have one Cut and zero Forward Copy, such as <italic>path_trace</italic> and <italic>heightfield</italic>, show that the number of instructions inserted by Cut is small. However, this is not the case for the Forward Copy. In the benchmark <italic>mummergpu</italic>, its code size is almost doubled by 26 Forward Copy transformations. The code size increment caused by Forward Copy depends on the size of the shared CFG nodes that need to be duplicated. Column eight is the relative static code expansion. <xref ref-type="fig" rid="fig13-1094342011434814">Figure 13</xref>
 shows the code expansion of those benchmarks using at least one Forward Copy with an average of 18.68%. For those benchmarks having a large number of transformations, such as <italic>mummergpu</italic>, <italic>mcx</italic>, and <italic>Renderer</italic>, the static code expansion is significant.</p>
<fig id="fig13-1094342011434814" position="float">
<label>Figure 13.</label>
<caption>
<p>Static code expansion of benchmarks using Forward Copy.</p>
</caption>
<graphic alternate-form-of="fig13-1094342011434814" xlink:href="10.1177_1094342011434814-fig13.tif"/>
</fig>
<p>Among all of the benchmarks, <italic>Renderer</italic> has far more transformations than the rest. Other graphics benchmarks (<italic>particles</italic>, <italic>Mandlebrot</italic>, Optix SDK suite) also have more unstructured control flow on average. It is fair to say that graphics applications have great potential to improve performance if unstructured control flow could be handled more efficiently.</p>
<p>The ninth column lists the transformation time of each benchmark. The overhead is basically proportional to the number of taken transformations. Most of the benchmarks uses less than 1 ms to finish the transformation. Only <italic>Renderer</italic> takes more than 0.1 s because it has more than 8000 unstructured branches. Considering the fact that the transformation is a one time investment and complex programs usually run for a long time (e.g. tested ray tracing programs can run forever), this overhead is affordable even if applied in runtime.</p>
</sec>
<sec id="section9-1094342011434814">
<title>4.2 Dynamic characterization</title>
<sec id="section10-1094342011434814">
<title>4.2.1 Impact of IPDOM</title>
<p>In the absence of support for re-convergence for unstructured control flow versus immediate post-dominator, we use the functional emulator provided by Ocelot to count the number of instructions executed due to the lack of earlier re-convergence. For example, the instructions executed in the red circle of <xref ref-type="fig" rid="fig14-1094342011434814">Figure 14</xref>
. We perform measurements over code segments that meet three requirements: (i) start with an unstructured branch; (ii) the threads are divergent; (iii) ends with the immediate post-dominator of the unstructured branch. The instructions satisfying above three requirements can be optimized by re-converging at the earlier point.</p>
<fig id="fig14-1094342011434814" position="float">
<label>Figure 14.</label>
<caption>
<p>Example of measured dynamic code expansion statistics</p>
</caption>
<graphic alternate-form-of="fig14-1094342011434814" xlink:href="10.1177_1094342011434814-fig14.tif"/>
</fig>
<p>To find these instructions, we first determined the basic blocks (CFG nodes) between an unstructured branch and its immediate post-dominator by using our static transformation. These basic blocks might be dynamically expanded at runtime (such as B3, B4, and B5 in <xref ref-type="fig" rid="fig14-1094342011434814">Figure 14</xref>). Then, we used the emulator to count the number of times these basic blocks will run in a divergent <italic>warp</italic>. For example, in <xref ref-type="fig" rid="fig14-1094342011434814">Figure 14</xref>, B3 and B4 each run twice in the divergent <italic>warp</italic> and B5 runs four times. Assuming each basic block has one instruction for the simplicity of counting instruction number, we can say at most eight instructions may miss the early re-convergence (actual number of dynamic expanded instructions is five, executed in time slots 7–11). Although this method overestimates the performance degradation, the overestimated part is limited to the initial execution of these instructions. Taking <xref ref-type="fig" rid="fig14-1094342011434814">Figure 14</xref> as an example, the overestimated part is time slots 4–6 during which B3, B4 and B5 are executed for the first time.</p>
<p>
<xref ref-type="table" rid="table3-1094342011434814">Table 3</xref> shows the upper limit of dynamic code expansion for benchmarks using Forward Copy. Some benchmarks are not included because the emulator cannot correctly execute them yet. The results vary greatly. Four simple benchmarks of CUDA SDK have very low values because the unstructured part is executed infrequently or <italic>warps</italic> do not diverge when executing them. However, other benchmarks, such as <italic>Renderer</italic> and <italic>mcx</italic>, have a significant value meaning the application repeatedly executes these unstructured control flow. In this case, not having earlier re-convergence will impact the performance significantly. It is also interesting to notice that benchmark <italic>tpacf</italic> has low static code expansion but high dynamic code expansion, which means the unstructured part is executed very frequently.</p>
<table-wrap id="table3-1094342011434814" position="float">
<label>Table 3.</label>
<caption>
<p>Upper limit of dynamic code expansion.</p>
</caption>
<graphic alternate-form-of="table3-1094342011434814" xlink:href="10.1177_1094342011434814-table3.tif"/>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Dynamic code expansion area (number of instructions)</th>
<th>Original dynamic instruction count</th>
<th>Dynamic code expansion area (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mandelbrot</td>
<td>86,690</td>
<td>40,756,133</td>
<td>0.21%</td>
</tr>
<tr>
<td>mergeSort</td>
<td>0</td>
<td>192,036,155</td>
<td>0.00%</td>
</tr>
<tr>
<td>particles</td>
<td>8</td>
<td>277,126,005</td>
<td>0.00%</td>
</tr>
<tr>
<td>eigenValues</td>
<td>7100</td>
<td>628,718,500</td>
<td>0.00%</td>
</tr>
<tr>
<td>heartwall</td>
<td>749,028</td>
<td>121,606,107</td>
<td>0.61%</td>
</tr>
<tr>
<td>mummergpu</td>
<td>11,947,451</td>
<td>53,616,778</td>
<td>22.28%</td>
</tr>
<tr>
<td>tpacf</td>
<td>2,082,509,458</td>
<td>11,724,288,389</td>
<td>17.76%</td>
</tr>
<tr>
<td>Myocyte</td>
<td>205,924</td>
<td>7,893,897</td>
<td>2.61%</td>
</tr>
<tr>
<td>Renderer</td>
<td>462,485,018</td>
<td>279,729,298</td>
<td>84.21%</td>
</tr>
<tr>
<td>mcx</td>
<td>13,928,549,604</td>
<td>20,820,693,588</td>
<td>66.90%</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="section11-1094342011434814">
<title>4.2.2 Performance evaluation of the transformation</title>
<p>In this experiment, we compare the performance of benchmarks listed in <xref ref-type="table" rid="table3-1094342011434814">Table 3</xref> before and after the non-structural to structural transformation to explore its impact. In <xref ref-type="fig" rid="fig15-1094342011434814">Figure 15</xref>, <bold>IPDOM</bold> uses IPDOM to re-converge those unstructured benchmarks, <bold>STRUCT</bold> first applies the proposed transformation and then use IPDOM to re-converge. The performance result shows that <bold>STRUCT</bold> is slightly worse than <bold>IPDOM</bold> due to the execution of static code expansion. The benchmarks such as <italic>mergeSort</italic> have no noticeable difference between two methods since they do not spent much time in unstructured code as shown in <xref ref-type="table" rid="table3-1094342011434814">Table 3</xref> and do not need to apply lots of transformations. <bold>IPDOM</bold> works over 1% better than <bold>STRUCT</bold> for the benchmarks such as <italic>Renderer</italic> since they stayed in the unstructured part longer than the other benchmarks.</p>
<fig id="fig15-1094342011434814" position="float">
<label>Figure 15.</label>
<caption>
<p>Dynamic instruction count before and after the transformation (normalized to IPDOM)</p>
</caption>
<graphic alternate-form-of="fig15-1094342011434814" xlink:href="10.1177_1094342011434814-fig15.tif"/>
</fig>
</sec>
</sec>
</sec>
<sec id="section12-1094342011434814">
<title>5 Related work</title>
<p>SIMD architectures have been designed with basic support for control flow since their large-scale deployment in the 1960s. Since that time, new designs have been incrementally augmented with compiler-assisted hardware support for non-nested and eventually all structured control flow. These designs have culminated in support for all forms of unstructured control flow without any static code expansion since they allow arbitrary branches instead of being restricted to the nested structured control flow. However, to the best of the authors’ knowledge, all schemes employed in existing designs experience dynamic code expansion when executing unstructured control flow. A recently proposed technique, dynamic warp formation, introduced by <xref ref-type="bibr" rid="bibr13-1094342011434814">Fung et al. (2007)</xref> potentially addresses this problem. However, it requires fully associative comparisons across at least all warps on a multi-processor that cannot be feasibly implemented in modern power-limited designs.</p>
<p>ILLIAC IV (<xref ref-type="bibr" rid="bibr3-1094342011434814">Bouknight et al. 1972</xref>), which is in general considered to be the first large-scale SIMD supercomputer, was designed around the concept of a control processor that maintained a series of predicate bits, one for each SIMD lane. Its instruction set could be used to set the predicate bits to implement simple common structured control flow such as if-then-else blocks and loops.</p>
<p>The primary limitation of a single predicate register is its inability to handle programs with nested control flow. In 1982 the CHAP (<xref ref-type="bibr" rid="bibr19-1094342011434814">Levinthal and Porter 1984</xref>) graphics processor introduced the concept of a stack of predicate registers to address this problem. CHAP includes explicit instructions for if, else, endif, do, while statements in the high-level language. This is currently the most popular method of supporting control flow on SIMD processors and is also used by the AMD Evergreen and Intel GEN5 graphics processors.</p>
<p>To support unstructured control flow, a technique referred to as immediate post-dominator re-convergence was developed, which extends the concept of a predicate stack to support programs with arbitrary control flow (<xref ref-type="bibr" rid="bibr13-1094342011434814">Fung et al. 2007</xref>). This is done by finding the immediate post-dominator for all potentially divergent branches and inserting an explicit re-converge instruction. During execution, predicate registers are pushed onto the stack on divergent branches and popped when re-convergence points are hit. In order to resume execution after all paths have reached the post-dominator, the program counter of the warp executing the branch is adjusted to the instruction immediately after the re-converge point.</p>
<p>All of the previous techniques have been implemented in commercial SIMD processors. Dynamic warp formation is a technique originally described by <xref ref-type="bibr" rid="bibr13-1094342011434814">Fung et al. (2007)</xref> that increases the efficiency of immediate post-dominator re-convergence by migrating threads between warps if they are executing the same instruction. This scheme takes advantage of the fact that most programs executed by GPUs are SPMD programs where all threads in all warps begin from the same program entry point. This makes it likely that threads from different warps will be at the same PC in the program at the same time. Fung et al. suggest adding hardware support for detecting this case and dynamically creating a new warp from a pool of threads at the same PC. In cases with where warps have many disabled threads, this can lead to significant performance improvements. However, the power and complexity of the hardware support required to perform fully associative comparisons across active warp PCs every cycle coupled with changes to the register file structure may potentially outweigh the performance advantages. Like post-dominator re-convergence, this scheme supports all program control flow. In the new extension of the dynamic warp formation, Fung et al. propose the concept of Likely-Convergence Points (<xref ref-type="bibr" rid="bibr12-1094342011434814">Fung and Aamodt 2011</xref>), which is basically the probable earlier re-convergence points, without giving a practical approach to find these points. They found speedup when iterating Likely-Convergence Points with IPDOM and their dynamic warp formation framework.</p>
<p>Very recently, <xref ref-type="bibr" rid="bibr6-1094342011434814">Diamos et al. (2011)</xref> for the first time systematically addressed the problem of unstructured control flow in SIMD processors by replacing IPDOM with a technique called <italic>thread frontier</italic>, which includes a static algorithm to find earlier re-convergence points and a hardware framework to let the program re-converge at these points. To get its best performance which is 1.5–633% speedup over IPDOM, their method relies on a specific scheduling order which may not be possible to get statically and custom hardware support. Their findings prove the argument of this work that this is an area worth more attention and research investment.</p>
<p>As to the area of GPU application characterization, <xref ref-type="bibr" rid="bibr17-1094342011434814">Kerr et al (2009)</xref> and <xref ref-type="bibr" rid="bibr14-1094342011434814">Goswami et al. (2010)</xref>, respectively, characterized a large number of GPU benchmarks by using a wide range of metrics covering control flow, data flow, parallelism, and memory behaviors. <xref ref-type="bibr" rid="bibr14-1094342011434814">Goswami et al. (2010)</xref> also researched the similarities between different benchmarks. Their studies are valuable for future GPU compilation and microarchitecture design. Our work differs from theirs in that we target the execution of unstructured control flow in GPUs and provides insight, characterizations, and suggestions for future GPU designs.</p>
</sec>
<sec id="section13-1094342011434814">
<title>6 Conclusions</title>
<p>This work addresses the problem of running arbitrary programs on any GPU device. The current state of practice is not satisfactory since the support of unstructured control flow is very poor. Some GPU devices do not support unstructured control flow at all, while others do not support it efficiently because they will miss the earliest re-converge point. We propose an IR level control flow transformation that can turn an unstructured control flow into a structured one. This transformation is used to characterize the existence of unstructured control flow in a large number of benchmarks. The result verifies the importance of the problem. Further, the transformation is also useful in a dynamic compiler used in heterogeneous systems.</p>
<p>In the future, we focus on automatically finding earliest re-convergence points in an unstructured control flow graph by using different compiler and hardware techniques to improve execution efficiency of arbitrary programs on GPUs. Moreover, we are also considering a structured to unstructured transformation. The motivation of this reverse transformation is that if we have the technique to re-converge at the earliest point, the performance of an unstructured CFG is better than its functionally equivalent structured CFG (see Section 2.3). The process is simple: it continuously finds identical subgraphs and then merges them. The difficulty here is searching identical CFG subgraphs which needs to compare the register name and pointer value of all of the instruction operands.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank Andrew Kerr, Tri Pho and Naila Farooquie for helping us set up the experiments. Tips from the anonymous referees also greatly helped shape this paper.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure" id="fn9-1094342011434814">
<p>This research was supported by the NSF (grant numbers IIP-1032032, CCF-0905459 and OCI-0910735), by LogicBlox Corporation, and equipment grants from NVIDIA Corporation.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<title>Notes</title>
<fn fn-type="other" id="fn6-1094342011434814">
<label>1.</label>
<p>See https://keeneland.gatech.edu/.</p>
</fn>
<fn fn-type="other" id="fn7-1094342011434814">
<label>2.</label>
<p>The immediate post-dominator of a branch in a CFG, informally, is the node through which all paths from the branch pass and which does not post-dominate any other post dominator.</p>
</fn>
<fn fn-type="other" id="fn8-1094342011434814">
<label>3.</label>
<p>See http://users.softlab.ece.ntua.gr/˜ttsiod/.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1094342011434814">
<citation citation-type="book">
<collab collab-type="author">AMD</collab> (<year>2009</year>) <source>Compute Abstraction Layer (CAL) Technology: Intermediate Language (IL)</source>, <edition>2.0 edition</edition>. <publisher-name>AMD Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr2-1094342011434814">
<citation citation-type="book">
<collab collab-type="author">AMD</collab> (<year>2010</year>) <source>Evergreen Family Instruction Set Architecture Instructions and Microcode</source>. <publisher-name>AMD Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr3-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bouknight</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Denenberg</surname>
<given-names>S</given-names>
</name>
<name>
<surname>McIntyre</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Randall</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Sameh</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Slotnick</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>1972</year>) <article-title>The Illiac IV system</article-title>. <source>Proceedings of the IEEE</source>
<volume>60</volume>: <fpage>369</fpage>–<lpage>388</lpage>.</citation>
</ref>
<ref id="bibr4-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Che</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Boyer</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Meng</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Tarjan</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Sheaffer</surname>
<given-names>JW</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>S-H,</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Rodinia: A benchmark suite for heterogeneous computing</article-title>. In <source>IEEE International Symposium on Workload Characterization, 2009 (IISWC 2009)</source>, vol. <volume>9</volume>, pp. <fpage>44</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr5-1094342011434814">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cooper</surname>
<given-names>KD</given-names>
</name>
<name>
<surname>Harvey</surname>
<given-names>TJ</given-names>
</name>
<name>
<surname>Kennedy</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>2001</year>) <source>A Simple, Fast Dominance Algorithm</source>. <comment>Technical report</comment>.</citation>
</ref>
<ref id="bibr6-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Diamos</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Ashbaugh</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Maiyuran</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Kerr</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Yalamanchili</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>SIMD re-convergence at thread frontiers</article-title>. In <source>Proceedings of the 44th Annual International Symposium on Microarchitecture</source>.</citation>
</ref>
<ref id="bibr7-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Diamos</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Kerr</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Yalamanchili</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Clark</surname>
<given-names>N</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Ocelot: A dynamic compiler for bulk-synchronous applications in heterogeneous systems</article-title>. In <source>Proceedings of PACT’10</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>, pp. <fpage>353</fpage>–<lpage>364</lpage>.</citation>
</ref>
<ref id="bibr8-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dominguez</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Schaa</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Kaeli</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Caracal: Dynamic translation of runtime environments for gpus</article-title>. In <source>Proceedings of the Fourth Workshop on General Purpose Processing on Graphics Processing Units</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>ACM Press</publisher-name>, pp. <fpage>5</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr9-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fang</surname>
<given-names>Q</given-names>
</name>
<name>
<surname>Boas</surname>
<given-names>D</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Monte Carlo simulation of photon migration in 3D turbid media accelerated by graphics processing units</article-title>. <source>Optics express</source>
<volume>17</volume>: <fpage>20178</fpage>–<lpage>20190</lpage>.</citation>
</ref>
<ref id="bibr10-1094342011434814">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Fernando</surname>
<given-names>R</given-names>
</name>
</person-group> (<year>2004</year>) <source>GPU Gems: Programming Techniques, Tips and Tricks for Real-Time Graphics</source>. <publisher-name>Pearson Higher Education</publisher-name>.</citation>
</ref>
<ref id="bibr11-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ferrante</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Ottenstein</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Warren</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1987</year>) <article-title>The program dependence graph and its use in optimization</article-title>. <source>ACM Transactions on Programming Languages and Systems</source>
<volume>9</volume>: <fpage>319</fpage>–<lpage>349</lpage>.</citation>
</ref>
<ref id="bibr12-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fung</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Aamodt</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>Thread block compaction for efficient simt control flow</article-title>. In <comment>2011</comment>
<source>IEEE 17th International Symposium on High Performance Computer Architecture (HPCA)</source>. <comment>IEEE</comment>, pp. <fpage>25</fpage>–<lpage>36</lpage>.</citation>
</ref>
<ref id="bibr13-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fung</surname>
<given-names>WWL</given-names>
</name>
<name>
<surname>Sham</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Yuan</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Aamodt</surname>
<given-names>TM</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Dynamic warp formation and scheduling for efficient GPU control flow</article-title>. In <source>MICRO’07: Proceedings of the 40th Annual IEEE/ACM International Symposium on Microarchitecture</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE Computer Society</publisher-name>, pp. <fpage>407</fpage>–<lpage>420</lpage>.</citation>
</ref>
<ref id="bibr14-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Goswami</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Shankar</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Joshi</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Exploring GPGPU workloads: Characterization methodology, analysis and microarchitecture evaluation implications</article-title>. In <comment>2010</comment>
<source>IEEE International Symposium on Workload Characterization (IISWC)</source>. IEEE, pp. <fpage>1</fpage>–<lpage>10</lpage>.</citation>
</ref>
<ref id="bibr15-1094342011434814">
<citation citation-type="web">
<collab collab-type="web">Impact Research Group</collab> (<year>2009</year>) <article-title>Parboil benchmark suite</article-title>. <ext-link ext-link-type="uri" xlink:href="http://impact.crhc.illinois.edu/parboil.php">http://impact.crhc.illinois.edu/parboil.php</ext-link>.</citation>
</ref>
<ref id="bibr16-1094342011434814">
<citation citation-type="book">
<collab collab-type="author">Intel</collab> (<year>2009</year>) <source>Intel G35 Express Chipset Graphics Controller Programmers Reference Manual</source>.</citation>
</ref>
<ref id="bibr17-1094342011434814">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kerr</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Diamos</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Yalamanchili</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>A characterization and analysis of PTX kernels</article-title>.</citation>
</ref>
<ref id="bibr18-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lattner</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Adve</surname>
<given-names>V</given-names>
</name>
</person-group> (<year>2004</year>) <article-title>LLVM: A compilation framework for lifelong program analysis and transformation</article-title>. In <source>Proceedings of the 2004 International Symposium on Code Generation and Optimization</source>, pp. <fpage>75</fpage>–<lpage>86</lpage>.</citation>
</ref>
<ref id="bibr19-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Levinthal</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Porter</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>1984</year>) <article-title>Chap - a SIMD graphics processor</article-title>. <source>SIGGRAPH Computer Graphics</source>
<volume>18</volume>(<issue>3</issue>): <fpage>77</fpage>–<lpage>82</lpage>.</citation>
</ref>
<ref id="bibr20-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Matsuoka</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>The road to TSUBAME and beyond</article-title>. In <source>High Performance Computing on Vector Systems</source>
<comment>2007</comment>, pp. <fpage>265</fpage>–<lpage>267</lpage>.</citation>
</ref>
<ref id="bibr21-1094342011434814">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Muchnick</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>1997</year>) <source>Advanced Compiler Design Implementation</source>. <publisher-name>Morgan Kaufmann Publishers</publisher-name>.</citation>
</ref>
<ref id="bibr22-1094342011434814">
<citation citation-type="book">
<collab collab-type="author">NVIDIA</collab> (<year>2009</year>) <source>NVIDIA Compute PTX: Parallel Thread Execution</source>,
<edition>2.1 edition</edition>. <publisher-loc>Santa Clara, CA</publisher-loc>: <publisher-name>NVIDIA Corporation</publisher-name>.</citation>
</ref>
<ref id="bibr23-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Parker</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Bigler</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Dietrich</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Friedrich</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Hoberock</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Luebke</surname>
<given-names>D</given-names>
</name>
<etal/>
</person-group>. (<year>2010</year>) <article-title>OptiX: a general purpose ray tracing engine</article-title>. <source>ACM Transactions on Graphics</source>
<volume>29</volume>(<issue>4</issue>): <fpage>1</fpage>–<lpage>13</lpage>.</citation>
</ref>
<ref id="bibr24-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rixner</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Dally</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Kapasi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Khailany</surname>
<given-names>B</given-names>
</name>
<name>
<surname>López-Lagunas</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mattson</surname>
<given-names>P</given-names>
</name>
<etal/>
</person-group>. (<year>1998</year>) <article-title>A bandwidth-efficient architecture for media processing</article-title>. In <source>Proceedings of the 31st Annual International Symposium on Microarchitecture</source>. <publisher-loc>Los Alamitos, CA</publisher-loc>: <publisher-name>IEEE Computer Society Press</publisher-name>, pp. <fpage>3</fpage>–<lpage>13</lpage>.</citation>
</ref>
<ref id="bibr25-1094342011434814">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>F</given-names>
</name>
<name>
<surname>D’Hollander</surname>
<given-names>EH</given-names>
</name>
</person-group> (<year>2004</year>) <article-title>Using hammock graphs to structure programs</article-title>. <source>IEEE Transactions on Software Engineering</source>
<volume>XX</volume>: <fpage>231</fpage>–<lpage>245</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>