<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="EN">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TCS</journal-id>
<journal-id journal-id-type="hwp">sptcs</journal-id>
<journal-title>Theory, Culture &amp; Society</journal-title>
<issn pub-type="ppub">0263-2764</issn>
<issn pub-type="epub">1460-3616</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0263276413476558</article-id>
<article-id pub-id-type="publisher-id">10.1177_0263276413476558</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Living Multiples: How Large-scale Scientific Data-mining Pursues Identity and Differences</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Mackenzie</surname><given-names>Adrian</given-names></name>
</contrib>
<aff id="aff1-0263276413476558">Lancaster University, UK</aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>McNally</surname><given-names>Ruth</given-names></name>
</contrib>
<aff id="aff2-0263276413476558">Anglia Ruskin University, UK</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0263276413476558">Adrian Mackenzie, Lancaster University, Lancaster LA1 4YL, UK. Email: <email>a.mackenzie@lancaster.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>30</volume>
<issue>4</issue>
<issue-title>Special issue on The Social Life of Methods Edited by Evelyn Ruppert, John Law and Mike Savage</issue-title>
<fpage>72</fpage>
<lpage>91</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="society">Theory, Culture &amp; Society Ltd.</copyright-holder>
</permissions>
<abstract>
<p>This article responds to two problems confronting social and human sciences: how to relate to digital data, inasmuch as it challenges established social science methods; and how to relate to life sciences, insofar as they produce knowledge that impinges on our own ways of knowing. In a case study of proteomics, we explore how digital devices grapple with large-scale multiples – of molecules, databases, machines and people. We analyse one particular visual device, a cluster-heatmap, produced by scientists by mining data from a large number of experiments on human blood plasma proteins. These proteins make up a myriad multiple whose identity shifts in many ways. Rather than displaying data about proteins, the heatmap constructs a view of the differences and similarities between experiments. We find this attempt to construct a view on many things at once instructive in thinking about multiples more generally. Instead of flattening molecular ‘life itself’, this visual device superimposes layers of digital devices and techniques from a wide variety of disciplines. This layering suggests a different way of relating to the life sciences more generally: rather than <italic>what</italic> they know, <italic>how</italic> they know might be of use to social and human sciences when attending to multiplicities.</p>
</abstract>
<kwd-group>
<kwd>digital device</kwd>
<kwd>life</kwd>
<kwd>method</kwd>
<kwd>multiple</kwd>
<kwd>visualization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p><disp-quote>
<p>There are many ways to recount the history of the sciences, and to ground the politics of the future on them. What I am proposing puts the emphasis on the event, the risk, the proliferation of practices. (<xref ref-type="bibr" rid="bibr22-0263276413476558">Stengers, 2000</xref>: 114)</p></disp-quote>Over the last five decades, a stunning variety of claims have been made for the transformative power of digital ways of imaging, sorting, networking, communicating, recording, retrieving, calculating and controlling. Until fairly recently, these claims have less often been voiced as a problem of method for the social and human sciences. But in recent years, a more concerted attempt to regard digital devices in terms of method has appeared (<xref ref-type="bibr" rid="bibr10-0263276413476558">Latour et al., 2012</xref>; <xref ref-type="bibr" rid="bibr18-0263276413476558">Rogers, 2004</xref>; <xref ref-type="bibr" rid="bibr21-0263276413476558">Savage and Burrows, 2007</xref>). In this literature, digital devices no longer flatten or reduce lives. Rather, digital devices proliferate circuits, they set up competing and cross-cutting scales of knowing, relating and responding, and they expose fresh margins of indeterminacy in the ensembles of people, machines, lives and things we inhabit. Digital devices, they imply, can lend themselves to a multiplicative stance on the real. Digital devices <italic>thicken</italic> as well as <italic>flatten</italic> worlds.</p>
<p>In their encounter with forms of the multiple they provoke us to re-envisage <italic>the act of describing</italic> multiples. Anne-Marie <xref ref-type="bibr" rid="bibr13-0263276413476558">Mol (2002</xref>: 6) writes:<disp-quote>
<p>if it is not removed from the practices that sustain it, reality is multiple. This may be read as a description that beautifully fits the facts. But attending to the multiplicity of reality is also an <italic>act</italic>. It is something that may be done – or left undone.</p></disp-quote>It is easier to describe multiples in some places rather than others. While artwork or media events are obvious places, we focus on a case that is both easier and harder: contemporary ‘omic’-style biology, with its connotations of addressing the whole or total complement of parts of an organism. Scientists are often avid proponents of digital devices in their experimental work (e.g. Berners-Lee’s WWW protocol in nuclear physics; the CCD optical sensor and the Hubble Space Telescope; the Human Genome Project and its massive sequence alignment and whole genome assembly software, etc.). This optimism about digital devices and their ability to apprehend the whole or totality pervades genomic biology. This article conducts an archaeology of a single diagram produced in 2007 by scientists working in the field of proteomics. Like many contemporary ‘big data’ knowledge enterprises, proteomics – the study of the whole complement of proteins in an organism, its proteome – is characterized by a proliferation of information, data, electronic instruments, publications, databases, software and standards, all of which endeavour to federate large-scale aggregates of experimental information about the myriad species of proteins into forms that can be interrogated, queried, explored, mined, distilled, abstracted and displayed. Scientists have an intense experiential investment in the agency of experimental methods of knowing. Although they might not adopt the same terminology, they also from time to time construct visual devices that seek to make that agency explicit. The question for us is what we can learn from their attempts to do this.</p>
<p>We have a specific interest in focusing on a protein-related digital device. The social and human sciences are meant to be engaging with life sciences (<xref ref-type="bibr" rid="bibr20-0263276413476558">Rose, 2013</xref>). Although it is a relatively obscure component of biodigital life, proteomics work on proteins can be seen as forming part of the molecularization of life. Proteins epitomize biomolecularization. If, as Nikolas <xref ref-type="bibr" rid="bibr19-0263276413476558">Rose (2006</xref>: 13) writes, ‘the laboratory has become a kind of factory for the creation of new forms of molecular life. And in doing so, it is fabricating a new understanding of life itself’, it would be important to assay what forms of life proteins find themselves in. If the human and social sciences are to take an affirmative stance in relation to life sciences and their increasingly dynamic understandings of lives, then we need to identify and explore ways of relating to those understandings in situ. This is an extremely challenging problem, and one that many sociologists, philosophers, anthropologists and geographers have been addressing. Here we focus on one slender, but arguably indispensable, thread: the ways in which biological molecules such as proteins find themselves amid much more general problematization of multiples, aggregates and groupings taking place in association with digital devices. Proteins participate in increasing numbers in myriad multiples assembled through digital devices. Rather than proteins per se, it may be the problem of their multiplicity that will really exercise social and cultural knowing.</p>
<p>The increase in number can be seen by starting from a canonical science studies laboratory study. In <italic>Laboratory Life</italic>, <xref ref-type="bibr" rid="bibr9-0263276413476558">Bruno Latour and Steven Woolgar (1986)</xref> described the laboratory of the Nobel prize-winning protein scientist Roger Guillemin during the 1970s. They describe a dispute over a single substance that was ultimately resolved as a fragment of a protein called a peptide. In the late 1960s, a turning point in the dispute occurred when Guillemin’s lab invented a way to analyse the amino acid sequence of the disputed peptide using a mass spectrometer. Borrowing the physicists’ treatment of matter in terms of mass, charge and kinetics, the introduction of mass spectrometry into the biology laboratory not only decisively ended the dispute in hand, but began the displacement of the ‘softer’ and slower bioassay as the standard of proof for the discovery of novel peptides. As a result, the ultimate proof of existence for proteins shifted from the bioassay demonstration of their physiological effect in a living system to the demonstration of their molecular structure as a sequence of amino acids. The protein was molecularized.</p>
<p>Guillemin’s laboratory exemplified an era in which a scientist or research group conducted in-depth analysis of one particular biological entity, or class of such entities, at a time. A single protein could preoccupy a laboratory in the 1960s and 1970s. In contrast to the oneness of <italic>Laboratory Life</italic>, contemporary work on proteins often highlights uncertain numbers of proteins. The precise numbers, types and interactions of proteins in a single human tissue, blood plasma, are hard to ascertain, yet genomic biology is predicated on grasping the whole. The visual device we are going to discuss is itself an experiment in comparing experimental methods of finding proteins in order to see why the numbers of proteins in one myriad multiple – the human blood plasma proteome – keep shifting. In pursuit of identity in the multiple, it superimposes many digital devices from laboratories, from databases, from fields of information retrieval, library science, sociology, archaeology, matrix geometry, statistics, data-mining and data analysis on a single visual plane. It overlaps and interweaves techniques of categorizing, clustering, scoring and algebraic transformations.</p>
<p>What is at stake in superimposing so much on one flattened figure? While an overwhelming sense of flatness remains, closer examination reveals an intricate meshwork of techniques and devices. In later parts of this discussion, it will be necessary to introduce some of the technical detail in order to understand how the superimposition occurs. In asking our readers to bear with these technical details, we are arguing that scientific attempts to grapple with large multiples are instructive in the twists, conjunctions, tweaks and modifications they stage. In the encounter between digital methods and the manifold, fluxing multiples of proteins, there are singular instabilities and serialized erosion of forms of ontological identity. The visual device itself is an attempt to stabilize not proteins themselves (to which it has no direct access), but the multiple experiments undertaken to find out how many proteins are in blood plasma. Hence this visualization is a partially stratified archaeological site of previous experimental activity. As Gabriele <xref ref-type="bibr" rid="bibr23-0263276413476558">Tarde (1999</xref>: 34) writes: ‘in any sufficiently prolonged evolution, we observe a succession and interlacing of phenomenal levels remarkable for regularity and caprice, for the permanence and fugacity, of the relations they present to us’. It will be hard to decide, in analysing this visual device, what is due to regularity and what is due to difference, what is durable and what is transient, and indeed, what comes from proteins and what comes from us. We don’t know well enough the multiples of proteins and humans in the making in proteomics and other such fields. Techniques and methods meant to epitomize the potential for regularity and indeed for identity can just as well produce new genres of difference and variation. Everywhere today, not just in natural or social sciences, techniques are invented in the struggle to track or extract forms of identity, regularity or pattern that we are not able to see, make or say directly or immediately. The intensification of digital methods in the pursuit of identity <italic>multiplies</italic> methods. The consequence of this interlaced variation is that as we aspire to say something about life – collective, biological, social, psychological, organic or even inorganic – we often end up saying things about techniques. This indeed is one our key arguments – any attempt to enumerate multiples also multiplies methods of enumeration. Digital devices endemically fold together different techniques of knowing and acting. In a sense, what we might hope to learn by following the tortuous technical details of a single scientific visual device is how to better countenance worlds made through the superimposition of different repetitions, aggregate worlds artificed in encounters with myriad multiples, worlds whose performative excesses undo or <italic>unmake</italic> identities as much as they make them.</p>
<sec id="sec1-0263276413476558"><title>The Figure in Question</title>
<p>There are particular challenges in making this point through scientific digital devices. Arguing for the singularity of modern experimental sciences, and the provocation they pose to philosophical thought, philosopher of science Isabelle Stengers writes that<disp-quote>
<p>the scope of the [experimental] event is part of its effects, of the problem posed in the future it creates. Its measure is the object of multiple interpretations, but it can be measured by the very multiplicity of these interpretations. (<xref ref-type="bibr" rid="bibr22-0263276413476558">Stengers 2000</xref>: 67)</p></disp-quote>Can we see a cluster-heatmap of ‘experimental similiarity matrix’ as such an event (of which our reading would be another interpretation)? In other words, do experimental settings have an evental capacity that social and cultural theory can also draw on?</p>
<p>The visual device we analyse appeared in an article published in the <italic>Journal of Proteome Research</italic> in 2007 (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>). The article is entitled ‘Analyzing large-scale proteomics projects with latent semantic indexing’, and it describes how the authors brought various data exploration and data-mining techniques to bear on the results of a large number of experiments carried out by a global scientific consortium focused on the human blood plasma. Visual devices in the article include equations, tables, histograms, Venn diagrams, and then, most significantly, two half-page visualizations entitled ‘experiment similarity matrix’ (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: 186–7). These two graphics are central to the article. By all appearances, they are what are called ‘heatmaps’. Paying attention to some of the details of the operations carried out in making these heatmaps, we learn something about the ‘interlacing of phenomenal levels’ even in the flattest of digital devices.</p>
<p>One of these visualizations – the figure in question – is shown in <xref ref-type="fig" rid="fig1-0263276413476558">Figure 1</xref>. This figure attempts to bring to light the relationships between various human blood plasma protein datasets in terms of the proteins found, the laboratory techniques and experimental apparatus used, and the software and databases used to analyse the experimental data. All of these data about the making of data via digital and non-digital techniques are placed on the map. Problems of retrievability, exactitude, hidden patterns, and the dynamics of global scientific assemblages interlace with profiles of the proteins themselves. Why bring these techniques and problems in the conduct of techniques together graphically?
<fig id="fig1-0263276413476558" position="float"><label>Figure 1.</label><caption><p>A visualization of the protein-based experiment similarity matrix.</p>
<p><italic>Source</italic>: <xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al. (2007</xref>: Figure 3).</p></caption><graphic xlink:href="10.1177_0263276413476558-fig1.tif"/>
</fig></p>
<p>The field of proteomics came into being through recognition of the problems of dealing with many molecules. The molecularization of life yields many, many proteins. More numerous, heterogeneous and labile than genes or DNA, proteins are exquisitely sensitive to their surrounding environment, changing their molecular constitution, shape and function in response to their immediate milieu. In exceptional numbers and variety, proteins populate living things in the form of enzymes, hormones, structural molecules and antibodies. An organism’s proteome – its full complement of proteins – varies from youth to old age, from cell type to cell type, and between healthy and diseased tissue. Over a lifetime and even at any point in time, an organism contains not one but many proteomes. If there is a human genome, there are many human proteomes, and each proteome is a population of proteins (<xref ref-type="bibr" rid="bibr25-0263276413476558">Twyman, 2004</xref>). It is hard to know, name and number the proteins in a proteome. From this perspective, proteins are particularly provocative entities in thinking about how we encounter multiples.</p>
<p>As biomolecules, proteins have a certain contemporary theoretical resonance we wish to highlight. In the wake of ANT (Actor Network Theory), OOO (Object Oriented Ontology) (<xref ref-type="bibr" rid="bibr8-0263276413476558">LarvalSubjects, 2012</xref>), and a generally resurgent interest in materialities and vitalities (<xref ref-type="bibr" rid="bibr2-0263276413476558">Bennett, 2009</xref>) or post-biopolitical life (<xref ref-type="bibr" rid="bibr16-0263276413476558">Rabinow and Rose, 2003</xref>), we can begin to recognize proteins as fully fledged ontological forms. But this general recognition does not tell us much about the sociality of molecules, their specific propensity to associate, to aggregate and to enter into relations of possession. The sociality of proteins, Gabriel Tarde suggests, is just as active as ours. ‘Why’, Tarde asks, ‘would a molecule not be just as much a society as a plant or animal?’ (<xref ref-type="bibr" rid="bibr23-0263276413476558">Tarde, 1999</xref>: 24). In terms of <xref ref-type="bibr" rid="bibr23-0263276413476558">Tarde’s ‘universal psychomorphism’ (1999</xref>: 12), a protein is just as social as a plant, animal or indeed a human society because it has the tendencies to associate, to possess or appropriate other molecules just as plants, animals or a state have in relation to their associated milieus. The abundance of proteins in living things should not, according to Tarde, lead us to believe that there is something fundamentally stable or even particularly ontologically solid about proteins. Just the opposite: if proteins do display some kind of stability or defining identity, this should be surprising: ‘identity is only a minimum, and consequently a species, an infinitely rare species, of difference’ (<xref ref-type="bibr" rid="bibr23-0263276413476558">Tarde, 1999</xref>: 33). Viewed from this perspective, what we are seeing in Klie et al.’s heatmaps are the diffracted rays of many attempts and efforts on the part of people, proteins and other things to associate in many ways – biologically, mathematically, institutionally, infrastructurally, machinically, etc.</p>
<p>While social theory, piggybacking on science, can recognize protein sociality, it cannot possibly absorb all the specificities of proteins acting out as hormones, enzymes, antibodies, in plasma, in membranes, in fibres such as hair or skin, etc. If proteomics scientists manage to develop methods of sorting, classifying, and visualizing proteins in all their specificities, what do we take from that? In Tarde’s terms, proteomics is a way of ‘having’ proteins and being possessed by proteins. But we don’t need to be possessed by proteins ourselves in the same way as the proteomics researchers in order to find their ways of having and being possessed by proteins instructive.</p>
</sec>
<sec id="sec2-0263276413476558"><title>Is This a Heatmap?</title>
<p>The heatmap in <xref ref-type="fig" rid="fig1-0263276413476558">Figure 1</xref> presents a central grid of many finely demarcated squares or tiles of varying grey-scale shades and sizes, and 10 larger clusters of darker tiles running along the diagonal. The latter are labelled with large Roman numerals (I–X). Along the top, left and bottom edges are many names and acronyms (2d gel, esi-ion, etc.). This genre of diagram, the cluster-heatmap, has been heavily used in biological and medical research for more than a decade as a way of detecting and displaying patterns of similarity between numerous measurements produced by the increasingly automated and digitized laboratory instruments of contemporary biology. Heatmaps are now so widely used by biologists that a recent review of the visualization of data in post-genomic biology observes:<disp-quote>
<p>by far the most popular graphical representation has been the ‘clustered heat map’, which compacts large amounts of information into a small space to bring out coherent patterns in the data. (<xref ref-type="bibr" rid="bibr26-0263276413476558">Weinstein, 2008</xref>: 1772)</p></disp-quote>From the mid 1990s on, brightly coloured heatmaps populated the pages of scientific publications, as biologists sought to display different patterns of gene activity, drug response and protein levels across different cell-lines, different tissues or at different times in the same cell (<xref ref-type="bibr" rid="bibr5-0263276413476558">Eisen et al., 1998</xref>; <xref ref-type="bibr" rid="bibr27-0263276413476558">Weinstein et al., 1997</xref>). The adoption by many biologists of the heatmap as a primary way of trying to not only display but also make sense of biological data is a striking development in the cultural life of data, for the heatmap is a layered and contingent visual form.</p>
<p>As a way of tabulating and comparing data, heatmaps can be traced back to 19th-century statistics. As sociologists sought to display distributions of social statistics across cities such as Paris (<xref ref-type="bibr" rid="bibr28-0263276413476558">Wilkinson and Friendly, 2009</xref>), they coloured the cells of tables to reflect values or categories. In the early 20th century, the Egyptologist William Mathew Flinders Petrie developed a method – ‘seriation’ – for ordering a data matrix so that the diagonal conveyed a temporal ordering of large numbers of excavated artefacts. Taken up by anthropologists and archaeologists, the data matrix was statistically formalized in the mid 20th century, and used in a variety of social and natural sciences, as well as operational settings (for instance, in social science, the American-Israeli sociologist Louis Guttman’s ‘Scalogram’ was widely used). In the 1980s and 1990s, the ‘cluster-heatmap’ took its current shape, supported by the SYSTAT software developed initially by the University of Chicago statistician Leland Wilkinson (SYSTAT was later incorporated into the standard social scientific statistical software package, SPSS). The key contribution of statisticians of clustering methods to the sociological-anthropological graphic allowed the heatmap to show patterns, particularly when viewed on multi-colour computer screens.</p>
<p>In these various incarnations, and as it moves across disciplines and applications ranging from sociology to biology, what does this visual device do? While it is called a ‘map’, there is little reference to terrestrial cartography in this device apart from the grid-lines. The most striking visual feature displayed in the diagrams in Klie et al. is the enlarged diagonals. Although not all heatmaps have diagonals, they nearly always highlight some linear order of that kind. (In Petrie’s ordering of Egyptian pottery, for instance, the diagonal represented the most likely chronology.) While a mosaic of colours can be striking or interesting to the eye, the dominant visual forms of the diagonal or the line are crucial in the popularity of heatmaps in biology. Without the diagonal form, the heatmaps show less. We would only be able to see a complex field of differences, whose underlying regularities would remain latent. A heatmap only begins to configure a multiple when some linear figure flashes out of the flattened field.</p>
<p>In order to begin to appreciate the genesis of these diagonals, we need to know a bit more about the data shown in Klie et al.’s ‘experimental similarity matrix’. The multi-toned tiled grid displays something of the relation between the data produced by many different experiments carried out in laboratories around the world working on human blood plasma proteins. Each of the small tiles that dot this grid conveys a measure of similarity between the results of two experiments. On this heatmap any experiment can be compared to any other. The darker the colour of a particular tile, the greater the similarity between the experiments it compares. In both of Klie et al.’s heatmap diagrams (second one not shown here), there is a solid black diagonal line. The thin central diagonal reflects that every experiment is by definition identical with itself. But around this necessary diagonal, larger groups of lesser identity can be found in both diagrams. These zones where the diagonal widens onto groups labelled I, II, III, IV, etc. are key points of interest on the heatmap, for they suggest the existence of forms of identity. The tiles clustered at various points around the diagonals could be seen as one of the principal findings of this article. Without them, the heatmap would look much more scattered. Yet these hotspots do not just appear from the data. The patterns have to be made to appear.</p>
<p>A glance at the diagrams in Klie et al. shows that not only are they tiled grids, but that these tiles are surrounded by less obvious but no less important groupings of the data along the axes. The clusters along the axes are actually just as powerful organizations of the data as the tiled area that dominates the visual space. When heatmaps began appearing in biological publications in the mid 1990s, this clustering of the rows and columns of the heatmap was described much more explicitly. For instance, an article (<xref ref-type="bibr" rid="bibr27-0263276413476558">Weinstein et al., 1997</xref>) from the US National Cancer Institute is cited as one of the first uses of heatmaps in biology. They used heatmaps to detect correlations between data on anti-cancer drug candidates and targets in a range of cell-lines. They write that ‘the rows and columns of the product matrix were rearranged into “cluster order.” Only with this last step did patterns emerge’ (<xref ref-type="bibr" rid="bibr27-0263276413476558">Weinstein et al., 1997</xref>: xx). It is the combination of clustering techniques with the comparison embodied in the data matrix that permits patterns to be discovered. In the proteomics paper, if the experiments were compared in, say, the order that they were found in the database, it is doubtful that any meaningful pattern would appear. The labels on the axes of the heatmaps in Klie et al. indicate that another statistical technique, <italic>hierarchical clustering</italic>, has been applied as a way of reordering the rows and columns so that order becomes discernible. Like the heatmap itself, albeit in a more fine-grained way, the now standard data-mining technique of hierarchical clustering (<xref ref-type="bibr" rid="bibr6-0263276413476558">Hastie et al., 2009</xref>) has been used to sort the different experiments into groups related by their results.</p>
</sec>
<sec id="sec3-0263276413476558"><title>A Matrix of Laboratory Life Today?</title>
<p>The labels and text that are clustered on the margins of the figure (<xref ref-type="fig" rid="fig1-0263276413476558">Figure 1</xref>), along its axes, refer to practices, instruments and data-processing devices used in the laboratories life of protein scientists today. They are the proteomics response to the problems of getting to know proteins. The top margin lists protocols for preparing the proteins in the samples. Along the left margin are various types and models of mass spectrometer, the instruments used to analyse ionized fragments of them. Those clustered along the bottom margin belong to specialized search engines that re-associate these fragments with whole proteins in reference databases.</p>
<p>This ensemble of techniques, instruments, search engines and databases is part of the attempt to profile the seething complement of proteins in various ways: chemically, physically and comparatively. For instance, 2d gel, a technology for separating chemicals, was recruited for the large-scale study of proteins during the 1970s and 1980s (<xref ref-type="bibr" rid="bibr17-0263276413476558">Righetti, 2004</xref>). The list of mass spectrometers along the left-hand axis reflects the embrace of physical methods for the large-scale analysis of proteins since the 1990s. Along the bottom boundary of the figure, digital methods <italic>sensu stricto</italic> are ranged. In 1993 and 1994, a cluster of seven scientific papers published algorithms that could relate mass spectra with known molecules in reference databases (<xref ref-type="bibr" rid="bibr15-0263276413476558">Patterson and Aebersold, 2003</xref>). Such algorithms perform the comparative operations of the search engines, such as Mascot and Sequest, that appear along the bottom axis of the figure.</p>
<p>Proteomics is both etymologically and organizationally modelled on genomics. Like genomics’ treatment of genes, proteomics takes an ‘-omic’ approach to proteins. The ‘-omic’ suffix connotes an attempt to grasp the multiple, fluxing entirety of a collection of things. However, there is no direct encounter with the living mass of proteins. Mass spectrometry proteomics samples populations all the way down. Being very large molecules, proteins must be broken down into peptides before they enter the mass spectrometers. The data generated is a mass spectrum, a statistically sampled measure of the peptide population. At each stage just a sample of the population of entities in the previous sample is analysed. Like so many other knowledge practices of the last two centuries, proteomics takes a statistical approach to its objects. That is the very meaning of the ‘-omic’ suffix. This treatment of wholeness is seriously and irreducibly sampled and inferential on multiple levels.</p>
<p>The specific names and labels running around the figure were taken from the methods and instruments used to produce protein datasets by 95 experiments deposited in PRIDE, a digital repository for proteomics data. The datasets were from the Plasma Proteome Project, an international collaboration to identify the proteins in human plasma. The immediate concern of Klie et al. was that these and other such datasets were not being used. One reason for this neglect was the many differences in their provenance: differences in how the samples were prepared and in the instruments used for the mass spectrometry; differences in the statistical inference algorithms built into the search engines. What was the value in having these datasets together in a repository if they were too different?</p>
<p>Hence, the first question Klie et al. asked was: ‘How similar are these datasets to each other?’ We might think that proteomics experiments on the same tissue will find more or less the same proteins. Actually, in the Plasma Proteome Project no single protein was seen in every experiment and even the same lab could not replicate its own results with the same sample. As the Plasma Proteome Project’s leading scientist notes:<disp-quote>
<p>the inherent limitations of incomplete sampling of peptides by mass spectrometry and potentially high error rates of peptide identifications and protein assignments with various search algorithms and databases lead to low concordance of protein identifications even with repeat analyses of the same sample … [T]he same specimen in the same lab typically has no more than 40 to 50 per cent concordance on repeat analysis. (<xref ref-type="bibr" rid="bibr14-0263276413476558">Omenn, 2005</xref>: 3223–5)</p></disp-quote>Identity is a rare species in proteomics. We could attribute this to the mass spectrometer. While a mass spectrometer identifies many proteins, it does not see any of them directly. Rather it ‘detects’ them forensically, based on circumstantial evidence. A mass spectrometer is like a security camera trying to identify everybody as they pass by in a crowd. It is impossible to capture the image of every individual, so only a sample is analysed, and only little fragments of each individual in the sample are scrutinized in detail. In this post-biological, post-chemical environment of the mass spectrometer, protein fragments are known as bundles of mass and electrical charge. From these forensic data traces, the identities of particular proteins are reconstructed by search engines trawling reference databases for likely candidates. Like pieces from a jigsaw puzzle, the tiny fragments could have belonged to this protein or that one, or maybe a different one altogether, it is not always possible to say with confidence. Much that takes place in this identification of proteins is probabilistic. An ‘inherent ambiguity’ afflicts mass spectrometry proteomics (<xref ref-type="bibr" rid="bibr12-0263276413476558">Martens and Hermjakob, 2007</xref>). The probabilistic character of any protein identification is ineluctable.</p>
<p>The second question Klie et al. asked, however, is actually much more provocative for our purposes. They ask: ‘How similar are the experiments that produced these datasets to each other?’ When this analysis was done striking patterns, visualized in the figure (<xref ref-type="fig" rid="fig1-0263276413476558">Figure 1</xref>), ‘were revealed’ (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: 183). One of the largest and blackest clusters, signifying where the findings – the proteins discovered – are most similar, is Cluster VI. All of the experiments in this cluster used the same separation method (2d gel), the same type of mass spectrometer (maldi) and the same search engine (mascot). Cluster VII, even blacker, differs in that it used an additional sample preparation method (top6). The gap between these two clusters, an expression of their dissimilarity, illustrates how a change in experimental practice finds an almost completely different part of the plasma proteome. Reconfigurations – different mass spectrometers, different search engines, different sample preparation and separation protocols – assemble different proteins.</p>
<p>Something else is immanent in this figure. Implicit in, though not fully explained nor accounted for by the instruments and procedures inscribed along the axes, is the reconstitution of laboratory life. If we compare Cluster 1 with Cluster VI, the gap between these clusters suggests dissimilar datasets. Yet according to the axes, the experiments that created them (2d gel, maldi, mascot) were identical. What explains this difference is that they come from different laboratories.</p>
<p>By recontextualizing the datasets, and arranging them in relation to how they were produced, Klie et al. figure the proteomics data in relation to multiple laboratories. Moreover, in the midst of the heterogeneity, they point to limited versions of identity, zones of partial data consensus, clustered by association with particular instruments, and search engines and sample protocols, and even individual laboratories. The experimental similarity matrix graphically displays how local performance of methods affects data production, yet at the same time shows that localities partially overlap.</p>
</sec>
<sec id="sec4-0263276413476558"><title>The Heatmap as Matrix of Methods</title>
<p>We begin to see what strangely encrusted and composite entities these visual devices are. Rather than flatly display data about something in the world, they turn methods for producing data about proteins into data about how proteins are known. Rather than furnishing meta-data, the heatmap, and the data workflow that precedes it, proliferate methods in trying to see what destabilizes the identity of proteins. How have the authors managed to make the heatmaps into a mirror of methods in their own field of research? In order to answer this question, we need to turn away from the margins of the visual devices, and move back into the grid of tiles. This grid, or more accurately this matrix, the numerically intensive part of the visual device, is filled with numbers. How does the flat space of the matrix accommodate the avalanche of numbers generated by the mass spectrometers? Like many others today, the authors have ready access to experimental datasets produced by instruments and deposited in databases. This data is itself no less multiple than proteins in the proteomes. They construct visual devices in order to reactivate from the sediment of digital data something of the animated, diverse sociality of proteins. This desire to reactivate data is widespread, and Klie et al. are not alone in wanting to show that ‘far from being places where data goes to die’ (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: 190), such data collections can be mined for valuable information that could not be obtained in any other way. They looked for information that ‘lies hidden’ in large bodies of data (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: 182). What can be done with so many datasets? What kinds of relationality can be found or made between the thousands of proteins found by each experiment? This is the problem that many search engines, databases and many data-mining enterprises address. What Klie et al. did was perhaps slightly unusual in proteomics but not at all unusual in the field of information retrieval (<xref ref-type="bibr" rid="bibr11-0263276413476558">Manning et al., 2008</xref>). They regarded the Plasma Proteome Project (PPP) experiments as a set of documents or texts that could be text-mined in the same way that search engines text-mine the web. The ‘latent semantic analysis’ of the title of their article refers to document analysis techniques, which they apply to the conduct of high-throughout proteomics experiments.</p>
<p>But surely experiments and web pages are different? In attempting to reactivate sedimented data in order to enable its re-use, their first step was to render all the experimental data into a common frame in which each experiment becomes a ‘document’ and the proteins found in each experiment become the ‘terms’ or words of that document. Within a dataset there are various kinds of data, including raw data, processed data, peptide identifications, inferred proteins and meta-data. The researchers initially extracted from the gamut of experimental results just <italic>one</italic> specific type of data – inferred protein identifications – as terms in the document. A second step was then to treat each ‘document’ (experiment) as a <italic>vector in a several thousand dimension space</italic>. The overall direction of each vector (document/experiment) is determined by the terms (proteins) that comprise it, and its magnitude in a particular dimension by how often a particular term (protein) occurs. This re-shaping of the data that transforms protein identifications into a geometrical space is reminiscent of the sedimenting process that Edmund Husserl describes in <italic>Origin of Geometry</italic> (<xref ref-type="bibr" rid="bibr4-0263276413476558">Derrida, 1989</xref>: 164). That is, the flattening of all the experiments as vectors in a hugely dimensional space – a vector space – allows geometrical operations to have free play. What ends up flatly displayed as a matrix in which columns represent documents and rows represent terms belies the accompanying geometrical manifold which, as we will see next, embodies depths or ‘latent semantics’ which the researchers are interested in unearthing using matrix algebra. Already in the non-visualizable high dimension of the vector space model, proteins and experimental work on proteins, have been brought into the mundane, malleable and, shall we say, tractably associative world of texts.</p>
<p>It might seem that the transformation of protein experimental results into sets of documents and terms/words is not in the service of a reduction of the world of proteins to linear text. We would argue that it relocates the ensemble of 95 experiments in a somewhat different formalization, the vector space, in which many comparisons can be made. This geometrical emphasis is important for it opens a way to see similarities and differences. Once all experiments are rendered in a geometric-document space, the relation between any two vectors can be expressed as an angle. Any two documents/experiments can be compared in terms of the angle between the vectors that express them. While distance or angle are familiar spatial concepts, in vector space angles measure similarities between different documents. Vectors that point in more or less the same direction indicate documents that have similar distributions of terms. In turn, documents that have similar terms stand for experiments that found many of the same proteins. Hence, not only have experiments been transformed into documents and proteins into words, but the proteomic experiments are now in the vector space model that ‘is fundamental to a host of information retrieval operations ranging from scoring documents on a query, document classification and document clustering’ (<xref ref-type="bibr" rid="bibr11-0263276413476558">Manning et al., 2008</xref>: 121). Ranking, classification and clustering – these ways of making multiples by number, by order, and by class – clearly extend well beyond sciences. These scientists did not invent these ways of making multiples, but we can learn from them how multiples are made in many adjacent or affiliated settings – and this is one reason why contemporary sciences are so useful.</p>
<p>The series of experiments done on blood plasma has been rendered in a geometrico-informatic space. In a geometrical space of abstraction, experiments represented by vectors that point more or less in the same direction have greater similarity than vectors that point in different directions. This then is the key to the range of grey-scale tones in the visual devices. Black represents identity or coincidence between vectors/documents/experiments. White represents complete divergence, or geometrically, vectors that are ‘orthogonal’ – at right angles – to each other. The greys suggest various degrees of alignment or similarity between the 95 experiments.</p>
<p>Would we say, then, that having started by regarding experiments as texts, the researchers have backed away to a more distant standoff, an abstract or alienated standpoint from which they apprehend experiments at a distance because they are unable to engage more intimately? Quantification entails an ineluctable compromise between the acceptance of the difficulty of capturing variations and the desire to make out identities or regularities. Is the experimental similarity matrix a way of handling the specificities of experiments at a necessary distance, a mode of abstraction that a 95-site ethnographic comparison of the experiments would not need to accept? Or is there an experimental invention here, a way of, as <xref ref-type="bibr" rid="bibr22-0263276413476558">Stengers (2000: 86)</xref> writes: ‘“creating” a fact that singularizes one class of phenomena among others’, a space in which experiment-proteins/documents-terms/vectors-dimensions are re-modelled in a number of stages, stages that inject and interweave diverse linguistic, statistical and mathematical operations into the space?</p>
<p>It is not as if the scientists are completely happy with the reduction of all experiments to a similarity matrix where all comparisons are quantified. As we shall see, they are uneasy about what they can see in the vector space. The vector space model of the experiments proves to be overly exact. Exactitude can proliferate differences. Too many interesting similarities and resemblances – ‘synonyms’ the authors call them (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al. 2007</xref>: 184) – between proteins are missed by the many-dimensional exactness of the vector space representation. Conversely, much of the vector space is empty or sparsely populated. Since each protein (term) requires a new dimension, rare proteins will create dimensions that are largely empty in the vector space. (The problem of matrix sparsity vexes social scientists who do quantitative work too [see <xref ref-type="bibr" rid="bibr1-0263276413476558">Abbott (2001)</xref> on the challenge of matrix sparsity]; in the domain of machine learning, where high-dimensional vector spaces pose many computational problems, this is known as ‘the curse of dimensionality’ [<xref ref-type="bibr" rid="bibr6-0263276413476558">Hastie et al., 2009</xref>]). Faced with these problems of over-precision and emptiness, the researchers again draw on an informational retrieval system known as latent semantic analysis (LSA), developed in the late 1980s for the analysis of large numbers of documents (<xref ref-type="bibr" rid="bibr3-0263276413476558">Deerwester et al.,1990</xref>). The base intuition behind LSA and many other dimensional reduction techniques that use information retrieval and data-mining is that any discourse contains forms of semantic order that a proliferation of almost synonymous words conceals. LSA uses the vector space model of terms and documents, but ‘decomposes’ it in order to shrink the vector space to a number of dimensions present in the vector space model.</p>
<p>The authors go to some lengths to present the matrix algebra used in LSA. The presentation of the linear algebra of LSA and its prominent graphical depiction (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: <xref ref-type="fig" rid="fig1-0263276413476558">Figure 1</xref>) in an article in the <italic>Journal of Proteome Research</italic> suggests that this informational retrieval technique is not widely known to biologists, yet is important enough to what the researchers are attempting to do that they need to include it in the article. The techniques of LSA pivot on an underlying mathematical operation – the Singular Value Decomposition (SVD) – to produce lower-dimensional versions of the vector space that can then be used to generate a new, less exact but also less noisy similarity matrix. The SVD of a vector space factors a matrix into three separate component matrices. These matrices embody the relations between terms, documents and the ‘latent semantics’ of text, expressed in the ‘singular values’. Using the <italic>singular</italic> values, one can scale up and down one’s grasp of a space, adding and reducing dimensions. By implication, one can choose how many dimensions in which to view the semantics of a collection of documents. Documents in LSA become like signals in signal processing – they are flows of information that need to be amplified or attenuated. Like the heatmap itself, the mathematics of the Singular Value Decomposition was developed from the late 19th century through to the late 1960s, so SVD is a relatively recent achievement. The key point for our purposes is that the SVD acts as a kind of scaling control on a dataset, allowing it to be seen in all it noisy variety or only in its basic patterns.<sup><xref ref-type="fn" rid="fn1-0263276413476558">1</xref></sup></p>
<p>We can now understand why there are two heatmaps in <xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al.’s (2007)</xref> article. Many digital devices sample, approximate and compress data in the name of mobility. LSA is a method of compressing data in the interests of re-scaling knowing. It addresses the noisy exactitude of digital data. LSA offers the researchers a way of trying different approximations rather than noisily exact measures. The two heatmaps at k = 75 (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: Figure 3 [Figure 1 in this article]) and k = 10 (<xref ref-type="bibr" rid="bibr7-0263276413476558">Klie et al., 2007</xref>: Figure 4 [not shown here]) regenerate the vector space at widely different levels of granularity. Put more informally, they show us the relationships between experiments viewed at disparate scales. No doubt, Klie et al. tried other settings of k in examining the similarities between PPP experiments. Effectively, the two visuals they chose are saying that different degrees of relation between the experiments can be found, depending on how closely we look at it. As Anna <xref ref-type="bibr" rid="bibr24-0263276413476558">Tsing (2005: 58)</xref> writes: ‘scale is not just a neutral frame for viewing the world; scale must be brought into being: proposed, practiced and evaded, as well as taken for granted’.</p>
</sec>
<sec id="sec5-0263276413476558"><title>The Thickness of Digital Devices</title>
<p>Where does our contemplation of the figures end? From many angles, the cluster heatmaps look like a typical digital flattening of the world. The matrix on which they are based is one of the most pervasive and generic digital forms (in sensors, in display screens, in graphics, in data architectures, in silicon hardware itself). We started by seeing them as symptoms of contemporary scientists’ avid engagement with large multiples, with populations of molecules whose own fluxing sociality makes numbering and identifying them difficult. The cluster heatmap is a symptomatic digital device, albeit with a multi-stranded genealogy coming from social science, statistics and recent genomic biology.</p>
<p>Yet these particular heatmaps are themselves somewhat monadological in character, and they are experiments in seeing, in furnishing ways of seeing how data on proteins could become re-usable, could be reactivated as collective property rather than the by-product of publication. The heatmaps graphed experimental methods, machines and data infrastructures focused on human blood plasma proteins. They attempted to render visible how scientists know such proteins today, using the diverse experimental techniques and ways of collecting and sorting data known as proteomics. The heatmaps render the work of knowing proteins more visible. In this respect, they are not typical heatmaps at all. They start to dissolve the givenness of digital data through other digital devices – document-term matrices, vector spaces, singular value decomposition, latent semantic indexing, hierarchical clustering – drawn from diverse domains. The translation of experiments in the vector space, the ensuing latent semantic analysis, and the techniques of clustering needed to make forms of order appear on the visualizations, all of this effort is multiplied because the multiple of proteins and experiments will not stay the same.</p>
<p>Via a digital rendering of Tarde’s monadological perspective, Bruno Latour and co-authors recently suggested that ‘another experience of “being in a whole” should be explored that has little to do with “being a part” of a “structure” no matter if this structure is a sui generis super-organism or an emerging level’ (<xref ref-type="bibr" rid="bibr10-0263276413476558">Latour et al., 2012</xref>: 11). In some ways, our tracing of the heatmap in quasi-Tardean terms is doing something similar. But our emphasis has been different. For Latour and co-authors, the availability of rich datasets produced by collective action is an unmitigated boon. In our case, at least inasmuch as we empathize with the proteomics scientists, the givenness of datasets is a problem because they open onto different ways of being multiple, some of which pertain to proteins, some of which stem from the lives of scientists, some of which come from the omnidirectional propagation of methods. This latter multiple – the multiples of method – is the principal ‘finding’ of our diagrams. In these diagrams, a tumult of methods overruns the specialized knowledge of the structure, chemistry and biology of proteins. When a digital device superimposes multiple methods, including other digital devices, some of which are on display, others behind the scenes, what does this mean for the life of data? In the flatness of these visual digital devices, the mobility of methods across disciplines is striking. Methods seem to live lives that as are mobile, contagious and pluriform as proteins. As proteomics finds ways to know proteins as sequences, it turns to many other information retrieval methods. No doubt the proteins of mass spectrometry are not practised in the same way as the proteins of bioassays and, in fact, even the proteins of mass spectrometry are not the same as each other. The molecular decomposition of life is followed by an attempt at restoring proteins to biological systems, although not necessarily by the same route. And never to the same place or the same thing. In trying to grapple with what they have done, in trying to reactivate their own work, to discover the forms of identity and difference that characterize it and, ultimately, in trying to bring proteins to biosocial human-non-human lives, the proteomic scientists make methodological borrowings that thicken digital devices.</p>
<p>The heatmaps, or experiment similarity matrices, are an experiment in analysing experiments monadologically. They directly recognize the manifold ways in which a proteome is experimentally, infrastructurally, equipmentally and conventionally made multiple. They are forms of recognition of the singularity of experimental method as an invention and event. But this recognition proliferates practices. In describing their work, we have sought to affirm the multiples these devices bring into being. When experimental methods are brought together with the increased mobility of methods, we see that the digital is not so much about mobility of data, but is about the multiplication and mobilization of methods.</p>
<p>If methods are constantly being multiplied and mobilized in digital devices, what would this imply for how human and social sciences relate to the life sciences? The continuous invention and lateral transfer of methods destabilizes any single real; methods make the real multiply. In this proliferation, when scientists aspire to say something about reality or life, they cannot escape talking about techniques. Everywhere, not just in the sciences, techniques are invented in the desire and struggle to reconstitute or re-animate something that we are not able to acquire directly. The irony of the increased inventiveness or mobility of digital methods around living things is that they make it harder to ignore the mediation of method. Life scientists have shown themselves adept at revitalizing methods. In the human and social sciences, with all our fabled reflexivity, might we be able to revitalize our sense of what it means to live multiples in a similar way?</p>
</sec>
</body>
<back><notes>
<title>Note</title>
<fn-group>
<fn id="fn1-0263276413476558"><label>1</label><p>SVD as the mathematical foundation of LSA is not especially statistical in character although it is very widely used in statistics. Like many statistical procedures, it is a way of sampling data – in this case many ‘documents’ – in order to estimate underlying population parameters that cannot be measured directly. Over the last decade newer techniques such as ‘probabilistic LSA’ (pLSA), ‘latent Dirichelet Allocation’ (LDA) and ‘correlated topic models’ (CTM) have provided much more sophisticated statistical underpinnings for the vector space models of text. The very liveliness of the field of statistically supported text processing (and statistical machine learning more generally) suggests that older dispositifs derived from understandings of population distributions, norms and aggregates, are still very relevant.</p></fn></fn-group></notes><ack>
<title>Acknowledgments</title>
<p>The support of the Economic and Social Research Council (ESRC) is gratefully acknowledged. This work was undertaken as part of the research programme of the ESRC Genomics Network at the Centre for Economic and Social Aspects of Genomics (Cesagen), Cardiff School of Social Sciences, Cardiff University, UK.</p></ack>
<ref-list>
<title>References</title>
<ref id="bibr1-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>A.</given-names></name></person-group> (<year>2001</year>) <source>Time Matters: On Theory and Method</source>, pp. <publisher-loc>Chicago</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation></ref>
<ref id="bibr2-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bennett</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>) <source>Vibrant Matter: A Political Ecology of Things</source>, pp. <publisher-loc>Durham, NC</publisher-loc>: <publisher-name>Duke University Press</publisher-name>.</citation></ref>
<ref id="bibr3-0263276413476558"><citation citation-type="other"><comment>Deerwester, S., Dumais, S., Landauer, T., Furnas, G. and Harshman, R. (1990) ‘Indexing by latent semantic analysis’, <italic>Journal of the American Society for Information Science</italic> 41(6): 391–407</comment>.</citation></ref>
<ref id="bibr4-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Derrida</surname><given-names>J.</given-names></name></person-group> (<year>1989</year>) <source>Edmund Husserl’s Origin of Geometry: An Introduction</source>, pp. <publisher-loc>Lincoln</publisher-loc>: <publisher-name>University of Nebraska Press</publisher-name>.</citation></ref>
<ref id="bibr5-0263276413476558"><citation citation-type="other"><comment>Eisen, M.B., Spellman, P.T., Brown, P.O. and Botstein, D. (1998) ‘Cluster analysis and display of genome-wide expression patterns’, <italic>Proceedings of the National Academy of Sciences of the United States of America</italic> 95(25): 14863–14868</comment>.</citation></ref>
<ref id="bibr6-0263276413476558"><citation citation-type="other"><comment>Hastie, T., Tibshirani, R. and Friedman, J.H. (2009) <italic>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</italic>, 2nd edn. New York: Springer</comment>.</citation></ref>
<ref id="bibr7-0263276413476558"><citation citation-type="other"><comment>Klie, S., Martens, L., Vizcaíno, J.A., Côté, R., Jones, P., Apweiler, R., et al. (2007) ‘Analyzing large-scale proteomics projects with latent semantic indexing’, <italic>Journal of Proteome Research</italic> 7(1): 182–191</comment>.</citation></ref>
<ref id="bibr8-0263276413476558"><citation citation-type="other"><comment>LarvalSubjects (2012) ‘Object-Oriented Materialism (OOM)’, <italic>Larval Subjects.</italic> Available at: <ext-link ext-link-type="uri" xlink:href="http://larvalsubjects.wordpress.com/2012/01/16/object-oriented-materialism-oom/">http://larvalsubjects.wordpress.com/2012/01/16/object-oriented-materialism-oom/</ext-link> (accessed July 2012)</comment>.</citation></ref>
<ref id="bibr9-0263276413476558"><citation citation-type="other"><comment>Latour, B. and Woolgar, S. (1986) <italic>Laboratory Life</italic>, 2nd edn. Princeton, NJ: Princeton University Press</comment>.</citation></ref>
<ref id="bibr10-0263276413476558"><citation citation-type="other"><comment>Latour, B., Jensen, P., Venturini, T., Grauwin, S. and Boullier, D. (2012) ‘The whole is always smaller than its parts: a digital test of Gabriel Tarde’s monads’, <italic>British Journal of Sociology</italic> 63(4): 590–615</comment>.</citation></ref>
<ref id="bibr11-0263276413476558"><citation citation-type="other"><comment>Manning, C.D., Raghavan, P. and Schütze, H. (2008) <italic>Introduction to Information Retrieval</italic>, 1st edn. Cambridge: Cambridge University Press</comment>.</citation></ref>
<ref id="bibr12-0263276413476558"><citation citation-type="other"><comment>Martens, L. and Hermjakob, H. (2007) ‘Proteomics data validation: why all must provide data’, <italic>Molecular BioSystems</italic> 3: 518–522</comment>.</citation></ref>
<ref id="bibr13-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mol</surname><given-names>A.</given-names></name></person-group> (<year>2002</year>) <source>The Body Multiple: Ontology in Medical Practice</source>, pp. <publisher-loc>Durham, NC</publisher-loc>: <publisher-name>Duke University Press</publisher-name>.</citation></ref>
<ref id="bibr14-0263276413476558"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Omenn</surname><given-names>G.S.</given-names></name></person-group> (<year>2005</year>) <article-title>Exploring the human plasma proteome</article-title>. <source>Proteomics</source> <volume>5</volume>: <fpage>3223</fpage>–<lpage>3225</lpage>.</citation></ref>
<ref id="bibr15-0263276413476558"><citation citation-type="other"><comment>Patterson, S.D. and Aebersold, R.H. (2003) ‘Proteomics: the first decade and beyond’, <italic>Nature</italic> 33(March): 311–321</comment>.</citation></ref>
<ref id="bibr16-0263276413476558"><citation citation-type="other"><comment>Rabinow, P. and Rose, N. (2003) Thoughts on the concept of biopower today. Unpublished paper</comment>.</citation></ref>
<ref id="bibr17-0263276413476558"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Righetti</surname><given-names>P.G.</given-names></name></person-group> (<year>2004</year>) <article-title>Bioanalysis: Its past, present and some future</article-title>. <source>Electrophoresis</source> <volume>25</volume>: <fpage>2111</fpage>–<lpage>2127</lpage>.</citation></ref>
<ref id="bibr18-0263276413476558"><citation citation-type="other"><comment>Rogers, R. (2004) ‘Information politics on the web’. Available at: <ext-link ext-link-type="uri" xlink:href="http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=10329">http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=10329</ext-link> (accessed July 2012)</comment>.</citation></ref>
<ref id="bibr19-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>N.</given-names></name></person-group> (<year>2006</year>) <source>The Politics of Life Itself: Biomedicine, Power and Subjectivity in the Twenty-first Century</source>, pp. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation></ref>
<ref id="bibr20-0263276413476558"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>N.</given-names></name></person-group> (<year>2013</year>) <article-title>The human sciences in a biological age</article-title>. <source>Theory, Culture &amp; Society</source> <volume>30</volume>(<issue>1</issue>): <fpage>3</fpage>–<lpage>34</lpage>.</citation></ref>
<ref id="bibr21-0263276413476558"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Savage</surname><given-names>M.</given-names></name><name><surname>Burrows</surname><given-names>R.</given-names></name></person-group> (<year>2007</year>) <article-title>The coming crisis of empirical sociology</article-title>. <source>Sociology</source> <volume>41</volume>(<issue>5</issue>): <fpage>885</fpage>–<lpage>899</lpage>.</citation></ref>
<ref id="bibr22-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Stengers</surname><given-names>I.</given-names></name></person-group> (<year>2000</year>) <source>The Invention of Modern Science</source>, pp. <publisher-loc>Minneapolis</publisher-loc>: <publisher-name>University of Minnesota Press</publisher-name>.</citation></ref>
<ref id="bibr23-0263276413476558"><citation citation-type="other"><comment>Tarde, G.D. (1999) <italic>Monadologie et sociologie</italic>, edited by Alliez E. (Collection Les empêcheurs de penser en rond). Paris: Institut Synthêlabo</comment>.</citation></ref>
<ref id="bibr24-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Tsing</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>) <source>Friction: An Ethnography of Global Connection</source>, pp. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation></ref>
<ref id="bibr25-0263276413476558"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Twyman</surname><given-names>R.M.</given-names></name></person-group> (<year>2004</year>) <source>Principles of Proteomics</source>, pp. <publisher-loc>Abingdon/New York</publisher-loc>: <publisher-name>Garland Science/BIOS Scientific Publishers</publisher-name>.</citation></ref>
<ref id="bibr26-0263276413476558"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Weinstein</surname><given-names>J.N.</given-names></name></person-group> (<year>2008</year>) <article-title>Biochemistry: A postgenomic visual icon</article-title>. <source>Science</source> <volume>319</volume>(<issue>5871</issue>): <fpage>1772</fpage>–<lpage>1773</lpage>.</citation></ref>
<ref id="bibr27-0263276413476558"><citation citation-type="other"><comment>Weinstein, J.N., Myers, T.G., O’Connor, P.M., Friend, S.H., Fornace, Jr A.J., Kohn, K.W. et al. (1997) ‘An information-intensive approach to the molecular pharmacology of cancer’, <italic>Science</italic> 275(5298): 343–349</comment>.</citation></ref>
<ref id="bibr28-0263276413476558"><citation citation-type="other"><comment>Wilkinson, L. and Friendly, M. (2009) ‘The history of the cluster heat map’, <italic>American Statistician</italic> 63(2): 179–184</comment>.</citation></ref>
</ref-list>
<bio><title>Author Biographies</title>
<p><bold>Adrian Mackenzie</bold> is a Reader in the Centre for Social and Economic Aspects of Genomics, Department of Sociology, Lancaster University. He has published work on technology: <italic>Transductions: Bodies and Machines at Speed</italic> (2002/6); <italic>Cutting Code: Software and Sociality</italic> (2006) and <italic>Wirelessness: Radical Empiricism in Network Cultures</italic> (2010). He is currently working on the circulation of data-intensive methods across science, government and business in network media. He co-directs the Centre for Science Studies, Lancaster University.</p>
<p><bold>Ruth McNally</bold> is Principal Lecturer in Innovation and Technology Management at Anglia Ruskin University, Cambridge, and Senior Research Fellow on the EPSRC Catalyst project at Lancaster University. She is co-author with Mike Lynch, Simon Cole and Kathleen Jordan of <italic>Truth Machine: The Contentious History of DNA Fingerprinting</italic> (2008).</p></bio>
</back>
</article>