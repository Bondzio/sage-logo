<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">ADB</journal-id>
<journal-id journal-id-type="hwp">spadb</journal-id>
<journal-title>Adaptive Behavior</journal-title>
<issn pub-type="ppub">1059-7123</issn>
<issn pub-type="epub">1741-2633</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1059712312462249</article-id>
<article-id pub-id-type="publisher-id">10.1177_1059712312462249</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Papers</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Ultrastable neuroendocrine robot controller</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Pitonakova</surname><given-names>Lenka</given-names></name>
</contrib>
<aff id="aff1-1059712312462249">Department of Informatics, University of Sussex, Falmer, Brighton, UK</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-1059712312462249">Lenka Pitonakova, Department of Informatics, University of Sussex, Falmer, Brighton, BN1 9QJ, UK Email: <email>contact@lenkaspace.net</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>2</month>
<year>2013</year>
</pub-date>
<volume>21</volume>
<issue>1</issue>
<fpage>47</fpage>
<lpage>63</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">International Society of Adaptive Behavior</copyright-holder>
</permissions>
<abstract>
<p>The work of a simulated neuroendocrine controller with ultrastable neurons and glands is sketched and tested in terms of stability and adaptability. The artificial neurons connect to each other and to motors, while hormones produced by behaviour-related glands regulate their output. The ultrastable nature of the cells allows them to maintain their homeostasis by random reconfiguration of their connections and parameters without reference to the global goal of the system. Interactions of these ultrastable components cause individual robot behaviours to emerge to certain extents. The presented results show that the controller as a whole is capable of not only configuring itself to perform random walk, obstacle avoidance, mineral collection and recharging, but also to stay robust or adapt to a number of environmental and body perturbations without a need for a body model.</p>
</abstract>
<kwd-group>
<kwd>Distributed adaptation</kwd>
<kwd>ultrastability</kwd>
<kwd>hormonal modulation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1059712312462249" sec-type="intro">
<title>1 Introduction</title>
<p>In the field of robotics, we continuously try to build better and more autonomous machines that could one day operate in unknown environments with no need for human intervention. Biological systems have developed mechanisms that support autonomy through maintenance of homeostasis. Minor behavioural alterations are often controlled by the amount of hormones in the body, whereas adaptation to rapid environmental changes involves alteration of survival strategies.</p>
<p>Biologically inspired engineering thus seems to be becoming more and more important when it comes to creation of autonomous agents. Two distinct groups of biologically inspired robot controllers are considered in this paper. On one hand, there are hormonally modulated controllers where different (but often pre-learned) behaviours are executed based on levels of behaviourally dependent hormones (<xref ref-type="bibr" rid="bibr8-1059712312462249">French &amp; Cañamero, 2005</xref>; <xref ref-type="bibr" rid="bibr17-1059712312462249">Liang, You, &amp; Wang, 2010</xref>; <xref ref-type="bibr" rid="bibr25-1059712312462249">Moioli, Vargas, Von Zuben, &amp; Husbands, 2008</xref>; <xref ref-type="bibr" rid="bibr28-1059712312462249">Neal &amp; Timmis, 2003</xref>; <xref ref-type="bibr" rid="bibr33-1059712312462249">Sauzé &amp; Neal, 2010</xref>; <xref ref-type="bibr" rid="bibr35-1059712312462249">Schmickl, Thenius, Strander, Hamann, &amp; Crailsheim, 2011</xref>; <xref ref-type="bibr" rid="bibr36-1059712312462249">Shen, Will, &amp; Galstyan, 2004</xref>; <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis, Neal, &amp; Thorniley, 2009</xref>; <xref ref-type="bibr" rid="bibr43-1059712312462249">Vargas et al., 2005</xref>), providing a robot with a need-based action selection. Work particularly relevant to this paper describes controllers where roles of artificial cells are adapted during the life-time of a robot based on hormonal levels (<xref ref-type="bibr" rid="bibr9-1059712312462249">Hamann, Strander, Schmickl, &amp; Crailsheim, 2010</xref>; <xref ref-type="bibr" rid="bibr35-1059712312462249">Schmickl et al., 2011</xref>) and where hormonal release itself is adapted (<xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al., 2009</xref>). On the other hand, there are ultrastable controllers that do not use action selection but attempt to maintain optimal levels of variables that are essential for their work. An ultrastable unit alters its own parameters in order to change the way actions are executed, providing adaptation driven by the goal of internal stability (<xref ref-type="bibr" rid="bibr1-1059712312462249">Ashby, 1960</xref>; <xref ref-type="bibr" rid="bibr18-1059712312462249">Manicka &amp; Di Paolo, 2009</xref>; <xref ref-type="bibr" rid="bibr30-1059712312462249">Portha, Deneubourg, &amp; Detrain, 2004</xref>).</p>
<p>This paper proposes an ultrastable neuroendocrine controller (UNEC) where both of these principles work in parallel, merging their advantages in a single simulated agent. The controller consists of ultrastable self-reconfiguring neurons and glands, commonly referred to as cells. The neurons are organised in a continuous-time self-recurrent neural network (CTRNN) (<xref ref-type="bibr" rid="bibr2-1059712312462249">Beer, 1995</xref>) and are affected by hormones produced by glands, providing the robot with an action-selection mechanism. In the spirit of ultrastability, both cell types use a small Gaussian-random reconfiguration of their outgoing connections that is triggered each time a cell’s activation is out of its ‘comfort zone’ for a certain amount of time. Stability of a connection increases with time elapsed since its last reconfiguration. All controller behaviours, including hormonal release itself, emerge to various extents from behaviours of the self-reconfiguring cells. Furthermore, the ultrastable nature of cells implies that there are no distinguished ‘training’ and ‘trained behaviour’ of the controller. Any behaviour can be changed at any point in time if constraints given to cells responsible for that behaviour are not satisfied. This paper approaches robot control in a novel way: the main question asked is not how to execute agent-level actions but why cells would need to execute them in the first place.</p>
<p>The agent is given a task of resource gathering and has to avoid obstacles, as well as maintain level of its energy by recharging near specified objects. It is hypothesised that behaviour of an UNEC-controlled agent will be robust to minor perturbations due to the elasticity that ultrastability affords. More severe perturbations are expected to degrade the controller performance but adaptation should return the performance close to normal, especially when body changes will occur while the environmental conditions will remain the same.</p>
<p>The following section explains the rationale behind hormonal modulation and ultrastability. Section 3 describes the controller mechanics, followed by Section 4 with preliminary behavioural and adaptation results. A full hormone-modulated controller is then tested with the methods described in Section 5 and the results are presented in Section 6. The nature of the proposed control mechanism, its limitations and possible implications for robotics are discussed in Section 7.</p>
</sec>
<sec id="section2-1059712312462249">
<title>2 Background</title>
<p>Despite our engineering efforts, the ability to withstand and adapt to various environmental conditions and changes to the body is still a unique trait of living organisms. For example, ants and bees sample food sources during foraging and abandon them if they are not suitable. They take into account not only the presence of needed substances and their balance in a food source (<xref ref-type="bibr" rid="bibr14-1059712312462249">Josens &amp; Roces, 2000</xref>; <xref ref-type="bibr" rid="bibr30-1059712312462249">Portha et al., 2004</xref>), but also their intake rate (<xref ref-type="bibr" rid="bibr29-1059712312462249">O’Brien &amp; Hooper-Bùi, 2005</xref>). A similar behaviour was recorded in domestic cats exposed to experimental diets (<xref ref-type="bibr" rid="bibr11-1059712312462249">Hewson-Hughes et al., 2011</xref>). Furthermore, <xref ref-type="bibr" rid="bibr16-1059712312462249">Lefebvre, Pierre, Outreman, and Pierre (2007)</xref> showed that the patch-leaving behaviour of honeybees during nectar collection is related to quality of a visited patch as well as its distance from the nest. These and other experiments show that living organisms try to maintain the presence of essential elements in their bodies within a certain range (<xref ref-type="bibr" rid="bibr37-1059712312462249">Simpson &amp; Raubenheimer, 1993</xref>). At the same time, they indicate that biological entities are able to make effective trade-offs in food intake when different food sources provide varied amounts of required substances in order to satisfy as many of their needs as possible.</p>
<p>Biological adaptation even goes beyond short-term decisions and involves changing of behavioural strategies. For instance, <xref ref-type="bibr" rid="bibr14-1059712312462249">Josens and Roces (2000)</xref> showed that motivation to start foraging is largely affected by the nutritional state of an insect colony and that homeostatic mechanisms affect the type of behaviour that is executed. Their experiments with food-deprived ants revealed that higher motivation to eat suppressed behaviours such as carrying of food to the nest and scent marking of the food location.</p>
<p>There are various mechanisms in organic bodies that maintain the level of nutrients, water, temperature and other attributes in order to make cells function optimally. This phenomenon is referred to as homeostasis. Vertebrates evolved an especially complicated structure consisting of the neural, endocrine and immune system in order to maintain homeostasis (<xref ref-type="bibr" rid="bibr28-1059712312462249">Neal &amp; Timmis, 2003</xref>). Cells of the immune system protect the organism from antibodies, such as viruses and bacteria (<xref ref-type="bibr" rid="bibr41-1059712312462249">Tsankova, 2009</xref>), and together with endocrine glands modulate the neural system through hormones (<xref ref-type="bibr" rid="bibr28-1059712312462249">Neal &amp; Timmis, 2003</xref>; <xref ref-type="bibr" rid="bibr37-1059712312462249">Simpson &amp; Raubenheimer, 1993</xref>). Hormones are produced when changes in the body are detected and their levels decay over time specific to a particular hormone (<xref ref-type="bibr" rid="bibr28-1059712312462249">Neal &amp; Timmis, 2003</xref>). For example, the information about level of nutrients in the body is carried through blood by hormones that affect taste sensors (<xref ref-type="bibr" rid="bibr37-1059712312462249">Simpson &amp; Raubenheimer, 1993</xref>) and by extension feeding. Neurons alter their synaptic strengths and consequently their spiking frequency (<xref ref-type="bibr" rid="bibr38-1059712312462249">Surmeier, Plotkin, &amp; Shen, 2009</xref>) if they have appropriate hormone receptors and the detected level of the hormone reaches a specific threshold (<xref ref-type="bibr" rid="bibr15-1059712312462249">Kaltenbach, 1988</xref>, <xref ref-type="bibr" rid="bibr17-1059712312462249">Liang et al., 2010</xref>). Neurons thereby contribute to the homeostasis of the whole system by being homeostatic themselves, even if the system has no cognitive abilities (<xref ref-type="bibr" rid="bibr31-1059712312462249">Sánchez-Lasheras, Könner, &amp; Brüning, 2010</xref>).</p>
<p>From an engineering perspective, hormones found in bodily fluids maintain a global pool of information that the neural system reads from and is influenced by. As soon as activity of an organism makes its internal state change, glands seize production of a hormone. A basic experiment by <xref ref-type="bibr" rid="bibr28-1059712312462249">Neal and Timmis (2003)</xref> showed that if an artificial hormone that is produced when obstacles are detected alters weights of a simple neural network responsible for random walk and obstacle avoidance, the behaviour can be more adaptive than if no hormonal control is used. The controller could thus produce both calm roaming in uncluttered environments and cautions obstacle approach in narrow corridors. A similar principle was used to drive energy replenishment through phototaxis (<xref ref-type="bibr" rid="bibr8-1059712312462249">French &amp; Cañamero, 2005</xref>; <xref ref-type="bibr" rid="bibr25-1059712312462249">Moioli et al., 2008</xref>; <xref ref-type="bibr" rid="bibr43-1059712312462249">Vargas et al., 2005</xref>). <xref ref-type="bibr" rid="bibr33-1059712312462249">Sauzé and Neal (2010)</xref> used several hormones in a sailing boat controller with pre-learned sensorimotor control to keep a boat in operation and drive it towards specified targets. Artificial hormones were also used to control pre-evolved GasNets that could avoid obstacles and steer towards or away from light sources based on the current homeostatic need (<xref ref-type="bibr" rid="bibr24-1059712312462249">Moioli, Vargas, &amp; Husbands, 2009</xref>). The Digital Hormone Model by <xref ref-type="bibr" rid="bibr36-1059712312462249">Shen et al. (2004)</xref> used hormones during inter-robot communication in order to allow for collective seizing of a target, balanced spreading in space and even repairing swarm topological damage. This model is similar to the UNEC as it implies distributed control where behaviour of units is co-dependent, but is not unit-specific. Throughout all the above-mentioned experiments, hormonal modulation was used to temporarily change weights of neural connections in order to create an action-selection mechanism. The UNEC follows a similar approach but also considers adaptation of the hormonal modulation itself.</p>
<p>One kind of mechanism where action selection was adapted was implemented by <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al. (2009)</xref>, who used pre-evolved neural networks, outputs of which were affected by hormones and fed to a single-layer perceptron controlling a robot’s motors. The controller was able to self-configure as well as adapt its hormonal secretion using a form of Hebbian learning. However, the reported time needed for the initial configuration was up to 45 minutes and not all of the adaptation experiments were successful due to uncontrolled connection weight increase. Another model proposed by <xref ref-type="bibr" rid="bibr9-1059712312462249">Hamann et al. (2010)</xref>, and also used by <xref ref-type="bibr" rid="bibr35-1059712312462249">Schmickl et al. (2011)</xref>, involved the use of artificial hormones that affected module actuators in a multi-modular robotic organism. The authors showed that continuous observing of hormonal gradients allowed the robotic organism to adapt to different body configurations, since actions of the individual modules could be executed based on positions of these modules within the body. Furthermore, a similar mechanism was applied to a swarm of robots that demonstrated successful collective obstacle avoidance and phototaxis (<xref ref-type="bibr" rid="bibr34-1059712312462249">Schmickl, Hamann, Strander, Mayet, &amp; Crailsheim, 2010</xref>).</p>
<p>A different adaptation mechanism first described by <xref ref-type="bibr" rid="bibr1-1059712312462249">Ashby (1960)</xref> that builds on the principle of internal stability rather than on performance-driven behaviour (<xref ref-type="bibr" rid="bibr30-1059712312462249">Portha et al., 2004</xref>) deals with adaptation directly. According to Ashby, an organism acts in order to maintain levels of its ‘essential variables’, such as energy, water, etc., in a (conceivably genetically specified) ‘viability zone’ and reconfigures randomly through small steps when conditions change and the levels of these variables cannot be maintained. While interaction with the environment happens through sensorimotor feedback in the primary loop, the essential variables are observed by a slower secondary loop that can change the parameters of the system via random step functions. Ashby called this principle ultrastability and demonstrated its effectiveness by building Homeostat, a machine that was able to reach a stable state even after serious perturbations because of the distributed nature of its adaptation.</p>
<p><xref ref-type="bibr" rid="bibr6-1059712312462249">Di Paolo (2000)</xref> applied the principle of essential variables in a phototactic robot that was able to adapt to sensory inversion and also worked on an ultrastable programmable spring machine (<xref ref-type="bibr" rid="bibr18-1059712312462249">Manicka &amp; Di Paolo, 2009</xref>). <xref ref-type="bibr" rid="bibr26-1059712312462249">Montebelli et al. (2010)</xref> used a similar but non-self-reconfigurable principle to create a CTRNN driving an evolved ECOBOT controller that was able to collect water and food to sustain its energy. Despite the indications that ultrastability is beneficial for adaptation, its use in engineering is rather rare. According to <xref ref-type="bibr" rid="bibr18-1059712312462249">Manicka and Di Paolo (2009)</xref>, choosing an effective state change mechanism is a potential problem, since random reconnection of elements could take a long time. In their paper, they used semi-random self-reconfiguration by identifying spring transitions that caused the system’s behaviour to deviate from ideal and changed them until a desired behaviour was reached. The change was a product of the measured deviation, a mutation rate and a random number. The authors pointed out that maintenance of stability of found solutions was problematic, since introducing more randomness into their mutations caused the system to deviate from good solutions. Other authors implementing on-line learning (<xref ref-type="bibr" rid="bibr13-1059712312462249">Iizuka &amp; Di Paolo, 2008</xref>; <xref ref-type="bibr" rid="bibr32-1059712312462249">Santos, Husbands, &amp; Froese, 2010</xref>; <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al., 2009</xref>) also altered weights in their neural networks by calculating the difference between actual and expected outcomes of the behaviour, but without introducing randomness. On the other hand, the UNEC attempts to implement the Ashby’s original concept by changing its weights in a Gaussian-random fashion, without any reference to a desired outcome. Stability is achieved by adding a secondary homeostatic loop as described by Ashby. Furthermore, plasticity of connections is based on the time elapsed since their last change, giving well-working configurations a higher chance to survive minor perturbations.</p>
</sec>
<sec id="section3-1059712312462249">
<title>3 Ultrastable neuroendocrine framework</title>
<sec id="section4-1059712312462249">
<title>3.1 The basics: random walk and obstacle avoidance</title>
<p>The tested controller was situated inside of a simulated robot that was 60×60 units (pixels) large, had an octagonal shape and two wheels on its left- and right-hand side. All tests were performed in two-dimensional arenas 700×650 units large where obstacles, food and resources were placed. One time step of the simulation update loop was executed each 1/60 seconds. The robot movement was simulated as continuous (<xref ref-type="bibr" rid="bibr4-1059712312462249">Bourg &amp; Seeman, 2004</xref>) where the centre of the robot body was moved by a floating-point distance from range &lt;–2; 2&gt; every time step, allowing the robot to move backwards or forwards. The distance moved was calculated based on positive or negative forces applied to the wheels. The effect of size and distance of the wheels was not simulated.</p>
<p>The controller consisted of several sensors, each of them having a corresponding neuron that handled the sensory data. The initial controller could configure itself to move randomly and avoid obstacles. It consisted of eight proximity sensor-neuron couples and one accelerometer – a random-walk neuron couple (<xref ref-type="fig" rid="fig1-1059712312462249">Figure 1</xref>, highlighted part in the middle without hormonal modulation). Each neuron had a reconfigurable connection to each of the two motors. Both sensory and motor values were from range &lt;−1; 1&gt; and a noise of uniformly distributed random values between &lt;–0.1, 0.1&gt; was added to them.</p>
<fig id="fig1-1059712312462249" position="float">
<label>Figure 1.</label>
<caption>
<p>Schema of the ultrastable neuroendocrine controller. Only two out of eight proximity sensor-neuron pairs are shown for clarity. Schema of the initial controller described in Section 3.1 where hormonal modulation was not used is highlighted in the middle grey area.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig1.tif"/>
</fig>
<p>The proximity sensors were spread around the robot’s body (<xref ref-type="fig" rid="fig2-1059712312462249">Figure 2</xref>) and their outputs (closeness of objects and self-movement for proximity and accelerometer sensors, respectively) were from the range &lt;0; 1&gt;. Signals from the sensors caused corresponding continuous-time self-recurrent neurons <italic>n</italic> to change their activation level, <italic>AC</italic>, as shown in <xref ref-type="disp-formula" rid="disp-formula1-1059712312462249">Equations (1)</xref> and <xref ref-type="disp-formula" rid="disp-formula2-1059712312462249">(2)</xref>:</p>
<fig id="fig2-1059712312462249" position="float">
<label>Figure 2.</label>
<caption>
<p>Position of proximity sensors and the accelerometer within the robot body.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig2.tif"/>
</fig>
<p><disp-formula id="disp-formula1-1059712312462249">
<label>(1)</label>
<mml:math display="block" id="math1-1059712312462249">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:mi>AC</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>AC</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>AC</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>θ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mfrac>
<mml:mo stretchy="false">(</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>AC</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:mo>+</mml:mo>
<mml:mi>λ</mml:mi>
<mml:mo>*</mml:mo>
<mml:mi>compositeSigmoid</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>INPUT</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-1059712312462249" xlink:href="10.1177_1059712312462249-eq1.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula2-1059712312462249">
<label>(2)</label>
<mml:math display="block" id="math2-1059712312462249">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>compositeSigmoid</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
<mml:mo>+</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>&gt;</mml:mo>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>∧</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>&lt;</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mi>e</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>7</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>*</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>α</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>&gt;</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>∧</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo>&lt;</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-1059712312462249" xlink:href="10.1177_1059712312462249-eq2.tif"/>
</disp-formula></p>
<p>The parameters <italic>AC</italic>θ and λ were neuron-type specific and generally governed the sensitivity of activation in relation to a cell’s input. The used compositeSigmoid function consisted of two sigmoids inverted along the <italic>y</italic>-axis and its output value was either from range &lt;0; 1&gt; or &lt;−1; 0&gt;, depending on what range the input came from (<xref ref-type="fig" rid="fig3-1059712312462249">Figure 3</xref>). This function could therefore modulate the input like a standard sigmoid function used in CTRNNs (<xref ref-type="bibr" rid="bibr2-1059712312462249">Beer, 1995</xref>), amplifying extreme input values −1, 0 and 1.</p>
<fig id="fig3-1059712312462249" position="float">
<label>Figure 3.</label>
<caption>
<p>The compositeSigmoid function. (a) The compositeSigmoid function (<xref ref-type="disp-formula" rid="disp-formula2-1059712312462249">Equation (2)</xref>) with β = 15, α = 0. (b) The compositeSigmoid function (<xref ref-type="disp-formula" rid="disp-formula2-1059712312462249">Equation (2)</xref>) with β = 25, α = 0.3.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig3.tif"/>
</fig>
<p>Output <italic>O</italic> of a neuron was based on the activation level and a separate noisy connection signal <italic>S</italic><sub><italic>conn</italic></sub> was sent to each of the two motors in parallel with signals from other neurons:</p>
<p><disp-formula id="disp-formula3-1059712312462249">
<label>(3)</label>
<mml:math display="block" id="math3-1059712312462249">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>O</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>compositeSigmoid</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>A</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mn>13</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-1059712312462249" xlink:href="10.1177_1059712312462249-eq3.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula4-1059712312462249">
<label>(4)</label>
<mml:math display="block" id="math4-1059712312462249">
<mml:mtable columnalign="left">
<mml:mtr>
<mml:mtd>
<mml:msub>
<mml:mi>S</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mi>O</mml:mi>
<mml:mi>n</mml:mi>
</mml:msub>
<mml:mo>*</mml:mo>
<mml:msub>
<mml:mi>W</mml:mi>
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>n</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>e</mml:mi>
<mml:mo>*</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>*</mml:mo>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="right">
<mml:mi>r</mml:mi>
<mml:mi>a</mml:mi>
<mml:mi>n</mml:mi>
<mml:mi>d</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>,</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>−</mml:mo>
<mml:mi>n</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>e</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>;</mml:mo>
<mml:mi>n</mml:mi>
<mml:mi>o</mml:mi>
<mml:mi>i</mml:mi>
<mml:mi>s</mml:mi>
<mml:mi>e</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>1</mml:mn>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula4-1059712312462249" xlink:href="10.1177_1059712312462249-eq4.tif"/>
</disp-formula></p>
<p>In Ashby’s terms, the input-activation-output sequence provided the controller with a primary sensorimotor loop. A slower secondary loop that allowed for cell homeostasis maintenance was created by adding cell variable ‘irritation’ <italic>IR</italic> that observed activation and caused small random weight changes of the cell connections when its value was higher than a cell-type-specific irritation threshold <italic>IR</italic>ϑ. Irritation (<xref ref-type="disp-formula" rid="disp-formula5-1059712312462249">Equation (5)</xref>) started increasing rapidly when a cell’s activation was out of its viability zone for a certain amount of time, that is, when the cell was not causing a behaviour that was required of it. For example, activation of a proximity neuron remained high while there was a high input from a proximity sensor, that is, when an object was not avoided:</p>
<p><disp-formula id="disp-formula5-1059712312462249">
<label>(5)</label>
<mml:math display="block" id="math5-1059712312462249">
<mml:mtable>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mi>IR</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>+</mml:mo>
<mml:mn>1</mml:mn>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>IR</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">) </mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>IR</mml:mi>
<mml:mi>θ</mml:mi>
</mml:mrow>
</mml:mfrac>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mspace width="0.25em"/>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="right">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>brokenLine</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>AC</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>ϑ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:mi>AC</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
<graphic alternate-form-of="disp-formula5-1059712312462249" xlink:href="10.1177_1059712312462249-eq5.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula6-1059712312462249">
<label>(6)</label>
<mml:math display="block" id="math6-1059712312462249">
<mml:mrow>
<mml:mi>brokenLine</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ϑ</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>x</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtable align="left">
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>x</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>ϑ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>&lt;</mml:mo>
<mml:mi>ϑ</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd>
<mml:mrow>
<mml:mfrac>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>ϑ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>ϑ</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:mtd>
<mml:mtd>
<mml:mrow>
<mml:mi>x</mml:mi>
<mml:mo>≥</mml:mo>
<mml:mi>ϑ</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-1059712312462249" xlink:href="10.1177_1059712312462249-eq6.tif"/>
</disp-formula></p>
<p>Note that only the amount by which activation deviated from a neuron resting state equivalent to <italic>AC</italic> = 0 was important for calculation of irritation, while the sign of activation was irrelevant. The speed of irritation change was controlled by the brokenLine function (<xref ref-type="disp-formula" rid="disp-formula6-1059712312462249">Equation (6)</xref>), more specifically by a neuron-type-based activation threshold <italic>AC</italic>ϑ. BrokenLine was a linear function that returned output from range &lt;0; 1&gt; but had two different gradients based on the input value (<xref ref-type="fig" rid="fig4-1059712312462249">Figure 4</xref>). The <italic>AC</italic>ϑ parameter thus defined ranges of activation that caused irritation to change at different speeds, specifying when a neuron was more sensitive towards its homeostasis.</p>
<fig id="fig4-1059712312462249" position="float">
<label>Figure 4.</label>
<caption>
<p>The brokenLine function. (a) The brokenLine function (<xref ref-type="disp-formula" rid="disp-formula6-1059712312462249">Equation (6)</xref>) with ϑ = 0.2. (b) The brokenLine function (<xref ref-type="disp-formula" rid="disp-formula6-1059712312462249">Equation (6)</xref>) with ϑ = 0.7.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig4.tif"/>
</fig>
<p>At the point of reconnection, the irritation was reset to zero and a new weight was chosen separately for each connection using random Gaussian function with the mean in the current connection weight and a variance <italic>VAR</italic> based on a maximum pre-defined connection change variance <italic>CCVAR</italic> of a cell and the cell’s current activation (<xref ref-type="disp-formula" rid="disp-formula7-1059712312462249">Equation (7)</xref>). The probability of connection change (<italic>probChange</italic>) depended on the current connection age with respect to max <italic>ConnAge</italic> ≅ 167 seconds and was at least <italic>MINPROB</italic> = 0.2 (<xref ref-type="disp-formula" rid="disp-formula8-1059712312462249">Equation (8)</xref>). The connection age was reset to 0 when its weight changed. The value of maxConnAge represented 10,000 update loops and was chosen from a range of possible values found experimentally that allowed for both long-term stability and effective adaptation. The connection weights were initialised at random and kept within the range &lt;−1; 1&gt;:</p>
<p><disp-formula id="disp-formula7-1059712312462249">
<label>(7)</label>
<mml:math display="block" id="math7-1059712312462249">
<mml:mrow>
<mml:mi>VAR</mml:mi>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>CCVAR</mml:mi>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>*</mml:mo>
<mml:mi>A</mml:mi>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-1059712312462249" xlink:href="10.1177_1059712312462249-eq7.tif"/>
</disp-formula></p>
<p><disp-formula id="disp-formula8-1059712312462249">
<label>(8)</label>
<mml:math display="block" id="math8-1059712312462249">
<mml:mrow>
<mml:mtable align="right" width="80%">
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:mspace width="0.25em"/>
<mml:mspace width="0.25em"/>
<mml:mspace width="0.25em"/>
<mml:mi>probChange</mml:mi>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mi>MINPROB</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>*</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
<mml:mtr>
<mml:mtd columnalign="right" columnspan="1">
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>connAge</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>max</mml:mo>
<mml:mi>ConnAge</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>+</mml:mo>
<mml:mi>MINPROB</mml:mi>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula8-1059712312462249" xlink:href="10.1177_1059712312462249-eq8.tif"/>
</disp-formula></p>
<p>Movement of the robot was generally governed by the frequently reconfiguring random-walk neuron RW-n (λ<sub><italic>RW</italic>−<italic>n</italic></sub> = 0.7, <italic>AC</italic>θ<sub><italic>RW</italic>−<italic>n</italic></sub> = 20, <italic>AC</italic>ϑ<sub><italic>RW</italic>−<italic>n</italic></sub> = 0.65, <italic>IR</italic>θ<sub><italic>RW</italic>−<italic>n</italic></sub> = 40, <italic>IR</italic>ϑ<sub><italic>RW</italic>−<italic>n</italic></sub> = 0.2, <italic>CCVAR</italic><sub><italic>RW</italic>−<italic>n</italic></sub>= 1.5) that tried to maintain the robot’s speed based on the input from the accelerometer. The proximity neurons inhibited RW-n when the proximity sensors detected objects nearby, interrupting random walk and triggering obstacle avoidance. The resulting behaviour and adaptation obtained with this controller are presented in Section 4.1.</p>
</sec>
<sec id="section5-1059712312462249">
<title>3.2 Extended behaviours and hormonal action selection</title>
<p>An extension of the controller involved adding of carried-weight and energy sensors and their corresponding glands in order to allow for recharging and mineral collection. Furthermore, base-, mineral- and food-memory neurons, carried-weight and appetite glands, as well as a navigation neuron, were added (<xref ref-type="fig" rid="fig1-1059712312462249">Figure 1</xref>). The memory neurons maintained relative vectors towards items of interest and they were connected to the navigation neuron N-n that affected motors and inhibited the random-walk neuron. The outputs of memory neurons were from range &lt;−1; 1&gt; and expressed magnitude change of the remembered vectors, producing high positive output when distance to the object significantly increased and high negative input when it significantly decreased. The activation of N-n was thus smaller when it correctly navigated towards an item, keeping its irritation low and preventing the neuron’s connections to motors from changing. This mechanism caused the robot to move towards the item but change its course quickly when it started drifting away. N-n considered only a signal from a memory neuron with the highest utility each update loop, giving the food-memory neuron precedence in case of a tie (<xref ref-type="bibr" rid="bibr24-1059712312462249">Moioli et al., 2009</xref>).</p>
<p>Utility <italic>U</italic> of a memory neuron was carried along its output in a two-dimensional signal to N-n. Its value was mostly based on a corresponding hormonal concentration <italic>C</italic><sub><italic>h</italic></sub>, but it was also high when an object of interest was very close to the robot, giving the robot a slightly opportunistic behaviour (<xref ref-type="disp-formula" rid="disp-formula9-1059712312462249">Equation (9)</xref>):</p>
<p><disp-formula id="disp-formula9-1059712312462249">
<label>(9)</label>
<mml:math display="block" id="math9-1059712312462249">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>U</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>n</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mi>MAX</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>9</mml:mn>
<mml:mo>*</mml:mo>
<mml:mi>f</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>distanceComponent</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula9-1059712312462249" xlink:href="10.1177_1059712312462249-eq9.tif"/>
</disp-formula></p>
<p>The carried-weight gland CW-g produced high amounts of carried-weight hormone CW-h when there was little or no weight carried, causing high utility of the mineral-memory neuron MM-n. The gland ceased the hormonal production when the robot carried a certain amount of weight, which decreased utility of MM-n and increased utility of base-memory neuron BM-n. Similarly, the appetite gland produced appetite hormone AP-h when the level of energy started getting low and caused the utility of the food-memory neuron to become high and take over navigation. The resulting behaviour during a gathering–recharging cycle is presented in Section 4.2. All hormones were produced by a hormone repository based on signals <italic>S</italic> from glands <italic>g</italic>, a hormone decay rate ρ<sub><italic>h</italic></sub> and a hormone growth multiplier γ<sub><italic>h</italic></sub>, as shown in <xref ref-type="disp-formula" rid="disp-formula10-1059712312462249">Equation (10)</xref>. The glands were ultrastable and had their own activation and irritation parameters. However, in contrast with neurons, they were more effective by adapting the activation thresholds α that governed sensitivity of activation in respect to input (<xref ref-type="disp-formula" rid="disp-formula1-1059712312462249">Equation (1)</xref> and <xref ref-type="disp-formula" rid="disp-formula2-1059712312462249">(2)</xref>), rather than the connection weights to the repository:</p>
<p><disp-formula id="disp-formula10-1059712312462249">
<label>(10)</label>
<mml:math display="block" id="math10-1059712312462249">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>C</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>γ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>*</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>*</mml:mo>
<mml:mrow>
<mml:mo>|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>S</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>conn</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>|</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>ρ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mi>h</mml:mi>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula10-1059712312462249" xlink:href="10.1177_1059712312462249-eq10.tif"/>
</disp-formula></p>
<p>Apart from affecting the utility of memory neurons, the carried-weight and appetite hormones inverted the signs of inputs from the proximity sensors to proximity neurons when objects such as food, minerals or base were detected, effectively making the robot steer towards the objects rather than away from them when obstacle avoidance would normally take place. A similar type of hormonal modulation where hormones affected inputs of neurons was implemented by <xref ref-type="bibr" rid="bibr28-1059712312462249">Neal and Timmis (2003)</xref>, <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al. (2009)</xref> and <xref ref-type="bibr" rid="bibr9-1059712312462249">Hamann et al. (2010)</xref>.</p>
</sec>
</sec>
<sec id="section6-1059712312462249" sec-type="results">
<title>4 Initial results</title>
<sec id="section7-1059712312462249">
<title>4.1 Behaviour and adaptation of the initial random-walking robot</title>
<p><xref ref-type="fig" rid="fig5-1059712312462249">Figures 5</xref> and <xref ref-type="fig" rid="fig6-1059712312462249">6</xref> show an exemplary run with the simple obstacle-avoiding controller described in Section 3.1. The run consisted of Trial 0, where the initial configuration of the proximity neurons occurred, and Trial 1, where the resultant controller from Trial 0 was used in the same arena. A significant amount of obstacle hitting was noted during the first two thirds of Trial 0 (<xref ref-type="fig" rid="fig5-1059712312462249">Figure 5(a)</xref>), accompanied by frequent weight changes of proximity neuron connections (<xref ref-type="fig" rid="fig6-1059712312462249">Figure 6(a)</xref>). The reconnection stabilised between the 110th and 120th seconds into a configuration where the collective inputs from the neurons to motors allowed the robot to steer away from obstacles, keeping the neural activations and thus connection reconfigurations to minimum. Two minor reconnections occurred at around the 135th and 155th seconds, caused by an obstacle hit in the first case and a close encounter with an obstacle in the second case. There was only one obstacle hit in the subsequent Trial 1, which caused minor reconnections on several neurons at around the 10th second. Small reconnections also occurred later in Trial 1 due to longer near encounters with obstacles, although the obstacles were successfully avoided.</p>
<fig id="fig5-1059712312462249" position="float">
<label>Figure 5.</label>
<caption>
<p>Example of obstacle avoidance learning. Percentage of time during which the robot was hitting as obstacle was sampled for each second during the training (top) and a subsequent (bottom) trial with a single controller.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig5.tif"/>
</fig>
<fig id="fig6-1059712312462249" position="float">
<label>Figure 6.</label>
<caption>
<p>Changes in connection weights during obstacle avoidance learning presented in <xref ref-type="fig" rid="fig5-1059712312462249">Figure 5</xref>. Weights of connections from the eight proximity sensors to two motors were sampled for each second during Trial 0 (top) and subsequent Trial 1 (bottom).</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig6.tif"/>
</fig>
<p>It is important to point out that the controller never completely stops reconfiguring. If near an obstacle for long enough, a cell’s irritation reaches a high level and causes a connection weight to change, although the probability of that happening decreases for well-working connections. Furthermore, small and isolated alterations usually do not impact the overall obstacle avoidance performance and obstacle avoidance can rarely fail after the initial reconfiguration. <xref ref-type="fig" rid="fig7-1059712312462249">Figure 7</xref> shows average obstacle hitting times based on 50 runs, sampled every 20 seconds during Trials 0 and 1. Encounters with obstacles gradually decreased during Trial 0, from initial 20% to approximately 5%. The random reconfigurations of proximity neurons had on average the most significant impact between the 40th and 60th seconds when the obstacle hitting time dropped from 19.15% to 11.27%. A slightly less significant decrease was noted between the 100th and 120th seconds, from 10.85% to 8.02%, after which the performance slowly improved by no more than 2.5% during one 20-second window. The average obstacle hitting time during Trial 1 was 3.19% and did not exceed 5.62%.</p>
<fig id="fig7-1059712312462249" position="float">
<label>Figure 7.</label>
<caption>
<p>Obstacle hitting throughout initial configuration tests. The shown values represent average percentage of time during which the robot was hitting an obstacle sampled between two data points, each 20 seconds apart.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig7.tif"/>
</fig>
<p>Throughout the 50 runs, a few controllers were found that learned obstacle avoidance poorly relative to the other controllers. <xref ref-type="fig" rid="fig8-1059712312462249">Figure 8</xref> shows the dependence of the amount of obstacle hitting during Trial 1 (<italic>y</italic>-axis) on Trial 0 obstacle hitting (<italic>x</italic>-axis). A high amount of obstacle hitting during Trial 1 correlated with low obstacle hitting times in Trial 0. This was an expected result, since obstacle avoidance could not be properly learned when a small number of obstacles were encountered in the initial trial.</p>
<fig id="fig8-1059712312462249" position="float">
<label>Figure 8.</label>
<caption>
<p>Relationship between obstacle hitting time in Trials 0 and 1.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig8.tif"/>
</fig>
<p>In addition to initial self-configuration, the controller was also able to adapt to perturbations including higher sensory noise of up to 0.4 and inversion of motor rotation directions that caused the robot to steer in opposite ways than it originally configured itself for. The robot was initially configured for 120 seconds under normal conditions (Trial 0), after which a perturbation was introduced for 360 seconds (Trial 1) and then again for 360 seconds (Trial 2). The robot’s position and the cell activations and irritations were reset at the beginning of each trial. The duration of Trial 0 was chosen based on the fact that no significant improvements in obstacle avoidance were noted after the 120th second with an unperturbed controller. The performances from Trials 1 and 2 were compared with the performance of Controller A, which did not experience perturbations and ran for 360 seconds after Trial 0. Controller A achieved a median obstacle hitting time of 2.79%.</p>
<p><xref ref-type="fig" rid="fig9-1059712312462249">Figure 9</xref> reveals that the obstacle avoidance behaviour was robust and even slightly improved for sensory noise of 0.3 (1.75% median hitting time in Trial 1 and 1.09% in Trial 2). The hitting time was significantly higher in Trial 1 with both sensory noise of 0.4 (median hitting time 7.72%) and 0.5 (6.57%) and only improved in Trial 2 with noise of 0.4 (2.65%). The performance during Trial 2 with noise of 0.5 did not improve (median hitting time 6.32%), as effective reconnection was not possible due to constantly high activation of the proximity neurons. These results are also reflected in <xref ref-type="fig" rid="fig10-1059712312462249">Figure 10</xref>, which shows the average obstacle hitting time throughout Trials 1 (a) and 2 (b) sampled for each 40 seconds. It is interesting to note that when sensory noise of 0.4 was used, the performance did not improve throughout Trial 1, but was on average significantly better in Trial 2. It seems that there were frequent encounters with obstacles between the 280th and 360th seconds in Trial 1 and between the 120th and 160th seconds in Trial 2 that probably caused final correct configurations to be found. Also, note the instability of performance when sensory noise of 0.5 occurred. A significant performance improvement was recorded on average between the 160th and 200th seconds of Trial 1, but the configurations often broke down and the performance degraded again.</p>
<fig id="fig9-1059712312462249" position="float">
<label>Figure 9.</label>
<caption>
<p>Analysis of variance of initial adaptation results. (Matlab A). Average obstacle hitting time of Controller A that did not experience perturbations is compared to Controllers B that did experience them in Trials 1 and 2. The used annotation pattern is [controller][perturbation] [trial no.]. Medians are shown as lines in the middle of each box, with the 25th and 75th percentiles represented by tops and bottoms of each box respectively. The whiskers represent interquartile ranges of the samples and observations beyond the whisker length are marked as outliers (Matlab B).</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig9.tif"/>
</fig>
<fig id="fig10-1059712312462249" position="float">
<label>Figure 10.</label>
<caption>
<p>Obstacle hitting throughout initial adaptation tests. The shown values represent average percentage of time during which the robot was hitting an obstacle sampled between two data points, each 40 seconds apart. Results from tests with Controller B during Trials 1 (left) and 2 (right) are shown.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig10.tif"/>
</fig>
<p>The impact of motor rotation direction change was immediate and high at the beginning of Trial 1 (<xref ref-type="fig" rid="fig9-1059712312462249">Figure 9</xref>, median hitting time 8.32%). Adaptation was most significant during the first 200 seconds of Trial 1 (<xref ref-type="fig" rid="fig10-1059712312462249">Figure 10</xref>) and returned the controller to its normal obstacle avoidance performance in Trial 2, slightly outperforming Controller A (median hitting time 1.83%).</p>
<p>Similarly to the results from the initial controller configuration, the success of adaptation depended on how often obstacles were encountered during Trial 1, giving controllers that experienced more hits a better chance to adapt.</p>
</sec>
<sec id="section8-1059712312462249">
<title>4.2 Gathering–recharging cycle of the hormone-controlled robot</title>
<p>The following paragraph and <xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref> describe normal behaviour of a fully implemented hormone-modulated UNEC as described in Section 3.2. The robot started off near a base carrying zero weight and having full energy. Since there initially was no weight carried, the amount of carried-weight hormone CW-h was low, causing high utility of the mineral-memory neuron MM-n. However, because there was no mineral in the memory yet, the output of MM-n was still 0, RW-n was not suppressed and the robot moved randomly (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref>, trajectories between Points 1 and 2). When a mineral was detected, the output transferred from MM-n to N-n became high, causing N-n to suppress RW-n and the robot to steer towards the mineral (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref>, Points 2). The level of CW-h became high when there was a certain amount of weight carried (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref>, Points 3). This hormonal change caused utility of the base-memory neuron BM-n to become the highest, thus making the N-n start reconnecting in order to minimise the distance between the robot and the base. The location of the base was always known as it was the starting position of the robot. The mineral collection loop kept repeating while there were minerals in the memory (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11(a)</xref>, unlabelled triangle point near the base). Otherwise, the robot resumed random walk as RW-n was not suppressed anymore, which continued until another mineral source was found.</p>
<fig id="fig11-1059712312462249" position="float">
<label>Figure 11.</label>
<caption>
<p>Examples of the robot performing gathering and recharging. Trajectories from the first mineral gathering - feeding cycles only are shown.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig11.tif"/>
</fig>
<p>The appetite gland AP-g started producing the appetite hormone AP-h when the energy level started getting low, causing high utility of a food-memory neuron FM-n. Similar to the case with minerals, behaviour of the N-n based on the input from FM-n caused the robot to minimise its distance towards food or to perform random walk, depending on whether a food item was in the memory. This meant that the robot started searching for food rather than continuing to collect minerals when the energy was low but no food was found so far. Food following or search could be triggered at any time during the gathering cycle (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref>, Points 4) and the gathering cycle resumed once the robot’s energy was high again (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref>, Points 5). The whole process repeated once the base was reached and minerals were unloaded (<xref ref-type="fig" rid="fig11-1059712312462249">Figure 11</xref>, Points 6).</p>
</sec>
</sec>
<sec id="section9-1059712312462249">
<title>5 Adaptation evaluation methods</title>
<p>The navigation abilities of the robot were evaluated on their own, as well as alongside mineral gathering and recharging, by comparing the performance of Controller A, which did not experience perturbations, and Controller B, which did. The individually introduced perturbations included increased sensory noise, increased motor noise and inversion of motor rotation direction.</p>
<p>Trial 0, which lasted 120 seconds under normal conditions with sensory and motor noise of 0.1, was executed in an arena with no resources or base in order to allow for initial obstacle avoidance configuration. Subsequent Trials 1 and 2 with Controller B were performed for 360 seconds with the individual perturbations. Controller A ran for 360 seconds after Trial 0 under normal conditions.</p>
<p>The following hypotheses were tested:</p>
<list id="list1-1059712312462249" list-type="order">
<list-item><p>the performance of Controller B in both trials will not significantly differ from Trial 1 of Controller A under perturbations up to a certain value, that is, Controller B will stay robust to small perturbations;</p></list-item>
<list-item><p>if degradation of behaviour of Controller B in Trial 1 occurs, adaptation will cause the performance in Trial 2 to be better;</p></list-item>
<list-item><p>in the case of body changes, the performance of Controller B in Trial 2 will be similar to that of Controller A in Trial 1, as the environmental conditions for executing a tested behaviour will not change and adaptation will be able to return the controller to its normal working state.</p></list-item>
</list>
<p>The controller performances were compared using balanced one-way analysis of variance (ANOVA; Matlab A) and Dunn–Sidak adjusted comparison tests (Matlab C).</p>
<p>The testing was performed in three arenas, labelled GAT1, GAT2 and BIG, containing three food items each holding one floating-point unit of energy, one base and eleven mineral items each containing 2.0 units of minerals. Food items started recharging after 50 seconds of being depleted and their recharging took approximately 13 seconds. While resources were placed in between obstacles in the first two arenas, there were no obstacles in the BIG arena, apart from its surrounding walls. The following three test cases consisting of 50 runs each were executed in order to gradually test the performance of:</p>
<list id="list2-1059712312462249" list-type="bullet">
<list-item><p>Test Case 1: obstacle avoidance;</p></list-item>
<list-item><p>Test Case 2: obstacle avoidance and mineral gathering;</p></list-item>
<list-item><p>Test Case 3: obstacle avoidance, mineral gathering and recharging.</p></list-item>
</list>
<p>The robot’s energy level was fixed to 1.0 in Test Cases 1 and 2. Because random configuration of the appetite gland could potentially make the robot deplete its energy before the gland could function properly, an emergency energy supply was used for both Controllers A and B in Test Case 3 during a separate configuration Trial 0b that lasted 360 seconds and preceded Trial 1. The energy level decreased by approximately 0.9% per second, meaning that the energy was completely depleted in approximately 110 seconds, allowing for short contingences in cases when food needed to be searched for by random walk. The robot’s speed linearly decreased with the amount of carried minerals, which introduced a penalty to robots that tried to ‘cheat’ by not returning to the base to unload the minerals at reasonable intervals.</p>
</sec>
<sec id="section10-1059712312462249">
<title>6 Adaptation results</title>
<sec id="section11-1059712312462249">
<title>6.1 Sensory perturbations</title>
<p>The robot behaviour was evaluated with sensory noise of 0.3 and 0.4 that simulated worse visibility, for example rainy or foggy conditions. The navigation abilities of Controller B in Test Case 1 were not affected by noise of 0.3 and the controller was able to adapt to sensory noise of 0.4 in all three testing arenas (data not shown), mirroring results of the initial controller without glands and confirming Hypotheses 1 and 2. A higher input noise of 0.5 caused high activation of the proximity neurons and spontaneous reconnections that prevented adaptation.</p>
<p>Results from Test Cases 2 and 3 are presented in <xref ref-type="fig" rid="fig12-1059712312462249">Figure 12</xref>. Gathering was mostly not affected by sensory noise of 0.3 in Test Case 2, confirming Hypothesis 1 (median amount of gathered minerals during Trial 1 17.72% compared to Controller A’s 17.58% in GAT1 and 44.91% compared to 41.73% in BIG). However, this did not occur in GAT2, where gathering performance dropped in Trial 2 (12.51% compared to Controller A’s 17.03%). Gathering also degraded with sensory noise of 0.4 (median gathered obstacles during Trial 1: 12.20% in GAT1, 5.05% in GAT2 and 27.20% in BIG) and was not improved by adaptation (Trial 2 results: 12.56% in GAT1, 4.99% in GAT2 and 24.11% in BIG). Similar results were achieved during Test Case 3. Hypothesis 1 was confirmed in all arenas during tests with sensory noise of 0.3, where gathering remained robust, although the amount of gathered resources was smaller due to the robot’s need to recharge (Trial 1 results: 8.38% compared to Controller A’s 9.71% in GAT1, 1.54% compared to 1.58% in GAT2, 24.39% compared to 25.81% in BIG). Adaptation with sensory noise of 0.4 was not successful in any arena, although the amount of gathered minerals slightly improved in BIG (12.11% in Trial 1, 15.34% in Trial 2). Recharging in Test Case 3 was robust to sensory noise of 0.3 (Trial 1 0-energy time 13.60% compared to Controller A’s 11.60% in GAT1, 22.3% for both controllers in GAT2 and 3.42% compared to 5.08% in BIG) and broke down with sensory noise of 0.4 in arenas GAT1 (19.41% in Trial 1 and 23.83% in Trial 2) and GAT2 (19.62% in Trial 1 and 30.89% in Trial 2), although the results were not statistically significant. Hypothesis 2 was only confirmed in the BIG arena with noise of 0.4, where the recharging was worse in Trial 1 (0-energy time 7.66%) but improved in Trial 2 (3.98%).</p>
<fig id="fig12-1059712312462249" position="float">
<label>Figure 12.</label>
<caption>
<p>Dunn–Sidak adjusted comparison of gathering and recharging controller performances during sensory perturbations. The used annotation pattern for the shown groups is [controller]([perturbation]) [trial no.]. The controllers from Test case 2 where the robot’s energy was fixed to 1 have ‘(f)’ appended to their names. Group means are represented by circles and group intervals are shown as whiskers (Matlab C). Group means significantly different (p &lt; 0.05) from the normal Controller A(f) of Test Case 2 are marked with *. Group means significantly different from the normal Controller A of Test Case 3 are marked with +. (a) Arenta GAT1, 0-energy time. (b) Arena GAT1, gathered minerals. (c) Arena GAT2, 0-energy time. (d) Arena GAT2, gathered minerals. (e) Arena BIG, 0-energy time. (f) Arena BIG, gathered minerals.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig12.tif"/>
</fig>
</sec>
<sec id="section12-1059712312462249">
<title>6.2 Motor perturbations</title>
<p>Higher motor noise was introduced in order to test how the controller could adapt to changed environmental conditions such as rougher terrain. Furthermore, a change in the robot body was simulated by inverting motor rotation directions, which caused the robot to steer in opposite ways than it initially configured itself for. Obstacle avoidance of Controller B was robust during tests with motor noise of 0.3, confirming Hypothesis 1. The performance with other perturbations was worse in Trial 1, but the controller adapted successfully and its behaviour returned to normal in Trial 2, confirming Hypotheses 2 and 3. <xref ref-type="fig" rid="fig13-1059712312462249">Figure 13</xref> shows the results from arena BIG, where the differences between Trials 1 and 2 were the most significant (motor noise of 0.5: median obstacle hitting time 1.85% in Trial 1 and 0.67% in Trial 2, motor rotation inversion: 2.36% in Trial 1 and 1.08% in Trial 2)</p>
<fig id="fig13-1059712312462249" position="float">
<label>Figure 13.</label>
<caption>
<p>Obstacle hitting time in the BIG arena during Test Case 1 with motor perturbations. The used annotation pattern for the shown groups is [controller]([perturbation]) [trial no.]. Group means are represented by circles and group intervals are shown as whiskers (Matlab C). None of the groups has a significantly different mean that the original Controller A.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig13.tif"/>
</fig>
<p>Results from Test Cases 2 and 3 are shown in <xref ref-type="fig" rid="fig14-1059712312462249">Figure 14</xref>. Similar to the tests with sensory noise, the gathering performance of Controller B remained robust with motor noise of 0.3 during Test Case 2 (median amount of gathered minerals in Trial 1: 18.18% compared to Controller A’s 18.28% in GAT1, 17.62% compared to 17.13% in GAT2 and 43.87% compared to 41.78% in BIG). This result was also achieved when the motor rotation direction was changed in GAT1 (17.40%). Hypotheses 2 and 3 were confirmed when the motor rotation inversion was introduced in GAT2 and BIG, where the amount of gathered minerals dropped in Trial 1 (10.42% in GAT 2 and 35.45% in BIG) but increased in Trial 2 (15.11% in GAT 2 and 40.51% in BIG), getting closer to the performance of Controller A. Similar results were found when looking at gathering during Test Case 3, where motor noise of 0.3 did not affect the performance significantly (Trial 1 results: 11.41% compared to 9.69% in GAT1, 1.91% compared to 1.58% in GAT2 and 25.78% compared to 21.18% in BIG) The controller’s performance dropped in Trial 1 when the motor rotation inversion was introduced (8.40% in GAT1, 0.25% in GAT2 and 21.11% in BIG), but the performance matched or was better than Controller A’s in Trial 2 (11.20% in GAT1, 2.26% in GAT2 and 24.72% in BIG).</p>
<fig id="fig14-1059712312462249" position="float">
<label>Figure 14.</label>
<caption>
<p>Dunn–Sidak adjusted comparison of gathering and recharging controller performances during motor perturbations. The used annotation pattern for the shown groups is [controller]([perturbation]) [trial no.]. The controllers from Text case 2 where the robot’s energy was fixed to 1 have ‘(f)’ appended to their names. Group means are represented by circles and group intervals are shown as whiskers (Matlab C). Group means significantly different (p &lt; 0.05) from the normal Controller A(f) of Test Case 2 are marked with *. Group means significantly different from the normal Controller A of Test Case 3 are marked with +. (a) Arena GAT1, 0-energy time. (b) Arena GAT1, gathered minerals. (c) Arena GAT2, 0-energy time. (d) Arena GAT2, gathered minerals. (e) Arena BIG, 0-energy time. (f) Arena BIG, gathered minerals.</p>
</caption>
<graphic xlink:href="10.1177_1059712312462249-fig14.tif"/>
</fig>
<p>Although the gathering performance results obtained during motor perturbation tests were not as statistically different as with sensory perturbations, ANOVA evaluation (results not shown) revealed that the adapted gathering performance was generally similar or better and more stable during Trial 2 compared to Trial 1, implying that adaptation did play its role.</p>
<p>Finally, recharging did not seem to be significantly affected when motor noise was increased, although the results varied by arena, and the performance was not as consistent as the gathering performance. Hypotheses 2 and 3 were confirmed when motor rotation was inverted in GAT2 (0-energy time 28.20% during Trial 1 compared to Controller A’s 22.21% and 20.08% during Trial 2) and BIG (7.38% during Trial 1 compared to 5.12% and 4.26% during Trial 2). The results from GAT1 were not statistically significant.</p>
</sec>
<sec id="section13-1059712312462249">
<title>6.3 The impact of random walk</title>
<p>It was apparent especially during tests with higher sensory noise that the effectiveness of navigation based on randomly reconfiguring cells was relatively low, causing multiple encounters with the same object when the agent tried to steer away from it and then resume its original path. This negatively affected feeding and gathering in arenas GAT1 and GAT2, where obstacles were often in the way between the robot and its item of interest.</p>
<p>Furthermore, the search efficiency of random walk was also limited. Even in small testing arenas, food or minerals were sometimes not found and there was no search behaviour to execute since there was no memory of visited places. Adding more sophisticated motor control along with ‘visited landmarks’ memory neurons could potentially support path planning and help with these issues.</p>
</sec>
</sec>
<sec id="section14-1059712312462249" sec-type="discussion">
<title>7 Discussion</title>
<p>Work of a simulated UNEC where cells reconfigure in order to maintain their homeostasis was sketched and tested in terms of obstacle avoidance, alteration between recharging and gathering and adaptability to environmental (sensory and motor noise) and body (motor rotation inversion) perturbations. It was hypothesised that:</p>
<list id="list3-1059712312462249" list-type="order">
<list-item><p>the controller will stay robust during minor perturbations;</p></list-item>
<list-item><p>if degradation of behaviour due to a perturbation occurs, adaptation will cause the performance to improve after a certain time;</p></list-item>
<list-item><p>in the case of body changes, the adapted performance will be similar to the original performance without a perturbation, as the general conditions for executing a tested behaviour will not change and adaptation will be able to return the controller to its normal working state.</p></list-item>
</list>
<p>The results presented in Sections 4 and 6 show that the controller was mostly capable of remaining robust to minor environmental and body perturbations, confirming Hypothesis 1. Adaptation to high sensory noise was only possible for obstacle avoidance, although terrain roughness and changes in the robot’s motors were handled more appropriately and hormone-modulated behaviours were adapted as well. Hypothesis 2 was therefore mainly satisfied for navigation. Hypothesis 3 expressed the intuition that it is not only the adaptation mechanism itself but also the range of possibilities afforded by a changed environment that affect a robot’s performance. This was confirmed, as the adapted behaviour of a controller that experienced motor rotation inversion was either similar to or more effective than behaviour of the original controller that did not experience any perturbations.</p>
<p>The fact that the same mechanism was applied to both the controller configuration and adaptation and to both action execution (obstacle avoidance, gathering, etc.) and action selection (working of glands) indicates that the properties of the presented ultrastable cells are not limited to a specific cell type or functionality and are applicable to a larger variety of problems than those targeted by the particular simulations developed for this paper. The controller components utilising ultrastability had different roles and operated on different time scales, while their main common property was that they interacted with each other through their environment, that is, the internal and external state of the robot. Rather than using action selection to achieve ultrastability on the robot level, ultrastability was used on the cellular level to configure behaviours including action selection. This ties in more closely with biological neurons (<xref ref-type="bibr" rid="bibr31-1059712312462249">Sánchez-Lasheras et al., 2010</xref>).</p>
<p>The nature of the UNEC allowed for the following advantages.</p>
<list id="list4-1059712312462249" list-type="simple">
<list-item><p><bold>1. Robustness</bold></p></list-item>
</list>
<p>It was shown in Section 4 that cell connections stabilised at the point when a behaviour started working effectively, that is, when activation of a cell was kept within acceptable bounds. Furthermore, a connection was stable under minor activation perturbations due to a time gap between high activation and reconnection provided by irritation, as well as due to the fact that there was a smaller probability for older connections to reconfigure. The UNEC thus provides a possible solution to the problem of achieving robustness, which is one of the reasons why ultrastability tends not to be widely used in engineering (<xref ref-type="bibr" rid="bibr18-1059712312462249">Manicka &amp; Di Paolo, 2009</xref>).</p>
<list id="list5-1059712312462249" list-type="simple">
<list-item><p><bold>2. Reduced design requirements</bold></p></list-item>
</list>
<p>Adaptation is random and parallel and there is no pre-defined correct configuration of the controller because of the fact that cells behaviourally depend on each other. <xref ref-type="bibr" rid="bibr40-1059712312462249">Tolley and Lipson (2011)</xref> advocate stochasticity in motion planning and locomotion and argue that it reduces design requirements. It is certainly the case in the UNEC, where the robot behaviour is not dependent on exact cell parameter values and it was often found that values within the same or very similar order of magnitude delivered statistically similar results.</p>
<list id="list6-1059712312462249" list-type="simple">
<list-item><p><bold>3. Hormonal modulation learned through ultrastability</bold></p></list-item>
</list>
<p>Most of today’s work with hormonal modulation (<xref ref-type="bibr" rid="bibr8-1059712312462249">French &amp; Cañamero, 2005</xref>; <xref ref-type="bibr" rid="bibr17-1059712312462249">Liang et al., 2010</xref>; <xref ref-type="bibr" rid="bibr25-1059712312462249">Moioli et al., 2008</xref>, <xref ref-type="bibr" rid="bibr24-1059712312462249">2009</xref>; <xref ref-type="bibr" rid="bibr33-1059712312462249">Sauzé &amp; Neal, 2010</xref>; <xref ref-type="bibr" rid="bibr35-1059712312462249">Schmickl et al., 2011</xref>; <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al., 2009</xref>; <xref ref-type="bibr" rid="bibr43-1059712312462249">Vargas et al., 2005</xref>) involves (simulated) robots with pre-learned behaviours that are switched on or off depending on levels of hormones but are not adaptive themselves. Also, the way hormonal modulation works is often evolved and pre-defined for life-time of a robot (<xref ref-type="bibr" rid="bibr9-1059712312462249">Hamann et al., 2010</xref>; <xref ref-type="bibr" rid="bibr24-1059712312462249">Moioli et al., 2009</xref>), although some authors implemented learning algorithms for on-line adjustment of hormonal release (<xref ref-type="bibr" rid="bibr13-1059712312462249">Iizuka &amp; Di Paolo, 2008</xref>; <xref ref-type="bibr" rid="bibr32-1059712312462249">Santos et al., 2010</xref>; <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al., 2009</xref>). <xref ref-type="bibr" rid="bibr44-1059712312462249">Walker and Wilson (2011)</xref> developed on-line adaptation of hormone-to-task sensitivity based on a robot’s effectiveness at a task, showing that heterogeneous robots pre-evolved to be better at different tasks could pick those tasks when given a choice. Similarly, the hormonal release in the UNEC is adaptable, although task performance is evaluated indirectly through the irritation level of neurons responsible for a particular behaviour. Furthermore, on the contrary to the previous work discussed above, there is not a set of pre-configured behaviours and even the most basic random walk and obstacle avoidance are constantly able to change, giving an UNEC-operated robot the ability to perform hormone-selected behaviours under various environmental conditions. More hormone-related perturbations need to be tested in order to confirm this intuition.</p>
<list id="list7-1059712312462249" list-type="simple">
<list-item><p><bold>4. On-line adaption without a body model module</bold></p></list-item>
</list>
<p>There is a relatively new branch of robotics interested in adaptation through body and forward action-reaction modelling advocated, for example, by <xref ref-type="bibr" rid="bibr3-1059712312462249">Bongard, Zykov, and Lipson (2006)</xref>, <xref ref-type="bibr" rid="bibr27-1059712312462249">Moriguchi and Lipson (2011)</xref> and <xref ref-type="bibr" rid="bibr12-1059712312462249">Hild, Kubisch, and Höfer (2011)</xref>. The tests with the UNEC indicate the possibility that there is no need for such a model, at least in a sense that there is no need for a specific place where the model would be stored or calculated and that it is possible to approach behavioural adaptation as a property of a system where adjustments to changes are distributed between the system’s parts.</p>
<p>The following problems with the UNEC were noted.</p>
<list id="list8-1059712312462249" list-type="simple">
<list-item><p><bold>1. No time autonomy</bold></p></list-item>
</list>
<p>The time gap between high activation and reconfiguration is governed by currently hard-coded irritation parameters, preventing the activation from being time autonomous. This problem was apparent especially during adaptation experiments with the appetite gland, which became unstable in cases when food was not available for a prolonged amount of time. It was also problematic to stabilise a proximity neuron when its activation rose too quickly, for example during tests with sensory noise of 0.5. This was observed across different cell parameter ranges. A similar time-dependency problem was found by <xref ref-type="bibr" rid="bibr39-1059712312462249">Timmis et al. (2009)</xref>. It is possible that there is a more fundamental version of ultrastability that could deal with this issue.</p>
<list id="list9-1059712312462249" list-type="simple">
<list-item><p><bold>2. Target of cell adaptation</bold></p></list-item>
</list>
<p>A human designer needs to specify the source of cell activation, that is, what the cell is trying to optimise itself against. Therefore, artificial evolution would probably be needed in order to create more complex controllers.</p>
<p>It is apparent from the above points that apart from relatively poor navigation, which could very probably be improved by adding more complexity, the main problems of the controller were related to designer-specified constants that governed behaviour of the artificial cells. This fact only underlines the importance of ultrastability as a principle that should be applied to as many parameters as possible in order to minimise human-imposed restrictions and increase autonomy. The mechanics based on the type of presented ultrastability tie in with the argument of <xref ref-type="bibr" rid="bibr10-1059712312462249">Haselhager (2005)</xref> that artificial cells should not act because humans programmed them to do so but because they are trying to do something beneficial for themselves, such as to maintain their survival or survival of the artificial creature. Arguably, robots that are hard-coded to blindly execute pre-programmed behaviours have limited life-like behaviour, no self-purpose and a very limited autonomy. It is also questionable whether learning where body and forward models are calculated in a black-box ‘mind’ is not equally blind. Even if such learning can make a machine walk autonomously, autonomy and adaptation will most probably be limited to what a program given by the designer can model and what conditions were assumed when it was designed. This became apparent when most of the problems of the UNEC were related to values of designer-specified parameters.</p>
<p>Only fairly recently, neuroscientists started to lean towards the argument that a self-model of a human probably exists as a configuration of the nervous system itself (<xref ref-type="bibr" rid="bibr23-1059712312462249">Metzinger, 2008</xref>) and that the feeling of ‘self’ is its secondary property (<xref ref-type="bibr" rid="bibr22-1059712312462249">Metzinger, 2006</xref>, <xref ref-type="bibr" rid="bibr23-1059712312462249">2008</xref>; <xref ref-type="bibr" rid="bibr45-1059712312462249">Wegner, 2003</xref>). From this perspective, imposing of self-modelling as a separate function of an artificial body represents a step back towards the Good Old Fashioned AI, when reasoning modules did all sensorimotor calculations in vacuo. This approach was proven limited some time ago (<xref ref-type="bibr" rid="bibr5-1059712312462249">Brooks, 1991</xref>; <xref ref-type="bibr" rid="bibr7-1059712312462249">Dreyfus, 1979</xref>). On the other hand, it is highly probable that a truly space- and time-autonomous robot will plan and feel with its whole body and reconfigure not only its behaviour, but also behavioural planning and execution in order to survive and satisfy its needs. We perhaps need to start looking at approaches to robot design where the overall behaviour itself is not as important as the behaviour of a robot’s interacting artificial cells, appreciating the complexity of their interactions as well as the emergence of phenomena these interactions result in.</p>
</sec>
</body>
<back>
<ack>
<p>This work was performed during my Masters program at the University of Sussex, UK. I would like to thank Professor Phil Husbands and Dr Luc Berthouze for inspiration and feedback. I would also like to thank Dr Inman Harvey and Dr Andy Philippides for their useful advice during writing of this article.</p>
</ack>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.</p>
</fn>
</fn-group>
<bio>
<title>About the Author</title>
<p><bold>Lenka Pitonakova</bold> comes from a software development background and obtained her MSc in evolutionary and adaptive systems from the University of Sussex in 2011. She was recently accepted for a funded PhD program in simulation of complex systems at the University of Southampton. Her interests include biologically inspired computing, swarm intelligence and emergence.</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-1059712312462249">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Ashby</surname><given-names>W. R.</given-names></name>
</person-group> (<year>1960</year>). <source>Design for a Brain: the origin of adaptive behaviour</source> (<edition>2nd edition</edition>). <publisher-loc>London, UK</publisher-loc>: <publisher-name>Chapman and Hall</publisher-name>.</citation>
</ref>
<ref id="bibr2-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Beer</surname><given-names>R. D.</given-names></name>
</person-group> (<year>1995</year>). <article-title>On the dynamics of small continuous-time recurrent neural networks</article-title>. <source>Adaptive Behaviour</source>, <volume>3</volume>, <fpage>469</fpage>–<lpage>509</lpage>.</citation>
</ref>
<ref id="bibr3-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bongard</surname><given-names>J.</given-names></name>
<name><surname>Zykov</surname><given-names>V.</given-names></name>
<name><surname>Lipson</surname><given-names>H.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Resilient machines through continuous self-modeling</article-title>. <source>Science</source>, <volume>314</volume>, <fpage>1118</fpage>–<lpage>1121</lpage>.</citation>
</ref>
<ref id="bibr4-1059712312462249">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bourg</surname><given-names>D. M.</given-names></name>
<name><surname>Seeman</surname><given-names>G.</given-names></name>
</person-group> (<year>2004</year>) <source>AI for game developers</source> (<edition>1st edition</edition>, pp. <fpage>16</fpage>–<lpage>19</lpage>). <publisher-loc>Sebastopol</publisher-loc>: <publisher-name>O’ Reilly Media</publisher-name>.</citation>
</ref>
<ref id="bibr5-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Brooks</surname><given-names>R. A.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Intelligence without reason</article-title>. In <source>Computers and Thought IJCAI- 91</source>, <month>April</month> <year>1991</year>.</citation>
</ref>
<ref id="bibr6-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Di Paolo</surname><given-names>E. A.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Homeostatic adaptation to inversion of the visual field and other sensorimotor disruptions</article-title>. In <person-group person-group-type="editor">
<name><surname>Meyer</surname><given-names>J.-A.</given-names></name>
<name><surname>Berthoz</surname><given-names>A.</given-names></name>
<name><surname>Floreano</surname><given-names>D.</given-names></name>
<name><surname>Roitblat</surname><given-names>H.</given-names></name>
<name><surname>Wilson</surname><given-names>S. W.</given-names></name>
</person-group> (Eds.), From Animals to Animats, <conf-name>Proceedings of the Sixth International Conference on the Simulation of Adaptive Behavior</conf-name> (pp. <fpage>440</fpage>–<lpage>449</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr7-1059712312462249">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Dreyfus</surname><given-names>H. L.</given-names></name>
</person-group> (<year>1979</year>). <source>What computers can’t do: The limits of artificial intelligence</source> (<edition>revised edition</edition>). <publisher-loc>New York</publisher-loc>: <publisher-name>Harper and Row</publisher-name>.</citation>
</ref>
<ref id="bibr8-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>French</surname><given-names>R. L. B.</given-names></name>
<name><surname>Cañamero</surname><given-names>L.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Introducing neuromodulation to a Braitenberg vehicle</article-title>. In <conf-name>Proceedings of the 2005 IEEE International Conference on Robotics and Automation</conf-name>, pp. <fpage>4188</fpage>–<lpage>4193</lpage>.</citation>
</ref>
<ref id="bibr9-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Hamann</surname><given-names>H.</given-names></name>
<name><surname>Strander</surname><given-names>J.</given-names></name>
<name><surname>Schmickl</surname><given-names>T.</given-names></name>
<name><surname>Crailsheim</surname><given-names>K.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A hormone-based controller for evolutionary multi-modular robotics: from single modules to gait learning</article-title>. In <conf-name>Proceedings of the IEEE Congress on Evolutionary Computation</conf-name> (pp. <fpage>244</fpage>–<lpage>251</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE Press</publisher-name>.</citation>
</ref>
<ref id="bibr10-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haselhager</surname><given-names>W. F. G.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Robotics, philosophy and the problems of autonomy</article-title>. <source>Pragmatics &amp; Cognition</source>, <volume>13</volume>, <fpage>515</fpage>–<lpage>532</lpage>.</citation>
</ref>
<ref id="bibr11-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hewson-Hughes</surname><given-names>A. K.</given-names></name>
<name><surname>Hewson-Hughes</surname><given-names>V. L.</given-names></name>
<name><surname>Miller</surname><given-names>A. T.</given-names></name>
<name><surname>Hall</surname><given-names>S. R.</given-names></name>
<name><surname>Simpson</surname><given-names>S. J.</given-names></name>
<name><surname>Raubenheimer</surname><given-names>D.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Geometric analysis of macronutrient selection in the adult domestic cat, Felis catus</article-title>. <source>Journal of Experimental Biology</source>, <volume>214</volume>, <fpage>1039</fpage>–<lpage>1051</lpage>.</citation>
</ref>
<ref id="bibr12-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hild</surname><given-names>M.</given-names></name>
<name><surname>Kubisch</surname><given-names>M.</given-names></name>
<name><surname>Höfer</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Using quadric-representing neurons (QRENs) for real-time learning of an implicit body model</article-title>. In <source>Robotica 2011</source>.</citation>
</ref>
<ref id="bibr13-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Iizuka</surname><given-names>H.</given-names></name>
<name><surname>Di Paolo</surname><given-names>E. A.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Extended homeostatic adaptation: Improving the link between internal and behavioural stability</article-title>. In <person-group person-group-type="editor">
<name><surname>Asada</surname><given-names>M.</given-names></name>
<name><surname>Hallam</surname><given-names>J. C.</given-names></name>
<name><surname>Meyer</surname><given-names>J.</given-names></name>
<name><surname>Tani</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <conf-name>From Animats to Animals 10, the Tenth International Conference on the Simulation of Adaptive Behavior</conf-name> (pp. <fpage>1</fpage>–<lpage>11</lpage>). <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr14-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Josens</surname><given-names>R. B.</given-names></name>
<name><surname>Roces</surname><given-names>F.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Foraging in the ant Camponotus mus: nectar-intake rate and crop filling depend on colony starvation</article-title>. <source>Journal of Insect Physiology</source>, <volume>46</volume>, <fpage>1103</fpage>–<lpage>1110</lpage>.</citation>
</ref>
<ref id="bibr15-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaltenbach</surname><given-names>J. C.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Endocrine aspects of homeostasis</article-title>. <source>American Zoologist</source>, <volume>28</volume>, <fpage>761</fpage>–<lpage>773</lpage>.</citation>
</ref>
<ref id="bibr16-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lefebvre</surname><given-names>D.</given-names></name>
<name><surname>Pierre</surname><given-names>J.</given-names></name>
<name><surname>Outreman</surname><given-names>Y.</given-names></name>
<name><surname>Pierre</surname><given-names>J.-S.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Patch departure rules in Bumblebees: evidence of a decremental motivational mechanism</article-title>. <source>Behavioral Ecology and Sociobiology</source>, <volume>61</volume>, <fpage>1707</fpage>–<lpage>1715</lpage>.</citation>
</ref>
<ref id="bibr17-1059712312462249">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Liang</surname><given-names>J.</given-names></name>
<name><surname>You</surname><given-names>H.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A hormone-modulated emotional model</article-title>. In <conf-name>2010 2nd International Conference on Computer Engineering and Technology</conf-name>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5485816">http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5485816</ext-link></citation>
</ref>
<ref id="bibr18-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Manicka</surname><given-names>S.</given-names></name>
<name><surname>Di Paolo</surname><given-names>E. A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Local ultrastability in a real system based on programmable springs</article-title>. In <person-group person-group-type="editor">
<name><surname>Kampis</surname><given-names>G.</given-names></name>
<name><surname>Karsai</surname><given-names>I.</given-names></name>
<name><surname>Szathmary</surname><given-names>E.</given-names></name>
</person-group> (Eds.), <conf-name>Advances in Artificial Life, Proceedings of the 10th European Conference on Artificial Life, ECAL09</conf-name> (LNAI 5777: 87–94). <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr19-1059712312462249">
<citation citation-type="web"><collab>Matlab A: anova1</collab>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.co.uk/help/stats/anova1.html">http://www.mathworks.co.uk/help/stats/anova1.html</ext-link></citation>
</ref>
<ref id="bibr20-1059712312462249">
<citation citation-type="web"><collab>Matlab B: box plots</collab>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.co.uk/help/stats/boxplot.html">http://www.mathworks.co.uk/help/stats/boxplot.html</ext-link></citation>
</ref>
<ref id="bibr21-1059712312462249">
<citation citation-type="web"><collab>Matlab C: multcompare</collab>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.co.uk/help/stats/multcompare.html">http://www.mathworks.co.uk/help/stats/multcompare.html</ext-link></citation>
</ref>
<ref id="bibr22-1059712312462249">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Metzinger</surname><given-names>T.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Conscious volition and mental representation: towards a more fine-grained analysis</article-title>. In <person-group person-group-type="editor">
<name><surname>Sebanz</surname><given-names>N.</given-names></name>
<name><surname>Prinz</surname><given-names>W.</given-names></name>
</person-group> (Eds.), <source>Disorders of volition</source> (pp. <fpage>19</fpage>–<lpage>48</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr23-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Metzinger</surname><given-names>T.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Empirical perspectives from the self-model theory of subjectivity: a brief summary with examples</article-title>. <source>Progress in Brain Research</source>, <volume>168</volume>, <fpage>215</fpage>–<lpage>244</lpage>.</citation>
</ref>
<ref id="bibr24-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Moioli</surname><given-names>R. C.</given-names></name>
<name><surname>Vargas</surname><given-names>P. A.</given-names></name>
<name><surname>Husbands</surname><given-names>P.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A multiple hormone approach to the homeostatic control of conflicting behaviours in an autonomous mobile robot</article-title>. In <person-group person-group-type="editor">
<name><surname>Tyrrell</surname><given-names>A.</given-names></name>
</person-group> (Ed.), <conf-name>Proceedings of IEEE Congress on Evolutionary Computation</conf-name> (pp. <fpage>47</fpage>–<lpage>54</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE Press</publisher-name>.</citation>
</ref>
<ref id="bibr25-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moioli</surname><given-names>R. C.</given-names></name>
<name><surname>Vargas</surname><given-names>P. A.</given-names></name>
<name><surname>Von Zuben</surname><given-names>F. J.</given-names></name>
<name><surname>Husbands</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <source>Evolving an artificial homeostatic system. Lecture Notes in Artificial Intelligence</source>, <volume>5249</volume>, <fpage>278</fpage>–<lpage>288</lpage>.</citation>
</ref>
<ref id="bibr26-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Montebelli</surname><given-names>A.</given-names></name>
<name><surname>Lowe</surname><given-names>R.</given-names></name>
<name><surname>Ieropoulos</surname><given-names>I.</given-names></name>
<name><surname>Melhuish</surname><given-names>C.</given-names></name>
<name><surname>Greenman</surname><given-names>J.</given-names></name>
<name><surname>Ziemke</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Microbial fuel cell driven behavioral dynamics in robot simulations</article-title>. In <person-group person-group-type="editor">
<name><surname>Fellerman</surname><given-names>H.</given-names></name>
<etal/>
</person-group>. (Eds.), <conf-name>Proceedings of the Twelfth International Conference on the Synthesis and Simulation of Living Systems</conf-name> (pp. <fpage>749</fpage>–<lpage>756</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr27-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Moriguchi</surname><given-names>H.</given-names></name>
<name><surname>Lipson</surname><given-names>H.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Learning symbolic forward models for robotic motion planning and control</article-title>. In <conf-name>Proceedings of European Conference of Artificial Life (ECAL 2011)</conf-name> (pp. <fpage>558</fpage>–<lpage>564</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr28-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Neal</surname><given-names>M.</given-names></name>
<name><surname>Timmis</surname><given-names>J.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Timidity: a useful mechanism for robot control?</article-title> <source>Informatica</source>, <volume>4</volume>, <fpage>197</fpage>–<lpage>204</lpage>.</citation>
</ref>
<ref id="bibr29-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>O’Brien</surname><given-names>K. S.</given-names></name>
<name><surname>Hooper-Bùi</surname><given-names>L. M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Sucrose intake and percent effort by the red imported fire ant, Solenopsis invicta Buren (Hymenoptera: Formicidae)</article-title>. In <person-group person-group-type="editor">
<name><surname>Lee</surname><given-names>C.-Y.</given-names></name>
<name><surname>Robinson</surname><given-names>W. H.</given-names></name>
</person-group> (Eds.), <conf-name>Proceedings of the 5th International Conference on Urban Pests</conf-name> (pp. <fpage>135</fpage>–<lpage>139</lpage>). <publisher-loc>Malaysia</publisher-loc>: <publisher-name>Perniagaan Ph’ng</publisher-name>.</citation>
</ref>
<ref id="bibr30-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Portha</surname><given-names>S.</given-names></name>
<name><surname>Deneubourg</surname><given-names>J.-L.</given-names></name>
<name><surname>Detrain</surname><given-names>C.</given-names></name>
</person-group> (<year>2004</year>). <article-title>How food type and brood influence foraging decisions of Lasius niger scouts</article-title>. <source>Animal Behaviour</source>, <volume>68</volume>, <fpage>115</fpage>–<lpage>122</lpage>.</citation>
</ref>
<ref id="bibr31-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sánchez-Lasheras</surname><given-names>C.</given-names></name>
<name><surname>Könner</surname><given-names>A. C.</given-names></name>
<name><surname>Brüning</surname><given-names>J. C.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Integrative neurobiology of energy homeostasis - neurocircuits, signals and mediators</article-title>. <source>Frontiers in Neuroendocrinology</source>, <volume>31</volume>, <fpage>4</fpage>–<lpage>15</lpage>.</citation>
</ref>
<ref id="bibr32-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Santos</surname><given-names>B. A.</given-names></name>
<name><surname>Husbands</surname><given-names>P.</given-names></name>
<name><surname>Froese</surname><given-names>T.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Accommodating homeostatically stable dynamical regimes to cope with different environmental conditions</article-title>. In <person-group person-group-type="editor">
<name><surname>Fellerman</surname><given-names>H.</given-names></name>
<name><surname>Dörr</surname><given-names>M.</given-names></name>
<name><surname>Hanczyc</surname><given-names>M.M</given-names></name>
<name><surname>Laursen</surname><given-names>L. L.</given-names></name>
<etal/>
</person-group>. (Eds.), <conf-name>Proceedings of the Alife XII Conference</conf-name> (pp. <fpage>395</fpage>–<lpage>402</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr33-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Sauzé</surname><given-names>C.</given-names></name>
<name><surname>Neal</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A neuro-endocrine inspired approach to long term energy autonomy in sailing robots</article-title>. In <conf-name>Proceedings of TAROS (Towards Autonomous Robotic Systems) 2010</conf-name> (pp. <fpage>255</fpage>–<lpage>262</lpage>), <conf-date>August 31st–September 2nd 2010</conf-date>.</citation>
</ref>
<ref id="bibr34-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Schmickl</surname><given-names>T.</given-names></name>
<name><surname>Hamann</surname><given-names>H.</given-names></name>
<name><surname>Strander</surname><given-names>J.</given-names></name>
<name><surname>Mayet</surname><given-names>R.</given-names></name>
<name><surname>Crailsheim</surname><given-names>K.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Complex taxis-behaviour in a novel bio-inspired robot controller</article-title>. In <person-group person-group-type="editor">
<name><surname>Fellermann</surname></name>
<etal/>
</person-group>. (Eds.), <conf-name>Proceedings of the Alife XII Conference</conf-name> (pp. <fpage>648</fpage>–<lpage>655</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr35-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Schmickl</surname><given-names>T.</given-names></name>
<name><surname>Thenius</surname><given-names>R.</given-names></name>
<name><surname>Strander</surname><given-names>J.</given-names></name>
<name><surname>Hamann</surname><given-names>H.</given-names></name>
<name><surname>Crailsheim</surname><given-names>K.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Robotic organisms - artificial homeostatic hormone system and virtual embryogenesis as examples for adaptive reaction-diffusion controllers</article-title>. In <person-group person-group-type="editor">
<name><surname>Kernbach</surname><given-names>S.</given-names></name>
<name><surname>Fitch</surname><given-names>R.</given-names></name>
</person-group> (Eds.), <conf-name>Reconfigurable Modular Robotics: Challenges of Mechatronic and Bio-Chemo-Hybrid Systems (IROS 2011 Workshop)</conf-name>.</citation>
</ref>
<ref id="bibr36-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Shen</surname><given-names>W.</given-names></name>
<name><surname>Will</surname><given-names>P.</given-names></name>
<name><surname>Galstyan</surname><given-names>A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Hormone-inspired self-organization and distributed control of robotic swarms</article-title>. <source>Autonomous Robots</source>, <volume>17</volume>, <fpage>93</fpage>–<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr37-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Simpson</surname><given-names>S. J.</given-names></name>
<name><surname>Raubenheimer</surname><given-names>D.</given-names></name>
</person-group> (<year>1993</year>). <article-title>A multi-level analysis of feeding behaviour: the geometry of nutritional decisions</article-title>. <source>Philosophical Transactions of the Royal Society</source>, <volume>342</volume>, <fpage>381</fpage>–<lpage>402</lpage>.</citation>
</ref>
<ref id="bibr38-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Surmeier</surname><given-names>D. J.</given-names></name>
<name><surname>Plotkin</surname><given-names>J.</given-names></name>
<name><surname>Shen</surname><given-names>W.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Dopamine and synaptic plasticity in dorsal striatal circuits controlling action selection</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>19</volume>, <fpage>621</fpage>–<lpage>628</lpage>.</citation>
</ref>
<ref id="bibr39-1059712312462249">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Timmis</surname><given-names>J.</given-names></name>
<name><surname>Neal</surname><given-names>M.</given-names></name>
<name><surname>Thorniley</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>An adaptive neuro-endocrine system for robotic systems</article-title>. In <conf-name>Workshop on Robotic Intelligence in Informationally Structured Space, (RIISS ’09)</conf-name> (pp. <fpage>129</fpage>–<lpage>136</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE Press</publisher-name>.</citation>
</ref>
<ref id="bibr40-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tolley</surname><given-names>M. T.</given-names></name>
<name><surname>Lipson</surname><given-names>H.</given-names></name>
</person-group> (<year>2011</year>). <article-title>On-line assembly planning for stochastically reconfigurable systems</article-title>. <source>International Journal of Robotic Research</source>, <volume>30</volume>, <fpage>1566</fpage>–<lpage>1584</lpage>.</citation>
</ref>
<ref id="bibr41-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tsankova</surname><given-names>D. D.</given-names></name>
</person-group> (<year>2009</year>). <article-title>‘Emotional Intervention on an Action Selection Mechanism Based on Artificial Immune Networks for Navigation of Autonomous Agents</article-title>. <source>Adaptive Behaviour</source>, <volume>17</volume>, <fpage>135</fpage>–<lpage>152</lpage>.</citation>
</ref>
<ref id="bibr42-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Turrigiano</surname><given-names>G. G.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Homeostatic plasticity in neuronal networks: the more things change, the more stay the same</article-title>. <source>Trends in Neurosciences</source>, <volume>2</volume>, <fpage>221</fpage>–<lpage>227</lpage>.</citation>
</ref>
<ref id="bibr43-1059712312462249">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Vargas</surname><given-names>P.</given-names></name>
<name><surname>Moioli</surname><given-names>R.</given-names></name>
<name><surname>de Castro</surname><given-names>L. N.</given-names></name>
<name><surname>Timmis</surname><given-names>J.</given-names></name>
<name><surname>Neal</surname><given-names>M.</given-names></name>
<name><surname>Von Zuben</surname><given-names>F. J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Artificial homeostatic system: a novel approach</article-title>. In <person-group person-group-type="editor">
<name><surname>Capcarrere</surname><given-names>M.</given-names></name>
<etal/>
</person-group>. (Eds.), <source>ECAL 2005</source> (LNAI 3630:754–764). <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</citation>
</ref>
<ref id="bibr44-1059712312462249">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Walker</surname><given-names>J. H.</given-names></name>
<name><surname>Wilson</surname><given-names>M. S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Task allocation for robots using inspiration from hormones</article-title>. <source>Adaptive Behaviour</source>, <volume>19</volume>, <fpage>208</fpage>–<lpage>224</lpage>.</citation>
</ref>
<ref id="bibr45-1059712312462249">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wegner</surname><given-names>D. M.</given-names></name>
</person-group> (<year>2003</year>). <source>The illusion of conscious will</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>