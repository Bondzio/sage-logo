<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">STH</journal-id>
<journal-id journal-id-type="hwp">spsth</journal-id>
<journal-title>Science, Technology, &amp; Human Values</journal-title>
<issn pub-type="ppub">0162-2439</issn>
<issn pub-type="epub">1552-8251</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0162243911433057</article-id>
<article-id pub-id-type="publisher-id">10.1177_0162243911433057</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Co-production of Science, Ethics, and Emotion</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Pickersgill</surname>
<given-names>Martyn</given-names>
</name>
<xref ref-type="aff" rid="aff1-0162243911433057">1</xref>
<xref ref-type="corresp" rid="corresp1-0162243911433057"/>
</contrib>
<aff id="aff1-0162243911433057"><label>1</label>Centre for Population Health Sciences, University of Edinburgh, Edinburgh, United Kingdom</aff>
<bio>
<title>Bio</title>
<p>
<bold>Martyn Pickersgill</bold> is Wellcome Trust Senior Research Fellow, University of Edinburgh. A sociologist, his research is primarily concerned with the social and ethical dimensions of biomedicine and the human sciences. He is lead editor of <italic>Sociological Reflections on the Neurosciences,</italic> and a member of the Editorial Board of the journal <italic>Sociology of Health &amp; Illness</italic>.</p>
</bio>
</contrib-group>
<author-notes>
<corresp id="corresp1-0162243911433057">Martyn Pickersgill, Centre for Population Health Sciences, University of Edinburgh, Medical School, Teviot Place, Edinburgh  EH8 9AG, United Kingdom Email: <email>martyn.pickersgill@ed.ac.uk</email>
</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>11</month>
<year>2012</year>
</pub-date>
<volume>37</volume>
<issue>6</issue>
<fpage>579</fpage>
<lpage>603</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The concept of “ethical research” holds considerable sway over the ways in which contemporary biomedical, natural, and social science investigations are funded, regulated, and practiced within a variety of countries. Some commentators have viewed this “new” means of governance positively; others, however, have been resoundingly critical, regarding it as restrictive and ethics bodies and regulations unfit for the task they have been set (or have set themselves). Regardless, it is clear that science today is an “ethical” business. The ways in which formal and informal ethical discourses and practices—what might be called “regimes of normativity”—structure scientific work and the meanings it is ascribed with have, however, been underexplored. This article attends to how science and ethics articulate; how they are, in many ways, co-produced. Exploring these processes of co-production casts into sharp relief the essential emotionality of science; the relationships investigators have with their colleagues, work, and research participants pulse with emotion, potentially shaping in important ways the very kinds of knowledge that laboratories produce.</p>
</abstract>
<kwd-group>
<kwd>academic disciplines and traditions</kwd>
<kwd>ethics</kwd>
<kwd>labor</kwd>
<kwd>emotion</kwd>
<kwd>power</kwd>
<kwd>governance</kwd>
<kwd>law</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0162243911433057">
<title>Introduction</title>
<p>“Western” bioethics—the assemblage of traditions and professionals that take as their focus the normative analysis of biomedicine—has never been more influential. In response, science and technology studies scholars have examined the development, framing, implementation, and problematization of bioethics in practice (<xref ref-type="bibr" rid="bibr11-0162243911433057">Felt et al. 2009</xref>; <xref ref-type="bibr" rid="bibr35-0162243911433057">Sperling 2004</xref>; <xref ref-type="bibr" rid="bibr37-0162243911433057">Svendsen and Koch 2008</xref>).<sup>
<xref ref-type="fn" rid="fn1-0162243911433057">1</xref>
</sup> Such studies have signal the contextual and open-ended nature of bioethical discussion, as well as its political economy and the great degree to which the normative is grounded in everyday practices of laboratories and clinics (<xref ref-type="bibr" rid="bibr9-0162243911433057">Easter et al. 2006</xref>; Hedgecoe <xref ref-type="bibr" rid="bibr18-0162243911433057">2006</xref>; Hedgecoe and Martin <xref ref-type="bibr" rid="bibr19-0162243911433057">2003</xref>; <xref ref-type="bibr" rid="bibr46-0162243911433057">Salter 2007</xref>; <xref ref-type="bibr" rid="bibr40-0162243911433057">Wainwright et al. 2006</xref>).</p>
<p>This article contributes to this emergent sociology of bioethics through an analysis of the association between scientific work (specifically, neuroscience) and the webs of official and informal institutions, agents and discourses that prescribe what scientists ought to do (what we might call “regimes of normativity”). By framing my analysis in terms of the normative broadly, the author seeks to move away from an understanding of “ethics” in science as solely defined by and under the purview of formal regulatory bodies and moral philosophers. Accordingly, the author brings to bear concerns with how science and the normative impact one another, and how (in)formal norms transform the relationships scientists have with their work.</p>
</sec>
<sec id="section2-0162243911433057">
<title>Neuroscience and Ethics</title>
<p>The move toward “ethical governance” within biomedicine broadly is exemplified in the United Kingdom by the interdisciplinary endeavor of neuroscience. This set of overlapping traditions and approaches is, of course, subject to the usual regulatory structures (the Data Protection Act, National Health Service Research Ethics Committees (NHS RECS), University departmental ethical review boards, etc.) that govern science. However, a whole new branch of bioethics—neuroethics—has also emerged to tackle the unprecedented issues some believe are associated with developments in the neurosciences (<xref ref-type="bibr" rid="bibr6-0162243911433057">de Vries 2007</xref>).</p>
<p>The work of neuroethicists is wide-ranging, dealing with issues as diverse as how to protect the privacy of research participants, to determining the criteria for (brain) death, to reflecting on the role of neuroscientists in professions like law. Many of these might be regarded as important issues; however, as <xref ref-type="bibr" rid="bibr6-0162243911433057">de Vries (2007</xref>) has argued, it is uncommon for neuroethicists to appraise critically scientific claims—only their implications. A failure to engage with the knowledge practices and rhetoric of science implicitly constructs boundaries between science and ethics; hence, science is viewed as having ethical <italic>implications</italic> but not an ethical <italic>dimension</italic> per se: ethical deliberation comes after (or, occasionally, before) the “facts” of science but is not viewed as constitutive of knowledge production. Consequently, opportunities for reflection on how neuroscience and the normative articulate are closed down.</p>
<p>In contrast to figurations of science and ethics that view these as fundamentally discrete categories, social scientists have painted somewhat different pictures of the relationships between these domains. Stem cell science, for instance, has been shown to be structured in important ways by imaginaries of “the public” and their actual or assumed positions in relation to this endeavour, shaping profoundly the regulation of science and the availability of embryos for research (<xref ref-type="bibr" rid="bibr35-0162243911433057">Sperling 2004</xref>). As <xref ref-type="bibr" rid="bibr40-0162243911433057">Wainwright et al. (2006</xref>) demonstrate within the laboratory setting, ethical positions and frameworks have a dynamic relationship with actual scientific practice, undergirding the kinds of work that can be done and the means by which it can be legitimated. Furthermore, as anthropologist <xref ref-type="bibr" rid="bibr2-0162243911433057">Brodwin (2008</xref>) illustrates in the case of US psychiatry, formal ethical governance, and informal moral discourses interpolate not only one another but are also coproduced with clinical work.</p>
<p>Brodwin’s use of “co-production” is reflexively indebted to the articulation of this idiom within science and technology studies (STS) by Sheila <xref ref-type="bibr" rid="bibr23-0162243911433057">Jasanoff (2004</xref>). In her words: <disp-quote>
<p>[C]o-production is shorthand for the proposition that the ways in which we know and represent the world (both nature and society) are inseparable from the ways in which we choose to live in it. Knowledge and its material embodiments are at once products of social work and constitutive of forms of social life. (<xref ref-type="bibr" rid="bibr23-0162243911433057">Jasanoff 2004</xref> 2)</p>
</disp-quote>
</p>
<p>For Brodwin, a coproductionist framework is valuable in that it helps to “illuminate the connections between things usually regarded as ontologically distinct” (<xref ref-type="bibr" rid="bibr2-0162243911433057">Brodwin 2008</xref>, 129). Accordingly, it is a useful perspective from which to approach the regimes of biomedicine and ethics. We might usefully understand “the ethical” as relating here not solely to the terrain defined and charted by bioethicists, but the assemblage of morally inflected global and local discourses and practices that together form a “regime of normativity,” and which has a part to play in the structuring of everyday work.</p>
<p>Here, such findings and theoretical orientations are a departure point for a broad analysis of the relationship between neuroscience and issues understood to be related to “ethics.” The paper attends to the kinds of concerns that neuroscientists regard their research as raising and explores how regimes of normativity shape processes of laboratory work. Such an analysis creates a vantage point from which we might view how ideas about ethics transform scientists’ relationships with their work; in particular, the emotions it stimulates and channels, and the consequences of this for knowledge production.</p>
</sec>
<sec id="section3-0162243911433057" sec-type="methods">
<title>Method</title>
<p>The article draws upon six semistructured focus groups undertaken at three research-intensive UK universities. The groups are a subset of sixteen conducted with scientists, various professionals (e.g., counsellors and teachers) and patient groups (including Alzheimer’s disease and epilepsy). These were convened to explore how “issues and identities interweave” (<xref ref-type="bibr" rid="bibr41-0162243911433057">Waterton and Wynne 1999</xref>, 142) in discourse on the place of neuroscience in society, as part of an Economic and Social Research Council (ESRC)-funded study on “Constituting Neurologic Subjects.”</p>
<p>Each focus group contained three researchers (<italic>n</italic> = 18) who in some way identified as a “neuroscientist.” Most of the sample were early career scientists; seven were male and eleven were female. Recruitment was primarily via targeted e-mails inviting laboratory group heads to circulate a participant information sheet, as well as invitations disseminated by scientists with whom the author already had a relationship. Mirroring the breadth of the neurosciences, the participants’ work was wide-ranging: from pathological studies of neurologic diseases to neurogenetic studies of mental disorders. The majority of the scientists worked directly with human subjects; however, some dealt only with tissue or animals. The focus groups were all conducted at the institution where the scientist worked, each lasting (from entrance to exit of the researcher) approximately ninety minutes. All were digitally recorded and professionally transcribed.</p>
<p>Discussion within the focus groups was structured around three key themes: the nature of the scientists’ work; the “ethical” dimensions of neuroscience broadly; and the place and role of neuroscience in society. Questions were designed to elicit discussions centring on the implications and dilemmas of neuroscience, including personal and professional challenges the scientists had faced or which they could conceive. The participants were encouraged to recognize their position as “active subjects” (<xref ref-type="bibr" rid="bibr5-0162243911433057">Cunningham-Burley, Kerr, and Pavis 1999</xref>, 191) in the group who might “engage with one another” (<xref ref-type="bibr" rid="bibr25-0162243911433057">Kitzinger 1994</xref>, 106) though mutual questioning, enabling more dynamic discussion. Data were analyzed deductively using the NVivo software package: exchanges and comments pertaining in some way to “ethics” were coded and subjected to multiple readings in order to develop an understanding of the relationship between scientific work and the regimes of normativity governing it.</p>
<p>The methodological framework of the study and its sample characteristics have implications for generalizability. In particular, a focus on predominantly early career UK researchers, most of whom were concerned with human subjects (and several of which were engaged in neuroimaging), cannot be regarded as representative of all neuroscientists. Indeed, the term neuroscientist is itself problematic, given the extent to which “neuroscience” is made up of a whole range of approaches and methodological traditions. However, what this article can evidence is the broad tendency of science and ethics to articulate with one another in complex ways; this is illustrated with concrete examples that may well also be important features of knowledge production in quite different institutional and scientific contexts. Furthermore, while there may be caveats to the use of focus groups in highlighting the processes of fact-making in science, these are particularly useful in order to stimulate the (co-)telling of stories by respondents which can illustrate themes which are salient to the participants. Such stories are often fleshed out through prompts made by other focus group members; these commonly drew on specialist knowledge, and thus can have an advantage over traditional interviews in that focus group members themselves partly take on the role of interviewer. Future work on the co-production of science, ethics, and emotion might usefully employ a comparative historical approach or utilize longitudinal multisited ethnography.</p>
<p>In what follows, the author discusses broadly the meanings of ethical practice and practical ethics within neuroscience, before going on to interrogate-specific examples of issues to which discourses of ethics and morality adhere. The article moves then to discuss a specific and important example of the co-production of science, ethics, and emotions: the challenge of clinically significant incidental findings located through brain imaging. The paper concludes with further reflections on neuroscience and the normative, and how this might relate to scholarship on neuroethics.</p>
</sec>
<sec id="section4-0162243911433057">
<title>Ethical Practice and Practical Ethics</title>
<p>Although many scientists “dread” (M3, group 5), the bureaucracy of securing ethics approval, they nevertheless feel a duty to ensure their work is conducted “ethically” according to both formal and informal guidelines and norms. As one focus group member noted when introducing herself, “the ethics and management of brain imaging is really becoming a very key feature of […] everyday imaging” (F2, group 4). Yet, what does “ethical” research mean, and what do scientists consider important? The issues that the participants pointed to as “ethical” were wide-ranging, reflecting both the promissory nature of neuroscience and the diverse institutional and personal norms governing research. One extract exemplifies the broad feeling about research ethics felt across the range of focus group participants:<disp-quote>
<p>I think when I say you know ethical research, I don’t mean research passed by an ethics committee I mean ethical to what I would consider ethical and I couldn’t bring myself to do anything that I didn’t consider ethical in my job even if its been passed by an ethics committee. I guess researchers should hold themselves to that standard. (F1, group 2)</p>
</disp-quote>
</p>
<p>Some of the complexity regarding neuroscience and the normative that will be set out in this analysis can be introduced through a brief word on recruitment. As any investigator undertaking human subjects research knows, participant recruitment is seldom an easy task and it can have significant implications for the nature of the study. At a neuropsychiatry conference observed as part of this research, one presenter noted how a colleague had departed from a particular area of study as a consequence of severe difficulties in recruiting participants. Such problems were far from foreign both in my own study, and for those who agreed to take part in it. In one focus group (group 1), three postdoctoral neuroscientists reflected on the terminologies their different ethics approval committees had enjoined them to use in their recruitment materials, and the potential effects of this on their work. One scientist (F3) was particularly disgruntled that another focus group member (F2) was forced by her department to adjust the wording of a recruitment poster such that it stated participants would not be “paid,” but would instead receive an “inconvenience allowance.” This terminological shift, and the deletion of the sum involved, was regarded as neither helpful nor any more “ethical” than the alterative. After all, it was imputed, the “pay” was a minor financial incentive, which although not so large a sum as to coerce participation would nevertheless act as a helpful inducement. As one scientist (F3, group 1) reflected, “it’s just so hard to get subjects. Also if you need to get subjects from the general public, you know, you <italic>need </italic>these tricks.” The described change to the practical ethics of recruitment did not lead, in this scientist’s eyes, to more ethical practice. Rather, it <italic>transformed</italic> practice: the nature of recruitment was remade, and knowledge production arguably impeded.</p>
<p>This transformation of scientific practice due to ethical norms, and the ways in which practice might transform the topography of the terrain scientists view as “ethical,” is the primary focus of the remainder this article. In the rest of this section, the analysis will be developed by exploring three interrelated examples of topics constructed by the focus group participants as ethical matters: international collaboration; confidentiality; and the social implications of science. To different extents, all of these were figured as both produced by neuroscientific developments and as engines of knowledge production themselves.</p>
<sec id="section5-0162243911433057">
<title>International Collaboration</title>
<p>Some of the scientists highlighted instances of personal ambivalence regarding <italic>international collaboration</italic>, such as when working with countries perceived to have less stringent methods of formal ethical governance than the United Kingdom. Collaboration in this case “leaves you with this slight uneasy feeling in your stomach” (F2, group 4). Yet, in spite of the boundaries the scientists drew between more and less ethical countries (e.g., the United States vs. China), it did not seem to be the case that their own research had been shaped by these concerns; for instance, no examples were given of collaborations that had broken down as a result of disagreements relating to ethics, nor had perceived differences prevented collaboration in the first place. Yet, the <italic>idea</italic> of potential differences, and the problems these might create, was resonant in the scientists’ talk. This suggested that, at some level, a shared normative agenda did play a role in structuring scientific collaboration. Furthermore, the unease inherent in working with a “country that doesn’t have the same ethics” (F2, group 4) shifted scientists’ relationships with their work.</p>
<p>Since collaborators in existing networks did share broadly similar principles, the potential significance of formal and personal ethical codes was largely eclipsed by “scientific” exigencies. The ethical dynamics of collaboration were therefore seen as having more import in the future than the present. For instance, some of the participants were disquieted by the possibility (constructed within the focus group setting) that “less ethical” countries could “get there first” in answering particular questions. Accordingly, future scientific advances in the United Kingdom—understood to be an unproblematic necessity—might one day depend on direct collaboration with unprincipled researchers or nation states (or, at the very least, implicitly endorse dubious practices through drawing on data produced by them). Scientists thus can face difficult decisions regarding who to work with, and what research can be done.</p>
</sec>
<sec id="section6-0162243911433057">
<title>Confidentiality</title>
<p>Friction also exists between ethical requirements and norms, and the practicalities of scientific work in regards to the twin necessities of assuring participant <italic>confidentiality</italic> and sharing research data. Again, while these scientific/normative practices are characteristic of biomedicine broadly (Wouters and Shroeder <xref ref-type="bibr" rid="bibr45-0162243911433057">2003</xref>), in the neurosciences (especially neuroimaging) they are ascribed a particular importance, given the cultural and biological significance of the brain, and the necessity of sharing imaging data with other investigators within and beyond the research team. This leads, then, to the necessity of scientists engaging with the question of how raw data can be shared between investigators without compromising the anonymity of research participants.</p>
<p>For those who took part in this research, the significance of this problem had increased—and was expected to increase further—as a result of the greater “depth” of information about an individual that new neuroimaging technologies routinely collected, regardless of the research question. Accordingly, practice in the distributed laboratory had to change to manage these difficulties: more than ever before, scientists have to make strenuous efforts to divorce their data from anything that might help identify its (human) source. As one scientist (M3, group 3) pointed out, this does not merely change specific features of scientific work, but the relationships investigators have with that: scientists no longer “own” data, so much as act as responsible chaperones toward it. Operationalizing such normative practice involves “trying to change the structure” (M3, group 3) of everyday scientific work.</p>
</sec>
<sec id="section7-0162243911433057">
<title>Social Implications of Science</title>
<p>Discussions of confidentiality resonated with a wider concern with the <italic>social implications of science</italic>. As neuroethicists have extensively discussed (<xref ref-type="bibr" rid="bibr10-0162243911433057">Farah 2002</xref>; <xref ref-type="bibr" rid="bibr12-0162243911433057">Fuchs 2006</xref>; <xref ref-type="bibr" rid="bibr22-0162243911433057">Illes and Racine 2005</xref>), and which the focus group participants described, when neuroimaging technologies increase in resolution and experiments become ever more elegant, research ethics became increasingly important to consider. One scientist summed up the thoughts of all the participants across the range of focus groups when she reflected,<disp-quote>
<p>I think the scope of what we can do is broadening all the time and every time you find out something new, you have to consider the implications on your [research] population. (F1, group 2)</p>
</disp-quote>
</p>
<p>Some of the participants feared that data produced about research subjects could reveal important information to scientists, and have the potential to impact upon, for instance insurance, expectations about old age, legal credibility, etc. Like many ethicists and scientists (<xref ref-type="bibr" rid="bibr10-0162243911433057">Farah 2002</xref>; <xref ref-type="bibr" rid="bibr14-0162243911433057">Gazzaniga 2005</xref>; <xref ref-type="bibr" rid="bibr22-0162243911433057">Illes and Racine 2005</xref>), as well as wider publics (<xref ref-type="bibr" rid="bibr31-0162243911433057">Pickersgill, Cunningham-Burley, and Martin 2011</xref>), the researchers were wary of a neuroscience which could reveal an individual’s thoughts and could predict “pathological” behaviors such as extreme criminality. Research like this might lead to “labeling” (F1, group 4) or “compartmentalizing” (F2, group 4) people. Accordingly, work involving the participation of children, prisoners or “vulnerable people” (F2, group 4) was avoided. This could cause considerable friction within institutions when colleagues were undertaking research that the scientists considered unethical.</p>
<p>However, a minority of scientists reflexively positioned themselves in opposition to these future-orientated narratives, highlighting instead the “hype” associated with neuroscience and arguing that it should be resisted (cf. <xref ref-type="bibr" rid="bibr19-0162243911433057">Hedgecoe and Martin 2003</xref>, 8). Such individuals nevertheless allowed for the possibility that grand sociotechnical promises (e.g., mind reading and its use by states) might be realized:<disp-quote>
<p>[T]here’s definitely a lot of ethical implications on that in terms of what the average person thinks that these methods can do and can’t do, and what they actually can do. And if the methods should get to the point where they <italic>could</italic> do things like that, to what extent is it going to get used in what way. (F1, group 1)</p>
</disp-quote>
</p>
<p>After all, “you want to develop your imaging techniques, but how can you control what it’s being applied to?” (F2, group 4)</p>
<p>However, none of the scientists thought that “dangerous” research should be limited. A question regarding whether there were any areas of research that should not be carried out at all commonly met with passionate rebuttals: “Absolutely not!” (F1, group 3) laughed one scientist, in mock horror. As a different participant put it: <disp-quote>
<p>I think you can research any question you want. The question is how you design your research, how ethical is the design in order to answer the question you’re looking at. (F2, group 2)</p>
</disp-quote>
</p>
<p>Put another way: “a good experiment is a good experiment as long as you’ve got full informed consent, actually!” (F1, group 3)</p>
<p>As with “nuclear power” (F1, group 1; and also F1, group 5)—a potent symbol of the ambivalence associated with technoscientific progress—new neuroscientific developments were regarded as neither intrinsically good nor bad. Rather, the implications of new knowledge were argued to “come down to the people who use it” (F1, group 1). Given such sentiments, it is perhaps unsurprising that when asked questions like “is there anything you think shouldn’t be researched?” the scientists were either silent as they struggled to locate any relevant issues or emphatically stated that nothing should be “off-limits” to science. The latter was justified in terms of international differences in research ethics: if the United Kingdom was too restrictive, a “less ethical” country might carry out the prohibited research instead, since “somebody somewhere’s going to do it” (M3, group 3). Accordingly, some of the respondents argued, “you just can’t stop research” (F1, group 3); attempts do so would, they believed, introduce barriers to scientific work that should and perhaps could not be enforced.</p>
<p>Such assertions efface the great degree to which science is already (in)formally governed, partly through researchers’ own sensibilities. We can hear two voices, then, within the focus groups: on the one hand, the participants extolled the virtues of “ethical” research and lamented the possibility of “irresponsible” scientists undertaking socially regressive research; on the other, a deterministic narrative of progress was told, wherein attempts to “stop” science were deplored—even as the scientific enterprise was figured as ultimately impervious to such challenges (cf. <xref ref-type="bibr" rid="bibr16-0162243911433057">Hagendijk 2004</xref>). These “two voices” resonate with those heard earlier, in the discussion of participant recruitment; while scientists aim to conduct research in ways they considered ethically robust, they also seem to claim that regulation stifles good science.</p>
<p>Such ambivalence underscores the complicated relationships between scientific knowledge production and its associated ethical debates. Normativity is embedded within all aspects of science: both the processes and products of science are taken to have ethical implications which, consequently, shape both scientific work and the relationships investigators have with it. Recognition of the latter confronts scientists with the essentially social nature of their practice, stimulating the discursive reinforcement of strict science/ethics boundaries (exemplified in discourse on the social implications of science). This boundary work illuminates the necessity of consistently constructing and dismantling science/ethics distinctions in order to both justify and undertake research (cf. <xref ref-type="bibr" rid="bibr40-0162243911433057">Wainwright et al. 2006</xref>). Ironically, sustained boundary work underscores the pervasiveness of ethical dynamics within science and their structuring of the content of scientific knowledge itself.</p>
<p>In sum, the issues scientists might highlight as pertaining to “ethics” are diverse. What is common, however, is the extent that scientific practice can be and sometimes is transformed through these, and the great degree to which scientific work might loop back and reshape the boundaries of “ethical” space. In the next section, the analysis is developed further; it examines the difficulties that arise when scientists produce—or assume they might produce—findings of clinical-significance when undertaking investigations involving neuroimaging.</p>
</sec>
<sec id="section8-0162243911433057">
<title>The Challenge of Incidental Findings</title>
<p>One of the most discussed—and arguably salient—concerns raised by the scientists related to the management of incidental findings (for instance, the detection of a brain tumor within a standard research scan). Incidental findings are not uncommon and have been argued to have considerable import for research participants, as well as the neuroscientific enterprise more broadly (<xref ref-type="bibr" rid="bibr1-0162243911433057">Booth et al. 2010</xref>). In what follows, the author elaborates further on the analysis unfolded thus far by attending to this important case, which vividly illuminates the colours of the science–ethics relationship.</p>
<p>Dealing with incidental findings was accounted for as extremely challenging: “a whole can of worms” (F1, group 3). As many of the scientists noted, incidental findings have “huge implications” (F2, group 4) for “future life insurance and your driving license, that kind of thing” (F1, group 2). Accordingly, locating and dealing with clinically relevant neuroimaging data were highly emotive, demanding considerable emotional labour (<xref ref-type="bibr" rid="bibr20-0162243911433057">Hochschild 1979</xref>; <xref ref-type="bibr" rid="bibr21-0162243911433057">1983</xref>):<disp-quote>
<p>I remember the first time [I discovered an incidental finding] ‘cos we were in the scanner room we were scanning the child and we see it online basically, that there might be something. <bold>It’s a horrible feeling</bold> because you then, you obviously at this point you know the child from a few hours, since a few hours already, you’ve been working with the child and it’s … <bold>you have a personal investment, emotional investment</bold> in that already but the important thing is then once the child comes out of the scanner, <bold>you can’t say anything, you can’t let them feel anything,</bold> you know realise anything so <bold>you have to be just really back to normal and pretend there’s nothing wrong.</bold> Same with the parents, you can’t give any kind of indication to them at all until you’ve got feedback from an expert which obviously takes so many days, so on the day <bold>you can’t let anything go</bold> and no, yeah it was, <bold>not a nice experience.</bold> (F2, group 2; emphasis added)</p>
</disp-quote>
</p>
<p>Exemplifying the intrinsic emotionality of science (<xref ref-type="bibr" rid="bibr24-0162243911433057">Keller 1983</xref>; Svendsen and Koch <xref ref-type="bibr" rid="bibr38-0162243911433057">2011</xref>; <xref ref-type="bibr" rid="bibr42-0162243911433057">White 2009</xref>; <xref ref-type="bibr" rid="bibr43-0162243911433057">Wilson 2008</xref>, <xref ref-type="bibr" rid="bibr44-0162243911433057">2009</xref>), the above extract paints a striking picture of the horrors of discovering something untoward in imaging data when scientists form “personal” and “emotional” investments in their subjects.</p>
<p>The “difficult” position researchers find themselves in when clinically relevant incidental findings become apparent are the products of the relationships that are necessarily formed with participants in order to undertake research. As Cohn has shown, scientists need “to forge brief but intimate and personal relationships with the volunteers in their studies” to ensure both the smooth running of scans and that “volunteers will participate in the ways intended” (<xref ref-type="bibr" rid="bibr4-0162243911433057">Cohn 2008</xref>, 86; <xref ref-type="bibr" rid="bibr34-0162243911433057">Shostak and Waggoner 2011</xref>). A corollary of this is, as we have seen, an “investment” in the research participant that makes the discovery of incidental findings difficult to deal with: administratively, ethically, emotionally.</p>
<p>Indeed, even when there are no problematic incidental findings, the intimacies of working with research participants can generate a need to perform emotional labour. This is particularly the case when those taking part in scientific studies are from “vulnerable” populations: it can be “difficult knowing where to draw the line into getting kind of drawn into all of those [personal] issues” (M2, group 5).</p>
<p>Managing incidental findings could be especially troubling when a coworker was involved: this would be “even more difficult to deal with” than worrisome data obtained through a scan of “a person from the general public” (F1, group 1). Science is, of course, intrinsically social, with relationships between scientific team members tightly interwoven with processes of knowledge production (<xref ref-type="bibr" rid="bibr26-0162243911433057">Knorr-Cetina and Mulkay 1983</xref>; <xref ref-type="bibr" rid="bibr27-0162243911433057">Latour 1987</xref>). The intimacies between scientists and their research subjects thus pales in comparison to those between colleagues; accordingly, as emotional closeness increases, so too do the difficulties researchers face when discovering clinically relevant incidental findings. Such difficulties are created precisely because of the penetrative gaze of new imaging techniques and their power to reveal more than scientists might wish to see.</p>
<p>Furthermore, while powerful scanning technologies and a degree of intimacy between laboratory members are essential to knowledge production, the emotions research practices embed and are embedded by can, paradoxically, have undesirable implications for the structuring of work and the social relationships undergirding laboratory life. For instance, some of the scientists declared that even though recruiting research participants was a part of their jobs, they themselves would decline to take part in their own or coworkers’ imaging studies. This was as a consequence of their potential to reveal profound somatic and psychological truths that the scientists would rather not confront, and uncertainty regarding how their colleagues would manage such intimate knowledge.<sup>
<xref ref-type="fn" rid="fn2-0162243911433057">2</xref>
</sup>
</p>
<p>Such reticence to “help out” was problematic, given the frequency that researchers would, for instance, ask one another to undergo a test scan when trialling a protocol or designing an experiment. Declining to help a colleague both brings to light and disturbs the tacit trust that must necessarily exist between those who work closely together in the same institution and disrupts the mutualism that is enabled through and constitutive of such trust. In the process, relations between laboratory members are reconfigured, possibly compromising the ability of the team to produce new knowledge through improvised collaboration free of the kinds of managerial constraints that might be introduced through formalised mechanisms of reciprocity.</p>
<p>The perceived novel normative aspect of neuroimaging also has the potential to undermine the expertise scientists ascribe to themselves:<disp-quote>
<p>[Research Assistants] are not qualified to give any feedback to the parents [of children who take part in imaging studies] about any abnormalities obviously but which is the best way of dealing with this issues? […] [A]t the moment, the data has to be sent to a clinical neuroscientist who’s an expert on this kind of area and he has to look at the scans. (F2, group 2)</p>
</disp-quote>
</p>
<p>Here, we see how researchers are “not qualified” to deal with this issue, forcing collaboration with a clinical “expert” and thus transforming the nature of the matrix of professionals involved in the study—and the (hierarchical) relationships between them. Again, different emotions are activated by particular configurations of expertise: a scientist may “<bold>feel uncomfortable</bold> showing anybody their research scan without having had a radiologist look at it to reassure you it was normal” (F1, group 3; emphasis added). Lacking the clinical training needed to accurately adjudicate between normal and pathological brains, scientists are caught between a desire to reassure anxious research subjects and a normative imperative to refrain from stepping into arenas within which they lack expertise. This imperative is deeply felt; for example, a young male scientist (M2, group 3) told me an “atrocity story” (<xref ref-type="bibr" rid="bibr7-0162243911433057">Dingwall 1977</xref>) about a research group which did not include a radiologist and where a medical physicist had assured a participant that their brain scan was normal. This professional did not have the credentialed expertise to make such a claim and the scientist relating the story was appalled by such practice.</p>
<p>The quandary of incidental findings, constituted through technoscientific advance (imaging methods that could detect tumors) and normative imperatives (a duty of care toward research participants), thus also looped back and shaped scientific work. Most obviously, this might entail longer and more formalized encounters between researchers and study participants as meaningful consent is sought. On a more macro level, some of the scientists noted that grant applications from their laboratories now include funds for a radiologist to consult each scan, since, as one participant wryly put it, “to be truly ethical puts the cost up” (F2, group 4). “Ethical” research is thus more expensive, forcing potential investigators to narrow the kinds of support they sought (e.g., from well funded but highly competitive schemes like those provided by the Wellcome Trust), and, therefore, the nature of the studies they might conduct. As STS scholars have long shown, science <italic>is </italic>practice (<xref ref-type="bibr" rid="bibr29-0162243911433057">Pickering 1992</xref>); accordingly, shifts in practice that regimes of normativity enjoin might introduce new forms of symbolic and material “resistance” that must be “accommodated” by scientists (cf. <xref ref-type="bibr" rid="bibr30-0162243911433057">Pickering 1995</xref>), with one consequence being that the actual content of the knowledge a neuroscience laboratory might produce could be remade (cf. <xref ref-type="bibr" rid="bibr28-0162243911433057">Longino 1990</xref>, 85).</p>
<p>This relationship between normativity and knowledge production was starkly documented by a focus group participant (M3, group 5) who discussed difficulties a colleague of his had experienced when attempting to secure ethical approval to conduct a drug trial. The regulatory hurdles that had to be overcome were so significant that such work was never again attempted. As my participant reflected:<disp-quote>
<p>[T]those kind of small scale studies and pilots and things like that won’t get done by […] overworked university departments because it’s just not feasible anymore. So more drug trials will be done only by pharmaceutical companies… (M2, group 5)</p>
</disp-quote>
</p>
<p>Ethical procedures thus not only provide new ways for scientists to experience disquiet but act as a kind of road map indicating to researchers what kinds of studies they have the resources to undertake.</p>
</sec>
<sec id="section9-0162243911433057">
<title>Normative Uncertainty and the Overdetermination of Ethical Practice</title>
<p>Potentially, the management of incidental findings might be rendered less procedurally challenging and emotionally laborious through well-defined regulation. However, in practice, the regulation of neuroscience is perceived to be complex—and not solely in regards to incidental findings. Some scientists find their formal guidelines on research practice to be “too broad” and “open to interpretation” (F1, group 2), and “a bit woolly” and “ambiguous” (F2, group 2).<sup>
<xref ref-type="fn" rid="fn3-0162243911433057">3</xref>
</sup> Accordingly, the complexity and ambiguity of prescriptions such as the Data Protection Act meant that<disp-quote>
<p>each employee in the institution will take their own view and write their own code or practice, and have their own data protection officer so … although it’s the same thing at the top by the time it’s disseminated to the employees, you know, it can be quite a different thing. (F1, group 3)</p>
</disp-quote>
</p>
<p>Procedural ambiguity about what should be done and how right it is to do so—what we might call a kind of “normative uncertainty”—is also extended, rather than reduced, through regulatory multiplicity within the research setting. For instance, at one of the universities where a focus group was convened, the participants described three separate formal ethical regimes that structured their experimental work: regulations set by the psychology department, medical school, and NHS REC. These boards had different criteria for what kinds of experimental work they took to be their proper object of regulation, and hence what kinds of procedures they mandate (e.g., the scope of and format for taking informed participant consent).</p>
<p>Clear, uniform guidelines that substituted for individual agency could, feasibly, act as the “right tool for the job” (<xref ref-type="bibr" rid="bibr3-0162243911433057">Clarke and Fujimura 1992</xref>) in helping to (re)construct the discovery of clinically significant incidental findings as a “doable” (<xref ref-type="bibr" rid="bibr13-0162243911433057">Fujimura 1987</xref>) ethical problem. However, in their absence, the (organizationally, scientifically, legally, and morally) “right” thing to do was sometimes unclear. Consequently, ethical practice often emerged “from below.” As one scientist noted when describing taking blood from her research participants for a particular study:<disp-quote>
<p>I would say if you take blood for research purposes you only try twice and then stop but that’s not actually written down in the ethics is it it’s just a standard people work to but it’s not a formal standard is it? (F1, group 2)</p>
</disp-quote>
</p>
<p>After all,<disp-quote>
<p>not every little detail can be written down in the ethics and a lot of it is in terms of if you’re a researcher you have to you know make your mind up in terms of the ethical procedures you have to adhere to yourself and what would you want to be done to yourself or not to be done…. (F2, group 2)</p>
</disp-quote>
</p>
<p>Such comments highlight the importance of individual (ethical-scientific) agency in addressing perceived regulatory deficits in neuroscience.</p>
<p>The management of incidental findings in particular has the potential to be an extremely complicated business, not least because different scientists have “all got a different way of handling” them (F2, group 4). As one researcher described:<disp-quote>
<p>[I]f you scan a brain and you detect any abnormalities or problems you are obliged to do something about this but […] there needs to be proper guidelines to tell you what you actually do but, and I think this is where we’re struggling because we’re quite unsure, ok, what do you do. (F2, group 2)</p>
</disp-quote>
</p>
<p>Such comments highlight the great degree to which tightly focused procedural guidelines might be taken to be a desirable commodity in scientific work that is perceived by its practitioners as having a significant ethical valence. Conversely, the frustrations engendered by procedural uncertainty are clearly evident when this researcher was asked how she felt the first time she discovered a clinically relevant incidental finding following a routine research scan:<disp-quote>
<p>
<bold>It was unnerving!</bold> And also because it was the first time <bold>I wasn’t really sure how to deal with it all,</bold> so I had to go back in the, see my supervisor and talk to them about it and, try to find out how exactly we’re dealing now with this issue because <bold>I wasn’t aware of the exact clear guidelines.</bold> (F2, group 2; emphasis added)</p>
</disp-quote>
</p>
<p>Uncertainty is an understandable response to what is an overdetermined procedure. Within the international neuroscientific and neuroethics community, there are many ways of dealing with this issue (<xref ref-type="bibr" rid="bibr1-0162243911433057">Booth et al. 2010</xref>). As one postdoctoral researcher described:<disp-quote>
<p>[W]hen I was in the more clinical setting in [a US university], there was always a doctor that had to read the scans so it was just required, it wasn’t the patient’s choice or whatever, or the subject’s choice. So there was always a doctor on hand to read things and then, but then at [a different university] it was more, there wasn’t a doctor on hand, there was only just the subject. (F1, group 1)</p>
</disp-quote>
</p>
<p>Clearly, different research centres produce different forms of “good” ethical-scientific practice. However, as we have seen, even within the same institution there may be a variety of coexisting regulatory frameworks constitutive of the regimes of normativity structuring laboratory life.</p>
<p>A key problem for scientists who discover clinically relevant incidental findings, this can be further illustrated through a discussion between two scientists (F1 and F2, group 2) from the same university but located in different departments. Their talk revolved around the complex matter of how the management of incidental findings was partly an outcome of the informed consent procedures that study participants navigated prior to the imaging event. In some senses, a simple exchange between the scientists regarding their practice, their debate could also be viewed as an instance of what could be called “ethical truth making”: the procedures they might follow and the propriety of those became concretised through the talk. Rather than reproduce this lengthy and rather confusing exchange in full, two key aspects will instead be noted.</p>
<p>The first is the fact that a significant difference exists between the governance of the two studies F1 and F2 are involved in; specifically, whether a participants’ general medical practitioner (GP) would be informed if clinically relevant incidental findings were obtained as part of the imaging process. For F1, participants could opt out of the scientists contacting their GP should any abnormalities in the scan be detected; yet, for F2, it was routine for the GP to be contacted in these instances. Nevertheless, her lab group did not actually have the relevant information needed to enact this procedure:<disp-quote>
<p>F2 (group 2): [W]e don’t have the details of the GP so if we found something we would have to contact them [the participant] and we’d have to ask them for the GP contact and in that case they could say no, we don’t want to, so it’s up to them to decide really, but we can’t actually say anything directly to them what we’ve found or what we think there might be because we don’t know, ‘cos the GP then will have to send them to proper scans to determine the exact problem, ‘cos our scans are obviously not designed for any kind of medical diagnosis are they? So I suppose they’ve still got the option to say no.</p>
<p>Martyn: It sounds like quite a complicated thing to deal with.</p>
<p>F1: It is very complicated yeah.</p>
</disp-quote>
</p>
<p>Thus, the relationship between scientist and research subject constituted through the study that F1 and F2 are involved with is, potentially, very fraught. While F1 has to deal with the possibility of clinically relevant incidental findings arising from the imaging studies she is involved with and the work of passing these on to a medical professional, F2 (or perhaps her coworkers) has the added burden of recontacting the participant for further information (i.e., the GP’s contact details). Such work has the potential to entail significant emotional labour, as participants may well wish to know <italic>why</italic> their GP is to be contacted. Here, the scientist is recast as a holder of an important somatic truth about an individual that they are unwilling (if not unable) to share.</p>
<p>For the case at hand, then, although differences in ethics procedures between study sites do not have an obvious impact on the content of the knowledge being produced, even slight differences in ethical protocols have the potential to introduce variations in the nature of scientific work and the emotional response of individual scientists to it. This is significant given the already intense emotional labour involved in the management of incidental findings. The degree to which this is, ultimately, significant in shaping knowledge production is unclear. However, the forging of new relations between scientists and subjects through routinized normative procedures surely enjoins further attention.</p>
<p>Of further note in the dialogue of F1 and F2 is the lack of clarity regarding where the normative procedure in question originated. Was F2 correct in her assertion that she <italic>had</italic> to contact a GP following the detection of cerebral anomalies? If so, was this requirement set down by an ethics committee (and if so, which one), or was it a feature of the everyday normativity constituted through and regulative of the practices of her particular laboratory group? In some senses, it is inconsequential whether the reported difference F1 and F2 describe for the formal management of incidental findings is objectively verifiable: the key points here - which this extract vividly illustrates - are first, that regimes of normativity powerfully structure the daily work of scientists (shaping its content and the relationships investigators have with it), and second, that the notion of “ethical” laboratory practice is essentially overdetermined: there are several routes (and departure points for these) through which a scientist might pass in order to make their work adhere to personal and institutional ethical standards.</p>
</sec>
</sec>
<sec id="section10-0162243911433057">
<title>Discussion</title>
<p>In this article, the author has argued that “neuroscience” and “ethics” are not two distinct realms that must be bridged in order for new scientific knowledge to be made socially acceptable. Rather, science and ethics—or, more opaquely, but also more specifically, <italic>the normative per se</italic>—articulate with one another. Neuroscience “creates” certain ethical issues through its methods, technologies, and foci by producing forms of knowledge and instating certain practices that, in specific social and historical moments, are constructed by particular actors, groups, or institutions as being “ethical issues” as a consequence of sometimes significant sociotechnical work (cf. <xref ref-type="bibr" rid="bibr13-0162243911433057">Fujimura 1987</xref>). These engender normative concerns that may loop back to structure the kinds of work scientists might do and the manner in which they must perform it, “determining what paths to the knowledge we want will be followed” (<xref ref-type="bibr" rid="bibr28-0162243911433057">Longino 1990</xref>, 85). Regimes of normativity might thus ultimately shape the knowledge produced within them through the new kinds of symbolic and material “resistances” investigators are forced to “accommodate” (cf. <xref ref-type="bibr" rid="bibr30-0162243911433057">Pickering 1995</xref>).</p>
<p>The kinds of “ethical” issues the scientists highlighted as significant during the focus group setting were wide-ranging, including recruitment, international collaboration, confidentiality, societal implications of their research, and the detection of clinically relevant incidental findings in research scans. In discussing these, the participants undertook a number of forms of “ethical boundary work” (<xref ref-type="bibr" rid="bibr40-0162243911433057">Wainwright et al. 2006</xref>), distinguishing not only between good and bad science and scientists but also science and ethics itself. However, these boundaries were unstable, with progressivist narratives expressed alongside more salutatory tropes about the dangers of particular kinds of research. These twin voices (<xref ref-type="bibr" rid="bibr16-0162243911433057">Hagendijk 2004</xref>) underscore the complex relationship between science and ethics: regimes of normativity structure the kinds of science that can be undertaken and “ethical” research often comes to align with scientific merit. However, science/ethics boundaries seem essential to be erected in order to prevent paralysis by reflexivity and to allow scientific work to proceed.<sup>
<xref ref-type="fn" rid="fn4-0162243911433057">4</xref>
</sup>
</p>
<p>Accordingly, in spite of (and precisely indicated by) the boundary work scientists undertake, we can see that “ethics” seems to be embedded within the very fabric of laboratory life. At all levels (pre-, during- and postexperimental work) the participants appeared to incorporate different degrees of normative reflection into their daily practice; from working to a personal standard regarding how many attempts should be made to draw blood from a research participant before stopping, to declining to take part in colleagues’ test scans lest personal (somatic) information be revealed, to regulating the sharing of data. Some of these issues of “practical ethics” are governed by formal bodies; however, regulatory multiplicity results in a deficit of surety regarding the “correct” way to behave. Consequently, ethical practice comes to be shaped by norms that are at once born of individual scientists’ personal beliefs and the communities within which they work, effectively circumventing the normative uncertainty that multiple ethical discourses instate. Together, these official and informal institutions, agents and discourses that prescribe what one <italic>ought</italic> to do configure the “regimes of normativity” which at once embed the (neuro)scientific life and are embedded within it.</p>
<p>The ways in which “ethics” articulates with practice, then, is intrinsically social. Accordingly, “ethics” might be understood as one way through which the sociality of science (<xref ref-type="bibr" rid="bibr26-0162243911433057">Knorr-Cetina and Mulkay 1983</xref>; <xref ref-type="bibr" rid="bibr27-0162243911433057">Latour 1987</xref>) is activated and structured—and scientific work legitimated (Hedgecoe and Martin <xref ref-type="bibr" rid="bibr19-0162243911433057">2003</xref>; Salter and <xref ref-type="bibr" rid="bibr46-0162243911433057">Salter 2007</xref>; <xref ref-type="bibr" rid="bibr40-0162243911433057">Wainwright et al. 2006</xref>). In turn, knowledge production can, to some degree, be understood as an outcome of the “ethical” relationships scientists have with other members of the distributed laboratory within which they work, including research participants. In particular, dealing with the clinically relevant incidental findings that can be discovered within brain scans entails onerous emotional labour (<xref ref-type="bibr" rid="bibr20-0162243911433057">Hochschild 1979</xref>, <xref ref-type="bibr" rid="bibr21-0162243911433057">1983</xref>) that is tightly interwoven with the cultural context of the laboratory (cf. <xref ref-type="bibr" rid="bibr18-0162243911433057">Hedgecoe 2006</xref>). To a significant degree this is due to the kinds of obligations to (<xref ref-type="bibr" rid="bibr9-0162243911433057">Easter et al. 2006</xref>) and intimacies with research subjects (<xref ref-type="bibr" rid="bibr4-0162243911433057">Cohn 2008</xref>) that scientists form, and which may influence study trajectories in surprising ways (<xref ref-type="bibr" rid="bibr34-0162243911433057">Shostak and Waggoner 2011</xref>). Casting new light on the essential emotionality of science (<xref ref-type="bibr" rid="bibr24-0162243911433057">Keller 1983</xref>; <xref ref-type="bibr" rid="bibr38-0162243911433057">Svendsen and Koch 2011</xref>; <xref ref-type="bibr" rid="bibr42-0162243911433057">White 2009</xref>; <xref ref-type="bibr" rid="bibr43-0162243911433057">Wilson 2008</xref>; <xref ref-type="bibr" rid="bibr44-0162243911433057">2009</xref>), this analysis signals how ethical issues and prescriptions can activate and channel emotions, sometimes transforming the relationships scientists have with their work (and its sociotechnical organization). In the process, the kinds of knowledge that scientists might produce has the potential to be reformed. In effect, knowledge, ethics and emotion come, in part, to be coproduced (cf. Brodwin 2006).</p>
<p>In sum, neuroscience and the normative interact such that knowledge is partially constituted through particular regimes of normativity consisting of formal ethical review, informal moral discourse, official/unofficial protocols within specific scientific communities, and individual personal beliefs and emotions.<sup>
<xref ref-type="fn" rid="fn5-0162243911433057">5</xref>
</sup> The resultant knowledge can, in turn, reshape these same regimes. Although transformations in the meanings and processes of knowledge production are not always significant, it is clear that the relationships between neuroscience and “ethics” are more complex and multifaceted than many bioethical analyses suggest. While the kind of coproductionist (Jasanoff 2005) understanding of the science–ethics relationship outlined here does not, of course, preclude the ethical appraisal of scientific facts following their production and authorization, it does complicate such endeavours and suggests that bioethicists might keep in mind the inherently contextual nature of not only the application of scientific knowledge but also its means of production.<sup>
<xref ref-type="fn" rid="fn6-0162243911433057">6</xref>
</sup> Accordingly, a fruitful avenue for STS explorations of ethics is an analysis of the multiple transformations in scientific work (and scientists’ relationships to it) that ethical appraisals, recommendations, and restrictions enjoin (cf. <xref ref-type="bibr" rid="bibr39-0162243911433057">Timmermans and Berg 2003</xref>, 168), and, symmetrically, the shifts in bioethical foci that new science impels.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The author is extremely grateful to the participants who agreed to take part in his research, as well as to members of the BIOS Centre (LSE) and CBAS Centre (King’s College, London) for very helpful commentary on earlier versions of this article.</p>
</ack>
<fn-group>
<fn fn-type="conflict" id="fn7-0162243911433057">
<label>Declaration of Conflicting Interests</label>
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure" id="fn8-0162243911433057">
<label>Funding</label>
<p>The author disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The funding for this study was obtained from the ESRC, awarded to Sarah Cunningham-Burley, Paul Martin, and the author.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0162243911433057">
<label>1.</label>
<p>Such work casts new light on the “moral orders” of science, which has historically not been a key feature of STS (<xref ref-type="bibr" rid="bibr33-0162243911433057">Shapin 1995</xref>).</p>
</fn>
<fn fn-type="other" id="fn2-0162243911433057">
<label>2.</label>
<p> Bodies have long been regarded as a source of profound knowledge; today, they remain salient markers of identity. As the surveillance studies literature shows, techniques of bodily surveillance reflect but also reinforce conceptions of the soma as a source of truth that can reveal much about the subject who inhabits it (<xref ref-type="bibr" rid="bibr36-0162243911433057">Staples 2000</xref>). Technology “breaks down previously immutable body boundaries, making visible to the outside world the dark secrets” of human interiority (<xref ref-type="bibr" rid="bibr8-0162243911433057">Draper 2002</xref>, 779). At the same time, such means of visualization play a role in constructing ideas about the ontology of disease. It is not surprising, therefore, that scientists (as with participants and their close ones; <xref ref-type="bibr" rid="bibr32-0162243911433057">Rapp, 2011</xref>) regard the information that brain scans can impute as significant—and, therefore, ethically troubling to work with. More broadly, we might speculate whether such unease is part of a wider kind of “performance” within neuroimaging work, serving to signal the care and attention scientists pay to their participants (thus indicating high standards of professionalism; <xref ref-type="bibr" rid="bibr15-0162243911433057">Goffman 1959</xref>).</p>
</fn>
<fn fn-type="other" id="fn3-0162243911433057">
<label>3.</label>
<p> Exceptions to this were neuroscientists who worked only with animals, who deemed governance transparent and precise: “It’s fairly clear cut as to what we should be doing” (M2, group 4). Such strict regulation enjoined scientists to ask themselves, “Is the experiment I’m doing <italic>worth</italic> doing” (F1, group 6), again underscoring the great extent to which regimes of normativity constitute the kinds of knowledge that can be produced, and scientists’ relationships with their work.</p>
</fn>
<fn fn-type="other" id="fn4-0162243911433057">
<label>4.</label>
<p> More plainly: dwelling too much on the implications of scientific work could prevent it getting done in the first place.</p>
</fn>
<fn fn-type="other" id="fn5-0162243911433057">
<label>5.</label>
<p> As discussed, comparative historical work and multisited ethnographic studies might add further texture to the analytic tapestry the author has sought to weave herein.</p>
</fn>
<fn fn-type="other" id="fn6-0162243911433057">
<label>6.</label>
<p> This article might thus be read as a piece of “critical bioethics” (Hedegecoe 2004).</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Booth</surname>
<given-names>T. C.</given-names>
</name>
<name>
<surname>Jackson</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Wardlaw</surname>
<given-names>J. M.</given-names>
</name>
<name>
<surname>Taylor</surname>
<given-names>S. A.</given-names>
</name>
<name>
<surname>Waldman</surname>
<given-names>A. D.</given-names>
</name>
</person-group>. <year>2010</year>. <article-title>“Incidental Findings in ‘Healthy’ Volunteers during Imaging Performed for Research: Current Legal and Ethical Implications.”</article-title> <source>British Journal of Radiology</source> <volume>83</volume>
<issue>(990)</issue>:<fpage>456</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr2-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Brodwin</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“The Coproduction of Moral Discourse in U.S. Community Psychiatry.”</article-title> <source>Medical Anthropology Quarterly</source> <volume>22</volume> (<issue>2</issue>): <fpage>127</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr3-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Clarke</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Fujimura</surname>
<given-names>J.</given-names>
</name>
</person-group>, eds. <year>1992</year>. <source>The Right Tools for the Job: At Work in Twentieth-Century Life Sciences</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr4-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cohn</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Making Objective Facts from Intimate Relations: The Case of Neuroscience and its Entanglements with Volunteers.”</article-title> <source>History of the Human Sciences</source> <volume>21</volume> (<issue>4</issue>): <fpage>86</fpage>–<lpage>103</lpage>.</citation>
</ref>
<ref id="bibr5-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Cunningham-Burley</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Kerr</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Pavis</surname>
<given-names>S.</given-names>
</name>
</person-group>. <year>1999</year>. <article-title>“Theorizing Subjects and Subject Matter in Focus Group Research.”</article-title> In <source>Developing Focus Group Research: Politics, Theory and Practice</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Barbour</surname>
<given-names>R. S.</given-names>
</name>
<name>
<surname>Kitzinger</surname>
<given-names>J.</given-names>
</name>
</person-group>, <fpage>186</fpage>–<lpage>99</lpage>. <publisher-loc>London</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr6-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>de Vries</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>“Who Will Guard the Guardians of Neuroscience? Firing the Neuroethical Imagination.”</article-title> <source>EMBO Reports</source> <volume>8</volume> (<issue>Special Issue</issue>): <fpage>1</fpage>–<lpage>5</lpage>.</citation>
</ref>
<ref id="bibr7-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dingwall</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>1977</year>. <article-title>“‘Atrocity Stories’ and Professional Relationships.”</article-title> <source>Work and Occupations</source> <volume>4</volume>
<issue>(4)</issue>:<fpage>371</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr8-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Draper</surname>
<given-names>J.</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>‘‘It was a Real Good Show’: The Ultrasound Scan, Fathers and the Power of Visual Knowledge.”</article-title> <source>Sociology of Health and Illness</source> <volume>24</volume>:<fpage>771</fpage>–<lpage>95</lpage>.</citation>
</ref>
<ref id="bibr9-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Easter</surname>
<given-names>M. M.</given-names>
</name>
<name>
<surname>Henderson</surname>
<given-names>G. E.</given-names>
</name>
<name>
<surname>Davis</surname>
<given-names>A. M.</given-names>
</name>
<name>
<surname>Churchill</surname>
<given-names>L. R.</given-names>
</name>
<name>
<surname>King</surname>
<given-names>N. M.</given-names>
</name>
</person-group>. <year>2006</year>. <article-title>“The Many Meanings of Care in Clinical Research.”</article-title> <source>Sociology of Health and Illness</source> <volume>28</volume>:<fpage>695</fpage>–<lpage>712</lpage>.</citation>
</ref>
<ref id="bibr10-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Farah</surname>
<given-names>M. J.</given-names>
</name>
</person-group> <year>2002</year>. <article-title>“Emerging Ethical Issues in Neuroscience.”</article-title> <source>Nature Neuroscience</source> <volume>5</volume>:<fpage>1123</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr11-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Felt</surname>
<given-names>U.</given-names>
</name>
<name>
<surname>Fochler</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Müller</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Strassnig</surname>
<given-names>M.</given-names>
</name>
</person-group>. <year>2009</year>. <article-title>“Unruly Ethics: On the Difficulties of a Bottom-Up Approach to Ethics in the Field of Genomics.”</article-title> <source>Public Understanding of Science</source> <volume>18</volume>:<fpage>354</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr12-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fuchs</surname>
<given-names>T.</given-names>
</name>
</person-group> <year>2006</year>. <article-title>“Ethical Issues in Neuroscience.”</article-title> <source>Current Opinion in Psychiatry</source> <volume>19</volume>:<fpage>600</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr13-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fujimura</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>1987</year>. <article-title>“Constructing ‘Do-Able’ Problems in Cancer Research: Articulating Alignment.”</article-title> <source>Social Studies of Science</source> <volume>17</volume>:<fpage>257</fpage>–<lpage>93</lpage>.</citation>
</ref>
<ref id="bibr14-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Gazzaniga</surname>
<given-names>M.</given-names>
</name>
</person-group> <year>2005</year>. <source>The Ethical Brain</source>. <publisher-loc>Chicago</publisher-loc>: <publisher-name>Dana Press</publisher-name>.</citation>
</ref>
<ref id="bibr15-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Goffman</surname>
<given-names>E.</given-names>
</name>
</person-group> <year>1959 [1990]</year>. <source>The Presentation of Self in Everyday Life</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Penguin</publisher-name>.</citation>
</ref>
<ref id="bibr16-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hagendijk</surname>
<given-names>R. P.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>“The Public Understanding of Science and Public Participation in Regulated Worlds.”</article-title> <source>Minerva</source> <volume>42</volume>:<fpage>41</fpage>–<lpage>59</lpage>.</citation>
</ref>
<ref id="bibr17-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hedgecoe</surname>
<given-names>A.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>“Critical Bioethics: Beyond the Social Science Critique of Applied Ethics.”</article-title> <source>Bioethics</source> <volume>18</volume>:<fpage>120</fpage>–<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr18-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hedgecoe</surname>
<given-names>A.</given-names>
</name>
</person-group>. <year>2006</year>. <article-title>“Context, Ethics and Pharmacogenetics.”</article-title> <source>Studies in History and Philosophy of Biological and Biomedical Sciences</source> <volume>37</volume>:<fpage>566</fpage>–<lpage>82</lpage>.</citation>
</ref>
<ref id="bibr19-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hedgecoe</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Martin</surname>
<given-names>P.</given-names>
</name> </person-group>
<year>2003</year>. <article-title>“The Drugs Don’t Work: Expectations and the Shaping of Pharmacogenetics.”</article-title> <source>Social Studies of Science</source> <volume>33</volume>:<fpage>327</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr20-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hochschild</surname>
<given-names>A. R.</given-names>
</name>
</person-group> <year>1979</year>. <article-title>“Emotion Work, Feeling Rules and Social Structure.”</article-title> <source>American Journal of Sociology</source> <volume>85</volume>:<fpage>551</fpage>–<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr21-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Hochschild</surname>
<given-names>A. R.</given-names>
</name>
</person-group>. <year>1983</year>. <source>The Managed Heart: Commercialization of Human Feeling</source>. <publisher-loc>Berkeley</publisher-loc>: <publisher-name>University of California Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Illes</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Racine</surname>
<given-names>E.</given-names>
</name>
</person-group>. <year>2005</year>. <article-title>“Imaging or Imagining? A Neuroethics Challenge Informed by Genetics.”</article-title> <source>American Journal of Bioethics</source> <volume>5</volume>:<fpage>5</fpage>–<lpage>18</lpage>.</citation>
</ref>
<ref id="bibr23-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="editor">
<name>
<surname>Jasanoff</surname>
<given-names>S.</given-names>
</name>
</person-group> (ed.) <year>2004</year>. <source>States of Knowledge: The Co-Production of Science and Social Order</source>, <fpage>1</fpage>–<lpage>12</lpage>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr24-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Keller</surname>
<given-names>E. F.</given-names>
</name>
</person-group> <year>1983</year>. <source>A Feeling for the Organism: The Life and Work of Barbara McClintock</source>. <publisher-loc>San Francisco</publisher-loc>: <publisher-name>Freeman</publisher-name>.</citation>
</ref>
<ref id="bibr25-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kitzinger</surname>
<given-names>J.</given-names>
</name>
</person-group> <year>1994</year>. <article-title>“The Methodology of Focus Groups: The Implications of Interaction Between Research Participants.”</article-title> <source>Sociology of Health and Illness</source> <volume>16</volume>:<fpage>103</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr26-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Knorr-Cetina</surname>
<given-names>K. D.</given-names>
</name>
<name>
<surname>Mulkay</surname>
<given-names>M.</given-names>
</name>
</person-group> (eds.) <year>1983</year>. <source>Science Observed: Perspectives on the Social Study of Science</source>. <publisher-loc>Beverly Hills, CA</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr27-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Latour</surname>
<given-names>B.</given-names>
</name>
</person-group> <year>1987</year>. <source>Science in Action: How to Follow Scientists and Engineers Through Society</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr28-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Longino</surname>
<given-names>H. E.</given-names>
</name>
</person-group> <year>1990</year>. <source>Science as Social Knowledge: Values and Objectivity in Scientific Inquiry</source>. <publisher-loc>Princeton</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>.</citation>
</ref>
<ref id="bibr29-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Pickering</surname>
<given-names>A.</given-names>
</name>
</person-group> (ed.) <year>1992</year>. <source>Science as Practice and Culture</source>. <publisher-loc>Chicago</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</citation>
</ref>
<ref id="bibr30-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Pickering</surname>
<given-names>A.</given-names>
</name>
</person-group>. <year>1995</year>. <source>The Mangle of Practice: Time, Agency, and Science</source>. <publisher-loc>Chicago and London</publisher-loc>: <publisher-name>Chicago University Press</publisher-name>.</citation>
</ref>
<ref id="bibr31-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pickersgill</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Cunningham-Burley</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Martin</surname>
<given-names>P.</given-names>
</name>
</person-group>. <year>2011</year>. <article-title>“Constituting Neurologic Subjects: Neuroscience, Subjectivity and the Mundane Significance of the Brain.”</article-title> <source>Subjectivity</source> <volume>4</volume>:<fpage>346</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr32-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rapp</surname>
<given-names>R.</given-names>
</name>
</person-group> <year>2011</year>. <article-title>“A Child Surrounds this Brain: The Future of Neurological Difference According to Scientists, Parents and Diagnosed Young Adults.”</article-title> In <source>Sociological Reflections on the Neurosciences</source>, edited by M. D. Pickersgill and I. van Keulen, <fpage>3</fpage>–<lpage>26</lpage>. Bingley: Emerald.</citation>
</ref>
<ref id="bibr46-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Salter</surname>
<given-names>B.</given-names>
</name>
</person-group> <year>2007</year>. <article-title>“Bioethics, Politics and the Moral Economy of Human Embryonic Stem Cell Science: The Case of the European Union’s Sixth Framework Programme.”</article-title> <source>New Genetics and Society</source> <volume>26</volume>:<fpage>269</fpage>–<lpage>88</lpage>.</citation>
</ref>
<ref id="bibr33-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Shapin</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>1995</year>. <article-title>“Here and Everywhere: Sociology of Scientific Knowledge.”</article-title> <source>Annual Review of Sociology</source> <volume>21</volume>:<fpage>289</fpage>–<lpage>321</lpage>.</citation>
</ref>
<ref id="bibr34-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Shostak</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Waggoner</surname>
<given-names>M.</given-names>
</name>
</person-group>. <year>2011</year>. <article-title>“Narration and Neuroscience: Encountering the Social on the ‘Last Frontier of Medicine’.”</article-title> In <source>Sociological Reflections on the Neurosciences</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Pickersgill</surname>
<given-names>M. D.</given-names>
</name>
<name>
<surname>van Keulen</surname>
<given-names>I.</given-names>
</name>
</person-group>, <fpage>51</fpage>–<lpage>74</lpage>. <publisher-loc>Bingley</publisher-loc>: <publisher-name>Emerald</publisher-name>.</citation>
</ref>
<ref id="bibr35-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sperling</surname>
<given-names>S.</given-names>
</name>
</person-group> <year>2004</year>. <article-title>“Managing Potential Selves: Stem Cells, Immigrants, and German Identity.”</article-title> <source>Science and Public Policy</source> <volume>31</volume>:<fpage>139</fpage>–<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr36-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Staples</surname>
<given-names>W. G.</given-names>
</name>
</person-group> <year>2000</year>. <source>Everyday Surveillance: Vigilance and Visibility in Postmodern Life</source>. <publisher-loc>Lanham</publisher-loc>: <publisher-name>Rowman and Littlefield</publisher-name>.</citation>
</ref>
<ref id="bibr37-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Svendsen</surname>
<given-names>M. N.</given-names>
</name>
<name>
<surname>Koch</surname>
<given-names>L.</given-names>
</name>
</person-group>. <year>2008</year>. <article-title>“Between Neutrality and Engagement: A Case Study of Recruitment to Pharmacogenomic Research in Denmark.”</article-title> <source>BioSocieties</source> <volume>3</volume>:<fpage>399</fpage>–<lpage>418</lpage>.</citation>
</ref>
<ref id="bibr38-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Svendsen</surname>
<given-names>M. N.</given-names>
</name>
<name>
<surname>Koch</surname>
<given-names>L.</given-names>
</name>
</person-group>. <year>2011</year>. <article-title>“In the Mood for Science: A Discussion of Emotion Management in a Pharmacogenomics Research Encounter in Denmark.”</article-title> <source>Social Science and Medicine</source> <volume>72</volume>:<fpage>781</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr39-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Timmermans</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Berg</surname>
<given-names>M.</given-names>
</name>
</person-group>. <year>2003</year>. <source>The Gold Standard: The Challenge of Evidence-Based Medicine and Standardization in Health Care</source>. <publisher-loc>Philadelphia</publisher-loc>: <publisher-name>Temple University Press</publisher-name>.</citation>
</ref>
<ref id="bibr40-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wainwright</surname>
<given-names>S. P.</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Michael</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Farsides</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Cribb</surname>
<given-names>A.</given-names>
</name>
</person-group>. <year>2006</year>. <article-title>“Ethical Boundary-Work in the Embryonic Stem Cell Laboratory.”</article-title> <source>Sociology of Health and Illness</source> <volume>28</volume>:<fpage>732</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr41-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Waterton</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Wynne</surname>
<given-names>C.</given-names>
</name>
</person-group>. <year>1999</year>. <article-title>“Can Focus Groups Access Community Views?”</article-title> In <source>Developing Focus Group Research: Politics, Theory and Practice</source>, edited by <person-group person-group-type="editor">
<name>
<surname>Barbour</surname>
<given-names>R. S.</given-names>
</name>
<name>
<surname>Kitzinger</surname>
<given-names>J.</given-names>
</name>
</person-group>, <fpage>127</fpage>–<lpage>43</lpage>. <publisher-loc>London</publisher-loc>: <publisher-name>SAGE</publisher-name>.</citation>
</ref>
<ref id="bibr42-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>White</surname>
<given-names>P.</given-names>
</name>
</person-group> <year>2009</year>. <article-title>“The Emotional Economy of Science.”</article-title> <source>Isis</source> <volume>100</volume>:<fpage>792</fpage>–<lpage>7</lpage>.</citation>
</ref>
<ref id="bibr43-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wilson</surname>
<given-names>E. A.</given-names>
</name>
</person-group> <year>2008</year>. <article-title>“Affect, Artificial Intelligence, and Internal Space.”</article-title> <source>Emotion, Space and Society</source> <volume>1</volume>:<fpage>22</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr44-0162243911433057">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wilson</surname>
<given-names>E. A.</given-names>
</name>
</person-group>. <year>2009</year>. <article-title>“Would I Always Have Him with Me Always: Affects of Longing in Early Artificial Intelligence.”</article-title> <source>Isis</source> <volume>100</volume>:<fpage>839</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr45-0162243911433057">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wouters</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Schroeder</surname>
<given-names>P.</given-names>
</name>
</person-group>. <year>2003</year>. <source>Promise and Practice in Data Sharing: The Public Domain of Digital Research Data</source>. <publisher-name>Amsterdam, Netherlands</publisher-name>: <publisher-loc>NIWI-KNAW</publisher-loc>.</citation>
</ref>
</ref-list>
</back>
</article>