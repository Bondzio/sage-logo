<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="news">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">EVI</journal-id>
<journal-id journal-id-type="hwp">spevi</journal-id>
<journal-title>Evaluation</journal-title>
<issn pub-type="ppub">1356-3890</issn>
<issn pub-type="epub">1461-7153</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1356389012463136</article-id>
<article-id pub-id-type="publisher-id">10.1177_1356389012463136</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>News from the community</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Department for Performance Monitoring and Evaluation of South Africa: A note prepared by Nicoletta Stame following a visit to South Africa</article-title>
</title-group>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>18</volume>
<issue>4</issue>
<fpage>505</fpage>
<lpage>506</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
</article-meta>
</front>
<body>
<p>How evaluation is institutionalized is always of interest to the readers of <italic>Evaluation</italic>. I therefore thought that I would describe a relatively new system in the Republic of South Africa.</p>
<p>The government of South Africa is committed to building systems for generating knowledge about the working of public policies as a step in the democratization process. Knowledge is produced through three ‘data streams’:</p>
<list id="list1-1356389012463136" list-type="bullet">
<list-item><p>program performance information (Treasury);</p></list-item>
<list-item><p>social, economic and demographic statistics (Statistics South Africa); and</p></list-item>
<list-item><p>evaluation.</p></list-item>
</list>
<p>The latter sits within an elaborate system that is anchored in the Presidency, which includes a new institution (the Department for Performance Monitoring and Evaluation, DPME), new roles (the outcome facilitators) and new tools (evaluation plans, quarterly reports to the Cabinet). The DPME was created in 2010 and is considered ‘the custodian of the national M&amp;E system’.</p>
<p>The policy of the M&amp;E system is based on:</p>
<list id="list2-1356389012463136" list-type="bullet">
<list-item><p>horizontal collaboration across government departments; as well as with the DPME and the Treasury;</p></list-item>
<list-item><p>vertical collaboration between government levels and the vertical partnership between the DPME and analogous roles in the provincial Offices of the Premier.</p></list-item>
</list>
<p>The M&amp;E system pursues a results-based approach. This has the following two main consequences.</p>
<p>First, the evaluation emphasis is on outcomes (what we want to achieve), not activities (what we do). The National Evaluation Plan has established 12 national outcomes, five of which have been singled out as priorities (education, health, safety, employment, sustainable rural communities).</p>
<p>The DPME defines evaluation as ‘the systematic collection and objective analysis of evidence on public policies, programmes, projects, functions and organizations to assess issues such as relevance, performance (effectiveness and efficiency), value for money, impact and sustainability and recommended ways forward’. To this end, it has promoted an evaluation policy, outlined in a <italic>National Evaluation Policy Framework</italic> (NEPF, November 2011); guidelines for evaluation competence (<italic>Evaluation Competency Framework for Government</italic>, August 2012); standards (<italic>Standards for Evaluation in Government</italic>, August 2012), and numerous guidelines on the management and commissioning of evaluation. Moreover, training courses are run by universities, internal training services and the private sector. The NEPF includes the establishment of an annual and a three-year rolling National Evaluation Plan, initially at the national level (national priorities), then at provincial and departmental level. Ten evaluations are planned in the years 2012/13.</p>
<p>Second, inside the DPME tasks are allocated to ‘outcome facilitators’ who work with departments on the specific outcomes. Their aim is to draw logic models of activity/outputs/outcomes, with targets and indicators, develop delivery agreements with departments, follow their implementation, and help provide data for the quarterly reports that departments have to send to the Cabinet. Concurrently, the outcome facilitators produce their independent report for the Cabinet. This dual role, reporting to both the departments and the Cabinet, has been described as leading to some tension, but if well implemented it could provide the missing link between a responsible administration and better policy making.</p>
<p>For further information visit: <ext-link ext-link-type="uri" xlink:href="http://www.thepresidency-dpme.gov.za">www.thepresidency-dpme.gov.za</ext-link></p>
</body>
</article>