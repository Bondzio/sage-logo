<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">BMS</journal-id>
<journal-id journal-id-type="hwp">spbms</journal-id>
<journal-title>Bulletin de Méthodologie Sociologique</journal-title>
<issn pub-type="ppub">0759-1063</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0759106312465547</article-id>
<article-id pub-id-type="publisher-id">10.1177_0759106312465547</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Response Rate and Nonresponse Bias - Impact of the Number of Contact Attempts on Data Quality in the European Social Survey</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Fuchs</surname>
<given-names>Marek</given-names>
</name>
<xref ref-type="corresp" rid="corresp1-0759106312465547"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bossert</surname>
<given-names>Dayana</given-names>
</name>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Stukowski</surname>
<given-names>Sabrina</given-names>
</name>
<aff id="aff1-0759106312465547"><italic>(Darmstadt University of Technology, Germany)</italic></aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="corresp1-0759106312465547">Marek Fuchs, Institute of Sociology, Darmstadt University of Technology, Residenzschloss, D-64283 Darmstadt, Germany. <bold>Email</bold>: <email>fuchs@ifs.tu-darmstadt.de</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>1</month>
<year>2013</year>
</pub-date>
<volume>117</volume>
<issue>1</issue>
<fpage>26</fpage>
<lpage>45</lpage>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">SAGE/ Association Internationale de Méthodologie Sociologique</copyright-holder>
</permissions>
<abstract>
<p>Increasing respondent contact problems and decreasing respondent willingness to cooperate have contributed to declining response rates in general population surveys, which has raised concerns of survey accuracy. To counteract nonresponse, several methods have been employed, including incentives, advanced letters, alternative survey modes for reluctant respondents, and increased field efforts to contact potential respondents. In particular, the number of contact attempts has been increased for many surveys. Even though more contact attempts increase survey costs, they are a reliable means for increasing response rates. However, the assumption that high response rates foster data quality and smaller nonresponse bias has been challenged. In this paper, we used contact data from the European Social Survey for Norway, Finland and Slovenia to see whether or not additional contact attempts resulting in a higher response rate can potentially reduce nonresponse bias.</p>
</abstract>
<trans-abstract xml:lang="fr">
<p>
<bold>Taux de réponse et biais de non-réponse - Impact du nombre de tentatives de contact sur la qualité des données de l'European Social Survey</bold> : Le problème de la difficulté de contacter des répondants et la baisse de la volonté de coopérer ont contribué à une baisse du taux de réponse pour les enquêtes dans la population. Pour lutter contre les non-réponses, plusieurs méthodes ont été employées : incitations, lettres d’annonce, enquêtes spécifiques pour les répondants réticents, efforts accrus sur le terrain pour contacter d’éventuels répondants. En particulier, le nombre de tentatives de contact a été augmenté pour beaucoup d’enquêtes. Bien que davantage de tentatives de contact augmentent les coûts d’enquête, ce procédé est un moyen efficace pour améliorer le taux de réponse. Cependant, l’idée qu’un taux de réponse élevé améliore la qualité des données et diminue le biais de non-réponse a été mise en doute. Dans cet article, nous utilisons les données concernant les contacts de l'European Social Survey concernant la Norvège, le Finlande et la Slovénie pour voir si oui ou non des tentatives de contacts supplémentaires, permettant un taux de réponse plus élevé, peuvent réduire le biais de non-réponse.</p></trans-abstract>
<kwd-group>
<kwd>Taux de réponse</kwd>
<kwd>Biais de non-réponse</kwd>
<kwd>Tentatives de contact</kwd>
<kwd>European Social Survey</kwd>
</kwd-group>
<kwd-group>
<kwd>Response Rate</kwd>
<kwd>Nonresponse Bias</kwd>
<kwd>Contact Attempts</kwd>
<kwd>European Social Survey</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-0759106312465547">
<title>Background and Literature Review</title>
<p>Since the early days of survey research, response rates have declined (<xref ref-type="bibr" rid="bibr6-0759106312465547">Brehm, 1994</xref>). In a study by <xref ref-type="bibr" rid="bibr49-0759106312465547">Steeh (1981)</xref>, refusal rates and other non-interview rates have been assessed for the Survey of Consumer Attitudes and US National Election Studies since the 1950s. Results indicate a substantial increase of refusals. Similarly, in a meta-analysis <xref ref-type="bibr" rid="bibr25-0759106312465547">Hox and de Leeuw (1994)</xref> found declining response rates for face-to-face and telephone surveys from the late 1940s to the early 1990s. In addition, <xref ref-type="bibr" rid="bibr22-0759106312465547">Harris-Kojetin and Tucker (1999)</xref> documented an increase in refusal rates in the US Current Population Study from 1960 to 1988 with a particularly steep rise from 1960 to 1976. Similar results were reported for Sweden (<xref ref-type="bibr" rid="bibr34-0759106312465547">Lyberg and Lyberg, 1991</xref>), the Netherlands (<xref ref-type="bibr" rid="bibr11-0759106312465547">de Leeuw, 1992</xref>), Germany (<xref ref-type="bibr" rid="bibr44-0759106312465547">Schnell, 1997</xref>), and Japan (<xref ref-type="bibr" rid="bibr54-0759106312465547">Synodinos and Yamada, 2000</xref>). In an international comparison using ISSP data, <xref ref-type="bibr" rid="bibr47-0759106312465547">Smith (1995</xref>: 168) states that in a longitudinal perspective increases of “both overall non-response and refusals do outnumber declines”.</p>
<p>In a comprehensive assessment of response rates and their components in surveys conducted in the 1990s by statistical agencies in Europe, North America, and Australia, <xref ref-type="bibr" rid="bibr12-0759106312465547">de Leeuw and de Heer (2002</xref>; see also <xref ref-type="bibr" rid="bibr10-0759106312465547">de Heer 1999</xref>) found a considerable average increase in nonresponse rates of roughly 0.5 percent per year. About 0.2 percent was due to increasing noncontacts while an increase of about 0.3 percent per year was attributed to accelerating refusals. While increases in noncontact are mainly due to fieldwork characteristics and at-home patterns of sample persons (<xref ref-type="bibr" rid="bibr1-0759106312465547">Bethlehem et al., 2011</xref>), refusals are attributed, for example, to respondents’ privacy concerns, restricted time resources (<xref ref-type="bibr" rid="bibr23-0759106312465547">Haunberger, 2011</xref>) or to respondent burden experienced during previous survey interviews (<xref ref-type="bibr" rid="bibr50-0759106312465547">Stockè and Langfeld, 2004</xref>). Even though the authors found evidence for country-specific differences in the rise of noncontact rates and refusal rates, the overall tendency suggests that nonresponse is generally increasing.</p>
<p>Most large scale ongoing surveys have elevated their field efforts to counteract increasing nonresponse (<xref ref-type="bibr" rid="bibr8-0759106312465547">Curtin et al., 2000</xref>).</p>
<disp-quote>
<p>“First, surveyors have made efforts to improve contact rates (for example, through a greater number of contact attempts, a longer data collection period or the use of multiple modes to establish contact […]). Secondly, surveyors have also tried to increase cooperation through the use of, for example, incentives, advanced notice of the survey request, follow-up procedures, and alternative response modes” (<xref ref-type="bibr" rid="bibr29-0759106312465547">Kreuter, Lemay and Casas-Cordero, 2007</xref>: 3144).</p>
</disp-quote>
<p>Other studies have focused on interviewer motivation (<xref ref-type="bibr" rid="bibr31-0759106312465547">Lapec, 2006</xref>; <xref ref-type="bibr" rid="bibr32-0759106312465547">Lemay and Durand, 2002</xref>). Since several of these methods have proven positive effect on response, the true decline of response rates (<italic>ceteris paribus</italic>) is presumably even more severe than documented in the studies mentioned above (<xref ref-type="bibr" rid="bibr54-0759106312465547">Synodinos and Yamada, 2000</xref>: 64).</p>
<p>From a traditional point of view, response rates have been seen as a key data quality indicator for surveys. High response rates of 70 percent or higher have been defined as thresholds for high quality surveys in various textbooks (see citations compiled by Groves in his 2006 review article), as well as in the methodological specifications for ambitious cross-sectional surveys like the European Social Survey (<xref ref-type="bibr" rid="bibr36-0759106312465547">Matsuo et al., 2009</xref>) – even though it seems challenging to achieve response rates of above 70 percent (<xref ref-type="bibr" rid="bibr27-0759106312465547">Jansen and Hak, 1999</xref>). The underlying presupposition that urges survey researchers to aim for high response rates is based on the assumption that high nonresponse rates may result in high nonresponse biases. In fact, several studies have demonstrated that nonresponse bias increases if response rates drop. For example, <xref ref-type="bibr" rid="bibr55-0759106312465547">Vehovar (2007</xref>: 355) concludes in his study using European Social Survey data that “in general, at the aggregate (country) level a larger non-response also means a larger non-response bias”. According to this reasoning, any strategy that helps increase response is assumed to reduce nonresponse bias and to improve data quality.</p>
<p>However, recent studies suggest that changes in nonresponse rates do not necessarily have a strong impact on nonresponse bias (<xref ref-type="bibr" rid="bibr8-0759106312465547">Curtin et al., 2000</xref>; <xref ref-type="bibr" rid="bibr28-0759106312465547">Keeter et al., 2000</xref>; <xref ref-type="bibr" rid="bibr37-0759106312465547">Merkle and Edelman, 2002</xref>; <xref ref-type="bibr" rid="bibr45-0759106312465547">Schouten, 2004</xref>). More precisely, higher response rates do not imply smaller nonresponse bias (<xref ref-type="bibr" rid="bibr46-0759106312465547">Schouten et al., 2009</xref>). Nevertheless, nonresponse bias exists. In a review article summarizing 30 studies on nonresponse bias, <xref ref-type="bibr" rid="bibr16-0759106312465547">Groves (2006)</xref> found ample evidence that nonresponse bias does occur. The mean percentage relative nonresponse bias for 335 estimates was about 9 percent. However, it is noteworthy that the magnitude of the bias (which is a property of a particular estimate, not of a survey as a whole) differs for variables within a survey and for subgroups within the sample (see <xref ref-type="bibr" rid="bibr9-0759106312465547">Deding et al., 2008</xref>; <xref ref-type="bibr" rid="bibr15-0759106312465547">Gray et al., 1996</xref>; <xref ref-type="bibr" rid="bibr3-0759106312465547">Billiet et al., 2007</xref>; <xref ref-type="bibr" rid="bibr53-0759106312465547">Stoop et al., 2008</xref>). In an even more extensive meta-analysis of 59 methodological studies on nonresponse bias, <xref ref-type="bibr" rid="bibr19-0759106312465547">Groves and Peytcheva (2008)</xref> found no overall significant correlation of response rate and nonresponse bias, but instead large variations of bias estimates across surveys with similar nonresponse rates.</p>
<p>Based on these findings, it becomes questionable whether or not a high response rate alone is a proper data quality indicator. However, since nonresponse bias is the product of the magnitude of the nonresponse rate and of the difference between respondents and nonrespondents, high nonresponse rates at least define the maximum nonresponse bias (<xref ref-type="bibr" rid="bibr56-0759106312465547">Wagner, 2008</xref>),and thus high response rates are still assumed to be “one of the best ways of preventing incorrect estimates due to non-response biases” (<xref ref-type="bibr" rid="bibr55-0759106312465547">Vehovar, 2007</xref>: 355). However, there is no stable correlation of response rate and nonresponse bias as pointed out by <xref ref-type="bibr" rid="bibr16-0759106312465547">Groves (2006)</xref> in his meta-analysis. In fact, there are examples for a deteriorating impact of increased response on the magnitude of the bias. <xref ref-type="bibr" rid="bibr1-0759106312465547">Bethlehem and colleagues (2011)</xref> describe an example of a positive correlation of response rate and nonresponse bias, warning readers of single-mindedly focus on response rates as an indicator of survey quality. This raises concerns that increased field efforts may indeed boost the response rate but at the same time hold the potential to increase nonresponse biases. Thus, an assessment of strategies that aim to increase response rates should simultaneously consider consequences for nonresponse bias.</p>
</sec>
<sec id="section2-0759106312465547">
<title>Increasing Response</title>
<p>The literature documents several methods that aim to increase response. Amongst others, incentives (<xref ref-type="bibr" rid="bibr26-0759106312465547">Jäckle and Lynn, 2008</xref>), refusal conversion (<xref ref-type="bibr" rid="bibr8-0759106312465547">Curtin et al., 2000</xref>), optimal scheduling of contact attempts (<xref ref-type="bibr" rid="bibr33-0759106312465547">Lipps and Benson, 2005</xref>) and increased number of contact attempts (<xref ref-type="bibr" rid="bibr43-0759106312465547">Romanov and Nir, 2010</xref>) are being used. Even though countries differ considerably with respect to the standard methods (<xref ref-type="bibr" rid="bibr39-0759106312465547">Nicoletti and Buck, 2004</xref>; <xref ref-type="bibr" rid="bibr5-0759106312465547">Blom et al., 2010</xref>; <xref ref-type="bibr" rid="bibr29-0759106312465547">Kreuter et al., 2007</xref>; <xref ref-type="bibr" rid="bibr41-0759106312465547">Philippens et al., 2003</xref>; <xref ref-type="bibr" rid="bibr4-0759106312465547">Blom et al., 2008</xref>) increased number of contact attempts are frequently used in many countries (<xref ref-type="bibr" rid="bibr48-0759106312465547">Smith, 2007</xref>).</p>
<p>Since increased fieldwork efforts typically cause elevated survey costs, the potential impact of various levels of fieldwork on nonresponse bias has been assessed. Using the Israel Household Expenditure Survey, <xref ref-type="bibr" rid="bibr43-0759106312465547">Romanov and Nir (2010)</xref> demonstrated that limiting the number of contact attempts resulted in a reduced response rate (a drop from 88 percent to 76 percent), but caused no significant bias for key survey variables. Similarly, <xref ref-type="bibr" rid="bibr28-0759106312465547">Keeter and colleagues (2000)</xref> assessed the impact of a rigorous fieldwork procedure (eight weeks of fieldwork) in comparison to a standard fieldwork approach (five days of fieldwork) and found only a few significant differences in survey estimates. By contrast, <xref ref-type="bibr" rid="bibr30-0759106312465547">Kreuter et al. (2010)</xref>, using data from a survey on labor market participation, found that an increased number of contact attempts resulted in significant reduction in nonresponse bias. Similarly, <xref ref-type="bibr" rid="bibr14-0759106312465547">Firdion (1993)</xref> using a survey on a sensitive topic demonstrated that respondents added to the sample by means of multiple contact attempts reduced nonresponse bias.</p>
<p>In a detailed study using data from the Flemish Housing Survey, <xref ref-type="bibr" rid="bibr24-0759106312465547">Heerwegh et al. (2007)</xref> differentiated nonresponse due to noncontact and nonresponse due to refusal. They found that additional contact attempts helped decrease the noncontact rate, but the remaining noncontacts became more different from the contacted cases (<xref ref-type="bibr" rid="bibr24-0759106312465547">Heerwegh et al., 2007</xref>), and accordingly increased field efforts did not decrease nonresponse bias.</p>
<p>This may have been connected to the fact that remaining noncontacted respondents vary even more from the completed cases which results in larger biases even though the proportion of nonrespondents decreases. However, it is important to note that additional contact attempts do not only increase the number of completes but may also lead to an elevated number of refusals. Thus, it is possible that additional field efforts do in fact reduce noncontacts. However, since some of the hard-to-contact respondents refuse to participate in the survey, the overall bias might not benefit to the full extent. Accordingly, it is necessary to analyze the contributions of noncontact and refusal to overall nonresponse bias over the course of the fieldwork. This could instruct survey organizations on whether reduction of noncontact results overall decreased nonresponse bias or if additional refusals accumulated by means of extensive field efforts lead to increased nonresponse bias and hence outweigh the positive effect of the lower noncontact rate.</p>
<p>Along this reasoning, <xref ref-type="bibr" rid="bibr35-0759106312465547">Lynn and Clarke (2002)</xref> assessed the impact of increased field efforts on refusal bias and noncontact bias. When comparing easy-to-get respondents (those who responded after standard field efforts) and hard-to-get respondents (those who answered after extended contact attempts), they found that nonresponse bias in age and employment status is predominantly caused by noncontacts, while respondents who answered only after refusal conversion differed in terms of gender. Based on further analyses of biases for substantive variables, they concluded that extended efforts in the field were justified in terms of bias reduction (<xref ref-type="bibr" rid="bibr35-0759106312465547">Lynn and Clarke, 2002</xref>). Compared to studies assessing the impact of increased field efforts on nonresponse, this study had clearly the advantage of correlating field efforts and nonresponse bias. However, an important constraint persisted: the extended field efforts did not yield a 100 percent response rate. Accordingly, this study lacked complete information regarding socio-demographic variables for all members of the gross sample. Thus, the magnitude of the nonresponse bias could not be estimated precisely.</p>
<sec id="section3-0759106312465547">
<title>Methods for the Assessment of Nonresponse Bias</title>
<p>To assess the magnitude of nonresponse bias, several methods have been proposed. Amongst others, respondents who initially refused to participate in a survey but later could be converted into respondents (<xref ref-type="bibr" rid="bibr7-0759106312465547">Burton et al., 2006</xref>) have been assessed to estimate the response distribution for refusals. This was done based on the assumption that the propensity to participate in a survey is an individual property on a continuum, and thus respondents who cooperated after refusal conversion would resemble refusals (<xref ref-type="bibr" rid="bibr42-0759106312465547">Proner, 2011</xref>). However, recent studies have demonstrated that this hypothesis of a continuum of resistance is not supported (<xref ref-type="bibr" rid="bibr38-0759106312465547">Neller, 2005</xref>; <xref ref-type="bibr" rid="bibr51-0759106312465547">Stoop, 2004</xref>; Billiet at al., 2007), and accordingly this approach is only of limited value for the assessment of nonresponse bias.</p>
<p>A more reliable method for the assessment of bias due to nonresponse makes use of information from the sampling frame or from any available register comprising respondents and nonrespondents. Following this approach, <xref ref-type="bibr" rid="bibr17-0759106312465547">Groves and Couper (1998)</xref>, in their Match Project, used census data for respondents and nonrespondents of six large scale surveys in the US. They then employed information from the US census to predict contact and cooperation of the respondents. However, this approach is typically not feasible since access to registers is limited, if possible at all.</p>
<p>Other studies aimed to estimate nonresponse bias by means of comparing data sets of the same survey that were either unweighted (aside from design weights) or weighted with nonresponse adjustment weights (see <xref ref-type="bibr" rid="bibr55-0759106312465547">Vehovar, 2007</xref>; <xref ref-type="bibr" rid="bibr3-0759106312465547">Billiet et al., 2007</xref>). The clear advantage of such a design is the availability of bias estimates for a wide range of substantive variables – since the bias assessment is not restricted to variables for which the true distribution is known from external sources. However, since weighting schemes are predominantly based on socio-demographic variables and (sometimes) on paradata obtained during fieldwork, it remains doubtful if and to what extent estimates based on weighted data in fact come closer to the parameter. Also, differences of the estimates based on the weighted and unweighted data may be attributed to multiple sources: amongst others, coverage error of the frame, error due to sampling and nonresponse error. To overcome this uncertainty, in this paper we used information collected by interviewer observation for respondents and nonrespondents throughout fieldwork.</p>
</sec>
</sec>
<sec id="section4-0759106312465547" sec-type="methods">
<title>Methods</title>
<p>For our analyses, we used data from the European Social Survey (ESS). The ESS is a biennial study fielded since 2002, currently in more than 30 nations. The survey is concerned with monitoring changes in public attitudes and values within Europe and investigating how these alterations interact with Europe’s changing institutions. In addition, it aims to improve methods of cross-national survey research in Europe and to develop a series of European social indicators (<xref ref-type="bibr" rid="bibr13-0759106312465547">European Social Survey, 2006</xref>). Data collection employs face-to-face interviews using probability samples in all participating countries. However, the methods used to draw the sample vary across participating countries, depending on their access to sampling sources. While some countries deploy individual named samples, others make use of household samples or address samples. The analyses in this paper were based on data from ESS round 3 (fielded in 2006). We used data weighted with design weights provided by the European Social Survey team correcting for unequal selection probability.</p>
<p>In the European Social Survey, a standard contact form has been used since the first round of this survey in 2002. The contact form data provides information on number and outcome of the contact attempts. In addition, the contact forms contain interviewer observations regarding gender and age of each member of the gross sample. Even though in several countries the samples for the European Social Survey has been drawn from a population register, due to privacy restrictions, the information from the frame could not be transferred into the contact form data. Thus, the information regarding age and gender of each potential respondent was provided by interviewer observation only.</p>
<p>
<xref ref-type="bibr" rid="bibr52-0759106312465547">Stoop (2005)</xref> points out that the quality of paradata from the contact forms in the ESS is mixed, since there are huge differences in the fieldwork procedures across participating countries. Accordingly, the use of contact data to understand cross-national differences in nonresponse is hampered by missing data, inconsistencies, and lack of equivalence (<xref ref-type="bibr" rid="bibr5-0759106312465547">Blom et al., 2010</xref>). However, the quality and completeness of the contact form data is crucial for our analysis, since we wanted to overcome limitations of other studies that assessed only part of the nonresponse. Thus, we restricted our analysis to Norway, Finland, and Slovenia for which complete information from the contact forms was available including information on age and gender of respondents and nonrespondents. The analysis reported in this paper was replicated for six other countries where information on age and gender of nonrespondents was less exhaustive (up to 15 % missing information in the contact forms): Denmark, Hungary, the Netherlands, Poland, Slovakia, and Ukraine. Results did not differ to a great extent; however, doubts remained whether or not the findings may have been affected by differential missing data from the contact forms. Accordingly, results reported in this paper refer to countries with complete contact form information only.</p>
<p>It is important to note that the three countries differ in the way the initial contact attempt was recorded: in Finland and Norway, the first contact attempt was made using telephone calls to make an appointment. In Norway, these calls were not recorded in the contact form when the call was not answered whereas in Finland they were. By contrast, in Slovenia the first contact attempt was made by a personal visit and recorded in the contact forms, regardless of the outcome. Because of these differences, we decided to assess response rates and nonresponse bias from the second contact attempt onwards (which was done by personal visit in all three countries).</p>
<p>All three countries reached the threshold of a maximum of 3 percent of noncontact at the end of the fieldwork period. However, other nonresponse (mostly appointments not met by either the respondent or the interviewer) was still considerably high, even after ten contact attempts. Refusals were highest in Norway (26 % of all eligible cases; this is not the AAPOR refusal rate, see the note below <xref ref-type="table" rid="table1-0759106312465547">Table 1</xref>). Refusals were slightly less pronounced in Finland (23 %) and were lowest in Slovenia (17 %). <xref ref-type="table" rid="table1-0759106312465547">Table 1</xref> provides details concerning fieldwork. In addition to the response rate, each column denotes the percentage of eligible cases (determined at the end of fieldwork) which were not contacted, resulted in a refusal or were coded as other nonresponse.</p>
<table-wrap id="table1-0759106312465547" position="float">
<label>Table 1.</label>
<caption>
<p>Response rate, percentage of noncontact, refusal, and other nonresponse by number of contact attempts in Finland, Norway, and Slovenia.</p>
</caption>
<graphic alternate-form-of="table1-0759106312465547" xlink:href="10.1177_0759106312465547-table1.tif"/>
<table>
<thead>
<tr>
<th rowspan="2">
</th>
<th colspan="9">Number of contact attempt<hr/></th>
</tr>
<tr>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="10">Finland (N=2,955 eligible cases)</td>
</tr>
<tr>
<td> Response Rate (%)</td>
<td>26</td>
<td>40</td>
<td>49</td>
<td>54</td>
<td>58</td>
<td>60</td>
<td>61</td>
<td>62</td>
<td>64</td>
</tr>
<tr>
<td> Noncontact (%)</td>
<td>17</td>
<td>11</td>
<td>7</td>
<td>5</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td> Refusals (%)</td>
<td>12</td>
<td>15</td>
<td>17</td>
<td>19</td>
<td>20</td>
<td>20</td>
<td>21</td>
<td>22</td>
<td>23</td>
</tr>
<tr>
<td> Other nonresponse (%)</td>
<td>45</td>
<td>34</td>
<td>27</td>
<td>22</td>
<td>18</td>
<td>16</td>
<td>15</td>
<td>14</td>
<td>10</td>
</tr>
<tr>
<td colspan="10">Norway (N=2,711 eligible cases)</td>
</tr>
<tr>
<td> Response Rate (%)</td>
<td>32</td>
<td>47</td>
<td>55</td>
<td>59</td>
<td>62</td>
<td>63</td>
<td>64</td>
<td>64</td>
<td>65</td>
</tr>
<tr>
<td> Noncontact (%)</td>
<td>6</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td> Refusals (%)</td>
<td>21</td>
<td>22</td>
<td>23</td>
<td>24</td>
<td>24</td>
<td>25</td>
<td>25</td>
<td>25</td>
<td>26</td>
</tr>
<tr>
<td> Other nonresponse (%)</td>
<td>44</td>
<td>30</td>
<td>21</td>
<td>16</td>
<td>13</td>
<td>12</td>
<td>11</td>
<td>10</td>
<td>9</td>
</tr>
<tr>
<td colspan="10">Slovenia (N=2,173 eligible cases)</td>
</tr>
<tr>
<td> Response Rate (%)</td>
<td>42</td>
<td>53</td>
<td>60</td>
<td>64</td>
<td>66</td>
<td>67</td>
<td>67</td>
<td>68</td>
<td>68</td>
</tr>
<tr>
<td> Noncontact (%)</td>
<td>10</td>
<td>6</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td> Refusals (%)</td>
<td>14</td>
<td>16</td>
<td>17</td>
<td>17</td>
<td>17</td>
<td>17</td>
<td>17</td>
<td>17</td>
<td>17</td>
</tr>
<tr>
<td> Other nonresponse (%)</td>
<td>34</td>
<td>25</td>
<td>19</td>
<td>16</td>
<td>15</td>
<td>14</td>
<td>13</td>
<td>13</td>
<td>13</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0759106312465547">
<p>
<bold>Note</bold>. In Slovenia, 93 cases could not be coded due to missing contact forms (<xref ref-type="bibr" rid="bibr36-0759106312465547">Matsuo et al., 2009</xref>: 10). These cases have been excluded from the analysis. The response rate was calculated according to AAPOR standards (RR2). However, the other percentages denote the proportion of all eligible cases that were coded as either noncontact, refusal, or other nonresponse after each contact attempt. These rates do not follow AAPOR guidelines, that is refusal rate = percentage of eligible cases that refused to participate in the survey.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>To compute the nonresponse bias, we focused on age and gender. For these two variables, the ESS provided not only the answers of the respondents to the respective socio-demographic questions, but also interviewer observations for non-interview cases. For those cases for which both the interviewer observation as well as the information from the respondent existed, we were able to compute considerably high correlations (Pearson corr., Finland: 1.0, Norway: .99, Slovenia: .97). We concluded that the estimation of the interviewer is a viable and safe method to estimate the true value of nonrespondents.</p>
<p>We used the following formula (<xref ref-type="bibr" rid="bibr2-0759106312465547">Biemer and Lyberg, 2003</xref>) to compute nonresponse biases:<disp-formula id="disp-formula1-0759106312465547">
<mml:math id="mml-disp1-0759106312465547"><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">=</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mo stretchy="false">−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mi>r</mml:mi></mml:msub></mml:math>
<graphic alternate-form-of="disp-formula1-0759106312465547" xlink:href="10.1177_0759106312465547-eq1.tif"/>
</disp-formula>
</p>
<p>This formula denotes the difference between the respondents in the net sample <inline-formula id="inline-formula1-0759106312465547">
<mml:math id="mml-inline1-0759106312465547"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mo fence="false" stretchy="false">↓</mml:mo></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math>
</inline-formula> and the respondents in the gross sample (<inline-formula id="inline-formula2-0759106312465547">
<mml:math id="mml-inline2-0759106312465547"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover></mml:math>
</inline-formula>). We also computed the absolute standardized nonresponse bias, which divides the nonresponse bias by the standard error of the estimate and ignores the algebraic sign (<xref ref-type="bibr" rid="bibr55-0759106312465547">Vehovar, 2007</xref>).<disp-formula id="disp-formula2-0759106312465547">
<mml:math id="mml-disp2-0759106312465547"><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">=</mml:mo><mml:mfenced close="|" open="|"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo accent="true" stretchy="false">ˉ</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mfenced></mml:math>
<graphic alternate-form-of="disp-formula2-0759106312465547" xlink:href="10.1177_0759106312465547-eq2.tif"/>
</disp-formula>
</p>
<p>Whereas the relative bias provides information about the magnitude of the bias, the absolute standardized bias serves as an indicator of its statistical significance. In this paper, only the absolute standardized bias is reported.</p>
<p>To assess the impact of fieldwork efforts on nonresponse bias, we conducted the following simulation: we analyzed the nonresponse bias as it would have occurred if we had stopped fieldwork after a certain number of contact attempts. Accordingly, we compared the net sample after first, second, third, and all following contact attempts to the gross sample with respect to age and gender. These sub-samples were named <italic>net sample 1</italic> to <italic>net sample 10</italic>. In <italic>net sample 1</italic>, we included all cases which were completed in the first contact attempt. In <italic>net sample 2</italic>, all cases were included for which an interview could be completed in the first or second contact attempt, and so on. In <italic>net sample 10</italic>, we merged all cases with a completed interview in the first to the tenth contact attempt.</p>
<p>While some countries asked interviewers to report the results of more than ten contact attempts, the standard ESS contact form provides space for up to ten contact attempts. In Norway, Finland, and Slovenia, the number of contact attempts was limited to ten. Thus, we restricted the analysis to up to ten contact attempts.</p>
<p>The results for <italic>net sample 1</italic> are not reported in this paper. As described above, the three countries differed with respect to the administration of the first contact attempt (telephone vs. personal visit) and in the rules applied to document this first contact attempt in cases it was not successful (<xref ref-type="bibr" rid="bibr36-0759106312465547">Matsuo et al., 2009</xref>). Accordingly, the results from the first contact attempt were not comparable and therefore dropped from the analysis.</p>
<p>To investigate which part of the overall nonresponse bias is due to which type of nonrespondents, we subdivided remaining nonrespondents after each contact attempt into three categories: <italic>noncontact</italic>, <italic>refusal</italic>, and <italic>other nonresponse</italic>. The nonresponse bias was computed overall and for each of the three components. For example in case of the refusal bias, we dropped the refusals and compared the distribution of gender and age of the remaining sample (net sample plus cases with noncontact and other nonresponse after each contact attempt) to the gross sample. Thus, we were able to simulate having all persons in the sample except the refusals. We followed the same approach for noncontact bias and other nonresponse bias.</p>
<p>The overall nonresponse bias as well as the three bias components due to noncontact, refusal, and other nonresponse were calculated for gender (percentage of males and females) and for four age groups (under age 20, 20 to 39 years, 40 to 59 years, and 60 years or older), as well as for the bivariate allocation of age and gender. For the sake of shortness, we report the overall bias and the three components for a selection of these estimates: for the proportion of females, for the proportion of young people under age 20, for the elderly age 60 or over, and for females age 60 or over.</p>
</sec>
<sec id="section5-0759106312465547">
<title>Results</title>
<p>Even though all three countries reached similar overall response rates after ten contact attempts (see <xref ref-type="table" rid="table1-0759106312465547">Table 1</xref>), they did not show identical patterns of nonresponse bias. Altogether, the nonresponse bias decreased for most estimates in all three countries, however there were several deviations. Also, the three countries showed interesting differences in the pattern of the nonresponse bias components. Results are summarized in <xref ref-type="table" rid="table2-0759106312465547">Table 2</xref>.</p>
<table-wrap id="table2-0759106312465547" position="float">
<label>Table 2.</label>
<caption>
<p>Standardized nonresponse bias and response rates for Finland, Norway, and Slovenia by number of contact attempts.</p>
</caption>
<graphic alternate-form-of="table2-0759106312465547" xlink:href="10.1177_0759106312465547-table2.tif"/>
<table>
<thead>
<tr>
<th rowspan="2">
</th>
<th colspan="9">Number of contact attempt<hr/></th>
</tr>
<tr>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="10">Finland</td>
</tr>
<tr>
<td> Female</td>
<td>2.4*</td>
<td>1.6</td>
<td>1.1</td>
<td>1.1</td>
<td>0.7</td>
<td>0.6</td>
<td>0.4</td>
<td>0.2</td>
<td>0.1</td>
</tr>
<tr>
<td> Under 20</td>
<td>0.8</td>
<td>1.1</td>
<td>0.8</td>
<td>0.6</td>
<td>0.1</td>
<td>0.3</td>
<td>0.3</td>
<td>0.1</td>
<td>0.2</td>
</tr>
<tr>
<td> 60 years or older</td>
<td>3.6***</td>
<td>4.3***</td>
<td>3.8***</td>
<td>3.1**</td>
<td>2.3*</td>
<td>2.1*</td>
<td>1.9</td>
<td>2.0*</td>
<td>1.5</td>
</tr>
<tr>
<td> Elderly female</td>
<td>3.7***</td>
<td>3.8***</td>
<td>3.1**</td>
<td>2.4*</td>
<td>1.6</td>
<td>1.4</td>
<td>1.1</td>
<td>1.1</td>
<td>0.9</td>
</tr>
<tr>
<td> Response Rate (%)</td>
<td align="center">26</td>
<td align="center">40</td>
<td align="center">49</td>
<td align="center">54</td>
<td align="center">58</td>
<td align="center">60</td>
<td align="center">61</td>
<td align="center">62</td>
<td align="center">64</td>
</tr>
<tr>
<td colspan="10">Norway</td>
</tr>
<tr>
<td> Female</td>
<td>1.7</td>
<td>1.6</td>
<td>1.3</td>
<td>1.4</td>
<td>1.8</td>
<td>1.9</td>
<td>2.0*</td>
<td>2.1*</td>
<td>2.3*</td>
</tr>
<tr>
<td> Under 20</td>
<td>1.5</td>
<td>1.1</td>
<td>1.1</td>
<td>0.5</td>
<td>0.1</td>
<td>0.1</td>
<td>0.3</td>
<td>0.3</td>
<td>0.3</td>
</tr>
<tr>
<td> 60 years or older</td>
<td>0.7</td>
<td>1.5</td>
<td>2.0*</td>
<td>2.5*</td>
<td>3.0**</td>
<td>3.2**</td>
<td>3.2**</td>
<td>3.3***</td>
<td>3.4***</td>
</tr>
<tr>
<td> Elderly female</td>
<td>2.9**</td>
<td>2.3*</td>
<td>2.6**</td>
<td>2.9**</td>
<td>3.3***</td>
<td>2.4*</td>
<td>3.6***</td>
<td>3.6***</td>
<td>3.8***</td>
</tr>
<tr>
<td> Response Rate (%)</td>
<td align="center">32</td>
<td align="center">47</td>
<td align="center">55</td>
<td align="center">59</td>
<td align="center">62</td>
<td align="center">63</td>
<td align="center">64</td>
<td align="center">64</td>
<td align="center">65</td>
</tr>
<tr>
<td colspan="10">Slovenia</td>
</tr>
<tr>
<td> Female</td>
<td>2.9**</td>
<td>2.2*</td>
<td>1.8</td>
<td>1.6</td>
<td>1.3</td>
<td>1.1</td>
<td>1.1</td>
<td>1.1</td>
<td>1.1</td>
</tr>
<tr>
<td> Under age 20</td>
<td>2.5*</td>
<td>3.1**</td>
<td>3.1**</td>
<td>3.0**</td>
<td>3.2**</td>
<td>3.1**</td>
<td>3.1**</td>
<td>3.0**</td>
<td>3.0**</td>
</tr>
<tr>
<td> 60 years or older</td>
<td>3.7***</td>
<td>2.7**</td>
<td>1.7</td>
<td>1.1</td>
<td>0.8</td>
<td>0.5</td>
<td>0.4</td>
<td>0.4</td>
<td>0.3</td>
</tr>
<tr>
<td> Elderly female</td>
<td>2.9**</td>
<td>1.6</td>
<td>0.7</td>
<td>0.2</td>
<td>0.0</td>
<td>0.3</td>
<td>0.4</td>
<td>0.4</td>
<td>0.4</td>
</tr>
<tr>
<td> Response Rate (%)</td>
<td align="center">42</td>
<td align="center">53</td>
<td align="center">60</td>
<td align="center">64</td>
<td align="center">66</td>
<td align="center">67</td>
<td align="center">67</td>
<td align="center">68</td>
<td align="center">68</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0759106312465547">
<p>Note. * p &lt; .05; ** p &lt; .01; *** p &lt; .001.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<sec id="section6-0759106312465547">
<title>Finland</title>
<p>Finland started with a response rate of 26 percent in the second contact attempt. Quickly the response rate reached higher levels and after the fourth contact attempt 49 percent of the eligible gross sample had yielded an interview. After that, only minor increases could be observed which lead to an overall response rate of 64 percent after the tenth contact attempt.</p>
<p>With respect to gender, the sample in Finland initially yielded a significant absolute standardized nonresponse bias of 2.4 (p &lt; .05) for the proportion of female respondents in the second contact attempt. This quickly dropped after the third contact attempt and never reached the level of significance again. After ten contact attempts, the proportion of female respondents was no longer biased in the net sample. By contrast, the proportion of elderly respondents (60 years or older) had a huge significant nonresponse bias from the second contact attempt onwards (3.6; p &lt; .001). Only after the ninth contact attempt, the nonresponse bias for this estimate dropped below the threshold of significance.</p>
<p>Interestingly, the standardized nonresponse bias for the percentage of respondents below the age of 20 was never significant. From the second contact attempt onwards, the standardized nonresponse bias for this estimate was fairly low and not significant. Over the course of the fieldwork, this standardized nonresponse bias could be reduced even further and reached a very low level close to zero after the tenth contact attempt.</p>
<p>When looking at the standardized nonresponse bias for the percentage of elderly female respondents, Finland started with a significant nonresponse bias of 3.7 (p &lt; .001) which could be reduced to a value below the threshold of statistical significance from the sixth contact attempt onwards.</p>
<p>Overall, Finland was prone to three different patterns in the development of the standardized nonresponse bias: (1) no significant bias from the second contact attempt onwards for the percentage of young respondents; (2) an initial significant nonresponse bias for female respondents and elderly female respondents which could be reduced quickly after the third to sixth contact attempt, and (3) a huge significant nonresponse bias for the elderly which could only be reduced below the threshold of significance after the ninth contact attempt.</p>
<p>When looking at the components of the standardized nonresponse bias (noncontact, refusal, other nonresponse), we observed the expected pattern (<xref ref-type="fig" rid="fig1-0759106312465547">Figure 1</xref>): given the high quality standards in terms of noncontact for the European Social Survey, the noncontact component of the nonresponse bias was rather small. For all estimates assessed, the noncontact component of the bias was close to zero and never reached statistical significance. The same was true for refusals, at least for the percentage of female respondents and of younger respondents. In those two groups, the nonresponse bias component due to refusal was rather low and dropped considerably over the course of the fieldwork. The only exemption with respect to refusal was the standardized nonresponse bias for respondents aged 60 and over. After the second contact attempt, the standardized nonresponse bias component for refusal was below the value of one. However, it increased over the course of the fieldwork and reached a value close to statistical significance after the tenth contact attempt. Accordingly, more contact attempts seemed to increase the nonresponse bias for respondents aged 60 and over due to refusal. This is in part the reason why the overall nonresponse bias for the elderly in Finland dropped only after the ninth contact attempt below the threshold of statistical significance. If the refusal bias could have been limited to lower levels earlier in the fieldwork, the overall nonresponse bias for the elderly would have dropped much faster.</p>
<fig id="fig1-0759106312465547" position="float">
<label>Figure 1.</label>
<caption>
<p>Standardized nonresponse bias components by response rate for Finland for socio-demographic estimates (each point on the lines denotes a contact attempt; first contact attempt not shown).</p>
</caption>
<graphic xlink:href="10.1177_0759106312465547-fig1.tif"/>
</fig>
<p>It is also interesting to observe that the nonresponse bias component due to other nonresponse shows an inverse u-shape pattern for the elderly respondents. While this nonresponse bias component was rather low after the second contact attempt, it increased through the fourth contact attempt and reached statistical significance. It dropped again after the fifth contact attempt to values below that threshold. This, too, was responsible for the late drop of the overall standardized nonresponse bias for the elderly in Finland. Taken together, with respect to the elderly, the fieldwork was faced with two problems: (1) the increasing refusal bias (meaning that refusing respondents differ to a great extent from those cooperating with the survey); and (2) the increase in the other nonresponse bias during the first three to four contact attempts.</p>
</sec>
<sec id="section7-0759106312465547">
<title>Norway</title>
<p>Compared to Finland, fieldwork in Norway started with a slightly larger initial response rate after the second contact attempt (32 %). This response rate quickly increased and reached about 60 percent through the fifth contact attempt. Subsequently, further increases in the overall response rates were rather small. The final response rate is 65 percent, similar to Finland. The development of the response rate, as well as the magnitude of the absolute standardized nonresponse bias, is shown in <xref ref-type="table" rid="table2-0759106312465547">Table 2</xref>.</p>
<p>The nonresponse bias for the percentage of female respondents yielded values close to statistical significance from the second contact attempt onwards. Even though it dropped slightly through the fifth contact attempt, it then increased sharply and exceeded the threshold of statistical significance from the eighth contact attempt on. A similar pattern could be observed for elderly respondents. Here, again, the initial absolute standardized nonresponse bias was not significant after the second and third contact attempt. However, from the fourth contact attempt onwards, the standardized nonresponse bias increased steeply and reached considerably high values after the sixth contact attempt. Those two patterns contradicted the typical expectation according to which nonresponse bias drops once the response rate increases. Such a pattern could, for example, be observed for young respondents below age 20. Here, the standardized nonresponse bias never reached statistical significant values. Instead from the second contact attempt onwards, the overall nonresponse bias dropped to very low values close to zero after the sixth contact attempt.</p>
<p>Since both gender and age were heavily prone to nonresponse bias after five or six contact attempts, the combined nonresponse bias for elderly female respondents was huge and highly significant. After the second contact attempt, the nonresponse bias for this group was already significant and considerably large (2.9; p &lt; .01). It dropped only slightly to a value above two in the third contact attempt. However, from then on it increased sharply and reached significant values close to four at the end of fieldwork.</p>
<p>The nonresponse bias components showed differential patterns for the variables assessed (<xref ref-type="fig" rid="fig2-0759106312465547">Figure 2</xref>): The only constant is the considerable small noncontact bias component which was close to zero for all estimates. However, huge differences could be observed for the refusal component. While for young respondents below the age of 20, refusals did not contribute heavily to the overall nonresponse bias, a different picture arose for respondents aged 60 and over. Here, the refusal component remained significant through the fourth contact attempt and dropped only after six contact attempts considerably below the threshold of statistical significance. Also, the other nonresponse bias started with a significant value (2.7; p &lt; .01) after the second contact attempt and dropped then below the threshold of significance. However, it is interesting to observe that this nonresponse component increased again after five contact attempts, which in part resulted in the increase of the overall standardized nonresponse bias for the percentage of elderly respondents after five or six contact attempts. For elderly respondents, the increase in the overall nonresponse bias was due to two factors: the considerably large refusal bias which never approached values close to zero, and the reemergence other nonresponse bias. Those two factors together contributed to the sharp increase in the overall standardized nonresponse bias.</p>
<fig id="fig2-0759106312465547" position="float">
<label>Figure 2.</label>
<caption>
<p>Standardized nonresponse bias components by response rate for Norway for socio-demographic estimates (each point on the lines denotes a contact attempt; first contact attempt not shown).</p>
</caption>
<graphic xlink:href="10.1177_0759106312465547-fig2.tif"/>
</fig>
<p>For the percentage of female respondents, a similar pattern could be observed. Again, noncontact seemed to be of minor importance for the overall standardized nonresponse bias in Norway. However, refusal bias was close to significant values throughout fieldwork and never dropped considerably below the threshold of statistical significance. This, combined with the increase of the other nonresponse bias after the sixth contact attempt, caused the overall increase in the standardized nonresponse bias at the end of the fieldwork period.</p>
<p>Results for Norway indicated two different patterns of the nonresponse development over the fieldwork period: for the percentage of young respondents the analysis revealed the desired pattern according to which overall nonresponse bias dropped once more contact attempts yielded a higher response rate. In contrast, with regard to female respondents and the elderly, we observed an increase of the overall nonresponse bias after five or six contact attempts which was due to a noteworthy refusal bias throughout the fieldwork which added to a late increase in the other nonresponse bias.</p>
</sec>
<sec id="section8-0759106312465547">
<title>Slovenia</title>
<p>Slovenia started out, after the second contact attempt, with a considerably high response rate of 42 percent. Fieldwork in Slovenia quickly yielded a response rate of 60 percent after the fourth contact attempt and was able to achieve even higher values throughout the remaining contact attempts. After ten contact attempts, the final response rate of 68 percent was reached (see <xref ref-type="table" rid="table2-0759106312465547">Table 2</xref>).</p>
<p>The fieldwork efforts seemed to pay off in Slovenia, at least with respect to the percentage of female respondents and of the elderly. For both estimates, the overall nonresponse bias yielded significant values throughout the second and third contact attempt, and then quickly dropped below the threshold of statistical significance after the fourth contact attempt. This was particularly true for the elderly where the nonresponse bias after the tenth contact attempt was close to zero.</p>
<p>A different pattern could be observed for the estimate of young respondents below the age of 20. Here, the initial nonresponse bias was statistically significant after the second contact attempt (2.5; p &lt; .01), and then slightly increased to values around three and remained statistically significant. Here, additional contact attempts throughout fieldwork were unable to counteract the initial nonresponse bias. Instead, the bias seemed to increase even further. This pattern indicated that further fieldwork efforts brought respondents into the net sample that belonged to socio-demographic groups already overrepresented from the second contact attempt onwards.</p>
<p>When looking at the nonresponse bias components (<xref ref-type="fig" rid="fig3-0759106312465547">Figure 3</xref>), it is interesting to note that noncontact bias seemed to be slightly more important in Slovenia compared to Norway and Finland. Initially, the nonresponse bias due to noncontact was slightly larger and the final value after ten contact attempts was also somewhat larger than in the two other countries. Nevertheless, compared to refusal and other nonresponse, the contribution of noncontact to the overall absolute standardized nonresponse bias seemed to be of minor importance.</p>
<fig id="fig3-0759106312465547" position="float">
<label>Figure 3.</label>
<caption>
<p>Standardized nonresponse bias components by response rate for Slovenia for socio-demographic estimates (each point on the lines denotes a contact attempt; first contact attempt not shown).</p>
</caption>
<graphic xlink:href="10.1177_0759106312465547-fig3.tif"/>
</fig>
<p>By contrast, the other nonresponse component was more pronounced for the estimate of female respondents and of the elderly. In both cases, the initial value of the other nonresponse bias was significant after the second contact attempt (3.8 p &lt; .001 for the elderly and 2.3 p &lt; .05 for women). However, as expected, further fieldwork efforts contributed to a significant drop of this nonresponse component. The same was true for the refusal bias which was initially insignificant and dropped even further throughout fieldwork. Accordingly, the pattern of the nonresponse components for female respondents and the elderly followed the desired pattern according to which nonresponse dropped over the course of the fieldwork.</p>
<p>For the younger respondents below the age of 20, the overall significant nonresponse bias was mostly due to a refusal bias. Even though this component of the standardized nonresponse bias never reached statistical significance, it started with a value slightly above one, and then approached values close to the statistical significance after ten contact attempts. Even though noncontact bias seemed to drop, the increase in the other nonresponse bias added to the slight increase of the refusal bias and lead to a significant overall standardized nonresponse bias.</p>
</sec>
</sec>
<sec id="section9-0759106312465547">
<title>Summary and Discussion</title>
<p>Overall, results suggest that increasing the number of contact attempts in the fieldwork of the European Social Survey in Finland, Norway and Slovenia increased response rates. In the three countries considered in the analysis, the response rates stabilized after 6 to 7 contact attempts. Of course, additional contact attempts further increased response rates. However, typically the additional gains were small. Interestingly, noncontact was reduced only moderately while most additional completes came from the other nonresponse group.</p>
<p>Based on these beneficial results, the question arises whether or not nonresponse bias was also reduced. In the analysis, age, gender and the bivariate distribution of age and gender was assessed after each contact attempt using a simulation approach (the net sample was assessed as if fieldwork had been abandoned after the second, third and so on contact attempt). Results did not reveal a uniform pattern in the development of nonresponse bias: in Finland all four estimates assessed showed declining nonresponse biases over the course of the fieldwork. Here, additional contact attempts did not only increase the response rates but also reduced nonresponse bias. After ten contact attempts, all standardized nonresponse biases fell below the threshold of statistical significance. In Slovenia, three out for four biases decreased to nonsignificant levels. In this country, only the proportion of respondents below the age of 20 was prone to have a significant nonresponse bias. By contrast, in Norway three out of four biases increased noteworthy throughout fieldwork and all three were statistically significant after ten contact attempts.</p>
<p>Since most completed interviews gained through additional contact attempts were obtained from the other nonresponse group, nonresponse bias due to noncontact was typically small from the outset and fell to even lower levels throughout the fieldwork. It is important to note that additional contact attempts did not only increase the number of completes but also the number of refusals. Interestingly, in some cases the refusal bias increased due to this development: Either because the number of refusals increased, or because of the socio-demographic particularities of the refusals with respect to age and gender, and thus, the refusals deviated even more from the completed cases. In Slovenia, the increase of the refusal bias can be held responsible for the significant overall nonresponse bias at the end of the fieldwork. By contrast, in Norway refusal biases were typically decreasing. However, the bias due to other nonresponse increased. Since this group became smaller with more contact attempts, it is safe to say that particular groups of potential respondents remained in the other nonresponse group. These heterogeneous findings suggest that the three countries followed differential (implicit) nonresponse strategies to increase response.</p>
<p>The fact that more contact attempts yielded higher response rates (which is good from the sampling error point of view), but did not uniformly result in smaller nonresponse biases, calls for more advanced and structured procedures during fieldwork. A uniform allocation of additional field efforts to all nonresponding cases may no longer be a sufficient method to improve data quality. This is in line with <xref ref-type="bibr" rid="bibr18-0759106312465547">Groves and Heeringa (2006)</xref> who proposed a responsive design that builds on the classic two-phase sampling for nonresponse (<xref ref-type="bibr" rid="bibr20-0759106312465547">Hansen and Hurwitz, 1946</xref>) and aims for a more balanced sample composition. Similarly, <xref ref-type="bibr" rid="bibr40-0759106312465547">Peytchev et al. (2010)</xref> suggested increasing field efforts predominantly for certain underrepresented groups of the sample to compensate for nonresponse bias. The results presented in this paper suggest that such an approach might be more viable than a uniform treatment of all nonrespondents.</p>
<p>It is important to note limitations of this study. First, we were able to use only data from three countries in our analysis. Consequently, the conclusions drawn based on the results might be relative to the specifics of fieldwork in these countries or to a specific survey climate (<xref ref-type="bibr" rid="bibr17-0759106312465547">Groves and Couper, 1998</xref>; <xref ref-type="bibr" rid="bibr21-0759106312465547">Harkness, 1999</xref>). Second, the results may be bound to the topic of the European Social Survey concerned with monitoring changes in public attitudes. By contrast, <xref ref-type="bibr" rid="bibr14-0759106312465547">Firdion (1993)</xref>, using a survey on a sensitive topic, has demonstrated that respondents joined late are characterized by distinct characteristics that unambiguously helped reduce nonresponse bias. Even more important is a potential methodological shortcoming. The results reported were based on a simulation approach (“What was the sample composition after X contact attempts”) which is not the same as a study were from the outset only X contact attempts had been planned for (“What would have been sample composition if fieldwork had been planned for X contact attempts”). As <xref ref-type="bibr" rid="bibr24-0759106312465547">Heerwegh and colleagues (2007</xref>: 9) put it: “If such a limitation were imposed upon the interviewers, it is possible that they would change their contact strategy, which would lead to different results” compared to this simulation. However, it is difficult to imagine a design that compensates for this shortcoming.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="bibr1-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Bethlehem</surname>
<given-names>JG</given-names>
</name>
<name>
<surname>Cobben</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Schouten</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>2011</year>) <source>Handbook of Nonresponse in Household Surveys</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr2-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Biemer</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>2003</year>) <source>Introduction to Survey Quality</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr3-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Billiet</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Philippens</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Fitzgerald</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Stoop</surname>
<given-names>I</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Estimation of Nonresponse Bias in the European Social Survey: Using Information from Reluctant Respondents</article-title>. <source>Journal of Official Statistics</source> <volume>23</volume>(<issue>2</issue>): <fpage>135</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr4-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Blom</surname>
<given-names>AG</given-names>
</name>
<name>
<surname>Lynn</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Jäckle</surname>
<given-names>A</given-names>
</name>
</person-group> (<year>2008</year>) <source>Understanding Cross-national Differences in Unit Non-response: The Role of Contact Data</source>. <publisher-loc>Essex</publisher-loc>: <publisher-name>Institute for Social and Economic Research</publisher-name>.</citation>
</ref>
<ref id="bibr5-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Blom</surname>
<given-names>AG</given-names>
</name>
<name>
<surname>Jäckle</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Lynn</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>The Use of Contact Data in Understanding Cross-national Differences in Unit Nonresponse</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Harkness</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Braun</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Edwards</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>TP</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Mohler</surname>
<given-names>PP</given-names>
</name>
<name>
<surname>Pennell</surname>
<given-names>BE</given-names>
</name>
<name>
<surname>Smith</surname>
<given-names>TW</given-names>
</name>
</person-group> (eds) <source>Survey Methods in Multinational, Multiregional, and Multicultural Contexts</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name>, <fpage>335</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr6-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Brehm</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1994</year>) <article-title>Stubbing Our Toes for a Foot in the Door? Prior Contact, Incentives and Survey Response</article-title>. <source>International Journal of Public Opinion Research</source> <volume>6</volume>(<issue>1</issue>): <fpage>45</fpage>–<lpage>63</lpage>.</citation>
</ref>
<ref id="bibr7-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Burton</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Laurie</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Lynn</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>The Long-term Effectiveness of Refusal Conversion Procedures on Longitudinal Surveys</article-title>. <source>Journal of the Royal Statistical Society. Series A (Statistics in Society)</source> <volume>169</volume>(<issue>3</issue>): <fpage>459</fpage>–<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr8-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Curtin</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Presser</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Singer</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2000</year>) <article-title>The Effects of Response Rate Changes on the Index of Consumer Sentiment</article-title>. <source>Public Opinion Quarterly</source> <volume>64</volume>(<issue>4</issue>): <fpage>413</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr9-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Deding</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Fridberg</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Jakobsen</surname>
<given-names>V</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Non-response in a Survey among Immigrants in Denmark</article-title>. <source>Survey Research Methods</source> <volume>2</volume>(<issue>3</issue>): <fpage>107</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr10-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>De Heer</surname>
<given-names>W</given-names>
</name>
</person-group> (<year>1999</year>) <article-title>International Response Trends: Results of an International Survey</article-title>. <source>Journal of Official Statistics</source> <volume>15</volume>(<issue>2</issue>): <fpage>129</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr11-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>De Leeuw</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>1992</year>) <source>Data Quality in Mail, Telephone and Face-to-face Surveys</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>TT-Publikaties</publisher-name>.</citation>
</ref>
<ref id="bibr12-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>De Leeuw</surname>
<given-names>E</given-names>
</name>
<name>
<surname>De Heer</surname>
<given-names>W</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>Trends in Household Survey Nonresponse: A Longitudinal and International Comparison</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>DA</given-names>
</name>
<name>
<surname>Eltinge</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Little</surname>
<given-names>RJA</given-names>
</name>
</person-group> (eds) <source>Survey Nonresponse</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>, <fpage>41</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr13-0759106312465547">
<citation citation-type="book">
<collab collab-type="author">European Social Survey</collab> (<year>2006</year>) <source>Documentation Report</source>. <publisher-loc>Bergen, Norway</publisher-loc>: <publisher-name>ESS Data Archive</publisher-name>, <edition>edition 3.2</edition>.</citation>
</ref>
<ref id="bibr14-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Firdion</surname>
<given-names>JM</given-names>
</name>
</person-group> (<year>1993</year>) <article-title>L'effet du rang d'appel et de la présence du conjoint dans une enquête par téléphone</article-title>. <source>Population</source> <volume>48</volume>(<issue>5</issue>): <fpage>1281</fpage>–<lpage>314</lpage>.</citation>
</ref>
<ref id="bibr15-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gray</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Campanelli</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Deepchand</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Prescott-Clarke</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>1996</year>) <article-title>Exploring Survey Non-response: The Effect of Attrition on a Follow-up of the 1984-85 Health and Life Style Survey</article-title>. <source>Journal of the Royal Statistical Society. Series D (The Statistician)</source> <volume>45</volume>(<issue>2</issue>): <fpage>163</fpage>–<lpage>83</lpage>.</citation>
</ref>
<ref id="bibr16-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Nonresponse Rates and Nonresponse Bias in Household Surveys</article-title>. <source>Public Opinion Quarterly</source> <volume>70</volume>(<issue>5</issue>): <fpage>646</fpage>–<lpage>75</lpage>.</citation>
</ref>
<ref id="bibr17-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Couper</surname>
<given-names>MP</given-names>
</name>
</person-group> (<year>1998</year>) <source>Nonresponse in Household Interview Surveys</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr18-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Heeringa</surname>
<given-names>SG</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Response Design for Household Surveys: Tools for Actively Controlling Survey Error and Costs</article-title>. <source>Journal of the Royal Statistical Society. Series A (Statistics in Society)</source> <volume>169</volume>(<issue>3</issue>): <fpage>439</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr19-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Peytcheva</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>The Impact of Nonresponse Rates on Nonresponse Bias</article-title>. <source>Public Opinion Quarterly</source> <volume>72</volume>(<issue>2</issue>): <fpage>167</fpage>–<lpage>89</lpage>.</citation>
</ref>
<ref id="bibr20-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hansen</surname>
<given-names>MH</given-names>
</name>
<name>
<surname>Hurwitz</surname>
<given-names>WN</given-names>
</name>
</person-group> (<year>1946</year>) <article-title>The Problem of Nonresponse in Sample Surveys</article-title>. <source>Journal of the American Statistical Association</source> <volume>41</volume>(<issue>3</issue>): <fpage>517</fpage>–<lpage>529</lpage>.</citation>
</ref>
<ref id="bibr21-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harkness</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>1999</year>) <article-title>In Pursuit of Quality: Issues for Cross-national Survey Research</article-title>. <source>International Journal of Social Research Methodology</source> <volume>2</volume>(<issue>2</issue>): <fpage>125</fpage>–<lpage>140</lpage>.</citation>
</ref>
<ref id="bibr22-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Harris-Kojetin</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Tucker</surname>
<given-names>C</given-names>
</name>
</person-group> (<year>1999</year>) <article-title>Exploring the Relation of Economic and Political Conditions with Refusal Rates to A Government Survey</article-title>. <source>Journal of Official Statistics</source> <volume>15</volume>(<issue>2</issue>): <fpage>167</fpage>–<lpage>84</lpage>.</citation>
</ref>
<ref id="bibr23-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haunberger</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2011</year>) <article-title>To Participate or Not To Participate: Decision Processes Related to Survey Non-response</article-title>. <source>Bulletin de Méthodologie Sociologique</source> <volume>109</volume>(<issue>1</issue>): <fpage>39</fpage>–<lpage>55</lpage>.</citation>
</ref>
<ref id="bibr24-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Heerwegh</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Abts</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Loosveldt</surname>
<given-names>G</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Minimizing Survey Refusal and Noncontact Rates; Do our Efforts Pay off?</article-title> <source>Survey Research Methods</source> <volume>1</volume>(<issue>1</issue>): <fpage>3</fpage>–<lpage>10</lpage>.</citation>
</ref>
<ref id="bibr25-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hox</surname>
<given-names>JJ</given-names>
</name>
<name>
<surname>de Leeuw</surname>
<given-names>E</given-names>
</name>
</person-group> (<year>1994</year>) <article-title>A Comparison of Nonresponse in Mail, Telephone, and Face-to-face Surveys</article-title>. <source>Quality &amp; Quantity</source> <volume>28</volume>(<issue>4</issue>): <fpage>329</fpage>–<lpage>44</lpage>.</citation>
</ref>
<ref id="bibr26-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jäckle</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Lynn</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Respondent Incentives in a Multi-mode Panel Survey: Cumulative Effects on Nonresponse and Bias</article-title>. <source>Survey Methodology</source> <volume>34</volume>(<issue>1</issue>): <fpage>105</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr27-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jansen</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Hak</surname>
<given-names>T</given-names>
</name>
</person-group> (<year>1999</year>) <article-title>Nonresponse to Mail Surveys in a Lower-class Urban Area - A Two-stage Exploration of Access Failure and Refusal</article-title>. <source>Bulletin de Méthodologie Sociologique</source> <volume>62</volume>(<issue>1</issue>): <fpage>5</fpage>–<lpage>27</lpage>.</citation>
</ref>
<ref id="bibr28-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Keeter</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Miller</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Kohut</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Presser</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2000</year>) <article-title>Consequences of Reducing Nonresponse in a National Telephone Survey</article-title>. <source>Public Opinion Quarterly</source> <volume>64</volume>(<issue>1</issue>): <fpage>125</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr29-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Kreuter</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Lemay</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Casas-Cordero</surname>
<given-names>C</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Using Proxy Measures of Survey Outcomes in Post-survey Adjustments: Examples from the European Social Survey (ESS)</article-title>. In <source>Joint Statistical Meetings, Salt Lake City, Utah, 29 July – 02 August 2007</source>. <publisher-loc>Alexandria, VA</publisher-loc>: <publisher-name>American Statistical Association</publisher-name>, <fpage>3142</fpage>–<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr30-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kreuter</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Müller</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Trappmann</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Nonresponse and Measurement Error in Employment Research. Making Use of Administrative Data</article-title>. <source>Public Opinion Quarterly</source> <volume>74</volume>(<issue>5</issue>): <fpage>880</fpage>–<lpage>906</lpage>.</citation>
</ref>
<ref id="bibr31-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lapec</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>2006</year>) <article-title>Quality Issues in Interview Surveys - Some Contributions</article-title>. <source>Bulletin de Méthodologie Sociologique</source> <volume>90</volume>(<issue>1</issue>): <fpage>26</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr32-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lemay</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Durand</surname>
<given-names>C</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>The Effect of Interviewer Attitude on Survey Cooperation</article-title>. <source>Bulletin de Méthodologie Sociologique</source> <volume>76</volume>(<issue>1</issue>): <fpage>27</fpage>–<lpage>44</lpage>.</citation>
</ref>
<ref id="bibr33-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lipps</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Benson</surname>
<given-names>G</given-names>
</name>
</person-group> (<year>2005</year>) <article-title>Cross National Contact Strategies</article-title>. In <source>The Annual Conference of the American Association for Public Opinion Research</source>, <comment>Miami Beach, Florida, FL, May 11-14, 2005</comment>. <publisher-loc>Alexandria, VA</publisher-loc>: <publisher-name>American Statistical Association</publisher-name>, <fpage>3905</fpage>–<lpage>14</lpage>.</citation>
</ref>
<ref id="bibr34-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Lyberg</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Lyberg</surname>
<given-names>L</given-names>
</name>
</person-group> (<year>1991</year>) <article-title>Nonresponse Research at Statistics Sweden</article-title>. In <source>Joint Statistical Meetings, Atlanta, GA, August 18-22, 2010</source>. <publisher-loc>Alexandria, VA</publisher-loc>: <publisher-name>American Statistical Association</publisher-name>, <fpage>78</fpage>–<lpage>87</lpage>.</citation>
</ref>
<ref id="bibr35-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lynn</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Clarke</surname>
<given-names>P</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>Separating Refusal Bias and Non-contact Bias: Evidence from UK National Surveys</article-title>. <source>Journal of the Royal Statistical Society. Series D (The Statistician)</source> <volume>51</volume>(<issue>3</issue>): <fpage>319</fpage>–<lpage>33</lpage>.</citation>
</ref>
<ref id="bibr36-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Matsuo</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Symons</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Beullens</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Billiet</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2009</year>) <source>Response Based Quality Assessment in the ESS - Round 3</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Centre for Social Research, Working Paper</publisher-name>.</citation>
</ref>
<ref id="bibr37-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Merkle</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Edelman</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2002</year>) <article-title>Nonresponse in Exit Polls: A Comprehensive Analysis</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Groves</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>Dillman</surname>
<given-names>DA</given-names>
</name>
<name>
<surname>Eltinge</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Little</surname>
<given-names>RJA</given-names>
</name>
</person-group> (eds) <source>Survey Nonresponse</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>, <fpage>243</fpage>–<lpage>58</lpage>.</citation>
</ref>
<ref id="bibr38-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Neller</surname>
<given-names>K</given-names>
</name>
</person-group> (<year>2005</year>) <article-title>Kooperation und Verweigerung: Eine Non-Response-Studie</article-title>. <source>ZUMA-Nachrichten</source> <volume>29</volume>(<issue>57</issue>): <fpage>9</fpage>–<lpage>36</lpage>.</citation>
</ref>
<ref id="bibr39-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Nicoletti</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Buck</surname>
<given-names>NN</given-names>
</name>
</person-group> (<year>2004</year>) <source>Explaining Interviewee Contact and Co-operation in the British and German Household Panels</source>. <publisher-loc>Colchester</publisher-loc>: <publisher-name>University of Essex</publisher-name>.</citation>
</ref>
<ref id="bibr40-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Peytchev</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Riley</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Rosen</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Murphy</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Lindblad</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Reduction of nonresponse bias in surveys through case prioritization</article-title>. <source>Survey Research Methods</source> <volume>4</volume>(<issue>1</issue>): <fpage>21</fpage>–<lpage>29</lpage>.</citation>
</ref>
<ref id="bibr41-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Philippens</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Loosveldt</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Stoop</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Billiet</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2003</year>) <article-title>Non-contact Rates and International Calling Strategies: An International Comparison</article-title>. In <source>14th International Workshop on Household Survey Non-response, Leuven, September 2003</source>.</citation>
</ref>
<ref id="bibr42-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Proner</surname>
<given-names>H</given-names>
</name>
</person-group> (<year>2011</year>) <source>Ist keine Antwort auch eine Antwort? Die Teilnahme an politischen Umfragen</source>. <publisher-loc>Wiesbaden</publisher-loc>: <publisher-name>VS Verlag, first edition</publisher-name>.</citation>
</ref>
<ref id="bibr43-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Romanov</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Nir</surname>
<given-names>M</given-names>
</name>
</person-group> (<year>2010</year>) <article-title>Get It or Drop It? Cost-benefit Analysis of Attempts to Interview in Household Surveys</article-title>. <source>Journal of Official Statistics</source> <volume>26</volume>(<issue>1</issue>): <fpage>165</fpage>–<lpage>91</lpage>.</citation>
</ref>
<ref id="bibr44-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Schnell</surname>
<given-names>R</given-names>
</name>
</person-group> (<year>1997</year>) <source>Nonresponse in Bevölkerungsumfragen. Ausmaß, Entwicklung und Ursachen</source>. <publisher-loc>Opladen</publisher-loc>: <publisher-name>Leske + Budrich</publisher-name>.</citation>
</ref>
<ref id="bibr45-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Schouten</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>2004</year>) <source>Adjustment for Bias in the Integrated Survey on Household Living Conditions (POLS) 1998</source>. <publisher-loc>Voorburg, NL</publisher-loc>: <publisher-name>Statistics Netherlands, Discussion paper no</publisher-name>. <fpage>04001</fpage>.</citation>
</ref>
<ref id="bibr46-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schouten</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Cobben</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Bethlehem</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2009</year>) <article-title>Indicators for the Representativeness of Survey Response</article-title>. <source>Survey Methodology</source> <volume>35</volume>(<issue>1</issue>): <fpage>101</fpage>–<lpage>13</lpage>.</citation>
</ref>
<ref id="bibr47-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smith</surname>
<given-names>TW</given-names>
</name>
</person-group> (<year>1995</year>) <article-title>Trends in Non-response Rates</article-title>. <source>International Journal of Public Opinion Research</source> <volume>7</volume>(<issue>2</issue>): <fpage>157</fpage>–<lpage>71</lpage>.</citation>
</ref>
<ref id="bibr48-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smith</surname>
<given-names>TW</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Survey Non-response Procedures in Cross-national Perspective: The 2005 ISSP Non-response Survey</article-title>. <source>Survey Research Methods</source> <volume>1</volume>(<issue>1</issue>): <fpage>45</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr49-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Steeh</surname>
<given-names>CG</given-names>
</name>
</person-group> (<year>1981</year>) <article-title>Trends in Nonresponse Rates, 1952-1979</article-title>. <source>Public Opinion Quarterly</source> <volume>45</volume>(<issue>1</issue>): <fpage>40</fpage>–<lpage>57</lpage>.</citation>
</ref>
<ref id="bibr50-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stocké</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Langfeld</surname>
<given-names>B</given-names>
</name>
</person-group> (<year>2004</year>) <article-title>Effects of Survey Experience on Respondents' Attitudes towards Surveys</article-title>. <source>Bulletin de Méthodologie Sociologique</source> <volume>81</volume>(<issue>1</issue>): <fpage>5</fpage>–<lpage>32</lpage>.</citation>
</ref>
<ref id="bibr51-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stoop</surname>
<given-names>I</given-names>
</name>
</person-group> (<year>2004</year>) <article-title>Surveying Nonrespondents</article-title>. <source>Field Methods</source> <volume>16</volume>(<issue>1</issue>): <fpage>23</fpage>–<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr52-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Stoop</surname>
<given-names>I</given-names>
</name>
</person-group> (<year>2005</year>) <source>The Hunt for the Last Respondent. Nonresponse in Sample Surveys</source>. <publisher-loc>The Hague</publisher-loc>: <publisher-name>Social and Cultural Planning Office of the Netherlands and Aksant Academic Publisher</publisher-name>.</citation>
</ref>
<ref id="bibr53-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Stoop</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Koch</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Billiet</surname>
<given-names>J</given-names>
</name>
</person-group> (<year>2008</year>) <article-title>Response Rates and Nonresponse Bias in the ESS. Eight Lessons from the First Three Rounds</article-title>. In <source>International Conference on Survey Methods in Multinational, Multiregional, and Multicultural Contexts (3MC), Berlin, Germany, 25-28 June 2008</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Berlin-Brandenburg Academy of Sciences and Humanities</publisher-name>.</citation>
</ref>
<ref id="bibr54-0759106312465547">
<citation citation-type="journal">
<person-group person-group-type="author">
<name>
<surname>Synodinos</surname>
<given-names>NE</given-names>
</name>
<name>
<surname>Yamada</surname>
<given-names>S</given-names>
</name>
</person-group> (<year>2000</year>) <article-title>Response Rate Trends in Japanese Surveys</article-title>. <source>International Journal of Public Opinion Research</source> <volume>12</volume>(<issue>1</issue>): <fpage>48</fpage>–<lpage>72</lpage>.</citation>
</ref>
<ref id="bibr55-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Vehovar</surname>
<given-names>V</given-names>
</name>
</person-group> (<year>2007</year>) <article-title>Non-response Bias in the European Social Survey</article-title>. In <person-group person-group-type="editor">
<name>
<surname>Loosveldt</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Swyngedouw</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Cambré</surname>
<given-names>B</given-names>
</name>
</person-group> (eds) <source>Measuring Meaningful Data in Social Research</source>. <publisher-loc>Leuven</publisher-loc>: <publisher-name>Acco</publisher-name>, <fpage>335</fpage>–<lpage>56</lpage>.</citation>
</ref>
<ref id="bibr56-0759106312465547">
<citation citation-type="book">
<person-group person-group-type="author">
<name>
<surname>Wagner</surname>
<given-names>JR</given-names>
</name>
</person-group> (<year>2008</year>) <source>Adaptive Survey Design to Reduce Nonresponse Bias</source>. <publisher-loc>Ann Arbor, MI</publisher-loc>: <publisher-name>University of Michigan</publisher-name>.</citation>
</ref>
</ref-list>
</back>
</article>