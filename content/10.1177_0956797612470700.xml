<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSS</journal-id>
<journal-id journal-id-type="hwp">sppss</journal-id>
<journal-id journal-id-type="nlm-ta">Psychol Sci</journal-id>
<journal-title>Psychological Science</journal-title>
<issn pub-type="ppub">0956-7976</issn>
<issn pub-type="epub">1467-9280</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0956797612470700</article-id>
<article-id pub-id-type="publisher-id">10.1177_0956797612470700</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Behavioral Demonstration of Overconfidence in Judgment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Mannes</surname><given-names>Albert E.</given-names></name>
<xref ref-type="aff" rid="aff1-0956797612470700">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Moore</surname><given-names>Don A.</given-names></name>
<xref ref-type="aff" rid="aff2-0956797612470700">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0956797612470700"><label>1</label>The Wharton School, University of Pennsylvania</aff>
<aff id="aff2-0956797612470700"><label>2</label>Haas School of Business, University of California, Berkeley</aff>
<author-notes>
<corresp id="corresp1-0956797612470700">Albert E. Mannes, The Wharton School, University of Pennsylvania, 3730 Walnut St., Philadelphia, PA 19104 E-mail: <email>albert.mannes@gmail.com</email></corresp>
<fn fn-type="con">
<label>Author Contributions</label>
<p>A. E. Mannes and D. A. Moore developed the theory and design used in all three experiments. A. E. Mannes programmed the experiments and conducted the analysis of the data. D. A. Moore collected the data. A. E. Mannes and D. A. Moore contributed equally to the drafting and revision of the manuscript. Both authors approved the final version of the manuscript for submission.</p>
</fn>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>7</month>
<year>2013</year>
</pub-date>
<volume>24</volume>
<issue>7</issue>
<fpage>1190</fpage>
<lpage>1197</lpage>
<history>
<date date-type="received">
<day>4</day>
<month>6</month>
<year>2012</year>
</date>
<date date-type="accepted">
<day>6</day>
<month>11</month>
<year>2012</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2013</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>Overprecision—an excessive confidence that one knows the truth—is both the most durable and the least understood form of overconfidence. This article outlines an approach to the study of overprecision that avoids some of the methodological problems of other approaches and better reflects the way uncertainty affects choices in everyday life. We measured the precision in judgment implied by people’s tendency to adjust their point estimates of an uncertain quantity in response to the costs of overestimating or underestimating the correct answer. The results revealed robust overprecision. People adjusted their estimates less than they should have given their actual knowledge, and this effect was driven by their subjective confidence.</p>
</abstract>
<kwd-group>
<kwd>judgment</kwd>
<kwd>decision making</kwd>
<kwd>prediction</kwd>
<kwd>simulation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Overconfidence has been called the most pervasive and potent bias to which human judgment is vulnerable (<xref ref-type="bibr" rid="bibr8-0956797612470700">De Bondt &amp; Thaler, 1995</xref>; <xref ref-type="bibr" rid="bibr15-0956797612470700">Kahneman, 2011</xref>). Of the various forms of overconfidence, the most robust and least understood is what <xref ref-type="bibr" rid="bibr19-0956797612470700">Moore and Healy (2008)</xref> call overprecision—excessive confidence that one knows the truth. Overprecision has profound consequences, giving investors excessive confidence in the value of their investments (<xref ref-type="bibr" rid="bibr6-0956797612470700">Daniel, Hirshleifer, &amp; Subrahmanyam, 2001</xref>), leading physicians to gravitate too quickly to a particular diagnosis (<xref ref-type="bibr" rid="bibr4-0956797612470700">Christensen-Szalanski &amp; Bushyhead, 1981</xref>), and making people intolerant of dissenting views (<xref ref-type="bibr" rid="bibr13-0956797612470700">Harvey, 1997</xref>; <xref ref-type="bibr" rid="bibr14-0956797612470700">Harvey &amp; Fischer, 1997</xref>).</p>
<p>Overprecision has proven remarkably resistant to debiasing by researchers using standard approaches to its study (<xref ref-type="bibr" rid="bibr13-0956797612470700">Harvey, 1997</xref>; <xref ref-type="bibr" rid="bibr21-0956797612470700">Soll &amp; Klayman, 2004</xref>).<sup><xref ref-type="fn" rid="fn1-0956797612470700">1</xref></sup> This has led to concerns that overprecision may be a methodological artifact (<xref ref-type="bibr" rid="bibr7-0956797612470700">Dawes &amp; Mulford, 1996</xref>; <xref ref-type="bibr" rid="bibr9-0956797612470700">Gigerenzer, 1991</xref>). Researchers typically study overprecision by asking people to specify 90% confidence intervals (CIs) around a numerical estimate (e.g., the length of the Nile River). These 90% CIs include the truth as rarely as 30% of the time, which suggests that people have excessively precise views of what they know (<xref ref-type="bibr" rid="bibr18-0956797612470700">McKenzie, Liersch, &amp; Yaniv, 2008</xref>; <xref ref-type="bibr" rid="bibr21-0956797612470700">Soll &amp; Klayman, 2004</xref>).</p>
<p>One criticism of this approach is that it requires familiarity with probability and CIs—statistical concepts with which even well-educated people routinely make large errors (<xref ref-type="bibr" rid="bibr5-0956797612470700">Cosmides &amp; Tooby, 1996</xref>; <xref ref-type="bibr" rid="bibr23-0956797612470700">Tversky &amp; Kahneman, 1993</xref>). A second criticism is that this approach does not reflect the way overprecision affects people’s judgments in daily life. It is rare for people to have to specify CIs around a belief. When deciding what time to depart for a lunch meeting, for example, people do not consider a 90% CI around the travel time. Instead, if punctuality is important, uncertainty should lead them to depart earlier. Or because falling off a cliff is worse than missing the great view, people keep back from the precipice. Every day, in hundreds of different instances, people steer clear of metaphorical cliffs as a function of the cost of erring on each side and of uncertainty. In the research reported here, we manipulated these two factors to observe their effects on people’s judgments. The first benefit of our approach is that it does not require asking participants about probabilities, degrees of confidence, or CIs. The second benefit is that our approach parallels the way in which uncertainty affects everyday judgments.</p>
<sec id="section1-0956797612470700">
<title>Overview</title>
<p>Our approach builds on that of <xref ref-type="bibr" rid="bibr17-0956797612470700">Mamassian (2008)</xref> by assessing overprecision in declarative knowledge. In our studies, people estimated the high temperature of cities on randomly selected days. We gave them feedback on the accuracy of their estimates and rewarded them for accuracy with tickets in a lottery for a prize. The days were divided into three blocks, and each block featured a different payoff function. One block featured symmetric payoffs, in which participants earned lottery tickets if their estimates were correct or close to (either above or below) the correct answer. The two other blocks featured asymmetric payoffs. In one, participants earned lottery tickets only for correctly guessing or overestimating the answer; in the other, participants earned lottery tickets only for correctly guessing or underestimating the answer. These payoffs were designed to mimic the asymmetric costs of erring to one side of the truth or the other in daily life.</p>
<p>The participants in Experiment 1a, for instance, earned five lottery tickets in the block with symmetric payoffs if their estimates were within 6 °C of the correct answer and zero tickets otherwise (see <xref ref-type="table" rid="table1-0956797612470700">Table 1</xref>). In the block with payoffs for overestimation, participants earned five tickets if they correctly guessed the answer or overestimated it by no more than 6 °C, earned two tickets if they overestimated it by more than 6 °C, and zero tickets if they underestimated it. The converse was true in the block with payoffs for underestimation: Participants earned five tickets if they correctly guessed the answer or underestimated it by no more than 6 °C, earned two tickets if they underestimated it by more than 6 °C, and zero tickets if they overestimated it.</p>
<table-wrap id="table1-0956797612470700" position="float">
<label>Table 1.</label>
<caption>
<p>Payoff Structures in Experiment 1a</p>
</caption>
<graphic alternate-form-of="table1-0956797612470700" xlink:href="10.1177_0956797612470700-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="4">Estimate (relative to actual temperature)<hr/></th>
</tr>
<tr>
<th align="center">Block</th>
<th align="center">More than 6 °C below</th>
<th align="center">Up to 6 °C below</th>
<th align="center">Up to 6 °C above</th>
<th align="center">More than 6 °C above</th>
</tr>
</thead>
<tbody>
<tr>
<td>Symmetric payoffs: equal reward for underestimation and overestimation</td>
<td>0</td>
<td>5</td>
<td>5</td>
<td>0</td>
</tr>
<tr>
<td>Asymmetric payoffs: no reward for underestimation, reward for overestimation</td>
<td>0</td>
<td>0</td>
<td>5</td>
<td>2</td>
</tr>
<tr>
<td>Asymmetric payoffs: no reward for overestimation, reward for underestimation</td>
<td>2</td>
<td>5</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0956797612470700">
<p>Note: Perfect estimates always earned five tickets. Because temperatures are less variable in Berkeley than in Pittsburgh, in Experiments 1b and 2 we reduced the cutoffs for earning tickets from 6 °C to 4 °C.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>For example, imagine a participant who is asked to guess the high temperature in Pittsburgh on March 10, 2006. The participant believes the most likely answer is 10 °C but also that any temperature in the range of 7 °C to 12 °C is possible. In the block with symmetric payoffs, the costs of overestimation and of underestimation are identical, so the participant should guess the most likely answer (10 °C) to try to earn five lottery tickets. In the blocks with asymmetric payoffs, the participant’s guess should account for his or her uncertainty about the correct answer and for the relative costs of overestimating and underestimating it. For instance, because the participant believes that the temperature could have been 11 °C or 12 °C that day, a guess of 10 °C may underestimate the correct answer. To earn five tickets in the block with payoffs for overestimation, the participant should adjust his or her estimate upward (e.g., +3 °C) to reduce the probability of underestimating the correct value. As indicated in <xref ref-type="table" rid="table1-0956797612470700">Table 1</xref>, however, the participant will earn only two tickets instead of five if he or she overestimates too much. Thus, to earn the maximum of five tickets, the participant should guess something close to the correct answer but not less than it.</p>
<p>The confidence that participants have in their answers should affect the degree to which they adjust their estimates in the asymmetric-payoffs blocks. If, for example, the aforementioned participant is less confident and believes that temperatures between 5 °C and 15 °C were possible that day, he or she should make even larger upward adjustments (e.g., +5 °C) to reduce the probability of underestimation.</p>
<p>We made two predictions about people’s behavior in this task. First, we expected people to be overprecise: That is, we expected people to adjust their point estimates in the correct direction in response to the asymmetric payoffs but to do so insufficiently. Experiments 1a and 1b demonstrate this basic result. Second, we expected people’s confidence to moderate their overprecision. Specifically, we predicted that the more confidence people had in their point estimates, the less they would adjust them. We manipulated confidence in Experiment 2. (Data and stimuli for all three experiments are available at Don Moore’s Web site: <ext-link ext-link-type="uri" xlink:href="http://learnmoore.org/mooredata/EJM/">http://learnmoore.org/mooredata/EJM/</ext-link>.)</p>
</sec>
<sec id="section2-0956797612470700">
<title>Experiment 1a</title>
<sec id="section3-0956797612470700">
<title>Method</title>
<p>We recruited 36 women and 28 men from Pittsburgh, Pennsylvania (mean age = 25.6 years), to participate in a study of judgment conducted at a local university. Participants were offered $5 and tickets in a lottery for an iPod Shuffle in return for completing the study.</p>
<p>Participants first provided 90% CIs for the high temperature in Pittsburgh (in degrees Celsius or degrees Fahrenheit, at their choosing) on 24 randomly selected days in 2006 and 2007. These data enabled us to compare traditional measures of overprecision with our measure. Next, participants made point estimates of the high temperature on 72 days, which were divided into three blocks of 24 days, and received trial-by-trial feedback with the correct answers. Participants earned tickets according to the payoffs in each block, up to a maximum of 120 per block. <xref ref-type="table" rid="table1-0956797612470700">Table 1</xref> shows the payoffs for each block. The block with symmetric payoffs came first, followed by the two blocks with asymmetric payoffs; the order of the asymmetric-payoffs blocks was counterbalanced. Before starting each block, participants had to correctly answer three questions about the payoffs to demonstrate their attention and understanding. Moreover, the payoff function for the current block was summarized at the top of the computer screen throughout the trials. After completing their estimates, participants answered questions about themselves and their knowledge of Pittsburgh temperatures. After learning how many tickets they had earned, they were dismissed.</p>
<p>To measure overprecision in the point estimates, we calculated the ratio between the <italic>observed adjustment</italic> of each person’s estimates in the asymmetric-payoffs blocks and a <italic>normative adjustment</italic> that would have maximized the expected payoffs in those blocks (cf. <xref ref-type="bibr" rid="bibr11-0956797612470700">Granger, 1969</xref>).</p>
<p>The observed adjustment for each person was his or her mean error (i.e., bias) in each block. We expected a positive bias when participants were rewarded for overestimating the correct answer (i.e., a positive average adjustment in the block with payoffs for overestimation) and a negative bias when participants were rewarded for underestimating the correct answer (i.e., a negative average adjustment in the block with payoffs for underestimation).</p>
<p>To determine the normative adjustment for each person, we first calculated how many lottery tickets the person would have earned in each of the asymmetric-payoffs blocks for a range of additional adjustments to his or her observed estimates. Specifically, for each asymmetric-payoff block, we simulated the number of tickets that would have been earned for 201 additional adjustments to the observed estimates (viz., −50 °C, −49.5 °C, . . . +49.5 °C, +50 °C; note that an adjustment of +0 °C reproduces the observed estimates). We then averaged those adjustments for which the simulated earnings exceeded the participant’s actual earnings. Finally, we added this number to the participant’s observed adjustment to produce his or her normative adjustment for that block (cf. <xref ref-type="bibr" rid="bibr16-0956797612470700">Lawrence &amp; O’Connor, 2005</xref>).<sup><xref ref-type="fn" rid="fn2-0956797612470700">2</xref></sup></p>
<p><italic>Overprecision</italic> was indexed by subtracting from 1 the ratio of each person’s observed adjustment to his or her normative adjustment. If the observed adjustment was less than the normative adjustment, overprecision was greater than zero (the person was overprecise); if the observed adjustment was greater than the normative adjustment, overprecision was less than zero (the person was underprecise); and if the observed and normative adjustments were equal, overprecision equaled zero (the person was neither underprecise nor overprecise). For example, assume that a person’s observed adjustment in the block with payoffs for overestimation was +3 °C and the simulations demonstrated that the person’s earnings would have been higher with an average additional adjustment of +2 °C. This person’s normative adjustment would be +5 °C, and his or her degree of overprecision would be 0.40 (1 − 3/5). This example is illustrated in <xref ref-type="fig" rid="fig1-0956797612470700">Figure 1</xref>.</p>
<fig id="fig1-0956797612470700" position="float">
<label>Fig. 1.</label>
<caption>
<p>A representation of overprecision in judgment. The solid line plots a hypothetical person’s observed distribution of errors in response to payoffs that reward overestimation; on average, this person added +3 to her estimates. The double line identifies the average adjustment that would have maximized her expected payoffs, which in this case is +5. The percentage difference between the observed and normative adjustments represents overprecision. The dashed line plots the person’s belief about her errors implied by the observed adjustment. (Note that although we portray this person’s errors as normally distributed, we did not make this assumption when calculating overprecision in the experiments.)</p>
</caption>
<graphic xlink:href="10.1177_0956797612470700-fig1.tif"/>
</fig>
</sec>
<sec id="section4-0956797612470700">
<title>Results and discussion</title>
<sec id="section5-0956797612470700">
<title>Preliminary analysis</title>
<p>Two point estimates greater than 100 °C were coded as entry errors and excluded prior to the analysis. To check the manipulation of payoffs, we calculated the observed adjustment (in degrees Celsius) by each person for each block. The average adjustment in the block with symmetric payoffs was 0.69, 95% CI = [0.25, 1.13]; in the block with payoffs for overestimation, the average adjustment was 4.93, 95% CI = [4.35, 5.50]; and in the block with payoffs for underestimation, the average adjustment was −6.29, 95% CI = [−6.88, −5.70]. Our manipulation of payoffs led people to adjust (i.e., bias) their estimates as expected.</p>
</sec>
<sec id="section6-0956797612470700">
<title>Point estimates</title>
<p>Because differences between the two asymmetric-payoffs blocks were not of substantive interest, we averaged the observed and normative adjustments (reverse-coded as necessary) across these blocks for each person before calculating overprecision. The average level of overprecision (<italic>M</italic> = 0.33, <italic>SD</italic> = 0.26) was significantly different from 0, <italic>t</italic>(63) = 10.16, <italic>p</italic> &lt; .001, Cohen’s <italic>d</italic> = 1.27. Participants’ actual earnings in the asymmetric-payoffs blocks (<italic>M</italic> = 118.69 tickets, <italic>SD</italic> = 12.06) were significantly less than what they would have earned absent their overprecision (<italic>M</italic> = 125.05 tickets, <italic>SD</italic> = 8.99), <italic>t</italic>(63) = 19.49, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.60.</p>
<p>Participants who made larger absolute errors in the symmetric-payoffs block tended to make larger adjustments to their point estimates in the asymmetric-payoffs blocks (<italic>r</italic><sub>s</sub> = .28, <italic>p</italic> = .024). In other words, those less knowledgeable about Pittsburgh temperatures adjusted more, as they should have. This suggests that confidence—knowledge of what one knows (<xref ref-type="bibr" rid="bibr20-0956797612470700">Russo &amp; Schoemaker, 1992</xref>)—was an important predictor of behavior.</p>
</sec>
<sec id="section7-0956797612470700">
<title>Confidence intervals</title>
<p>On average, participants’ 90% CIs contained the correct answer 49% of the time (<italic>SD</italic> = 24%). Thus, this study replicated the overprecision in CIs found in prior research. There was also correspondence in the measures of overprecision using our method and using CIs. Fifty-four of the participants were overprecise in both their CIs and their point estimates, 7 were overprecise only in their CIs, and 3 were overprecise only in their point estimates. In addition, individuals making the smallest adjustments to their point estimates constructed the narrowest 90% CIs (<italic>r</italic><sub>s</sub> = .43, <italic>p</italic> &lt; .001).</p>
</sec>
</sec>
</sec>
<sec id="section8-0956797612470700">
<title>Experiment 1b</title>
<p>Presenting the symmetric-payoffs block first in Experiment 1a provided participants with extensive feedback about their actual knowledge, which enabled them to make informed judgments about how to adjust their estimates in the asymmetric-payoffs blocks. However, it is possible that participants found it difficult to switch from making their best estimate of the temperature in the context of symmetric payoffs to making biased estimates when payoffs were asymmetric. If this was the case, the results of Experiment 1a would overstate the extent of overprecision. With this concern in mind, in Experiment 1b we counterbalanced the order of the symmetric- and asymmetric-payoff blocks.</p>
<sec id="section9-0956797612470700">
<title>Method</title>
<p>We recruited 60 women and 42 men from Berkeley, California (mean age = 20.7 years), to participate. Each was offered $10 and a chance to win a $50 gift card from an online retailer. Participants guessed the high temperature in Berkeley (in degrees Celsius or degrees Fahrenheit, at their choosing) on randomly chosen days from 2006 and 2007. The procedure and measures were identical to those of the prior experiment, with three exceptions. First, we counterbalanced the order of the symmetric- and asymmetric-payoff blocks. Second, participants provided their 90% CIs after finishing all three blocks of point estimates. Third, the cutoffs in the payoff functions were changed from 6 °C to 4 °C.</p>
</sec>
<sec id="section10-0956797612470700">
<title>Results and discussion</title>
<p>The average adjustment (in degrees Celsius) was −1.09, 95% CI = [−1.34, −0.84], in the block with symmetric payoffs; 2.79, 95% CI = [2.46, 3.12], in the block with payoffs for overestimation; and −2.84, 95% CI = [−3.12, −2.57], in the block with payoffs for underestimation.</p>
<p>The average level of overprecision (<italic>M</italic> = 0.40, <italic>SD</italic> = 0.26) was significantly different from 0, <italic>t</italic>(101) = 15.82, <italic>p</italic> &lt; .001, <italic>d</italic> = 1.57. Overprecision was marginally higher for the 53 participants who started with asymmetric payoffs (<italic>M</italic> = 0.45, <italic>SD</italic> = 0.26) than for the 49 participants who started with symmetric payoffs (<italic>M</italic> = 0.36, <italic>SD</italic> = 0.25), <italic>t</italic>(100) = 1.70, <italic>p</italic> = .092, <italic>d</italic> = 0.34. This suggests that presenting the symmetric payoffs first, if anything, produced less overprecision.</p>
<p>On average, participants’ 90% CIs contained the correct answer 70% of the time (<italic>SD</italic> = 18%). Seventy-five of the participants were overprecise in both their CIs and their point estimates, 8 were overprecise only in their CIs, 18 were overprecise only in their point estimates, and 1 was overprecise in neither task. As in the prior study, individuals making the smallest adjustments to their point estimates constructed the narrowest 90% CIs (<italic>r</italic><sub>s</sub> = .38, <italic>p</italic> &lt; .001).</p>
</sec>
</sec>
<sec id="section11-0956797612470700">
<title>Experiment 2</title>
<p>Experiments 1a and 1b produced strong evidence of overprecision in judgments. In Experiment 2, we investigated the role of confidence as a moderator of people’s adjustments of point estimates. We manipulated confidence directly by varying the feedback participants received about the accuracy of their estimates (cf. <xref ref-type="bibr" rid="bibr1-0956797612470700">Arkes, Christensen, Lai, &amp; Blumer, 1987</xref>; <xref ref-type="bibr" rid="bibr22-0956797612470700">Stone &amp; Opel, 2000</xref>). Specifically, participants received no trial-by-trial feedback about their accuracy, authentic feedback (as in Experiments 1a and 1b), or feedback that exaggerated their errors. We expected that the overprecision found in Experiments 1a and 1b would be replicated in the no-feedback and authentic-feedback conditions and that participants who received exaggerated feedback would show the least overprecision.</p>
<sec id="section12-0956797612470700">
<title>Method</title>
<p>We recruited 107 women and 77 men from Berkeley, California (mean age = 20.5 years), to participate. Each was offered $10 and a chance to win a $25 gift card from an online retailer. The procedure was the same as that of Experiment 1a, with three exceptions. First, the cutoffs in the payoff functions were changed from 6 °C to 4 °C. Second, after completing a block of 90% CIs, participants were assigned to one of three conditions for the point estimates. In the <italic>no-feedback</italic> condition, participants completed their point estimates without trial-level or summary feedback about their errors. In the <italic>authentic-feedback</italic> condition, participants received accurate trial-level feedback about their errors. In the <italic>exaggerated-feedback</italic> condition, participants received manufactured trial-level feedback about their errors. The feedback was exaggerated by telling participants that their errors were approximately 2.5 times greater than they actually were (e.g., if the actual error was +2 °C, the participant was told that the error was +5 °C).</p>
<p>Third, after making their point estimates in the symmetric-payoffs block, all participants provided subjective probability distributions of their errors using the subjective-probability interval-estimate technique (<xref ref-type="bibr" rid="bibr12-0956797612470700">Haran, Moore, &amp; Morewedge, 2010</xref>). They indicated how many of their errors would fall into each of nine intervals for every 100 temperature estimates. (In degrees Celsius, these nine intervals were less than −11, −10 to −8, −7 to −5, −4 to −2, −1 to +1, +2 to +4, +5 to +7, +8 to +10, and greater than +11.) After assigning a frequency to each interval, participants completed the asymmetric-payoffs blocks. Participants then answered questions about themselves, their understanding of the task, their motivation, and their confidence. Finally, they learned how many tickets they had earned and were dismissed.</p>
<p>Overprecision was operationalized in the same way as in the prior experiments. We collected two measures of participants’ confidence: one implicit and one explicit. The implicit measure was the subjective probability distribution of their errors that participants provided after completing the symmetric-payoffs block. We expected participants with less confidence to construct wider probability distributions (as measured by the standard deviation of their distributions) than those with more confidence (<xref ref-type="bibr" rid="bibr12-0956797612470700">Haran et al., 2010</xref>). The explicit measure of confidence was each person’s answer to the following question at the end of the study: “How confident are you in your ability to accurately estimate Berkeley, CA, temperatures?” (0 = <italic>not at all confident</italic>, 4 = <italic>extremely confident</italic>).</p>
</sec>
<sec id="section13-0956797612470700">
<title>Results and discussion</title>
<sec id="section14-0956797612470700">
<title>Preliminary analysis</title>
<p>Four estimates greater than 100 °C in absolute value were dropped as data entry errors. In addition, 3 participants who made constant and extreme estimates in the asymmetric-payoffs blocks (e.g., −18 °C for Berkeley, CA) were excluded from the analysis, which left a final sample of 181 participants.<sup><xref ref-type="fn" rid="fn3-0956797612470700">3</xref></sup></p>
<p>The average adjustment (in degrees Celsius) was −0.29, 95% CI = [−0.47, −0.10], in the block with symmetric payoffs; 3.78, 95% CI = [3.40, 4.15], in the block with payoffs for overestimation; and −3.21, 95% CI = [−3.63, −2.80], in the block with payoffs for underestimation.</p>
</sec>
<sec id="section15-0956797612470700">
<title>Confidence</title>
<p>The correlation between the two measures of confidence was −.41 (i.e., people with wider probability distributions also reported lower confidence). Our manipulation of confidence was successful: A multivariate omnibus test rejected the possibility that feedback had no effect on confidence, <italic>F</italic>(4, 178) = 13.20, <italic>p</italic> &lt; .001. As <xref ref-type="table" rid="table2-0956797612470700">Table 2</xref> indicates, participants in the no-feedback condition were most confident, followed by those in the authentic-feedback condition, followed by those in the exaggerated-feedback condition. This was true for both the subjective probability distributions, <italic>F</italic>(2, 178) = 16.33, <italic>p</italic> &lt; .001, η<sup>2</sup> = .15, and self-reported confidence, <italic>F</italic>(2, 178) = 18.28, <italic>p</italic> &lt; .001, η<sup>2</sup> = .17.</p>
<table-wrap id="table2-0956797612470700" position="float">
<label>Table 2.</label>
<caption>
<p>Mean Confidence, Adjustments, and Overprecision in Experiment 2</p>
</caption>
<graphic alternate-form-of="table2-0956797612470700" xlink:href="10.1177_0956797612470700-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th/>
<th/>
<th align="center" colspan="2">Confidence<hr/></th>
<th align="center" colspan="2">Adjustment<hr/></th>
<th/>
</tr>
<tr>
<th align="left">Condition</th>
<th align="center"><italic>n</italic></th>
<th align="center">Implicit</th>
<th align="center">Self-reported</th>
<th align="center">Observed</th>
<th align="center">Normative</th>
<th align="center">Overprecision</th>
</tr>
</thead>
<tbody>
<tr>
<td>No feedback</td>
<td>64</td>
<td>1.61 (0.56)</td>
<td>2.16 (0.93)</td>
<td>2.79 (1.88)</td>
<td>5.02 (1.47)</td>
<td>0.41 (0.51)</td>
</tr>
<tr>
<td>Authentic feedback</td>
<td>58</td>
<td>1.70 (0.43)</td>
<td>2.05 (0.91)</td>
<td>2.74 (1.07)</td>
<td>5.14 (1.52)</td>
<td>0.42 (0.28)</td>
</tr>
<tr>
<td>Exaggerated feedback</td>
<td>59</td>
<td>2.08 (0.46)</td>
<td>1.24 (0.90)</td>
<td>5.00 (2.66)</td>
<td>5.71 (1.70)</td>
<td>0.05 (0.51)</td>
</tr>
<tr>
<td> Overall</td>
<td>181</td>
<td>1.79 (0.53)</td>
<td>1.82 (1.00)</td>
<td>3.50 (2.23)</td>
<td>5.28 (1.59)</td>
<td>0.29 (0.48)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0956797612470700">
<p>Note: Standard deviations are given in parentheses. The implicit measure of confidence was the standard deviation of the participant’s subjective probability distribution, so lower values indicate higher confidence.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section16-0956797612470700">
<title>Point estimates</title>
<p>The average level of overprecision (<italic>M</italic> = 0.29, <italic>SD</italic> = 0.48) was significantly different from 0, <italic>t</italic>(180) = 8.31, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.62. Participants’ total earnings in the asymmetric-payoffs blocks (<italic>M</italic> = 116.40 tickets, <italic>SD</italic> = 18.77) were significantly less than what they would have earned absent their overprecision (<italic>M</italic> = 128.86, <italic>SD</italic> = 12.35), <italic>t</italic>(180) = 17.81, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.79.</p>
<p>As expected, we reduced overprecision by manipulating confidence. <xref ref-type="table" rid="table2-0956797612470700">Table 2</xref> indicates that participants who received exaggerated feedback were significantly less overprecise than those who received no feedback, <italic>t</italic>(178) = 3.91, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.59, or authentic feedback, <italic>t</italic>(178) = 4.95, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.74. In fact, overprecision in the exaggerated-feedback condition did not differ statistically from 0, <italic>t</italic>(58) = 0.72, <italic>p</italic> = .47, <italic>d</italic> = 0.09.</p>
<p>Participants displayed overprecision in this task by insufficiently adjusting their point estimates relative to their normative benchmarks (see <xref ref-type="table" rid="table2-0956797612470700">Table 2</xref> for participants’ average observed and normative adjustments for each condition). We have argued that such adjustments are influenced by confidence: People who are less confident in their expertise adjust their estimates more than people who are more confident do. The data supported this claim. Specifically, participants with wider subjective probability distributions made larger adjustments to their subsequent point estimates (<italic>r</italic> = .37, <italic>p</italic> &lt; .001) and were less overprecise (<italic>r</italic> = −.28, <italic>p</italic> &lt; .001) than participants with narrower subjective probability distributions.</p>
</sec>
<sec id="section17-0956797612470700">
<title>Confidence intervals</title>
<p>On average, participants’ 90% CIs contained the correct answer 63% of the time (<italic>SD</italic> = 22%). This overprecision did not differ by condition, <italic>F</italic>(2, 178) = 0.91, <italic>p</italic> = .405. Of the 181 participants, 121 were overprecise in both their CIs and their point estimates, 37 were overprecise only in their CIs, 17 were overprecise only in their point estimates, and 6 were overprecise in neither task. Individuals who made the smallest adjustments to their point estimates constructed the narrowest 90% CIs (<italic>r</italic><sub>s</sub> = .18, <italic>p</italic> = .018).</p>
</sec>
</sec>
</sec>
<sec id="section18-0956797612470700" sec-type="discussion">
<title>Discussion</title>
<p>The three experiments we have reported provide evidence of overprecision in judgment in a paradigm that does not require participants to understand probabilities or CIs and that reflects the everyday decision contexts that depend on confidence in judgment. The results suggest that overprecision is robust and is not solely a product of unfamiliar elicitation methods that assume too much about respondents’ statistical sophistication.</p>
<p>Yet two concerns about this method persist. First, participants may have simply been insensitive to the asymmetric payoff structure. Anticipating this possibility, we took procedural measures to ensure that participants understood and were aware of the payoffs. Moreover, participants adjusted their estimates in the appropriate direction, and did so, on average, on the first trial of each block. In short, participants understood their incentives (for additional evidence about people’s ability to respond to asymmetric payoffs, see <xref ref-type="bibr" rid="bibr10-0956797612470700">Goodwin, 2005</xref>; <xref ref-type="bibr" rid="bibr16-0956797612470700">Lawrence &amp; O’Connor, 2005</xref>; <xref ref-type="bibr" rid="bibr24-0956797612470700">Weber, 1994</xref>).</p>
<p>Second, even if participants understood the payoff structures, they may have insufficiently adjusted their estimates because they were anchored by their best estimates of the answers (<xref ref-type="bibr" rid="bibr2-0956797612470700">Block &amp; Harper, 1991</xref>). In fact, verbal protocols from a supplementary study confirmed that participants often started with a best guess and adjusted from there. However, although anchoring processes may have been at work, they cannot explain why (a) participants with less expertise made greater adjustments in Experiment 1a, (b) participants with less confidence made greater adjustments in Experiment 2, and (c) overprecision was eliminated in Experiment 2 when people received unfavorable feedback about their accuracy. In sum, when asymmetric incentives lead people to adjust their responses to one side or the other of a best guess, the amount of adjustment depends critically on how confident they are in the accuracy of their knowledge—the subjective precision in their judgment. Excessive confidence is therefore key to participants’ failure to adjust sufficiently.</p>
<p>The new method presented here has its limitations. It does not elicit direct measures of confidence, and it is pedagogically less useful than traditional means of illustrating overconfidence, such as CI estimation (<xref ref-type="bibr" rid="bibr20-0956797612470700">Russo &amp; Schoemaker, 1992</xref>). Nevertheless, it offers researchers an alternative to self-reports that rely on having to explain probabilities or CIs.</p>
<p>The consequences of overprecision are profound. People frequently cut things too close—arriving late, missing planes, bouncing checks, or falling off one of the many “cliffs” that present themselves in daily life. People also cling too fervently to beliefs that are poorly supported by evidence, adjusting their beliefs too little in light of the evidence or the consequences of being wrong. We hope that the methodology and evidence we have presented here will prove useful in elucidating the underlying sources of people’s excessive faith in the accuracy of their own judgment.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0956797612470700">
<label>1.</label>
<p>There has been some success at debiasing overprecision. Elicitation methods that call explicit attention to a large range of response values can reduce overprecision (see <xref ref-type="bibr" rid="bibr12-0956797612470700">Haran, Moore, &amp; Morewedge, 2010</xref>; <xref ref-type="bibr" rid="bibr25-0956797612470700">Winman, Hansson, &amp; Juslin, 2004</xref>), and, in some cases, even cause underprecision (<xref ref-type="bibr" rid="bibr3-0956797612470700">Bolger &amp; Harvey, 1995</xref>; <xref ref-type="bibr" rid="bibr10-0956797612470700">Goodwin, 2005</xref>).</p>
</fn>
<fn fn-type="other" id="fn2-0956797612470700">
<label>2.</label>
<p>We relied on each person’s empirical distribution of errors for each payoff function to identify his or her normative adjustment rather than make parametric assumptions about those distributions, such as normality or invariance across payoff functions. As one reviewer pointed out, however, our method does assume that these distributions would not otherwise materially change if people made smaller or larger average adjustments. We used data from Experiment 1b to investigate the validity of this assumption. First, <italic>p</italic> values provided by Kolmogorov-Smirnov tests comparing the distribution of errors between the asymmetric-payoff blocks for each person ranged from .14 to 1.00. Thus, aside from their obvious differences in location, these error distributions were statistically equivalent (at α = .10) between payoff conditions. Second, we assessed whether any differences in these error distributions, as indexed by the Kolmogorov-Smirnov test statistic <italic>D</italic>, were related to differences in participants’ observed adjustments for each payoff condition. This correlation was .15 (<italic>p</italic> = .146). In sum, differences in the error distributions between the two asymmetric-payoff blocks were minor and weakly related to differences in the observed adjustments.</p>
</fn>
<fn fn-type="other" id="fn3-0956797612470700">
<label>3.</label>
<p>These 3 participants also reported significantly less motivation, <italic>F</italic>(1, 182) = 3.64, <italic>p</italic> = .058, and spent significantly less time on the task, <italic>F</italic>(1, 183) = 8.16, <italic>p</italic> = .005, than the other participants.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Arkes</surname><given-names>H. R.</given-names></name>
<name><surname>Christensen</surname><given-names>C.</given-names></name>
<name><surname>Lai</surname><given-names>C.</given-names></name>
<name><surname>Blumer</surname><given-names>C.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Two methods of reducing overconfidence</article-title>. <source>Organizational Behavior and Human Decision Processes, 39</source>, <fpage>133</fpage>–<lpage>144</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0749-5978(87)90049-5</pub-id></citation>
</ref>
<ref id="bibr2-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Block</surname><given-names>R. A.</given-names></name>
<name><surname>Harper</surname><given-names>D. R.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Overconfidence in estimation: Testing the anchoring-and-adjustment hypothesis</article-title>. <source>Organizational Behavior and Human Decision Processes</source>, <volume>49</volume>, <fpage>188</fpage>–<lpage>207</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0749-5978(91)90048-x</pub-id></citation>
</ref>
<ref id="bibr3-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bolger</surname><given-names>F.</given-names></name>
<name><surname>Harvey</surname><given-names>N.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Judging the probability that the next point in an observed time-series will be below, or above, a given value</article-title>. <source>Journal of Forecasting</source>, <volume>14</volume>, <fpage>597</fpage>–<lpage>607</lpage>. doi:<pub-id pub-id-type="doi">10.1002/for.3980140705</pub-id></citation>
</ref>
<ref id="bibr4-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Christensen-Szalanski</surname><given-names>J. J.</given-names></name>
<name><surname>Bushyhead</surname><given-names>J. B.</given-names></name>
</person-group> (<year>1981</year>). <article-title>Physicians’ use of probabilistic information in a real clinical setting</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>7</volume>, <fpage>928</fpage>–<lpage>935</lpage>.</citation>
</ref>
<ref id="bibr5-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cosmides</surname><given-names>L.</given-names></name>
<name><surname>Tooby</surname><given-names>J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Are humans good intuitive statisticians after all? Rethinking some conclusions from the literature on judgment under uncertainty</article-title>. <source>Cognition</source>, <volume>58</volume>, <fpage>1</fpage>–<lpage>73</lpage>.</citation>
</ref>
<ref id="bibr6-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Daniel</surname><given-names>K. D.</given-names></name>
<name><surname>Hirshleifer</surname><given-names>D.</given-names></name>
<name><surname>Subrahmanyam</surname><given-names>A.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Overconfidence, arbitrage, and equilibrium asset pricing</article-title>. <source>Journal of Finance</source>, <volume>56</volume>, <fpage>921</fpage>–<lpage>965</lpage>.</citation>
</ref>
<ref id="bibr7-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dawes</surname><given-names>R. M.</given-names></name>
<name><surname>Mulford</surname><given-names>M.</given-names></name>
</person-group> (<year>1996</year>). <article-title>The false consensus effect and overconfidence: Flaws in judgment or flaws in how we study judgment?</article-title> <source>Organizational Behavior and Human Decision Processes</source>, <volume>65</volume>, <fpage>201</fpage>–<lpage>211</lpage>.</citation>
</ref>
<ref id="bibr8-0956797612470700">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>De Bondt</surname><given-names>W. F. M.</given-names></name>
<name><surname>Thaler</surname><given-names>R. H.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Financial decision-making in markets and firms: A behavioral perspective</article-title>. In <person-group person-group-type="editor">
<name><surname>Jarrow</surname><given-names>R.</given-names></name>
<name><surname>Maksimovic</surname><given-names>V.</given-names></name>
<name><surname>Ziemba</surname><given-names>W. T.</given-names></name>
</person-group> (Eds.), <source>Handbooks in operations research and management science</source> (Vol. <volume>9</volume>, pp. <fpage>385</fpage>–<lpage>410</lpage>). <publisher-loc>Amsterdam, The Netherlands</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</citation>
</ref>
<ref id="bibr9-0956797612470700">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Gigerenzer</surname><given-names>G.</given-names></name>
</person-group> (<year>1991</year>). <article-title>How to make cognitive illusions disappear: Beyond “heuristics and biases.”</article-title> In <person-group person-group-type="editor">
<name><surname>Stroebe</surname><given-names>W.</given-names></name>
<name><surname>Hewstone</surname><given-names>M.</given-names></name>
</person-group> (Eds.), <source>European review of social psychology</source> (<volume>Vol. 2</volume>, pp. <fpage>83</fpage>–<lpage>115</lpage>). <publisher-loc>Chichester, England</publisher-loc>: <publisher-name>Wiley</publisher-name>.</citation>
</ref>
<ref id="bibr10-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goodwin</surname><given-names>P.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Providing support for decisions based on time series information under conditions of asymmetric loss</article-title>. <source>European Journal of Operational Research</source>, <volume>163</volume>, <fpage>388</fpage>–<lpage>402</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ejor.2003.10.039</pub-id></citation>
</ref>
<ref id="bibr11-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Granger</surname><given-names>C. W. J.</given-names></name>
</person-group> (<year>1969</year>). <article-title>Prediction with a generalized cost of error function</article-title>. <source>Operational Research Quarterly</source>, <volume>20</volume>, <fpage>199</fpage>–<lpage>207</lpage>.</citation>
</ref>
<ref id="bibr12-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Haran</surname><given-names>U.</given-names></name>
<name><surname>Moore</surname><given-names>D. A.</given-names></name>
<name><surname>Morewedge</surname><given-names>C. K.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A simple remedy for overprecision in judgment</article-title>. <source>Judgment and Decision Making</source>, <volume>5</volume>, <fpage>467</fpage>–<lpage>476</lpage>.</citation>
</ref>
<ref id="bibr13-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Harvey</surname><given-names>N.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Confidence in judgment</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>1</volume>, <fpage>78</fpage>–<lpage>82</lpage>. doi:<pub-id pub-id-type="doi">10.1016/s1364-6613(97)01014-0</pub-id></citation>
</ref>
<ref id="bibr14-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Harvey</surname><given-names>N.</given-names></name>
<name><surname>Fischer</surname><given-names>I.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Taking advice: Accepting help, improving judgment, and sharing responsibility</article-title>. <source>Organizational Behavior and Human Decision Processes</source>, <volume>70</volume>, <fpage>117</fpage>–<lpage>133</lpage>.</citation>
</ref>
<ref id="bibr15-0956797612470700">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kahneman</surname><given-names>D.</given-names></name>
</person-group> (<year>2011</year>). <source>Thinking, fast and slow</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Farrar, Straus, and Giroux</publisher-name>.</citation>
</ref>
<ref id="bibr16-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lawrence</surname><given-names>M.</given-names></name>
<name><surname>O’Connor</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Judgmental forecasting in the presence of loss functions</article-title>. <source>International Journal of Forecasting</source>, <volume>21</volume>, <fpage>3</fpage>–<lpage>14</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ijforecast.2004.02.003</pub-id></citation>
</ref>
<ref id="bibr17-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mamassian</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Overconfidence in an objective anticipatory motor task</article-title>. <source>Psychological Science</source>, <volume>19</volume>, <fpage>601</fpage>–<lpage>606</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02129.x</pub-id></citation>
</ref>
<ref id="bibr18-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McKenzie</surname><given-names>C. R. M.</given-names></name>
<name><surname>Liersch</surname><given-names>M. J.</given-names></name>
<name><surname>Yaniv</surname><given-names>I.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Overconfidence in interval estimates: What does expertise buy you?</article-title> <source>Organizational Behavior and Human Deci-sion Processes</source>, <volume>107</volume>, <fpage>179</fpage>–<lpage>191</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.obhdp.2008.02.007</pub-id></citation>
</ref>
<ref id="bibr19-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moore</surname><given-names>D. A.</given-names></name>
<name><surname>Healy</surname><given-names>P. J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>The trouble with overconfidence</article-title>. <source>Psychological Review</source>, <volume>115</volume>, <fpage>502</fpage>–<lpage>517</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0033-295X.115.2.502</pub-id></citation>
</ref>
<ref id="bibr20-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Russo</surname><given-names>J. E.</given-names></name>
<name><surname>Schoemaker</surname><given-names>P. J. H.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Managing overconfidence</article-title>. <source>Sloan Management Review</source>, <volume>33</volume>, <fpage>7</fpage>–<lpage>17</lpage>.</citation>
</ref>
<ref id="bibr21-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Soll</surname><given-names>J. B.</given-names></name>
<name><surname>Klayman</surname><given-names>J.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Overconfidence in interval estimates</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>30</volume>, <fpage>299</fpage>–<lpage>314</lpage>.</citation>
</ref>
<ref id="bibr22-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>E. R.</given-names></name>
<name><surname>Opel</surname><given-names>R. B.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Training to improve calibration and discrimination: The effects of performance and environmental feedback</article-title>. <source>Organizational Behavior and Human Decision Processes</source>, <volume>83</volume>, <fpage>282</fpage>–<lpage>309</lpage>. doi:<pub-id pub-id-type="doi">10.1006/obhd.2000.2910</pub-id></citation>
</ref>
<ref id="bibr23-0956797612470700">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tversky</surname><given-names>A.</given-names></name>
<name><surname>Kahneman</surname><given-names>D.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Probabilistic reasoning</article-title>. In <person-group person-group-type="editor">
<name><surname>Goldman</surname><given-names>A. I.</given-names></name>
</person-group> (Ed.), <source>Readings in philosophy and cognitive science</source> (pp. <fpage>43</fpage>–<lpage>68</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr24-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Weber</surname><given-names>E. U.</given-names></name>
</person-group> (<year>1994</year>). <article-title>From subjective probabilities to decision weights: The effect of asymmetric loss functions on the evaluation of uncertain outcomes and events</article-title>. <source>Psychological Bulletin</source>, <volume>115</volume>, <fpage>228</fpage>–<lpage>242</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0033-2909.115.2.228</pub-id></citation>
</ref>
<ref id="bibr25-0956797612470700">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Winman</surname><given-names>A.</given-names></name>
<name><surname>Hansson</surname><given-names>P.</given-names></name>
<name><surname>Juslin</surname><given-names>P.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Subjective probability intervals: How to reduce overconfidence by interval evaluation</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>30</volume>, <fpage>1167</fpage>–<lpage>1175</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0278-7393.30.6.1167</pub-id></citation>
</ref>
</ref-list>
</back>
</article>