<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TAP</journal-id>
<journal-id journal-id-type="hwp">sptap</journal-id>
<journal-title>Theory &amp; Psychology</journal-title>
<issn pub-type="ppub">0959-3543</issn>
<issn pub-type="epub">1461-7447</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0959354311398703</article-id>
<article-id pub-id-type="publisher-id">10.1177_0959354311398703</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The modularity debate in evolutionary psychology</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Chiappe</surname><given-names>Dan</given-names></name>
</contrib>
<contrib contrib-type="author">
<name><surname>Gardner</surname><given-names>Ricca</given-names></name>
</contrib>
<aff id="aff1-0959354311398703">California State University, Long Beach</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0959354311398703">Dan Chiappe, Department of Psychology, California State University, Long Beach, 1250 Bellflower Blvd., Long Beach, CA 90840, USA. Email: <email>dan.chiappe@csulb.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>10</month>
<year>2012</year>
</pub-date>
<volume>22</volume>
<issue>5</issue>
<fpage>669</fpage>
<lpage>682</lpage>
<permissions>
<copyright-statement>© The Author(s) 2011</copyright-statement>
<copyright-year>2011</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>The adherence of evolutionary psychology (EP) to the massive modularity thesis has generated considerable controversy. Barrett and Kurzban argue that much of the debate is misplaced because critics have incorrectly characterized the sense of modularity involved in EP. They offer an account centered on “functional specialization,” an emphasis on formal properties of representations, and an eschewing of references to content domains. We argue that their concept of modularity is at odds with the claims made by EP advocates. Indeed, their definition of modularity is so broad that it includes mechanisms traditionally rejected by EP. Furthermore, their concept of modularity has limited usefulness in explaining the existence of mechanisms designed to deal with novel challenges and with the development of novel solutions to longstanding adaptive problems. A model based on Potts’ concept of “variability selection” is offered as an explanation of such mechanisms.</p>
</abstract>
<kwd-group>
<kwd>domain generality</kwd>
<kwd>evolutionary psychology</kwd>
<kwd>functional specialization</kwd>
<kwd>modularity</kwd>
<kwd>reasoning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>The issue of how to integrate different branches of the social sciences, and whether it is even possible to do so, has been a subject of considerable debate (<xref ref-type="bibr" rid="bibr28-0959354311398703">Kukla, 1992</xref>; <xref ref-type="bibr" rid="bibr38-0959354311398703">Staats, 1991</xref>). Evolutionary psychology (EP) has been proposed as a theoretical framework capable of providing this integration (<xref ref-type="bibr" rid="bibr5-0959354311398703">Caporael, 2001</xref>; <xref ref-type="bibr" rid="bibr42-0959354311398703">Tooby &amp; Cosmides, 1992</xref>; but for a critical view see <xref ref-type="bibr" rid="bibr13-0959354311398703">Derksen, 2005</xref>). EP offers a view of mind very different from more traditional approaches to psychology. EP argues that evolutionary considerations lead us to expect cognitive architecture to be massively modular: that is, composed of highly specialized psychological mechanisms rather than domain-general ones. These specialized mechanisms provide the core of a human nature that is universal, and the massive modularity view thus combats a relativist perspective on the social sciences that presupposes a domain-general architecture (<xref ref-type="bibr" rid="bibr14-0959354311398703">Derksen, 2010</xref>).</p>
<p>While the EP position has generated considerable controversy (e.g., <xref ref-type="bibr" rid="bibr3-0959354311398703">Buller, 2005</xref>; <xref ref-type="bibr" rid="bibr9-0959354311398703">Chiappe &amp; MacDonald, 2005</xref>), <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> have argued that much of the debate is misplaced. The controversy rests on a misunderstanding of the notion of modularity intended by EP. Barrett and Kurzban claim critics have mistakenly attacked a narrow sense of modularity taken from <xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor (1983)</xref> instead of a broader notion based on the concept of functional specialization. This broader concept also stresses a focus on the formal properties of representations and dismisses discussions of semantics and content domains. The resulting account of modularity is one that is meant to apply to all psychological mechanisms. We argue that the Barrett and Kurzban construal is inconsistent with the claims made by EP advocates. Furthermore, the broad notion of modularity fails to capture important distinctions that exist in psychological mechanisms, ones that need to be explained by appealing to different evolutionary processes.</p>
<p>Let us begin by briefly outlining <xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor’s (1983)</xref> view of modularity. On his view, modules are characterized by a cluster of properties. They are designed to process information in particular content domains (domain specificity) by exploiting a restricted database (information encapsulation). Furthermore, they are innate, associated with localized brain circuitry, automatic in their operation, fast, and feature specific breakdown patterns.</p>
<p>As <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> point out, many critics have rejected the massive modularity thesis by arguing that some cognitive processes fail to satisfy one or more of the characteristics identified by <xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor (1983)</xref>. On their view, modularity ought to be defined in terms of the biological concept of <italic>functional specialization</italic>. All psychological mechanisms, like other biological adaptations, are designed to solve particular adaptive problems. They do so by processing certain types of inputs in unique ways. As <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> put it, “[F]unctionally specialized mechanisms…are characteristic of human (and non-human) cognition and…these features should be identified as the signal properties of ‘modularity’” (p. 630). On their view, then, modules may or may not have other properties that Fodor associated with modularity. They say, “This stance allows us to look for specialization in cognitive processes that might not have much in common in how they process information…without prejudging the issue of what features might support specialized information processing in a given case” (p. 629). Psychological mechanisms, while highly specialized for solving particular adaptive problems, may nonetheless differ in their degree of encapsulation, automaticity, localization, and so forth. Empirical research is required to identify which features any given module possesses.</p>
<p>Furthermore, <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> are careful to distinguish their sense of domain specificity from that of <xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor (1983)</xref>. They claim that “domains” are to be understood not as content domains. Instead, they are to be defined formally:<disp-quote>
<p>We do not intend a reading of domain as content domain, in the folk sense of domains individuated by the meanings of their constituents. Rather, we define domains as individuated by the formal properties of representations because…this is the only possible means by which brain systems could select inputs. (<xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett &amp; Kurzban, 2006</xref>, p. 630)</p>
</disp-quote></p>
<p>Modules are thus domain-specific in that they engage in specialized processing of representations with particular formal properties.</p>
<sec id="section1-0959354311398703">
<title>EP and modularity</title>
<p>According to <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref>, the strict focus on formal properties enables them to support the massive modularity thesis. This is because all mechanisms have format requirements; no system can process <italic>all</italic> types of representations, regardless of their formal properties. As they say,<disp-quote>
<p>It might be true that there are domain-general mechanisms in the sense that the inputs some mechanisms take do not neatly fit intuitions of what constitutes a domain (e.g., the domain of all objects), but it is nevertheless false that these mechanisms have no formal input criteria. (p. 634)</p>
</disp-quote></p>
<p>In their view, even working memory, a mechanism that has been linked to general intelligence (e.g., <xref ref-type="bibr" rid="bibr15-0959354311398703">Engle, Tuholski, Laughlin, &amp; Conway, 1999</xref>), is domain-specific. The reason for this is because its storage mechanisms only hold information in certain representational formats. Surprisingly, even rules of logical inference, such as <italic>modus ponens</italic>, are domain-specific according to their proposal because they have “a restricted and clearly defined input domain: representations in the form of if-then statements” (<xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett &amp; Kurzban, 2006</xref>, p. 634).</p>
<p>We argue that in their eschewing of content from an analysis of modularity, <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> make a radical departure from the way the EP position has originally been outlined by its proponents. Much of the debate has centered on whether the mind possesses mechanisms designed to solve problems across a wide range of content domains (see, e.g., <xref ref-type="bibr" rid="bibr9-0959354311398703">Chiappe &amp; MacDonald, 2005</xref>; <xref ref-type="bibr" rid="bibr21-0959354311398703">Geary, 2005</xref>). The arguments for such domain-general mechanisms were advanced in response to claims made by evolutionary psychologists themselves. For example, <xref ref-type="bibr" rid="bibr42-0959354311398703">Tooby and Cosmides (1992)</xref> say, “A psychological architecture that consisted of nothing but…content-independent, or content-free mechanisms could not successfully perform the tasks the human mind is known to perform or solve the adaptive problems humans evolved to solve” (p. 34). They characterize their position as follows:<disp-quote>
<p>[H]uman psychological architecture contains many evolved mechanisms that are specialized for solving evolutionarily long-enduring adaptive problems and … these mechanisms have content-specialized representation formats, procedures, cues, and so on. These richly content-sensitive evolved mechanisms tend to impose certain types of content and conceptual organization on human mental life. (p. 34)</p>
</disp-quote></p>
<p>Similarly, they say,<disp-quote>
<p>Advocates of evolutionary views do not deny that humans learn, reason, develop, or acquire a culture; however, they do argue that these functions are accomplished at least in part through the operation of cognitive mechanisms that are content-specialized—mechanisms that are activated by particular content domains and that are designed to process information from those domains. (p. 166)</p>
</disp-quote></p>
<p>As these quotes show, the EP position clearly views content-specificity as an essential aspect of modularity.</p>
<p>It is therefore highly problematic given the original EP position to state that even the rules of logical inference count as domain-specific. In fact, it was precisely the rules of logic that were deemed domain-general by EP. This is clearly the case in discussions of social contract reasoning, where the content-independent rules of logic were rejected on a priori and empirical grounds as likely candidates for explaining how people reason (e.g., <xref ref-type="bibr" rid="bibr10-0959354311398703">Cosmides, 1989</xref>; <xref ref-type="bibr" rid="bibr24-0959354311398703">Gigerenzer &amp; Hug, 1992</xref>).</p>
<p>As we can see, EP advocates do not reject content as a mere “folk” notion, as <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> do. In fact, EP offers a proposal for how cognitive science can move beyond intuitions in identifying biologically relevant content domains. This is because understanding the evolutionary context of our species can help cognitive scientists generate computational theories (<xref ref-type="bibr" rid="bibr11-0959354311398703">Cosmides &amp; Tooby, 1994</xref>). These are <italic>semantic-level</italic> specifications of what problems a system is designed to solve, why it is designed to solve them, and what information is available in the environment to help it solve those problems. An example is provided by “social contract theory,” which holds that early hominids had to engage in social exchange to enhance survival and reproduction (<xref ref-type="bibr" rid="bibr11-0959354311398703">Cosmides &amp; Tooby, 1994</xref>). To do so, they had to be good at identifying cheaters. This is because social exchange is only adaptive in the presence of reciprocity. More specifically, the necessary elements required for social exchange include the ability to recognize members of a social group, to remember past interactions with them, to communicate needs among individuals in the group, and to adequately assess relative value of goods being exchanged.</p>
<p>While the computational level is an important level of analysis, EP advocates follow <xref ref-type="bibr" rid="bibr29-0959354311398703">Marr (1982)</xref> in claiming that there are two additional levels at which the mind has to be understood. These are the algorithmic level (i.e., the formal/syntactic mechanisms that compute the functions) and the physical implementation level (i.e., the brain mechanisms involved). Nonetheless, computational theories are useful because they can help to constrain the search for the formal mechanisms that are involved in carrying out the computations. As <xref ref-type="bibr" rid="bibr11-0959354311398703">Cosmides and Tooby (1994)</xref> say,<disp-quote>
<p>A theory of function may not determine a program’s structure uniquely, but it reduces the number of possibilities to an empirically manageable number. Task demands radically constrain the range of possible solutions; consequently, very few cognitive programs are capable of solving any given adaptive problem. By developing a careful task analysis of an information-processing problem, you can vastly simplify the empirical search for the cognitive program that solves it. And once that program has been identified, it becomes straightforward to develop clinical tests that will target its neural basis. (p. 46)</p>
</disp-quote></p>
<p>The foregoing also illustrates that EP advocates, while stressing the importance of content-specialized mechanisms, do not imply the brain directly computes over semantic properties, as <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> suggest. EP follows much of cognitive science in claiming that semantic properties have to be encoded in the syntactic features of representations for them to be capable of being processed by the brain. This is not a novel insight at all. It is the tradition in cognitive science to view the brain as a syntactic engine. For example, as <xref ref-type="bibr" rid="bibr2-0959354311398703">Block (1995)</xref> puts it, “[T]here is a correlation between the meanings of our internal representations and their forms. And this explains how it is that our syntactic engine can drive our semantic engine” (p. 398). Nonetheless, most cognitive scientists and evolutionary psychologists believe that the semantic/computational level of analysis cannot be eliminated, as it answers unique questions that are not answered by the syntactic or implementation level of analysis.</p>
<p>In short, <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban’s (2006)</xref> definition of modularity excludes a reference to content, which is out of step with the traditional EP approach and, we might add, with much of cognitive science. Furthermore, their move to define domain specificity in terms so broad they include working memory, the rules of logic, and so forth, yields a pyrrhic victory. Given their definition, it seems that all the processes discussed by traditional approaches to psychology are domain-specific. Consequently, none of these mechanisms can be ruled out on a priori grounds. However, an attractive feature of the original evolutionary approach, at least to its proponents, was that it deemed the existence of such mechanisms extremely unlikely. Indeed, if something is ruled out by the <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> approach, it certainly isn’t anything that has been taken seriously in psychology.</p>
</sec>
<sec id="section2-0959354311398703">
<title>Broad modularity and dual-process theories of reasoning</title>
<p>In the foregoing, we have argued that <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban’s (2006)</xref> conception of modularity is inconsistent with the traditional EP position. In what follows, we argue that the move to a broad notion of modularity that only focuses on functional specialization also has limited usefulness. <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> claim their account of modularity applies not just to “lower-level” aspects of cognition, such as face recognition, or emotion processing (labeled System 1 below), but also to mechanisms of “higher” cognition involved in reasoning and decision making (labeled System 2 below). We argue that their account fails to account for important distinctions that exist in these two kinds of cognitive processes.</p>
<sec id="section3-0959354311398703">
<title>System 1 and System 2 processes</title>
<p>Many cognitive scientists distinguish between two kinds of reasoning processes as a way of integrating the broad and diverse literature on human reasoning (e.g., <xref ref-type="bibr" rid="bibr17-0959354311398703">Evans, 1991</xref>; <xref ref-type="bibr" rid="bibr18-0959354311398703">Evans &amp; Over, 1996</xref>; <xref ref-type="bibr" rid="bibr36-0959354311398703">Sloman, 1996</xref>; <xref ref-type="bibr" rid="bibr39-0959354311398703">Stanovich, 1999</xref>). While the specific “dual-process” proposals differ in some respects, there are important similarities. We will follow <xref ref-type="bibr" rid="bibr39-0959354311398703">Stanovich (1999)</xref> and refer to these two types of computational processes using the generic labels “System 1” and “System 2.” System 1 consists of processes that are implicit in their operation, associative, fast, and not demanding of attentional resources. System 2 consists of processes that are explicit in their operation, deliberate, flexible, slow, and demanding of attentional resources.</p>
<p>According to Stanovich (<xref ref-type="bibr" rid="bibr39-0959354311398703">1999</xref>; <xref ref-type="bibr" rid="bibr40-0959354311398703">Stanovich &amp; West, 2000</xref>), an important difference between these two systems has to do with “contextualization.” In particular, System 1 contextualizes problems, while System 2 is used when decontextualization is important. Contextualization refers to the rapid and automatic activation of easily accessible background information about a domain. Contextualization comes from different sources, including expertise with a domain and natural selection. Expertise leads individuals to develop rich schemata that embody important information about a domain. This information can be rapidly activated by perceptual cues (<xref ref-type="bibr" rid="bibr16-0959354311398703">Ericsson &amp; Kintsch, 1995</xref>). For example, drawing on their expertise, chess players may be able to anticipate an opponent’s future move based on their perception of the current position of pieces. Natural selection can also enable us to quickly respond to situations by producing mechanisms that automatically activate pertinent representations and responses. For example, our emotion-recognition mechanisms respond to particular facial configurations by producing a representation of a person’s emotional state. Likewise, our fear module responds to the perception of a snake or spider by triggering a fear response (<xref ref-type="bibr" rid="bibr31-0959354311398703">Öhman &amp; Mineka, 2001</xref>).</p>
<p>In contrast, System 2 consists of “processes that often operate to strip excess content and context from representations generated by System 1” (<xref ref-type="bibr" rid="bibr39-0959354311398703">Stanovich, 1999</xref>, p. 193). One of the jobs of System 2 is to override the automatic and obligatory computations provided by System 1. While our individual experience and evolution may instill in us various reactions to stimuli, it is important at times to be able to prevent these reactions from influencing our behavior. This enables us to develop new and potentially more effective solutions to problems. For example, if a dominant person humiliates us publicly, System 1 processes may trigger the desire for revenge. Acting on this immediately, however, can cause us great harm. System 2 processes may therefore override this impulse and delay revenge until conditions are more auspicious. They can also be used to generate a suitable plan of action whereby revenge can be exacted.</p>
<p>The ability to decontextualize is closely connected to fluid intelligence (<italic>g</italic>F). Fluid intelligence refers to the ability to solve novel problems with minimal background knowledge. It is what we use when previous experiences do not enable us to solve a problem, except perhaps by analogy or induction. People who do well on one task involving decontextualization (e.g., abstract versions of Wason’s “selection task”) also tend to do well on other tasks requiring decontextualization (e.g., judging the strength of arguments for which one doesn’t agree with the conclusions), and they also tend to score high on general intelligence (<xref ref-type="bibr" rid="bibr39-0959354311398703">Stanovich, 1999</xref>). Measures of general intelligence, however, do not predict variability in performing System 1 operations. For example, performance on cheater-detection versions of the selection task is not predicted by measures of intelligence (<xref ref-type="bibr" rid="bibr39-0959354311398703">Stanovich, 1999</xref>; <xref ref-type="bibr" rid="bibr40-0959354311398703">Stanovich &amp; West, 2000</xref>).</p>
<p>In terms of psychological mechanisms, System 2 processes are carried out, at least in part, by the executive functions of working memory. These are involved in controlling attention and also inhibit potentially distracting representations and other pre-potent responses (<xref ref-type="bibr" rid="bibr15-0959354311398703">Engle et al., 1999</xref>; <xref ref-type="bibr" rid="bibr25-0959354311398703">Kane, Bleckley, Conway, &amp; Engle, 2001</xref>). They therefore play a crucial role in decontextualization. Furthermore, the executive functions have been linked to fluid intelligence (<xref ref-type="bibr" rid="bibr15-0959354311398703">Engle et al., 1999</xref>; <xref ref-type="bibr" rid="bibr30-0959354311398703">Öberauer, Schulze, Wilhelm, &amp; Süβ, 2005</xref>). <xref ref-type="bibr" rid="bibr15-0959354311398703">Engle et al. (1999)</xref>, for example, found that the variability in the executive functions predicted performance on tests of fluid intelligence, but variability in the storage functions of working memory did not.</p>
<p>The executive functions are also important for processes involved in creative problem solving, specifically metaphor and analogy (<xref ref-type="bibr" rid="bibr8-0959354311398703">Chiappe &amp; Chiappe, 2007</xref>; <xref ref-type="bibr" rid="bibr43-0959354311398703">Waltz, Lau, Grewal, &amp; Holyoak, 2000</xref>). Through analogical reasoning, we can find similarities between a present problem and past problems, allowing us to transfer successful solutions arrived at in the past to solve similar novel problems (<xref ref-type="bibr" rid="bibr23-0959354311398703">Gick &amp; Holyoak, 1980</xref>). Analogies require that the concepts and their properties be maintained in active state, while we search for abstract similarities between the domains. We also need to inhibit potentially distracting features of the two domains, features that can interfere with our ability to see relevant relational similarities underlying surface differences in attributes (<xref ref-type="bibr" rid="bibr22-0959354311398703">Gentner &amp; Holyoak, 1997</xref>). Analogy is thus a process involving considerable decontextualization, which explains why it is correlated with measures of general intelligence (e.g., <xref ref-type="bibr" rid="bibr41-0959354311398703">Sternberg, 1977</xref>) and working memory (<xref ref-type="bibr" rid="bibr43-0959354311398703">Waltz et al., 2000</xref>).</p>
<p>The case of metaphor and analogy also illustrates another important feature of System 2 processes: their dramatic ability to integrate information from quite disparate content domains (<xref ref-type="bibr" rid="bibr7-0959354311398703">Chiappe, 2000</xref>; <xref ref-type="bibr" rid="bibr8-0959354311398703">Chiappe &amp; Chiappe, 2007</xref>). In terms of information encapsulation, then, System 2 processes are relatively unencapsulated compared to System 1 processes. As <xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor (1983)</xref> says, “By definition, encapsulated mechanisms do not reason analogically” (p. 107). Put simply, people can compare and contrast any two concepts that they can explicitly represent. Many of the comparisons people <italic>can</italic> make are likely useless, such as if we decided to compare magazines to paper clips, or encyclopedias to exhaust pipes, and so on. Nevertheless, it certainly seems possible for us to do so. If so, the comparison process must be largely unencapsulated. More generally, processes like inductive inference and hypothesis generation seem to rely on mechanisms capable of integrating large amounts of information from distant domains.</p>
<p>According to <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref>, claims about such integrative abilities do not undermine the massive modularity thesis. To support their case they cite various examples of mechanisms widely regarded as being modular, which nonetheless are affected by contextual information. One such example is the McGurk effect, which shows that speech perception takes into account particular kinds of visual information. If a person is acoustically presented the syllable “Ba” and they watch a person mouthing the syllable “Ga,” what they perceive is the “Da” syllable. Similarly, visual illusions show how the size of an object can be perceived differently from one context to another. Therefore, according to <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref>, “the insistence on encapsulation, complete isolation from other systems, and insensitivity to contextual factors as criteria for modularity is misguided” (p. 633).</p>
<p>The problem is that <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> misrepresent the position of critics of massive modularity. No one denies that modules are able to do <italic>some</italic> integration of information. No one has advocated a position of “complete isolation” as a condition for modularity. Indeed, <xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor (1983)</xref> himself discussed such inter-modular communication, as in the case of the phonemic restoration effect, which shows that information from the lexicon can influence mechanisms of speech perception. The point, however, is that with certain reasoning processes, the integrative abilities are orders of magnitude greater than the examples of modular information integration <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> cite. As noted above, analogical reasoning and metaphor production have access to any concepts that can be explicitly represented, regardless of domain.</p>
<p>The difference in information integration between kinds of cognitive mechanisms is further illustrated by the fact that cognitive science has had much more success at producing theories of System 1 processes than System 2 processes (<xref ref-type="bibr" rid="bibr19-0959354311398703">Fodor, 1983</xref>, <xref ref-type="bibr" rid="bibr20-0959354311398703">2000</xref>). The difficulty in explaining the latter has to do precisely with formally specifying the information that can affect their operation. This, of course, is the frame problem in cognitive science—the problem of formalizing what information is relevant to a given computational process. As Fodor (<xref ref-type="bibr" rid="bibr19-0959354311398703">1983</xref>, <xref ref-type="bibr" rid="bibr20-0959354311398703">2000</xref>) points out, outbreaks of the frame problem are not universal. We only have them in explaining System 2 operations. Thus, <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> could not be less correct in claiming that “[t]his problem is probably best understood in perception” (p. 629). While it is true that “sense data have an infinite number of possible interpretations” (p. 629), it is also true that cognitive scientists have had considerable success at producing formal theories about the constraints that are involved in guiding the inferences made by perceptual systems. The same is not the case with such processes as analogical reasoning, decision making, and problem solving (for a discussion of the frame problem as it pertains to analogical reasoning, see <xref ref-type="bibr" rid="bibr6-0959354311398703">Chiappe, 1998</xref>). In these processes, the relevance of representations appears to be orders of magnitude more holistic and context-dependent.</p>
</sec>
<sec id="section4-0959354311398703">
<title>Does functional specialization explain System 1 and System 2 processes?</title>
<p><xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> could claim that System 2 processes rely on just another functionally specialized set of mechanisms. The processes involved in analogical reasoning, for example, can be seen as highly specialized for carrying out particular tasks (though, according to <xref ref-type="bibr" rid="bibr34-0959354311398703">Robin and Holyoak [1995]</xref>, it is a species of relational integration). After all, the structure-mapping processes involved in producing and comprehending analogies are quite different from, say, the processes involved in face recognition or speech perception. Analogical reasoning also has format requirements for information, such that the representations involved must be explicit, and must distinguish between attributes and relations (<xref ref-type="bibr" rid="bibr22-0959354311398703">Gentner &amp; Holyoak, 1997</xref>).</p>
<p>Nonetheless, <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban’s (2006)</xref> broad definition of modularity, while consistent with the existence of System 1 and System 2 processes, fails to explain why two such dramatically different kinds of cognitive processes exist. The reason is because claims about the need for functional specialization are too general. While they may provide some constraints on the kinds of cognitive processes that are likely to exist (though as we’ve seen, it isn’t clear that they rule out many of the mechanisms traditionally discussed by cognitive scientists), they don’t lead to the prediction that humans should have a dual-process type of architecture. Such an explanation requires appealing to more specific types of evolutionary factors.</p>
<p>The situation is analogous to trying to account for all evolutionary phenomena using general evolutionary theory (i.e., natural selection theory). While all biological phenomena are consistent with natural selection theory, many patterns exist in the biological world that can be explained only by appealing to more specific evolutionary theories. <xref ref-type="bibr" rid="bibr4-0959354311398703">Buss (2007)</xref>, for example, distinguishes between three levels of evolutionary analysis (see also <xref ref-type="bibr" rid="bibr27-0959354311398703">Ketelaar &amp; Ellis, 2000</xref>). At the top is general evolutionary theory, and at the next level there are various middle-level evolutionary theories. These include, among others, the theory of parental investment and the theory of reciprocal altruism. Parental investment theory, for example, is important for capturing important patterns in sex differences in mating behavior, ones that cannot simply be deduced from general evolutionary theory. Below the middle-level theories are numerous specific evolutionary hypotheses about how these middle-level theories apply to a given species (e.g., hypotheses about sex differences in jealousy). While the lower- and middle-level theories need to be consistent with general evolutionary theory, they are not entailed by it. In fact, lower-level hypotheses can be incorrect without invalidating theories at the higher levels.</p>
<p>In short, we need middle-level theories to elaborate how general evolutionary principles apply in particular aspects of the biological world. Likewise, we need to develop more specific explanations to account for the existence of System 1 and System 2 processes in the human mind.</p>
<p>On our view, System 1 and System 2 processes evolved to meet very different kinds of challenges (<xref ref-type="bibr" rid="bibr9-0959354311398703">Chiappe &amp; MacDonald, 2005</xref>; <xref ref-type="bibr" rid="bibr21-0959354311398703">Geary, 2005</xref>; <xref ref-type="bibr" rid="bibr26-0959354311398703">Kaplan, Hill, Lancaster, &amp; Hurtado, 2000</xref>).<sup><xref ref-type="fn" rid="fn1-0959354311398703">1</xref></sup> The mechanisms of System 1 are well suited for solving many longstanding adaptive problems, particularly when there are recurrent environmental cues that can be used in solving those problems. Many of the cases of modularity discussed by EP are best regarded as examples of System 1 processes. They are dedicated intelligences that process environmental information in highly specialized ways to produce adaptive responses (<xref ref-type="bibr" rid="bibr12-0959354311398703">Cosmides &amp; Tooby, 2002</xref>). For example, a longstanding problem our male ancestors faced is identifying fertile females. A cue that is correlated with female fertility is the waist-to-hip ratio (<xref ref-type="bibr" rid="bibr35-0959354311398703">Singh, 1993</xref>). As a result, mate-selection modules evolved to solve the problem of identifying fertile females by using this easily perceivable cue.</p>
<p>In contrast, System 2 processes are well suited for solving novel problems, and for developing new solutions to longstanding adaptive problems. For example, ancestral humans developed novel tool technologies (e.g., traps) as a way of expanding the range of food sources that could be acquired and processed. This ability became particularly prominent with modern humans, whose tool-making abilities surpassed those of Neanderthals, possibly owing to an enhancement of working memory functions (<xref ref-type="bibr" rid="bibr45-0959354311398703">Wynn &amp; Coolidge, 2003</xref>). Furthermore, in the modern world we have developed genetic testing as a way of helping males to solve problems posed by paternal uncertainty, a tool that certainly was not around through most of hominid evolution.</p>
<p>EP advocates, however, typically ignore novelty and instead characterize the evolutionary environment as consisting strictly of recurrent challenges and cues that can be exploited in dealing with them. As <xref ref-type="bibr" rid="bibr42-0959354311398703">Tooby and Cosmides (1992)</xref> say, “It is only those conditions that recur, statistically accumulating across many generations, that lead to the construction of complex adaptations. …For this reason, a major part of adaptationist analysis involves sifting for these environmental or organismic regularities or invariances” (p. 69). The evolutionary environment of humans, however, also consisted of novel challenges that had to be dealt with. The reason is that, as <xref ref-type="bibr" rid="bibr33-0959354311398703">Potts (1998)</xref> has argued, humans (and other mammals) were forced to adapt to inconsistent selection pressures owing to rapidly changing ecological conditions. Indeed, the geological record suggests environmental fluctuations became increasingly extreme during the Pleistocene, the geological era in which humans evolved. The climate was composed of many sudden shifts from cool–dry phases to warm–moist phases. These oscillations in climate led to substantial remodeling of the evolutionary environment. According to <xref ref-type="bibr" rid="bibr33-0959354311398703">Potts (1998)</xref>, “[S]hifts between dense, moist forest and cold dry steppe occurred repeatedly during the past 1 million years over large regions” (p. 83). The Pleistocene was therefore not a period of stasis, as evolutionary psychologists suggest. Rapid changes in ecological conditions forced humans to face considerable novel challenges in solving basic foraging problems, especially during the sudden cooling and drying phases, when food and water became scarce.</p>
<p>Rather than being evolutionarily irrelevant, the instability and inconsistency in selection pressures led to the evolution of mechanisms capable of responding to novelty. <xref ref-type="bibr" rid="bibr33-0959354311398703">Potts (1998)</xref> refers to the evolutionary process involved as “variability selection.” According to variability selection, “[L]arge environmental inconsistencies over time favor specific behavioral or anatomical complexes that are especially successful in novel settings and can help to buffer the inconsistencies” (<xref ref-type="bibr" rid="bibr33-0959354311398703">Potts, 1998</xref>, p. 90). In other words, when the environment presents consistent challenges, evolution favors highly specialized mechanisms—a process Potts refers to as “Darwinian selection.” As he says, “In the paradigm of Darwinian selection, the functional designs of a species reflect the stable and regular aspects of its environment” (<xref ref-type="bibr" rid="bibr32-0959354311398703">Potts, 1996</xref>, p. 232). However, when selection pressures change rapidly and in extreme directions within the lifetime of individuals, evolution favors mechanisms of “adaptive flexibility.” In these cases, organisms that are less specialized, and possessed of the ability to craft novel solutions to problems, are at a selective advantage. Of course, some organisms respond to extreme fluctuations by tracking a particular environment, as with migratory species. Other species, however, stay put and develop mechanisms capable of solving the problems posed by the extreme fluctuations in the environment. This appears to be what happened with our ancestors. As <xref ref-type="bibr" rid="bibr33-0959354311398703">Potts (1998)</xref> says, “Hominids became less inclined to track particular habitats as change occurred and more capable of adjusting to novel conditions and the increasing range of [climatic] oscillation” (p. 93). Indeed, an important trend in human evolution has been increased encephalization, and the largest increases in brain size coincide with the largest environmental oscillations (<xref ref-type="bibr" rid="bibr33-0959354311398703">Potts, 1998</xref>).</p>
<p>Owing to the process of variability selection, then, there was substantial pressure for the development of System 2 processes. These helped our ancestors in the attainment of evolutionary goals in unfamiliar, novel, or unpredictable conditions. In such situations, it would have been advantageous for them to engage in explicit information processing while they improvised a solution to a problem. For example, a hunter faced with conditions where meat or fish is only available seasonally may have to develop ways of storing and preserving food for those times of the year when the resource is not available. This involves considerable executive control. For example, tribes of the Pacific Northwest developed techniques for storing and preserving salmon so that it would be available throughout the year. As <xref ref-type="bibr" rid="bibr45-0959354311398703">Wynn and Coolidge (2003)</xref> say,<disp-quote>
<p>Storage, especially when combined with preservation, is clearly an executive function activity. One must suppress the natural [i.e., System 1] response to consume a food (or use it to gain immediate social advantage), and then, often, modify the food into a form that is less immediately desirable, all with the intent to consume or use it at a much later date. Response inhibition, response preparation, and integration of action across time are all necessary. (p. 4)</p>
</disp-quote></p>
<p>In a related vein, <xref ref-type="bibr" rid="bibr26-0959354311398703">Kaplan et al. (2000)</xref> argue that extreme intelligence, along with long lifespans, extended juvenile dependency, and male provisioning of offspring, is a trait that evolved as a response to a shift in diet toward the consumption of high-quality, but difficult to acquire, food resources. As they say, “Humans are specialists in that they consume only the highest-quality plant and animal resources in their local ecology and rely on creative, skill-intensive techniques to exploit them” (p. 156).</p>
<p><xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> fail to adequately deal with the challenges posed by novelty. The reason is because they attempt to deal with it using only the System 1 processes traditionally discussed by EP. Specifically, they try to reduce the problem of novelty to one that can be dealt with by relying on <xref ref-type="bibr" rid="bibr37-0959354311398703">Sperber’s (1994)</xref> distinction between the proper and actual domain of modules. The proper domain of a module is the set of inputs that a module evolved to process. The actual domain refers to stimuli that are similar in relevant respects to the proper domain of a module. They have similar formal properties that happen to satisfy the input criteria of a module. These can be novel stimuli—ones not present in the evolutionary environment. As <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> say, “[E]volved collision-avoidance systems could be recruited in driving, strategic social cognition systems could be recruited in chess, and systems evolved for identifying objects such as tools, or animals could be recruited to identify letters or words in reading” (p. 635).</p>
<p>There is no doubt that modules can receive novel stimuli as inputs. However, this does not eliminate the problem of novelty. For one, it doesn’t address the issue of how we invent novel solutions to longstanding problems. Provisioning for children in the modern world, for example, often requires carefully selecting between different investment plans and insurance policies, none of which were around in the ancestral environment. Furthermore, one cannot always rely on the lucky coincidence where a novel stimulus just happens to fit the input criteria of a module, and whose operation is going to produce a suitable response to that stimulus. In other words, sometimes we have to deal with novelty by engaging in <italic>problem solving</italic>. Sometimes we actually have to think about a problem and gain insight into it so that we can improvise a solution. We can’t rely on a prepared response produced by natural selection. This can require considerable effort and ingenuity. The sorts of processes involved are very different from the sorts of dedicated intelligences traditionally discussed by EP.</p>
</sec></sec>
<sec id="section5-0959354311398703" sec-type="conclusions">
<title>Conclusion</title>
<p>In conclusion, by defining modularity only in terms of functional specialization together with a strict focus on the formal features of representations, <xref ref-type="bibr" rid="bibr1-0959354311398703">Barrett and Kurzban (2006)</xref> are offering a position that is at odds in important respects with the EP position as traditionally defined. It is not the case that critics have wholly mischaracterized the sense of modularity that underlies EP, as Barrett and Kurzban charge. Furthermore, the broad definition of modularity does not allow us to explain why System 1 and System 2 processes exist. We argue that the former arise owing to recurrent features of the evolutionary environment, while the latter arise in response to inconsistent selection pressures, ones that put a premium on being able to solve novel challenges. Furthermore, Barrett and Kurzban do not offer an adequate account of the mechanisms that enable humans to deal with novelty, to whatever extent they are capable of doing so. Dealing with novelty requires that the mechanisms of creativity and problem solving traditionally discussed by cognitive psychologists be brought into the evolutionary fold.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0959354311398703">
<label>1.</label>
<p>An alternative perspective on the evolution of intelligence is provided by the Machiavellian Intelligence hypothesis. On this view, mechanisms of intelligence evolved to facilitate competition in complex social hierarchies. Mechanisms such as working memory evolved to solve problems posed by social living. For a critical discussion of this hypothesis, see <xref ref-type="bibr" rid="bibr44-0959354311398703">Whiten and Byrne (1997)</xref>.</p>
</fn>
</fn-group>
</notes>
<bio>
<p>Dan Chiappe is Professor of Psychology at California State University, Long Beach. His research interests are in the theoretical foundations of evolutionary psychology and cognitive science. Address: Department of Psychology, California State University, Long Beach, 1250 Bellflower Blvd., Long Beach, CA 90840, USA. [email: <email>dan.chiappe@csulb.edu</email>]</p>
<p>Ricca Gardner recently obtained her Masters in Psychology at California State University, Long Beach. Her research interests are in avian neurobiology and memory processes. Address: Department of Psychology, California State University, Long Beach, 1250 Bellflower Blvd., Long Beach, CA 90840, USA. [email: <email>riccadgardner@yahoo.com</email>]</p>
</bio>
<ref-list>
<title>References</title>
<ref id="bibr1-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barrett</surname><given-names>H.C.</given-names></name>
<name><surname>Kurzban</surname><given-names>R.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Modularity in cognition: Framing the debate</article-title>. <source>Psychological Review</source>, <volume>113</volume>, <fpage>628</fpage>–<lpage>647</lpage>.</citation>
</ref>
<ref id="bibr2-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Block</surname><given-names>N.</given-names></name>
</person-group> (<year>1995</year>). <article-title>The mind as the software of the brain</article-title>. In <person-group person-group-type="editor">
<name><surname>Smith</surname><given-names>E.</given-names></name>
<name><surname>Osherton</surname><given-names>D.</given-names></name>
</person-group> (Eds.), <source>An invitation to cognitive science</source> (<edition>2nd ed.</edition>, pp. <fpage>377</fpage>–<lpage>425</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr3-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Buller</surname><given-names>D.</given-names></name>
</person-group> (<year>2005</year>). <source>Adapting minds: Evolutionary psychology and the persistent quest for human nature</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr4-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Buss</surname><given-names>D.</given-names></name>
</person-group> (<year>2007</year>). <source>Evolutionary psychology: The new science of the mind</source> (<edition>3rd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Allyn &amp; Bacon</publisher-name>.</citation>
</ref>
<ref id="bibr5-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Caporael</surname><given-names>L.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Evolutionary psychology: Toward a unifying theory and a hybrid science</article-title>. <source>Annual Review of Psychology</source>, <volume>52</volume>, <fpage>607</fpage>–<lpage>628</lpage>.</citation>
</ref>
<ref id="bibr6-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chiappe</surname><given-names>D.L.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Similarity, relevance, and the comparison process</article-title>. <source>Metaphor and Symbol</source>, <volume>13</volume>, <fpage>17</fpage>–<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr7-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chiappe</surname><given-names>D.L.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Metaphor, modularity, and the evolution of conceptual integration</article-title>. <source>Metaphor and Symbol</source>, <volume>15</volume>, <fpage>137</fpage>–<lpage>158</lpage>.</citation>
</ref>
<ref id="bibr8-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chiappe</surname><given-names>D.L.</given-names></name>
<name><surname>Chiappe</surname><given-names>P.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The role of working memory in metaphor production and comprehension</article-title>. <source>Journal of Memory and Language</source>, <volume>56</volume>, <fpage>172</fpage>–<lpage>188</lpage>.</citation>
</ref>
<ref id="bibr9-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chiappe</surname><given-names>D.L.</given-names></name>
<name><surname>MacDonald</surname><given-names>K.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The evolution of domain-general mechanisms in intelligence and learning</article-title>. <source>Journal of General Psychology</source>, <volume>132</volume>, <fpage>5</fpage>–<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr10-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cosmides</surname><given-names>L.</given-names></name>
</person-group> (<year>1989</year>). <article-title>The logic of social exchange: Has natural selection shaped how humans reason? Studies with the Wason selection task</article-title>. <source>Cognition</source>, <volume>31</volume>, <fpage>187</fpage>–<lpage>276</lpage>.</citation>
</ref>
<ref id="bibr11-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cosmides</surname><given-names>L.</given-names></name>
<name><surname>Tooby</surname><given-names>J.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Beyond intuition and instinct blindness: Toward an evolutionarily rigorous cognitive science</article-title>. <source>Cognition</source>, <volume>50</volume>, <fpage>41</fpage>–<lpage>77</lpage>.</citation>
</ref>
<ref id="bibr12-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cosmides</surname><given-names>L.</given-names></name>
<name><surname>Tooby</surname><given-names>J.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Unraveling the enigma of human intelligence: Evolutionary psychology and the multimodular mind</article-title>. In <person-group person-group-type="editor">
<name><surname>Sternberg</surname><given-names>R.J.</given-names></name>
<name><surname>Kaufman</surname><given-names>J.C.</given-names></name>
</person-group> (Eds.), <source>The evolution of intelligence</source> (pp. <fpage>145</fpage>–<lpage>198</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr13-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Derksen</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Against integration. Why evolution cannot unify the social sciences</article-title>. <source>Theory &amp; Psychology</source>, <volume>15</volume>, <fpage>139</fpage>–<lpage>162</lpage>.</citation>
</ref>
<ref id="bibr14-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Derksen</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Realism, relativism, and evolutionary psychology</article-title>. <source>Theory &amp; Psychology</source>, <volume>20</volume>, <fpage>467</fpage>–<lpage>487</lpage>.</citation>
</ref>
<ref id="bibr15-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Engle</surname><given-names>R.</given-names></name>
<name><surname>Tuholski</surname><given-names>S.W.</given-names></name>
<name><surname>Laughlin</surname><given-names>J.E.</given-names></name>
<name><surname>Conway</surname><given-names>A.R.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Working memory, short-term memory, and general fluid intelligence: A latent-variable approach</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>128</volume>, <fpage>309</fpage>–<lpage>331</lpage>.</citation>
</ref>
<ref id="bibr16-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ericsson</surname><given-names>K.A.</given-names></name>
<name><surname>Kintsch</surname><given-names>W.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Long-term working memory</article-title>. <source>Psychological Review</source>, <volume>102</volume>, <fpage>211</fpage>–<lpage>245</lpage>.</citation>
</ref>
<ref id="bibr17-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Evans</surname><given-names>J.S.B.T.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Theories of human reasoning: The fragmented state of the art</article-title>. <source>Theory &amp; Psychology</source>, <volume>1</volume>, <fpage>83</fpage>–<lpage>105</lpage>.</citation>
</ref>
<ref id="bibr18-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Evans</surname><given-names>J.S.B.T.</given-names></name>
<name><surname>Over</surname><given-names>D.E.</given-names></name>
</person-group> (<year>1996</year>). <source>Rationality and reasoning</source>. <publisher-loc>Hove, UK</publisher-loc>: <publisher-name>Psychology Press</publisher-name>.</citation>
</ref>
<ref id="bibr19-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fodor</surname><given-names>J.A.</given-names></name>
</person-group> (<year>1983</year>). <source>The modularity of mind</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr20-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Fodor</surname><given-names>J.A.</given-names></name>
</person-group> (<year>2000</year>). <source>The mind doesn’t work that way</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr21-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Geary</surname><given-names>D.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The origin of mind: Evolution of brain, cognition, and general intelligence</article-title>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>.</citation>
</ref>
<ref id="bibr22-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gentner</surname><given-names>D.</given-names></name>
<name><surname>Holyoak</surname><given-names>K.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Reasoning and learning by analogy</article-title>. <source>American Psychologist</source>, <volume>52</volume>, <fpage>32</fpage>–<lpage>34</lpage>.</citation>
</ref>
<ref id="bibr23-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gick</surname><given-names>M.L.</given-names></name>
<name><surname>Holyoak</surname><given-names>K.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Analogical problem solving</article-title>. <source>Cognitive Psychology</source>, <volume>12</volume>, <fpage>306</fpage>–<lpage>355</lpage>.</citation>
</ref>
<ref id="bibr24-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gigerenzer</surname><given-names>G.</given-names></name>
<name><surname>Hug</surname><given-names>K.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Domain-specific reasoning: Social contracts, cheating, and perspective change</article-title>. <source>Cognition</source>, <volume>43</volume>, <fpage>127</fpage>–<lpage>171</lpage>.</citation>
</ref>
<ref id="bibr25-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kane</surname><given-names>M.J.</given-names></name>
<name><surname>Bleckley</surname><given-names>M.K.</given-names></name>
<name><surname>Conway</surname><given-names>A.R.</given-names></name>
<name><surname>Engle</surname><given-names>R.</given-names></name>
</person-group> (<year>2001</year>). <article-title>A controlled-attention view of working memory capacity</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>130</volume>, <fpage>169</fpage>–<lpage>183</lpage>.</citation>
</ref>
<ref id="bibr26-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kaplan</surname><given-names>H.</given-names></name>
<name><surname>Hill</surname><given-names>K.</given-names></name>
<name><surname>Lancaster</surname><given-names>J.</given-names></name>
<name><surname>Hurtado</surname><given-names>M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>A theory of human life history evolution: Diet, intelligence, and longevity</article-title>. <source>Evolutionary Anthropology</source>, <volume>9</volume>, <fpage>156</fpage>–<lpage>185</lpage>.</citation>
</ref>
<ref id="bibr27-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ketelaar</surname><given-names>T.</given-names></name>
<name><surname>Ellis</surname><given-names>B.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Are evolutionary explanations unfalsifiable? Evolutionary psychology and the Lakatosian philosophy of science</article-title>. <source>Psychological Inquiry</source>, <volume>11</volume>, <fpage>1</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr28-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kukla</surname><given-names>A.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Unification as a goal for psychology</article-title>. <source>American Psychologist</source>, <volume>47</volume>, <fpage>1054</fpage>–<lpage>1055</lpage>.</citation>
</ref>
<ref id="bibr29-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Marr</surname><given-names>D.</given-names></name>
</person-group> (<year>1982</year>). <source>Vision</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>W.H. Freeman</publisher-name>.</citation>
</ref>
<ref id="bibr30-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Öberauer</surname><given-names>K.</given-names></name>
<name><surname>Schulze</surname><given-names>R.</given-names></name>
<name><surname>Wilhelm</surname><given-names>O.</given-names></name>
<name><surname>Süβ</surname><given-names>H.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Working memory and intelligence—Their correlation and their relation: Comment on Ackerman, Beier, and Boyle</article-title>. <source>Psychological Bulletin</source>, <volume>131</volume>, <fpage>61</fpage>–<lpage>65</lpage>.</citation>
</ref>
<ref id="bibr31-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Öhman</surname><given-names>A.</given-names></name>
<name><surname>Mineka</surname><given-names>S.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Fears, phobias, and preparedness: Toward an evolved module of fear and fear learning</article-title>. <source>Psychological Review</source>, <volume>108</volume>, <fpage>483</fpage>–<lpage>522</lpage>.</citation>
</ref>
<ref id="bibr32-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Potts</surname><given-names>R.</given-names></name>
</person-group> (<year>1996</year>). <source>Humanity’s descent: The consequences of ecological instability</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Avon Books</publisher-name>.</citation>
</ref>
<ref id="bibr33-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Potts</surname><given-names>R.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Variability selection in hominid evolution</article-title>. <source>Evolutionary Anthropology</source>, <volume>7</volume>, <fpage>81</fpage>–<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr34-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Robin</surname><given-names>N.</given-names></name>
<name><surname>Holyoak</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Relational complexity and the functions of prefrontal cortex</article-title>. In <person-group person-group-type="editor">
<name><surname>Gazzaniga</surname><given-names>M.S.</given-names></name>
</person-group> (Ed.), <source>The cognitive neurosciences</source> (pp. <fpage>987</fpage>–<lpage>997</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</citation>
</ref>
<ref id="bibr35-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Singh</surname><given-names>D.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Adaptive significance of female attractiveness: Role of waist-to-hip ratio</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>65</volume>, <fpage>293</fpage>–<lpage>307</lpage>.</citation>
</ref>
<ref id="bibr36-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sloman</surname><given-names>S.A.</given-names></name>
</person-group> (<year>1996</year>). <article-title>The empirical case for two systems of reasoning</article-title>. <source>Psychological Bulletin</source>, <volume>119</volume>, <fpage>3</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr37-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sperber</surname><given-names>D.</given-names></name>
</person-group> (<year>1994</year>). <article-title>The modularity of thought and the epidemiology of representations</article-title>. In <person-group person-group-type="editor">
<name><surname>Hirschfeld</surname><given-names>L.A.</given-names></name>
<name><surname>Gelman</surname><given-names>S.</given-names></name>
</person-group> (Eds.), <source>Mapping the mind: Domain-specificity in cognition and culture</source> (pp. <fpage>39</fpage>–<lpage>67</lpage>). <publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr38-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Staats</surname><given-names>A.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Unified positivism and unification psychology: Fad or new field?</article-title> <source>American Psychologist</source>, <volume>46</volume>, <fpage>899</fpage>–<lpage>912</lpage>.</citation>
</ref>
<ref id="bibr39-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stanovich</surname><given-names>K.E.</given-names></name>
</person-group> (<year>1999</year>). <source>Who is rational?</source> <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr40-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stanovich</surname><given-names>K.E.</given-names></name>
<name><surname>West</surname><given-names>R.F.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Individual differences in reasoning: Implications for the rationality debate</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>23</volume>, <fpage>645</fpage>–<lpage>665</lpage>.</citation>
</ref>
<ref id="bibr41-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sternberg</surname><given-names>R.</given-names></name>
</person-group> (<year>1977</year>). <source>Intelligence, information processing, and analogical reasoning: A componential analysis of human abilities</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr42-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tooby</surname><given-names>J.</given-names></name>
<name><surname>Cosmides</surname><given-names>L.</given-names></name>
</person-group> (<year>1992</year>). <article-title>The psychological foundations of culture</article-title>. In <person-group person-group-type="editor">
<name><surname>Barkow</surname><given-names>J.</given-names></name>
<name><surname>Cosmides</surname><given-names>L.</given-names></name>
<name><surname>Tooby</surname><given-names>J.</given-names></name>
</person-group> (Eds.), <source>The adapted mind: Evolutionary psychology and the generation of culture</source> (pp. <fpage>19</fpage>–<lpage>136</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr43-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Waltz</surname><given-names>J.</given-names></name>
<name><surname>Lau</surname><given-names>A.</given-names></name>
<name><surname>Grewal</surname><given-names>S.</given-names></name>
<name><surname>Holyoak</surname><given-names>K.</given-names></name>
</person-group> (<year>2000</year>). <article-title>The role of working memory in analogical mapping</article-title>. <source>Memory &amp; Cognition</source>, <volume>28</volume>, <fpage>1205</fpage>–<lpage>1212</lpage>.</citation>
</ref>
<ref id="bibr44-0959354311398703">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Whiten</surname><given-names>A.</given-names></name>
<name><surname>Byrne</surname><given-names>R.</given-names></name>
</person-group> (<year>1997</year>). <source>Machiavellian Intelligence II: Extensions and evaluations</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr45-0959354311398703">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wynn</surname><given-names>T.</given-names></name>
<name><surname>Coolidge</surname><given-names>F.</given-names></name>
</person-group> (<year>2003</year>). <article-title>The role of working memory in the evolution of managed foraging</article-title>. <source>Before Farming</source>, <volume>2</volume>, <fpage>1</fpage>–<lpage>16</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>