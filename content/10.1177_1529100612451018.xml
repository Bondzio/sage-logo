<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PSI</journal-id>
<journal-id journal-id-type="hwp">sppsi</journal-id>
<journal-title>Psychological Science in the Public Interest</journal-title>
<issn pub-type="ppub">1529-1006</issn>
<issn pub-type="epub">1539-6053</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1529100612451018</article-id>
<article-id pub-id-type="publisher-id">10.1177_1529100612451018</article-id>
<title-group>
<article-title>Misinformation and Its Correction</article-title>
<subtitle>Continued Influence and Successful Debiasing</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Lewandowsky</surname><given-names>Stephan</given-names></name>
<xref ref-type="aff" rid="aff1-1529100612451018">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Ecker</surname><given-names>Ullrich K. H.</given-names></name>
<xref ref-type="aff" rid="aff1-1529100612451018">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Seifert</surname><given-names>Colleen M.</given-names></name>
<xref ref-type="aff" rid="aff2-1529100612451018">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Schwarz</surname><given-names>Norbert</given-names></name>
<xref ref-type="aff" rid="aff2-1529100612451018">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Cook</surname><given-names>John</given-names></name>
<xref ref-type="aff" rid="aff1-1529100612451018">1</xref>
<xref ref-type="aff" rid="aff3-1529100612451018">3</xref>
</contrib>
</contrib-group>
<aff id="aff1-1529100612451018"><label>1</label>University of Western Australia</aff>
<aff id="aff2-1529100612451018"><label>2</label>University of Michigan</aff>
<aff id="aff3-1529100612451018"><label>3</label>University of Queensland</aff>
<author-notes>
<corresp id="corresp1-1529100612451018">Stephan Lewandowsky, School of Psychology, University of Western Australia, Crawley, Western Australia 6009, Australia E-mail: <email>stephan.lewandowsky@uwa.edu.au</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>12</month>
<year>2012</year>
</pub-date>
<volume>13</volume>
<issue>3</issue>
<fpage>106</fpage>
<lpage>131</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">Association for Psychological Science</copyright-holder>
</permissions>
<abstract>
<p>The widespread prevalence and persistence of misinformation in contemporary societies, such as the false belief that there is a link between childhood vaccinations and autism, is a matter of public concern. For example, the myths surrounding vaccinations, which prompted some parents to withhold immunization from their children, have led to a marked increase in vaccine-preventable disease, as well as unnecessary public expenditure on research and public-information campaigns aimed at rectifying the situation.</p>
<p>We first examine the mechanisms by which such misinformation is disseminated in society, both inadvertently and purposely. Misinformation can originate from rumors but also from works of fiction, governments and politicians, and vested interests. Moreover, changes in the media landscape, including the arrival of the Internet, have fundamentally influenced the ways in which information is communicated and misinformation is spread.</p>
<p>We next move to misinformation at the level of the individual, and review the cognitive factors that often render misinformation resistant to correction. We consider how people assess the truth of statements and what makes people believe certain things but not others. We look at people’s memory for misinformation and answer the questions of why retractions of misinformation are so ineffective in memory updating and why efforts to retract misinformation can even backfire and, ironically, increase misbelief. Though ideology and personal worldviews can be major obstacles for debiasing, there nonetheless are a number of effective techniques for reducing the impact of misinformation, and we pay special attention to these factors that aid in debiasing.</p>
<p>We conclude by providing specific recommendations for the debunking of misinformation. These recommendations pertain to the ways in which corrections should be designed, structured, and applied in order to maximize their impact. Grounded in cognitive psychological theory, these recommendations may help practitioners—including journalists, health professionals, educators, and science communicators—design effective misinformation retractions, educational tools, and public-information campaigns.</p>
</abstract>
<kwd-group>
<kwd>misinformation</kwd>
<kwd>false beliefs</kwd>
<kwd>memory updating</kwd>
<kwd>debiasing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>On August 4, 1961, a young woman gave birth to a healthy baby boy in a hospital at 1611 Bingham St., Honolulu. That child, Barack Obama, later became the 44th president of the United States. Notwithstanding the incontrovertible evidence for the simple fact of his American birth—from a Hawaiian birth certificate to birth announcements in local papers to the fact that his pregnant mother went into the Honolulu hospital and left it cradling a baby—a group known as “birthers” claimed Obama had been born outside the United States and was therefore not eligible to assume the presidency. Even though the claims were met with skepticism by the media, polls at the time showed that they were widely believed by a sizable proportion of the public (<xref ref-type="bibr" rid="bibr203-1529100612451018">Travis, 2010</xref>), including a majority of voters in Republican primary elections in 2011 (<xref ref-type="bibr" rid="bibr9-1529100612451018">Barr, 2011</xref>).</p>
<p>In the United Kingdom, a 1998 study suggesting a link between a common childhood vaccine and autism generated considerable fear in the general public concerning the safety of the vaccine. The UK Department of Health and several other health organizations immediately pointed to the lack of evidence for such claims and urged parents not to reject the vaccine. The media subsequently widely reported that none of the original claims had been substantiated. Nonetheless, in 2002, between 20% and 25% of the public continued to believe in the vaccine-autism link, and a further 39% to 53% continued to believe there was equal evidence on both sides of the debate (<xref ref-type="bibr" rid="bibr70-1529100612451018">Hargreaves, Lewis, &amp; Speers, 2003</xref>). More worryingly still, a substantial number of health professionals continued to believe the unsubstantiated claims (<xref ref-type="bibr" rid="bibr157-1529100612451018">Petrovic, Roberts, &amp; Ramsay, 2001</xref>). Ultimately, it emerged that the first author of the study had failed to disclose a significant conflict of interest; thereafter, most of the coauthors distanced themselves from the study, the journal officially retracted the article, and the first author was eventually found guilty of misconduct and lost his license to practice medicine (<xref ref-type="bibr" rid="bibr33-1529100612451018">Colgrove &amp; Bayer, 2005</xref>; <xref ref-type="bibr" rid="bibr107-1529100612451018">Larson, Cooper, Eskola, Katz, &amp; Ratzan, 2011</xref>).</p>
<p>Another particularly well-documented case of the persistence of mistaken beliefs despite extensive corrective efforts involves the decades-long deceptive advertising for Listerine mouthwash in the U.S. Advertisements for Listerine had falsely claimed for more than 50 years that the product helped prevent or reduce the severity of colds and sore throats. After a long legal battle, the U.S. Federal Trade Commission mandated corrective advertising that explicitly withdrew the deceptive claims. For 16 months between 1978 and 1980, the company ran an ad campaign in which the cold-related claims were retracted in 5-second disclosures midway through 30-second TV spots. Notwithstanding a $10 million budget, the campaign was only moderately successful (<xref ref-type="bibr" rid="bibr211-1529100612451018">Wilkie, McNeill, &amp; Mazis, 1984</xref>). Using a cross-sectional comparison of nationally representative samples at various points during the corrective campaign, a telephone survey by <xref ref-type="bibr" rid="bibr5-1529100612451018">Armstrong, Gural, and Russ (1983)</xref> did reveal a significant reduction in consumers’ belief that Listerine could alleviate colds, but overall levels of acceptance of the false claim remained high. For example, 42% of Listerine users continued to believe that the product was still promoted as an effective cold remedy, and more than half (57%) reported that the product’s presumed medicinal effects were a key factor in their purchasing decision (compared with 15% of consumers of a competing product).</p>
<p>Those results underscore the difficulties of correcting widespread belief in misinformation. These difficulties arise from two distinct factors. First, there are cognitive variables within each person that render misinformation “sticky.” We focus primarily on those variables in this article. The second factor is purely pragmatic, and it relates to the ability to reach the target audience. The real-life Listerine quasi-experiment is particularly informative in this regard, because its effectiveness was limited even though the company had a fairly large budget for disseminating corrective information.</p>
<p>What causes the persistence of erroneous beliefs in sizable segments of the population? Assuming corrective information has been received, why does misinformation<sup><xref ref-type="fn" rid="fn1-1529100612451018">1</xref></sup> continue to influence people’s thinking despite clear retractions? The literature on these issues is extensive and complex, but it permits several reasonably clear conclusions, which we present in the remainder of this article. Psychological science has much light to shed onto the cognitive processes with which individuals process, acquire, and update information.</p>
<p>We focus primarily on individual-level cognitive processes as they relate to misinformation. However, a discussion of the continued influence of misinformation cannot be complete without addressing the societal mechanisms that give rise to the persistence of false beliefs in large segments of the population. Understanding why one might reject evidence about President Obama’s place of birth is a matter of individual cognition; however, understanding why more than half of Republican primary voters expressed doubt about the president’s birthplace (<xref ref-type="bibr" rid="bibr9-1529100612451018">Barr, 2011</xref>) requires a consideration of not only why individuals cling to misinformation, but also how information—especially false information—is disseminated through society. We therefore begin our analysis at the societal level, first by highlighting the societal costs of widespread misinformation, and then by turning to the societal processes that permit its spread.</p>
<sec id="section1-1529100612451018">
<title>The Societal Cost of Misinformation</title>
<p>It is a truism that a functioning democracy relies on an educated and well-informed populace (<xref ref-type="bibr" rid="bibr102-1529100612451018">Kuklinski, Quirk, Jerit, Schwieder, &amp; Rich, 2000</xref>). The processes by which people form their opinions and beliefs are therefore of obvious public interest, particularly if major streams of beliefs persist that are in opposition to established facts. If a majority believes in something that is factually incorrect, the misinformation may form the basis for political and societal decisions that run counter to a society’s best interest; if individuals are misinformed, they may likewise make decisions for themselves and their families that are not in their best interest and can have serious consequences. For example, following the unsubstantiated claims of a vaccination-autism link, many parents decided not to immunize their children, which has had dire consequences for both individuals and societies, including a marked increase in vaccine-preventable disease and hence preventable hospitalizations, deaths, and the unnecessary expenditure of large amounts of money for follow-up research and public-information campaigns aimed at rectifying the situation (<xref ref-type="bibr" rid="bibr107-1529100612451018">Larson et al., 2011</xref>; <xref ref-type="bibr" rid="bibr164-1529100612451018">Poland &amp; Spier, 2010</xref>; <xref ref-type="bibr" rid="bibr173-1529100612451018">Ratzan, 2010</xref>).</p>
<p>Reliance on misinformation differs from ignorance, which we define as the <italic>absence</italic> of relevant knowledge. Ignorance, too, can have obvious detrimental effects on decision making, but, perhaps surprisingly, those effects may be less severe than those arising from reliance on misinformation. Ignorance may be a lesser evil because in the self-acknowledged absence of knowledge, people often turn to simple heuristics when making decisions. Those heuristics, in turn, can work surprisingly well, at least under favorable conditions. For example, mere familiarity with an object often permits people to make accurate guesses about it (<xref ref-type="bibr" rid="bibr63-1529100612451018">Goldstein &amp; Gigerenzer, 2002</xref>; <xref ref-type="bibr" rid="bibr137-1529100612451018">Newell &amp; Fernandez, 2006</xref>). Moreover, people typically have relatively low levels of confidence in decisions made solely on the basis of such heuristics (<xref ref-type="bibr" rid="bibr37-1529100612451018">De Neys, Cromheeke, &amp; Osman, 2011</xref>; <xref ref-type="bibr" rid="bibr62-1529100612451018">Glöckner &amp; Bröder, 2011</xref>). In other words, ignorance rarely leads to strong support for a cause, in contrast to false beliefs based on misinformation, which are often held strongly and with (perhaps infectious) conviction. For example, those who most vigorously reject the scientific evidence for climate change are also those who believe they are best informed about the subject (<xref ref-type="bibr" rid="bibr109-1529100612451018">Leiserowitz, Maibach, Roser-Renouf, &amp; Hmielowski, 2011</xref>).</p>
<p>The costs of misinformation to society are thus difficult to ignore, and its widespread persistence calls for an analysis of its origins.</p>
</sec>
<sec id="section2-1529100612451018">
<title>Origins of Misinformation</title>
<p>Misinformation can be disseminated in a number of ways, often in the absence of any intent to mislead. For example, the timely news coverage of unfolding events is by its very nature piecemeal and requires occasional corrections of earlier statements. As a case in point, the death toll after a major natural disaster—such as the 2011 tsunami in Japan—is necessarily updated until a final estimate becomes available. Similarly, a piece of information that is considered “correct” at any given stage can later turn out to have been erroneous.</p>
<p>Indeed, this piecemeal approach to knowledge construction is the very essence of the scientific process, through which isolated initial findings are sometimes refuted or found not to be replicable. It is for this reason that scientific conclusions are usually made and accepted only after some form of consensus has been reached on the basis of multiple lines of converging evidence. Misinformation that arises during an evolving event or during the updating of knowledge is unavoidable as well as unintentional; however, there are other sources of misinformation that are arguably less benign. The particular sources we discuss in this article are:</p>
<list id="list1-1529100612451018" list-type="bullet">
<list-item><p>Rumors and fiction. Societies have struggled with the misinformation-spreading effects of rumors for centuries, if not millennia; what is perhaps less obvious is that even works of fiction can give rise to lasting misconceptions of the facts.</p></list-item>
<list-item><p>Governments and politicians. Governments and politicians can be powerful sources of misinformation, whether inadvertently or by design.</p></list-item>
<list-item><p>Vested interests. Corporate interests have a long and well-documented history of seeking to influence public debate by promulgating incorrect information. At least on some recent occasions, such systematic campaigns have also been directed <italic>against</italic> corporate interests, by nongovernmental interest groups.</p></list-item>
<list-item><p>The media. Though the media are by definition seeking to inform the public, it is notable that they are particularly prone to spreading misinformation for systemic reasons that are worthy of analysis and exposure. With regard to new media, the Internet has placed immense quantities of information at our fingertips, but it has also contributed to the spread of misinformation. The growing use of social networks may foster the quick and wide dissemination of misinformation. The fractionation of the information landscape by new media is an important contributor to misinformation’s particular resilience to correction.</p></list-item></list>
<p>We next consider each of these sources in turn.</p>
<sec id="section3-1529100612451018">
<title>Rumors and fiction</title>
<p>Rumors and urban myths constitute important sources of misinformation. For example, in 2006, a majority of Democrats believed that the George W. Bush administration either assisted in the 9/11 terror attacks or took no action to stop them (<xref ref-type="bibr" rid="bibr139-1529100612451018">Nyhan, 2010</xref>). This widespread belief is all the more remarkable because the conspiracy theory found virtually no traction in the mainstream media.</p>
<p>Human culture strongly depends on people passing on information. Although the believability of information has been identified as a factor determining whether it is propagated (<xref ref-type="bibr" rid="bibr36-1529100612451018">Cotter, 2008</xref>), people seem to mainly pass on information that will evoke an emotional response in the recipient, irrespective of the information’s truth value. Emotional arousal in general increases people’s willingness to pass on information (<xref ref-type="bibr" rid="bibr16-1529100612451018">Berger, 2011</xref>). Thus, stories containing content likely to evoke disgust, fear, or happiness are spread more readily from person to person and more widely through social media than are neutral stories (<xref ref-type="bibr" rid="bibr36-1529100612451018">Cotter, 2008</xref>; <xref ref-type="bibr" rid="bibr74-1529100612451018">Heath, Bell, &amp; Sternberg, 2001</xref>; <xref ref-type="bibr" rid="bibr156-1529100612451018">K. Peters, Kashima, &amp; Clark, 2009</xref>). Accordingly, the most effective “misinformers” about vaccines are parents who truly believe that their child has been injured by a vaccine. When such individuals present their mistaken beliefs as fact, their claims may be discussed on popular TV and radio talk shows and made the subject of TV dramas and docudramas (<xref ref-type="bibr" rid="bibr136-1529100612451018">Myers &amp; Pineda, 2009</xref>).</p>
<p>A related but perhaps more surprising source of misinformation is literary fiction. People extract knowledge even from sources that are explicitly identified as fictional. This process is often adaptive, because fiction frequently contains valid information about the world. For example, non-Americans’ knowledge of U.S. traditions, sports, climate, and geography partly stems from movies and novels, and many Americans know from movies that Britain and Australia have left-hand traffic. By definition, however, fiction writers are not obliged to stick to the facts, which creates an avenue for the spread of misinformation, even by stories that are explicitly identified as fictional. A study by <xref ref-type="bibr" rid="bibr121-1529100612451018">Marsh, Meade, and Roediger (2003)</xref> showed that people relied on misinformation acquired from clearly fictitious stories to respond to later quiz questions, even when these pieces of misinformation contradicted common knowledge. In most cases, source attribution was intact, so people were aware that their answers to the quiz questions were based on information from the stories, but reading the stories also increased people’s illusory belief of prior knowledge. In other words, encountering misinformation in a fictional context led people to assume they had known it all along and to integrate this misinformation with their prior knowledge (<xref ref-type="bibr" rid="bibr120-1529100612451018">Marsh &amp; Fazio, 2006</xref>; <xref ref-type="bibr" rid="bibr121-1529100612451018">Marsh et al., 2003</xref>).</p>
<p>The effects of fictional misinformation have been shown to be stable and difficult to eliminate. <xref ref-type="bibr" rid="bibr120-1529100612451018">Marsh and Fazio (2006)</xref> reported that prior warnings were ineffective in reducing the acquisition of misinformation from fiction, and that acquisition was only reduced (not eliminated) under conditions of active on-line monitoring—when participants were instructed to actively monitor the contents of what they were reading and to press a key every time they encountered a piece of misinformation (see also <xref ref-type="bibr" rid="bibr47-1529100612451018">Eslick, Fazio, &amp; Marsh, 2011</xref>). Few people would be so alert and mindful when reading fiction for enjoyment. These links between fiction and incorrect knowledge are particularly concerning when popular fiction pretends to accurately portray science but fails to do so, as was the case with Michael Crichton’s novel <italic>State of Fear</italic>. The novel misrepresented the science of global climate change but was nevertheless introduced as “scientific” evidence into a U.S. Senate committee (<xref ref-type="bibr" rid="bibr1-1529100612451018">Allen, 2005</xref>; <xref ref-type="bibr" rid="bibr108-1529100612451018">Leggett, 2005</xref>).</p>
<p>Writers of fiction are expected to depart from reality, but in other instances, misinformation is manufactured intentionally. There is considerable peer-reviewed evidence pointing to the fact that misinformation can be intentionally or carelessly disseminated, often for political ends or in the service of vested interests, but also through routine processes employed by the media.</p>
</sec>
<sec id="section4-1529100612451018">
<title>Governments and politicians</title>
<p>In the lead-up to the U.S.-led invasion of Iraq in 2003, U.S. government officials proclaimed there was no doubt that Saddam Hussein had weapons of mass destruction (WMDs) and was ready to use them against his enemies. The Bush administration also juxtaposed Iraq and the 9/11 terrorist attacks, identifying Iraq as the frontline in the “War on Terror” (<xref ref-type="bibr" rid="bibr176-1529100612451018">Reese &amp; Lewis, 2009</xref>) and implying that it had intelligence linking Iraq to al-Qaida. Although no WMDs were ever found in Iraq and its link to al-Qaida turned out to be unsubstantiated, large segments of the U.S. public continued to believe the administration’s earlier claims, with some 20% to 30% of Americans believing that WMDs had actually been discovered in Iraq years after the invasion (<xref ref-type="bibr" rid="bibr103-1529100612451018">Kull, Ramsay, &amp; Lewis, 2003</xref>; <xref ref-type="bibr" rid="bibr104-1529100612451018">Kull et al., 2006</xref>) and around half of the public endorsing links between Iraq and al-Qaida (<xref ref-type="bibr" rid="bibr104-1529100612451018">Kull et al., 2006</xref>). These mistaken beliefs persisted even though all tentative media reports about possible WMD sightings during the invasion were followed by published corrections, and even though the nonexistence of WMDs in Iraq and the absence of links between Iraq and al-Qaida was eventually widely reported and became the official bipartisan U.S. position through the Duelfer report.</p>
<p>Politicians were also a primary source of misinformation during the U.S. health care debate in 2009. Misinformation about the Obama health plan peaked when Sarah Palin posted a comment about “death panels” on her Facebook page. Within 5 weeks, 86% of Americans had heard the death-panel claim. Of those who heard the myth, fully half either believed it or were not sure of its veracity. <italic>Time</italic> magazine reported that the single phrase “death panels” nearly derailed Obama’s health care plan (<xref ref-type="bibr" rid="bibr139-1529100612451018">Nyhan, 2010</xref>).</p>
<p>Although Sarah Palin’s turn of phrase may have been spontaneous and its consequences unplanned, analyses have revealed seemingly systematic efforts to misinform the public—for example, about climate change (<xref ref-type="bibr" rid="bibr126-1529100612451018">McCright &amp; Dunlap, 2010</xref>). During the administration of President George W. Bush, political appointees demonstrably interfered with scientific assessments of climate change (e.g., <xref ref-type="bibr" rid="bibr133-1529100612451018">Mooney, 2007</xref>), and NASA’s inspector general found in 2008 that in previous years, the agency’s “Office of Public Affairs managed the topic of climate change in a manner that reduced, marginalized, or mischaracterized climate change science made available to the general public” (<xref ref-type="bibr" rid="bibr215-1529100612451018">Winters, 2008</xref>, p. 1).</p>
<p>The public seems to have some awareness of the presence of politically motivated misinformation in society, especially during election campaigns (<xref ref-type="bibr" rid="bibr171-1529100612451018">Ramsay, Kull, Lewis, &amp; Subias, 2010</xref>). However, when asked to identify specific instances of such misinformation, people are often unable to differentiate between information that is false and other information that is correct (<xref ref-type="bibr" rid="bibr171-1529100612451018">Ramsay et al., 2010</xref>). Thus, public awareness of the problem is no barrier to widespread and lasting confusion.</p>
</sec>
<sec id="section5-1529100612451018">
<title>Vested interests and nongovernmental organizations (NGOs)</title>
<p>There is also evidence of concerted efforts by vested interests to disseminate misinformation, especially when it comes to issues of the environment (e.g., <xref ref-type="bibr" rid="bibr81-1529100612451018">Jacques, Dunlap, &amp; Freeman, 2008</xref>) and public health (e.g., <xref ref-type="bibr" rid="bibr144-1529100612451018">Oreskes &amp; Conway, 2010</xref>; <xref ref-type="bibr" rid="bibr168-1529100612451018">Proctor, 2008</xref>) that have the potential to motivate policies that would impose a regulatory burden on certain industries (e.g., tobacco manufacturers or the fossil-fuel industry). This process of willful manufacture of mistaken beliefs has been described as “agnogenesis” (<xref ref-type="bibr" rid="bibr13-1529100612451018">Bedford, 2010</xref>). There is considerable legal and scientific evidence for this process in at least two arenas—namely, industry-based responses to the health consequences of smoking and to climate change.</p>
<p>In 2006, a U.S. federal court ruled that major domestic cigarette manufacturers were guilty of conspiring to deny, distort, and minimize the hazards of cigarette smoking (<xref ref-type="bibr" rid="bibr193-1529100612451018">Smith et al., 2011</xref>). Similarly, starting in the early 1990s, the American Petroleum Institute, the Western Fuels Association (a coal-fired electrical industry consortium), and The Advancement of Sound Science Coalition (TASSC; a group sponsored by Philip Morris) drafted and promoted campaigns to cast doubt on the science of climate change (<xref ref-type="bibr" rid="bibr76-1529100612451018">Hoggan, Littlemore, &amp; Littlemore, 2009</xref>). These industry groups have also formed an alliance with conservative think tanks, using a handful of scientists (typically experts from a different domain) as spokespersons (<xref ref-type="bibr" rid="bibr144-1529100612451018">Oreskes &amp; Conway, 2010</xref>). Accordingly, more than 90% of books published between 1972 and 2005 that expressed skepticism about environmental issues have been linked to conservative think tanks (<xref ref-type="bibr" rid="bibr81-1529100612451018">Jacques et al., 2008</xref>).</p>
<p>However, the spreading of misinformation is by no means always based on concerted efforts by vested interests. On the contrary, industry itself has been harmed by misinformation in some instances. For example, the vaccination-autism myth has led to decreased vaccination rates (<xref ref-type="bibr" rid="bibr146-1529100612451018">Owens, 2002</xref>; <xref ref-type="bibr" rid="bibr163-1529100612451018">Poland &amp; Jacobsen, 2011</xref>) and hence arguably decreased the revenue and profits of pharmaceutical companies. A similar case can be made for genetically modified (GM) foods, which are strongly opposed by sizable segments of the public, particularly in Europe (e.g., <xref ref-type="bibr" rid="bibr56-1529100612451018">Gaskell et al., 2003</xref>; <xref ref-type="bibr" rid="bibr130-1529100612451018">Mielby, Sandøe, &amp; Lassen, 2012</xref>). The magnitude of opposition to GM foods seems disproportionate to their actual risks as portrayed by expert bodies (e.g., <xref ref-type="bibr" rid="bibr217-1529100612451018">World Health Organization, 2005</xref>), and it appears that people often rely on NGOs, such as Greenpeace, that are critical of peer-reviewed science on the issue to form their opinions about GM foods (<xref ref-type="bibr" rid="bibr45-1529100612451018">Einsele, 2007</xref>). These alternative sources have been roundly criticized for spreading misinformation (e.g., <xref ref-type="bibr" rid="bibr149-1529100612451018">Parrott, 2010</xref>).</p>
</sec>
<sec id="section6-1529100612451018">
<title>Media</title>
<p>Given that people largely obtain their information from the media (broadly defined to include print newspapers and magazines, radio, TV, and the Internet), the media’s role in the dissemination of misinformation deserves to be explored. We have already mentioned that the media sometimes unavoidably report incorrect information because of the need for timely news coverage. There are, however, several other systemic reasons for why the media might get things wrong.</p>
<p>First, the media can inadvertently oversimplify, misrepresent, or overdramatize scientific results. Science is complex, and for the layperson, the details of many scientific studies are difficult to understand or of marginal interest. Science communication therefore requires simplification in order to be effective. Any oversimplification, however, can lead to misunderstanding. For example, after a study forecasting future global extinctions as a result of climate change was published in <italic>Nature</italic>, it was widely misrepresented by news media reports, which made the consequences seem more catastrophic and the timescale shorter than actually projected (<xref ref-type="bibr" rid="bibr105-1529100612451018">Ladle, Jepson, &amp; Whittaker, 2005</xref>). These mischaracterizations of scientific results imply that scientists need to take care to communicate their results clearly and unambiguously, and that press releases need to be meticulously constructed to avoid misunderstandings by the media (e.g., <xref ref-type="bibr" rid="bibr177-1529100612451018">Riesch &amp; Spiegelhalter, 2011</xref>).</p>
<p>Second, in all areas of reporting, journalists often aim to present a “balanced” story. In many instances, it is indeed appropriate to listen to both sides of a story; however, if media stick to journalistic principles of “balance” even when it is not warranted, the outcome can be highly misleading (<xref ref-type="bibr" rid="bibr31-1529100612451018">Clarke, 2008</xref>). For example, if the national meteorological service issued a severe weather warning for tomorrow, no one would—or should—be interested in their neighbor Jimmy’s opinion that it will be a fine day. For good reasons, a newspaper’s weather forecast relies on expert assessment and excludes lay opinions.</p>
<p>On certain hotly contested issues, there is evidence that the media have systematically overextended the “balance” frame. For example, the overwhelming majority (more than 95%; <xref ref-type="bibr" rid="bibr3-1529100612451018">Anderegg, Prall, Harold, &amp; Schneider, 2010</xref>; <xref ref-type="bibr" rid="bibr38-1529100612451018">Doran &amp; Zimmerman, 2009</xref>) of actively publishing climate scientists agree on the fundamental facts that the globe is warming and that this warming is due to greenhouse-gas emissions caused by humans; yet the contrarian opinions of nonexperts are featured prominently in the media (<xref ref-type="bibr" rid="bibr20-1529100612451018">Boykoff &amp; Boykoff, 2004</xref>). A major Australian TV channel recently featured a self-styled climate “expert” whose diverse qualifications included authorship of a book on cat palmistry (<xref ref-type="bibr" rid="bibr174-1529100612451018">Readfearn, 2011</xref>). This asymmetric choice of “experts” leads to the perception of a debate about issues that were in fact resolved in the relevant scientific literature long ago.</p>
<p>Although these systemic problems are shared to varying extents by most media outlets, the problems vary considerably both across time and among outlets. In the U.S., expert voices have repeatedly expressed alarm at the decline in “hard” news coverage since the 1990s and the growth of sensationalist coverage devoid of critical analysis or in-depth investigation (e.g., <xref ref-type="bibr" rid="bibr15-1529100612451018">Bennett, 2003</xref>). After the invasion of Iraq in 2003, the American media attracted much censure for their often uncritical endorsement of prewar claims by the Bush administration about Iraqi WMDs (e.g., <xref ref-type="bibr" rid="bibr6-1529100612451018">Artz &amp; Kamalipour, 2004</xref>, <xref ref-type="bibr" rid="bibr97-1529100612451018">Kamalipour &amp; Snow, 2004</xref>; <xref ref-type="bibr" rid="bibr170-1529100612451018">Rampton &amp; Stauber, 2003</xref>, <xref ref-type="bibr" rid="bibr200-1529100612451018">Tiffen, 2009</xref>), although there was considerable variation among outlets in the accuracy of their coverage, as revealed by survey research into the persistence of misinformation. Stephen Kull and his colleagues (e.g., <xref ref-type="bibr" rid="bibr103-1529100612451018">Kull et al., 2003</xref>) have repeatedly shown that the level of belief in misinformation among segments of the public varies dramatically according to preferred news outlets, running along a continuum from Fox News (whose viewers are the most misinformed on most issues) to National Public Radio (whose listeners are the least misinformed overall).</p>
<sec id="section7-1529100612451018">
<title>The role of the Internet</title>
<p>The Internet has revolutionized the availability of information; however, it has also facilitated the spread of <italic>mis</italic>information because it obviates the use of conventional “gate-keeping” mechanisms, such as professional editors. This is particularly the case with the development of Web 2.0, whereby Internet users have moved from being passive consumers of information to actively creating content on Web sites such as Twitter and YouTube or blogs.</p>
<p>People who use new media, such as blogs (<xref ref-type="bibr" rid="bibr124-1529100612451018">McCracken, 2011</xref>), to source their news report that they find them fairer, more credible, and more in-depth than traditional sources (<xref ref-type="bibr" rid="bibr89-1529100612451018">T. J. Johnson &amp; Kaye, 2004</xref>). Blog users judged war blogs to be more credible sources for news surrounding the conflicts in Iraq and Afghanistan than traditional media (<xref ref-type="bibr" rid="bibr90-1529100612451018">T. J. Johnson &amp; Kaye, 2010</xref>).</p>
<p>On the other hand, information on the Internet can be highly misleading, and it is progressively replacing expert advice. For example, people are increasingly sourcing health care information from social networks. In 2009, 61% of American adults looked online for health information (<xref ref-type="bibr" rid="bibr52-1529100612451018">Fox &amp; Jones, 2009</xref>). Relying on the Internet as a source of health information is fraught with risk because its reliability is highly variable. Among the worst performers in terms of accuracy are dietary Web sites: A survey of the first 50 Web sites matching the search term “weight loss diets” revealed that only 3 delivered sound dietary advice (<xref ref-type="bibr" rid="bibr131-1529100612451018">Miles, Petrie, &amp; Steel, 2000</xref>). Other domains fare more favorably: A survey of English-language Web sites revealed that 75% of sites on depression were completely accurate and that 86% of obesity-related Web sites were at least partially accurate (<xref ref-type="bibr" rid="bibr18-1529100612451018">Berland et al., 2001</xref>).</p>
<p>Online videos are an effective and popular means of disseminating information (and misinformation)—1.2 billion people viewed online videos in October 2011 (<xref ref-type="bibr" rid="bibr169-1529100612451018">Radwanick, 2011</xref>). A survey of 153 YouTube videos matching the search terms “vaccination” and “immunization” revealed that approximately half of the videos were not explicitly supportive of immunization, and that the information in the anti-immunization videos often contradicted official reference material (<xref ref-type="bibr" rid="bibr98-1529100612451018">Keelan, Pavri-Garcia, Tomlinson, &amp; Wilson, 2007</xref>). A survey of YouTube videos about the H1N1 influenza pandemic revealed that 61.3% of the videos contained useful information about the disease, whereas 23% were misleading (<xref ref-type="bibr" rid="bibr148-1529100612451018">Pandey, Patni, Singh, Sood, &amp; Singh, 2010</xref>).</p>
<p>Finally, there are hoax Web sites whose sole purpose is to disseminate misinformation. Although these sites can have many objectives, including parody, the more dangerous sites pass themselves off as official sources of information. For instance, the site <ext-link ext-link-type="uri" xlink:href="http://martinlutherking.org">martinlutherking.org</ext-link> (created by a White-power organization) disseminates hateful information about Dr. Martin Luther King while pretending to be an official King Web site (<xref ref-type="bibr" rid="bibr161-1529100612451018">Piper, 2000</xref>).</p>
</sec>
<sec id="section8-1529100612451018">
<title>Consequences of increasing media fractionation</title>
<p>The growth of cable TV, talk radio, and the Internet have made it easier for people to find news sources that support their existing views, a phenomenon known as <italic>selective exposure</italic> (<xref ref-type="bibr" rid="bibr166-1529100612451018">Prior, 2003</xref>). When people have more media options to choose from, they are more biased toward like-minded media sources. The emergence of the Internet in particular has led to a fractionation of the information landscape into “echo chambers”—that is, (political) blogs that primarily link to other blogs of similar persuasion and not to those with opposing viewpoints. More than half of blog readers seek out blogs that support their views, whereas only 22% seek out blogs espousing opposing views, a phenomenon that has led to the creation of “cyber-ghettos” (<xref ref-type="bibr" rid="bibr91-1529100612451018">T. J. Johnson, Bichard, &amp; Zhang, 2009</xref>). These cyber-ghettos have been identified as one reason for the increasing polarization of political discourse (<xref ref-type="bibr" rid="bibr125-1529100612451018">McCright, 2011</xref>; <xref ref-type="bibr" rid="bibr196-1529100612451018">Stroud, 2010</xref>).</p>
<p>One consequence of a fractionated information landscape is the emergence of “strategic extremism” among politicians (<xref ref-type="bibr" rid="bibr61-1529100612451018">Glaeser, Ponzetto, &amp; Shapiro, 2005</xref>). Although politicians have traditionally vied for the attention of the political center, extremism can be strategically effective if it garners more votes at one extreme of the political spectrum than it loses in the center or the opposite end of the spectrum. A precondition for the success—defined as a net gain of votes—of strategic extremism is a fractionated media landscape in which information (or an opinion) can be selectively channeled to people who are likely to support it, without alienating others. The long-term effects of such strategic extremism, however, may well include a pernicious and prolonged persistence of misinformation in large segments of society, especially when such information leaks out of cyber-ghettos into the mainstream. This fractionation of the information landscape is important in that, as we show later in this article, worldview plays a major role in people’s resistance to corrections of misinformation.</p>
</sec>
</sec>
</sec>
<sec id="section9-1529100612451018">
<title>From Individual Cognition to Debiasing Strategies</title>
<p>We now turn to the individual-level cognitive processes that are involved in the acquisition and persistence of misinformation. In the remainder of the article, we address the following points:</p>
<p>We begin by considering how people assess the truth of a statement: What makes people believe certain things, but not others?</p>
<p>Once people have acquired information and believe in it, why do corrections and retractions so often fail? Worse yet, why can attempts at retraction backfire, entrenching belief in misinformation rather than reducing it?</p>
<p>After addressing these questions, we survey the successful techniques by which the impact of misinformation can be reduced.</p>
<p>We then discuss how, in matters of public and political import, people’s personal worldviews, or ideology, can play a crucial role in preventing debiasing, and we examine how these difficulties arise and whether they can be overcome.</p>
<p>Finally, we condense our discussion into specific recommendations for practitioners and consider some ethical implications and practical limitations of debiasing efforts in general.</p>
</sec>
<sec id="section10-1529100612451018">
<title>Assessing the Truth of a Statement: Recipients’ Strategies</title>
<p>Misleading information rarely comes with a warning label. People usually cannot recognize that a piece of information is incorrect until they receive a correction or retraction. For better or worse, the acceptance of information as true is favored by tacit norms of everyday conversational conduct: Information relayed in conversation comes with a “guarantee of relevance” (<xref ref-type="bibr" rid="bibr195-1529100612451018">Sperber &amp; Wilson, 1986</xref>), and listeners proceed on the assumption that speakers try to be truthful, relevant, and clear, unless evidence to the contrary calls this default into question (<xref ref-type="bibr" rid="bibr67-1529100612451018">Grice, 1975</xref>; <xref ref-type="bibr" rid="bibr186-1529100612451018">Schwarz, 1994</xref>, <xref ref-type="bibr" rid="bibr187-1529100612451018">1996</xref>). Some research has even suggested that to comprehend a statement, people must at least temporarily accept it as true (<xref ref-type="bibr" rid="bibr58-1529100612451018">Gilbert, 1991</xref>). On this view, belief is an inevitable consequence of—or, indeed, precursor to—comprehension.</p>
<p>Although suspension of belief is possible (<xref ref-type="bibr" rid="bibr73-1529100612451018">Hasson, Simmons, &amp; Todorov, 2005</xref>; <xref ref-type="bibr" rid="bibr183-1529100612451018">Schul, Mayo, &amp; Burnstein, 2008</xref>), it seems to require a high degree of attention, considerable implausibility of the message, or high levels of distrust at the time the message is received. So, in most situations, the deck is stacked in favor of accepting information rather than rejecting it, provided there are no salient markers that call the speaker’s intention of cooperative conversation into question. Going beyond this default of acceptance requires additional motivation and cognitive resources: If the topic is not very important to you, or you have other things on your mind, misinformation will likely slip in.</p>
<p>When people do thoughtfully evaluate the truth value of information, they are likely to attend to a limited set of features. First, is this information compatible with other things I believe to be true? Second, is this information internally coherent?—do the pieces form a plausible story? Third, does it come from a credible source? Fourth, do other people believe it? These questions can be answered on the basis of declarative or experiential information—that is, by drawing on one’s knowledge or by relying on feelings of familiarity and fluency (<xref ref-type="bibr" rid="bibr188-1529100612451018">Schwarz, 2004</xref>; <xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz, Sanna, Skurnik, &amp; Yoon, 2007</xref>). In the following section, we examine those issues.</p>
<sec id="section11-1529100612451018">
<title>Is the information compatible with what I believe?</title>
<p>As numerous studies in the literature on social judgment and persuasion have shown, information is more likely to be accepted by people when it is consistent with other things they assume to be true (for reviews, see <xref ref-type="bibr" rid="bibr129-1529100612451018">McGuire, 1972</xref>; <xref ref-type="bibr" rid="bibr218-1529100612451018">Wyer, 1974</xref>). People assess the logical compatibility of the information with other facts and beliefs. Once a new piece of knowledge-consistent information has been accepted, it is highly resistant to change, and the more so the larger the compatible knowledge base is. From a judgment perspective, this resistance derives from the large amount of supporting evidence (<xref ref-type="bibr" rid="bibr218-1529100612451018">Wyer, 1974</xref>); from a cognitive-consistency perspective (<xref ref-type="bibr" rid="bibr50-1529100612451018">Festinger, 1957</xref>), it derives from the numerous downstream inconsistencies that would arise from rejecting the prior information as false. Accordingly, compatibility with other knowledge increases the likelihood that misleading information will be accepted, and decreases the likelihood that it will be successfully corrected.</p>
<p>When people encounter a piece of information, they can check it against other knowledge to assess its compatibility. This process is effortful, and it requires motivation and cognitive resources. A less demanding indicator of compatibility is provided by one’s meta-cognitive experience and affective response to new information. Many theories of cognitive consistency converge on the assumption that information that is inconsistent with one’s beliefs elicits negative feelings (<xref ref-type="bibr" rid="bibr50-1529100612451018">Festinger, 1957</xref>). Messages that are inconsistent with one’s beliefs are also processed less fluently than messages that are consistent with one’s beliefs (<xref ref-type="bibr" rid="bibr214-1529100612451018">Winkielman, Huber, Kavanagh, &amp; Schwarz, 2012</xref>). In general, fluently processed information feels more familiar and is more likely to be accepted as true; conversely, disfluency elicits the impression that something doesn’t quite “feel right” and prompts closer scrutiny of the message (<xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>; <xref ref-type="bibr" rid="bibr194-1529100612451018">Song &amp; Schwarz, 2008</xref>). This phenomenon is observed even when the fluent processing of a message merely results from superficial characteristics of its presentation. For example, the same statement is more likely to be judged as true when it is printed in high rather than low color contrast (<xref ref-type="bibr" rid="bibr175-1529100612451018">Reber &amp; Schwarz, 1999</xref>), presented in a rhyming rather than nonrhyming form (<xref ref-type="bibr" rid="bibr128-1529100612451018">McGlone &amp; Tofighbakhsh, 2000</xref>), or delivered in a familiar rather than unfamiliar accent (<xref ref-type="bibr" rid="bibr111-1529100612451018">Levy-Ari &amp; Keysar, 2010</xref>). Moreover, misleading questions are less likely to be recognized as such when printed in an easy-to-read font (<xref ref-type="bibr" rid="bibr194-1529100612451018">Song &amp; Schwarz, 2008</xref>).</p>
<p>As a result, analytic as well as intuitive processing favors the acceptance of messages that are compatible with a recipient’s preexisting beliefs: The message contains no elements that contradict current knowledge, is easy to process, and “feels right.”</p>
</sec>
<sec id="section12-1529100612451018">
<title>Is the story coherent?</title>
<p>Whether a given piece of information will be accepted as true also depends on how well it fits a broader story that lends sense and coherence to its individual elements. People are particularly likely to use an assessment strategy based on this principle when the meaning of one piece of information cannot be assessed in isolation because it depends on other, related pieces; use of this strategy has been observed in basic research on mental models (for a review, see <xref ref-type="bibr" rid="bibr92-1529100612451018">Johnson-Laird, 2012</xref>), as well as extensive analyses of juries’ decision making (<xref ref-type="bibr" rid="bibr153-1529100612451018">Pennington &amp; Hastie, 1992</xref>, <xref ref-type="bibr" rid="bibr154-1529100612451018">1993</xref>).</p>
<p>A story is compelling to the extent that it organizes information without internal contradictions in a way that is compatible with common assumptions about human motivation and behavior. Good stories are easily remembered, and gaps are filled with story-consistent intrusions. Once a coherent story has been formed, it is highly resistant to change: Within the story, each element is supported by the fit of other elements, and any alteration of an element may be made implausible by the downstream inconsistencies it would cause. Coherent stories are easier to process than incoherent stories are (<xref ref-type="bibr" rid="bibr92-1529100612451018">Johnson-Laird, 2012</xref>), and people draw on their processing experience when they judge a story’s coherence (<xref ref-type="bibr" rid="bibr202-1529100612451018">Topolinski, 2012</xref>), again giving an advantage to material that is easy to process.</p>
</sec>
<sec id="section13-1529100612451018">
<title>Is the information from a credible source?</title>
<p>When people lack the motivation, opportunity, or expertise to process a message in sufficient detail, they can resort to an assessment of the communicator’s credibility. Not surprisingly, the persuasiveness of a message increases with the communicator’s perceived credibility and expertise (for reviews, see <xref ref-type="bibr" rid="bibr39-1529100612451018">Eagly &amp; Chaiken, 1993</xref>; <xref ref-type="bibr" rid="bibr158-1529100612451018">Petty &amp; Cacioppo, 1986</xref>). However, even untrustworthy sources are often influential. Several factors contribute to this observation. People are often insensitive to contextual cues that bear on the credibility of a source. For example, expert testimony has been found to be similarly persuasive whether it is provided under oath or in another context (<xref ref-type="bibr" rid="bibr140-1529100612451018">Nyhan, 2011</xref>). Similarly, <xref ref-type="bibr" rid="bibr29-1529100612451018">Cho, Martens, Kim, and Rodrigue (2011)</xref> found that messages denying climate change were similarly influential whether recipients were told they came from a study “funded by Exxon” or from a study “funded from donations by people like you.” Such findings suggest that situational indicators of credibility may often go unnoticed, consistent with people’s tendency to focus on features of the actor rather than the situation (<xref ref-type="bibr" rid="bibr178-1529100612451018">Ross, 1977</xref>). In addition, the gist of a message is often more memorable than its source, and an engaging story from an untrustworthy source may be remembered and accepted long after the source has been forgotten (for a review of such “sleeper effects,” see <xref ref-type="bibr" rid="bibr39-1529100612451018">Eagly &amp; Chaiken, 1993</xref>).</p>
<p>People’s evaluation of a source’s credibility can be based on declarative information, as in the above examples, as well as experiential information. The mere repetition of an unknown name can cause it to seem familiar, making its bearer “famous overnight” (<xref ref-type="bibr" rid="bibr80-1529100612451018">Jacoby, Kelley, Brown, &amp; Jaseschko, 1989</xref>)—and hence more credible. Even when a message is rejected at the time of initial exposure, that initial exposure may lend it some familiarity-based credibility if the recipient hears it again.</p>
</sec>
<sec id="section14-1529100612451018">
<title>Do others believe this information?</title>
<p>Repeated exposure to a statement is known to increase its acceptance as true (e.g., <xref ref-type="bibr" rid="bibr14-1529100612451018">Begg, Anas, &amp; Farinacci, 1992</xref>; <xref ref-type="bibr" rid="bibr72-1529100612451018">Hasher, Goldstein, &amp; Toppino, 1977</xref>). In a classic study of rumor transmission, <xref ref-type="bibr" rid="bibr2-1529100612451018">Allport and Lepkin (1945)</xref> observed that the strongest predictor of belief in wartime rumors was simple repetition. Repetition effects may create a perceived social consensus even when no consensus exists. <xref ref-type="bibr" rid="bibr49-1529100612451018">Festinger (1954)</xref> referred to social consensus as a “secondary reality test”: If many people believe a piece of information, there’s probably something to it. Because people are more frequently exposed to widely shared beliefs than to highly idiosyncratic ones, the familiarity of a belief is often a valid indicator of social consensus. But, unfortunately, information can seem familiar for the wrong reason, leading to erroneous perceptions of high consensus. For example, <xref ref-type="bibr" rid="bibr207-1529100612451018">Weaver, Garcia, Schwarz, and Miller (2007)</xref> exposed participants to multiple iterations of the same statement, provided by the same communicator. When later asked to estimate how widely the conveyed belief is shared, participants estimated consensus to be greater the more often they had read the identical statement from the same, single source. In a very real sense, a single repetitive voice can sound like a chorus.</p>
<p>Social-consensus information is particularly powerful when it pertains to one’s reference group (for a review, see <xref ref-type="bibr" rid="bibr100-1529100612451018">Krech, Crutchfield, &amp; Ballachey, 1962</xref>). As already noted, this renders repetition in the echo chambers of social-media networks particularly influential. One possible consequence of such repetition is <italic>pluralistic ignorance</italic>, or a divergence between the actual prevalence of a belief in a society and what people in that society think others believe. For example, in the lead-up to the invasion of Iraq in 2003, voices that advocated unilateral military action were given prominence in the American media, which caused the large <italic>majority</italic> of citizens who actually wanted the U.S. to engage multilaterally, in concert with other nations, to feel that they were in the minority (<xref ref-type="bibr" rid="bibr110-1529100612451018">Leviston &amp; Walker, 2011</xref>; <xref ref-type="bibr" rid="bibr201-1529100612451018">Todorov &amp; Mandisodza, 2004</xref>). Conversely, the minority of citizens who advocated unilateral action incorrectly felt that they were in the majority (this <italic>false-consensus effect</italic> is the flip side of pluralistic ignorance).</p>
<p>The extent of pluralistic ignorance (or of the false-consensus effect) can be quite striking: In Australia, people with particularly negative attitudes toward Aboriginal Australians or asylum seekers have been found to overestimate public support for their attitudes by 67% and 80%, respectively (<xref ref-type="bibr" rid="bibr152-1529100612451018">Pedersen, Griffiths, &amp; Watt, 2008</xref>). Specifically, although only 1.8% of people in a sample of Australians were found to hold strongly negative attitudes toward Aboriginals, those few individuals thought that 69% of all Australians (and 79% of their friends) shared their fringe beliefs. This represents an extreme case of the false-consensus effect.</p>
<p>Perceived social consensus can serve to solidify and maintain belief in misinformation. But how do the processes we have reviewed affect people’s ability to correct misinformation? From the perspective of truth assessment, corrections involve a competition between the perceived truth value of misinformation and correct information. In the ideal case, corrections undermine the perceived truth of misinformation and enhance the acceptance of correct information. But as we discuss in the next section, corrections often fail to work as expected. It is this failure of corrections, known as the <italic>continued influence effect</italic> (<xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>), that constitutes the central conundrum in research on misinformation.</p>
</sec>
</sec>
<sec id="section15-1529100612451018">
<title>The Continued Influence Effect: Retractions Fail to Eliminate the Influence of Misinformation</title>
<p>We first consider the cognitive parameters of credible retractions in neutral scenarios, in which people have no inherent reason or motivation to believe one version of events over another. Research on this topic was stimulated by a paradigm pioneered by <xref ref-type="bibr" rid="bibr209-1529100612451018">Wilkes and Leatherbarrow (1988)</xref> and <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson and Seifert (1994)</xref>. In it, people are presented with a fictitious report about an event unfolding over time. The report contains a target piece of information: For some readers, this target information is subsequently retracted, whereas for readers in a control condition, no correction occurs. Participants’ understanding of the event is then assessed with a questionnaire, and the number of clear and uncontroverted references to the target (mis-)information in their responses is tallied.</p>
<p>A stimulus narrative commonly used in this paradigm involves a warehouse fire that is initially thought to have been caused by gas cylinders and oil paints that were negligently stored in a closet (e.g., <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, &amp; Chang, 2011</xref>; <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>; <xref ref-type="bibr" rid="bibr209-1529100612451018">Wilkes &amp; Leatherbarrow, 1988</xref>). Some participants are then presented with a retraction, such as “the closet was actually empty.” A comprehension test follows, and participants’ number of references to the gas and paint in response to indirect inference questions about the event (e.g., “What caused the black smoke?”) is counted. In addition, participants are asked to recall some basic facts about the event and to indicate whether they noticed any retraction.</p>
<p>Research using this paradigm has consistently found that retractions rarely, if ever, have the intended effect of eliminating reliance on misinformation, even when people believe, understand, and later remember the retraction (e.g., <xref ref-type="bibr" rid="bibr41-1529100612451018">Ecker, Lewandowsky, &amp; Apai, 2011</xref>; <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, &amp; Chang, 2011</xref>; <xref ref-type="bibr" rid="bibr44-1529100612451018">Ecker, Lewandowsky, &amp; Tang, 2010</xref>; <xref ref-type="bibr" rid="bibr48-1529100612451018">Fein, McCloskey, &amp; Tomlinson, 1997</xref>; <xref ref-type="bibr" rid="bibr59-1529100612451018">Gilbert, Krull, &amp; Malone, 1990</xref>; <xref ref-type="bibr" rid="bibr60-1529100612451018">Gilbert, Tafarodi, &amp; Malone, 1993</xref>; <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>, <xref ref-type="bibr" rid="bibr86-1529100612451018">1998</xref>, <xref ref-type="bibr" rid="bibr87-1529100612451018">1999</xref>; <xref ref-type="bibr" rid="bibr184-1529100612451018">Schul &amp; Mazursky, 1990</xref>; <xref ref-type="bibr" rid="bibr204-1529100612451018">van Oostendorp, 1996</xref>; <xref ref-type="bibr" rid="bibr205-1529100612451018">van Oostendorp &amp; Bonebakker, 1999</xref>; <xref ref-type="bibr" rid="bibr209-1529100612451018">Wilkes &amp; Leatherbarrow, 1988</xref>; <xref ref-type="bibr" rid="bibr210-1529100612451018">Wilkes &amp; Reynolds, 1999</xref>). In fact, a retraction will at most halve the number of references to misinformation, even when people acknowledge and demonstrably remember the retraction (<xref ref-type="bibr" rid="bibr41-1529100612451018">Ecker, Lewandowsky, &amp; Apai, 2011</xref>; <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, &amp; Chang, 2011</xref>); in some studies, a retraction did not reduce reliance on misinformation at all (e.g., <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>).</p>
<p>When misinformation is presented through media sources, the remedy is the presentation of a correction, often in a temporally disjointed format (e.g., if an error appears in a newspaper, the correction will be printed in a subsequent edition). In laboratory studies, misinformation is often retracted immediately and within the same narrative (<xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>). Despite this temporal and contextual proximity to the misinformation, retractions are ineffective. More recent studies (<xref ref-type="bibr" rid="bibr190-1529100612451018">Seifert, 2002</xref>) have examined whether clarifying the correction (minimizing misunderstanding) might reduce the continued influence effect. In these studies, the correction was thus strengthened to include the phrase “paint and gas were never on the premises.” Results showed that this enhanced negation of the presence of flammable materials backfired, making people even <italic>more</italic> likely to rely on the misinformation in their responses. Other additions to the correction were found to mitigate to a degree, but not eliminate, the continued influence effect: For example, when participants were given a rationale for how the misinformation originated, such as, “a truckers’ strike prevented the expected delivery of the items,” they were somewhat less likely to make references to it. Even so, the influence of the misinformation could still be detected. The wealth of studies on this phenomenon have documented its pervasive effects, showing that it is extremely difficult to return the beliefs of people who have been exposed to misinformation to a baseline similar to those of people who were never exposed to it.</p>
<p>Multiple explanations have been proposed for the continued influence effect. We summarize their key assumptions next.</p>
<sec id="section16-1529100612451018">
<title>Mental models</title>
<p>One explanation for the continued influence effect assumes that people build mental models of unfolding events (<xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>; <xref ref-type="bibr" rid="bibr205-1529100612451018">van Oostendorp &amp; Bonebakker, 1999</xref>; <xref ref-type="bibr" rid="bibr209-1529100612451018">Wilkes &amp; Leatherbarrow, 1988</xref>). In this view, factor A (e.g., negligence) led to factor B (e.g., the improper storage of flammable materials), and factor B in conjunction with factor C (e.g., an electrical fault) caused outcome X (e.g., the fire) to happen. If a retraction invalidates a central piece of information (e.g., factor B, the presence of gas and paint), people will be left with a gap in their model of the event and an event representation that just “doesn’t make sense” unless they maintain the false assertion. Therefore, when questioned about the event, a person may still rely on the retracted misinformation to respond (e.g., answering “The gas cylinders” when asked “What caused the explosions?”), despite demonstrating awareness of the correction when asked about it directly. Consistent with the mental-model notion, misinformation becomes particularly resilient to correction when people are asked to generate an explanation for why the misinformation might be true (<xref ref-type="bibr" rid="bibr4-1529100612451018">Anderson, Lepper, &amp; Ross, 1980</xref>). Moreover, the literature on false memory has shown that people tend to fill gaps in episodic memory with inaccurate but congruent information if such information is readily available from event schemata (<xref ref-type="bibr" rid="bibr57-1529100612451018">Gerrie, Belcher, &amp; Garry, 2006</xref>).</p>
<p>Nevertheless, the continued use of discredited mental models despite explicit correction remains poorly understood. On the one hand, people may be uncomfortable with gaps in their knowledge of an event and hence prefer an incorrect model over an incomplete model (<xref ref-type="bibr" rid="bibr41-1529100612451018">Ecker, Lewandowsky, &amp; Apai, 2011</xref>; <xref ref-type="bibr" rid="bibr44-1529100612451018">Ecker et al., 2010</xref>; <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>; <xref ref-type="bibr" rid="bibr205-1529100612451018">van Oostendorp &amp; Bonebakker, 1999</xref>). The conflict created by having a plausible answer to a question readily available, but at the same time knowing that it is wrong, may be most easily resolved by sticking to the original idea and ignoring the retraction.</p>
</sec>
<sec id="section17-1529100612451018">
<title>Retrieval failure</title>
<p>Another explanation for the continued influence of misinformation is the failure of controlled memory processes. First, misinformation effects could be based on source confusion or misattribution (<xref ref-type="bibr" rid="bibr88-1529100612451018">M. K. Johnson, Hashtroudi, &amp; Lindsay, 1993</xref>). People may correctly recollect a specific detail—in the case of the story of the fire discussed earlier, they may remember that it was assumed the fire was caused by oil and paints—but incorrectly attribute this information to the wrong source. For example, people could falsely recollect that this information was contained in the final police report rather than an initial report that was subsequently retracted.</p>
<p>Second, misinformation effects could be due to a failure of strategic monitoring processes (<xref ref-type="bibr" rid="bibr134-1529100612451018">Moscovitch &amp; Melo, 1997</xref>). <xref ref-type="bibr" rid="bibr7-1529100612451018">Ayers and Reder (1998)</xref> have argued that both valid and invalid memory entries compete for automatic activation, but that contextual integration requires strategic processing. In other words, it is reasonable to assume that a piece of misinformation that supplies a plausible account of an event will be activated when a person is questioned about the event. A strategic monitoring process is then required to determine the validity of this automatically retrieved piece of information. This may be the same monitoring process involved in source attribution, whereby people decide whether a memory is valid and put into the correct encoding context, or whether it was received from a reliable source (<xref ref-type="bibr" rid="bibr75-1529100612451018">Henkel &amp; Mattson, 2011</xref>).</p>
<p>Third, there is some evidence that processing retractions can be likened to attaching a “negation tag” to a memory entry (e.g., “there were oil paints and gas cylinders—NOT”; <xref ref-type="bibr" rid="bibr59-1529100612451018">Gilbert et al., 1990</xref>; <xref ref-type="bibr" rid="bibr86-1529100612451018">H. M. Johnson &amp; Seifert, 1998</xref>). <xref ref-type="bibr" rid="bibr86-1529100612451018">H. M. Johnson and Seifert (1998)</xref> showed that the automatic activation of misinformation in memory continues whenever it is referred to, even after a clear correction. For example, after reading, “John played hockey for New York. Actually, he played for Boston,” reading “the team” results in the activation of both cities in memory. The negation tag on the information can be lost, especially when strategic memory processing is impaired, as it can be in old age (<xref ref-type="bibr" rid="bibr212-1529100612451018">E. A. Wilson &amp; Park, 2008</xref>) or under high cognitive load (<xref ref-type="bibr" rid="bibr59-1529100612451018">Gilbert et al., 1990</xref>). From this perspective, negations should be more successful when they can be encoded as an affirmation of an alternative attribute (<xref ref-type="bibr" rid="bibr123-1529100612451018">Mayo, Schul, &amp; Burnstein, 2004</xref>). <xref ref-type="bibr" rid="bibr123-1529100612451018">Mayo and her colleagues (2004)</xref> found support for this possibility in the domain of person perception. For example, the information that Jim is “not messy” allows an affirmative encoding, “Jim is tidy,” incorporating the polar opposite of “messy”; in contrast, learning that Jim is “not charismatic” does not offer an alternative encoding because of the unipolar nature of the trait “charismatic.” Accordingly, Mayo et al. found that people were more likely to misremember unipolar traits (e.g., remembering “not charismatic” as “charismatic”) than bipolar traits (e.g., “not messy” was rarely misremembered as “messy,” presumably because “not messy” was recoded as “tidy” during encoding).</p>
</sec>
<sec id="section18-1529100612451018">
<title>Fluency and familiarity</title>
<p>Whereas the preceding accounts focus on whether people are more likely to recall a piece of misinformation or its correction, a <italic>fluency</italic> approach focuses on the experience of processing the two types of information upon later reexposure (<xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>). Without direct questions about truth values, people may rely on their metacognitive experience of fluency during thinking about an event to assess plausibility of their thoughts, a process that would give well-formed, coherent models an advantage—as long as thoughts flow smoothly, people may see little reason to question their veracity (<xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>). From this perspective, misinformation can exert an influence by increasing the perceived familiarity and coherence of related material encountered later in time. As a result, retractions may fail, or even backfire (i.e., by entrenching the initial misinformation), if they directly or indirectly repeat false information in order to correct it, thus further enhancing its familiarity.</p>
<p>For example, correcting an earlier account by explaining that there were <italic>no</italic> oil paints and gas cylinders present requires the repetition of the idea that “paints and gas were present.” Generally, repetition of information strengthens that information in memory and thus strengthens belief in it, simply because the repeated information seems more familiar or is associated with different contexts that can serve as later retrieval cues (<xref ref-type="bibr" rid="bibr2-1529100612451018">Allport &amp; Lepkin, 1945</xref>; <xref ref-type="bibr" rid="bibr40-1529100612451018">Eakin, Schreiber, &amp; Sergent-Marshall, 2003</xref>; <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, &amp; Chang, 2011</xref>; <xref ref-type="bibr" rid="bibr75-1529100612451018">Henkel &amp; Mattson, 2011</xref>; <xref ref-type="bibr" rid="bibr132-1529100612451018">Mitchell &amp; Zaragoza, 1996</xref>; <xref ref-type="bibr" rid="bibr184-1529100612451018">Schul &amp; Mazursky, 1990</xref>; <xref ref-type="bibr" rid="bibr206-1529100612451018">Verkoeijen, Rikers, &amp; Schmidt, 2004</xref>; <xref ref-type="bibr" rid="bibr220-1529100612451018">Zaragoza &amp; Mitchell, 1996</xref>). It follows that when people later reencounter the misinformation (e.g., “oil paints and gas cylinders were present”), it may be more familiar to them than it would have been without the retraction, leading them to think, “I’ve heard that before, so there’s probably something to it.” This impairs the effectiveness of public-information campaigns intended to correct misinformation (<xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>).</p>
<p>A common format for such campaigns is a “myth versus fact” approach that juxtaposes a given piece of false information with a pertinent fact. For example, the U.S. Centers for Disease Control and Prevention offer patient handouts that counter an erroneous health-related belief (e.g., “The side effects of flu vaccination are worse than the flu”) with relevant facts (e.g., “Side effects of flu vaccination are rare and mild”). When recipients are tested immediately after reading such hand-outs, they correctly distinguish between myths and facts, and report behavioral intentions that are consistent with the information provided (e.g., an intention to get vaccinated). However, a short delay is sufficient to reverse this effect: After a mere 30 minutes, readers of the handouts identify more “myths” as “facts” than do people who never received a handout to begin with (<xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>). Moreover, people’s behavioral intentions are consistent with this confusion: They report fewer vaccination intentions than people who were not exposed to the handout.</p>
<p>Because recollective memory shows more age-related impairment than familiarity-based memory does (<xref ref-type="bibr" rid="bibr79-1529100612451018">Jacoby, 1999</xref>), older adults (and potentially children) are particularly vulnerable to these backfire effects because they are more likely to forget the details of a retraction and retain only a sense of familiarity about it (<xref ref-type="bibr" rid="bibr11-1529100612451018">Bastin &amp; Van Der Linden, 2005</xref>; <xref ref-type="bibr" rid="bibr77-1529100612451018">Holliday, 2003</xref>; <xref ref-type="bibr" rid="bibr79-1529100612451018">Jacoby, 1999</xref>). Hence, they are more likely to accept a statement as true after exposure to explicit messages that it is false (<xref ref-type="bibr" rid="bibr192-1529100612451018">Skurnik, Yoon, Park, &amp; Schwarz, 2005</xref>; <xref ref-type="bibr" rid="bibr212-1529100612451018">E. A. Wilson &amp; Park, 2008</xref>).</p>
<p>A similar effect has recently been reported in the very different field of corporate-event sponsorship. Whereas some companies spend large amounts of money to be officially associated with a certain event, such as the Olympic Games, other companies try to create the impression of official affiliation without any sponsorship (and hence without expenditure on their part), a strategy known as “ambushing.” Not only is this strategy successful in associating a brand with an event, but attempts to publically expose a company’s ambushing attempt (i.e., “counter-ambushing”) may lead people to remember the feigned brand-to-event association even better (<xref ref-type="bibr" rid="bibr78-1529100612451018">Humphreys et al., 2010</xref>).</p>
</sec>
<sec id="section19-1529100612451018">
<title>Reactance</title>
<p>Finally, retractions can be ineffective because of social reactance (<xref ref-type="bibr" rid="bibr21-1529100612451018">Brehm &amp; Brehm, 1981</xref>). People generally do not like to be told what to think and how to act, so they may reject particularly authoritative retractions. For this reason, misinformation effects have received considerable research attention in a courtroom setting where mock jurors are presented with a piece of evidence that is later ruled inadmissible. When the jurors are asked to disregard the tainted evidence, their conviction rates are <italic>higher</italic> when an “inadmissible” ruling was accompanied by a judge’s extensive legal explanations than when the inadmissibility was left unexplained (<xref ref-type="bibr" rid="bibr160-1529100612451018">Pickel, 1995</xref>, <xref ref-type="bibr" rid="bibr216-1529100612451018">Wolf &amp; Montgomery, 1977</xref>). (For a review of the literature on how jurors process inadmissible evidence, see <xref ref-type="bibr" rid="bibr114-1529100612451018">Lieberman &amp; Arndt, 2000</xref>.)</p>
</sec>
</sec>
<sec id="section20-1529100612451018">
<title>Reducing the Impact of Misinformation</title>
<p>So far, we have shown that simply retracting a piece of information will not stop its influence. A number of other techniques for enhancing the effectiveness of retractions have been explored, but many have proven unsuccessful. Examples include enhancing the clarity of the retraction (<xref ref-type="bibr" rid="bibr190-1529100612451018">Seifert, 2002</xref>; <xref ref-type="bibr" rid="bibr204-1529100612451018">van Oostendorp, 1996</xref>) and presenting the retraction immediately after the misinformation to prevent inferences based on it before correction occurs (<xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>; <xref ref-type="bibr" rid="bibr210-1529100612451018">Wilkes &amp; Reynolds, 1999</xref>).</p>
<p>To date, only three factors have been identified that can increase the effectiveness of retractions: (a) warnings at the time of the initial exposure to misinformation, (b) repetition of the retraction, and (c) corrections that tell an alternative story that fills the coherence gap otherwise left by the retraction.</p>
<sec id="section21-1529100612451018">
<title>Preexposure warnings</title>
<p>Misinformation effects can be reduced if people are explicitly warned up front that information they are about to be given may be misleading (<xref ref-type="bibr" rid="bibr26-1529100612451018">Chambers &amp; Zaragoza, 2001</xref>; <xref ref-type="bibr" rid="bibr44-1529100612451018">Ecker et al., 2010</xref>; <xref ref-type="bibr" rid="bibr95-1529100612451018">Jou &amp; Foreman, 2007</xref>; <xref ref-type="bibr" rid="bibr182-1529100612451018">Schul, 1993</xref>). <xref ref-type="bibr" rid="bibr44-1529100612451018">Ecker et al. (2010)</xref> found, however, that to be effective, such warnings need to specifically explain the ongoing effects of misinformation rather than just generally mention that misinformation may be present (as in <xref ref-type="bibr" rid="bibr120-1529100612451018">Marsh &amp; Fazio, 2006</xref>). This result has obvious application: In any situation in which people are likely to encounter misinformation—for example, in advertising, in fiction that incorporates historical or pseudoscientific information, or in court settings, where jurors often hear information they are later asked to disregard—warnings could be given routinely to help reduce reliance on misinformation.</p>
<p>Warnings seem to be more effective when they are administered before the misinformation is encoded rather than after (<xref ref-type="bibr" rid="bibr26-1529100612451018">Chambers &amp; Zaragoza, 2001</xref>; <xref ref-type="bibr" rid="bibr44-1529100612451018">Ecker et al., 2010</xref>; <xref ref-type="bibr" rid="bibr182-1529100612451018">Schul, 1993</xref>). This can be understood in terms of Gricean maxims about communication (<xref ref-type="bibr" rid="bibr67-1529100612451018">Grice, 1975</xref>): People by default expect the information presented to be valid, but an a priori warning can change that expectation. Such a warning would allow recipients to monitor the encoded input and “tag” it as suspect. Consistent with this notion, <xref ref-type="bibr" rid="bibr182-1529100612451018">Schul (1993)</xref> found that people took longer to process misinformation when they had been warned about it, which suggests that, rather than quickly dismissing false information, people took care to consider the misinformation within an alternative mental model. Warnings may induce a temporary state of skepticism, which may maximize people’s ability to discriminate between true and false information. Later in this article, we return to the issue of skepticism and show how it can facilitate the detection of misinformation.</p>
<p>The fact that warnings are still somewhat effective <italic>after</italic> misinformation is encoded supports a dual-process view of misinformation retrieval, which assumes that a strategic monitoring process can be used to assess the validity of automatically retrieved pieces of misinformation (<xref ref-type="bibr" rid="bibr44-1529100612451018">Ecker et al., 2010</xref>). Because this monitoring requires effort and cognitive resources, warnings may be effective in prompting recipients of information to be vigilant.</p>
</sec>
<sec id="section22-1529100612451018">
<title>Repeated retractions</title>
<p>The success of retractions can also be enhanced if they are repeated or otherwise strengthened. <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, and Chang (2011)</xref> found that if misinformation was encoded repeatedly, repeating the retraction helped alleviate (but did not eliminate) misinformation effects. However, misinformation that was encoded only once persisted to the same extent whether one retraction or three retractions were given. This means that even after only weak encoding, misinformation effects are extremely hard to eliminate or drive below a certain level of irreducible persistence, irrespective of the strength of subsequent retractions.</p>
<p>There are a number of reasons why this could be the case. First, some misinformation effects may arise from automatic processing, which can be counteracted by strategic control processes only to the extent that people are aware of the automatic influence of misinformation on their reasoning (cf. <xref ref-type="bibr" rid="bibr213-1529100612451018">T. D. Wilson &amp; Brekke, 1994</xref>). Second, inferences based on misinformation may rely on a sample of the memory representations of that misinformation, and each of these representations may be offset (thereby having its impact reduced, but not eliminated) by only one retraction. Once a memory token has been associated with a “retracted” marker, further retractions do not appear to strengthen that marker; therefore, repeated retractions do not further reduce reliance on weakly encoded misinformation because weak encoding means only a single representation is created, whereas the multiple representations that arise with strong encoding can benefit from strong (i.e., multiple) retractions. (For a computational implementation of this sampling model, see <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, &amp; Chang, 2011</xref>.) Finally, the repetition of corrections may ironically decrease their effectiveness. On the one hand, some evidence suggests a “protest-too-much” effect, whereby overexerting a correction may reduce confidence in its veracity (<xref ref-type="bibr" rid="bibr22-1529100612451018">Bush, Johnson, &amp; Seifert, 1994</xref>). On the other hand, as noted above, corrections may paradoxically enhance the impact of misinformation by repeating it in retractions (e.g., <xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>).</p>
<p>Whatever the underlying cognitive mechanism, the findings of <xref ref-type="bibr" rid="bibr43-1529100612451018">Ecker, Lewandowsky, Swire, &amp; Chang, (2011)</xref> suggest that the repetition of initial misinformation has a stronger and more reliable (negative) effect on subsequent inferences than the repetition of its retraction does. This asymmetry in repetition effects is particularly unfortunate in the domain of social networking media, which allow information to be disseminated quickly, widely, and without much fact-checking, and to be taken only from sources consonant with particular worldviews.</p>
</sec>
<sec id="section23-1529100612451018">
<title>Filling the gap: Providing an alternative narrative</title>
<p>We noted earlier that retractions can cause a coherence gap in the recipient’s understanding of an event. Given that internal coherence plays a key role in truth assessments (<xref ref-type="bibr" rid="bibr92-1529100612451018">Johnson-Laird, 2012</xref>; <xref ref-type="bibr" rid="bibr154-1529100612451018">Pennington &amp; Hastie, 1993</xref>), the resulting gap may motivate reliance on misinformation in spite of a retraction (e.g., “It wasn’t the oil and gas, but what else could it be?”). Providing an alternative causal explanation of the event can fill the gap left behind by retracting misinformation. Studies have shown that the continued influence of misinformation can be eliminated through the provision of an alternative account that explains <italic>why</italic> the information was incorrect (e.g., “There were no gas cylinders and oil paints, but arson materials have been found”; “The initial suspect may not be guilty, as there is an alternative suspect”; <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>; <xref ref-type="bibr" rid="bibr198-1529100612451018">Tenney, Cleary, &amp; Spellman, 2009</xref>).</p>
<p>To successfully replace the misinformation, the alternative explanation provided by the correction must be plausible, account for the important causal qualities in the initial report, and, ideally, explain why the misinformation was thought to be correct in the first place (e.g., <xref ref-type="bibr" rid="bibr172-1529100612451018">Rapp &amp; Kendeou, 2007</xref>; <xref ref-type="bibr" rid="bibr184-1529100612451018">Schul &amp; Mazursky, 1990</xref>; <xref ref-type="bibr" rid="bibr190-1529100612451018">Seifert, 2002</xref>). For example, noting that the suspected WMD sites in Iraq were actually grain silos would not explain why the initial report that they housed WMDs occurred, so this alternative might be ineffective. An alternative will be more compelling if it covers the causal bases of the initial report. For example, an account might state that a suspected WMD site was actually a chemical factory, which would be more plausible because a chemical factory—unlike a grain silo—may contain components that also occur in WMDs (cf. <xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>). A correction may also be more likely to be accepted if it accounts for why the initial incorrect information was offered—for example, by stating that WMDs <italic>had</italic> been present in Iraq, but were destroyed before 2003.</p>
<p>Corrections can be particularly successful if they explain the motivation behind an incorrect report. For example, one might argue that the initial reports of WMDs facilitated the U.S. government’s intention to invade Iraq, so the misinformation was offered without sufficient evidence (i.e., government officials were “trigger-happy”; cf. <xref ref-type="bibr" rid="bibr112-1529100612451018">Lewandowsky, Stritzke, Oberauer, &amp; Morales, 2005</xref>, <xref ref-type="bibr" rid="bibr113-1529100612451018">2009</xref>). Drawing attention to a source’s motivation can undermine the impact of misinformation. For example, Governor Ronald Reagan defused President Jimmy Carter’s attack on his Medicare policies in a 1980 U.S. presidential debate by stating, “There you go again!”; by framing information as what would be “expected” from its source, Reagan discredited it (<xref ref-type="bibr" rid="bibr30-1529100612451018">Cialdini, 2001</xref>).</p>
<p>Some boundary conditions apply to the alternative-account technique. The mere mention, or self-generation, of alternative ideas is insufficient to reduce reliance on misinformation (<xref ref-type="bibr" rid="bibr85-1529100612451018">H. M. Johnson &amp; Seifert, 1994</xref>, <xref ref-type="bibr" rid="bibr87-1529100612451018">1999</xref>; <xref ref-type="bibr" rid="bibr190-1529100612451018">Seifert, 2002</xref>). That is, the alternative must be integrated into the existing information from the same source.</p>
<p>Also, people generally prefer simple explanations over complex explanations (<xref ref-type="bibr" rid="bibr27-1529100612451018">Chater &amp; Vitanyi, 2003</xref>; <xref ref-type="bibr" rid="bibr116-1529100612451018">Lombrozo, 2006</xref>, <xref ref-type="bibr" rid="bibr117-1529100612451018">2007</xref>). When misinformation is corrected with an alternative, but much more complex, explanation, people may reject it in favor of a simpler account that maintains the misinformation. Hence, providing too many counterarguments, or asking people to generate many counterarguments, can potentially backfire (<xref ref-type="bibr" rid="bibr180-1529100612451018">Sanna, Schwarz, &amp; Stocker, 2002</xref>; <xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>). This “overkill” backfire effect can be avoided by asking people to generate only a few arguments regarding why their belief may be wrong; in this case, the self-generation of the counterarguments can assist debiasing (<xref ref-type="bibr" rid="bibr179-1529100612451018">Sanna &amp; Schwarz, 2006</xref>). Moreover, suspicion about the rationale behind the correction, as well as for the rationale behind the initial presentation of the misinformation, may be particularly important in the case of corrections of political misinformation. Specific motivations likely underlie politicians’ explanations for events, so people may place more suspicion on alternative explanations from these sources.</p>
<p>In summary, the continued influence of misinformation can be reduced with three established techniques: (a) People can be warned about the potentially misleading nature of forthcoming information before it is presented; (b) corrections can be repeated to strengthen their efficacy; and (c) corrections can be accompanied by alternative explanations for the event in question, thus preventing causal gaps in the account. The last technique is particularly effective; however, it is not always possible, because an alternative explanation may not be available when an initial report is found to be in error. In addition, further complications arise when corrections of misinformation challenge the recipients’ worldview more broadly, as we discuss in the following section.</p>
</sec>
</sec>
<sec id="section24-1529100612451018">
<title>Corrections in the Face of Existing Belief Systems: Worldview and Skepticism</title>
<p>Recipients’ individual characteristics play an important role in determining whether misinformation continues to exert an influence. Here, we address two such characteristics—namely, worldview and level of skepticism—that exert opposing effects on the efficacy of corrections.</p>
<sec id="section25-1529100612451018">
<title>Worldview</title>
<p>Given that people more readily accept statements that are consistent with their beliefs, it is not surprising that people’s worldview, or personal ideology, plays a key role in the persistence of misinformation. For example, Republicans are more likely than Democrats to continue to believe the “birthers” and to accept claims about the presence of WMDs in Iraq despite retractions (<xref ref-type="bibr" rid="bibr103-1529100612451018">Kull et al., 2003</xref>; <xref ref-type="bibr" rid="bibr203-1529100612451018">Travis, 2010</xref>). At the opposite end of the political spectrum, liberals are less accurate than conservatives when it comes to judging the consequences of higher oil prices. In particular, whereas experts foresee considerable future risks to human health and society arising from “peak oil” (<xref ref-type="bibr" rid="bibr185-1529100612451018">Schwartz, Parker, Hess, &amp; Frumkin, 2011</xref>), surveys have shown that liberals are less likely than conservatives to recognize the magnitude of these risks (<xref ref-type="bibr" rid="bibr138-1529100612451018">Nisbet, Maibach, &amp; Leiserowitz, 2011</xref>).<sup><xref ref-type="fn" rid="fn2-1529100612451018">2</xref></sup></p>
<p>From this real-world survey research, we know that people’s preexisting attitudes often determine their level of belief in misinformation after it has been retracted. What is less well understood is whether retractions (a) fail to reduce reliance on misinformation specifically among people for whom the retraction violates personal belief or (b) are equally effective for all people, with observed post-retraction differences in belief only mirroring pre-retraction differences. Both possibilities are consistent with the literature on truth assessments discussed earlier. Compared with worldview-congruent retractions, retractions that contradict one’s worldview are inconsistent with other beliefs, less familiar, more difficult to process, less coherent, less supported in one’s social network, and more likely to be viewed as coming from an untrustworthy source. All of these factors may undermine the apparent truth value of a retraction that challenges one’s belief system. Conversely, misinformation consistent with one’s worldview fits with other beliefs, and is therefore more familiar, easier to process, more coherent, more supported in one’s network, and more likely to be viewed as coming from a trusted source. Accordingly, worldview-based differences in the effectiveness of retractions may reflect the differential appeal of the misinformation, the retraction, or both. The evidence concerning these distinctions is sparse and mixed.</p>
<p>In one study, people with high and low levels of racial prejudice were presented with a narrative about a robbery involving an indigenous Australian who was either the suspect of a crime (in one experiment) or a hero who prevented the crime (in another experiment; <xref ref-type="bibr" rid="bibr42-1529100612451018">Ecker, Lewandowsky, Fenton, &amp; Martin, 2012</xref>). People’s references to the racial information covaried with their racial attitudes; that is, people who were prejudiced mentioned the indigenous suspect more often and the indigenous hero less often. However, this effect was found irrespective of whether a retraction had been offered, indicating that the retraction was equally effective for low- and high-prejudice participants. Similarly, in a study in which a fictitious plane crash was initially attributed to a terrorist bomb before participants received a correction clarifying that a later investigation revealed a faulty fuel tank as the cause, participants with high levels of Islamophobia mentioned terrorism-related material more often on a subsequent inference test than their counterparts who scored lower on Islamophobia did, although a retraction was equally effective for both groups (unpublished analysis of <xref ref-type="bibr" rid="bibr41-1529100612451018">Ecker, Lewandowsky, &amp; Apai, 2011</xref>).</p>
<p>In contrast to these findings, reports from other studies have indicated that worldviews affect how people process corrective messages. In one study, retractions of nonfictitious misperceptions (e.g., the mistaken belief that President Bush’s tax cuts in the early 2000s had increased revenues; the idea that there were WMDs in Iraq) were effective only among people whose political orientation was supported by the retraction (<xref ref-type="bibr" rid="bibr141-1529100612451018">Nyhan &amp; Reifler, 2010</xref>). When the corrections were worldview-dissonant (in this case, for Republican participants), a “backfire” effect was observed, such that participants became <italic>more</italic> committed to the misinformation. <xref ref-type="bibr" rid="bibr71-1529100612451018">Hart and Nisbet (2011)</xref> reported a similar backfire effect using stimuli related to climate change. In their study, people were presented with messages highlighting the adverse effects on health caused by climate change. Compared with a control group, Democrats who received these messages were found to increase their support for climate mitigation policies, whereas support declined among Republicans.</p>
<p>The sway that people’s worldview holds over their perceptions and cognitions can be illustrated through a consideration of some other instances of polarization. <xref ref-type="bibr" rid="bibr64-1529100612451018">Gollust, Lantz, and Ubel (2009)</xref> showed that even public-health messages can have a polarizing effect along party lines: When people were presented with evidence that Type 2 diabetes can be caused by social circumstances (e.g., a scarcity of healthy food combined with an abundance of junk food in poor neighborhoods), subsequent endorsement of potential policy options (e.g., banning fast-food concessions in public schools) was found to decline among Republicans but to increase among Democrats in comparison with a control group that did not receive any information about the causes of diabetes. <xref ref-type="bibr" rid="bibr17-1529100612451018">Berinsky (2012)</xref> reported similar polarizing effects in experiments in which the death-panel myth surrounding President Obama’s health plan was rebutted.</p>
<p>The role of personal worldview may not be limited to the effects of misinformation regarding political issues: When people who felt a high degree of connection with their favorite brand were provided with negative information about the brand, they reported reduced self-esteem but retained their positive brand image, whereas the self-esteem of those with a low degree of personal connection to brands remained unchanged (<xref ref-type="bibr" rid="bibr28-1529100612451018">Cheng, White, &amp; Chaplin, 2011</xref>).</p>
<p>What boundary conditions limit the influence of one’s worldview on one’s acceptance of corrections? The study by <xref ref-type="bibr" rid="bibr42-1529100612451018">Ecker, Lewandowsky, Fenton, and Martin (2012)</xref> involved fictitious events that contained attitude-relevant information, whereas the studies just discussed involved real-world events and politicians about which people likely had preexisting opinions (<xref ref-type="bibr" rid="bibr141-1529100612451018">Nyhan &amp; Reifler, 2010</xref>). We therefore suggest that worldview affects the effectiveness of a retraction when the misinformation concerns a real-world event that relates to preexisting beliefs (e.g., it is harder to accept that the report of WMDs in Iraq was false if one supported the 2003 invasion). In confirmation of this idea, the political-science literature contains reports of people being sensitive to factual or corrective information on issues that arguably lack salience and emotiveness (<xref ref-type="bibr" rid="bibr8-1529100612451018">Barabas &amp; Jerit, 2009</xref>; <xref ref-type="bibr" rid="bibr19-1529100612451018">Blais et al., 2010</xref>; <xref ref-type="bibr" rid="bibr54-1529100612451018">Gaines, Kuklinski, Quirk, Peyton, &amp; Verkuilen, 2007</xref>; for a review of that literature, see <xref ref-type="bibr" rid="bibr143-1529100612451018">Nyhan &amp; Reifler, 2012</xref>). These findings suggest that not all political issues necessarily lead to polarization.</p>
</sec>
<sec id="section26-1529100612451018">
<title>Making things worse: Backfire effects</title>
<p>From a societal view, misinformation is particularly damaging if it concerns complex real-world issues, such as climate change, tax policies, or the decision to go to war. The preceding discussion suggests that in such real-world scenarios, people will refer more to misinformation that is in line with their attitudes <italic>and</italic> will be relatively immune to corrections, such that retractions may even backfire and strengthen the initially held beliefs (<xref ref-type="bibr" rid="bibr141-1529100612451018">Nyhan &amp; Reifler, 2010</xref>). This backfire effect has been attributed to a process by which people implicitly counterargue against any information that challenges their worldview. <xref ref-type="bibr" rid="bibr165-1529100612451018">Prasad et al. (2009)</xref> illuminated this counterarguing process particularly strikingly by using a “challenge interview” technique, asking participants to respond aloud to information that debunked their preexisting beliefs. Participants either came up with counterarguments or simply remained unmovable (e.g., as illustrated by responses like “I guess we still can have our opinions and feel that way even though they say that”). These findings mesh well with the work on “motivated skepticism” by <xref ref-type="bibr" rid="bibr197-1529100612451018">Taber and Lodge (2006)</xref>, which has shown similar responses to challenges to political opinions (as opposed to facts). In their study, people uncritically accepted arguments for their own position but were highly skeptical of opposing arguments, and they actively used counterarguments to deride or invalidate worldview-incongruent information (as revealed through protocol analysis).</p>
<p>Such backfire effects, also known as “boomerang” effects, are not limited to the correction of misinformation but also affect other types of communication. For example, messages intended to promote positive health behaviors can backfire, such that campaigns to reduce smoking may ironically lead to an increase in smoking rates (for a review, see <xref ref-type="bibr" rid="bibr23-1529100612451018">Byrne &amp; Hart, 2009</xref>). In other areas of research, backfire effects have been linked to people not only rejecting the message at hand but also becoming predisposed to reject any future messages from its source (<xref ref-type="bibr" rid="bibr21-1529100612451018">Brehm &amp; Brehm, 1981</xref>). If generalizations of source distrust may occur in the context of corrections of misinformation, their potential existence is cause for concern.</p>
<p>A phenomenon that is closely related to the backfire effects arising with worldview-dissonant corrections involves <italic>belief polarization</italic>. Belief polarization is said to occur if presentation of the same information elicits further attitudinal divergence between people with opposing views on an issue (<xref ref-type="bibr" rid="bibr118-1529100612451018">Lord, Ross, &amp; Lepper, 1979</xref>). For example, when both religious believers and nonbelievers were exposed to a fictitious report disproving the Biblical account of the resurrection, belief increased among believers, whereas nonbelievers became more skeptical (<xref ref-type="bibr" rid="bibr12-1529100612451018">Batson, 1975</xref>). This increased belief among believers is isomorphic to the worldview backfire effect in response to corrective information.</p>
<p>In another example, supporters and opponents of nuclear power reacted in opposite fashion to identical descriptions of technological breakdowns at a nuclear plant: Whereas supporters focused on the fact that the safeguards worked to prevent the accident from being worse, opponents focused on the fact that the breakdown occurred in the first place (<xref ref-type="bibr" rid="bibr162-1529100612451018">Plous, 1991</xref>). Not unexpectedly, techniques for reducing belief polarization are highly similar to techniques for overcoming worldview-related resistance to corrections of misinformation.</p>
<p>Feelings of affiliation with a source also influence whether or not one accepts a piece of information at face value. For example, <xref ref-type="bibr" rid="bibr17-1529100612451018">Berinsky (2012)</xref> found that among Republicans, corrections of the death-panel myth were effective primarily when they were issued by a Republican politician. However, judgments of a source’s credibility are themselves a function of beliefs: If you believe a statement, you judge its source to be more credible (<xref ref-type="bibr" rid="bibr53-1529100612451018">Fragale &amp; Heath, 2004</xref>). This interaction between belief and credibility judgments can lead to an epistemic circularity, whereby no opposing information is ever judged sufficiently credible to overturn dearly held prior knowledge. For example, <xref ref-type="bibr" rid="bibr135-1529100612451018">Munro (2010)</xref> has shown that exposure to belief-threatening scientific evidence can lead people to discount the scientific method itself: People would rather believe that an issue cannot be resolved scientifically, thus discounting the evidence, than accept scientific evidence in opposition to their beliefs. Indeed, even high levels of education do not protect against the worldview-based rejection of information; for example, <xref ref-type="bibr" rid="bibr68-1529100612451018">Hamilton (2011)</xref> showed that a higher level of education made Democrats more likely to view global warming as a threat, whereas the reverse was true for Republicans. This constitutes an extreme case of belief polarization (see also <xref ref-type="bibr" rid="bibr119-1529100612451018">Malka, Krosnick, &amp; Langer, 2009</xref>; <xref ref-type="bibr" rid="bibr127-1529100612451018">McCright &amp; Dunlap, 2011</xref>). Similarly, among Republicans, greater education was associated with a greater increase in the belief that President Obama was a Muslim (he is not) between 2009 and 2010 (<xref ref-type="bibr" rid="bibr191-1529100612451018">Sides, 2010</xref>). Among Democrats, few held this mistaken belief, and education did not moderate the effect.</p>
<p>In summary, personal beliefs can facilitate the acquisition of attitude-consonant misinformation, increase reliance on misinformation, and inoculate against the correction of false beliefs (<xref ref-type="bibr" rid="bibr42-1529100612451018">Ecker et al., 2012</xref>; <xref ref-type="bibr" rid="bibr103-1529100612451018">Kull et al., 2003</xref>; <xref ref-type="bibr" rid="bibr112-1529100612451018">Lewandowsky et al., 2005</xref>, <xref ref-type="bibr" rid="bibr113-1529100612451018">2009</xref>; <xref ref-type="bibr" rid="bibr141-1529100612451018">Nyhan &amp; Reifler, 2010</xref>; <xref ref-type="bibr" rid="bibr151-1529100612451018">Pedersen, Clarke, Dudgeon, &amp; Griffiths, 2005</xref>; <xref ref-type="bibr" rid="bibr150-1529100612451018">Pedersen, Attwell, &amp; Heveli, 2007</xref>). Interestingly, the extent to which material is emotive does not appear to affect its persistence in memory after correction (<xref ref-type="bibr" rid="bibr41-1529100612451018">Ecker, Lewandowsky, &amp; Apai, 2011</xref>). For example, after a retraction of a report about the cause of a plane crash, people will mistakenly continue to refer to a “terrorist attack” as the cause just as often as “bad weather” or a “technical fault,” even when they are demonstrably more emotionally affected by the first. Thus, people do not simply cling to the most emotional version of an event. Although information that challenges people’s worldview is likely to elicit an emotive response, emotion by itself is not sufficient to alter people’s resistance to corrections.</p>
<p>One limitation of this conclusion is that worldview does not by itself serve as a process explanation. Although it is indubitably useful to be able to predict a person’s response to corrections on the basis of party affiliation or other indicators of worldview, it would be helpful if the cognitive processes underlying that link could be characterized in greater detail. Recent advances in illuminating those links have been promising (e.g., <xref ref-type="bibr" rid="bibr25-1529100612451018">Castelli &amp; Carraro, 2011</xref>; <xref ref-type="bibr" rid="bibr24-1529100612451018">Carraro, Castelli, &amp; Macchiella, 2011</xref>; <xref ref-type="bibr" rid="bibr94-1529100612451018">Jost, Glaser, Kruglanski, &amp; Sulloway, 2003b</xref>). It is possible that one’s worldview forms a frame of reference for determining, in <xref ref-type="bibr" rid="bibr159-1529100612451018">Piaget’s (1928)</xref> terms, whether to assimilate information or to accommodate it. If one’s investment in a consistent worldview is strong, changing that worldview to accommodate inconsistencies may be too costly or effortful. In a sense, the worldview may serve as a schema for processing related information (<xref ref-type="bibr" rid="bibr10-1529100612451018">Bartlett, 1977/1932</xref>), such that relevant factual information may be discarded or misinformation preserved.</p>
</sec>
<sec id="section27-1529100612451018">
<title>Taming worldview by affirming it</title>
<p>The research on preexisting attitudes and worldviews implies that debiasing messages and retractions must be tailored to their specific audience, preferably by ensuring that the correction is consonant with the audience’s worldview. For example, the work on “cultural cognition” by Kahan and colleagues (e.g., <xref ref-type="bibr" rid="bibr96-1529100612451018">Kahan, 2010</xref>) have repeatedly shown that framing solutions to a problem in worldview-consonant terms can enhance acceptance of information that would be rejected if it were differently framed. Thus, people who might oppose nanotechnology because they have an “eco-centric” outlook may be less likely to dismiss evidence of its safety if the use of nanotechnology is presented as part of an effort to protect the environment. Similarly, people who oppose climate science because it challenges their worldview may do so less if the response to climate change is presented as a business opportunity for the nuclear industry (cf. <xref ref-type="bibr" rid="bibr51-1529100612451018">Feygina, Jost, &amp; Goldsmith, 2010</xref>). Even simple changes in wording can make information more acceptable by rendering it less threatening to a person’s worldview. For example, Republicans are far more likely to accept an otherwise identical charge as a “carbon offset” than as a “tax,” whereas the wording has little effect on Democrats or Independents (whose values are not challenged by the word “tax”; <xref ref-type="bibr" rid="bibr69-1529100612451018">Hardisty, Johnson, &amp; Weber, 2010</xref>).</p>
<p>Another way in which worldview-threatening messages can be made more palatable involves coupling them with self-affirmation—that is, by giving recipients an opportunity to affirm their basic values as part of the correction process (<xref ref-type="bibr" rid="bibr32-1529100612451018">Cohen et al., 2007</xref>, <xref ref-type="bibr" rid="bibr142-1529100612451018">Nyhan &amp; Reifler, 2011</xref>). Self-affirmation can be achieved by asking people to write a few sentences about a time they felt especially good about themselves because they acted on a value that was important to them. Compared with people who received no affirmation, those who self-affirmed became more receptive to messages that otherwise might have threatened their worldviews. Self- affirmation may give the facts a fighting chance (<xref ref-type="bibr" rid="bibr32-1529100612451018">Cohen et al., 2007</xref>, <xref ref-type="bibr" rid="bibr142-1529100612451018">Nyhan &amp; Reifler, 2011</xref>) by helping people handle challenges to their worldviews. Intriguingly, self-affirmation also enables people who have a high personal connection to a favorite brand to process negative information about it appropriately (by lowering their evaluations of the brand rather than their own self-esteem; <xref ref-type="bibr" rid="bibr28-1529100612451018">Cheng et al., 2011</xref>).</p>
<p>Factors that assist people in handling inconsistencies in their personal perspectives may also help to promote acceptance of corrections. For example, distancing oneself from a self-focused perspective has been shown to promote wise reasoning (<xref ref-type="bibr" rid="bibr101-1529100612451018">Kross &amp; Grossmann, 2012</xref>) and may be helpful in processing corrections.</p>
</sec>
<sec id="section28-1529100612451018">
<title>Skepticism: A key to accuracy</title>
<p>We have reviewed how worldview and prior beliefs can exert a distorting influence on information processing. However, some attitudes can also safeguard against misinformation effects. In particular, <italic>skepticism</italic> can reduce susceptibility to misinformation effects if it prompts people to question the origins of information that may later turn out to be false. For example, people who questioned the official casus belli for the invasion of Iraq (destroying WMDs) have been shown to be more accurate in processing war-related information in general (<xref ref-type="bibr" rid="bibr112-1529100612451018">Lewandowsky et al., 2005</xref>). Suspicion or skepticism about the overall context (i.e., the reasons for the war) thus led to more accurate processing of specific information about the event in question. Importantly, in this instance, skepticism also ensured that correct information was recognized more accurately, and thus did not translate into cynicism or a blanket denial of <italic>all</italic> war-related information. In a courtroom setting, <xref ref-type="bibr" rid="bibr48-1529100612451018">Fein et al. (1997)</xref> showed that mock jurors who were asked to disregard a piece of inadmissible evidence were still influenced by the retracted evidence despite claiming they were not—unless they were made suspicious of the motives of the prosecutor who had introduced the evidence.</p>
<p>These findings mesh well with related research on trust. Although trust plays a fundamental role in most human relationships, and the presence of distrust is often corrosive (e.g., <xref ref-type="bibr" rid="bibr208-1529100612451018">Whyte &amp; Crease, 2010</xref>), there are situations in which distrust can have a positive function. For example, <xref ref-type="bibr" rid="bibr183-1529100612451018">Schul et al. (2008)</xref> showed that when they elicited distrust in participants by showing them a face that had been rated as “untrustworthy” by others, the participants were more likely to be able to solve nonroutine problems on a subsequent, completely unrelated task. By contrast, participants in whom trust was elicited performed much better on routine problems (but not nonroutine problems), a result suggesting that distrust causes people to explore their environment more carefully, which sensitizes them to the existence of nonroutine contingencies. Similarly, <xref ref-type="bibr" rid="bibr122-1529100612451018">Mayer and Mussweiler (2011)</xref> showed that priming people to be distrustful enhances their creativity in certain circumstances.</p>
<p>Taken together, these results suggest that a healthy sense of skepticism or induced distrust can go a long way in avoiding the traps of misinformation. These benefits seem to arise from the nonroutine, “lateral” information processing that is primed when people are skeptical or distrustful (<xref ref-type="bibr" rid="bibr122-1529100612451018">Mayer &amp; Mussweiler, 2011</xref>; <xref ref-type="bibr" rid="bibr183-1529100612451018">Schul et al., 2008</xref>). However, distrust and skepticism are most likely to exert an influence when they are experienced at the time of message exposure, and they do not always protect people from unreliable or intentionally misleading sources, particularly when a source’s motivation becomes apparent only after message encoding. Even when misinformation is identified as intentionally deceptive (as opposed to accidentally wrong) or as stemming from an unreliable source, its effects can prevail (<xref ref-type="bibr" rid="bibr65-1529100612451018">Green &amp; Donahue, 2011</xref>; <xref ref-type="bibr" rid="bibr75-1529100612451018">Henkel &amp; Mattson, 2011</xref>). For example, <xref ref-type="bibr" rid="bibr65-1529100612451018">Green and Donahue (2011)</xref> first presented people with a report that was found to change people’s attitudes about an issue (e.g., a report about a heroin-addicted child changed people’s attitudes toward the effectiveness of social youth-assistance programs). Participants then received a retraction stating that the report was inaccurate, either because of a mix-up (error condition) or because the author had made up most of the “facts” in order to sensationalize the report (deception condition). The results showed that participants were motivated to undo their attitudinal changes, especially in the deception condition, but that the effects of misinformation could not be undone in either condition. The misinformation had a continuing effect on participants’ attitudes even after a retraction established the author had made it up.</p>
</sec>
<sec id="section29-1529100612451018">
<title>Using misinformation to inform</title>
<p>Unlike brief interventions using the “myth-versus-fact” approach (<xref ref-type="bibr" rid="bibr189-1529100612451018">Schwarz et al., 2007</xref>), whose adverse implications we discussed earlier, it appears that a careful and prolonged dissection of incorrect arguments may facilitate the acquisition of correct information. To illustrate this point, <xref ref-type="bibr" rid="bibr99-1529100612451018">Kowalski and Taylor (2009)</xref> conducted a naturalistic experiment in which they compared a standard teaching format with an alternative approach in which lectures explicitly refuted 17 common misconceptions about psychology but left others unchallenged. The results showed that direct refutation was more successful in reducing misconceptions than was the nonrefutational provision of the same information. On the basis of a more extensive review of the literature, <xref ref-type="bibr" rid="bibr145-1529100612451018">Osborne (2010)</xref> likewise argued for the centrality of argumentation and rebuttal in science education, suggesting that classroom studies “show improvements in conceptual learning when students engage in argumentation” (p. 464).</p>
<p>Recent work has indicated that argumentation and engagement with an opponent can even work in the political arena (<xref ref-type="bibr" rid="bibr82-1529100612451018">Jerit, 2008</xref>). Jerit’s analysis of more than 40 opinion polls ran contrary to the conventional wisdom that to win a policy debate, political actors should selectively highlight issues that mobilize public opinion in favor of their position and not engage an opponent in dialogue. Taking the argumentation and refutation approach to an extreme, some have suggested that even explicit misinformation can be used as an effective teaching tool. <xref ref-type="bibr" rid="bibr13-1529100612451018">Bedford (2010)</xref> reported a case study in which students learned about climate science by studying “denialist” literature—that is, they acquired actual knowledge by analyzing material that contained misinformation in depth and by developing the skills required to detect the flaws in the material. In line with <xref ref-type="bibr" rid="bibr145-1529100612451018">Osborne’s (2010)</xref> review, an in-depth discussion of misinformation and its correction may assist people in working through inconsistencies in their understanding and promote the acceptance of corrections.</p>
</sec>
</sec>
<sec id="section30-1529100612451018">
<title>Debiasing in an Open Society</title>
<p>Knowledge about the processes underlying the persistence of misinformation and about how misinformation effects can be avoided or reduced is of obvious public interest. Today, information is circulated at a faster pace and in greater amounts than ever before in society, and demonstrably false beliefs continue to find traction in sizable segments of the populace. The development of workable debiasing and retraction techniques, such as those reviewed here, is thus of considerable practical importance.</p>
<p>Encouraging precedents for the effectiveness of using such techniques on a large scale have been reported in Rwanda (e.g., <xref ref-type="bibr" rid="bibr147-1529100612451018">Paluck, 2009</xref>), where a controlled, yearlong field experiment revealed that a radio soap opera built around messages of reducing intergroup prejudice, violence, and survivors’ trauma altered listeners’ perceptions of social norms and their behavior—albeit not their beliefs—in comparison with a control group exposed to a health-focused soap opera. This field study confirmed that large-scale change <italic>can</italic> be achieved using conventional media. (Paluck’s experiment involved delivery of the program via tape recorders, but this was for reasons of experimental control and convenience, and it closely mimicked the way in which radio programs are traditionally consumed by Rwandans.)</p>
<sec id="section31-1529100612451018">
<title>Concise recommendations for practitioners</title>
<p>The literature we have reviewed thus far may appear kaleidoscopic in its complexity. Indeed, a full assessment of the debiasing literature must consider numerous nuances and subtleties, which we aimed to cover in the preceding sections. However, it is nonetheless possible to condense the core existing knowledge about debiasing into a limited set of recommendations that can be of use to practitioners.<sup><xref ref-type="fn" rid="fn3-1529100612451018">3</xref></sup></p>
<p>We summarize the main points from the literature in <xref ref-type="fig" rid="fig1-1529100612451018">Figure 1</xref> and in the following list of recommendations:</p>
<list id="list2-1529100612451018" list-type="bullet">
<list-item><p>Consider what gaps in people’s mental event models are created by debunking and fill them using an alternative explanation.</p></list-item>
<list-item><p>Use repeated retractions to reduce the influence of misinformation, but note that the risk of a backfire effect increases when the original misinformation is repeated in retractions and thereby rendered more familiar.</p></list-item>
<list-item><p>To avoid making people more familiar with misinformation (and thus risking a familiarity backfire effect), emphasize the facts you wish to communicate rather than the myth.</p></list-item>
<list-item><p>Provide an explicit warning before mentioning a myth, to ensure that people are cognitively on guard and less likely to be influenced by the misinformation.</p></list-item>
<list-item><p>Ensure that your material is simple and brief. Use clear language and graphs where appropriate. If the myth is simpler and more compelling than your debunking, it will be cognitively more attractive, and you will risk an overkill backfire effect.</p></list-item>
<list-item><p>Consider whether your content may be threatening to the worldview and values of your audience. If so, you risk a worldview backfire effect, which is strongest among those with firmly held beliefs. The most receptive people will be those who are not strongly fixed in their views.</p></list-item>
<list-item><p>If you must present evidence that is threatening to the audience’s worldview, you may be able to reduce the worldview backfire effect by presenting your content in a worldview-affirming manner (e.g., by focusing on opportunities and potential benefits rather than risks and threats) and/or by encouraging self-affirmation.</p></list-item>
<list-item><p>You can also circumvent the role of the audience’s worldview by focusing on behavioral techniques, such as the design of choice architectures, rather than overt debiasing.</p></list-item>
</list>
<fig id="fig1-1529100612451018" position="float">
<label>Fig. 1.</label>
<caption>
<p>A graphical summary of findings from the misinformation literature relevant to communication practitioners. The left-hand column summarizes the cognitive problems associated with misinformation, and the right-hand column summarizes the solutions reviewed in this article.</p>
</caption>
<graphic xlink:href="10.1177_1529100612451018-fig1.tif"/></fig>
</sec>
</sec>
<sec id="section32-1529100612451018">
<title>Future Directions</title>
<p>Our survey of the literature has enabled us to provide a range of recommendations and draw some reasonably strong conclusions. However, our survey has also identified a range of issues about which relatively little is known, and which deserve future research attention. We wish to highlight three such issues in particular—namely, the roles played by emotion, individual differences (e.g., race or culture), and social networks in misinformation effects.</p>
<p>Concerning emotion, we have discussed how misinformation effects arise independently of the emotiveness of the information (<xref ref-type="bibr" rid="bibr41-1529100612451018">Ecker, Lewandowsky, &amp; Apai, 2011</xref>). But we have also noted that the likelihood that people will pass on information is based strongly on the likelihood of its eliciting an emotional response in the recipient, rather than its truth value (e.g., <xref ref-type="bibr" rid="bibr156-1529100612451018">K. Peters et al., 2009</xref>), which means that the emotiveness of misinformation may have an indirect effect on the degree to which it spreads (and persists). Moreover, the effects of worldview that we reviewed earlier in this article provide an obvious departure point for future work on the link between emotion and misinformation effects, because challenges to people’s worldviews tend to elicit highly emotional defense mechanisms (cf. <xref ref-type="bibr" rid="bibr155-1529100612451018">E. M. Peters, Burraston, &amp; Mertz, 2004</xref>).</p>
<p>Concerning individual differences, research has already touched on how responses to the same information differ depending on people’s personal worldviews or ideology (<xref ref-type="bibr" rid="bibr42-1529100612451018">Ecker et al., 2012</xref>; <xref ref-type="bibr" rid="bibr96-1529100612451018">Kahan, 2010</xref>), but remarkably little is known about the effects of other individual-difference variables. Intelligence, memory capacity, memory-updating abilities, and tolerance for ambiguity are just a few factors that could potentially mediate misinformation effects.</p>
<p>Finally, concerning social networks, we have already pointed to the literature on the creation of cyber-ghettos (e.g., <xref ref-type="bibr" rid="bibr91-1529100612451018">T. J. Johnson et al., 2009</xref>), but considerable research remains to be done to develop a full understanding of the processes of (mis-)information dissemination through complex social networks (cf. <xref ref-type="bibr" rid="bibr46-1529100612451018">Eirinaki, Monga, &amp; Sundaram, 2012</xref>; <xref ref-type="bibr" rid="bibr181-1529100612451018">Scanfeld, Scanfeld, &amp; Larson, 2010</xref>; <xref ref-type="bibr" rid="bibr219-1529100612451018">Young, 2011</xref>) and of the ways in which these social networks facilitate the persistence of misinformation in selected segments of society.</p>
</sec>
<sec id="section33-1529100612451018">
<title>Concluding Remarks: Psychosocial, Ethical, and Practical Implications</title>
<p>We conclude by discussing how misinformation effects can be reconciled with the notion of human rationality, before addressing some limitations and ethical considerations surrounding debiasing and point to an alternative behavioral approach for counteracting the effects of misinformation.</p>
<p>Thus far, we have reviewed copious evidence about people’s inability to update their memories in light of corrective information and have shown how worldview can override fact and corrections can backfire. One might be tempted to conclude from those findings that people are somehow characteristically irrational, or cognitively “insufficient.” We caution against that conclusion. <xref ref-type="bibr" rid="bibr83-1529100612451018">Jern, Chang, and Kemp (2009)</xref> presented a model of belief polarization (which, as we noted earlier, is related to the continued influence of misinformation) that was instantiated within a Bayesian network. A Bayesian network captures causal relations among a set of variables: In a psychological context, it can capture the role of hidden psychological variables—for example, during belief updating. Instead of assuming that people consider the likelihood that hypothesis is true only in light of the information presented, a Bayesian network accounts for the fact that people may rely on other “hidden” variables, such as the degree to which they trust an information source (e.g., peer-reviewed literature). <xref ref-type="bibr" rid="bibr83-1529100612451018">Jern et al. (2009)</xref> showed that when these hidden variables are taken into account, Bayesian networks can capture behavior that at first glance might appear irrational—such as behavior in line with the backfire effects reviewed earlier. Although this research can only be considered suggestive at present, people’s rejection of corrective information may arguably represent a normatively rational integration of prior biases with new information.</p>
<p>Concerning the limitations of debiasing, there are several ethical and practical issues to consider. First, the application of any debiasing technique raises important ethical questions: While it is in the public interest to ensure that the population is well-informed, debiasing techniques can similarly be used to further <italic>mis</italic>inform people. Correcting misinformation is cognitively indistinguishable from misinforming people to replace their preexisting correct beliefs. It follows that it is important for the general public to have a basic understanding of misinformation effects: Widespread awareness of the fact that people may “throw mud” because they know it will “stick” is an important aspect of developing a healthy sense of public skepticism that will contribute to a well-informed populace.</p>
<p>Second, there are situations in which applying debiasing strategies is not advisable for reasons of efficiency. In our discussion of the worldview backfire effect, we argued that debiasing will be more effective for people who do not hold strong beliefs concerning the misinformation: In people who strongly believe in a piece of misinformation for ideological reasons, a retraction can in fact do more harm than good by ironically strengthening the misbelief. In such cases, particularly when the debiasing cannot be framed in a worldview-congruent manner, debiasing may not be a good strategy.</p>
<p>An alternative approach for dealing with pervasive misinformation is thus to ignore the misinformation altogether and seek more direct behavioral interventions. Behavioral economists have developed “nudging” techniques that can encourage people to make certain decisions over others, without preventing them from making a free choice (e.g., <xref ref-type="bibr" rid="bibr199-1529100612451018">Thaler &amp; Sunstein, 2008</xref>). For example, it no longer matters whether people are misinformed about climate science if they adopt ecologically friendly behaviors, such as by driving low- emission vehicles, in response to “nudges,” such as tax credits. Despite suggestions that even these nudges can be rendered ineffective by people’s worldviews (<xref ref-type="bibr" rid="bibr35-1529100612451018">Costa &amp; Kahn, 2010</xref>; <xref ref-type="bibr" rid="bibr106-1529100612451018">Lapinski, Rimal, DeVries, &amp; Lee, 2007</xref>), this approach has considerable promise.</p>
<p>Unlike debiasing techniques, behavioral interventions involve the explicit design of <italic>choice architectures</italic> to facilitate a desired outcome. For example, it has been shown that organ-donation rates in countries in which people have to “opt in” by explicitly stating their willingness to donate hover around 15–20%, compared to over 90% in countries in which people must “opt out” (<xref ref-type="bibr" rid="bibr84-1529100612451018">E. J. Johnson &amp; Goldstein, 2003</xref>). The fact that the design process for such choice architectures can be entirely transparent and subject to public and legislative scrutiny lessens any potential ethical implications.</p>
<p>A further advantage of the nudging approach is that its effects are not tied to a specific delivery vehicle, which may fail to reach target audiences. Thus, whereas debiasing requires that the target audience receive the corrective information—a potentially daunting obstacle—the design of choice architectures automatically reaches any person who is making a relevant choice.</p>
<p>We therefore see three situations in which nudging seems particularly applicable. First, when behavior changes need to occur quickly and across entire populations in order to prevent negative consequences, nudging may be the strategy of choice (cf. the Montreal Protocol to rapidly phase out CFCs to protect the ozone layer; e.g., <xref ref-type="bibr" rid="bibr55-1529100612451018">Gareau, 2010</xref>). Second, as discussed in the previous section, nudging may offer an alternative to debiasing when ideology is likely to prevent the success of debiasing strategies. Finally, nudging may be the only viable option in situations that involve organized efforts to deliberately misinform people—that is, when the dissemination of misinformation is programmatic (a case we reviewed at the outset of this article, using the examples of misinformation about tobacco smoke and climate change).</p>
<p>In this context, the persistence with which vested interests can pursue misinformation is notable: After decades of denying the link between smoking and lung cancer, the tobacco industry’s hired experts have opened a new line of testimony by arguing in court that even after the U.S. Surgeon General’s conclusion that tobacco was a major cause of death and injury in 1964, there was still “room for responsible disagreement” (<xref ref-type="bibr" rid="bibr167-1529100612451018">Proctor, 2004</xref>). Arguably, this position is intended to replace one set of well-orchestrated misinformation—that tobacco does not kill—with another convenient myth—that the tobacco industry did not know it. Spreading doubts by referring to the uncertainty of scientific conclusions—whether about smoking, climate change, or GM foods—is a very popular strategy for misinforming the populace (<xref ref-type="bibr" rid="bibr144-1529100612451018">Oreskes &amp; Conway, 2010</xref>). For laypeople, the magnitude of uncertainty does not matter much as long as it is believed to be meaningful. In addition to investigating the cognitive mechanisms of misinformation effects, researchers interested in misinformation would be well advised to monitor such sociopolitical developments in order to better understand why certain misinformation can gain traction and persist in society.</p>
</sec>
</body>
<back>
<ack>
<p>The first two authors contributed equally to the paper.</p>
</ack>
<fn-group>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>Preparation of this paper was facilitated by Discovery Grants DP0770666 and DP110101266 from the Australian Research Council and by an Australian Professorial Fellowship and an Australian Postdoctoral Fellowship to the first and second author, respectively.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1529100612451018">
<label>1.</label>
<p>We use the term “misinformation” here to refer to any piece of information that is initially processed as valid but that is subsequently retracted or corrected. This is in contrast to so-called <italic>post-event misinformation</italic>, the literature on which has been reviewed extensively elsewhere (e.g., <xref ref-type="bibr" rid="bibr7-1529100612451018">Ayers &amp; Reder, 1998</xref>, <xref ref-type="bibr" rid="bibr115-1529100612451018">Loftus, 2005</xref>) and has focused on the effects of suggestive and misleading information presented to witnesses <italic>after</italic> an event.</p>
</fn>
<fn fn-type="other" id="fn2-1529100612451018">
<label>2.</label>
<p>There is ongoing debate about whether the effects of worldview during information processing are more prevalent among conservatives than liberals (e.g., <xref ref-type="bibr" rid="bibr66-1529100612451018">Greenberg &amp; Jonas, 2003</xref>; <xref ref-type="bibr" rid="bibr93-1529100612451018">Jost, Glaser, Kruglanski, &amp; Sulloway, 2003a</xref>; <xref ref-type="bibr" rid="bibr94-1529100612451018">Jost, Glaser, Kruglanski, &amp; Sulloway, 2003b</xref>). This debate is informative and important but not directly relevant in this context. We are concerned with the existence of worldview-based effects on information processing irrespective of their partisan origin, given that misinformation effects are generic.</p>
</fn>
<fn fn-type="other" id="fn3-1529100612451018">
<label>3.</label>
<p>Two of the authors of this article (<xref ref-type="bibr" rid="bibr34-1529100612451018">Cook &amp; Lewandowsky, 2011</xref>) have prepared a practitioner’s guide to debiasing that, in 7 pages, summarizes the facets of the literature that are particularly relevant to practitioners (e.g., scientists and journalists). The booklet is available for free download in several languages (English, Dutch, German, and French as of July 2012) at <ext-link ext-link-type="uri" xlink:href="http://sks.to/debunk">http://sks.to/debunk</ext-link>, and can be considered an “executive summary” of the material in this article for practitioners.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Allen</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>A novel view of global warming</article-title>. <source>Nature</source>, <volume>433</volume>, <fpage>198</fpage>.</citation>
</ref>
<ref id="bibr2-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Allport</surname><given-names>F. H.</given-names></name>
<name><surname>Lepkin</surname><given-names>M.</given-names></name>
</person-group> (<year>1945</year>). <article-title>Wartime rumors of waste and special privilege: Why some people believe them</article-title>. <source>Journal of Abnormal and Social Psychology</source>, <volume>40</volume>, <fpage>3</fpage>–<lpage>36</lpage>.</citation>
</ref>
<ref id="bibr3-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Anderegg</surname><given-names>W. R. L.</given-names></name>
<name><surname>Prall</surname><given-names>J. W.</given-names></name>
<name><surname>Harold</surname><given-names>J.</given-names></name>
<name><surname>Schneider</surname><given-names>S. H.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Expert credibility in climate change</article-title>. <source>Proceedings of the National Academy of Sciences, USA</source>, <volume>107</volume>, <fpage>12107</fpage>–<lpage>12109</lpage>.</citation>
</ref>
<ref id="bibr4-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Anderson</surname><given-names>C. A.</given-names></name>
<name><surname>Lepper</surname><given-names>M. R.</given-names></name>
<name><surname>Ross</surname><given-names>L.</given-names></name>
</person-group> (<year>1980</year>). <article-title>Perseverance of social theories: The role of explanation in the persistence of discredited information</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>39</volume>, <fpage>1037</fpage>–<lpage>1049</lpage>.</citation>
</ref>
<ref id="bibr5-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Armstrong</surname><given-names>G. M.</given-names></name>
<name><surname>Gural</surname><given-names>M. N.</given-names></name>
<name><surname>Russ</surname><given-names>F. A.</given-names></name>
</person-group> (<year>1983</year>). <article-title>A longitudinal evaluation of the Listerine corrective advertising campaign</article-title>. <source>Journal of Public Policy &amp; Marketing</source>, <volume>2</volume>, <fpage>16</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr6-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Artz</surname><given-names>L.</given-names></name>
<name><surname>Kamalipour</surname><given-names>Y. R.</given-names></name>
</person-group> (<year>2004</year>). <source>Bring ’em on: Media and politics in the Iraq war</source>. <publisher-loc>Lanham, MD</publisher-loc>: <publisher-name>Rowman &amp; Littlefield</publisher-name>.</citation>
</ref>
<ref id="bibr7-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ayers</surname><given-names>M. S.</given-names></name>
<name><surname>Reder</surname><given-names>L. M.</given-names></name>
</person-group> (<year>1998</year>). <article-title>A theoretical review of the misinformation effect: Predictions from an activation-based memory model</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>5</volume>, <fpage>1</fpage>–<lpage>21</lpage>.</citation>
</ref>
<ref id="bibr8-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Barabas</surname><given-names>J.</given-names></name>
<name><surname>Jerit</surname><given-names>J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Estimating the causal effects of media coverage on policy-specific knowledge</article-title>. <source>American Journal of Political Science</source>, <volume>53</volume>, <fpage>73</fpage>–<lpage>89</lpage>.</citation>
</ref>
<ref id="bibr9-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Barr</surname><given-names>A.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Poll: 51 percent of GOP primary voters think Obama born abroad</article-title>. <source>Politico</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.politico.com/news/stories/0211/49554.html">http://www.politico.com/news/stories/0211/49554.html</ext-link></comment></citation>
</ref>
<ref id="bibr10-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bartlett</surname><given-names>F. C.</given-names></name>
</person-group> (<year>1977</year>). <source>Remembering: A study in experimental and social psychology</source>. <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>. (<comment>Original work published 1932</comment>)</citation>
</ref>
<ref id="bibr11-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bastin</surname><given-names>C.</given-names></name>
<name><surname>Van Der Linden</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Memory for temporal context: Effects of ageing, encoding instructions, and retrieval strategies</article-title>. <source>Memory</source>, <volume>13</volume>, <fpage>95</fpage>–<lpage>109</lpage>.</citation>
</ref>
<ref id="bibr12-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Batson</surname><given-names>C. D.</given-names></name>
</person-group> (<year>1975</year>). <article-title>Rational processing or rationalization? Effect of disconfirming information on a stated religious belief</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>32</volume>, <fpage>176</fpage>–<lpage>184</lpage>.</citation>
</ref>
<ref id="bibr13-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bedford</surname><given-names>D.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Agnotology as a teaching tool: Learning climate science by studying misinformation</article-title>. <source>Journal of Geography</source>, <volume>109</volume>, <fpage>159</fpage>–<lpage>165</lpage>.</citation>
</ref>
<ref id="bibr14-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Begg</surname><given-names>I. M.</given-names></name>
<name><surname>Anas</surname><given-names>A.</given-names></name>
<name><surname>Farinacci</surname><given-names>S.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Dissociation of processes in belief: Source recollection, statement familiarity, and the illusion of truth</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>121</volume>, <fpage>446</fpage>–<lpage>458</lpage>.</citation>
</ref>
<ref id="bibr15-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bennett</surname><given-names>W. L.</given-names></name>
</person-group> (<year>2003</year>). <article-title>The burglar alarm that just keeps ringing: A response to Zaller</article-title>. <source>Political Communication</source>, <volume>20</volume>, <fpage>131</fpage>–<lpage>138</lpage>.</citation>
</ref>
<ref id="bibr16-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Berger</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Arousal increases social transmission of information</article-title>. <source>Psychological Science</source>, <volume>22</volume>, <fpage>891</fpage>–<lpage>893</lpage>.</citation>
</ref>
<ref id="bibr17-1529100612451018">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Berinsky</surname><given-names>A.</given-names></name>
</person-group> (<year>2012</year>). <source>Rumors, truths, and reality: A study of political misinformation</source>. <comment>Unpublished manuscript</comment>, <publisher-name>Massachusetts Institute of Technology</publisher-name>, <publisher-loc>Cambridge, MA</publisher-loc>.</citation>
</ref>
<ref id="bibr18-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Berland</surname><given-names>G.</given-names></name>
<name><surname>Elliott</surname><given-names>M.</given-names></name>
<name><surname>Morales</surname><given-names>L.</given-names></name>
<name><surname>Algazy</surname><given-names>J.</given-names></name>
<name><surname>Kravitz</surname><given-names>R.</given-names></name>
<name><surname>Broder</surname><given-names>M.</given-names></name>
<name><surname>. . . McGlynn</surname><given-names>E. A.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Health information on the internet</article-title>. <source>Journal of the American Medical Association</source>, <volume>285</volume>, <fpage>2612</fpage>–<lpage>2621</lpage>.</citation>
</ref>
<ref id="bibr19-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Blais</surname><given-names>A.</given-names></name>
<name><surname>Gidengil</surname><given-names>E.</given-names></name>
<name><surname>Fournier</surname><given-names>P.</given-names></name>
<name><surname>Nevitte</surname><given-names>N.</given-names></name>
<name><surname>Everitt</surname><given-names>J.</given-names></name>
<name><surname>Kim</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Political judgments, perceptions of facts, and partisan effects</article-title>. <source>Electoral Studies</source>, <volume>29</volume>, <fpage>1</fpage>–<lpage>12</lpage>.</citation>
</ref>
<ref id="bibr20-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boykoff</surname><given-names>M. T.</given-names></name>
<name><surname>Boykoff</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Balance as bias: Global warming and the US prestige press</article-title>. <source>Global Environmental Change</source>, <volume>14</volume>, <fpage>125</fpage>–<lpage>136</lpage>.</citation>
</ref>
<ref id="bibr21-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Brehm</surname><given-names>S. S.</given-names></name>
<name><surname>Brehm</surname><given-names>J. W.</given-names></name>
</person-group> (<year>1981</year>). <source>Psychological reactance: A theory of freedom and control</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr22-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bush</surname><given-names>J. G.</given-names></name>
<name><surname>Johnson</surname><given-names>H. M.</given-names></name>
<name><surname>Seifert</surname><given-names>C. M.</given-names></name>
</person-group> (<year>1994</year>). <article-title>The implications of corrections: Then why did you mention it?</article-title> In <person-group person-group-type="editor">
<name><surname>Ram</surname><given-names>A.</given-names></name>
<name><surname>Eiselt</surname><given-names>K.</given-names></name>
</person-group> (Eds.), <source>Proceedings of the 16th annual conference of the cognitive science society</source> (pp. <fpage>112</fpage>–<lpage>117</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr23-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Byrne</surname><given-names>S.</given-names></name>
<name><surname>Hart</surname><given-names>P. S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The boomerang effect: A synthesis of findings and a preliminary theoretical framework</article-title>. In <person-group person-group-type="editor">
<name><surname>Beck</surname><given-names>C. S</given-names></name>
</person-group> (Ed.), <source>Communication yearbook</source> (<volume>Vol. 220</volume>, pp. <fpage>3</fpage>–<lpage>37</lpage>). <publisher-loc>Hoboken, NY</publisher-loc>: <publisher-name>Routledge</publisher-name>.</citation>
</ref>
<ref id="bibr24-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Carraro</surname><given-names>L.</given-names></name>
<name><surname>Castelli</surname><given-names>L.</given-names></name>
<name><surname>Macchiella</surname><given-names>C.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The automatic conservative: Ideology-based attentional asymmetries in the processing of valenced information</article-title>. <source>PLoS ONE</source>, <volume>6</volume>(<issue>11</issue>), <fpage>e26456</fpage>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosone.org/article/info:doi/10.1371/journal.pone.0026456">http://www.plosone.org/article/info:doi/10.1371/journal.pone.0026456</ext-link></comment></citation>
</ref>
<ref id="bibr25-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Castelli</surname><given-names>L.</given-names></name>
<name><surname>Carraro</surname><given-names>L.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Ideology is related to basic cognitive processes involved in attitude formation</article-title>. <source>Journal of Experimental Social Psychology</source>, <volume>47</volume>, <fpage>1013</fpage>–<lpage>1016</lpage>.</citation>
</ref>
<ref id="bibr26-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chambers</surname><given-names>K. L.</given-names></name>
<name><surname>Zaragoza</surname><given-names>M. S.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Intended and unintended effects of explicit warnings on eyewitness suggestibility: Evidence from source identification tests</article-title>. <source>Memory &amp; Cognition</source>, <volume>29</volume>, <fpage>1120</fpage>–<lpage>1129</lpage>.</citation>
</ref>
<ref id="bibr27-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chater</surname><given-names>N.</given-names></name>
<name><surname>Vitanyi</surname><given-names>P.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Simplicity: A unifying principle in cognitive science</article-title>. <source>Trends in Cognitive Science</source>, <volume>7</volume>, <fpage>19</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr28-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>S. Y. Y.</given-names></name>
<name><surname>White</surname><given-names>T. B.</given-names></name>
<name><surname>Chaplin</surname><given-names>L. N.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The effects of self-brand connections on responses to brand failure: A new look at the consumer–brand relationship</article-title>. <source>Journal of Consumer Psychology</source>, <volume>22</volume>, <fpage>280</fpage>–<lpage>288</lpage>.</citation>
</ref>
<ref id="bibr29-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cho</surname><given-names>C. H.</given-names></name>
<name><surname>Martens</surname><given-names>M. L.</given-names></name>
<name><surname>Kim</surname><given-names>H.</given-names></name>
<name><surname>Rodrigue</surname><given-names>M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Astroturfing global warming: It isn’t always greener on the other side of the fence</article-title>. <source>Journal of Business Ethics</source>, <volume>104</volume>, <fpage>571</fpage>–<lpage>587</lpage>.</citation>
</ref>
<ref id="bibr30-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Cialdini</surname><given-names>R. B.</given-names></name>
</person-group> (<year>2001</year>). <source>Influence: Science and practice</source> (<edition>4th ed.</edition>). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Allyn &amp; Bacon</publisher-name>.</citation>
</ref>
<ref id="bibr31-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clarke</surname><given-names>C.</given-names></name>
</person-group> (<year>2008</year>). <article-title>A question of balance: The autism-vaccine controversy in the British and American elite press</article-title>. <source>Science Communication</source>, <volume>30</volume>, <fpage>77</fpage>–<lpage>107</lpage>.</citation>
</ref>
<ref id="bibr32-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cohen</surname><given-names>G. L.</given-names></name>
<name><surname>Bastardi</surname><given-names>A.</given-names></name>
<name><surname>Sherman</surname><given-names>D. K.</given-names></name>
<name><surname>Hsu</surname><given-names>L.</given-names></name>
<name><surname>McGoey</surname><given-names>M.</given-names></name>
<name><surname>Ross</surname><given-names>L.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Bridging the partisan divide: Self-affirmation reduces ideological closed-mindedness and inflexibility in negotiation</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>93</volume>, <fpage>415</fpage>–<lpage>430</lpage>.</citation>
</ref>
<ref id="bibr33-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Colgrove</surname><given-names>J.</given-names></name>
<name><surname>Bayer</surname><given-names>R.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Could it happen here? Vaccine risk controversies and the specter of derailment</article-title>. <source>Health Affairs</source>, <volume>24</volume>, <fpage>729</fpage>–<lpage>739</lpage>.</citation>
</ref>
<ref id="bibr34-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Cook</surname><given-names>J.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <source>The debunking handbook</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.skepticalscience.com/docs/Debunking_Handbook.pdf">http://www.skepticalscience.com/docs/Debunking_Handbook.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr35-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Costa</surname><given-names>D. L.</given-names></name>
<name><surname>Kahn</surname><given-names>M. E.</given-names></name>
</person-group> (<year>2010</year>). <source>Energy conservation “nudges” and environmentalist ideology: Evidence from a randomized residential electricity field experiment</source> (<comment>NBER Working Paper No. 15939</comment>). <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>National Bureau of Economic Research</publisher-name>.</citation>
</ref>
<ref id="bibr36-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cotter</surname><given-names>E. M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Influence of emotional content and perceived relevance on spread of urban legends: A pilot study</article-title>. <source>Psychological Reports</source>, <volume>102</volume>, <fpage>623</fpage>–<lpage>629</lpage>.</citation>
</ref>
<ref id="bibr37-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>De Neys</surname><given-names>W.</given-names></name>
<name><surname>Cromheeke</surname><given-names>S.</given-names></name>
<name><surname>Osman</surname><given-names>M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Biased but in doubt: Conflict and decision confidence</article-title>. <source>PLoS ONE</source>, <volume>6</volume>, <fpage>e15954</fpage>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.plosone.org/article/info:doi/10.1371/journal.pone.0015954">http://www.plosone.org/article/info:doi/10.1371/journal.pone.0015954</ext-link></comment></citation>
</ref>
<ref id="bibr38-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Doran</surname><given-names>P. T.</given-names></name>
<name><surname>Zimmerman</surname><given-names>M. K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Examining the scientific consensus on climate change</article-title>. <source>Eos</source>, <volume>90</volume>, <fpage>21</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr39-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Eagly</surname><given-names>A. H.</given-names></name>
<name><surname>Chaiken</surname><given-names>S.</given-names></name>
</person-group> (<year>1993</year>). <source>The psychology of attitudes</source>. <publisher-loc>Fort Worth, TX</publisher-loc>: <publisher-name>Harcourt Brace Jovanovich</publisher-name>.</citation>
</ref>
<ref id="bibr40-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Eakin</surname><given-names>D. K.</given-names></name>
<name><surname>Schreiber</surname><given-names>T. A.</given-names></name>
<name><surname>Sergent-Marshall</surname><given-names>S.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Misinformation effects in eyewitness memory: The presence and absence of memory impairment as a function of warning and misinformation accessibility</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>29</volume>, <fpage>813</fpage>–<lpage>825</lpage>.</citation>
</ref>
<ref id="bibr41-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ecker</surname><given-names>U. K. H.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Apai</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Terrorists brought down the plane! —No, actually it was a technical fault: Processing corrections of emotive information</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>64</volume>, <fpage>283</fpage>–<lpage>310</lpage>.</citation>
</ref>
<ref id="bibr42-1529100612451018">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Ecker</surname><given-names>U. K. H.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Fenton</surname><given-names>O.</given-names></name>
<name><surname>Martin</surname><given-names>K.</given-names></name>
</person-group> (<year>2012</year>). <source>Pre-existing attitudes and the continued influence of misinformation</source>. <comment>Unpublished manuscript</comment>, <publisher-name>University of Western Australia</publisher-name>, <publisher-loc>Perth</publisher-loc>.</citation>
</ref>
<ref id="bibr43-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ecker</surname><given-names>U. K. H.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Swire</surname><given-names>B.</given-names></name>
<name><surname>Chang</surname><given-names>D.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Correcting false information in memory: Manipulating the strength of misinformation encoding and its retraction</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>18</volume>, <fpage>570</fpage>–<lpage>578</lpage>.</citation>
</ref>
<ref id="bibr44-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ecker</surname><given-names>U. K. H.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Tang</surname><given-names>D. T. W.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Explicit warnings reduce but do not eliminate the continued influence of misinformation</article-title>. <source>Memory &amp; Cognition</source>, <volume>38</volume>, <fpage>1087</fpage>–<lpage>1100</lpage>.</citation>
</ref>
<ref id="bibr45-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Einsele</surname><given-names>A.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The gap between science and perception: The case of plant biotechnology in Europe</article-title>. <source>Advances in Biochemical Engineering/Biotechnology</source>, <volume>107</volume>, <fpage>1</fpage>–<lpage>11</lpage>.</citation>
</ref>
<ref id="bibr46-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Eirinaki</surname><given-names>M.</given-names></name>
<name><surname>Monga</surname><given-names>S. P. S.</given-names></name>
<name><surname>Sundaram</surname><given-names>S.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Identification of influential social networkers</article-title>. <source>International Journal of Web Based Communities</source>, <volume>8</volume>, <fpage>136</fpage>–<lpage>158</lpage>.</citation>
</ref>
<ref id="bibr47-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Eslick</surname><given-names>A. N.</given-names></name>
<name><surname>Fazio</surname><given-names>L. K.</given-names></name>
<name><surname>Marsh</surname><given-names>E. J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Ironic effects of drawing attention to story errors</article-title>. <source>Memory</source>, <volume>19</volume>, <fpage>184</fpage>–<lpage>191</lpage>.</citation>
</ref>
<ref id="bibr48-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fein</surname><given-names>S.</given-names></name>
<name><surname>McCloskey</surname><given-names>A. L.</given-names></name>
<name><surname>Tomlinson</surname><given-names>T. M.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Can the jury disregard that information? The use of suspicion to reduce the prejudicial effects of pretrial publicity and inadmissible testimony</article-title>. <source>Personality and Social Psychology Bulletin</source>, <volume>23</volume>, <fpage>1215</fpage>–<lpage>1226</lpage>.</citation>
</ref>
<ref id="bibr49-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Festinger</surname><given-names>L.</given-names></name>
</person-group> (<year>1954</year>). <article-title>A theory of social comparison processes</article-title>. <source>Human Relations</source>, <volume>7</volume>, <fpage>123</fpage>–<lpage>146</lpage>.</citation>
</ref>
<ref id="bibr50-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Festinger</surname><given-names>L.</given-names></name>
</person-group> (<year>1957</year>). <source>A theory of cognitive dissonance</source>. <publisher-loc>Evanston, IL</publisher-loc>: <publisher-name>Row, Peterson</publisher-name>.</citation>
</ref>
<ref id="bibr51-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Feygina</surname><given-names>I.</given-names></name>
<name><surname>Jost</surname><given-names>J. T.</given-names></name>
<name><surname>Goldsmith</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2010</year>). <article-title>System justification, the denial of global warming, and the possibility of “system-sanctioned change.”</article-title> <source>Personality and Social Psychology Bulletin</source>, <volume>36</volume>, <fpage>326</fpage>–<lpage>338</lpage>.</citation>
</ref>
<ref id="bibr52-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Fox</surname><given-names>S.</given-names></name>
<name><surname>Jones</surname><given-names>S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The social life of health information</article-title>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.pewinternet.org/reports/2009/8-the-social-life-of-health-information.aspx">http://www.pewinternet.org/reports/2009/8-the-social-life-of-health-information.aspx</ext-link></comment></citation>
</ref>
<ref id="bibr53-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fragale</surname><given-names>A. R.</given-names></name>
<name><surname>Heath</surname><given-names>C.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Evolving informational credentials: The (mis)attribution of believable facts to credible sources</article-title>. <source>Personality and Social Psychology Bulletin</source>, <volume>30</volume>, <fpage>225</fpage>–<lpage>236</lpage>.</citation>
</ref>
<ref id="bibr54-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gaines</surname><given-names>B. J.</given-names></name>
<name><surname>Kuklinski</surname><given-names>J. H.</given-names></name>
<name><surname>Quirk</surname><given-names>P. J.</given-names></name>
<name><surname>Peyton</surname><given-names>B.</given-names></name>
<name><surname>Verkuilen</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Same facts, different interpretations: Partisan motivation and opinion on Iraq</article-title>. <source>Journal of Politics</source>, <volume>69</volume>, <fpage>957</fpage>–<lpage>974</lpage>.</citation>
</ref>
<ref id="bibr55-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gareau</surname><given-names>B. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A critical review of the successful CFC phase-out versus the delayed methyl bromide phase-out in the Montreal Protocol</article-title>. <source>International Environmental Agreements: Politics, Law and Economics</source>, <volume>10</volume>, <fpage>209</fpage>–<lpage>231</lpage>.</citation>
</ref>
<ref id="bibr56-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gaskell</surname><given-names>G.</given-names></name>
<name><surname>Allum</surname><given-names>N.</given-names></name>
<name><surname>Bauer</surname><given-names>M.</given-names></name>
<name><surname>Jackson</surname><given-names>J.</given-names></name>
<name><surname>Howard</surname><given-names>S.</given-names></name>
<name><surname>Lindsey</surname><given-names>N.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Climate change for biotechnology? UK public opinion 1991-2002</article-title>. <source>AgBioForum</source>, <volume>6</volume>, <fpage>55</fpage>–<lpage>67</lpage>.</citation>
</ref>
<ref id="bibr57-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gerrie</surname><given-names>M. P.</given-names></name>
<name><surname>Belcher</surname><given-names>L. E.</given-names></name>
<name><surname>Garry</surname><given-names>M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>“Mind the gap”: False memories for missing aspects of an event</article-title>. <source>Applied Cognitive Psychology</source>, <volume>20</volume>, <fpage>689</fpage>–<lpage>696</lpage>.</citation>
</ref>
<ref id="bibr58-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilbert</surname><given-names>D. T.</given-names></name>
</person-group> (<year>1991</year>). <article-title>How mental systems believe</article-title>. <source>American Psychologist</source>, <volume>46</volume>, <fpage>107</fpage>–<lpage>119</lpage>.</citation>
</ref>
<ref id="bibr59-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilbert</surname><given-names>D. T.</given-names></name>
<name><surname>Krull</surname><given-names>D.</given-names></name>
<name><surname>Malone</surname><given-names>P.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Unbelieving the unbelievable: Some problems in the rejection of false information</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>59</volume>, <fpage>601</fpage>–<lpage>613</lpage>.</citation>
</ref>
<ref id="bibr60-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gilbert</surname><given-names>D. T.</given-names></name>
<name><surname>Tafarodi</surname><given-names>R. W.</given-names></name>
<name><surname>Malone</surname><given-names>P. S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>You can’t not believe everything you read</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>65</volume>, <fpage>221</fpage>–<lpage>233</lpage>.</citation>
</ref>
<ref id="bibr61-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Glaeser</surname><given-names>E. L.</given-names></name>
<name><surname>Ponzetto</surname><given-names>G. A. M.</given-names></name>
<name><surname>Shapiro</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Strategic extremism: Why Republicans and Democrats divide on religious values</article-title>. <source>The Quarterly Journal of Economics</source>, <volume>120</volume>, <fpage>1283</fpage>–<lpage>1330</lpage>.</citation>
</ref>
<ref id="bibr62-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Glöckner</surname><given-names>A.</given-names></name>
<name><surname>Bröder</surname><given-names>A.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Processing of recognition information and additional cues: A model-based analysis of choice, confidence, and response time</article-title>. <source>Judgment and Decision Making</source>, <volume>6</volume>, <fpage>23</fpage>–<lpage>42</lpage>.</citation>
</ref>
<ref id="bibr63-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Goldstein</surname><given-names>D. G.</given-names></name>
<name><surname>Gigerenzer</surname><given-names>G.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Models of ecological rationality: The recognition heuristic</article-title>. <source>Psychological Review</source>, <volume>109</volume>, <fpage>75</fpage>–<lpage>90</lpage>.</citation>
</ref>
<ref id="bibr64-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gollust</surname><given-names>S. E.</given-names></name>
<name><surname>Lantz</surname><given-names>P. M.</given-names></name>
<name><surname>Ubel</surname><given-names>P. A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The polarizing effect of news media messages about the social determinants of health</article-title>. <source>American Journal of Public Health</source>, <volume>99</volume>, <fpage>2160</fpage>–<lpage>2167</lpage>.</citation>
</ref>
<ref id="bibr65-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Green</surname><given-names>M. C.</given-names></name>
<name><surname>Donahue</surname><given-names>J. K.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Persistence of belief change in the face of deception: The effect of factual stories revealed to be false</article-title>. <source>Media Psychology</source>, <volume>14</volume>, <fpage>312</fpage>–<lpage>331</lpage>.</citation>
</ref>
<ref id="bibr66-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Greenberg</surname><given-names>J.</given-names></name>
<name><surname>Jonas</surname><given-names>E.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Psychological motives and political orientation—The left, the right, and the rigid: Comment on Jost et al. (2003)</article-title>. <source>Psychological Bulletin</source>, <volume>129</volume>, <fpage>376</fpage>–<lpage>382</lpage>.</citation>
</ref>
<ref id="bibr67-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Grice</surname><given-names>H. P.</given-names></name>
</person-group> (<year>1975</year>). <article-title>Logic and conversation</article-title>. In <person-group person-group-type="editor">
<name><surname>Cole</surname><given-names>P.</given-names></name>
<name><surname>Morgan</surname><given-names>J. L</given-names></name>
</person-group> (Eds.), <source>Syntax and semantics, Vol. 3: Speech acts</source> (pp. <fpage>41</fpage>–<lpage>58</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr68-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hamilton</surname><given-names>L. C.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Education, politics and opinions about climate change evidence for interaction effects</article-title>. <source>Climatic Change</source>, <volume>104</volume>, <fpage>231</fpage>–<lpage>242</lpage>.</citation>
</ref>
<ref id="bibr69-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hardisty</surname><given-names>D. J.</given-names></name>
<name><surname>Johnson</surname><given-names>E. J.</given-names></name>
<name><surname>Weber</surname><given-names>E. U.</given-names></name>
</person-group> (<year>2010</year>). <article-title>A dirty word or a dirty world? Attribute framing, political affiliation, and query theory</article-title>. <source>Psychological Science</source>, <volume>21</volume>, <fpage>86</fpage>–<lpage>92</lpage>.</citation>
</ref>
<ref id="bibr70-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hargreaves</surname><given-names>I.</given-names></name>
<name><surname>Lewis</surname><given-names>J.</given-names></name>
<name><surname>Speers</surname><given-names>T.</given-names></name>
</person-group> (<year>2003</year>). <source>Towards a better map: Science, the public and the media</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Economic and Social Research Council</publisher-name>.</citation>
</ref>
<ref id="bibr71-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hart</surname><given-names>P. S.</given-names></name>
<name><surname>Nisbet</surname><given-names>E. C.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Boomerang effects in science communication: How motivated reasoning and identity cues amplify opinion polarization about climate mitigation policies</article-title>. <source>Communication Research</source>. <comment>Advance online publication</comment>. doi:10.1177/0093650211416646<pub-id pub-id-type="doi">10.1177/0093650211416646</pub-id></citation>
</ref>
<ref id="bibr72-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hasher</surname><given-names>L.</given-names></name>
<name><surname>Goldstein</surname><given-names>D.</given-names></name>
<name><surname>Toppino</surname><given-names>T.</given-names></name>
</person-group> (<year>1977</year>). <article-title>Frequency and the conference of referential validity</article-title>. <source>Journal of Verbal Learning and Verbal Behavior</source>, <volume>16</volume>, <fpage>107</fpage>–<lpage>112</lpage>.</citation>
</ref>
<ref id="bibr73-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hasson</surname><given-names>U.</given-names></name>
<name><surname>Simmons</surname><given-names>J. P.</given-names></name>
<name><surname>Todorov</surname><given-names>A.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Believe it or not: On the possibility of suspending belief</article-title>. <source>Psychological Science</source>, <volume>16</volume>, <fpage>566</fpage>–<lpage>571</lpage>.</citation>
</ref>
<ref id="bibr74-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Heath</surname><given-names>C.</given-names></name>
<name><surname>Bell</surname><given-names>C.</given-names></name>
<name><surname>Sternberg</surname><given-names>E.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Emotional selection in memes: The case of urban legends</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>81</volume>, <fpage>1028</fpage>–<lpage>1041</lpage>.</citation>
</ref>
<ref id="bibr75-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Henkel</surname><given-names>L. A.</given-names></name>
<name><surname>Mattson</surname><given-names>M. E.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Reading is believing: The truth effect and source credibility</article-title>. <source>Consciousness and Cognition</source>, <volume>20</volume>, <fpage>1705</fpage>–<lpage>1721</lpage>.</citation>
</ref>
<ref id="bibr76-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Hoggan</surname><given-names>J.</given-names></name>
<name><surname>Littlemore</surname><given-names>R.</given-names></name>
<name><surname>Littlemore</surname><given-names>R.</given-names></name>
</person-group> (<year>2009</year>). <source>Climate cover-up: The crusade to deny global warming</source>. <publisher-loc>Vancouver, BC</publisher-loc>: <publisher-name>Greystone Books</publisher-name>.</citation>
</ref>
<ref id="bibr77-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Holliday</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Reducing misinformation effects in children with cognitive interviews: Dissociating recollection and familiarity</article-title>. <source>Child Development</source>, <volume>74</volume>, <fpage>728</fpage>–<lpage>751</lpage>.</citation>
</ref>
<ref id="bibr78-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Humphreys</surname><given-names>M. S.</given-names></name>
<name><surname>Cornwell</surname><given-names>T. B.</given-names></name>
<name><surname>McAlister</surname><given-names>A. R.</given-names></name>
<name><surname>Kelly</surname><given-names>S. J.</given-names></name>
<name><surname>Quinn</surname><given-names>E. A.</given-names></name>
<name><surname>Murray</surname><given-names>K. L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Sponsorship, ambushing, and counter-strategy: Effects upon memory for sponsor and event</article-title>. <source>Journal of Experimental Psychology: Applied</source>, <volume>16</volume>, <fpage>96</fpage>–<lpage>108</lpage>.</citation>
</ref>
<ref id="bibr79-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jacoby</surname><given-names>L. L.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Ironic effects of repetition: Measuring age-related differences in memory</article-title>. <source>Journal of Experimental Psychology: Learning Memory, and Cognition</source>, <volume>25</volume>, <fpage>3</fpage>–<lpage>22</lpage>.</citation>
</ref>
<ref id="bibr80-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jacoby</surname><given-names>L. L.</given-names></name>
<name><surname>Kelley</surname><given-names>C. M.</given-names></name>
<name><surname>Brown</surname><given-names>J.</given-names></name>
<name><surname>Jaseschko</surname><given-names>J.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Becoming famous overnight: Limits on the ability to avoid unconscious influences of the past</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>56</volume>, <fpage>326</fpage>–<lpage>338</lpage>.</citation>
</ref>
<ref id="bibr81-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jacques</surname><given-names>P. J.</given-names></name>
<name><surname>Dunlap</surname><given-names>R. E.</given-names></name>
<name><surname>Freeman</surname><given-names>M.</given-names></name>
</person-group> (<year>2008</year>). <article-title>The organisation of denial: Conservative think tanks and environmental scepticism</article-title>. <source>Environmental Politics</source>, <volume>17</volume>, <fpage>349</fpage>–<lpage>385</lpage>.</citation>
</ref>
<ref id="bibr82-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jerit</surname><given-names>J.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Issue framing and engagement: Rhetorical strategy in public policy debates</article-title>. <source>Political Behavior</source>, <volume>30</volume>, <fpage>1</fpage>–<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr83-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Jern</surname><given-names>A.</given-names></name>
<name><surname>Chang</surname><given-names>K.-m. K.</given-names></name>
<name><surname>Kemp</surname><given-names>C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Bayesian belief polarization</article-title>. In <person-group person-group-type="editor">
<name><surname>Bengio</surname><given-names>Y.</given-names></name>
<name><surname>Schuurmans</surname><given-names>D.</given-names></name>
<name><surname>Lafferty</surname><given-names>J.</given-names></name>
<name><surname>Williams</surname><given-names>C. K. I.</given-names></name>
<name><surname>Culotta</surname><given-names>A.</given-names></name>
</person-group> (Eds.), <source>Advances in neural information processing systems</source> (<volume>Vol. 22</volume>, pp. <fpage>853</fpage>–<lpage>861</lpage>). <publisher-loc>La Jolla, CA</publisher-loc>: <publisher-name>Neural Information Processing Foundation</publisher-name>.</citation>
</ref>
<ref id="bibr84-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>E. J.</given-names></name>
<name><surname>Goldstein</surname><given-names>D.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Do defaults save lives?</article-title> <source>Science</source>, <volume>302</volume>, <fpage>1338</fpage>–<lpage>1339</lpage>.</citation>
</ref>
<ref id="bibr85-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>H. M.</given-names></name>
<name><surname>Seifert</surname><given-names>C. M.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Sources of the continued influence effect: When misinformation in memory affects later inferences</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>20</volume>, <fpage>1420</fpage>–<lpage>1436</lpage>.</citation>
</ref>
<ref id="bibr86-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>H. M.</given-names></name>
<name><surname>Seifert</surname><given-names>C. M.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Updating accounts following a correction of misinformation</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>24</volume>, <fpage>1483</fpage>–<lpage>1494</lpage>.</citation>
</ref>
<ref id="bibr87-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>H. M.</given-names></name>
<name><surname>Seifert</surname><given-names>C. M.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Modifying mental representations: Comprehending corrections</article-title>. In <person-group person-group-type="editor">
<name><surname>van Oostendorp</surname><given-names>H.</given-names></name>
<name><surname>Goldman</surname><given-names>S. R</given-names></name>
</person-group> (Eds.), <source>The construction of mental representations during reading</source> (pp. <fpage>303</fpage>–<lpage>318</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr88-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>M. K.</given-names></name>
<name><surname>Hashtroudi</surname><given-names>S.</given-names></name>
<name><surname>Lindsay</surname><given-names>D. S.</given-names></name>
</person-group> (<year>1993</year>). <article-title>Source monitoring</article-title>. <source>Psychological Bulletin</source>, <volume>114</volume>, <fpage>3</fpage>–<lpage>28</lpage>.</citation>
</ref>
<ref id="bibr89-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>T. J.</given-names></name>
<name><surname>Kaye</surname><given-names>B.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Wag the blog: How reliance on traditional media and the internet influence credibility perceptions of weblogs among blog users</article-title>. <source>Journalism &amp; Mass Communication Quarterly</source>, <volume>81</volume>, <fpage>622</fpage>–<lpage>642</lpage>.</citation>
</ref>
<ref id="bibr90-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>T. J.</given-names></name>
<name><surname>Kaye</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Believing the blogs of war? How blog users compare on credibility and characteristics in 2003 and 2007</article-title>. <source>Media, War &amp; Conflict</source>, <volume>3</volume>, <fpage>315</fpage>–<lpage>333</lpage>.</citation>
</ref>
<ref id="bibr91-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>T. J.</given-names></name>
<name><surname>Bichard</surname><given-names>S. L.</given-names></name>
<name><surname>Zhang</surname><given-names>W.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Communication communities or “cyberghettos?”: A path analysis model examining factors that explain selective exposure to blogs</article-title>. <source>Journal of Computer-Mediated Communication</source>, <volume>15</volume>, <fpage>60</fpage>–<lpage>82</lpage>.</citation>
</ref>
<ref id="bibr92-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Johnson-Laird</surname><given-names>P. N.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Mental models and consistency</article-title>. In <person-group person-group-type="editor">
<name><surname>Gawronski</surname><given-names>B.</given-names></name>
<name><surname>Strack</surname><given-names>F.</given-names></name>
</person-group> (Eds.), <source>Cognitive consistency: A fundamental principle in social cognition</source> (pp. <fpage>225</fpage>–<lpage>243</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</citation>
</ref>
<ref id="bibr93-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jost</surname><given-names>J. T.</given-names></name>
<name><surname>Glaser</surname><given-names>J.</given-names></name>
<name><surname>Kruglanski</surname><given-names>A. W.</given-names></name>
<name><surname>Sulloway</surname><given-names>F. J.</given-names></name>
</person-group> (<year>2003a</year>). <article-title>Exceptions that prove the rule—Using a theory of motivated social cognition to account for ideological incongruities and political anomalies: Reply to Greenberg and Jonas (2003)</article-title>. <source>Psychological Bulletin</source>, <volume>129</volume>, <fpage>383</fpage>–<lpage>393</lpage>.</citation>
</ref>
<ref id="bibr94-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jost</surname><given-names>J. T.</given-names></name>
<name><surname>Glaser</surname><given-names>J.</given-names></name>
<name><surname>Kruglanski</surname><given-names>A. W.</given-names></name>
<name><surname>Sulloway</surname><given-names>F. J.</given-names></name>
</person-group> (<year>2003b</year>). <article-title>Political conservatism as motivated social cognition</article-title>. <source>Psychological Bulletin</source>, <volume>129</volume>, <fpage>339</fpage>–<lpage>375</lpage>.</citation>
</ref>
<ref id="bibr95-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Jou</surname><given-names>J.</given-names></name>
<name><surname>Foreman</surname><given-names>J.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Transfer of learning in avoiding false memory: The roles of warning, immediate feedback, and incentive</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>60</volume>, <fpage>977</fpage>–<lpage>896</lpage>.</citation>
</ref>
<ref id="bibr96-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kahan</surname><given-names>D. M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Fixing the communications failure</article-title>. <source>Nature</source>, <volume>463</volume>, <fpage>296</fpage>–<lpage>297</lpage>.</citation>
</ref>
<ref id="bibr97-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kamalipour</surname><given-names>Y. R.</given-names></name>
<name><surname>Snow</surname><given-names>N. E.</given-names></name>
</person-group> (<year>2004</year>). <source>War, media, and propaganda</source>. <publisher-loc>Oxford, England</publisher-loc>: <publisher-name>Rowman &amp; Littlefield</publisher-name>.</citation>
</ref>
<ref id="bibr98-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Keelan</surname><given-names>J.</given-names></name>
<name><surname>Pavri-Garcia</surname><given-names>V.</given-names></name>
<name><surname>Tomlinson</surname><given-names>G.</given-names></name>
<name><surname>Wilson</surname><given-names>K.</given-names></name>
</person-group> (<year>2007</year>). <article-title>YouTube as a source of information on immunization: A content analysis</article-title>. <source>Journal of the American Medical Association</source>, <volume>298</volume>, <fpage>2482</fpage>–<lpage>2484</lpage>.</citation>
</ref>
<ref id="bibr99-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kowalski</surname><given-names>P.</given-names></name>
<name><surname>Taylor</surname><given-names>A. K.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The effect of refuting misconceptions in the introductory psychology class</article-title>. <source>Teaching of Psychology</source>, <volume>36</volume>, <fpage>153</fpage>–<lpage>159</lpage>.</citation>
</ref>
<ref id="bibr100-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Krech</surname><given-names>D.</given-names></name>
<name><surname>Crutchfield</surname><given-names>R. S.</given-names></name>
<name><surname>Ballachey</surname><given-names>E. L.</given-names></name>
</person-group> (<year>1962</year>). <source>Individual in society</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</citation>
</ref>
<ref id="bibr101-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kross</surname><given-names>E.</given-names></name>
<name><surname>Grossmann</surname><given-names>I.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Boosting wisdom: Distance from the self enhances wise reasoning, attitudes, and behavior</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>141</volume>, <fpage>43</fpage>–<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr102-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kuklinski</surname><given-names>J. H.</given-names></name>
<name><surname>Quirk</surname><given-names>P. J.</given-names></name>
<name><surname>Jerit</surname><given-names>J.</given-names></name>
<name><surname>Schwieder</surname><given-names>D.</given-names></name>
<name><surname>Rich</surname><given-names>R. F.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Misinformation and the currency of democratic citizenship</article-title>. <source>Journal of Politics</source>, <volume>62</volume>, <fpage>790</fpage>–<lpage>816</lpage>.</citation>
</ref>
<ref id="bibr103-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Kull</surname><given-names>S.</given-names></name>
<name><surname>Ramsay</surname><given-names>C.</given-names></name>
<name><surname>Lewis</surname><given-names>E.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Misperceptions, the media, and the Iraq war</article-title>. <source>Political Science Quarterly</source>, <volume>118</volume>, <fpage>569</fpage>–<lpage>598</lpage>.</citation>
</ref>
<ref id="bibr104-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Kull</surname><given-names>S.</given-names></name>
<name><surname>Ramsay</surname><given-names>C.</given-names></name>
<name><surname>Stephens</surname><given-names>A.</given-names></name>
<name><surname>Weber</surname><given-names>S.</given-names></name>
<name><surname>Lewis</surname><given-names>E.</given-names></name>
<name><surname>Hadfield</surname><given-names>J.</given-names></name>
</person-group> (<year>2006</year>). <source>Americans on Iraq: Three years on</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.worldpublicopinion.org/pipa/pdf/mar06/usiraq_mar06_rpt.pdf">http://www.worldpublicopinion.org/pipa/pdf/mar06/usiraq_mar06_rpt.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr105-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ladle</surname><given-names>R.</given-names></name>
<name><surname>Jepson</surname><given-names>P.</given-names></name>
<name><surname>Whittaker</surname><given-names>R.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Scientists and the media: The struggle for legitimacy in climate change and conservation science</article-title>. <source>Interdisciplinary Science Reviews</source>, <volume>30</volume>, <fpage>231</fpage>–<lpage>240</lpage>.</citation>
</ref>
<ref id="bibr106-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lapinski</surname><given-names>M. K.</given-names></name>
<name><surname>Rimal</surname><given-names>R. N.</given-names></name>
<name><surname>DeVries</surname><given-names>R.</given-names></name>
<name><surname>Lee</surname><given-names>E. L.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The role of group orientation and descriptive norms on water conservation attitudes and behaviors</article-title>. <source>Health Communication</source>, <volume>22</volume>, <fpage>133</fpage>–<lpage>142</lpage>.</citation>
</ref>
<ref id="bibr107-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Larson</surname><given-names>H. J.</given-names></name>
<name><surname>Cooper</surname><given-names>L. Z.</given-names></name>
<name><surname>Eskola</surname><given-names>J.</given-names></name>
<name><surname>Katz</surname><given-names>S. L.</given-names></name>
<name><surname>Ratzan</surname><given-names>S. C.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Addressing the vaccine confidence gap</article-title>. <source>The Lancet</source>, <volume>378</volume>, <fpage>526</fpage>–<lpage>535</lpage>.</citation>
</ref>
<ref id="bibr108-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Leggett</surname><given-names>J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Dangerous fiction</article-title>. <source>New Scientist</source>, <volume>185</volume>(<issue>2489</issue>), <fpage>50</fpage>–<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr109-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Leiserowitz</surname><given-names>A.</given-names></name>
<name><surname>Maibach</surname><given-names>E.</given-names></name>
<name><surname>Roser-Renouf</surname><given-names>C.</given-names></name>
<name><surname>Hmielowski</surname><given-names>J. D.</given-names></name>
</person-group> (<year>2011</year>). <source>Politics and global warming: Democrats, Republicans, Independents, and the Tea Party</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://environment.yale.edu/climate/files/politicsglobalwarming2011.pdf">http://environment.yale.edu/climate/files/politicsglobalwarming2011.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr110-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Leviston</surname><given-names>Z.</given-names></name>
<name><surname>Walker</surname><given-names>I.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Second annual survey of Australian attitudes to climate change: Interim report</article-title>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.csiro.au/outcomes/climate/adapting/annual-climate-change-attitudes-survey-2011.aspx">http://www.csiro.au/outcomes/climate/adapting/annual-climate-change-attitudes-survey-2011.aspx</ext-link></comment></citation>
</ref>
<ref id="bibr111-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Levy-Ari</surname><given-names>S.</given-names></name>
<name><surname>Keysar</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Why don’t we believe non-native speakers? The influence of accent on credibility</article-title>. <source>Journal of Experimental Social Psychology</source>, <volume>46</volume>, <fpage>1093</fpage>–<lpage>1096</lpage>.</citation>
</ref>
<ref id="bibr112-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Stritzke</surname><given-names>W. G. K.</given-names></name>
<name><surname>Oberauer</surname><given-names>K.</given-names></name>
<name><surname>Morales</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Memory for fact, fiction, and misinformation: The Iraq War 2003</article-title>. <source>Psychological Science</source>, <volume>16</volume>, <fpage>190</fpage>–<lpage>195</lpage>.</citation>
</ref>
<ref id="bibr113-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Stritzke</surname><given-names>W. G. K.</given-names></name>
<name><surname>Oberauer</surname><given-names>K.</given-names></name>
<name><surname>Morales</surname><given-names>M.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Misinformation and the “War on Terror”: When memory turns fiction into fact</article-title>. In <person-group person-group-type="editor">
<name><surname>Stritzke</surname><given-names>W. G. K.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Denemark</surname><given-names>D.</given-names></name>
<name><surname>Clare</surname><given-names>J.</given-names></name>
<name><surname>Morgan</surname><given-names>F.</given-names></name>
</person-group> (Eds.), <source>Terrorism and torture: An interdisciplinary perspective</source> (pp. <fpage>179</fpage>–<lpage>203</lpage>). <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr114-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lieberman</surname><given-names>J. D.</given-names></name>
<name><surname>Arndt</surname><given-names>J.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Understanding the limits of limiting instruction: Social psychology explanations for the failure of instructions to disregard pretrial publicity and other inadmissible evidence</article-title>. <source>Psychology, Public Policy, and Law</source>, <volume>6</volume>, <fpage>677</fpage>–<lpage>711</lpage>.</citation>
</ref>
<ref id="bibr115-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Loftus</surname><given-names>E. F.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Planting misinformation in the human mind: A 30-year investigation of the malleability of memory</article-title>. <source>Learning &amp; Memory</source>, <volume>12</volume>, <fpage>361</fpage>–<lpage>366</lpage>.</citation>
</ref>
<ref id="bibr116-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lombrozo</surname><given-names>T.</given-names></name>
</person-group> (<year>2006</year>). <article-title>The structure and function of explanations</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>10</volume>, <fpage>464</fpage>–<lpage>470</lpage>.</citation>
</ref>
<ref id="bibr117-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lombrozo</surname><given-names>T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Simplicity and probability in causal explanation</article-title>. <source>Cognitive Psychology</source>, <volume>55</volume>, <fpage>232</fpage>–<lpage>257</lpage>.</citation>
</ref>
<ref id="bibr118-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Lord</surname><given-names>C. G.</given-names></name>
<name><surname>Ross</surname><given-names>L.</given-names></name>
<name><surname>Lepper</surname><given-names>M. R.</given-names></name>
</person-group> (<year>1979</year>). <article-title>Biased assimilation and attitude polarization: The effects of prior theories on subsequently considered evidence</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>37</volume>, <fpage>2098</fpage>–<lpage>2109</lpage>.</citation>
</ref>
<ref id="bibr119-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Malka</surname><given-names>A.</given-names></name>
<name><surname>Krosnick</surname><given-names>J. A.</given-names></name>
<name><surname>Langer</surname><given-names>G.</given-names></name>
</person-group> (<year>2009</year>). <article-title>The association of knowledge with concern about global warming: Trusted information sources shape public thinking</article-title>. <source>Risk Analysis</source>, <volume>29</volume>, <fpage>633</fpage>–<lpage>647</lpage>.</citation>
</ref>
<ref id="bibr120-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>E. J.</given-names></name>
<name><surname>Fazio</surname><given-names>L. K.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Learning errors from fiction: Difficulties in reducing reliance on fictional stories</article-title>. <source>Memory &amp; Cognition</source>, <volume>34</volume>, <fpage>1140</fpage>–<lpage>1149</lpage>.</citation>
</ref>
<ref id="bibr121-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Marsh</surname><given-names>E. J.</given-names></name>
<name><surname>Meade</surname><given-names>M. L.</given-names></name>
<name><surname>Roediger</surname><given-names>H. L.</given-names><suffix>III</suffix></name>
</person-group>. (<year>2003</year>). <article-title>Learning fact from fiction</article-title>. <source>Journal of Memory and Language</source>, <volume>49</volume>, <fpage>519</fpage>–<lpage>536</lpage>.</citation>
</ref>
<ref id="bibr122-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mayer</surname><given-names>J.</given-names></name>
<name><surname>Mussweiler</surname><given-names>T.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Suspicious spirits, flexible minds: When distrust enhances creativity</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>101</volume>, <fpage>1262</fpage>–<lpage>1277</lpage>.</citation>
</ref>
<ref id="bibr123-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mayo</surname><given-names>R.</given-names></name>
<name><surname>Schul</surname><given-names>Y.</given-names></name>
<name><surname>Burnstein</surname><given-names>E.</given-names></name>
</person-group> (<year>2004</year>). <article-title>“I am not guilty” vs. “I am innocent”: Successful negation</article-title> <month>may</month> <article-title>depend on the schema used for its encoding</article-title>. <source>Journal of Experimental Social Psychology</source>, <volume>40</volume>, <fpage>433</fpage>–<lpage>449</lpage>.</citation>
</ref>
<ref id="bibr124-1529100612451018">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>McCracken</surname><given-names>B.</given-names></name>
</person-group> (<year>2011</year>). <source>Are new media credible? A multidimensional approach to measuring news consumers’ credibility and bias perceptions and the frequency of news consumption</source>. <comment>Unpublished doctoral dissertation</comment>, <publisher-name>Rochester Institute of Technology</publisher-name>, <publisher-loc>Rochester, NY</publisher-loc>.</citation>
</ref>
<ref id="bibr125-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCright</surname><given-names>A. M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Political orientation moderates Americans’ beliefs and concern about climate change</article-title>. <source>Climatic Change</source>, <volume>104</volume>, <fpage>243</fpage>–<lpage>253</lpage>.</citation>
</ref>
<ref id="bibr126-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCright</surname><given-names>A. M.</given-names></name>
<name><surname>Dunlap</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Anti-reflexivity: The American conservative movement’s success in undermining climate science and policy</article-title>. <source>Theory, Culture &amp; Society</source>, <volume>27</volume>, <fpage>100</fpage>–<lpage>133</lpage>.</citation>
</ref>
<ref id="bibr127-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McCright</surname><given-names>A. M.</given-names></name>
<name><surname>Dunlap</surname><given-names>R. E.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The politicization of climate change and polarization in the American public’s views of global warming, 2001–2010</article-title>. <source>The Sociological Quarterly</source>, <volume>52</volume>, <fpage>155</fpage>–<lpage>194</lpage>.</citation>
</ref>
<ref id="bibr128-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>McGlone</surname><given-names>M. S.</given-names></name>
<name><surname>Tofighbakhsh</surname><given-names>J.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Birds of a feather flock conjointly (?): Rhyme as reason in aphorisms</article-title>. <source>Psychological Science</source>, <volume>11</volume>, <fpage>424</fpage>–<lpage>428</lpage>.</citation>
</ref>
<ref id="bibr129-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>McGuire</surname><given-names>W. J.</given-names></name>
</person-group> (<year>1972</year>). <article-title>Attitude change: The information processing paradigm</article-title>. In <person-group person-group-type="editor">
<name><surname>McClintock</surname><given-names>C. G</given-names></name>
</person-group> (Ed.), <source>Experimental social psychology</source> (pp. <fpage>108</fpage>–<lpage>141</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Holt, Rinehart, &amp; Winston</publisher-name>.</citation>
</ref>
<ref id="bibr130-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mielby</surname><given-names>H.</given-names></name>
<name><surname>Sandøe</surname><given-names>P.</given-names></name>
<name><surname>Lassen</surname><given-names>J.</given-names></name>
</person-group> (<year>2012</year>). <article-title>The role of scientific knowledge in shaping public attitudes to GM technologies</article-title>. <source>Public Understanding of Science</source>. <comment>Advance online publication</comment>. doi:0.1177/0963662511430577<pub-id pub-id-type="doi">0.1177/0963662511430577</pub-id></citation>
</ref>
<ref id="bibr131-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Miles</surname><given-names>J.</given-names></name>
<name><surname>Petrie</surname><given-names>C.</given-names></name>
<name><surname>Steel</surname><given-names>M.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Slimming on the internet</article-title>. <source>Journal of the Royal Society of Medicine</source>, <volume>93</volume>, <fpage>254</fpage>.</citation>
</ref>
<ref id="bibr132-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mitchell</surname><given-names>K. J.</given-names></name>
<name><surname>Zaragoza</surname><given-names>M. S.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Repeated exposure to suggestion and false memory: The role of contextual variability</article-title>. <source>Journal of Memory and Language</source>, <volume>35</volume>, <fpage>246</fpage>–<lpage>260</lpage>.</citation>
</ref>
<ref id="bibr133-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Mooney</surname><given-names>C.</given-names></name>
</person-group> (<year>2007</year>). <article-title>An inconvenient assessment</article-title>. <source>Bulletin of the Atomic Scientists</source>, <volume>63</volume>, <fpage>40</fpage>–<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr134-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moscovitch</surname><given-names>M.</given-names></name>
<name><surname>Melo</surname><given-names>B.</given-names></name>
</person-group> (<year>1997</year>). <article-title>Strategic retrieval and the frontal lobes: Evidence from confabulation and amnesia</article-title>. <source>Neuropsychologia</source>, <volume>35</volume>, <fpage>1017</fpage>–<lpage>1034</lpage>.</citation>
</ref>
<ref id="bibr135-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Munro</surname><given-names>G. D.</given-names></name>
</person-group> (<year>2010</year>). <article-title>The scientific impotence excuse: Discounting belief-threatening scientific abstracts</article-title>. <source>Journal of Applied Social Psychology</source>, <volume>40</volume>, <fpage>579</fpage>–<lpage>600</lpage>.</citation>
</ref>
<ref id="bibr136-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Myers</surname><given-names>M.</given-names></name>
<name><surname>Pineda</surname><given-names>D.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Misinformation about vaccines</article-title>. In <person-group person-group-type="editor">
<name><surname>Barrett</surname><given-names>A. D. T.</given-names></name>
<name><surname>Stanberry</surname><given-names>L.</given-names></name>
</person-group> (Eds.), <source>Vaccines for biodefense and emerging and neglected diseases</source> (pp. <fpage>255</fpage>–<lpage>270</lpage>). <publisher-loc>London, England</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</citation>
</ref>
<ref id="bibr137-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Newell</surname><given-names>B. R.</given-names></name>
<name><surname>Fernandez</surname><given-names>D.</given-names></name>
</person-group> (<year>2006</year>). <article-title>On the binary quality of recognition and the inconsequentially of further knowledge: Two critical tests of the recognition heuristic</article-title>. <source>Journal of Behavioral Decision Making</source>, <volume>19</volume>, <fpage>333</fpage>–<lpage>346</lpage>.</citation>
</ref>
<ref id="bibr138-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nisbet</surname><given-names>M. C.</given-names></name>
<name><surname>Maibach</surname><given-names>E.</given-names></name>
<name><surname>Leiserowitz</surname><given-names>A.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Framing peak petroleum as a public health problem: Audience research and participatory engagement in the United States</article-title>. <source>American Journal of Public Health</source>, <volume>101</volume>, <fpage>1620</fpage>–<lpage>1626</lpage>.</citation>
</ref>
<ref id="bibr139-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nyhan</surname><given-names>B.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Why the “death panel” myth wouldn’t die: Misinformation in the health care reform debate</article-title>. <source>The Forum</source>, <volume>8</volume>(<issue>1</issue>), <comment>Article 5</comment>. doi:10.2202/1540-8884.1354<pub-id pub-id-type="doi">10.2202/1540-8884.1354</pub-id></citation>
</ref>
<ref id="bibr140-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nyhan</surname><given-names>B.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The limited effects of testimony on political persuasion</article-title>. <source>Public Choice</source>, <volume>148</volume>, <fpage>283</fpage>–<lpage>312</lpage>.</citation>
</ref>
<ref id="bibr141-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nyhan</surname><given-names>B.</given-names></name>
<name><surname>Reifler</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>When corrections fail: The persistence of political misperceptions</article-title>. <source>Political Behavior</source>, <volume>32</volume>, <fpage>303</fpage>–<lpage>330</lpage>.</citation>
</ref>
<ref id="bibr142-1529100612451018">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Nyhan</surname><given-names>B.</given-names></name>
<name><surname>Reifler</surname><given-names>J.</given-names></name>
</person-group> (<year>2011</year>). <source>Opening the political mind? The effects of self-affirmation and graphical information on factual misperceptions</source>. <comment>Unpublished manuscript</comment>, <publisher-name>Dartmouth College</publisher-name>, <publisher-loc>Hanover, NH</publisher-loc>.</citation>
</ref>
<ref id="bibr143-1529100612451018">
<citation citation-type="other">
<person-group person-group-type="author">
<name><surname>Nyhan</surname><given-names>B.</given-names></name>
<name><surname>Reifler</surname><given-names>J.</given-names></name>
</person-group> (<year>2012</year>). <source>Misinformation and corrections: Research findings from social science</source>. <comment>Unpublished manuscript</comment>, <publisher-name>Dartmouth College</publisher-name>, <publisher-loc>Hanover, NH</publisher-loc>.</citation>
</ref>
<ref id="bibr144-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Oreskes</surname><given-names>N.</given-names></name>
<name><surname>Conway</surname><given-names>E. M.</given-names></name>
</person-group> (<year>2010</year>). <source>Merchants of doubt</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Bloomsbury</publisher-name>.</citation>
</ref>
<ref id="bibr145-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Osborne</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Arguing to learn in science: The role of collaborative, critical discourse</article-title>. <source>Science</source>, <volume>328</volume>, <fpage>463</fpage>–<lpage>466</lpage>.</citation>
</ref>
<ref id="bibr146-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Owens</surname><given-names>S. R.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Injection of confidence: The recent controversy in the UK has led to falling MMR vaccination rates</article-title>. <source>European Molecular Biology Organization Reports</source>, <volume>3</volume>, <fpage>406</fpage>–<lpage>409</lpage>.</citation>
</ref>
<ref id="bibr147-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Paluck</surname><given-names>E. L.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Reducing intergroup prejudice and conflict using the media: A field experiment in Rwanda</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>96</volume>, <fpage>574</fpage>–<lpage>587</lpage>.</citation>
</ref>
<ref id="bibr148-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pandey</surname><given-names>A.</given-names></name>
<name><surname>Patni</surname><given-names>N.</given-names></name>
<name><surname>Singh</surname><given-names>M.</given-names></name>
<name><surname>Sood</surname><given-names>A.</given-names></name>
<name><surname>Singh</surname><given-names>G.</given-names></name>
</person-group> (<year>2010</year>). <article-title>YouTube as a source of information on the H1N1 influenza pandemic</article-title>. <source>American Journal of Preventive Medicine</source>, <volume>38</volume>, <fpage>e1</fpage>–<lpage>e3</lpage>.</citation>
</ref>
<ref id="bibr149-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Parrott</surname><given-names>W.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Genetically modified myths and realities</article-title>. <source>New Biotechnology</source>, <volume>27</volume>, <fpage>545</fpage>–<lpage>551</lpage>.</citation>
</ref>
<ref id="bibr150-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pedersen</surname><given-names>A.</given-names></name>
<name><surname>Attwell</surname><given-names>J.</given-names></name>
<name><surname>Heveli</surname><given-names>D.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Prediction of negative attitudes toward Australian asylum seekers: False beliefs, nationalism, and self-esteem</article-title>. <source>Australian Journal of Psychology</source>, <volume>57</volume>, <fpage>148</fpage>–<lpage>160</lpage>.</citation>
</ref>
<ref id="bibr151-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pedersen</surname><given-names>A.</given-names></name>
<name><surname>Clarke</surname><given-names>S.</given-names></name>
<name><surname>Dudgeon</surname><given-names>P.</given-names></name>
<name><surname>Griffiths</surname><given-names>B.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Attitudes toward indigenous Australians and asylum seekers: The role of false beliefs and other social-psychological variables</article-title>. <source>Australian Psychologist</source>, <volume>40</volume>, <fpage>170</fpage>–<lpage>178</lpage>.</citation>
</ref>
<ref id="bibr152-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pedersen</surname><given-names>A.</given-names></name>
<name><surname>Griffiths</surname><given-names>B.</given-names></name>
<name><surname>Watt</surname><given-names>S. E.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Attitudes toward out-groups and the perception of consensus: All feet do not wear one shoe</article-title>. <source>Journal of Community &amp; Applied Social Psychology</source>, <volume>18</volume>, <fpage>543</fpage>–<lpage>557</lpage>.</citation>
</ref>
<ref id="bibr153-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pennington</surname><given-names>N.</given-names></name>
<name><surname>Hastie</surname><given-names>R.</given-names></name>
</person-group> (<year>1992</year>). <article-title>Explaining the evidence: Tests of the story model for juror decision making</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>62</volume>, <fpage>189</fpage>–<lpage>206</lpage>.</citation>
</ref>
<ref id="bibr154-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Pennington</surname><given-names>N.</given-names></name>
<name><surname>Hastie</surname><given-names>R.</given-names></name>
</person-group> (<year>1993</year>). <article-title>The story model for juror decision making</article-title>. In <person-group person-group-type="editor">
<name><surname>Hastie</surname><given-names>R.</given-names></name>
</person-group> (Ed.), <source>Inside the juror</source> (pp. <fpage>192</fpage>–<lpage>223</lpage>.). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr155-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peters</surname><given-names>E. M.</given-names></name>
<name><surname>Burraston</surname><given-names>B.</given-names></name>
<name><surname>Mertz</surname><given-names>C. K.</given-names></name>
</person-group> (<year>2004</year>). <article-title>An emotion-based model of risk perception and stigma susceptibility: Cognitive appraisals of emotion, affective reactivity, worldviews and risk perceptions in the generation of technological stigma</article-title>. <source>Risk Analysis</source>, <volume>24</volume>, <fpage>1349</fpage>–<lpage>1367</lpage>.</citation>
</ref>
<ref id="bibr156-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Peters</surname><given-names>K.</given-names></name>
<name><surname>Kashima</surname><given-names>Y.</given-names></name>
<name><surname>Clark</surname><given-names>A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Talking about others: Emotionality and the dissemination of social information</article-title>. <source>European Journal of Social Psychology</source>, <volume>39</volume>, <fpage>207</fpage>–<lpage>222</lpage>.</citation>
</ref>
<ref id="bibr157-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Petrovic</surname><given-names>M.</given-names></name>
<name><surname>Roberts</surname><given-names>R.</given-names></name>
<name><surname>Ramsay</surname><given-names>M.</given-names></name>
</person-group> (<year>2001</year>). <article-title>Second dose of measles, mumps, and rubella vaccine: Questionnaire survey of health professionals</article-title>. <source>British Medical Journal</source>, <volume>322</volume>, <fpage>82</fpage>–<lpage>85</lpage>.</citation>
</ref>
<ref id="bibr158-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Petty</surname><given-names>R. E.</given-names></name>
<name><surname>Cacioppo</surname><given-names>J. T.</given-names></name>
</person-group> (<year>1986</year>). <article-title>The elaboration likelihood model of persuasion</article-title>. <source>Advances in Experimental Social Psychology</source>, <volume>19</volume>, <fpage>123</fpage>–<lpage>205</lpage>.</citation>
</ref>
<ref id="bibr159-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Piaget</surname><given-names>J.</given-names></name>
</person-group> (<year>1928</year>). <source>The child’s conception of the world</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Routledge and Kegan Paul</publisher-name>.</citation>
</ref>
<ref id="bibr160-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Pickel</surname><given-names>K. L.</given-names></name>
</person-group> (<year>1995</year>). <article-title>Inducing jurors to disregard inadmissible evidence: A legal explanation does not help</article-title>. <source>Law and Human Behavior</source>, <volume>19</volume>, <fpage>407</fpage>–<lpage>424</lpage>.</citation>
</ref>
<ref id="bibr161-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Piper</surname><given-names>P.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Better read that again: Web hoaxes and misinformation</article-title>. <source>Searcher</source>, <volume>8</volume>, <fpage>40</fpage>–<lpage>49</lpage>.</citation>
</ref>
<ref id="bibr162-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Plous</surname><given-names>S.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Biases in the assimilation of technological breakdowns—Do accidents make us safer?</article-title> <source>Journal of Applied Social Psychology</source>, <volume>21</volume>, <fpage>1058</fpage>–<lpage>1082</lpage>.</citation>
</ref>
<ref id="bibr163-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Poland</surname><given-names>G. A.</given-names></name>
<name><surname>Jacobsen</surname><given-names>R. M.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The age-old struggle against the antivaccinationists</article-title>. <source>The New England Journal of Medicine</source>, <volume>364</volume>, <fpage>97</fpage>–<lpage>99</lpage>.</citation>
</ref>
<ref id="bibr164-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Poland</surname><given-names>G. A.</given-names></name>
<name><surname>Spier</surname><given-names>R.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Fear, misinformation, and innumerates: How the Wakefield paper, the press, and advocacy groups damaged the public health</article-title>. <source>Vaccine</source>, <volume>28</volume>, <fpage>2361</fpage>–<lpage>2362</lpage>.</citation>
</ref>
<ref id="bibr165-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Prasad</surname><given-names>M.</given-names></name>
<name><surname>Perrin</surname><given-names>A. J.</given-names></name>
<name><surname>Bezila</surname><given-names>K.</given-names></name>
<name><surname>Hoffman</surname><given-names>S. G.</given-names></name>
<name><surname>Kindleberger</surname><given-names>K.</given-names></name>
<name><surname>Manturuk</surname><given-names>K.</given-names></name>
<name><surname>. . . Powers</surname><given-names>A. S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>“There must be a reason”: Osama, Saddam, and inferred justification</article-title>. <source>Sociological Inquiry</source>, <volume>79</volume>, <fpage>142</fpage>–<lpage>162</lpage>.</citation>
</ref>
<ref id="bibr166-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Prior</surname><given-names>M.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Liberated viewers, polarized voters: The implications of increased media choice for democratic politics</article-title>. <source>The Good Society</source>, <volume>11</volume>, <fpage>10</fpage>–<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr167-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Proctor</surname><given-names>R. N.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Should medical historians be working for the tobacco industry?</article-title> <source>The Lancet</source>, <volume>363</volume>, <fpage>1174</fpage>–<lpage>1175</lpage>.</citation>
</ref>
<ref id="bibr168-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Proctor</surname><given-names>R. N.</given-names></name>
</person-group> (<year>2008</year>). <article-title>On playing the Nazi card</article-title>. <source>Tobacco Control</source>, <volume>17</volume>, <fpage>289</fpage>–<lpage>290</lpage>.</citation>
</ref>
<ref id="bibr169-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Radwanick</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>, <month>December</month>). <source>More than 200 billion online videos viewed globally in October</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.comscore.com/press_events/press_releases/2011/12/more_than_200_billion_online_videos_viewed_globally_in_october">http://www.comscore.com/press_events/press_releases/2011/12/more_than_200_billion_online_videos_viewed_globally_in_october</ext-link></comment></citation>
</ref>
<ref id="bibr170-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Rampton</surname><given-names>J.</given-names></name>
<name><surname>Stauber</surname><given-names>S.</given-names></name>
</person-group> (<year>2003</year>). <source>The uses of propaganda in Bush’s war on Iraq</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Tarcher/Penguin</publisher-name>.</citation>
</ref>
<ref id="bibr171-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Ramsay</surname><given-names>C.</given-names></name>
<name><surname>Kull</surname><given-names>S.</given-names></name>
<name><surname>Lewis</surname><given-names>E.</given-names></name>
<name><surname>Subias</surname><given-names>S.</given-names></name>
</person-group> (<year>2010</year>). <source>Misinformation and the 2010 election: A study of the US electorate</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://drum.lib.umd.edu/bitstream/1903/11375/3/misinformation_dec10_quaire.pdf">http://drum.lib.umd.edu/bitstream/1903/11375/3/misinformation_dec10_quaire.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr172-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rapp</surname><given-names>D. N.</given-names></name>
<name><surname>Kendeou</surname><given-names>P.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Revisiting what readers know: Updating text representations during narrative comprehension</article-title>. <source>Memory &amp; Cognition</source>, <volume>35</volume>, <fpage>2019</fpage>–<lpage>2032</lpage>.</citation>
</ref>
<ref id="bibr173-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ratzan</surname><given-names>S. C.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Editorial: Setting the record straight: Vaccines, autism, and The Lancet</article-title>. <source>Journal of Health Communication</source>, <volume>15</volume>, <fpage>237</fpage>–<lpage>239</lpage>.</citation>
</ref>
<ref id="bibr174-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Readfearn</surname><given-names>G.</given-names></name>
</person-group> (<year>2011</year>). <source>A Sunrise climate cock-up and reading cat’s paws</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.readfearn.com/2011/01/a-sunrise-climate-cock-up-and-reading-cats-paws/">http://www.readfearn.com/2011/01/a-sunrise-climate-cock-up-and-reading-cats-paws/</ext-link></comment></citation>
</ref>
<ref id="bibr175-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Reber</surname><given-names>R.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Effects of perceptual fluency on judgments of truth</article-title>. <source>Consciousness and Cognition</source>, <volume>8</volume>, <fpage>338</fpage>–<lpage>342</lpage>.</citation>
</ref>
<ref id="bibr176-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Reese</surname><given-names>S.</given-names></name>
<name><surname>Lewis</surname><given-names>S.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Framing the war on terror</article-title>. <source>Journalism</source>, <volume>10</volume>, <fpage>777</fpage>–<lpage>797</lpage>.</citation>
</ref>
<ref id="bibr177-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Riesch</surname><given-names>H.</given-names></name>
<name><surname>Spiegelhalter</surname><given-names>D. J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>‘Careless pork costs lives’: Risk stories from science to press release to media</article-title>. <source>Health, Risk &amp; Society</source>, <volume>13</volume>, <fpage>47</fpage>–<lpage>64</lpage>.</citation>
</ref>
<ref id="bibr178-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ross</surname><given-names>L.</given-names></name>
</person-group> (<year>1977</year>). <article-title>The intuitive psychologist and his shortcomings: Distortion in the attribution process</article-title>. <source>Advances in Experimental Social Psychology</source>, <volume>10</volume>, <fpage>174</fpage>–<lpage>221</lpage>.</citation>
</ref>
<ref id="bibr179-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sanna</surname><given-names>L. J.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Metacognitive experiences and human judgment: The case of hindsight bias and its debiasing</article-title>. <source>Current Directions in Psychological Science</source>, <volume>17</volume>, <fpage>172</fpage>–<lpage>176</lpage>.</citation>
</ref>
<ref id="bibr180-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sanna</surname><given-names>L. J.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
<name><surname>Stocker</surname><given-names>S. L.</given-names></name>
</person-group> (<year>2002</year>). <article-title>When debiasing backfires: Accessible content and accessibility experiences in debiasing hindsight</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>28</volume>, <fpage>497</fpage>–<lpage>502</lpage>.</citation>
</ref>
<ref id="bibr181-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scanfeld</surname><given-names>D.</given-names></name>
<name><surname>Scanfeld</surname><given-names>V.</given-names></name>
<name><surname>Larson</surname><given-names>E. L.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Dissemination of health information through social networks: Twitter and antibiotics</article-title>. <source>American Journal of Infection Control</source>, <volume>38</volume>, <fpage>182</fpage>–<lpage>188</lpage>.</citation>
</ref>
<ref id="bibr182-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schul</surname><given-names>Y.</given-names></name>
</person-group> (<year>1993</year>). <article-title>When warning succeeds: The effect of warning on success in ignoring invalid information</article-title>. <source>Journal of Experimental Social Psychology</source>, <volume>29</volume>, <fpage>42</fpage>–<lpage>62</lpage>.</citation>
</ref>
<ref id="bibr183-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schul</surname><given-names>Y.</given-names></name>
<name><surname>Mayo</surname><given-names>R.</given-names></name>
<name><surname>Burnstein</surname><given-names>E.</given-names></name>
</person-group> (<year>2008</year>). <article-title>The value of distrust</article-title>. <source>Journal of Experimental Social Psychology</source>, <volume>44</volume>, <fpage>1293</fpage>–<lpage>1302</lpage>.</citation>
</ref>
<ref id="bibr184-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schul</surname><given-names>Y.</given-names></name>
<name><surname>Mazursky</surname><given-names>D.</given-names></name>
</person-group> (<year>1990</year>). <article-title>Conditions facilitating successful discounting in consumer decision making</article-title>. <source>Journal of Consumer Research</source>, <volume>16</volume>, <fpage>442</fpage>–<lpage>451</lpage>.</citation>
</ref>
<ref id="bibr185-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schwartz</surname><given-names>B. S.</given-names></name>
<name><surname>Parker</surname><given-names>C. L.</given-names></name>
<name><surname>Hess</surname><given-names>J.</given-names></name>
<name><surname>Frumkin</surname><given-names>H.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Public health and medicine in an age of energy scarcity: The case of petroleum</article-title>. <source>American Journal of Public Health</source>, <volume>101</volume>, <fpage>1560</fpage>–<lpage>1567</lpage>.</citation>
</ref>
<ref id="bibr186-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Judgment in a social context: Biases, shortcomings, and the logic of conversation</article-title>. <source>Advances in Experimental Social Psychology</source>, <volume>26</volume>, <fpage>123</fpage>–<lpage>162</lpage>.</citation>
</ref>
<ref id="bibr187-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>1996</year>). <source>Cognition and communication: Judgmental biases, research methods, and the logic of conversation</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr188-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Meta-cognitive experiences in consumer judgment and decision making</article-title>. <source>Journal of Consumer Psychology</source>, <volume>14</volume>, <fpage>332</fpage>–<lpage>348</lpage>.</citation>
</ref>
<ref id="bibr189-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
<name><surname>Sanna</surname><given-names>L. J.</given-names></name>
<name><surname>Skurnik</surname><given-names>I.</given-names></name>
<name><surname>Yoon</surname><given-names>C.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Metacognitive experiences and the intricacies of setting people straight: Implications for debiasing and public information campaigns</article-title>. <source>Advances in Experimental Social Psychology</source>, <volume>39</volume>, <fpage>127</fpage>–<lpage>161</lpage>.</citation>
</ref>
<ref id="bibr190-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Seifert</surname><given-names>C. M.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The continued influence of misinformation in memory: What makes a correction effective?</article-title> <source>Psychology of Learning and Motivation</source>, <volume>41</volume>, <fpage>265</fpage>–<lpage>292</lpage>.</citation>
</ref>
<ref id="bibr191-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Sides</surname><given-names>J.</given-names></name>
</person-group> (<year>2010</year>). <source>Why do more people think Obama is a Muslim?</source> <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://voices.washingtonpost.com/ezra-klein/2010/08/why_do_more_people_think_obama.html">http://voices.washingtonpost.com/ezra-klein/2010/08/why_do_more_people_think_obama.html</ext-link></comment></citation>
</ref>
<ref id="bibr192-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Skurnik</surname><given-names>I.</given-names></name>
<name><surname>Yoon</surname><given-names>C.</given-names></name>
<name><surname>Park</surname><given-names>D. C.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>2005</year>). <article-title>How warnings about false claims become recommendations</article-title>. <source>Journal of Consumer Research</source>, <volume>31</volume>, <fpage>713</fpage>–<lpage>724</lpage>.</citation>
</ref>
<ref id="bibr193-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Smith</surname><given-names>P.</given-names></name>
<name><surname>Bansal-Travers</surname><given-names>M.</given-names></name>
<name><surname>O’Connor</surname><given-names>R.</given-names></name>
<name><surname>Brown</surname><given-names>A.</given-names></name>
<name><surname>Banthin</surname><given-names>C.</given-names></name>
<name><surname>Guardino-Colket</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Correcting over 50 years of tobacco industry misinformation</article-title>. <source>American Journal of Preventive Medicine</source>, <volume>40</volume>, <fpage>690</fpage>–<lpage>698</lpage>.</citation>
</ref>
<ref id="bibr194-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Song</surname><given-names>H.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Fluency and the detection of distortions: Low processing fluency attenuates the Moses illusion</article-title>. <source>Social Cognition</source>, <volume>26</volume>, <fpage>791</fpage>–<lpage>799</lpage>.</citation>
</ref>
<ref id="bibr195-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Sperber</surname><given-names>D.</given-names></name>
<name><surname>Wilson</surname><given-names>D.</given-names></name>
</person-group> (<year>1986</year>). <source>Relevance: Communication and cognition</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</citation>
</ref>
<ref id="bibr196-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stroud</surname><given-names>N. J.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Polarization and partisan selective exposure</article-title>. <source>Journal of Communication</source>, <volume>60</volume>, <fpage>556</fpage>–<lpage>576</lpage>.</citation>
</ref>
<ref id="bibr197-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Taber</surname><given-names>C. S.</given-names></name>
<name><surname>Lodge</surname><given-names>M.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Motivated skepticism in the evaluation of political beliefs</article-title>. <source>American Journal of Political Science</source>, <volume>50</volume>, <fpage>755</fpage>–<lpage>769</lpage>.</citation>
</ref>
<ref id="bibr198-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Tenney</surname><given-names>E. R.</given-names></name>
<name><surname>Cleary</surname><given-names>H. M. D.</given-names></name>
<name><surname>Spellman</surname><given-names>B. A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Unpacking the doubt in “beyond a reasonable doubt”: Plausible alternative stories increase not guilty verdicts</article-title>. <source>Basic and Applied Social Psychology</source>, <volume>31</volume>, <fpage>1</fpage>–<lpage>8</lpage>.</citation>
</ref>
<ref id="bibr199-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Thaler</surname><given-names>R. H.</given-names></name>
<name><surname>Sunstein</surname><given-names>C. R.</given-names></name>
</person-group> (<year>2008</year>). <source>Nudge: Improving decisions about health, wealth, and happiness</source>. <publisher-loc>New Haven, CT</publisher-loc>: <publisher-name>Yale University Press</publisher-name>.</citation>
</ref>
<ref id="bibr200-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Tiffen</surname><given-names>R.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Reversed negatives: How the news media respond to “our” atrocities</article-title>. In <person-group person-group-type="editor">
<name><surname>Stritzke</surname><given-names>W. G. K.</given-names></name>
<name><surname>Lewandowsky</surname><given-names>S.</given-names></name>
<name><surname>Denemark</surname><given-names>D.</given-names></name>
<name><surname>Clare</surname><given-names>J.</given-names></name>
<name><surname>Morgan</surname><given-names>F.</given-names></name>
</person-group> (Eds.), <source>Terrorism and torture</source> (pp. <fpage>246</fpage>–<lpage>264</lpage>). <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr201-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Todorov</surname><given-names>A.</given-names></name>
<name><surname>Mandisodza</surname><given-names>A. N.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Public opinion on foreign policy: The multilateral public that perceives itself as unilateral</article-title>. <source>Public Opinion Quarterly</source>, <volume>68</volume>, <fpage>323</fpage>–<lpage>348</lpage>.</citation>
</ref>
<ref id="bibr202-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Topolinski</surname><given-names>S.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Nonpropositional consistency</article-title>. In <person-group person-group-type="editor">
<name><surname>Gawronski</surname><given-names>B.</given-names></name>
<name><surname>Strack</surname><given-names>F.</given-names></name>
</person-group> (Eds.), <source>Cognitive consistency: A fundamental principle in social cognition</source> (pp. <fpage>112</fpage>–<lpage>131</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</citation>
</ref>
<ref id="bibr203-1529100612451018">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Travis</surname><given-names>S.</given-names></name>
</person-group> (<year>2010</year>). <source>CNN poll: Quarter doubt Obama was born in U.S</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://politicalticker.blogs.cnn.com/2010/08/04/cnn-poll-quarter-doubt-president-was-born-in-u-s/">http://politicalticker.blogs.cnn.com/2010/08/04/cnn-poll-quarter-doubt-president-was-born-in-u-s/</ext-link></comment></citation>
</ref>
<ref id="bibr204-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van Oostendorp</surname><given-names>H.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Updating situation models derived from newspaper articles</article-title>. <source>Medienpsychologie</source>, <volume>8</volume>, <fpage>21</fpage>–<lpage>33</lpage>.</citation>
</ref>
<ref id="bibr205-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>van Oostendorp</surname><given-names>H.</given-names></name>
<name><surname>Bonebakker</surname><given-names>C.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Difficulties in updating mental representations during reading news reports</article-title>. In <person-group person-group-type="editor">
<name><surname>van Oostendorp</surname><given-names>H.</given-names></name>
<name><surname>Goldman</surname><given-names>S. R</given-names></name>
</person-group> (Eds.), <source>The construction of mental representations during reading</source> (pp. <fpage>319</fpage>–<lpage>339</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr206-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Verkoeijen</surname><given-names>P. P. J. L.</given-names></name>
<name><surname>Rikers</surname><given-names>R. M. J. P.</given-names></name>
<name><surname>Schmidt</surname><given-names>H. G.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Detrimental influence of contextual change on spacing effects in free recall</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>30</volume>, <fpage>796</fpage>–<lpage>800</lpage>.</citation>
</ref>
<ref id="bibr207-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Weaver</surname><given-names>K.</given-names></name>
<name><surname>Garcia</surname><given-names>S. M.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
<name><surname>Miller</surname><given-names>D. T.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Inferring the popularity of an opinion from its familiarity: A repetitive voice can sound like a chorus</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>92</volume>, <fpage>821</fpage>–<lpage>833</lpage>.</citation>
</ref>
<ref id="bibr208-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Whyte</surname><given-names>K. P.</given-names></name>
<name><surname>Crease</surname><given-names>R. P.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Trust, expertise, and the philosophy of science</article-title>. <source>Synthese</source>, <volume>177</volume>, <fpage>411</fpage>–<lpage>425</lpage>.</citation>
</ref>
<ref id="bibr209-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilkes</surname><given-names>A. L.</given-names></name>
<name><surname>Leatherbarrow</surname><given-names>M.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Editing episodic memory following the identification of error</article-title>. <source>Quarterly Journal of Experimental Psychology: Human Experimental Psychology</source>, <volume>40</volume>, <fpage>361</fpage>–<lpage>387</lpage>.</citation>
</ref>
<ref id="bibr210-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilkes</surname><given-names>A. L.</given-names></name>
<name><surname>Reynolds</surname><given-names>D. J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>On certain limitations accompanying readers’ interpretations of corrections in episodic text</article-title>. <source>The Quarterly Journal of Experimental Psychology, 52A</source>, <fpage>165</fpage>–<lpage>183</lpage>.</citation>
</ref>
<ref id="bibr211-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilkie</surname><given-names>W. L.</given-names></name>
<name><surname>McNeill</surname><given-names>D. L.</given-names></name>
<name><surname>Mazis</surname><given-names>M. B.</given-names></name>
</person-group> (<year>1984</year>). <article-title>Marketing’s “scarlet letter”: The theory and practice of corrective advertising</article-title>. <source>The Journal of Marketing</source>, <volume>48</volume>, <fpage>11</fpage>–<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr212-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>E. A.</given-names></name>
<name><surname>Park</surname><given-names>D. C.</given-names></name>
</person-group> (<year>2008</year>). <article-title>A case for clarity in the writing of health statements</article-title>. <source>Patient Education and Counseling</source>, <volume>72</volume>, <fpage>330</fpage>–<lpage>335</lpage>.</citation>
</ref>
<ref id="bibr213-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wilson</surname><given-names>T. D.</given-names></name>
<name><surname>Brekke</surname><given-names>N.</given-names></name>
</person-group> (<year>1994</year>). <article-title>Mental contamination and mental correction: Unwanted influences on judgments and evaluations</article-title>. <source>Psychological Bulletin</source>, <volume>116</volume>, <fpage>117</fpage>–<lpage>142</lpage>.</citation>
</ref>
<ref id="bibr214-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Winkielman</surname><given-names>P.</given-names></name>
<name><surname>Huber</surname><given-names>D. E.</given-names></name>
<name><surname>Kavanagh</surname><given-names>L.</given-names></name>
<name><surname>Schwarz</surname><given-names>N.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Fluency of consistency: When thoughts fit nicely and flow smoothly</article-title>. In <person-group person-group-type="editor">
<name><surname>Gawronski</surname><given-names>B.</given-names></name>
<name><surname>Strack</surname><given-names>F.</given-names></name>
</person-group> (Eds.), <source>Cognitive consistency: A fundamental principle in social cognition</source> (pp. <fpage>89</fpage>–<lpage>111</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</citation>
</ref>
<ref id="bibr215-1529100612451018">
<citation citation-type="gov">
<person-group person-group-type="author">
<name><surname>Winters</surname><given-names>K. H.</given-names></name>
</person-group> (<year>2008</year>). <source>Investigative Summary Regarding Allegations That NASA Suppressed Climate Change Science and Denied Media Access to Dr. James E. Hansen, a NASA Scientist</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://oig.nasa.gov/investigations/oi_sti_summary.pdf">http://oig.nasa.gov/investigations/oi_sti_summary.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr216-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wolf</surname><given-names>S.</given-names></name>
<name><surname>Montgomery</surname><given-names>D. A.</given-names></name>
</person-group> (<year>1977</year>). <article-title>Effects of inadmissible evidence and level of judicial admonishment to disregard on the judgments of mock jurors</article-title>. <source>Journal of Applied Social Psychology</source>, <volume>7</volume>, <fpage>205</fpage>–<lpage>219</lpage>.</citation>
</ref>
<ref id="bibr217-1529100612451018">
<citation citation-type="web">
<collab>World Health Organization</collab>. (<year>2005</year>). <source>Modern food biotechnology, human health and development: an evidence-based study</source>. <comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.who.int/foodsafety/publications/biotech/biotech_en.pdf">http://www.who.int/foodsafety/publications/biotech/biotech_en.pdf</ext-link></comment></citation>
</ref>
<ref id="bibr218-1529100612451018">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wyer</surname><given-names>R. S.</given-names></name>
</person-group> (<year>1974</year>). <source>Cognitive organization and change: An information processing approach</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr219-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Young</surname><given-names>S. D.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Recommendations for using online social networking technologies to reduce inaccurate online health information</article-title>. <source>Online Journal of Health and Allied Sciences</source>, <volume>10</volume>, <fpage>2</fpage>.</citation>
</ref>
<ref id="bibr220-1529100612451018">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zaragoza</surname><given-names>M. S.</given-names></name>
<name><surname>Mitchell</surname><given-names>K. J.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Repeated exposure to suggestion and the creation of false memories</article-title>. <source>Psychological Science</source>, <volume>7</volume>, <fpage>294</fpage>–<lpage>300</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>