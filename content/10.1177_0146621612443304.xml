<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">APM</journal-id>
<journal-id journal-id-type="hwp">spapm</journal-id>
<journal-title>Applied Psychological Measurement</journal-title>
<issn pub-type="ppub">0146-6216</issn>
<issn pub-type="epub">1552-3497</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0146621612443304</article-id>
<article-id pub-id-type="publisher-id">10.1177_0146621612443304</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Problem of Bias in Person Parameter Estimation in Adaptive Testing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Doebler</surname><given-names>Anna</given-names></name>
<xref ref-type="aff" rid="aff1-0146621612443304">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-0146621612443304"><label>1</label>Westfälische Wilhelms-Universität Münster, Germany</aff>
<author-notes>
<corresp id="corresp1-0146621612443304">Anna Doebler, Westfälische Wilhelms-Universität Münster, Institute of Psychology, Fliednerstrasse 21, 48149 Münster, Germany Email: <email>anna.doebler@uni-muenster.de</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>6</month>
<year>2012</year>
</pub-date>
<volume>36</volume>
<issue>4</issue>
<fpage>255</fpage>
<lpage>270</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>It is shown that deviations of estimated from true values of item difficulty parameters, caused for example by item calibration errors, the neglect of randomness of item difficulty parameters, testlet effects, or rule-based item generation, can lead to systematic bias in point estimation of person parameters in the context of adaptive testing. This effect occurs even when the errors of the item difficulty parameters are themselves unbiased. Analytical calculations as well as simulation studies are discussed.</p>
</abstract>
<kwd-group>
<kwd>computerized adaptive testing</kwd>
<kwd>biased point estimation</kwd>
<kwd>item response theory</kwd>
<kwd>calibration errors</kwd>
<kwd>differential item functioning</kwd>
<kwd>testlets</kwd>
<kwd>computerized item generation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>As many computer-based methods are readily available nowadays, adaptive testing has become a popular and efficient testing method in psychometrics. The basic principle of an adaptive test can be shortly described as follows: An examinee is first given a few items to obtain a crude initial estimate of the person parameter. Then the next item is chosen so that it contributes maximally to the precision of the updated estimate obtained after the examinee has completed the item. Therefore, several item selection criteria have been developed, for example, the criterion of maximal Fisher information, which is probably the most commonly used in practice (<xref ref-type="bibr" rid="bibr15-0146621612443304">van der Linden, 2010</xref>). Furthermore, a number of content- and test-specific constraints often have to be taken into account. The item selection process is iteratively repeated and terminates after a certain predefined number of items or when the estimate of the person parameter no longer changes significantly.</p>
<p>Item response theory (IRT) models are an essential element of adaptive testing, as they allow for an easy evaluation of the Fisher information for single items. A central feature of IRT models is that they have separate parameters to describe item and person characteristics. However, in this article it is shown that when the true item difficulty parameters of IRT models differ from the estimated ones, a systematic bias in the estimation of person parameters in adaptive testing arises, even when the errors of the difficulty parameters are unbiased.</p>
<p>Various sources of errors in item difficulty estimation are conceivable, four of which are discussed in the following section. Their effects will be demonstrated on person parameter estimation in adaptive testing analytically as well as by simulation studies with the Rasch, the two-parameter logistic (2PL), and the three-parameter logistic (3PL) models.</p>
<p>An already known phenomenon caused by imprecise item parameters in adaptive testing is the so-called <italic>capitalization on chance</italic>, which is described in more detail by <xref ref-type="bibr" rid="bibr16-0146621612443304">van der Linden and Glas (2000)</xref>. This effect is mainly due to the fact that an overestimation of the discrimination parameter leads to a disproportionate overestimation of the corresponding information function, which is a quadratic function of the discrimination. Hence, in many cases, the test algorithm prefers items with high-calibration errors. As a result, the accuracy of person parameter estimation is likely to be overestimated; however, no systematic bias is expected for the estimates themselves.</p>
<sec id="section1-0146621612443304">
<title>Sources of Variation in Item Difficulties</title>
<p>Deviations of the true item difficulty parameters from the estimated ones might be due to several reasons. Here four possible sources are briefly discussed, which are, depending on the specific testing situation, likely to contribute in varying degrees.</p>
<p>First, <italic>errors in the calibration of item parameters</italic> are generally not avoidable. In adaptive testing, a whole item pool rather than just a single test has to be calibrated. Furthermore, the items of the pool usually need to be replaced regularly to maintain item pool integrity. As calibrating new items is often expensive, the current trend is to minimize the size of the calibration sample (<xref ref-type="bibr" rid="bibr15-0146621612443304">van der Linden, 2010</xref>), which in most cases leads to increased calibration errors. Errors in item calibration might therefore often be more predominant in adaptive testing than in linear testing.</p>
<p>Second, the neglect of <italic>person- or subgroup-specific differences in item difficulties</italic> might equally result in a misfit between true and estimated difficulty parameters. Item parameters are usually modeled as fixed effects. However, especially the item difficulty parameters might be slightly different for different individual persons. It is not unusual that when given two items, A and B, some people find Item A more difficult than Item B, whereas other people have more problems dealing with Item B than with Item A. Furthermore, when there are distinguishable subgroups of respondents, (mean) difficulty parameters might also vary across different groups (differential item functioning [DIF]; see <xref ref-type="bibr" rid="bibr2-0146621612443304">Camilli &amp; Shepard, 1994</xref>; <xref ref-type="bibr" rid="bibr6-0146621612443304">Holland &amp; Wainer, 1993</xref>; <xref ref-type="bibr" rid="bibr10-0146621612443304">Osterlind &amp; Everson, 2009</xref>; <xref ref-type="bibr" rid="bibr21-0146621612443304">Zumbo, 2007</xref>). There are methods for detecting DIF, yet they are not always routinely applied. Also, they might only work when the differences are sufficiently large.</p>
<p>Although in classical IRT it is generally assumed that the difficulty of an item is not person or group dependent, it might therefore in many cases be more realistic to think of item difficulties as random parameters which differ across persons and/or groups (<xref ref-type="bibr" rid="bibr3-0146621612443304">De Boeck, 2008</xref>; <xref ref-type="bibr" rid="bibr12-0146621612443304">Rijmen &amp; De Boeck, 2002</xref>). Assuming that in the calibration of (fixed) item parameters the means of these random effects are estimated, deviations from these means to the true person- or group-dependent item difficulty parameters are likely to occur.</p>
<p>Third, another source of variation in item difficulty parameters can arise within tests that comprise so-called <italic>testlets</italic> (<xref ref-type="bibr" rid="bibr1-0146621612443304">Bradlow, Wainer, &amp; Wang, 1999</xref>; <xref ref-type="bibr" rid="bibr8-0146621612443304">Ip, 2010</xref>; <xref ref-type="bibr" rid="bibr13-0146621612443304">Scott &amp; Ip, 2002</xref>; <xref ref-type="bibr" rid="bibr14-0146621612443304">Sireci, Thissen, &amp; Wainer, 1991</xref>; <xref ref-type="bibr" rid="bibr17-0146621612443304">Wainer, Bradlow, &amp; Wang, 2007</xref>; <xref ref-type="bibr" rid="bibr18-0146621612443304">Wainer &amp; Kiely, 1987</xref>; <xref ref-type="bibr" rid="bibr19-0146621612443304">Wang &amp; Wilson, 2005</xref>). Testlets are subsets of items for which the assumption of local item independence might be violated. Often, items of the same testlet share a common stimulus (e.g., a reading passage or a table of numbers). In these situations, it can be assumed that the performance on the items not only depends on absolute values of item difficulties but also on how well the examinee is able to process the stimulus. In other words, true item difficulties are no longer fixed, but vary across persons, where the direction of the person-dependent shift of item difficulty is the same for all items that belong to the same testlet. <xref ref-type="bibr" rid="bibr17-0146621612443304">Wainer et al. (2007)</xref> point out that testlets are especially useful in adaptive testing, as they can be conveniently used to meet additional constraints.</p>
<p>Fourth, deviations of true from estimated values of item difficulty in adaptive testing can also arise from <italic>rule-based item generation</italic> (<xref ref-type="bibr" rid="bibr5-0146621612443304">Geerlings, Glas, &amp; van der Linden, 2011</xref>; <xref ref-type="bibr" rid="bibr7-0146621612443304">Holling, Bertling, &amp; Zeuch, 2009</xref>). This technique can significantly improve test security, as the traditional item pool is replaced by an (ideally) infinite pool of items that can be generated by a computer algorithm. The main idea for rule-based item generation is that the items in the pool are nested in families, where items that belong to the same family share the same values of item parameters and can be generated according to certain rules (item cloning). However, as the items within a family actually differ from one another, it can be assumed that in practical applications, the assumption of equal item parameters of items within the same family holds only approximately, so that, at least to a certain extent, deviations of the true from the estimated (mean) item difficulty parameters can be expected (<xref ref-type="bibr" rid="bibr15-0146621612443304">van der Linden, 2010</xref>).</p>
</sec>
<sec id="section2-0146621612443304">
<title>Systematic Bias in Estimating Persons</title>
<p>In adaptive testing, deviations of estimated from true values of item difficulty parameters, caused, for example, by the sources described in the previous section can lead to systematic bias in point estimation of person parameters. When the errors of the item parameter estimates are unbiased, a systematic overestimation of the absolute values of person parameter estimates is expected, which generally increases with absolute values of true person parameters.</p>
<p>For the sake of simplicity, the following explanation of this phenomenon is based on the family of Rasch models and the criterion of maximal Fisher information because here the next item of an adaptive test is chosen so that its difficulty parameter coincides with the current estimate of the person parameter. This is the situation in which the systematic bias of person parameter estimation occurs in “pure form.” However, as for other models and other selection criteria, a difficulty parameter close to the current estimate is in most cases also advantageous, the effect will also be observable in much more general settings. This is demonstrated in the following section by simulation studies, where, next to the Rasch model, also the 2PL and 3PL models are evaluated.</p>
<p>To explain the effect of biased person parameter estimation in adaptive testing with imprecise difficulty parameters, assume that the distribution of the true difficulty parameters in the item pool has its maximum around 0 and constantly fewer items on the left and right tail, which is a reasonable assumption in most settings of adaptive testing. In an arbitrary step of the iterative test algorithm, let <italic>y</italic> be the current estimate of the person parameter, and assume that <italic>y</italic> is unequal to zero. Let <italic>U</italic> be a small interval containing <italic>y</italic>, so that an item is to be selected with estimated difficulty in <italic>U</italic>. Having assumed error variance in the (unbiased) estimation of basic parameters, <italic>U</italic> is likely to contain estimated difficulty parameters of items for which the true difficulty parameter is not in <italic>U</italic>. Let <italic>I</italic><sub>1</sub> and <italic>I</italic><sub>2</sub> denote two intervals of the same length <italic>d</italic> bordering on <italic>U</italic> to the left and right, where <italic>I</italic><sub>1</sub> is the one more remote from 0. Let <italic>A</italic><sub>1</sub> be the number of true difficulty parameters β in <italic>I</italic><sub>1</sub> so that the error ξ of β is of such a magnitude that <inline-formula id="inline-formula1-0146621612443304">
<mml:math display="inline" id="math1-0146621612443304">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mtext>ξ</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula> or <inline-formula id="inline-formula2-0146621612443304">
<mml:math display="inline" id="math2-0146621612443304">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mtext>ξ</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula> is in <italic>U</italic>. Let <italic>A</italic><sub>2</sub> denote the same number for <italic>I</italic><sub>2</sub>. For an easier illustration, assume that <italic>A</italic><sub>1</sub>, <italic>A</italic><sub>2</sub>, and the distribution of true item difficulties are continuous. Then for an infinitesimal <italic>d</italic>, <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub> are proportional to the density of true difficulty parameters in <italic>I</italic><sub>1</sub> and <italic>I</italic><sub>2</sub>, respectively, so <inline-formula id="inline-formula3-0146621612443304">
<mml:math display="inline" id="math3-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>&lt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>. As the density of difficulties is smaller in every point of <italic>I</italic><sub>1</sub> than in any point of <italic>I</italic><sub>2</sub>, the inequality <inline-formula id="inline-formula4-0146621612443304">
<mml:math display="inline" id="math4-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo>&lt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> holds for arbitrary large <italic>d</italic>. Assuming that the errors of the basic parameters are unbiased, the number of true difficulty parameters β in I_1, such that the corresponding estimate <inline-formula id="inline-formula5-0146621612443304">
<mml:math display="inline" id="math5-0146621612443304">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mtext>ξ</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula> is in <italic>U</italic>, is approximately <inline-formula id="inline-formula6-0146621612443304">
<mml:math display="inline" id="math6-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula> and is hence less than <inline-formula id="inline-formula7-0146621612443304">
<mml:math display="inline" id="math7-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>A</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, the approximate number of true β in <italic>I</italic><sub>2</sub> such that the corresponding estimate <inline-formula id="inline-formula8-0146621612443304">
<mml:math display="inline" id="math8-0146621612443304">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mtext>ξ</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula> is in <italic>U</italic>. <xref ref-type="fig" rid="fig1-0146621612443304">Figure 1</xref> illustrates this situation.</p>
<fig id="fig1-0146621612443304" position="float">
<label>Figure 1.</label>
<caption>
<p>Effect of deviations of true from estimated values of item difficulty parameters on the estimation of person parameters in adaptive testing</p>
<p>Note: It is assumed that the density of item difficulty parameters decreases from the center to the boundaries. Arrows begin at the true and end at the estimated difficulty parameters. Only difficulty parameters that contribute to <italic>A</italic><sub>1</sub> or <italic>A</italic><sub>2</sub> are displayed.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig1.tif"/>
</fig>
<p>For a person with a positive true person parameter, the algorithm will hence select items with overestimated difficulty parameters more often than items with underestimated difficulty. These items are easier to solve for the person than their difficulty estimates suggest, so the person parameter is systematically overestimated. The same reasoning holds for persons with negative true person parameters, which are therefore systematically underestimated.</p>
<sec id="section3-0146621612443304">
<title>An Asymptotic Formula of the Expected Bias</title>
<p>A formula is derived, which describes, as a function of the current estimate, the approximate expected value of the error term ξ when choosing an item whose estimated difficulty is supposed to match this current estimate. Therefore, the following assumptions were made:</p>
<list id="list1-0146621612443304" list-type="order">
<list-item><p>Every item of the pool has a true difficulty parameter β that is estimated with an error term ξ; that is, the estimated difficulty of the item is <inline-formula id="inline-formula9-0146621612443304">
<mml:math display="inline" id="math9-0146621612443304">
<mml:mrow>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mtext>ξ</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula>.</p></list-item>
<list-item><p>The density of the distribution of the true item difficulty parameters in the pool is given by <inline-formula id="inline-formula10-0146621612443304">
<mml:math display="inline" id="math10-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p></list-item>
<list-item><p>The density of the distribution of the error terms is given by <inline-formula id="inline-formula11-0146621612443304">
<mml:math display="inline" id="math11-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> and the corresponding cumulative distribution function by <inline-formula id="inline-formula12-0146621612443304">
<mml:math display="inline" id="math12-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>.</p></list-item>
<list-item><p>β and ξ are independent.</p></list-item>
</list>
<p>Let <italic>y</italic> be the current estimate of the person parameter. For <inline-formula id="inline-formula13-0146621612443304">
<mml:math display="inline" id="math13-0146621612443304">
<mml:mrow>
<mml:mtext>ε</mml:mtext>
<mml:mspace width="0.25em"/>
<mml:mo>&gt;</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:math>
</inline-formula>, the neighborhood <inline-formula id="inline-formula14-0146621612443304">
<mml:math display="inline" id="math14-0146621612443304">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ε</mml:mtext>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>+</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ε</mml:mtext>
<mml:mo stretchy="false">/</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> of <italic>y</italic> is denoted as <inline-formula id="inline-formula15-0146621612443304">
<mml:math display="inline" id="math15-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>U</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. The event of obtaining an item with estimated difficulty parameter in <inline-formula id="inline-formula16-0146621612443304">
<mml:math display="inline" id="math16-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>U</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> is given by</p>
<p>
<disp-formula id="disp-formula1-0146621612443304">
<mml:math display="block" id="math17-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>:</mml:mo>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">{</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mtext>ξ</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>:</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mtext>ξ</mml:mtext>
<mml:mo>∈</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>U</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">}</mml:mo>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula1-0146621612443304" xlink:href="10.1177_0146621612443304-eq1.tif"/>
</disp-formula>
</p>
<p>and the probability of this event is</p>
<p>
<disp-formula id="disp-formula2-0146621612443304">
<mml:math display="block" id="math18-0146621612443304">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mo>∫</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mtext>d</mml:mtext>
<mml:mi>β</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula2-0146621612443304" xlink:href="10.1177_0146621612443304-eq2.tif"/>
</disp-formula>
</p>
<p>Let</p>
<p>
<disp-formula id="disp-formula3-0146621612443304">
<mml:math display="block" id="math19-0146621612443304">
<mml:mrow>
<mml:mi>B</mml:mi>
<mml:mo>:</mml:mo>
<mml:mo>=</mml:mo>
<mml:munder>
<mml:mrow>
<mml:mo>lim</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
<mml:mo>→</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>=</mml:mo>
<mml:mo stretchy="false">{</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mtext>ξ</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>:</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mtext>ξ</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo stretchy="false">}</mml:mo>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula3-0146621612443304" xlink:href="10.1177_0146621612443304-eq3.tif"/>
</disp-formula>
</p>
<p>For a given <italic>y</italic>, interest lies in <inline-formula id="inline-formula17-0146621612443304">
<mml:math display="inline" id="math20-0146621612443304">
<mml:mrow>
<mml:mtext>E</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mtext>ξ</mml:mtext>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>, the conditional expectation of the error term ξ given that the estimated value of the item equals <italic>y</italic>.</p>
<p>A density function of the conditional distribution of β given <inline-formula id="inline-formula18-0146621612443304">
<mml:math display="inline" id="math21-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula> is</p>
<p>
<disp-formula id="disp-formula4-0146621612443304">
<mml:math display="block" id="math22-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>:</mml:mo>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo>∫</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mtext>d</mml:mtext>
<mml:mi>β</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula4-0146621612443304" xlink:href="10.1177_0146621612443304-eq4.tif"/>
</disp-formula>
</p>
<p>as for an arbitrary measurable <inline-formula id="inline-formula19-0146621612443304">
<mml:math display="inline" id="math23-0146621612443304">
<mml:mrow>
<mml:mtext>ζ</mml:mtext>
<mml:mo>⊆</mml:mo>
<mml:mi>R</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>
</p>
<p>
<disp-formula id="disp-formula5-0146621612443304">
<mml:math display="block" id="math24-0146621612443304">
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>ζ</mml:mtext>
<mml:mo stretchy="false">|</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mtext>ζ</mml:mtext>
<mml:mo>∧</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mi>P</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>B</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mo>∫</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mtext>ζ</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mtext>d</mml:mtext>
<mml:mi>β</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mo>∫</mml:mo>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>+</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>Φ</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
</mml:mfrac>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mtext>d</mml:mtext>
<mml:mi>β</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>,</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula5-0146621612443304" xlink:href="10.1177_0146621612443304-eq5.tif"/>
</disp-formula>
</p>
<p>holds. Expanding the ratio in the expression for the density <inline-formula id="inline-formula20-0146621612443304">
<mml:math display="inline" id="math25-0146621612443304">
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> by <inline-formula id="inline-formula21-0146621612443304">
<mml:math display="inline" id="math26-0146621612443304">
<mml:mrow>
<mml:mn>1</mml:mn>
<mml:mo stretchy="false">/</mml:mo>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula> and taking the limit yields a density function <inline-formula id="inline-formula22-0146621612443304">
<mml:math display="inline" id="math27-0146621612443304">
<mml:mrow>
<mml:mi>g</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula> of the conditional distribution of β given <italic>B</italic>:</p>
<p>
<disp-formula id="disp-formula6-0146621612443304">
<mml:math display="block" id="math28-0146621612443304">
<mml:mrow>
<mml:munder>
<mml:mrow>
<mml:mo>lim</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
<mml:mo>→</mml:mo>
<mml:mn>0</mml:mn>
</mml:mrow>
</mml:munder>
<mml:msub>
<mml:mrow>
<mml:mi>g</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>ε</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
<mml:mrow>
<mml:mo>∫</mml:mo>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>err</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:msub>
<mml:mrow>
<mml:mi>f</mml:mi>
</mml:mrow>
<mml:mrow>
<mml:mtext>pool</mml:mtext>
</mml:mrow>
</mml:msub>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mtext>d</mml:mtext>
<mml:mi>β</mml:mi>
</mml:mrow>
</mml:mfrac>
<mml:mo>=</mml:mo>
<mml:mo>:</mml:mo>
<mml:mi>g</mml:mi>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula6-0146621612443304" xlink:href="10.1177_0146621612443304-eq6.tif"/>
</disp-formula>
</p>
<p>As <inline-formula id="inline-formula23-0146621612443304">
<mml:math display="inline" id="math29-0146621612443304">
<mml:mrow>
<mml:mtext>ξ</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula> for all <inline-formula id="inline-formula24-0146621612443304">
<mml:math display="inline" id="math30-0146621612443304">
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo>,</mml:mo>
<mml:mtext>ξ</mml:mtext>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>∈</mml:mo>
<mml:mi>B</mml:mi>
</mml:mrow>
</mml:math>
</inline-formula>, the following is obtained:</p>
<p>
<disp-formula id="disp-formula7-0146621612443304">
<mml:math display="block" id="math31-0146621612443304">
<mml:mrow>
<mml:mtext>E</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>ξ</mml:mi>
<mml:mo stretchy="false">|</mml:mo>
<mml:mi>B</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mo>∫</mml:mo>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>y</mml:mi>
<mml:mo>−</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mi>g</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>β</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mtext>d</mml:mtext>
<mml:mi>β</mml:mi>
<mml:mo>.</mml:mo>
</mml:mrow>
</mml:math>
<graphic alternate-form-of="disp-formula7-0146621612443304" xlink:href="10.1177_0146621612443304-eq7.tif"/>
</disp-formula></p>
<p><xref ref-type="disp-formula" rid="disp-formula7-0146621612443304">Equation 7</xref> describes the expected value of the error term ξ of an item difficulty parameter as a function of <italic>y</italic> (note that <italic>g</italic> is also dependent on <italic>y</italic>), which is the value of the difficulty parameter that the next item is intended to have and which is commonly the value of the current estimate of the person parameter.</p>
<p>As the person parameter scale and the item difficulty scale coincide, the expected error term of the difficulty parameter for a given <italic>y</italic> can also be interpreted as the expected bias of the person parameter estimate when a person is only tested with items that are chosen so that their estimated difficulties equal <italic>y</italic>. In a real adaptive testing situation, <italic>y</italic> is supposed to change in each step of the iterative testing algorithm. However, it can be assumed that <italic>y</italic> will approximately alternate around the true value of the person parameter. Therefore, <xref ref-type="disp-formula" rid="disp-formula7-0146621612443304">Equation 7</xref> might nevertheless, for sufficiently large test lengths, give a good estimate of the expected bias of person parameter estimation when the true person parameter is <italic>y</italic>, as the expected bias is bigger for values of <italic>y</italic> whose absolute values extend the absolute value of the true person parameter and smaller for values of <italic>y</italic> whose absolute values are less than the absolute value of the true person parameter.</p>
<p><xref ref-type="fig" rid="fig2-0146621612443304">Figure 2</xref> shows <xref ref-type="disp-formula" rid="disp-formula7-0146621612443304">Equation 7</xref> evaluated as a function of <italic>y</italic> under different assumptions of the true difficulty parameter distribution and the error term distribution. Increasing bias for growing error variances is clearly observable. Also, as expected, in the case of a skew normal distribution for the true item difficulties (compare <xref ref-type="fig" rid="fig3-0146621612443304">Figure 3</xref>), the bias is larger when the gradient of this distribution is higher and lower when the gradient becomes smaller.</p>
<fig id="fig2-0146621612443304" position="float">
<label>Figure 2.</label>
<caption>
<p>Expected bias as a function of <italic>y</italic>, as calculated in <xref ref-type="disp-formula" rid="disp-formula7-0146621612443304">Equation 7</xref></p>
<p>Note: For the left figure, a standard normal distribution for the true item parameter difficulties as well as different normal distributions with mean zero and different variances for the error terms of the item parameters are assumed. The variances of the error distribution vary between 0.2 and 2, with gaps of 0.3. The flattest curve corresponds to the smallest error variance, the steepest to the largest one. The right figure shows the same situation for the case that the true item difficulty parameters follow the skew normal distribution shown in <xref ref-type="fig" rid="fig3-0146621612443304">Figure 3</xref>.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig2.tif"/>
</fig>
<fig id="fig3-0146621612443304" position="float">
<label>Figure 3.</label>
<caption>
<p>Standard normal distribution and skew normal distribution with shape = 8, scale ≈ 1.64, and location ≈ 1.30</p>
<p>Note: Both distributions have mean 0 and variance 1.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig3.tif"/>
</fig>
</sec>
</sec>
<sec id="section4-0146621612443304">
<title>Simulation Studies</title>
<p>Several simulation studies were conducted to study the effect of biased person parameter estimates caused by imprecise item parameters in different testing situations. These simulation studies investigated three models (Rasch, 2PL, and 3PL models), four estimators (maximum likelihood [ML], weighted maximum likelihood [WML; <xref ref-type="bibr" rid="bibr20-0146621612443304">Warm, 1989]</xref> as well as expected a posteriori [EAP], and maximum a posteriori [MAP], both with normal priors), three variances of normally distributed error terms for the estimated item difficulty parameters (0.1, 0.25, 0.5), four test lengths (15, 30, 50, 100), and two sizes of item pools (500, 1,000). Item selection was based on the criterion of maximal Fisher information.</p>
<p>For each testing situation, 1,000 replications of testing five person parameters (−2, −1, 0, 1, 2) were made. For each run of these replications, true item difficulty parameters were randomly sampled from a standard normal distribution. For the 2PL and 3PL models, discrimination parameters were sampled from a lognormal distribution with location 0 and scale 0.2. Guessing parameters for the 3PL model were sampled from a uniform distribution on <inline-formula id="inline-formula25-0146621612443304">
<mml:math display="inline" id="math32-0146621612443304">
<mml:mrow>
<mml:mo stretchy="false">[</mml:mo>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>01</mml:mn>
<mml:mo>,</mml:mo>
<mml:mspace width="0.25em"/>
<mml:mn>0</mml:mn>
<mml:mo>.</mml:mo>
<mml:mn>25</mml:mn>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula>. Error terms for the difficulty parameters were, also in each replication, generated from a normal distribution with the corresponding variance and mean zero. All analyses were conducted in R (<xref ref-type="bibr" rid="bibr11-0146621612443304">R Development Core Team, 2009</xref>) using the package catR (<xref ref-type="bibr" rid="bibr9-0146621612443304">Magis &amp; Raîche, 2011</xref>).<sup><xref ref-type="fn" rid="fn1-0146621612443304">1</xref></sup></p>
<sec id="section5-0146621612443304">
<title>Results</title>
<p>For each testing situation, the deviations of the estimated from the true person parameters were calculated. To obtain single numeric values representing the bias in person parameter estimation, an ordinary least squares (OLS) regression of the bias on the true <inline-formula id="inline-formula26-0146621612443304">
<mml:math display="inline" id="math33-0146621612443304">
<mml:mrow>
<mml:mtext>θ</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula> was calculated for each testing situation. Corresponding slopes are displayed in <xref ref-type="table" rid="table1-0146621612443304">Table 1</xref>. Slope parameters that are unequal to zero at the 0.95 significance level are indicated in bold.</p>
<table-wrap id="table1-0146621612443304" position="float">
<label>Table 1.</label>
<caption>
<p>Slopes of Regressions of Mean Bias of <inline-formula id="inline-formula27-0146621612443304">
<mml:math display="inline" id="math34-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> on True θ</p>
</caption>
<graphic alternate-form-of="table1-0146621612443304" xlink:href="10.1177_0146621612443304-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="7">Rasch model</th>
<th align="center" colspan="7">2PL model</th>
<th align="center" colspan="7">3PL model</th>
</tr>
<tr>
<th align="center" colspan="7"><italic>N</italic></th>
<th align="center" colspan="7"><italic>N</italic></th>
<th align="center" colspan="7"><italic>N</italic></th>
</tr>
<tr>
<th align="left">
<inline-formula id="inline-formula28-0146621612443304">
<mml:math display="inline" id="math35-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula>
</th>
<th align="center">Pool</th>
<th align="center">
<inline-formula id="inline-formula29-0146621612443304">
<mml:math display="inline" id="math36-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula>
</th>
<th align="center">15</th>
<th align="center">30</th>
<th align="center">50</th>
<th align="center">100</th>
<th align="center"><inline-formula id="inline-formula30-0146621612443304">
<mml:math display="inline" id="math37-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">Pool</th>
<th align="center">
<inline-formula id="inline-formula31-0146621612443304">
<mml:math display="inline" id="math38-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">15</th>
<th align="center">30</th>
<th align="center">50</th>
<th align="center">100</th>
<th align="center">
<inline-formula id="inline-formula32-0146621612443304">
<mml:math display="inline" id="math39-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">pool</th>
<th align="center">
<inline-formula id="inline-formula33-0146621612443304">
<mml:math display="inline" id="math40-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">15</th>
<th align="center">30</th>
<th align="center">50</th>
<th align="center">100</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.000</td>
<td>500</td>
<td>WML</td>
<td>−0.017</td>
<td>−0.003</td>
<td>0.008</td>
<td>0.002</td>
<td>0.000</td>
<td>500</td>
<td>WML</td>
<td>0.001</td>
<td>0.005</td>
<td>−0.003</td>
<td>0.001</td>
<td>0.000</td>
<td>500</td>
<td>WML</td>
<td>−0.009</td>
<td>−0.003</td>
<td>0.001</td>
<td>0.003</td>
</tr>
<tr>
<td>0.000</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.225</bold>
</td>
<td>−<bold>0.126</bold>
</td>
<td>−<bold>0.075</bold>
</td>
<td>−<bold>0.038</bold>
</td>
<td>
<bold>0.000</bold>
</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.131</bold>
</td>
<td>−<bold>0.073</bold>
</td>
<td>−<bold>0.053</bold>
</td>
<td>−<bold>0.029</bold>
</td>
<td>0.000</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.159</bold>
</td>
<td>−<bold>0.096</bold>
</td>
<td>−<bold>0.065</bold>
</td>
<td>−<bold>0.038</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.239</bold>
</td>
<td>−<bold>0.139</bold>
</td>
<td>−<bold>0.078</bold>
</td>
<td>−<bold>0.044</bold>
</td>
<td>
<bold>0.000</bold>
</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.142</bold>
</td>
<td>−<bold>0.086</bold>
</td>
<td>−<bold>0.057</bold>
</td>
<td>−<bold>0.029</bold>
</td>
<td>0.000</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.182</bold>
</td>
<td>−<bold>0.106</bold>
</td>
<td>−<bold>0.069</bold>
</td>
<td>−<bold>0.041</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>500</td>
<td>ML</td>
<td>−0.004</td>
<td>−0.002</td>
<td>0.005</td>
<td>0.005</td>
<td>0.000</td>
<td>500</td>
<td>ML</td>
<td>0.013</td>
<td>0.009</td>
<td>0.008</td>
<td>0.003</td>
<td>0.000</td>
<td>500</td>
<td>ML</td>
<td>0.024</td>
<td>0.014</td>
<td>0.007</td>
<td>0.005</td>
</tr>
<tr>
<td>0.000</td>
<td>1,000</td>
<td>WML</td>
<td>−0.008</td>
<td>−0.005</td>
<td>−0.004</td>
<td>−0.001</td>
<td>0.000</td>
<td>1,000</td>
<td>WML</td>
<td>−0.007</td>
<td>0.005</td>
<td>−0.001</td>
<td>0.001</td>
<td>0.000</td>
<td>1,000</td>
<td>WML</td>
<td>−0.013</td>
<td>0.005</td>
<td>0.002</td>
<td>−0.003</td>
</tr>
<tr>
<td>0.000</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.234</bold>
</td>
<td>−<bold>0.121</bold>
</td>
<td>−<bold>0.077</bold>
</td>
<td>−<bold>0.039</bold>
</td>
<td>0.000</td>
<td>1,000</td>
<td>EAP</td>
<td>−0.123</td>
<td>−<bold>0.067</bold>
</td>
<td>−<bold>0.040</bold>
</td>
<td>−<bold>0.027</bold>
</td>
<td>0.000</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.148</bold>
</td>
<td>−<bold>0.089</bold>
</td>
<td>−<bold>0.054</bold>
</td>
<td>−<bold>0.030</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.239</bold>
</td>
<td>−<bold>0.132</bold>
</td>
<td>−<bold>0.077</bold>
</td>
<td>−<bold>0.040</bold>
</td>
<td>0.000</td>
<td>1,000</td>
<td>MAP</td>
<td>−0.135</td>
<td>−<bold>0.069</bold>
</td>
<td>−<bold>0.048</bold>
</td>
<td>−<bold>0.025</bold>
</td>
<td>0.000</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.158</bold>
</td>
<td>−<bold>0.086</bold>
</td>
<td>−<bold>0.062</bold>
</td>
<td>−<bold>0.037</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>1,000</td>
<td>ML</td>
<td>0.001</td>
<td>−0.008</td>
<td>0.005</td>
<td>0.001</td>
<td>0.000</td>
<td>1,000</td>
<td>ML</td>
<td>0.009</td>
<td>0.009</td>
<td>0.006</td>
<td>0.003</td>
<td>0.000</td>
<td>1,000</td>
<td>ML</td>
<td>0.020</td>
<td>0.008</td>
<td>0.001</td>
<td>0.004</td>
</tr>
<tr>
<td>0.100</td>
<td>500</td>
<td>WML</td>
<td>0.070</td>
<td>
<bold>0.079</bold>
</td>
<td>
<bold>0.075</bold>
</td>
<td>
<bold>0.067</bold>
</td>
<td>0.100</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.063</bold>
</td>
<td>
<bold>0.065</bold>
</td>
<td>
<bold>0.060</bold>
</td>
<td>
<bold>0.053</bold>
</td>
<td>0.100</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.063</bold>
</td>
<td>
<bold>0.060</bold>
</td>
<td>
<bold>0.067</bold>
</td>
<td>
<bold>0.056</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.199</bold>
</td>
<td>−<bold>0.067</bold>
</td>
<td>−0.013</td>
<td>0.021</td>
<td>0.100</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.090</bold>
</td>
<td>−0.020</td>
<td>0.004</td>
<td>0.021</td>
<td>0.100</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.131</bold>
</td>
<td>−<bold>0.049</bold>
</td>
<td>−0.008</td>
<td>0.014</td>
</tr>
<tr>
<td>0.100</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.212</bold>
</td>
<td>−<bold>0.084</bold>
</td>
<td>−0.016</td>
<td>0.020</td>
<td>0.100</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.102</bold>
</td>
<td>−0.032</td>
<td>0.000</td>
<td>0.016</td>
<td>0.100</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.136</bold>
</td>
<td>−<bold>0.049</bold>
</td>
<td>−0.022</td>
<td>0.006</td>
</tr>
<tr>
<td>0.100</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.076</bold>
</td>
<td>
<bold>0.091</bold>
</td>
<td>
<bold>0.087</bold>
</td>
<td>
<bold>0.074</bold>
</td>
<td>0.100</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.086</bold>
</td>
<td>
<bold>0.083</bold>
</td>
<td>
<bold>0.066</bold>
</td>
<td>
<bold>0.057</bold>
</td>
<td>0.100</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.095</bold>
</td>
<td>
<bold>0.083</bold>
</td>
<td>
<bold>0.075</bold>
</td>
<td>
<bold>0.066</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.075</bold>
</td>
<td>
<bold>0.087</bold>
</td>
<td>
<bold>0.084</bold>
</td>
<td>
<bold>0.079</bold>
</td>
<td>0.100</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.065</bold>
</td>
<td>
<bold>0.072</bold>
</td>
<td>
<bold>0.069</bold>
</td>
<td>
<bold>0.064</bold>
</td>
<td>0.100</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.056</bold>
</td>
<td>
<bold>0.069</bold>
</td>
<td>
<bold>0.071</bold>
</td>
<td>
<bold>0.067</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.196</bold>
</td>
<td>−<bold>0.070</bold>
</td>
<td>−0.016</td>
<td>0.031</td>
<td>0.100</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.078</bold>
</td>
<td>−<bold>0.010</bold>
</td>
<td>0.018</td>
<td>0.034</td>
<td>0.100</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.104</bold>
</td>
<td>−0.029</td>
<td>0.010</td>
<td>0.027</td>
</tr>
<tr>
<td>0.100</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.205</bold>
</td>
<td>−<bold>0.082</bold>
</td>
<td>−<bold>0.021</bold>
</td>
<td>
<bold>0.036</bold>
</td>
<td>0.100</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.089</bold>
</td>
<td>−<bold>0.023</bold>
</td>
<td>0.008</td>
<td>0.033</td>
<td>0.100</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.120</bold>
</td>
<td>−0.036</td>
<td>−0.004</td>
<td>0.023</td>
</tr>
<tr>
<td>0.100</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.089</bold>
</td>
<td>
<bold>0.085</bold>
</td>
<td>
<bold>0.088</bold>
</td>
<td>
<bold>0.085</bold>
</td>
<td>0.100</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.087</bold>
</td>
<td>
<bold>0.082</bold>
</td>
<td>
<bold>0.071</bold>
</td>
<td>
<bold>0.070</bold>
</td>
<td>0.100</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.103</bold>
</td>
<td>
<bold>0.087</bold>
</td>
<td>
<bold>0.077</bold>
</td>
<td>
<bold>0.071</bold>
</td>
</tr>
<tr>
<td>0.250</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.164</bold>
</td>
<td>0.189</td>
<td>
<bold>0.185</bold>
</td>
<td>
<bold>0.159</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.159</bold>
</td>
<td>
<bold>0.160</bold>
</td>
<td>
<bold>0.157</bold>
</td>
<td>
<bold>0.138</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.143</bold>
</td>
<td>
<bold>0.154</bold>
</td>
<td>
<bold>0.155</bold>
</td>
<td>
<bold>0.133</bold>
</td>
</tr>
<tr>
<td>0.250</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.165</bold>
</td>
<td>−0.011</td>
<td>
<bold>0.066</bold>
</td>
<td>
<bold>0.105</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>EAP</td>
<td>−0.026</td>
<td>
<bold>0.048</bold>
</td>
<td>
<bold>0.080</bold>
</td>
<td>
<bold>0.093</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.072</bold>
</td>
<td>0.029</td>
<td>0.067</td>
<td>0.090</td>
</tr>
<tr>
<td>0.250</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.171</bold>
</td>
<td>−0.017</td>
<td>
<bold>0.058</bold>
</td>
<td>
<bold>0.100</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>MAP</td>
<td>−0.045</td>
<td>
<bold>0.044</bold>
</td>
<td>
<bold>0.075</bold>
</td>
<td>
<bold>0.091</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.081</bold>
</td>
<td>0.007</td>
<td>0.055</td>
<td>0.077</td>
</tr>
<tr>
<td>0.250</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.207</bold>
</td>
<td>
<bold>0.204</bold>
</td>
<td>
<bold>0.191</bold>
</td>
<td>
<bold>0.166</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.192</bold>
</td>
<td>
<bold>0.177</bold>
</td>
<td>
<bold>0.163</bold>
</td>
<td>
<bold>0.141</bold>
</td>
<td>0.250</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.192</bold>
</td>
<td>
<bold>0.189</bold>
</td>
<td>
<bold>0.167</bold>
</td>
<td>
<bold>0.145</bold>
</td>
</tr>
<tr>
<td>0.250</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.177</bold>
</td>
<td>
<bold>0.202</bold>
</td>
<td>
<bold>0.205</bold>
</td>
<td>
<bold>0.195</bold>
</td>
<td>0.250</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.168</bold>
</td>
<td>
<bold>0.178</bold>
</td>
<td>
<bold>0.174</bold>
</td>
<td>
<bold>0.154</bold>
</td>
<td>0.250</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.159</bold>
</td>
<td>
<bold>0.179</bold>
</td>
<td>
<bold>0.179</bold>
</td>
<td>
<bold>0.156</bold>
</td>
</tr>
<tr>
<td>0.250</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.162</bold>
</td>
<td>−0.005</td>
<td>0.072</td>
<td>
<bold>0.129</bold>
</td>
<td>
<bold>0.250</bold>
</td>
<td>1,000</td>
<td>EAP</td>
<td>−0.014</td>
<td>
<bold>0.077</bold>
</td>
<td>
<bold>0.098</bold>
</td>
<td>
<bold>0.120</bold>
</td>
<td>0.250</td>
<td>1,000</td>
<td>EAP</td>
<td>−0.044</td>
<td>0.044</td>
<td>
<bold>0.081</bold>
</td>
<td>
<bold>0.111</bold>
</td>
</tr>
<tr>
<td>0.250</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.168</bold>
</td>
<td>−0.012</td>
<td>0.069</td>
<td>
<bold>0.127</bold>
</td>
<td>
<bold>0.250</bold>
</td>
<td>1,000</td>
<td>MAP</td>
<td>−0.021</td>
<td>0.058</td>
<td>
<bold>0.096</bold>
</td>
<td>
<bold>0.115</bold>
</td>
<td>0.250</td>
<td>1,000</td>
<td>MAP</td>
<td>−0.074</td>
<td>0.033</td>
<td>
<bold>0.079</bold>
</td>
<td>
<bold>0.105</bold>
</td>
</tr>
<tr>
<td>0.250</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.202</bold>
</td>
<td>
<bold>0.213</bold>
</td>
<td>
<bold>0.211</bold>
</td>
<td>
<bold>0.196</bold>
</td>
<td>0.250</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.207</bold>
</td>
<td>
<bold>0.202</bold>
</td>
<td>
<bold>0.180</bold>
</td>
<td>
<bold>0.162</bold>
</td>
<td>0.250</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.203</bold>
</td>
<td>
<bold>0.199</bold>
</td>
<td>
<bold>0.180</bold>
</td>
<td>
<bold>0.166</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.307</bold>
</td>
<td>
<bold>0.351</bold>
</td>
<td>
<bold>0.344</bold>
</td>
<td>
<bold>0.295</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.289</bold>
</td>
<td>
<bold>0.311</bold>
</td>
<td>
<bold>0.294</bold>
</td>
<td>
<bold>0.261</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>WML</td>
<td>
<bold>0.294</bold>
</td>
<td>
<bold>0.315</bold>
</td>
<td>
<bold>0.300</bold>
</td>
<td>
<bold>0.260</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>500</td>
<td>EAP</td>
<td>−<bold>0.109</bold>
</td>
<td>
<bold>0.085</bold>
</td>
<td>
<bold>0.180</bold>
</td>
<td>
<bold>0.226</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>EAP</td>
<td>0.052</td>
<td>0.161</td>
<td>
<bold>0.201</bold>
</td>
<td>
<bold>0.210</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>EAP</td>
<td>−0.000</td>
<td>0.128</td>
<td>
<bold>0.180</bold>
</td>
<td>
<bold>0.196</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>500</td>
<td>MAP</td>
<td>−<bold>0.128</bold>
</td>
<td>
<bold>0.078</bold>
</td>
<td>
<bold>0.179</bold>
</td>
<td>
<bold>0.222</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>MAP</td>
<td>0.036</td>
<td>0.150</td>
<td>
<bold>0.194</bold>
</td>
<td>
<bold>0.204</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>MAP</td>
<td>−0.027</td>
<td>0.105</td>
<td>
<bold>0.169</bold>
</td>
<td>
<bold>0.191</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.357</bold>
</td>
<td>
<bold>0.373</bold>
</td>
<td>
<bold>0.356</bold>
</td>
<td>
<bold>0.299</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.364</bold>
</td>
<td>
<bold>0.340</bold>
</td>
<td>
<bold>0.316</bold>
</td>
<td>
<bold>0.267</bold>
</td>
<td>0.500</td>
<td>500</td>
<td>ML</td>
<td>
<bold>0.370</bold>
</td>
<td>
<bold>0.345</bold>
</td>
<td>
<bold>0.316</bold>
</td>
<td>
<bold>0.261</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.343</bold>
</td>
<td>
<bold>0.373</bold>
</td>
<td>
<bold>0.382</bold>
</td>
<td>
<bold>0.354</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.320</bold>
</td>
<td>
<bold>0.333</bold>
</td>
<td>
<bold>0.330</bold>
</td>
<td>
<bold>0.299</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>WML</td>
<td>
<bold>0.296</bold>
</td>
<td>
<bold>0.331</bold>
</td>
<td>
<bold>0.331</bold>
</td>
<td>
<bold>0.298</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>1,000</td>
<td>EAP</td>
<td>−<bold>0.110</bold>
</td>
<td>
<bold>0.090</bold>
</td>
<td>
<bold>0.195</bold>
</td>
<td>
<bold>0.271</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>EAP</td>
<td>
<bold>0.070</bold>
</td>
<td>
<bold>0.184</bold>
</td>
<td>
<bold>0.231</bold>
</td>
<td>
<bold>0.253</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>EAP</td>
<td>0.016</td>
<td>
<bold>0.150</bold>
</td>
<td>
<bold>0.214</bold>
</td>
<td>
<bold>0.244</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>1,000</td>
<td>MAP</td>
<td>−<bold>0.122</bold>
</td>
<td>
<bold>0.079</bold>
</td>
<td>
<bold>0.185</bold>
</td>
<td>
<bold>0.267</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>MAP</td>
<td>0.053</td>
<td>
<bold>0.174</bold>
</td>
<td>
<bold>0.226</bold>
</td>
<td>
<bold>0.246</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>MAP</td>
<td>0.009</td>
<td>
<bold>0.143</bold>
</td>
<td>
<bold>0.197</bold>
</td>
<td>
<bold>0.236</bold>
</td>
</tr>
<tr>
<td>0.500</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.408</bold>
</td>
<td>
<bold>0.408</bold>
</td>
<td>
<bold>0.397</bold>
</td>
<td>
<bold>0.362</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.383</bold>
</td>
<td>
<bold>0.370</bold>
</td>
<td>
<bold>0.346</bold>
</td>
<td>
<bold>0.313</bold>
</td>
<td>0.500</td>
<td>1,000</td>
<td>ML</td>
<td>
<bold>0.396</bold>
</td>
<td>
<bold>0.372</bold>
</td>
<td>
<bold>0.347</bold>
</td>
<td>
<bold>0.311</bold>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0146621612443304">
<p>Note: 2PL model = two-parameter logistic model; 3PL model = three-parameter logistic model; <italic>N</italic> = test length; <inline-formula id="inline-formula34-0146621612443304">
<mml:math display="inline" id="math41-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula> = error variance of the difficulty parameters; Pool = size of item pool; <inline-formula id="inline-formula35-0146621612443304">
<mml:math display="inline" id="math42-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula> = estimator for the person parameter; WML = weighted maximum likelihood; EAP = expected a posteriori; MAP = maximum a posteriori; ML = maximum likelihood. Slopes are boldface if significantly different from zero at the 95% level.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>To illustrate some of the results in more detail, <xref ref-type="fig" rid="fig4-0146621612443304">Figures 4</xref> to <xref ref-type="fig" rid="fig7-0146621612443304">7</xref> show the deviations from true and estimated person parameters for some selected testing situations.</p>
<fig id="fig4-0146621612443304" position="float">
<label>Figure 4.</label>
<caption>
<p>First three panels: Deviations of the estimated from the true person parameters for the four different estimators and the three different models. Lower right panel: Bias resulting from Bayesian MAP estimators for all three models.</p>
<p>Note: Test length = 50, size of item pool = 1,000. First three panels: Error variance of difficulty parameters = 0.5. Lower right panel: Error variance of difficulty parameters = 0.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig4.tif"/>
</fig>
<fig id="fig5-0146621612443304" position="float">
<label>Figure 5.</label>
<caption>
<p>Deviations of the estimated from the true person parameters for different error variances of difficulty parameters.</p>
<p>Note: Estimation for the 2PL model under WML and MAP. Testlength=50, size of itempool =1,000.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig5.tif"/>
</fig>
<fig id="fig6-0146621612443304" position="float">
<label>Figure 6.</label>
<caption>
<p>Deviations of the estimated from the true person parameters for test length varying from 15 to 100.</p>
<p>Note: Estimation for the Rasch model under WML and MAP. Error variance of difficulty parameters = 0.5, size of itempool = 1,000.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig6.tif"/>
</fig>
<fig id="fig7-0146621612443304" position="float">
<label>Figure 7.</label>
<caption>
<p>Deviations of the estimated from the true person parameters for item pools of size 500 and 1,000, respectively</p>
<p>Note: Estimation for the Rasch model under WML and MAP. Error variance of difficulty parameters = 0.25.</p>
</caption>
<graphic xlink:href="10.1177_0146621612443304-fig7.tif"/>
</fig>
</sec>
<sec id="section6-0146621612443304">
<title>Dependence on the Estimator</title>
<p><xref ref-type="table" rid="table1-0146621612443304">Table 1</xref> shows that, if the test length is sufficiently long, the effect occurs for all estimators. However, it is less distinct for the Bayesian estimators. Depending on the prior distribution and the test length, estimates obtained from MAP and EAP estimators are shifted toward the mean, which partially counteracts the bias induced by imprecise difficulty parameters. In <xref ref-type="table" rid="table1-0146621612443304">Table 1</xref>, systematic bias toward the mean is indicated by negative slope parameters, which occur for the Bayesian estimators mainly in testing situations where the error variance of the difficulty parameters is zero or the test length is small.</p>
<p>Comparing the two likelihood and the two Bayesian estimators, respectively, the effect of biased person parameter estimation caused by imprecise item parameter estimates is marginally stronger for the ML than for the WML, and slightly more pronounced for the EAP than for the MAP estimator.</p>
<p>As an example, <xref ref-type="fig" rid="fig4-0146621612443304">Figure 4</xref> shows the dependence of the effect of biased person parameter estimation on the estimator for all three models for specific testing situations. As the WML and the ML, as well as the MAP and the EAP estimator, are very similar for all models, <xref ref-type="fig" rid="fig5-0146621612443304">Figures 5</xref> to <xref ref-type="fig" rid="fig7-0146621612443304">7</xref> only show results for WML and MAP estimators.</p>
</sec>
<sec id="section7-0146621612443304">
<title>Dependence on the Model</title>
<p>The dependence of the observed effect on the model is indicated in <xref ref-type="table" rid="table1-0146621612443304">Table 1</xref> and <xref ref-type="fig" rid="fig4-0146621612443304">Figure 4</xref>. As the information functions of the 2PL and 3PL models depend on the difficulty and the discrimination parameters, and, in the case of the 3PL model, also on the guessing parameter, it is expected that the effect of biased person parameter estimation will be most noticeable for the Rasch models. This can indeed be observed in the case of ML estimation, although the differences between the three models are not very distinct. For Bayesian estimators, however, the effect is for test lengths of 30 and 50 items in most cases even more pronounced for the 2PL and 3PL models than for the Rasch model. The explanation for this apparently contradictory result is that the bias toward the mean, which is induced by the Bayesian estimators, is (at least in the setting described here) stronger for the Rasch model than for the 2PL or 3PL model, as indicated in the last panel of <xref ref-type="fig" rid="fig4-0146621612443304">Figure 4</xref>. Highly discriminating items, which are commonly chosen by the adaptive testing algorithm in the case of 2PL and 3PL models, provide more information than do Rasch-scaled items, therefore the prior distribution, which in turn causes the shift toward the mean, is here less decisive. However, as the influence of the prior decreases as test length increases, the effect of biased person parameter estimation is again strongest for the Rasch model for long tests (<inline-formula id="inline-formula36-0146621612443304">
<mml:math display="inline" id="math43-0146621612443304">
<mml:mrow>
<mml:mo>≈</mml:mo>
<mml:mn>100</mml:mn>
<mml:mspace width="0.25em"/>
<mml:mtext>items</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula>), regardless of whether a Bayesian or an ML estimator is used.</p>
</sec>
<sec id="section8-0146621612443304">
<title>Dependence on the Error Variance</title>
<p><xref ref-type="table" rid="table1-0146621612443304">Table 1</xref> and <xref ref-type="fig" rid="fig5-0146621612443304">Figure 5</xref> indicate the dependence on the error variance of item difficulty parameters. As expected, the effect becomes more pronounced with increasing error variance. When there is no error variance, estimates seem to be unbiased in the case of likelihood estimation and slightly biased in the opposite direction due to a shift to the mean in the case of Bayesian estimation.</p>
</sec>
<sec id="section9-0146621612443304">
<title>Dependence on the Test Length</title>
<p>At least for tests with fewer than 100 items, test length has a stronger effect on biased person parameter estimation for Bayesian than for likelihood estimators, as indicated in <xref ref-type="table" rid="table1-0146621612443304">Table 1</xref> and <xref ref-type="fig" rid="fig6-0146621612443304">Figure 6</xref>. For a short test length of only 15 items, the bias toward the mean induced by the Bayesian estimators is in most cases even stronger than the reverse bias induced by imprecise item difficulty parameters. The dependence on the test length in the case of the Bayesian estimators is caused by the fact that for short tests, the prior assumption is quite decisive for the posterior distribution, whereas for long tests, the likelihood is the dominating factor. Therefore, the shift toward the mean, which is induced by using a Bayesian estimator, becomes smaller with increasing test length.</p>
</sec>
<sec id="section10-0146621612443304">
<title>Dependence on the Size of the Item Pool</title>
<p><xref ref-type="table" rid="table1-0146621612443304">Table 1</xref> and <xref ref-type="fig" rid="fig7-0146621612443304">Figure 7</xref> show that the effect of biased person parameter estimation caused by imprecise item difficulty parameters is slightly stronger for an item pool of size 1,000 than of size 500, at least for the more extreme values of theta. This is not surprising, as tests become more “adaptive” the larger the item pool is. This result is independent of the estimator and the model.</p>
</sec>
</sec>
<sec id="section11-0146621612443304">
<title>Discussion</title>
<p>In adaptive testing, deviations of the true from the estimated difficulty parameters can lead to systematic overestimation for positive person parameters and to systematic underestimation for negative person parameters, even when the errors of the item parameters are unbiased. The given theoretical explanation for this phenomenon is very general and (as long as the difficulty parameter is decisive in the item selection process) can therefore be assumed to hold for many situations in adaptive testing.</p>
<sec id="section12-0146621612443304">
<title>Decisive Factors</title>
<p>The actual influence of the described effect on person parameter estimation depends mainly on the following factors: (a) the exactness of item calibration, (b) the amount of person- and/or group-specific differences in item difficulty parameters, (c) the presence of local item dependence (testlets), (d) the possible use of rule-based item generation, (e) other possible sources of variation in item difficulty parameters, (f) the distribution of the true item difficulty parameters in the pool, (g) the distribution of the errors of the item difficulty parameters, (h) the estimator, (i) the model, (j) the test length, (k) the size of the item pool, (l) the item selection criterion, and (m) additional constraints in the item selection procedure.</p>
<p>At least to a certain degree, calibration errors and person- or group-specific differences in item difficulty parameters can be assumed to be present in most real testing situations. The impact of the latter seems especially important for models with comparatively few item parameters. An example of such a model is the linear logistic test model (LLTM; <xref ref-type="bibr" rid="bibr4-0146621612443304">Fischer, 1973</xref>), which comprises only a certain number <italic>K</italic> of basic parameters that determine the difficulty of <inline-formula id="inline-formula37-0146621612443304">
<mml:math display="inline" id="math44-0146621612443304">
<mml:mrow>
<mml:msup>
<mml:mrow>
<mml:mn>2</mml:mn>
</mml:mrow>
<mml:mrow>
<mml:mi>K</mml:mi>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula> different items. This model is rather interesting for applications in adaptive testing, as it enables the generation of a large item pool with comparatively little calibration effort and is also well suited for an easy implementation of rule-based item generation (<xref ref-type="bibr" rid="bibr7-0146621612443304">Holling et al., 2009</xref>). <xref ref-type="table" rid="table1-0146621612443304">Table A1</xref> in the Appendix shows results similar to <xref ref-type="table" rid="table1-0146621612443304">Table 1</xref> for the LLTM.</p>
<p>However, it is a known problem of the LLTM that it often does not fit real data sufficiently, even when most of the variation in the item difficulties can be explained (<xref ref-type="bibr" rid="bibr12-0146621612443304">Rijmen &amp; De Boeck, 2002</xref>). For this reason, some authors have already suggested modeling some or all of the basic parameters as person-specific random effects (<xref ref-type="bibr" rid="bibr12-0146621612443304">Rijmen &amp; De Boeck, 2002</xref>) or introducing an additive item-specific random parameter that contributes to the difficulty parameter (<xref ref-type="bibr" rid="bibr3-0146621612443304">De Boeck, 2008</xref>). <xref ref-type="bibr" rid="bibr12-0146621612443304">Rijmen and De Boeck (2002)</xref>, analyzing data from a test of deductive reasoning, report that some of the variances associated with random basic parameters were estimated to be rather large. Therefore, it seems reasonable that, in the case of the LLTM, most of the error variance of estimated item difficulty parameters is due to individual differences in item difficulties rather than to calibration errors.</p>
<p>Generally, when the model is comparatively simple with only a few item parameters, the calibration is expected to be more exact, but the effects of the neglect of individual differences are often larger. However, when the model is more complex and comprises more item parameters, calibration errors might be more predominant than the deviations due to the approximation by the model.</p>
<p>Testlets and rule-based item generation are especially useful in adaptive testing. However, the possible side effect of additional error variation of the difficulty parameters can be particularly severe in precisely this testing format.</p>
<p>When modeling testlet effects with additional random effects that are added to item difficulty parameters (cf. <xref ref-type="bibr" rid="bibr17-0146621612443304">Wainer et al., 2007</xref>), the error variances associated with deviations of true from estimated (mean) difficulty parameters due to these testlet effects can be directly assessed. However, error variances can only be specified for particular testing situations, so that general statements about the magnitudes of these variances are limited. Yet, in this context, it might be interesting to note that <xref ref-type="bibr" rid="bibr17-0146621612443304">Wainer et al. (2007)</xref> report various examples of testlet applications where these variances are often quite large.</p>
<p>Concerning rule-based item generation, there are no studies so far that investigate the magnitudes of possible error variances of item difficulty parameters within families of cloned items. Like the variances arising from person-specific differences or testlets, these variances are assumed to be strongly dependent on content-related aspects and can probably be best assessed by random effects modeling.</p>
<p>The distribution of the difficulty parameters in the item pool plays an important role in explaining the observed effect. Generally, as indicated in <xref ref-type="fig" rid="fig2-0146621612443304">Figure 2</xref>, the bias is expected to be larger for person parameters for which the gradient of this distribution is high (note that the person and difficulty parameter scales coincide). To prevent systematic bias in person parameter estimation caused by imprecise item parameters, a uniform distribution over the whole range of person parameters would be necessary.</p>
<p>The choice of the estimator can be quite decisive for the bias in person parameter estimation. As Bayesian estimators bias the estimates toward the mean, the effect observed here is generally stronger for likelihood estimators. Especially in the case of short tests, the bias caused by imprecise item difficulty parameters is often balanced by the bias induced through the prior distribution, and in some cases the latter is still predominant. However, the influence of the prior distribution on the posterior, and hence the bias toward the mean, decreases with increasing test length. Therefore, the choice of the estimator becomes less important for longer tests.</p>
<p>In the case of Rasch models, the item selection algorithm based on maximal Fisher information chooses the next item in such a way that an optimal match is obtained between the difficulty parameter and the current estimate of the person parameter. For models with more item parameters, the criterion of maximal Fisher information is generally also influenced by other parameters. However, in this study, the simulation for the 2PL and 3PL models shows that the bias is very similar to the one obtained under the Rasch model. In the case of Bayesian estimators, the bias is often even slightly stronger for the 2PL and 3PL models, as the bias toward the mean is marginally more distinct for the Rasch model.</p>
<p>The dependence of the bias in person parameter estimation in adaptive testing on the test lengths is more distinct for Bayesian estimators, as the induced bias toward the mean, which counteracts the bias caused by imprecise item parameters, is test-length dependent. Larger item pools slightly intensify the bias, as corresponding tests are “more adaptive.”</p>
<p>In this study, the author only examined the item selection criterion of maximal Fisher information. However, other criteria also depend on the difficulty parameter, though sometimes more indirectly. For example, in a Bayesian context, it is common to weigh a measure of information (which commonly depends on the difficulty parameter) with the posterior distribution and to maximize the corresponding integral over a certain interval (<xref ref-type="bibr" rid="bibr15-0146621612443304">van der Linden, 2010</xref>). With respect to the discrimination parameter, using a Bayesian criterion can indeed lead to a significantly different choice of items, as the information function becomes steeper and more focused when the discrimination parameter increases. However, in the case of the difficulty parameter, there is no comparable phenomenon that might suggest the use of Bayesian criteria, and therefore, the choice of the actual criterion is not expected to make much difference.</p>
</sec>
<sec id="section13-0146621612443304">
<title>Dealing With the Resulting Bias</title>
<p>From a practical point of view, an important question is how to deal with the problem of possibly biased person parameter estimation in adaptive testing. The left panel of <xref ref-type="fig" rid="fig2-0146621612443304">Figure 2</xref> as well as the results of the simulation studies indicate that in many cases a sufficient rescaling of the person parameter estimates might be possible by a multiplicative factor. This can be assumed to hold when the distribution of true item difficulty parameters in the pool is approximately “well behaved,” that is, symmetric, centered around the origin, and with a moderate gradient. The item pools used in the preceding simulation studies correspond to this situation and correlations of estimated and true values of person parameters, even with error variances of 0.5, are indeed not much different here from those obtained under precise item parameters (for more details, compare <xref ref-type="table" rid="table2-0146621612443304">Table A2</xref> in the Appendix). Therefore, if the only purpose of testing is to decide on the relative standing of examinees, the observed bias might be negligible.</p>
<p>However, in most cases the aim of adaptive testing is the assessment of individual persons based on a predefined scale that is obtained during the calibration process. In this case, a sufficiently exact rescaling of the person parameter scale might be necessary, as otherwise person parameter estimation can be systematically biased.</p>
<p>Furthermore, as the right panel of <xref ref-type="fig" rid="fig2-0146621612443304">Figure 2</xref> shows, the situation can be much more difficult for more complicated distributions of item difficulties. In such cases, the assumption of a simple correction factor might not be realistic, and therefore, relative decision making as well as more precise individual assessment might both be affected.</p>
<p>Another approach to deal with possible bias in adaptive testing is to try to reduce its underlying causes. In the context of the problem of capitalization on chance, <xref ref-type="bibr" rid="bibr16-0146621612443304">van der Linden and Glas (2000)</xref> point out some ways of reducing calibration errors in adaptive testing, most of which are probably also useful here. However, a further strategy these authors suggest is to use Rasch models rather than models with more parameters, as capitalization on chance in adaptive testing is caused by imprecisely calibrated discrimination parameters. Ironically, to avoid the phenomenon observed in the current study, one might, at least when likelihood estimators are used or when the test is sufficiently long, recommend just the opposite strategy: In Rasch models, the dependence of the Fisher information on the difficulty parameter is more pronounced than in models with further item parameters; hence, the bias in person parameter estimation for Rasch models is in many cases expected to be larger.</p>
<p>Errors in item calibration can be controlled at least to a certain extent; however, it is much more difficult to deal with deviations arising from person-specific differences in difficulty parameters, testlets, or rule-based item generation. Using random effects models would provide a straightforward way of directly modeling the error variance arising from these sources. However, random effects models are most useful when the objective is to estimate population characteristics. In the case of adaptive testing, where the focus is on the measurement of individual persons, they do not make a big difference, as for an individual examinee and a given item the values of corresponding random effects would still be unknown, so that the means would continue to be the best approximations. Hence, with respect to the difficulty parameter, the item selection algorithm would still pick the same items as under a standard fixed effects model.</p>
<p>Further research could aim to quantify the magnitudes of error variation in item difficulty parameters in diverse practical applications by using random effects models. Based on the obtained estimates of error variances, the effect of biased person parameter estimation could then be evaluated for various IRT models, estimators, and item pools, to investigate how serious its consequences are for the actual practice of adaptive testing.</p>
</sec>
</sec>
</body>
<back>
<app-group>
<app id="app1-0146621612443304">
<title>Appendix</title>
<table-wrap id="table2-0146621612443304" position="float">
<label>Table A1.</label>
<caption>
<p>Slopes of Regressions of Mean Bias of <inline-formula id="inline-formula38-0146621612443304">
<mml:math display="inline" id="math45-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula> on True θ</p>
</caption>
<graphic alternate-form-of="table2-0146621612443304" xlink:href="10.1177_0146621612443304-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="7">LLTM</th>
</tr>
<tr>
<th align="center" colspan="7"><italic>N</italic></th>
</tr>
<tr>
<th align="left"><inline-formula id="inline-formula39-0146621612443304">
<mml:math display="inline" id="math46-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">Pool</th>
<th align="center"><inline-formula id="inline-formula40-0146621612443304">
<mml:math display="inline" id="math47-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">15</th>
<th align="center">30</th>
<th align="center">50</th>
<th align="center">100</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.000</td>
<td>512</td>
<td>WML</td>
<td>−0.010</td>
<td>0.004</td>
<td>−0.002</td>
<td>−0.002</td>
</tr>
<tr>
<td>0.000</td>
<td>512</td>
<td>EAP</td>
<td>
<bold>−0.230</bold>
</td>
<td>
<bold>−0.127</bold>
</td>
<td>
<bold>−0.081</bold>
</td>
<td>
<bold>−0.044</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>512</td>
<td>MAP</td>
<td>
<bold>−0.246</bold>
</td>
<td>
<bold>−0.137</bold>
</td>
<td>
<bold>−0.087</bold>
</td>
<td>
<bold>−0.048</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>512</td>
<td>ML</td>
<td>0.023</td>
<td>0.020</td>
<td>
<bold>0.019</bold>
</td>
<td>0.004</td>
</tr>
<tr>
<td>0.000</td>
<td>1,024</td>
<td>WML</td>
<td>−0.007</td>
<td>−0.001</td>
<td>−0.005</td>
<td>−0.001</td>
</tr>
<tr>
<td>0.000</td>
<td>1,024</td>
<td>EAP</td>
<td>
<bold>−0.227</bold>
</td>
<td>
<bold>−0.130</bold>
</td>
<td>
<bold>−0.077</bold>
</td>
<td>
<bold>−0.041</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>1,024</td>
<td>MAP</td>
<td>
<bold>−0.239</bold>
</td>
<td>
<bold>−0.139</bold>
</td>
<td>
<bold>−0.086</bold>
</td>
<td>
<bold>−0.048</bold>
</td>
</tr>
<tr>
<td>0.000</td>
<td>1,024</td>
<td>ML</td>
<td>0.019</td>
<td>0.012</td>
<td>0.006</td>
<td>0.005</td>
</tr>
<tr>
<td>0.050</td>
<td>512</td>
<td>WML</td>
<td>
<bold>0.096</bold>
</td>
<td>
<bold>0.112</bold>
</td>
<td>
<bold>0.101</bold>
</td>
<td>
<bold>0.099</bold>
</td>
</tr>
<tr>
<td>0.050</td>
<td>512</td>
<td>EAP</td>
<td>
<bold>−0.186</bold>
</td>
<td>
<bold>−0.056</bold>
</td>
<td>0.002</td>
<td>0.039</td>
</tr>
<tr>
<td>0.050</td>
<td>512</td>
<td>MAP</td>
<td>
<bold>−0.190</bold>
</td>
<td>−0.065</td>
<td>−0.007</td>
<td>0.032</td>
</tr>
<tr>
<td>0.050</td>
<td>512</td>
<td>ML</td>
<td>
<bold>0.140</bold>
</td>
<td>
<bold>0.133</bold>
</td>
<td>
<bold>0.125</bold>
</td>
<td>
<bold>0.105</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>512</td>
<td>WML</td>
<td>
<bold>0.198</bold>
</td>
<td>
<bold>0.203</bold>
</td>
<td>
<bold>0.193</bold>
</td>
<td>
<bold>0.181</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>512</td>
<td>EAP</td>
<td>
<bold>−0.148</bold>
</td>
<td>0.002</td>
<td>
<bold>0.072</bold>
</td>
<td>
<bold>0.109</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>512</td>
<td>MAP</td>
<td>
<bold>−0.153</bold>
</td>
<td>−0.005</td>
<td>0.064</td>
<td>
<bold>0.101</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>512</td>
<td>ML</td>
<td>
<bold>0.240</bold>
</td>
<td>
<bold>0.238</bold>
</td>
<td>
<bold>0.217</bold>
</td>
<td>
<bold>0.186</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>1,024</td>
<td>WML</td>
<td>
<bold>0.201</bold>
</td>
<td>
<bold>0.231</bold>
</td>
<td>
<bold>0.229</bold>
</td>
<td>
<bold>0.215</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>1,024</td>
<td>EAP</td>
<td>
<bold>−0.124</bold>
</td>
<td>0.024</td>
<td>
<bold>0.100</bold>
</td>
<td>
<bold>0.145</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>1,024</td>
<td>MAP</td>
<td>
<bold>−0.150</bold>
</td>
<td>0.017</td>
<td>
<bold>0.086</bold>
</td>
<td>
<bold>0.139</bold>
</td>
</tr>
<tr>
<td>0.100</td>
<td>1,024</td>
<td>ML</td>
<td>
<bold>0.258</bold>
</td>
<td>
<bold>0.254</bold>
</td>
<td>
<bold>0.246</bold>
</td>
<td>
<bold>0.222</bold>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0146621612443304">
<p>Note: <inline-formula id="inline-formula41-0146621612443304">
<mml:math display="inline" id="math48-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula> = estimator for the person parameter; LLTM = linear logistic test model; <italic>N</italic> = test length; <inline-formula id="inline-formula42-0146621612443304">
<mml:math display="inline" id="math49-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula> = error variance of the basic parameters; Pool = size of item pool; WML = weighted maximum likelihood; EAP = expected a posteriori; MAP = maximum a posteriori; ML = maximum likelihood. Slopes are boldface if significantly different from zero at the 95% level.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table3-0146621612443304" position="float">
<label>Table A2.</label>
<caption>
<p>Correlations of Estimated and True Person Parameters</p>
</caption>
<graphic alternate-form-of="table3-0146621612443304" xlink:href="10.1177_0146621612443304-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">
<inline-formula id="inline-formula43-0146621612443304">
<mml:math display="inline" id="math50-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">
<inline-formula id="inline-formula44-0146621612443304">
<mml:math display="inline" id="math51-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula>
</th>
<th align="center">Model</th>
<th align="center"><italic>R</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td>0.0</td>
<td>MAP</td>
<td>Rasch</td>
<td>.957</td>
</tr>
<tr>
<td>0.0</td>
<td>MAP</td>
<td>2PL</td>
<td>.972</td>
</tr>
<tr>
<td>0.0</td>
<td>MAP</td>
<td>3PL</td>
<td>.970</td>
</tr>
<tr>
<td>0.0</td>
<td>WML</td>
<td>Rasch</td>
<td>.956</td>
</tr>
<tr>
<td>0.0</td>
<td>WML</td>
<td>2PL</td>
<td>.971</td>
</tr>
<tr>
<td>0.0</td>
<td>WML</td>
<td>3PL</td>
<td>.971</td>
</tr>
<tr>
<td>0.1</td>
<td>MAP</td>
<td>Rasch</td>
<td>.959</td>
</tr>
<tr>
<td>0.1</td>
<td>MAP</td>
<td>2PL</td>
<td>.971</td>
</tr>
<tr>
<td>0.1</td>
<td>MAP</td>
<td>3PL</td>
<td>.970</td>
</tr>
<tr>
<td>0.1</td>
<td>WML</td>
<td>Rasch</td>
<td>.957</td>
</tr>
<tr>
<td>0.1</td>
<td>WML</td>
<td>2PL</td>
<td>.970</td>
</tr>
<tr>
<td>0.1</td>
<td>WML</td>
<td>3PL</td>
<td>.970</td>
</tr>
<tr>
<td>0.5</td>
<td>MAP</td>
<td>Rasch</td>
<td>.954</td>
</tr>
<tr>
<td>0.5</td>
<td>MAP</td>
<td>2PL</td>
<td>.972</td>
</tr>
<tr>
<td>0.5</td>
<td>MAP</td>
<td>3PL</td>
<td>.965</td>
</tr>
<tr>
<td>0.5</td>
<td>WML</td>
<td>Rasch</td>
<td>.944</td>
</tr>
<tr>
<td>0.5</td>
<td>WML</td>
<td>2PL</td>
<td>.970</td>
</tr>
<tr>
<td>0.5</td>
<td>WML</td>
<td>3PL</td>
<td>.964</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn3-0146621612443304">
<p>Note: <inline-formula id="inline-formula45-0146621612443304">
<mml:math display="inline" id="math52-0146621612443304">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>β</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math></inline-formula> = error variance of the difficulty parameters; <inline-formula id="inline-formula46-0146621612443304">
<mml:math display="inline" id="math53-0146621612443304">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>θ</mml:mi>
<mml:mo stretchy="true">^</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math></inline-formula> = estimator of the person parameter; MAP = maximum a posteriori; 2PL model = two-parameter logistic model; 3PL model = three-parameter logistic model; WML = weighted maximum likelihood. Each correlation was calculated from a simulation (1,000 items in the pool; 50 items in each adaptive test; and 2,000 normally distributed person parameters).</p>
</fn>
</table-wrap-foot>
</table-wrap>
</app>
</app-group>
<fn-group>
<fn fn-type="conflict">
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
</fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-0146621612443304">
<label>1.</label>
<p>The R code is available from the author on request.</p>
</fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Bradlow</surname><given-names>E.</given-names></name>
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group> (<year>1999</year>). <article-title>A Bayesian random effects model for testlets</article-title>. <source>Psychometrika</source>, <volume>64</volume>, <fpage>153</fpage>-<lpage>168</lpage>.</citation>
</ref>
<ref id="bibr2-0146621612443304">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Camilli</surname><given-names>G.</given-names></name>
<name><surname>Shepard</surname><given-names>L.</given-names></name>
</person-group> (<year>1994</year>). <source>Methods for identifying biased test items</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr3-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>De Boeck</surname><given-names>P.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Random item IRT models</article-title>. <source>Psychometrika</source>, <volume>73</volume>, <fpage>533</fpage>-<lpage>559</lpage>.</citation>
</ref>
<ref id="bibr4-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fischer</surname><given-names>G.</given-names></name>
</person-group> (<year>1973</year>). <article-title>The linear logistic test model as an instrument in educational research</article-title>. <source>Acta Psychologica</source>, <volume>37</volume>, <fpage>359</fpage>-<lpage>374</lpage>.</citation>
</ref>
<ref id="bibr5-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Geerlings</surname><given-names>H.</given-names></name>
<name><surname>Glas</surname><given-names>C. A. W.</given-names></name>
<name><surname>van der Linden</surname><given-names>W. J.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Modeling rule-based item generation</article-title>. <source>Psychometrika</source>, <volume>76</volume>, <fpage>337</fpage>-<lpage>359</lpage>.</citation>
</ref>
<ref id="bibr6-0146621612443304">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Holland</surname><given-names>P. W.</given-names></name>
<name><surname>Wainer</surname><given-names>H.</given-names></name>
</person-group> (<year>1993</year>). <source>Differential item functioning</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</citation>
</ref>
<ref id="bibr7-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Holling</surname><given-names>H.</given-names></name>
<name><surname>Bertling</surname><given-names>J. P.</given-names></name>
<name><surname>Zeuch</surname><given-names>N.</given-names></name>
</person-group> (<year>2009</year>). <article-title>Automatic item generation of probability word problems</article-title>. <source>Studies in Educational Evaluation</source>, <volume>35</volume>, <fpage>71</fpage>-<lpage>76</lpage>.</citation>
</ref>
<ref id="bibr8-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ip</surname><given-names>E. H.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Interpretation of the three-parameter testlet response model and information function</article-title>. <source>Applied Psychological Measurement</source>, <volume>34</volume>, <fpage>467</fpage>-<lpage>482</lpage>.</citation>
</ref>
<ref id="bibr9-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Magis</surname><given-names>D.</given-names></name>
<name><surname>Raîche</surname><given-names>G.</given-names></name>
</person-group> (<year>2011</year>). <article-title>catR: An R package for computerized adaptive testing</article-title>. <source>Applied Psychological Measurement</source>, <volume>35</volume>, <fpage>576</fpage>-<lpage>577</lpage>.</citation>
</ref>
<ref id="bibr10-0146621612443304">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Osterlind</surname><given-names>S.</given-names></name>
<name><surname>Everson</surname><given-names>H.</given-names></name>
</person-group> (<year>2009</year>). <source>Differential item functioning</source>. <publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</citation>
</ref>
<ref id="bibr11-0146621612443304">
<citation citation-type="web">
<collab>R Development Core Team</collab>. (<year>2009</year>). <article-title>R: A language and environment for statistical computing. ISBN 3-900051-07-0. Vienna, Austria: R Foundation for Statistical Computing</article-title>. <comment>Available from <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org">http://www.R-project.org</ext-link></comment></citation>
</ref>
<ref id="bibr12-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Rijmen</surname><given-names>F.</given-names></name>
<name><surname>De Boeck</surname><given-names>P.</given-names></name>
</person-group> (<year>2002</year>). <article-title>The random weights linear logistic test model</article-title>. <source>Applied Psychological Measurement</source>, <volume>26</volume>, <fpage>271</fpage>-<lpage>285</lpage>.</citation>
</ref>
<ref id="bibr13-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scott</surname><given-names>S.</given-names></name>
<name><surname>Ip</surname><given-names>E.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Empirical Bayes and item-clustering effects in a latent variable hierarchical model</article-title>. <source>Journal of the American Statistical Association</source>, <volume>97</volume>, <fpage>409</fpage>-<lpage>419</lpage>.</citation>
</ref>
<ref id="bibr14-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sireci</surname><given-names>S.</given-names></name>
<name><surname>Thissen</surname><given-names>D.</given-names></name>
<name><surname>Wainer</surname><given-names>H.</given-names></name>
</person-group> (<year>1991</year>). <article-title>On the reliability of testlet-based tests</article-title>. <source>Journal of Educational Measurement</source>, <volume>28</volume>, <fpage>237</fpage>-<lpage>247</lpage>.</citation>
</ref>
<ref id="bibr15-0146621612443304">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>van der Linden</surname><given-names>W.</given-names></name>
</person-group> (<year>2010</year>). <source>Elements of adaptive testing</source>. <publisher-name>Springer, NY</publisher-name>; <publisher-loc>Dordrecht Heidelberg, London</publisher-loc>.</citation>
</ref>
<ref id="bibr16-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van der Linden</surname><given-names>W.</given-names></name>
<name><surname>Glas</surname><given-names>C.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Capitalization on item calibration error in adaptive testing</article-title>. <source>Applied Measurement in Education</source>, <volume>13</volume>, <fpage>35</fpage>-<lpage>53</lpage>.</citation>
</ref>
<ref id="bibr17-0146621612443304">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Bradlow</surname><given-names>E. T.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group> (<year>2007</year>). <source>Testlet response theory and its applications</source>. <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation>
</ref>
<ref id="bibr18-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wainer</surname><given-names>H.</given-names></name>
<name><surname>Kiely</surname><given-names>G.</given-names></name>
</person-group> (<year>1987</year>). <article-title>Item clusters and computerized adaptive testing: A case for testlets</article-title>. <source>Journal of Educational Measurement</source>, <volume>24</volume>, <fpage>185</fpage>-<lpage>201</lpage>.</citation>
</ref>
<ref id="bibr19-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Wang</surname><given-names>W.</given-names></name>
<name><surname>Wilson</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Exploring local item dependence using a random-effects facet model</article-title>. <source>Applied Psychological Measurement</source>, <volume>29</volume>, <fpage>296</fpage>-<lpage>318</lpage>.</citation>
</ref>
<ref id="bibr20-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Warm</surname><given-names>T. A.</given-names></name>
</person-group> (<year>1989</year>). <article-title>Weighted likelihood estimation of ability in item response models</article-title>. <source>Psychometrika</source>, <volume>54</volume>, <fpage>427</fpage>-<lpage>450</lpage>.</citation>
</ref>
<ref id="bibr21-0146621612443304">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zumbo</surname><given-names>B.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Three generations of DIF analyses: Considering where it has been, where it is now, and where it is going</article-title>. <source>Language Assessment Quarterly</source>, <volume>4</volume>, <fpage>223</fpage>-<lpage>233</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>